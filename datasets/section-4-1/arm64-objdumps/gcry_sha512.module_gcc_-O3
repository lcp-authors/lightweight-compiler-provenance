
/home/anony/Documents/anonymous--anonymous/pizzolotto-binaries//gcry_sha512.module_gcc_-O3:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <sha512_init>:
   0:	mov	x8, #0xc908                	// #51464
   4:	mov	x7, #0xa73b                	// #42811
   8:	mov	x6, #0xf82b                	// #63531
   c:	mov	x5, #0x36f1                	// #14065
  10:	mov	x4, #0x82d1                	// #33489
  14:	mov	x3, #0x6c1f                	// #27679
  18:	mov	x2, #0xbd6b                	// #48491
  1c:	mov	x1, #0x2179                	// #8569
  20:	movk	x8, #0xf3bc, lsl #16
  24:	movk	x7, #0x84ca, lsl #16
  28:	movk	x6, #0xfe94, lsl #16
  2c:	movk	x5, #0x5f1d, lsl #16
  30:	movk	x4, #0xade6, lsl #16
  34:	movk	x3, #0x2b3e, lsl #16
  38:	movk	x2, #0xfb41, lsl #16
  3c:	movk	x1, #0x137e, lsl #16
  40:	movk	x8, #0xe667, lsl #32
  44:	movk	x7, #0xae85, lsl #32
  48:	movk	x6, #0xf372, lsl #32
  4c:	movk	x5, #0xf53a, lsl #32
  50:	movk	x4, #0x527f, lsl #32
  54:	movk	x3, #0x688c, lsl #32
  58:	movk	x2, #0xd9ab, lsl #32
  5c:	movk	x1, #0xcd19, lsl #32
  60:	movk	x8, #0x6a09, lsl #48
  64:	movk	x7, #0xbb67, lsl #48
  68:	movk	x6, #0x3c6e, lsl #48
  6c:	movk	x5, #0xa54f, lsl #48
  70:	movk	x4, #0x510e, lsl #48
  74:	movk	x3, #0x9b05, lsl #48
  78:	movk	x2, #0x1f83, lsl #48
  7c:	movk	x1, #0x5be0, lsl #48
  80:	stp	x8, x7, [x0]
  84:	stp	x6, x5, [x0, #16]
  88:	stp	x4, x3, [x0, #32]
  8c:	stp	x2, x1, [x0, #48]
  90:	str	xzr, [x0, #64]
  94:	str	wzr, [x0, #200]
  98:	ret
  9c:	nop

00000000000000a0 <sha384_init>:
  a0:	mov	x8, #0x9ed8                	// #40664
  a4:	mov	x7, #0xd507                	// #54535
  a8:	mov	x6, #0xdd17                	// #56599
  ac:	mov	x5, #0x5939                	// #22841
  b0:	mov	x4, #0xb31                 	// #2865
  b4:	mov	x3, #0x1511                	// #5393
  b8:	mov	x2, #0x8fa7                	// #36775
  bc:	mov	x1, #0x4fa4                	// #20388
  c0:	movk	x8, #0xc105, lsl #16
  c4:	movk	x7, #0x367c, lsl #16
  c8:	movk	x6, #0x3070, lsl #16
  cc:	movk	x5, #0xf70e, lsl #16
  d0:	movk	x4, #0xffc0, lsl #16
  d4:	movk	x3, #0x6858, lsl #16
  d8:	movk	x2, #0x64f9, lsl #16
  dc:	movk	x1, #0xbefa, lsl #16
  e0:	movk	x8, #0x9d5d, lsl #32
  e4:	movk	x7, #0x292a, lsl #32
  e8:	movk	x6, #0x15a, lsl #32
  ec:	movk	x5, #0xecd8, lsl #32
  f0:	movk	x4, #0x2667, lsl #32
  f4:	movk	x3, #0x4a87, lsl #32
  f8:	movk	x2, #0x2e0d, lsl #32
  fc:	movk	x1, #0x481d, lsl #32
 100:	movk	x8, #0xcbbb, lsl #48
 104:	movk	x7, #0x629a, lsl #48
 108:	movk	x6, #0x9159, lsl #48
 10c:	movk	x5, #0x152f, lsl #48
 110:	movk	x4, #0x6733, lsl #48
 114:	movk	x3, #0x8eb4, lsl #48
 118:	movk	x2, #0xdb0c, lsl #48
 11c:	movk	x1, #0x47b5, lsl #48
 120:	stp	x8, x7, [x0]
 124:	stp	x6, x5, [x0, #16]
 128:	stp	x4, x3, [x0, #32]
 12c:	stp	x2, x1, [x0, #48]
 130:	str	xzr, [x0, #64]
 134:	str	wzr, [x0, #200]
 138:	ret
 13c:	nop

0000000000000140 <transform>:
 140:	sub	sp, sp, #0x2d0
 144:	mov	w18, #0x10                  	// #16
 148:	add	x7, sp, #0x50
 14c:	mov	x2, x7
 150:	stp	x29, x30, [sp]
 154:	mov	x29, sp
 158:	stp	x19, x20, [sp, #16]
 15c:	stp	x21, x22, [sp, #32]
 160:	stp	x23, x24, [sp, #48]
 164:	str	x25, [sp, #64]
 168:	ldp	x3, x15, [x1]
 16c:	ldp	x14, x8, [x1, #16]
 170:	ldp	x13, x12, [x1, #32]
 174:	ldp	x11, x10, [x1, #48]
 178:	rev	x15, x15
 17c:	ldp	x9, x6, [x1, #64]
 180:	rev	x14, x14
 184:	ldp	x5, x4, [x1, #80]
 188:	rev	x8, x8
 18c:	rev	x13, x13
 190:	rev	x12, x12
 194:	rev	x11, x11
 198:	rev	x10, x10
 19c:	rev	x6, x6
 1a0:	rev	x9, x9
 1a4:	rev	x3, x3
 1a8:	stp	x3, x15, [sp, #80]
 1ac:	rev	x5, x5
 1b0:	rev	x4, x4
 1b4:	stp	x14, x8, [sp, #96]
 1b8:	mov	x17, x6
 1bc:	stp	x13, x12, [sp, #112]
 1c0:	mov	x19, x4
 1c4:	mov	x8, x5
 1c8:	stp	x11, x10, [sp, #128]
 1cc:	stp	x9, x6, [sp, #144]
 1d0:	stp	x5, x4, [sp, #160]
 1d4:	ldp	x6, x20, [x1, #96]
 1d8:	ldp	x4, x5, [x1, #112]
 1dc:	ldp	x16, x15, [x0]
 1e0:	ldp	x14, x13, [x0, #16]
 1e4:	rev	x20, x20
 1e8:	ldp	x12, x11, [x0, #32]
 1ec:	rev	x1, x4
 1f0:	ldp	x10, x9, [x0, #48]
 1f4:	rev	x5, x5
 1f8:	rev	x6, x6
 1fc:	mov	x4, x20
 200:	stp	x6, x20, [sp, #176]
 204:	mov	x20, x1
 208:	stp	x1, x5, [sp, #192]
 20c:	mov	x1, x5
 210:	ror	x5, x20, #61
 214:	ldp	x25, x23, [x2, #8]
 218:	eor	x5, x5, x20, ror #19
 21c:	add	x3, x3, x17
 220:	eor	x17, x5, x20, lsr #6
 224:	ldr	x22, [x2, #24]
 228:	ror	x21, x1, #19
 22c:	eor	x21, x21, x1, ror #61
 230:	add	w18, w18, #0x7
 234:	add	x19, x23, x19
 238:	ror	x5, x25, #8
 23c:	eor	x5, x5, x25, ror #1
 240:	eor	x21, x21, x1, lsr #6
 244:	eor	x5, x5, x25, lsr #7
 248:	add	x21, x21, x25
 24c:	add	x17, x17, x5
 250:	ror	x5, x23, #1
 254:	add	x17, x17, x3
 258:	eor	x5, x5, x23, ror #8
 25c:	eor	x5, x5, x23, lsr #7
 260:	cmp	w18, #0x4f
 264:	add	x8, x5, x8
 268:	ror	x3, x17, #19
 26c:	ldp	x5, x23, [x2, #32]
 270:	eor	x3, x3, x17, ror #61
 274:	eor	x24, x3, x17, lsr #6
 278:	ror	x3, x22, #1
 27c:	eor	x3, x3, x22, ror #8
 280:	add	x8, x21, x8
 284:	eor	x3, x3, x22, lsr #7
 288:	add	x22, x22, x6
 28c:	add	x3, x3, x24
 290:	ror	x21, x8, #19
 294:	add	x19, x3, x19
 298:	ror	x3, x5, #1
 29c:	eor	x3, x3, x5, ror #8
 2a0:	eor	x21, x21, x8, ror #61
 2a4:	eor	x3, x3, x5, lsr #7
 2a8:	ror	x6, x19, #19
 2ac:	add	x5, x5, x4
 2b0:	ror	x4, x23, #1
 2b4:	eor	x21, x21, x8, lsr #6
 2b8:	eor	x4, x4, x23, ror #8
 2bc:	eor	x6, x6, x19, ror #61
 2c0:	eor	x4, x4, x23, lsr #7
 2c4:	eor	x6, x6, x19, lsr #6
 2c8:	add	x3, x3, x21
 2cc:	add	x4, x4, x6
 2d0:	add	x6, x3, x22
 2d4:	ldp	x21, x3, [x2, #48]
 2d8:	add	x4, x4, x5
 2dc:	add	x23, x23, x20
 2e0:	ror	x22, x6, #19
 2e4:	eor	x22, x22, x6, ror #61
 2e8:	ror	x20, x4, #19
 2ec:	eor	x20, x20, x4, ror #61
 2f0:	eor	x22, x22, x6, lsr #6
 2f4:	eor	x20, x20, x4, lsr #6
 2f8:	stp	x17, x8, [x2, #128]
 2fc:	ror	x5, x21, #1
 300:	eor	x5, x5, x21, ror #8
 304:	stp	x19, x6, [x2, #144]
 308:	eor	x5, x5, x21, lsr #7
 30c:	add	x21, x21, x1
 310:	ror	x1, x3, #1
 314:	eor	x1, x1, x3, ror #8
 318:	add	x5, x5, x22
 31c:	eor	x1, x1, x3, lsr #7
 320:	add	x1, x1, x20
 324:	add	x20, x5, x23
 328:	add	x1, x1, x21
 32c:	stp	x4, x20, [x2, #160]
 330:	add	x2, x2, #0x38
 334:	str	x1, [x2, #120]
 338:	b.ne	210 <transform+0xd0>  // b.any
 33c:	ldr	x1, [sp, #592]
 340:	adrp	x6, 0 <sha512_init>
 344:	ldr	x2, [sp, #696]
 348:	add	x8, x7, #0x280
 34c:	ror	x4, x1, #1
 350:	ldr	x3, [sp, #584]
 354:	ror	x5, x2, #19
 358:	ldr	x17, [sp, #656]
 35c:	eor	x5, x5, x2, ror #61
 360:	eor	x4, x4, x1, ror #8
 364:	eor	x2, x5, x2, lsr #6
 368:	eor	x1, x4, x1, lsr #7
 36c:	add	x3, x3, x17
 370:	add	x1, x1, x2
 374:	mov	x20, x9
 378:	ldr	x19, [x6]
 37c:	mov	x18, x14
 380:	mov	x6, x12
 384:	mov	x30, x15
 388:	mov	x2, x10
 38c:	mov	x5, x11
 390:	mov	x17, x13
 394:	mov	x4, x16
 398:	add	x1, x1, x3
 39c:	str	x1, [sp, #712]
 3a0:	and	x23, x6, x5
 3a4:	bic	x21, x2, x6
 3a8:	eor	x21, x21, x23
 3ac:	ror	x3, x6, #18
 3b0:	ldp	x22, x23, [x7]
 3b4:	eor	x3, x3, x6, ror #14
 3b8:	ldr	x1, [x19]
 3bc:	eor	x3, x3, x6, ror #41
 3c0:	add	x3, x3, x21
 3c4:	eor	x24, x30, x18
 3c8:	and	x24, x24, x4
 3cc:	ror	x21, x4, #34
 3d0:	add	x1, x1, x22
 3d4:	eor	x21, x21, x4, ror #28
 3d8:	add	x3, x3, x1
 3dc:	eor	x21, x21, x4, ror #39
 3e0:	add	x3, x3, x20
 3e4:	add	x19, x19, #0x40
 3e8:	add	x17, x3, x17
 3ec:	ldur	x20, [x19, #-56]
 3f0:	ror	x1, x17, #18
 3f4:	and	x25, x17, x6
 3f8:	bic	x22, x5, x17
 3fc:	eor	x1, x1, x17, ror #14
 400:	eor	x22, x22, x25
 404:	eor	x1, x1, x17, ror #41
 408:	add	x20, x20, x23
 40c:	add	x1, x1, x22
 410:	add	x1, x1, x20
 414:	and	x20, x30, x18
 418:	add	x2, x1, x2
 41c:	eor	x24, x24, x20
 420:	add	x18, x2, x18
 424:	add	x21, x21, x24
 428:	and	x25, x17, x18
 42c:	bic	x22, x6, x18
 430:	add	x3, x21, x3
 434:	ror	x1, x18, #18
 438:	eor	x1, x1, x18, ror #14
 43c:	eor	x22, x22, x25
 440:	eor	x21, x4, x30
 444:	eor	x1, x1, x18, ror #41
 448:	add	x1, x1, x22
 44c:	and	x21, x21, x3
 450:	and	x22, x4, x30
 454:	eor	x21, x21, x22
 458:	ldp	x23, x22, [x7, #16]
 45c:	add	x7, x7, #0x40
 460:	ldur	x20, [x19, #-48]
 464:	add	x20, x20, x23
 468:	add	x1, x1, x20
 46c:	ror	x20, x3, #34
 470:	add	x1, x1, x5
 474:	add	x5, x1, x30
 478:	eor	x30, x20, x3, ror #28
 47c:	eor	x30, x30, x3, ror #39
 480:	and	x24, x18, x5
 484:	add	x30, x30, x21
 488:	ror	x20, x5, #18
 48c:	ldur	x23, [x19, #-40]
 490:	add	x2, x30, x2
 494:	bic	x21, x17, x5
 498:	eor	x20, x20, x5, ror #14
 49c:	eor	x21, x21, x24
 4a0:	eor	x20, x20, x5, ror #41
 4a4:	add	x23, x23, x22
 4a8:	add	x20, x20, x21
 4ac:	eor	x22, x3, x4
 4b0:	ror	x21, x2, #34
 4b4:	add	x20, x20, x23
 4b8:	and	x22, x22, x2
 4bc:	and	x23, x3, x4
 4c0:	eor	x21, x21, x2, ror #28
 4c4:	add	x6, x20, x6
 4c8:	eor	x21, x21, x2, ror #39
 4cc:	eor	x20, x22, x23
 4d0:	add	x4, x6, x4
 4d4:	add	x21, x21, x20
 4d8:	and	x25, x5, x4
 4dc:	add	x1, x21, x1
 4e0:	bic	x24, x18, x4
 4e4:	eor	x22, x3, x2
 4e8:	eor	x24, x24, x25
 4ec:	ror	x21, x1, #34
 4f0:	and	x25, x3, x2
 4f4:	ror	x20, x4, #18
 4f8:	and	x22, x22, x1
 4fc:	eor	x21, x21, x1, ror #28
 500:	ldur	x30, [x7, #-32]
 504:	eor	x22, x22, x25
 508:	ldur	x23, [x19, #-32]
 50c:	eor	x20, x20, x4, ror #14
 510:	eor	x21, x21, x1, ror #39
 514:	eor	x20, x20, x4, ror #41
 518:	add	x21, x21, x22
 51c:	add	x23, x23, x30
 520:	add	x6, x21, x6
 524:	add	x20, x20, x24
 528:	add	x20, x20, x23
 52c:	eor	x22, x2, x1
 530:	add	x17, x20, x17
 534:	ror	x21, x6, #34
 538:	add	x20, x3, x17
 53c:	and	x25, x2, x1
 540:	and	x22, x22, x6
 544:	eor	x21, x21, x6, ror #28
 548:	eor	x22, x22, x25
 54c:	eor	x21, x21, x6, ror #39
 550:	add	x21, x21, x22
 554:	ror	x3, x20, #18
 558:	ldur	x22, [x7, #-24]
 55c:	and	x24, x4, x20
 560:	ldur	x30, [x19, #-24]
 564:	bic	x23, x5, x20
 568:	eor	x3, x3, x20, ror #14
 56c:	eor	x23, x23, x24
 570:	eor	x3, x3, x20, ror #41
 574:	add	x30, x30, x22
 578:	add	x3, x3, x23
 57c:	add	x17, x21, x17
 580:	add	x3, x3, x30
 584:	eor	x22, x1, x6
 588:	add	x18, x3, x18
 58c:	ror	x21, x17, #34
 590:	add	x2, x2, x18
 594:	and	x3, x1, x6
 598:	eor	x21, x21, x17, ror #28
 59c:	and	x22, x22, x17
 5a0:	eor	x22, x22, x3
 5a4:	eor	x21, x21, x17, ror #39
 5a8:	ror	x30, x2, #18
 5ac:	ldur	x23, [x7, #-16]
 5b0:	add	x21, x21, x22
 5b4:	ldur	x3, [x19, #-16]
 5b8:	bic	x22, x4, x2
 5bc:	and	x24, x20, x2
 5c0:	eor	x30, x30, x2, ror #14
 5c4:	add	x18, x21, x18
 5c8:	eor	x30, x30, x2, ror #41
 5cc:	eor	x21, x22, x24
 5d0:	add	x3, x3, x23
 5d4:	add	x30, x30, x21
 5d8:	eor	x22, x6, x17
 5dc:	add	x30, x30, x3
 5e0:	ror	x21, x18, #28
 5e4:	add	x3, x30, x5
 5e8:	and	x23, x6, x17
 5ec:	and	x22, x22, x18
 5f0:	eor	x30, x21, x18, ror #34
 5f4:	add	x5, x1, x3
 5f8:	eor	x21, x22, x23
 5fc:	eor	x30, x30, x18, ror #39
 600:	bic	x23, x20, x5
 604:	add	x30, x30, x21
 608:	ror	x1, x5, #14
 60c:	add	x30, x30, x3
 610:	eor	x1, x1, x5, ror #18
 614:	ldur	x24, [x7, #-8]
 618:	and	x3, x2, x5
 61c:	ldur	x22, [x19, #-8]
 620:	eor	x23, x23, x3
 624:	eor	x1, x1, x5, ror #41
 628:	eor	x21, x17, x18
 62c:	add	x1, x1, x23
 630:	ror	x3, x30, #28
 634:	and	x21, x21, x30
 638:	and	x23, x17, x18
 63c:	eor	x3, x3, x30, ror #34
 640:	add	x22, x22, x24
 644:	eor	x21, x21, x23
 648:	eor	x3, x3, x30, ror #39
 64c:	add	x1, x1, x22
 650:	cmp	x7, x8
 654:	add	x1, x1, x4
 658:	add	x4, x3, x21
 65c:	add	x6, x6, x1
 660:	add	x4, x4, x1
 664:	b.ne	3a0 <transform+0x260>  // b.any
 668:	add	x15, x15, x30
 66c:	add	x3, x9, x20
 670:	add	x4, x16, x4
 674:	add	x14, x14, x18
 678:	add	x13, x13, x17
 67c:	add	x6, x12, x6
 680:	add	x1, x11, x5
 684:	add	x2, x10, x2
 688:	stp	x4, x15, [x0]
 68c:	stp	x14, x13, [x0, #16]
 690:	stp	x6, x1, [x0, #32]
 694:	stp	x2, x3, [x0, #48]
 698:	ldp	x29, x30, [sp]
 69c:	ldp	x19, x20, [sp, #16]
 6a0:	ldp	x21, x22, [sp, #32]
 6a4:	ldp	x23, x24, [sp, #48]
 6a8:	ldr	x25, [sp, #64]
 6ac:	add	sp, sp, #0x2d0
 6b0:	ret
 6b4:	nop
	...

00000000000006c0 <sha512_read>:
 6c0:	add	x0, x0, #0x48
 6c4:	ret

00000000000006c8 <sha512_write>:
 6c8:	stp	x29, x30, [sp, #-48]!
 6cc:	mov	x29, sp
 6d0:	stp	x19, x20, [sp, #16]
 6d4:	mov	x20, x1
 6d8:	ldr	w1, [x0, #200]
 6dc:	stp	x21, x22, [sp, #32]
 6e0:	mov	x19, x0
 6e4:	mov	x21, x2
 6e8:	cmp	w1, #0x80
 6ec:	b.eq	7d0 <sha512_write+0x108>  // b.none
 6f0:	cbz	x20, 7c0 <sha512_write+0xf8>
 6f4:	cbz	w1, 734 <sha512_write+0x6c>
 6f8:	cbz	x2, 7c0 <sha512_write+0xf8>
 6fc:	sxtw	x0, w1
 700:	add	x1, x19, #0x48
 704:	b	720 <sha512_write+0x58>
 708:	str	w2, [x19, #200]
 70c:	subs	x21, x21, #0x1
 710:	ldrb	w3, [x20], #1
 714:	strb	w3, [x1, x0]
 718:	add	x0, x0, #0x1
 71c:	b.eq	834 <sha512_write+0x16c>  // b.none
 720:	add	w2, w0, #0x1
 724:	cmp	w0, #0x7f
 728:	b.le	708 <sha512_write+0x40>
 72c:	cmp	w0, #0x80
 730:	b.eq	7f8 <sha512_write+0x130>  // b.none
 734:	mov	x22, x20
 738:	cmp	x21, #0x7f
 73c:	b.ls	77c <sha512_write+0xb4>  // b.plast
 740:	sub	x22, x21, #0x80
 744:	and	x22, x22, #0xffffffffffffff80
 748:	add	x22, x22, #0x80
 74c:	add	x22, x20, x22
 750:	mov	x1, x20
 754:	mov	x0, x19
 758:	bl	140 <transform>
 75c:	str	wzr, [x19, #200]
 760:	ldr	x0, [x19, #64]
 764:	add	x20, x20, #0x80
 768:	cmp	x20, x22
 76c:	add	x0, x0, #0x1
 770:	str	x0, [x19, #64]
 774:	b.ne	750 <sha512_write+0x88>  // b.any
 778:	and	x21, x21, #0x7f
 77c:	mov	w0, #0x300                 	// #768
 780:	bl	0 <_gcry_burn_stack>
 784:	cbz	x21, 7c0 <sha512_write+0xf8>
 788:	ldrsw	x1, [x19, #200]
 78c:	add	x2, x19, #0x48
 790:	sub	x22, x22, x1
 794:	add	x21, x21, x1
 798:	b	7b4 <sha512_write+0xec>
 79c:	str	w0, [x19, #200]
 7a0:	ldrb	w0, [x22, x1]
 7a4:	strb	w0, [x2, x1]
 7a8:	add	x1, x1, #0x1
 7ac:	cmp	x1, x21
 7b0:	b.eq	7c0 <sha512_write+0xf8>  // b.none
 7b4:	add	w0, w1, #0x1
 7b8:	cmp	w1, #0x7f
 7bc:	b.le	79c <sha512_write+0xd4>
 7c0:	ldp	x19, x20, [sp, #16]
 7c4:	ldp	x21, x22, [sp, #32]
 7c8:	ldp	x29, x30, [sp], #48
 7cc:	ret
 7d0:	add	x1, x0, #0x48
 7d4:	bl	140 <transform>
 7d8:	mov	w0, #0x300                 	// #768
 7dc:	bl	0 <_gcry_burn_stack>
 7e0:	str	wzr, [x19, #200]
 7e4:	ldr	x0, [x19, #64]
 7e8:	add	x0, x0, #0x1
 7ec:	str	x0, [x19, #64]
 7f0:	cbnz	x20, 734 <sha512_write+0x6c>
 7f4:	b	7c0 <sha512_write+0xf8>
 7f8:	add	x1, x19, #0x48
 7fc:	mov	x0, x19
 800:	bl	140 <transform>
 804:	mov	w0, #0x300                 	// #768
 808:	bl	0 <_gcry_burn_stack>
 80c:	str	wzr, [x19, #200]
 810:	ldr	x0, [x19, #64]
 814:	cmp	x21, #0x7f
 818:	add	x0, x0, #0x1
 81c:	str	x0, [x19, #64]
 820:	b.hi	740 <sha512_write+0x78>  // b.pmore
 824:	mov	x22, x20
 828:	mov	w0, #0x300                 	// #768
 82c:	bl	0 <_gcry_burn_stack>
 830:	b	788 <sha512_write+0xc0>
 834:	cmp	w2, #0x80
 838:	b.ne	7c0 <sha512_write+0xf8>  // b.any
 83c:	mov	x0, x19
 840:	bl	140 <transform>
 844:	mov	w0, #0x300                 	// #768
 848:	bl	0 <_gcry_burn_stack>
 84c:	ldr	x0, [x19, #64]
 850:	str	wzr, [x19, #200]
 854:	add	x0, x0, #0x1
 858:	str	x0, [x19, #64]
 85c:	b	7c0 <sha512_write+0xf8>

0000000000000860 <sha512_final>:
 860:	stp	x29, x30, [sp, #-48]!
 864:	mov	x29, sp
 868:	ldr	w1, [x0, #200]
 86c:	stp	x19, x20, [sp, #16]
 870:	mov	x19, x0
 874:	add	x20, x0, #0x48
 878:	stp	x21, x22, [sp, #32]
 87c:	cmp	w1, #0x80
 880:	b.eq	d80 <sha512_final+0x520>  // b.none
 884:	ldr	x3, [x19, #64]
 888:	sxtw	x0, w1
 88c:	add	w5, w1, #0x1
 890:	lsl	x2, x3, #7
 894:	adds	x2, x0, x2
 898:	cset	x4, cs  // cs = hs, nlast
 89c:	cmp	w1, #0x6f
 8a0:	add	x4, x4, x3, lsr #57
 8a4:	lsl	x22, x2, #3
 8a8:	extr	x21, x4, x2, #61
 8ac:	b.le	aac <sha512_final+0x24c>
 8b0:	add	x0, x19, x0
 8b4:	str	w5, [x19, #200]
 8b8:	mov	w2, #0xffffff80            	// #-128
 8bc:	cmp	w5, #0x7f
 8c0:	strb	w2, [x0, #72]
 8c4:	b.gt	aa0 <sha512_final+0x240>
 8c8:	add	x5, x19, w5, sxtw
 8cc:	cmp	w1, #0x7e
 8d0:	add	w0, w1, #0x2
 8d4:	strb	wzr, [x5, #72]
 8d8:	b.eq	9e8 <sha512_final+0x188>  // b.none
 8dc:	add	x0, x19, w0, sxtw
 8e0:	cmp	w1, #0x7d
 8e4:	add	w2, w1, #0x3
 8e8:	strb	wzr, [x0, #72]
 8ec:	b.eq	9e8 <sha512_final+0x188>  // b.none
 8f0:	add	x2, x19, w2, sxtw
 8f4:	cmp	w1, #0x7c
 8f8:	add	w0, w1, #0x4
 8fc:	strb	wzr, [x2, #72]
 900:	b.eq	9e8 <sha512_final+0x188>  // b.none
 904:	add	x0, x19, w0, sxtw
 908:	cmp	w1, #0x7b
 90c:	add	w2, w1, #0x5
 910:	strb	wzr, [x0, #72]
 914:	b.eq	9e8 <sha512_final+0x188>  // b.none
 918:	add	x2, x19, w2, sxtw
 91c:	cmp	w1, #0x7a
 920:	add	w0, w1, #0x6
 924:	strb	wzr, [x2, #72]
 928:	b.eq	9e8 <sha512_final+0x188>  // b.none
 92c:	add	x0, x19, w0, sxtw
 930:	cmp	w1, #0x79
 934:	add	w2, w1, #0x7
 938:	strb	wzr, [x0, #72]
 93c:	b.eq	9e8 <sha512_final+0x188>  // b.none
 940:	add	x2, x19, w2, sxtw
 944:	cmp	w1, #0x78
 948:	add	w0, w1, #0x8
 94c:	strb	wzr, [x2, #72]
 950:	b.eq	9e8 <sha512_final+0x188>  // b.none
 954:	add	x0, x19, w0, sxtw
 958:	cmp	w1, #0x77
 95c:	add	w2, w1, #0x9
 960:	strb	wzr, [x0, #72]
 964:	b.eq	9e8 <sha512_final+0x188>  // b.none
 968:	add	x2, x19, w2, sxtw
 96c:	cmp	w1, #0x76
 970:	add	w0, w1, #0xa
 974:	strb	wzr, [x2, #72]
 978:	b.eq	9e8 <sha512_final+0x188>  // b.none
 97c:	add	x0, x19, w0, sxtw
 980:	cmp	w1, #0x75
 984:	add	w2, w1, #0xb
 988:	strb	wzr, [x0, #72]
 98c:	b.eq	9e8 <sha512_final+0x188>  // b.none
 990:	add	x2, x19, w2, sxtw
 994:	cmp	w1, #0x74
 998:	add	w0, w1, #0xc
 99c:	strb	wzr, [x2, #72]
 9a0:	b.eq	9e8 <sha512_final+0x188>  // b.none
 9a4:	add	x0, x19, w0, sxtw
 9a8:	cmp	w1, #0x73
 9ac:	add	w2, w1, #0xd
 9b0:	strb	wzr, [x0, #72]
 9b4:	b.eq	9e8 <sha512_final+0x188>  // b.none
 9b8:	add	x2, x19, w2, sxtw
 9bc:	cmp	w1, #0x72
 9c0:	add	w0, w1, #0xe
 9c4:	strb	wzr, [x2, #72]
 9c8:	b.eq	9e8 <sha512_final+0x188>  // b.none
 9cc:	add	x0, x19, w0, sxtw
 9d0:	cmp	w1, #0x71
 9d4:	add	w1, w1, #0xf
 9d8:	strb	wzr, [x0, #72]
 9dc:	b.eq	9e8 <sha512_final+0x188>  // b.none
 9e0:	add	x1, x19, w1, sxtw
 9e4:	strb	wzr, [x1, #72]
 9e8:	mov	w0, #0x80                  	// #128
 9ec:	str	w0, [x19, #200]
 9f0:	mov	x1, x20
 9f4:	mov	x0, x19
 9f8:	bl	140 <transform>
 9fc:	mov	w0, #0x300                 	// #768
 a00:	bl	0 <_gcry_burn_stack>
 a04:	str	wzr, [x19, #200]
 a08:	ldr	x0, [x19, #64]
 a0c:	add	x0, x0, #0x1
 a10:	str	x0, [x19, #64]
 a14:	mov	x0, x20
 a18:	mov	x2, #0x70                  	// #112
 a1c:	mov	w1, #0x0                   	// #0
 a20:	bl	0 <grub_memset>
 a24:	rev16	w2, w21
 a28:	rev	x3, x22
 a2c:	mov	x1, x20
 a30:	str	wzr, [x19, #184]
 a34:	strh	wzr, [x19, #188]
 a38:	mov	x0, x19
 a3c:	strh	w2, [x19, #190]
 a40:	str	x3, [x19, #192]
 a44:	bl	140 <transform>
 a48:	mov	w0, #0x300                 	// #768
 a4c:	bl	0 <_gcry_burn_stack>
 a50:	ldp	x7, x6, [x19]
 a54:	ldp	x5, x4, [x19, #16]
 a58:	ldp	x3, x2, [x19, #32]
 a5c:	ldp	x1, x0, [x19, #48]
 a60:	rev	x7, x7
 a64:	rev	x6, x6
 a68:	rev	x5, x5
 a6c:	rev	x4, x4
 a70:	stp	x7, x6, [x19, #72]
 a74:	rev	x3, x3
 a78:	rev	x2, x2
 a7c:	stp	x5, x4, [x19, #88]
 a80:	rev	x1, x1
 a84:	rev	x0, x0
 a88:	stp	x3, x2, [x19, #104]
 a8c:	stp	x1, x0, [x19, #120]
 a90:	ldp	x19, x20, [sp, #16]
 a94:	ldp	x21, x22, [sp, #32]
 a98:	ldp	x29, x30, [sp], #48
 a9c:	ret
 aa0:	cmp	w5, #0x80
 aa4:	b.ne	a14 <sha512_final+0x1b4>  // b.any
 aa8:	b	9f0 <sha512_final+0x190>
 aac:	add	x2, x19, x0
 ab0:	str	w5, [x19, #200]
 ab4:	mov	w3, #0xffffff80            	// #-128
 ab8:	cmp	w5, #0x6f
 abc:	strb	w3, [x2, #72]
 ac0:	b.gt	a24 <sha512_final+0x1c4>
 ac4:	add	x2, x0, #0x49
 ac8:	mov	w7, #0xb                   	// #11
 acc:	add	x3, x19, x2
 ad0:	mov	w6, #0x6e                  	// #110
 ad4:	neg	x3, x3
 ad8:	sub	w6, w6, w1
 adc:	and	w3, w3, #0x7
 ae0:	mov	w4, #0x6f                  	// #111
 ae4:	add	w0, w3, #0x7
 ae8:	sub	w4, w4, w1
 aec:	cmp	w0, w7
 af0:	csel	w0, w0, w7, cs  // cs = hs, nlast
 af4:	cmp	w0, w6
 af8:	b.hi	dd8 <sha512_final+0x578>  // b.pmore
 afc:	cbz	w3, dd0 <sha512_final+0x570>
 b00:	add	x6, x19, w5, sxtw
 b04:	cmp	w3, #0x1
 b08:	add	w0, w5, #0x1
 b0c:	strb	wzr, [x6, #72]
 b10:	b.eq	b84 <sha512_final+0x324>  // b.none
 b14:	add	x6, x19, w0, sxtw
 b18:	cmp	w3, #0x2
 b1c:	add	w0, w5, #0x2
 b20:	strb	wzr, [x6, #72]
 b24:	b.eq	b84 <sha512_final+0x324>  // b.none
 b28:	add	x6, x19, w0, sxtw
 b2c:	cmp	w3, #0x3
 b30:	add	w0, w5, #0x3
 b34:	strb	wzr, [x6, #72]
 b38:	b.eq	b84 <sha512_final+0x324>  // b.none
 b3c:	add	x6, x19, w0, sxtw
 b40:	cmp	w3, #0x4
 b44:	add	w0, w5, #0x4
 b48:	strb	wzr, [x6, #72]
 b4c:	b.eq	b84 <sha512_final+0x324>  // b.none
 b50:	add	x6, x19, w0, sxtw
 b54:	cmp	w3, #0x5
 b58:	add	w0, w5, #0x5
 b5c:	strb	wzr, [x6, #72]
 b60:	b.eq	b84 <sha512_final+0x324>  // b.none
 b64:	add	x6, x19, w0, sxtw
 b68:	cmp	w3, #0x7
 b6c:	add	w0, w5, #0x6
 b70:	strb	wzr, [x6, #72]
 b74:	b.ne	b84 <sha512_final+0x324>  // b.any
 b78:	add	x6, x19, w0, sxtw
 b7c:	add	w0, w5, #0x7
 b80:	strb	wzr, [x6, #72]
 b84:	mov	w6, w3
 b88:	sub	w3, w4, w3
 b8c:	add	x2, x6, x2
 b90:	lsr	w4, w3, #3
 b94:	add	x6, x19, x2
 b98:	cmp	w4, #0x1
 b9c:	str	xzr, [x19, x2]
 ba0:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 ba4:	str	xzr, [x6, #8]
 ba8:	cmp	w4, #0x2
 bac:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 bb0:	str	xzr, [x6, #16]
 bb4:	cmp	w4, #0x3
 bb8:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 bbc:	str	xzr, [x6, #24]
 bc0:	cmp	w4, #0x4
 bc4:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 bc8:	str	xzr, [x6, #32]
 bcc:	cmp	w4, #0x5
 bd0:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 bd4:	str	xzr, [x6, #40]
 bd8:	cmp	w4, #0x6
 bdc:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 be0:	str	xzr, [x6, #48]
 be4:	cmp	w4, #0x7
 be8:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 bec:	str	xzr, [x6, #56]
 bf0:	cmp	w4, #0x8
 bf4:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 bf8:	str	xzr, [x6, #64]
 bfc:	cmp	w4, #0x9
 c00:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 c04:	str	xzr, [x6, #72]
 c08:	cmp	w4, #0xa
 c0c:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 c10:	str	xzr, [x6, #80]
 c14:	cmp	w4, #0xb
 c18:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 c1c:	str	xzr, [x6, #88]
 c20:	cmp	w4, #0xc
 c24:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 c28:	str	xzr, [x6, #96]
 c2c:	cmp	w4, #0xd
 c30:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 c34:	str	xzr, [x6, #104]
 c38:	cmp	w4, #0xe
 c3c:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 c40:	str	xzr, [x6, #112]
 c44:	cmp	w4, #0xf
 c48:	b.eq	c50 <sha512_final+0x3f0>  // b.none
 c4c:	str	xzr, [x6, #120]
 c50:	and	w2, w3, #0xfffffff8
 c54:	add	w0, w2, w0
 c58:	cmp	w2, w3
 c5c:	b.eq	d70 <sha512_final+0x510>  // b.none
 c60:	add	x2, x19, w0, sxtw
 c64:	cmp	w0, #0x6f
 c68:	add	w3, w0, #0x1
 c6c:	strb	wzr, [x2, #72]
 c70:	b.eq	d70 <sha512_final+0x510>  // b.none
 c74:	add	x3, x19, w3, sxtw
 c78:	cmp	w0, #0x6e
 c7c:	add	w2, w0, #0x2
 c80:	strb	wzr, [x3, #72]
 c84:	b.eq	d70 <sha512_final+0x510>  // b.none
 c88:	add	x2, x19, w2, sxtw
 c8c:	cmp	w0, #0x6d
 c90:	add	w3, w0, #0x3
 c94:	strb	wzr, [x2, #72]
 c98:	b.eq	d70 <sha512_final+0x510>  // b.none
 c9c:	add	x3, x19, w3, sxtw
 ca0:	cmp	w0, #0x6c
 ca4:	add	w2, w0, #0x4
 ca8:	strb	wzr, [x3, #72]
 cac:	b.eq	d70 <sha512_final+0x510>  // b.none
 cb0:	add	x2, x19, w2, sxtw
 cb4:	cmp	w0, #0x6b
 cb8:	add	w3, w0, #0x5
 cbc:	strb	wzr, [x2, #72]
 cc0:	b.eq	d70 <sha512_final+0x510>  // b.none
 cc4:	add	x3, x19, w3, sxtw
 cc8:	cmp	w0, #0x6a
 ccc:	add	w2, w0, #0x6
 cd0:	strb	wzr, [x3, #72]
 cd4:	b.eq	d70 <sha512_final+0x510>  // b.none
 cd8:	add	x2, x19, w2, sxtw
 cdc:	cmp	w0, #0x69
 ce0:	add	w3, w0, #0x7
 ce4:	strb	wzr, [x2, #72]
 ce8:	b.eq	d70 <sha512_final+0x510>  // b.none
 cec:	add	x3, x19, w3, sxtw
 cf0:	cmp	w0, #0x68
 cf4:	add	w2, w0, #0x8
 cf8:	strb	wzr, [x3, #72]
 cfc:	b.eq	d70 <sha512_final+0x510>  // b.none
 d00:	add	x2, x19, w2, sxtw
 d04:	cmp	w0, #0x67
 d08:	add	w3, w0, #0x9
 d0c:	strb	wzr, [x2, #72]
 d10:	b.eq	d70 <sha512_final+0x510>  // b.none
 d14:	add	x3, x19, w3, sxtw
 d18:	cmp	w0, #0x66
 d1c:	add	w2, w0, #0xa
 d20:	strb	wzr, [x3, #72]
 d24:	b.eq	d70 <sha512_final+0x510>  // b.none
 d28:	add	x2, x19, w2, sxtw
 d2c:	cmp	w0, #0x65
 d30:	add	w3, w0, #0xb
 d34:	strb	wzr, [x2, #72]
 d38:	b.eq	d70 <sha512_final+0x510>  // b.none
 d3c:	add	x3, x19, w3, sxtw
 d40:	cmp	w0, #0x64
 d44:	add	w2, w0, #0xc
 d48:	strb	wzr, [x3, #72]
 d4c:	b.eq	d70 <sha512_final+0x510>  // b.none
 d50:	add	x2, x19, w2, sxtw
 d54:	cmp	w0, #0x63
 d58:	add	w0, w0, #0xd
 d5c:	strb	wzr, [x2, #72]
 d60:	b.eq	d70 <sha512_final+0x510>  // b.none
 d64:	add	x0, x19, w0, sxtw
 d68:	strb	wzr, [x0, #72]
 d6c:	nop
 d70:	sub	w1, w5, w1
 d74:	add	w1, w1, #0x6f
 d78:	str	w1, [x19, #200]
 d7c:	b	a24 <sha512_final+0x1c4>
 d80:	mov	x1, x20
 d84:	bl	140 <transform>
 d88:	mov	w0, #0x300                 	// #768
 d8c:	bl	0 <_gcry_burn_stack>
 d90:	ldr	x0, [x19, #64]
 d94:	mvn	w3, w19
 d98:	mov	w6, #0x1                   	// #1
 d9c:	mov	w7, #0xffffff80            	// #-128
 da0:	add	x0, x0, #0x1
 da4:	and	w3, w3, #0x7
 da8:	mov	w5, w6
 dac:	mov	w4, #0x6f                  	// #111
 db0:	lsl	x22, x0, #10
 db4:	lsr	x21, x0, #54
 db8:	mov	w1, #0x0                   	// #0
 dbc:	mov	x2, #0x49                  	// #73
 dc0:	str	x0, [x19, #64]
 dc4:	strb	w7, [x19, #72]
 dc8:	str	w6, [x19, #200]
 dcc:	b	afc <sha512_final+0x29c>
 dd0:	mov	w0, w5
 dd4:	b	b84 <sha512_final+0x324>
 dd8:	mov	w0, w5
 ddc:	b	c60 <sha512_final+0x400>

0000000000000de0 <grub_mod_init>:
 de0:	stp	x29, x30, [sp, #-32]!
 de4:	adrp	x0, 0 <sha512_init>
 de8:	mov	x29, sp
 dec:	str	x19, [sp, #16]
 df0:	ldr	x19, [x0]
 df4:	mov	x0, x19
 df8:	bl	0 <grub_md_register>
 dfc:	add	x0, x19, #0x60
 e00:	ldr	x19, [sp, #16]
 e04:	ldp	x29, x30, [sp], #32
 e08:	b	0 <grub_md_register>
 e0c:	nop
	...

0000000000000e18 <grub_mod_fini>:
 e18:	stp	x29, x30, [sp, #-32]!
 e1c:	adrp	x0, 0 <sha512_init>
 e20:	mov	x29, sp
 e24:	str	x19, [sp, #16]
 e28:	ldr	x19, [x0]
 e2c:	mov	x0, x19
 e30:	bl	0 <grub_md_unregister>
 e34:	add	x0, x19, #0x60
 e38:	ldr	x19, [sp, #16]
 e3c:	ldp	x29, x30, [sp], #32
 e40:	b	0 <grub_md_unregister>
 e44:	nop
	...
