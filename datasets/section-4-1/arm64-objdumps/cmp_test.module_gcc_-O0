
/home/anony/Documents/anonymous--anonymous/pizzolotto-binaries//cmp_test.module_gcc_-O0:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <leading_bit64>:
       0:	sub	sp, sp, #0x10
       4:	str	x0, [sp, #8]
       8:	ldr	x0, [sp, #8]
       c:	lsr	x0, x0, #63
      10:	and	w0, w0, #0xff
      14:	add	sp, sp, #0x10
      18:	ret

000000000000001c <leading_bit32>:
      1c:	sub	sp, sp, #0x10
      20:	str	w0, [sp, #12]
      24:	ldr	w0, [sp, #12]
      28:	lsr	w0, w0, #31
      2c:	and	w0, w0, #0xff
      30:	add	sp, sp, #0x10
      34:	ret

0000000000000038 <is_less32>:
      38:	stp	x29, x30, [sp, #-32]!
      3c:	mov	x29, sp
      40:	str	w0, [sp, #28]
      44:	str	w1, [sp, #24]
      48:	ldr	w0, [sp, #28]
      4c:	bl	1c <leading_bit32>
      50:	cmp	w0, #0x0
      54:	b.eq	70 <is_less32+0x38>  // b.none
      58:	ldr	w0, [sp, #24]
      5c:	bl	1c <leading_bit32>
      60:	cmp	w0, #0x0
      64:	b.ne	70 <is_less32+0x38>  // b.any
      68:	mov	w0, #0x0                   	// #0
      6c:	b	a8 <is_less32+0x70>
      70:	ldr	w0, [sp, #28]
      74:	bl	1c <leading_bit32>
      78:	cmp	w0, #0x0
      7c:	b.ne	98 <is_less32+0x60>  // b.any
      80:	ldr	w0, [sp, #24]
      84:	bl	1c <leading_bit32>
      88:	cmp	w0, #0x0
      8c:	b.eq	98 <is_less32+0x60>  // b.none
      90:	mov	w0, #0x1                   	// #1
      94:	b	a8 <is_less32+0x70>
      98:	ldr	w1, [sp, #28]
      9c:	ldr	w0, [sp, #24]
      a0:	sub	w0, w1, w0
      a4:	bl	1c <leading_bit32>
      a8:	ldp	x29, x30, [sp], #32
      ac:	ret

00000000000000b0 <test32>:
      b0:	stp	x29, x30, [sp, #-48]!
      b4:	mov	x29, sp
      b8:	str	x19, [sp, #16]
      bc:	str	w0, [sp, #44]
      c0:	str	w1, [sp, #40]
      c4:	ldr	w1, [sp, #44]
      c8:	ldr	w0, [sp, #40]
      cc:	cmp	w1, w0
      d0:	cset	w0, cc  // cc = lo, ul, last
      d4:	and	w0, w0, #0xff
      d8:	mov	w19, w0
      dc:	ldr	w1, [sp, #40]
      e0:	ldr	w0, [sp, #44]
      e4:	bl	38 <is_less32>
      e8:	cmp	w19, w0
      ec:	cset	w0, eq  // eq = none
      f0:	and	w0, w0, #0xff
      f4:	mov	w8, w0
      f8:	ldr	w0, [sp, #44]
      fc:	ldr	w1, [sp, #40]
     100:	mov	x7, x1
     104:	mov	x6, x0
     108:	adrp	x0, 0 <leading_bit64>
     10c:	add	x0, x0, #0x0
     110:	ldr	x5, [x0]
     114:	adrp	x0, 0 <leading_bit64>
     118:	add	x0, x0, #0x0
     11c:	ldr	x4, [x0]
     120:	mov	w3, #0x3e                  	// #62
     124:	adrp	x0, 0 <leading_bit64>
     128:	add	x0, x0, #0x0
     12c:	ldr	x2, [x0]
     130:	adrp	x0, 0 <leading_bit64>
     134:	add	x0, x0, #0x0
     138:	ldr	x1, [x0]
     13c:	mov	w0, w8
     140:	bl	0 <grub_test_assert_helper>
     144:	ldr	w1, [sp, #44]
     148:	ldr	w0, [sp, #40]
     14c:	cmp	w1, w0
     150:	cset	w0, hi  // hi = pmore
     154:	and	w0, w0, #0xff
     158:	mov	w19, w0
     15c:	ldr	w1, [sp, #44]
     160:	ldr	w0, [sp, #40]
     164:	bl	38 <is_less32>
     168:	cmp	w19, w0
     16c:	cset	w0, eq  // eq = none
     170:	and	w0, w0, #0xff
     174:	mov	w8, w0
     178:	ldr	w0, [sp, #44]
     17c:	ldr	w1, [sp, #40]
     180:	mov	x7, x1
     184:	mov	x6, x0
     188:	adrp	x0, 0 <leading_bit64>
     18c:	add	x0, x0, #0x0
     190:	ldr	x5, [x0]
     194:	adrp	x0, 0 <leading_bit64>
     198:	add	x0, x0, #0x0
     19c:	ldr	x4, [x0]
     1a0:	mov	w3, #0x40                  	// #64
     1a4:	adrp	x0, 0 <leading_bit64>
     1a8:	add	x0, x0, #0x0
     1ac:	ldr	x2, [x0]
     1b0:	adrp	x0, 0 <leading_bit64>
     1b4:	add	x0, x0, #0x0
     1b8:	ldr	x1, [x0]
     1bc:	mov	w0, w8
     1c0:	bl	0 <grub_test_assert_helper>
     1c4:	ldr	w1, [sp, #40]
     1c8:	ldr	w0, [sp, #44]
     1cc:	cmp	w1, w0
     1d0:	cset	w0, cc  // cc = lo, ul, last
     1d4:	and	w0, w0, #0xff
     1d8:	mov	w19, w0
     1dc:	ldr	w1, [sp, #44]
     1e0:	ldr	w0, [sp, #40]
     1e4:	bl	38 <is_less32>
     1e8:	cmp	w19, w0
     1ec:	cset	w0, eq  // eq = none
     1f0:	and	w0, w0, #0xff
     1f4:	mov	w8, w0
     1f8:	ldr	w0, [sp, #44]
     1fc:	ldr	w1, [sp, #40]
     200:	mov	x7, x1
     204:	mov	x6, x0
     208:	adrp	x0, 0 <leading_bit64>
     20c:	add	x0, x0, #0x0
     210:	ldr	x5, [x0]
     214:	adrp	x0, 0 <leading_bit64>
     218:	add	x0, x0, #0x0
     21c:	ldr	x4, [x0]
     220:	mov	w3, #0x42                  	// #66
     224:	adrp	x0, 0 <leading_bit64>
     228:	add	x0, x0, #0x0
     22c:	ldr	x2, [x0]
     230:	adrp	x0, 0 <leading_bit64>
     234:	add	x0, x0, #0x0
     238:	ldr	x1, [x0]
     23c:	mov	w0, w8
     240:	bl	0 <grub_test_assert_helper>
     244:	ldr	w1, [sp, #40]
     248:	ldr	w0, [sp, #44]
     24c:	cmp	w1, w0
     250:	cset	w0, hi  // hi = pmore
     254:	and	w0, w0, #0xff
     258:	mov	w19, w0
     25c:	ldr	w1, [sp, #40]
     260:	ldr	w0, [sp, #44]
     264:	bl	38 <is_less32>
     268:	cmp	w19, w0
     26c:	cset	w0, eq  // eq = none
     270:	and	w0, w0, #0xff
     274:	mov	w8, w0
     278:	ldr	w0, [sp, #44]
     27c:	ldr	w1, [sp, #40]
     280:	mov	x7, x1
     284:	mov	x6, x0
     288:	adrp	x0, 0 <leading_bit64>
     28c:	add	x0, x0, #0x0
     290:	ldr	x5, [x0]
     294:	adrp	x0, 0 <leading_bit64>
     298:	add	x0, x0, #0x0
     29c:	ldr	x4, [x0]
     2a0:	mov	w3, #0x44                  	// #68
     2a4:	adrp	x0, 0 <leading_bit64>
     2a8:	add	x0, x0, #0x0
     2ac:	ldr	x2, [x0]
     2b0:	adrp	x0, 0 <leading_bit64>
     2b4:	add	x0, x0, #0x0
     2b8:	ldr	x1, [x0]
     2bc:	mov	w0, w8
     2c0:	bl	0 <grub_test_assert_helper>
     2c4:	ldr	w1, [sp, #40]
     2c8:	ldr	w0, [sp, #44]
     2cc:	bl	38 <is_less32>
     2d0:	cmp	w0, #0x0
     2d4:	b.eq	2ec <test32+0x23c>  // b.none
     2d8:	ldr	w1, [sp, #44]
     2dc:	ldr	w0, [sp, #40]
     2e0:	bl	38 <is_less32>
     2e4:	cmp	w0, #0x0
     2e8:	b.ne	2f4 <test32+0x244>  // b.any
     2ec:	mov	w0, #0x1                   	// #1
     2f0:	b	2f8 <test32+0x248>
     2f4:	mov	w0, #0x0                   	// #0
     2f8:	ldr	w1, [sp, #44]
     2fc:	ldr	w2, [sp, #40]
     300:	mov	x7, x2
     304:	mov	x6, x1
     308:	adrp	x1, 0 <leading_bit64>
     30c:	add	x1, x1, #0x0
     310:	ldr	x5, [x1]
     314:	adrp	x1, 0 <leading_bit64>
     318:	add	x1, x1, #0x0
     31c:	ldr	x4, [x1]
     320:	mov	w3, #0x46                  	// #70
     324:	adrp	x1, 0 <leading_bit64>
     328:	add	x1, x1, #0x0
     32c:	ldr	x2, [x1]
     330:	adrp	x1, 0 <leading_bit64>
     334:	add	x1, x1, #0x0
     338:	ldr	x1, [x1]
     33c:	bl	0 <grub_test_assert_helper>
     340:	nop
     344:	ldr	x19, [sp, #16]
     348:	ldp	x29, x30, [sp], #48
     34c:	ret
	...

0000000000000398 <is_less32s>:
     398:	stp	x29, x30, [sp, #-32]!
     39c:	mov	x29, sp
     3a0:	str	w0, [sp, #28]
     3a4:	str	w1, [sp, #24]
     3a8:	ldr	w0, [sp, #28]
     3ac:	bl	1c <leading_bit32>
     3b0:	cmp	w0, #0x0
     3b4:	b.eq	3d0 <is_less32s+0x38>  // b.none
     3b8:	ldr	w0, [sp, #24]
     3bc:	bl	1c <leading_bit32>
     3c0:	cmp	w0, #0x0
     3c4:	b.ne	3d0 <is_less32s+0x38>  // b.any
     3c8:	mov	w0, #0x1                   	// #1
     3cc:	b	408 <is_less32s+0x70>
     3d0:	ldr	w0, [sp, #28]
     3d4:	bl	1c <leading_bit32>
     3d8:	cmp	w0, #0x0
     3dc:	b.ne	3f8 <is_less32s+0x60>  // b.any
     3e0:	ldr	w0, [sp, #24]
     3e4:	bl	1c <leading_bit32>
     3e8:	cmp	w0, #0x0
     3ec:	b.eq	3f8 <is_less32s+0x60>  // b.none
     3f0:	mov	w0, #0x0                   	// #0
     3f4:	b	408 <is_less32s+0x70>
     3f8:	ldr	w1, [sp, #28]
     3fc:	ldr	w0, [sp, #24]
     400:	sub	w0, w1, w0
     404:	bl	1c <leading_bit32>
     408:	ldp	x29, x30, [sp], #32
     40c:	ret

0000000000000410 <test32s>:
     410:	stp	x29, x30, [sp, #-48]!
     414:	mov	x29, sp
     418:	str	x19, [sp, #16]
     41c:	str	w0, [sp, #44]
     420:	str	w1, [sp, #40]
     424:	ldr	w1, [sp, #44]
     428:	ldr	w0, [sp, #40]
     42c:	cmp	w1, w0
     430:	cset	w0, lt  // lt = tstop
     434:	and	w0, w0, #0xff
     438:	mov	w19, w0
     43c:	ldr	w1, [sp, #40]
     440:	ldr	w0, [sp, #44]
     444:	bl	398 <is_less32s>
     448:	cmp	w19, w0
     44c:	cset	w0, eq  // eq = none
     450:	and	w0, w0, #0xff
     454:	mov	w8, w0
     458:	ldrsw	x0, [sp, #44]
     45c:	ldrsw	x1, [sp, #40]
     460:	mov	x7, x1
     464:	mov	x6, x0
     468:	adrp	x0, 0 <leading_bit64>
     46c:	add	x0, x0, #0x0
     470:	ldr	x5, [x0]
     474:	adrp	x0, 0 <leading_bit64>
     478:	add	x0, x0, #0x0
     47c:	ldr	x4, [x0]
     480:	mov	w3, #0x58                  	// #88
     484:	adrp	x0, 0 <leading_bit64>
     488:	add	x0, x0, #0x0
     48c:	ldr	x2, [x0]
     490:	adrp	x0, 0 <leading_bit64>
     494:	add	x0, x0, #0x0
     498:	ldr	x1, [x0]
     49c:	mov	w0, w8
     4a0:	bl	0 <grub_test_assert_helper>
     4a4:	ldr	w1, [sp, #44]
     4a8:	ldr	w0, [sp, #40]
     4ac:	cmp	w1, w0
     4b0:	cset	w0, gt
     4b4:	and	w0, w0, #0xff
     4b8:	mov	w19, w0
     4bc:	ldr	w1, [sp, #44]
     4c0:	ldr	w0, [sp, #40]
     4c4:	bl	398 <is_less32s>
     4c8:	cmp	w19, w0
     4cc:	cset	w0, eq  // eq = none
     4d0:	and	w0, w0, #0xff
     4d4:	mov	w8, w0
     4d8:	ldrsw	x0, [sp, #44]
     4dc:	ldrsw	x1, [sp, #40]
     4e0:	mov	x7, x1
     4e4:	mov	x6, x0
     4e8:	adrp	x0, 0 <leading_bit64>
     4ec:	add	x0, x0, #0x0
     4f0:	ldr	x5, [x0]
     4f4:	adrp	x0, 0 <leading_bit64>
     4f8:	add	x0, x0, #0x0
     4fc:	ldr	x4, [x0]
     500:	mov	w3, #0x5a                  	// #90
     504:	adrp	x0, 0 <leading_bit64>
     508:	add	x0, x0, #0x0
     50c:	ldr	x2, [x0]
     510:	adrp	x0, 0 <leading_bit64>
     514:	add	x0, x0, #0x0
     518:	ldr	x1, [x0]
     51c:	mov	w0, w8
     520:	bl	0 <grub_test_assert_helper>
     524:	ldr	w1, [sp, #40]
     528:	ldr	w0, [sp, #44]
     52c:	cmp	w1, w0
     530:	cset	w0, lt  // lt = tstop
     534:	and	w0, w0, #0xff
     538:	mov	w19, w0
     53c:	ldr	w1, [sp, #44]
     540:	ldr	w0, [sp, #40]
     544:	bl	398 <is_less32s>
     548:	cmp	w19, w0
     54c:	cset	w0, eq  // eq = none
     550:	and	w0, w0, #0xff
     554:	mov	w8, w0
     558:	ldrsw	x0, [sp, #44]
     55c:	ldrsw	x1, [sp, #40]
     560:	mov	x7, x1
     564:	mov	x6, x0
     568:	adrp	x0, 0 <leading_bit64>
     56c:	add	x0, x0, #0x0
     570:	ldr	x5, [x0]
     574:	adrp	x0, 0 <leading_bit64>
     578:	add	x0, x0, #0x0
     57c:	ldr	x4, [x0]
     580:	mov	w3, #0x5c                  	// #92
     584:	adrp	x0, 0 <leading_bit64>
     588:	add	x0, x0, #0x0
     58c:	ldr	x2, [x0]
     590:	adrp	x0, 0 <leading_bit64>
     594:	add	x0, x0, #0x0
     598:	ldr	x1, [x0]
     59c:	mov	w0, w8
     5a0:	bl	0 <grub_test_assert_helper>
     5a4:	ldr	w1, [sp, #40]
     5a8:	ldr	w0, [sp, #44]
     5ac:	cmp	w1, w0
     5b0:	cset	w0, gt
     5b4:	and	w0, w0, #0xff
     5b8:	mov	w19, w0
     5bc:	ldr	w1, [sp, #40]
     5c0:	ldr	w0, [sp, #44]
     5c4:	bl	398 <is_less32s>
     5c8:	cmp	w19, w0
     5cc:	cset	w0, eq  // eq = none
     5d0:	and	w0, w0, #0xff
     5d4:	mov	w8, w0
     5d8:	ldrsw	x0, [sp, #44]
     5dc:	ldrsw	x1, [sp, #40]
     5e0:	mov	x7, x1
     5e4:	mov	x6, x0
     5e8:	adrp	x0, 0 <leading_bit64>
     5ec:	add	x0, x0, #0x0
     5f0:	ldr	x5, [x0]
     5f4:	adrp	x0, 0 <leading_bit64>
     5f8:	add	x0, x0, #0x0
     5fc:	ldr	x4, [x0]
     600:	mov	w3, #0x5e                  	// #94
     604:	adrp	x0, 0 <leading_bit64>
     608:	add	x0, x0, #0x0
     60c:	ldr	x2, [x0]
     610:	adrp	x0, 0 <leading_bit64>
     614:	add	x0, x0, #0x0
     618:	ldr	x1, [x0]
     61c:	mov	w0, w8
     620:	bl	0 <grub_test_assert_helper>
     624:	ldr	w1, [sp, #40]
     628:	ldr	w0, [sp, #44]
     62c:	bl	398 <is_less32s>
     630:	cmp	w0, #0x0
     634:	b.eq	64c <test32s+0x23c>  // b.none
     638:	ldr	w1, [sp, #44]
     63c:	ldr	w0, [sp, #40]
     640:	bl	398 <is_less32s>
     644:	cmp	w0, #0x0
     648:	b.ne	654 <test32s+0x244>  // b.any
     64c:	mov	w0, #0x1                   	// #1
     650:	b	658 <test32s+0x248>
     654:	mov	w0, #0x0                   	// #0
     658:	ldrsw	x1, [sp, #44]
     65c:	ldrsw	x2, [sp, #40]
     660:	mov	x7, x2
     664:	mov	x6, x1
     668:	adrp	x1, 0 <leading_bit64>
     66c:	add	x1, x1, #0x0
     670:	ldr	x5, [x1]
     674:	adrp	x1, 0 <leading_bit64>
     678:	add	x1, x1, #0x0
     67c:	ldr	x4, [x1]
     680:	mov	w3, #0x60                  	// #96
     684:	adrp	x1, 0 <leading_bit64>
     688:	add	x1, x1, #0x0
     68c:	ldr	x2, [x1]
     690:	adrp	x1, 0 <leading_bit64>
     694:	add	x1, x1, #0x0
     698:	ldr	x1, [x1]
     69c:	bl	0 <grub_test_assert_helper>
     6a0:	nop
     6a4:	ldr	x19, [sp, #16]
     6a8:	ldp	x29, x30, [sp], #48
     6ac:	ret
	...

00000000000006f8 <is_less64>:
     6f8:	stp	x29, x30, [sp, #-32]!
     6fc:	mov	x29, sp
     700:	str	x0, [sp, #24]
     704:	str	x1, [sp, #16]
     708:	ldr	x0, [sp, #24]
     70c:	bl	0 <leading_bit64>
     710:	cmp	w0, #0x0
     714:	b.eq	730 <is_less64+0x38>  // b.none
     718:	ldr	x0, [sp, #16]
     71c:	bl	0 <leading_bit64>
     720:	cmp	w0, #0x0
     724:	b.ne	730 <is_less64+0x38>  // b.any
     728:	mov	w0, #0x0                   	// #0
     72c:	b	768 <is_less64+0x70>
     730:	ldr	x0, [sp, #24]
     734:	bl	0 <leading_bit64>
     738:	cmp	w0, #0x0
     73c:	b.ne	758 <is_less64+0x60>  // b.any
     740:	ldr	x0, [sp, #16]
     744:	bl	0 <leading_bit64>
     748:	cmp	w0, #0x0
     74c:	b.eq	758 <is_less64+0x60>  // b.none
     750:	mov	w0, #0x1                   	// #1
     754:	b	768 <is_less64+0x70>
     758:	ldr	x1, [sp, #24]
     75c:	ldr	x0, [sp, #16]
     760:	sub	x0, x1, x0
     764:	bl	0 <leading_bit64>
     768:	ldp	x29, x30, [sp], #32
     76c:	ret

0000000000000770 <test64>:
     770:	stp	x29, x30, [sp, #-48]!
     774:	mov	x29, sp
     778:	str	x19, [sp, #16]
     77c:	str	x0, [sp, #40]
     780:	str	x1, [sp, #32]
     784:	ldr	x1, [sp, #40]
     788:	ldr	x0, [sp, #32]
     78c:	cmp	x1, x0
     790:	cset	w0, cc  // cc = lo, ul, last
     794:	and	w0, w0, #0xff
     798:	mov	w19, w0
     79c:	ldr	x1, [sp, #32]
     7a0:	ldr	x0, [sp, #40]
     7a4:	bl	6f8 <is_less64>
     7a8:	cmp	w19, w0
     7ac:	cset	w0, eq  // eq = none
     7b0:	and	w0, w0, #0xff
     7b4:	mov	w8, w0
     7b8:	ldr	x0, [sp, #40]
     7bc:	ldr	x1, [sp, #32]
     7c0:	mov	x7, x1
     7c4:	mov	x6, x0
     7c8:	adrp	x0, 0 <leading_bit64>
     7cc:	add	x0, x0, #0x0
     7d0:	ldr	x5, [x0]
     7d4:	adrp	x0, 0 <leading_bit64>
     7d8:	add	x0, x0, #0x0
     7dc:	ldr	x4, [x0]
     7e0:	mov	w3, #0x72                  	// #114
     7e4:	adrp	x0, 0 <leading_bit64>
     7e8:	add	x0, x0, #0x0
     7ec:	ldr	x2, [x0]
     7f0:	adrp	x0, 0 <leading_bit64>
     7f4:	add	x0, x0, #0x0
     7f8:	ldr	x1, [x0]
     7fc:	mov	w0, w8
     800:	bl	0 <grub_test_assert_helper>
     804:	ldr	x1, [sp, #40]
     808:	ldr	x0, [sp, #32]
     80c:	cmp	x1, x0
     810:	cset	w0, hi  // hi = pmore
     814:	and	w0, w0, #0xff
     818:	mov	w19, w0
     81c:	ldr	x1, [sp, #40]
     820:	ldr	x0, [sp, #32]
     824:	bl	6f8 <is_less64>
     828:	cmp	w19, w0
     82c:	cset	w0, eq  // eq = none
     830:	and	w0, w0, #0xff
     834:	mov	w8, w0
     838:	ldr	x0, [sp, #40]
     83c:	ldr	x1, [sp, #32]
     840:	mov	x7, x1
     844:	mov	x6, x0
     848:	adrp	x0, 0 <leading_bit64>
     84c:	add	x0, x0, #0x0
     850:	ldr	x5, [x0]
     854:	adrp	x0, 0 <leading_bit64>
     858:	add	x0, x0, #0x0
     85c:	ldr	x4, [x0]
     860:	mov	w3, #0x74                  	// #116
     864:	adrp	x0, 0 <leading_bit64>
     868:	add	x0, x0, #0x0
     86c:	ldr	x2, [x0]
     870:	adrp	x0, 0 <leading_bit64>
     874:	add	x0, x0, #0x0
     878:	ldr	x1, [x0]
     87c:	mov	w0, w8
     880:	bl	0 <grub_test_assert_helper>
     884:	ldr	x1, [sp, #32]
     888:	ldr	x0, [sp, #40]
     88c:	cmp	x1, x0
     890:	cset	w0, cc  // cc = lo, ul, last
     894:	and	w0, w0, #0xff
     898:	mov	w19, w0
     89c:	ldr	x1, [sp, #40]
     8a0:	ldr	x0, [sp, #32]
     8a4:	bl	6f8 <is_less64>
     8a8:	cmp	w19, w0
     8ac:	cset	w0, eq  // eq = none
     8b0:	and	w0, w0, #0xff
     8b4:	mov	w8, w0
     8b8:	ldr	x0, [sp, #40]
     8bc:	ldr	x1, [sp, #32]
     8c0:	mov	x7, x1
     8c4:	mov	x6, x0
     8c8:	adrp	x0, 0 <leading_bit64>
     8cc:	add	x0, x0, #0x0
     8d0:	ldr	x5, [x0]
     8d4:	adrp	x0, 0 <leading_bit64>
     8d8:	add	x0, x0, #0x0
     8dc:	ldr	x4, [x0]
     8e0:	mov	w3, #0x76                  	// #118
     8e4:	adrp	x0, 0 <leading_bit64>
     8e8:	add	x0, x0, #0x0
     8ec:	ldr	x2, [x0]
     8f0:	adrp	x0, 0 <leading_bit64>
     8f4:	add	x0, x0, #0x0
     8f8:	ldr	x1, [x0]
     8fc:	mov	w0, w8
     900:	bl	0 <grub_test_assert_helper>
     904:	ldr	x1, [sp, #32]
     908:	ldr	x0, [sp, #40]
     90c:	cmp	x1, x0
     910:	cset	w0, hi  // hi = pmore
     914:	and	w0, w0, #0xff
     918:	mov	w19, w0
     91c:	ldr	x1, [sp, #32]
     920:	ldr	x0, [sp, #40]
     924:	bl	6f8 <is_less64>
     928:	cmp	w19, w0
     92c:	cset	w0, eq  // eq = none
     930:	and	w0, w0, #0xff
     934:	mov	w8, w0
     938:	ldr	x0, [sp, #40]
     93c:	ldr	x1, [sp, #32]
     940:	mov	x7, x1
     944:	mov	x6, x0
     948:	adrp	x0, 0 <leading_bit64>
     94c:	add	x0, x0, #0x0
     950:	ldr	x5, [x0]
     954:	adrp	x0, 0 <leading_bit64>
     958:	add	x0, x0, #0x0
     95c:	ldr	x4, [x0]
     960:	mov	w3, #0x78                  	// #120
     964:	adrp	x0, 0 <leading_bit64>
     968:	add	x0, x0, #0x0
     96c:	ldr	x2, [x0]
     970:	adrp	x0, 0 <leading_bit64>
     974:	add	x0, x0, #0x0
     978:	ldr	x1, [x0]
     97c:	mov	w0, w8
     980:	bl	0 <grub_test_assert_helper>
     984:	ldr	x1, [sp, #32]
     988:	ldr	x0, [sp, #40]
     98c:	bl	6f8 <is_less64>
     990:	cmp	w0, #0x0
     994:	b.eq	9ac <test64+0x23c>  // b.none
     998:	ldr	x1, [sp, #40]
     99c:	ldr	x0, [sp, #32]
     9a0:	bl	6f8 <is_less64>
     9a4:	cmp	w0, #0x0
     9a8:	b.ne	9b4 <test64+0x244>  // b.any
     9ac:	mov	w0, #0x1                   	// #1
     9b0:	b	9b8 <test64+0x248>
     9b4:	mov	w0, #0x0                   	// #0
     9b8:	ldr	x1, [sp, #40]
     9bc:	ldr	x2, [sp, #32]
     9c0:	mov	x7, x2
     9c4:	mov	x6, x1
     9c8:	adrp	x1, 0 <leading_bit64>
     9cc:	add	x1, x1, #0x0
     9d0:	ldr	x5, [x1]
     9d4:	adrp	x1, 0 <leading_bit64>
     9d8:	add	x1, x1, #0x0
     9dc:	ldr	x4, [x1]
     9e0:	mov	w3, #0x7a                  	// #122
     9e4:	adrp	x1, 0 <leading_bit64>
     9e8:	add	x1, x1, #0x0
     9ec:	ldr	x2, [x1]
     9f0:	adrp	x1, 0 <leading_bit64>
     9f4:	add	x1, x1, #0x0
     9f8:	ldr	x1, [x1]
     9fc:	bl	0 <grub_test_assert_helper>
     a00:	nop
     a04:	ldr	x19, [sp, #16]
     a08:	ldp	x29, x30, [sp], #48
     a0c:	ret
	...

0000000000000a58 <is_less64s>:
     a58:	stp	x29, x30, [sp, #-32]!
     a5c:	mov	x29, sp
     a60:	str	x0, [sp, #24]
     a64:	str	x1, [sp, #16]
     a68:	ldr	x0, [sp, #24]
     a6c:	bl	0 <leading_bit64>
     a70:	cmp	w0, #0x0
     a74:	b.eq	a90 <is_less64s+0x38>  // b.none
     a78:	ldr	x0, [sp, #16]
     a7c:	bl	0 <leading_bit64>
     a80:	cmp	w0, #0x0
     a84:	b.ne	a90 <is_less64s+0x38>  // b.any
     a88:	mov	w0, #0x1                   	// #1
     a8c:	b	ac8 <is_less64s+0x70>
     a90:	ldr	x0, [sp, #24]
     a94:	bl	0 <leading_bit64>
     a98:	cmp	w0, #0x0
     a9c:	b.ne	ab8 <is_less64s+0x60>  // b.any
     aa0:	ldr	x0, [sp, #16]
     aa4:	bl	0 <leading_bit64>
     aa8:	cmp	w0, #0x0
     aac:	b.eq	ab8 <is_less64s+0x60>  // b.none
     ab0:	mov	w0, #0x0                   	// #0
     ab4:	b	ac8 <is_less64s+0x70>
     ab8:	ldr	x1, [sp, #24]
     abc:	ldr	x0, [sp, #16]
     ac0:	sub	x0, x1, x0
     ac4:	bl	0 <leading_bit64>
     ac8:	ldp	x29, x30, [sp], #32
     acc:	ret

0000000000000ad0 <test64s>:
     ad0:	stp	x29, x30, [sp, #-48]!
     ad4:	mov	x29, sp
     ad8:	str	x19, [sp, #16]
     adc:	str	x0, [sp, #40]
     ae0:	str	x1, [sp, #32]
     ae4:	ldr	x1, [sp, #40]
     ae8:	ldr	x0, [sp, #32]
     aec:	cmp	x1, x0
     af0:	cset	w0, lt  // lt = tstop
     af4:	and	w0, w0, #0xff
     af8:	mov	w19, w0
     afc:	ldr	x1, [sp, #32]
     b00:	ldr	x0, [sp, #40]
     b04:	bl	a58 <is_less64s>
     b08:	cmp	w19, w0
     b0c:	cset	w0, eq  // eq = none
     b10:	and	w0, w0, #0xff
     b14:	mov	w8, w0
     b18:	ldr	x7, [sp, #32]
     b1c:	ldr	x6, [sp, #40]
     b20:	adrp	x0, 0 <leading_bit64>
     b24:	add	x0, x0, #0x0
     b28:	ldr	x5, [x0]
     b2c:	adrp	x0, 0 <leading_bit64>
     b30:	add	x0, x0, #0x0
     b34:	ldr	x4, [x0]
     b38:	mov	w3, #0x8c                  	// #140
     b3c:	adrp	x0, 0 <leading_bit64>
     b40:	add	x0, x0, #0x0
     b44:	ldr	x2, [x0]
     b48:	adrp	x0, 0 <leading_bit64>
     b4c:	add	x0, x0, #0x0
     b50:	ldr	x1, [x0]
     b54:	mov	w0, w8
     b58:	bl	0 <grub_test_assert_helper>
     b5c:	ldr	x1, [sp, #40]
     b60:	ldr	x0, [sp, #32]
     b64:	cmp	x1, x0
     b68:	cset	w0, gt
     b6c:	and	w0, w0, #0xff
     b70:	mov	w19, w0
     b74:	ldr	x1, [sp, #40]
     b78:	ldr	x0, [sp, #32]
     b7c:	bl	a58 <is_less64s>
     b80:	cmp	w19, w0
     b84:	cset	w0, eq  // eq = none
     b88:	and	w0, w0, #0xff
     b8c:	mov	w8, w0
     b90:	ldr	x7, [sp, #32]
     b94:	ldr	x6, [sp, #40]
     b98:	adrp	x0, 0 <leading_bit64>
     b9c:	add	x0, x0, #0x0
     ba0:	ldr	x5, [x0]
     ba4:	adrp	x0, 0 <leading_bit64>
     ba8:	add	x0, x0, #0x0
     bac:	ldr	x4, [x0]
     bb0:	mov	w3, #0x8e                  	// #142
     bb4:	adrp	x0, 0 <leading_bit64>
     bb8:	add	x0, x0, #0x0
     bbc:	ldr	x2, [x0]
     bc0:	adrp	x0, 0 <leading_bit64>
     bc4:	add	x0, x0, #0x0
     bc8:	ldr	x1, [x0]
     bcc:	mov	w0, w8
     bd0:	bl	0 <grub_test_assert_helper>
     bd4:	ldr	x1, [sp, #32]
     bd8:	ldr	x0, [sp, #40]
     bdc:	cmp	x1, x0
     be0:	cset	w0, lt  // lt = tstop
     be4:	and	w0, w0, #0xff
     be8:	mov	w19, w0
     bec:	ldr	x1, [sp, #40]
     bf0:	ldr	x0, [sp, #32]
     bf4:	bl	a58 <is_less64s>
     bf8:	cmp	w19, w0
     bfc:	cset	w0, eq  // eq = none
     c00:	and	w0, w0, #0xff
     c04:	mov	w8, w0
     c08:	ldr	x7, [sp, #32]
     c0c:	ldr	x6, [sp, #40]
     c10:	adrp	x0, 0 <leading_bit64>
     c14:	add	x0, x0, #0x0
     c18:	ldr	x5, [x0]
     c1c:	adrp	x0, 0 <leading_bit64>
     c20:	add	x0, x0, #0x0
     c24:	ldr	x4, [x0]
     c28:	mov	w3, #0x90                  	// #144
     c2c:	adrp	x0, 0 <leading_bit64>
     c30:	add	x0, x0, #0x0
     c34:	ldr	x2, [x0]
     c38:	adrp	x0, 0 <leading_bit64>
     c3c:	add	x0, x0, #0x0
     c40:	ldr	x1, [x0]
     c44:	mov	w0, w8
     c48:	bl	0 <grub_test_assert_helper>
     c4c:	ldr	x1, [sp, #32]
     c50:	ldr	x0, [sp, #40]
     c54:	cmp	x1, x0
     c58:	cset	w0, gt
     c5c:	and	w0, w0, #0xff
     c60:	mov	w19, w0
     c64:	ldr	x1, [sp, #32]
     c68:	ldr	x0, [sp, #40]
     c6c:	bl	a58 <is_less64s>
     c70:	cmp	w19, w0
     c74:	cset	w0, eq  // eq = none
     c78:	and	w0, w0, #0xff
     c7c:	mov	w8, w0
     c80:	ldr	x7, [sp, #32]
     c84:	ldr	x6, [sp, #40]
     c88:	adrp	x0, 0 <leading_bit64>
     c8c:	add	x0, x0, #0x0
     c90:	ldr	x5, [x0]
     c94:	adrp	x0, 0 <leading_bit64>
     c98:	add	x0, x0, #0x0
     c9c:	ldr	x4, [x0]
     ca0:	mov	w3, #0x92                  	// #146
     ca4:	adrp	x0, 0 <leading_bit64>
     ca8:	add	x0, x0, #0x0
     cac:	ldr	x2, [x0]
     cb0:	adrp	x0, 0 <leading_bit64>
     cb4:	add	x0, x0, #0x0
     cb8:	ldr	x1, [x0]
     cbc:	mov	w0, w8
     cc0:	bl	0 <grub_test_assert_helper>
     cc4:	ldr	x1, [sp, #32]
     cc8:	ldr	x0, [sp, #40]
     ccc:	bl	a58 <is_less64s>
     cd0:	cmp	w0, #0x0
     cd4:	b.eq	cec <test64s+0x21c>  // b.none
     cd8:	ldr	x1, [sp, #40]
     cdc:	ldr	x0, [sp, #32]
     ce0:	bl	a58 <is_less64s>
     ce4:	cmp	w0, #0x0
     ce8:	b.ne	cf4 <test64s+0x224>  // b.any
     cec:	mov	w0, #0x1                   	// #1
     cf0:	b	cf8 <test64s+0x228>
     cf4:	mov	w0, #0x0                   	// #0
     cf8:	ldr	x7, [sp, #32]
     cfc:	ldr	x6, [sp, #40]
     d00:	adrp	x1, 0 <leading_bit64>
     d04:	add	x1, x1, #0x0
     d08:	ldr	x5, [x1]
     d0c:	adrp	x1, 0 <leading_bit64>
     d10:	add	x1, x1, #0x0
     d14:	ldr	x4, [x1]
     d18:	mov	w3, #0x94                  	// #148
     d1c:	adrp	x1, 0 <leading_bit64>
     d20:	add	x1, x1, #0x0
     d24:	ldr	x2, [x1]
     d28:	adrp	x1, 0 <leading_bit64>
     d2c:	add	x1, x1, #0x0
     d30:	ldr	x1, [x1]
     d34:	bl	0 <grub_test_assert_helper>
     d38:	nop
     d3c:	ldr	x19, [sp, #16]
     d40:	ldp	x29, x30, [sp], #48
     d44:	ret
	...

0000000000000d90 <test_all>:
     d90:	stp	x29, x30, [sp, #-32]!
     d94:	mov	x29, sp
     d98:	str	x0, [sp, #24]
     d9c:	str	x1, [sp, #16]
     da0:	ldr	x1, [sp, #16]
     da4:	ldr	x0, [sp, #24]
     da8:	bl	770 <test64>
     dac:	ldr	x0, [sp, #24]
     db0:	mov	w2, w0
     db4:	ldr	x0, [sp, #16]
     db8:	mov	w1, w0
     dbc:	mov	w0, w2
     dc0:	bl	b0 <test32>
     dc4:	ldr	x0, [sp, #24]
     dc8:	ldr	x1, [sp, #16]
     dcc:	bl	ad0 <test64s>
     dd0:	ldr	x0, [sp, #24]
     dd4:	mov	w2, w0
     dd8:	ldr	x0, [sp, #16]
     ddc:	mov	w1, w0
     de0:	mov	w0, w2
     de4:	bl	410 <test32s>
     de8:	ldr	x2, [sp, #24]
     dec:	ldr	x0, [sp, #16]
     df0:	neg	x0, x0
     df4:	mov	x1, x0
     df8:	mov	x0, x2
     dfc:	bl	ad0 <test64s>
     e00:	ldr	x0, [sp, #24]
     e04:	mov	w2, w0
     e08:	ldr	x0, [sp, #16]
     e0c:	neg	w0, w0
     e10:	mov	w1, w0
     e14:	mov	w0, w2
     e18:	bl	410 <test32s>
     e1c:	ldr	x0, [sp, #24]
     e20:	neg	x0, x0
     e24:	mov	x2, x0
     e28:	ldr	x0, [sp, #16]
     e2c:	mov	x1, x0
     e30:	mov	x0, x2
     e34:	bl	ad0 <test64s>
     e38:	ldr	x0, [sp, #24]
     e3c:	neg	w0, w0
     e40:	mov	w2, w0
     e44:	ldr	x0, [sp, #16]
     e48:	mov	w1, w0
     e4c:	mov	w0, w2
     e50:	bl	410 <test32s>
     e54:	ldr	x0, [sp, #24]
     e58:	neg	x0, x0
     e5c:	mov	x2, x0
     e60:	ldr	x0, [sp, #16]
     e64:	neg	x0, x0
     e68:	mov	x1, x0
     e6c:	mov	x0, x2
     e70:	bl	ad0 <test64s>
     e74:	ldr	x0, [sp, #24]
     e78:	neg	w0, w0
     e7c:	mov	w2, w0
     e80:	ldr	x0, [sp, #16]
     e84:	neg	w0, w0
     e88:	mov	w1, w0
     e8c:	mov	w0, w2
     e90:	bl	410 <test32s>
     e94:	nop
     e98:	ldp	x29, x30, [sp], #32
     e9c:	ret

0000000000000ea0 <cmp_test>:
     ea0:	stp	x29, x30, [sp, #-48]!
     ea4:	mov	x29, sp
     ea8:	mov	x0, #0x194                 	// #404
     eac:	str	x0, [sp, #40]
     eb0:	mov	x0, #0x7                   	// #7
     eb4:	str	x0, [sp, #32]
     eb8:	str	xzr, [sp, #24]
     ebc:	b	f10 <cmp_test+0x70>
     ec0:	adrp	x0, 0 <leading_bit64>
     ec4:	add	x0, x0, #0x0
     ec8:	ldr	x1, [x0]
     ecc:	ldr	x0, [sp, #24]
     ed0:	lsl	x0, x0, #4
     ed4:	add	x0, x1, x0
     ed8:	ldr	x2, [x0]
     edc:	adrp	x0, 0 <leading_bit64>
     ee0:	add	x0, x0, #0x0
     ee4:	ldr	x1, [x0]
     ee8:	ldr	x0, [sp, #24]
     eec:	lsl	x0, x0, #4
     ef0:	add	x0, x1, x0
     ef4:	ldr	x0, [x0, #8]
     ef8:	mov	x1, x0
     efc:	mov	x0, x2
     f00:	bl	d90 <test_all>
     f04:	ldr	x0, [sp, #24]
     f08:	add	x0, x0, #0x1
     f0c:	str	x0, [sp, #24]
     f10:	ldr	x0, [sp, #24]
     f14:	cmp	x0, #0x4
     f18:	b.ls	ec0 <cmp_test+0x20>  // b.plast
     f1c:	str	xzr, [sp, #24]
     f20:	b	fcc <cmp_test+0x12c>
     f24:	ldr	x1, [sp, #40]
     f28:	mov	x0, x1
     f2c:	lsl	x0, x0, #4
     f30:	add	x2, x0, x1
     f34:	ldr	x1, [sp, #32]
     f38:	mov	x0, x1
     f3c:	lsl	x0, x0, #1
     f40:	add	x0, x0, x1
     f44:	lsl	x0, x0, #2
     f48:	add	x0, x0, x1
     f4c:	add	x0, x2, x0
     f50:	str	x0, [sp, #40]
     f54:	ldr	x1, [sp, #40]
     f58:	mov	x0, x1
     f5c:	lsl	x0, x0, #1
     f60:	add	x0, x0, x1
     f64:	lsl	x0, x0, #3
     f68:	sub	x2, x0, x1
     f6c:	ldr	x1, [sp, #32]
     f70:	mov	x0, x1
     f74:	lsl	x0, x0, #3
     f78:	sub	x0, x0, x1
     f7c:	lsl	x0, x0, #2
     f80:	add	x0, x0, x1
     f84:	add	x0, x2, x0
     f88:	str	x0, [sp, #32]
     f8c:	ldr	x0, [sp, #32]
     f90:	cmp	x0, #0x0
     f94:	b.ne	fa0 <cmp_test+0x100>  // b.any
     f98:	mov	x0, #0x1                   	// #1
     f9c:	str	x0, [sp, #32]
     fa0:	ldr	x0, [sp, #40]
     fa4:	cmp	x0, #0x0
     fa8:	b.ne	fb4 <cmp_test+0x114>  // b.any
     fac:	mov	x0, #0x1                   	// #1
     fb0:	str	x0, [sp, #40]
     fb4:	ldr	x1, [sp, #32]
     fb8:	ldr	x0, [sp, #40]
     fbc:	bl	d90 <test_all>
     fc0:	ldr	x0, [sp, #24]
     fc4:	add	x0, x0, #0x1
     fc8:	str	x0, [sp, #24]
     fcc:	ldr	x1, [sp, #24]
     fd0:	mov	x0, #0x9c3f                	// #39999
     fd4:	cmp	x1, x0
     fd8:	b.ls	f24 <cmp_test+0x84>  // b.plast
     fdc:	nop
     fe0:	nop
     fe4:	ldp	x29, x30, [sp], #48
     fe8:	ret
     fec:	nop
	...

0000000000000ff8 <grub_mod_init>:
     ff8:	stp	x29, x30, [sp, #-32]!
     ffc:	mov	x29, sp
    1000:	str	x0, [sp, #24]
    1004:	adrp	x0, 0 <leading_bit64>
    1008:	add	x0, x0, #0x0
    100c:	ldr	x1, [x0]
    1010:	adrp	x0, 0 <leading_bit64>
    1014:	add	x0, x0, #0x0
    1018:	ldr	x0, [x0]
    101c:	bl	0 <grub_test_register>
    1020:	nop
    1024:	ldp	x29, x30, [sp], #32
    1028:	ret
    102c:	nop
	...

0000000000001040 <grub_mod_fini>:
    1040:	stp	x29, x30, [sp, #-16]!
    1044:	mov	x29, sp
    1048:	adrp	x0, 0 <leading_bit64>
    104c:	add	x0, x0, #0x0
    1050:	ldr	x0, [x0]
    1054:	bl	0 <grub_test_unregister>
    1058:	nop
    105c:	ldp	x29, x30, [sp], #16
    1060:	ret
    1064:	nop
	...
