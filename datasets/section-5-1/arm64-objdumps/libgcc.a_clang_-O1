In archive /home/anony/Documents/anonymous--anonymous/pizzolotto-binaries//libgcc.a_clang_-O1:

_muldi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__multi3>:
   0:	and	x5, x0, #0xffffffff
   4:	lsr	x4, x0, #32
   8:	and	x6, x2, #0xffffffff
   c:	lsr	x8, x2, #32
  10:	mul	x7, x5, x6
  14:	mul	x6, x4, x6
  18:	mul	x4, x4, x8
  1c:	madd	x5, x5, x8, x6
  20:	add	x5, x5, x7, lsr #32
  24:	mov	x8, #0x100000000           	// #4294967296
  28:	add	x8, x4, x8
  2c:	cmp	x6, x5
  30:	csel	x4, x8, x4, hi  // hi = pmore
  34:	add	x4, x4, x5, lsr #32
  38:	and	x7, x7, #0xffffffff
  3c:	madd	x4, x0, x3, x4
  40:	add	x0, x7, x5, lsl #32
  44:	madd	x1, x2, x1, x4
  48:	ret

_negdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negti2>:
   0:	neg	x1, x1
   4:	cmp	x0, #0x0
   8:	cset	x2, ne  // ne = any
   c:	neg	x0, x0
  10:	sub	x1, x1, x2
  14:	ret

_lshrdi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__lshrti3>:
   0:	cbz	x2, 28 <__lshrti3+0x28>
   4:	mov	x3, #0x40                  	// #64
   8:	sub	x3, x3, x2
   c:	cmp	x3, #0x0
  10:	b.le	2c <__lshrti3+0x2c>
  14:	lsr	x4, x1, x2
  18:	lsr	x0, x0, x2
  1c:	lsl	x2, x1, x3
  20:	orr	x0, x0, x2
  24:	mov	x1, x4
  28:	ret
  2c:	mov	x4, #0x0                   	// #0
  30:	neg	w2, w3
  34:	lsr	x0, x1, x2
  38:	b	24 <__lshrti3+0x24>

_ashldi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ashlti3>:
   0:	cbz	x2, 28 <__ashlti3+0x28>
   4:	mov	x3, #0x40                  	// #64
   8:	sub	x3, x3, x2
   c:	cmp	x3, #0x0
  10:	b.le	2c <__ashlti3+0x2c>
  14:	lsl	x4, x0, x2
  18:	lsl	x1, x1, x2
  1c:	lsr	x2, x0, x3
  20:	orr	x1, x1, x2
  24:	mov	x0, x4
  28:	ret
  2c:	mov	x4, #0x0                   	// #0
  30:	neg	w2, w3
  34:	lsl	x1, x0, x2
  38:	b	24 <__ashlti3+0x24>

_ashrdi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ashrti3>:
   0:	cbz	x2, 28 <__ashrti3+0x28>
   4:	mov	x3, #0x40                  	// #64
   8:	sub	x3, x3, x2
   c:	cmp	x3, #0x0
  10:	b.le	2c <__ashrti3+0x2c>
  14:	asr	x4, x1, x2
  18:	lsr	x0, x0, x2
  1c:	lsl	x2, x1, x3
  20:	orr	x0, x0, x2
  24:	mov	x1, x4
  28:	ret
  2c:	asr	x4, x1, #63
  30:	neg	w2, w3
  34:	asr	x0, x1, x2
  38:	b	24 <__ashrti3+0x24>

_cmpdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__cmpti2>:
   0:	mov	x4, x0
   4:	mov	w0, #0x0                   	// #0
   8:	cmp	x1, x3
   c:	b.lt	2c <__cmpti2+0x2c>  // b.tstop
  10:	mov	w0, #0x2                   	// #2
  14:	b.gt	2c <__cmpti2+0x2c>
  18:	mov	w0, #0x0                   	// #0
  1c:	cmp	x4, x2
  20:	b.cc	2c <__cmpti2+0x2c>  // b.lo, b.ul, b.last
  24:	cset	w0, hi  // hi = pmore
  28:	add	w0, w0, #0x1
  2c:	ret

_ucmpdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ucmpti2>:
   0:	mov	x4, x0
   4:	mov	w0, #0x0                   	// #0
   8:	cmp	x1, x3
   c:	b.cc	2c <__ucmpti2+0x2c>  // b.lo, b.ul, b.last
  10:	mov	w0, #0x2                   	// #2
  14:	b.hi	2c <__ucmpti2+0x2c>  // b.pmore
  18:	mov	w0, #0x0                   	// #0
  1c:	cmp	x4, x2
  20:	b.cc	2c <__ucmpti2+0x2c>  // b.lo, b.ul, b.last
  24:	cset	w0, hi  // hi = pmore
  28:	add	w0, w0, #0x1
  2c:	ret

_clear_cache.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__clear_cache>:
   0:	stp	x29, x30, [sp, #-16]!
   4:	mov	x29, sp
   8:	bl	0 <__aarch64_sync_cache_range>
   c:	ldp	x29, x30, [sp], #16
  10:	ret

_trampoline.o:     file format elf64-littleaarch64


__main.o:     file format elf64-littleaarch64


_absvsi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__absvdi2>:
   0:	tbnz	x0, #63, 8 <__absvdi2+0x8>
   4:	ret
   8:	negs	x0, x0
   c:	b.pl	4 <__absvdi2+0x4>  // b.nfrst
  10:	stp	x29, x30, [sp, #-16]!
  14:	mov	x29, sp
  18:	bl	0 <abort>

000000000000001c <__absvsi2>:
  1c:	tbnz	w0, #31, 24 <__absvsi2+0x8>
  20:	ret
  24:	negs	w0, w0
  28:	b.pl	20 <__absvsi2+0x4>  // b.nfrst
  2c:	stp	x29, x30, [sp, #-16]!
  30:	mov	x29, sp
  34:	bl	0 <abort>

_absvdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__absvti2>:
   0:	tbnz	x1, #63, 8 <__absvti2+0x8>
   4:	ret
   8:	negs	x0, x0
   c:	ngc	x2, x1
  10:	mov	x1, x2
  14:	tbz	x2, #63, 4 <__absvti2+0x4>
  18:	stp	x29, x30, [sp, #-16]!
  1c:	mov	x29, sp
  20:	bl	0 <abort>

_addvsi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__addvdi3>:
   0:	mov	x2, x0
   4:	add	x0, x0, x1
   8:	tbnz	x1, #63, 1c <__addvdi3+0x1c>
   c:	cmp	x2, x0
  10:	cset	w1, gt
  14:	cbnz	w1, 28 <__addvdi3+0x28>
  18:	ret
  1c:	cmp	x2, x0
  20:	cset	w1, lt  // lt = tstop
  24:	b	14 <__addvdi3+0x14>
  28:	stp	x29, x30, [sp, #-16]!
  2c:	mov	x29, sp
  30:	bl	0 <abort>

0000000000000034 <__addvsi3>:
  34:	mov	w2, w0
  38:	add	w0, w0, w1
  3c:	tbnz	w1, #31, 50 <__addvsi3+0x1c>
  40:	cmp	w2, w0
  44:	cset	w1, gt
  48:	cbnz	w1, 5c <__addvsi3+0x28>
  4c:	ret
  50:	cmp	w2, w0
  54:	cset	w1, lt  // lt = tstop
  58:	b	48 <__addvsi3+0x14>
  5c:	stp	x29, x30, [sp, #-16]!
  60:	mov	x29, sp
  64:	bl	0 <abort>

_addvdi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__addvti3>:
   0:	mov	x4, x0
   4:	mov	x5, x1
   8:	adds	x0, x0, x2
   c:	adc	x1, x1, x3
  10:	tbnz	x3, #63, 40 <__addvti3+0x40>
  14:	mov	w2, #0x1                   	// #1
  18:	cmp	x5, x1
  1c:	b.gt	28 <__addvti3+0x28>
  20:	b.eq	34 <__addvti3+0x34>  // b.none
  24:	mov	w2, #0x0                   	// #0
  28:	and	w2, w2, #0xff
  2c:	cbnz	w2, 68 <__addvti3+0x68>
  30:	ret
  34:	cmp	x4, x0
  38:	b.hi	28 <__addvti3+0x28>  // b.pmore
  3c:	b	24 <__addvti3+0x24>
  40:	mov	w2, #0x1                   	// #1
  44:	cmp	x1, x5
  48:	b.gt	54 <__addvti3+0x54>
  4c:	b.eq	5c <__addvti3+0x5c>  // b.none
  50:	mov	w2, #0x0                   	// #0
  54:	and	w2, w2, #0xff
  58:	b	2c <__addvti3+0x2c>
  5c:	cmp	x0, x4
  60:	b.hi	54 <__addvti3+0x54>  // b.pmore
  64:	b	50 <__addvti3+0x50>
  68:	stp	x29, x30, [sp, #-16]!
  6c:	mov	x29, sp
  70:	bl	0 <abort>

_subvsi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__subvdi3>:
   0:	mov	x2, x0
   4:	sub	x0, x0, x1
   8:	tbnz	x1, #63, 1c <__subvdi3+0x1c>
   c:	cmp	x2, x0
  10:	cset	w1, lt  // lt = tstop
  14:	cbnz	w1, 28 <__subvdi3+0x28>
  18:	ret
  1c:	cmp	x2, x0
  20:	cset	w1, gt
  24:	b	14 <__subvdi3+0x14>
  28:	stp	x29, x30, [sp, #-16]!
  2c:	mov	x29, sp
  30:	bl	0 <abort>

0000000000000034 <__subvsi3>:
  34:	mov	w2, w0
  38:	sub	w0, w0, w1
  3c:	tbnz	w1, #31, 50 <__subvsi3+0x1c>
  40:	cmp	w2, w0
  44:	cset	w1, lt  // lt = tstop
  48:	cbnz	w1, 5c <__subvsi3+0x28>
  4c:	ret
  50:	cmp	w2, w0
  54:	cset	w1, gt
  58:	b	48 <__subvsi3+0x14>
  5c:	stp	x29, x30, [sp, #-16]!
  60:	mov	x29, sp
  64:	bl	0 <abort>

_subvdi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__subvti3>:
   0:	mov	x5, x0
   4:	mov	x4, x1
   8:	subs	x0, x0, x2
   c:	sbc	x1, x1, x3
  10:	tbnz	x3, #63, 40 <__subvti3+0x40>
  14:	mov	w2, #0x1                   	// #1
  18:	cmp	x1, x4
  1c:	b.gt	28 <__subvti3+0x28>
  20:	b.eq	34 <__subvti3+0x34>  // b.none
  24:	mov	w2, #0x0                   	// #0
  28:	and	w2, w2, #0xff
  2c:	cbnz	w2, 68 <__subvti3+0x68>
  30:	ret
  34:	cmp	x0, x5
  38:	b.hi	28 <__subvti3+0x28>  // b.pmore
  3c:	b	24 <__subvti3+0x24>
  40:	mov	w2, #0x1                   	// #1
  44:	cmp	x4, x1
  48:	b.gt	54 <__subvti3+0x54>
  4c:	b.eq	5c <__subvti3+0x5c>  // b.none
  50:	mov	w2, #0x0                   	// #0
  54:	and	w2, w2, #0xff
  58:	b	2c <__subvti3+0x2c>
  5c:	cmp	x5, x0
  60:	b.hi	54 <__subvti3+0x54>  // b.pmore
  64:	b	50 <__subvti3+0x50>
  68:	stp	x29, x30, [sp, #-16]!
  6c:	mov	x29, sp
  70:	bl	0 <abort>

_mulvsi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulvdi3>:
   0:	mov	x2, x0
   4:	asr	x5, x0, #63
   8:	asr	x4, x1, #63
   c:	mul	x0, x0, x1
  10:	umulh	x3, x2, x1
  14:	madd	x3, x5, x1, x3
  18:	madd	x3, x2, x4, x3
  1c:	cmp	x3, x0, asr #63
  20:	b.ne	28 <__mulvdi3+0x28>  // b.any
  24:	ret
  28:	stp	x29, x30, [sp, #-16]!
  2c:	mov	x29, sp
  30:	bl	0 <abort>

0000000000000034 <__mulvsi3>:
  34:	smull	x0, w1, w0
  38:	asr	x1, x0, #32
  3c:	cmp	w1, w0, asr #31
  40:	b.ne	48 <__mulvsi3+0x14>  // b.any
  44:	ret
  48:	stp	x29, x30, [sp, #-16]!
  4c:	mov	x29, sp
  50:	bl	0 <abort>

_mulvdi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulvti3>:
   0:	mov	x4, x0
   4:	cmp	x1, x0, asr #63
   8:	b.ne	74 <__mulvti3+0x74>  // b.any
   c:	cmp	x3, x2, asr #63
  10:	b.ne	30 <__mulvti3+0x30>  // b.any
  14:	asr	x0, x0, #63
  18:	asr	x3, x2, #63
  1c:	umulh	x1, x4, x2
  20:	madd	x1, x0, x2, x1
  24:	mul	x0, x4, x2
  28:	madd	x1, x4, x3, x1
  2c:	ret
  30:	mul	x0, x2, x0
  34:	umulh	x1, x2, x4
  38:	mov	x6, x1
  3c:	umulh	x7, x3, x4
  40:	mul	x1, x3, x4
  44:	sub	x5, x7, x4
  48:	cmp	x3, #0x0
  4c:	csel	x5, x5, x7, lt  // lt = tstop
  50:	tbnz	x4, #63, 68 <__mulvti3+0x68>
  54:	adds	x1, x1, x6
  58:	cinc	x5, x5, cs  // cs = hs, nlast
  5c:	cmp	x5, x1, asr #63
  60:	b.ne	154 <__mulvti3+0x154>  // b.any
  64:	ret
  68:	subs	x1, x1, x2
  6c:	sbc	x5, x5, x3
  70:	b	54 <__mulvti3+0x54>
  74:	cmp	x3, x2, asr #63
  78:	b.ne	bc <__mulvti3+0xbc>  // b.any
  7c:	mul	x0, x0, x2
  80:	umulh	x6, x4, x2
  84:	umulh	x7, x1, x2
  88:	mul	x5, x1, x2
  8c:	sub	x3, x7, x2
  90:	cmp	x1, #0x0
  94:	csel	x3, x3, x7, lt  // lt = tstop
  98:	tbnz	x2, #63, b0 <__mulvti3+0xb0>
  9c:	adds	x1, x5, x6
  a0:	cinc	x3, x3, cs  // cs = hs, nlast
  a4:	cmp	x3, x1, asr #63
  a8:	b.ne	154 <__mulvti3+0x154>  // b.any
  ac:	ret
  b0:	subs	x5, x5, x4
  b4:	sbc	x3, x3, x1
  b8:	b	9c <__mulvti3+0x9c>
  bc:	tbnz	x1, #63, 104 <__mulvti3+0x104>
  c0:	tbnz	x3, #63, e0 <__mulvti3+0xe0>
  c4:	orr	x1, x1, x3
  c8:	cbnz	x1, 154 <__mulvti3+0x154>
  cc:	umulh	x3, x0, x2
  d0:	mul	x0, x0, x2
  d4:	mov	x1, x3
  d8:	tbnz	x3, #63, 154 <__mulvti3+0x154>
  dc:	ret
  e0:	cmp	x1, #0x0
  e4:	ccmn	x3, #0x1, #0x0, eq  // eq = none
  e8:	b.ne	154 <__mulvti3+0x154>  // b.any
  ec:	mul	x0, x0, x2
  f0:	umulh	x1, x4, x2
  f4:	subs	x4, x1, x4
  f8:	b.pl	154 <__mulvti3+0x154>  // b.nfrst
  fc:	mov	x1, x4
 100:	ret
 104:	tbnz	x3, #63, 12c <__mulvti3+0x12c>
 108:	cmp	x3, #0x0
 10c:	ccmn	x1, #0x1, #0x0, eq  // eq = none
 110:	b.ne	154 <__mulvti3+0x154>  // b.any
 114:	mul	x0, x0, x2
 118:	umulh	x4, x4, x2
 11c:	subs	x4, x4, x2
 120:	b.pl	154 <__mulvti3+0x154>  // b.nfrst
 124:	mov	x1, x4
 128:	ret
 12c:	and	x1, x1, x3
 130:	cmn	x1, #0x1
 134:	b.ne	154 <__mulvti3+0x154>  // b.any
 138:	orr	x0, x0, x2
 13c:	cbz	x0, 154 <__mulvti3+0x154>
 140:	mul	x0, x4, x2
 144:	umulh	x1, x4, x2
 148:	sub	x1, x1, x4
 14c:	subs	x1, x1, x2
 150:	b.pl	dc <__mulvti3+0xdc>  // b.nfrst
 154:	stp	x29, x30, [sp, #-16]!
 158:	mov	x29, sp
 15c:	bl	0 <abort>

_negvsi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negvdi2>:
   0:	mov	x1, x0
   4:	neg	x0, x0
   8:	tbnz	x1, #63, 1c <__negvdi2+0x1c>
   c:	cmp	x0, #0x0
  10:	cset	w1, gt
  14:	cbnz	w1, 28 <__negvdi2+0x28>
  18:	ret
  1c:	lsr	x1, x0, #63
  20:	and	w1, w1, #0xff
  24:	b	14 <__negvdi2+0x14>
  28:	stp	x29, x30, [sp, #-16]!
  2c:	mov	x29, sp
  30:	bl	0 <abort>

0000000000000034 <__negvsi2>:
  34:	mov	w1, w0
  38:	neg	w0, w0
  3c:	lsr	w2, w0, #31
  40:	tbnz	w1, #31, 4c <__negvsi2+0x18>
  44:	cmp	w0, #0x0
  48:	cset	w2, gt
  4c:	cbnz	w2, 54 <__negvsi2+0x20>
  50:	ret
  54:	stp	x29, x30, [sp, #-16]!
  58:	mov	x29, sp
  5c:	bl	0 <abort>

_negvdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negvti2>:
   0:	mov	x2, x1
   4:	negs	x0, x0
   8:	ngc	x1, x1
   c:	tbnz	x2, #63, 30 <__negvti2+0x30>
  10:	mov	x3, x0
  14:	asr	x2, x1, #63
  18:	subs	x3, x2, x3
  1c:	sbc	x2, x2, x1
  20:	lsr	x2, x2, #63
  24:	and	w2, w2, #0xff
  28:	cbnz	w2, 3c <__negvti2+0x3c>
  2c:	ret
  30:	lsr	x2, x1, #63
  34:	and	w2, w2, #0xff
  38:	b	28 <__negvti2+0x28>
  3c:	stp	x29, x30, [sp, #-16]!
  40:	mov	x29, sp
  44:	bl	0 <abort>

_ctors.o:     file format elf64-littleaarch64


_ffssi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ffsdi2>:
   0:	rbit	x1, x0
   4:	clz	x1, x1
   8:	cmp	x0, #0x0
   c:	csinc	w0, wzr, w1, eq  // eq = none
  10:	ret

_ffsdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ffsti2>:
   0:	cbz	x0, 1c <__ffsti2+0x1c>
   4:	mov	x1, #0x0                   	// #0
   8:	add	w1, w1, #0x1
   c:	rbit	x0, x0
  10:	clz	x0, x0
  14:	add	w0, w1, w0
  18:	ret
  1c:	mov	w0, #0x0                   	// #0
  20:	cbz	x1, 18 <__ffsti2+0x18>
  24:	mov	x0, x1
  28:	mov	x1, #0x40                  	// #64
  2c:	b	8 <__ffsti2+0x8>

_clz.o:     file format elf64-littleaarch64


_clzsi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__clzdi2>:
   0:	clz	x0, x0
   4:	ret

_clzdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__clzti2>:
   0:	cbz	x1, 18 <__clzti2+0x18>
   4:	mov	x0, x1
   8:	mov	x1, #0x0                   	// #0
   c:	clz	x0, x0
  10:	add	w0, w1, w0
  14:	ret
  18:	mov	x1, #0x40                  	// #64
  1c:	b	c <__clzti2+0xc>

_ctzsi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ctzdi2>:
   0:	rbit	x0, x0
   4:	clz	x0, x0
   8:	ret

_ctzdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ctzti2>:
   0:	cbz	x0, 18 <__ctzti2+0x18>
   4:	mov	x1, #0x0                   	// #0
   8:	rbit	x0, x0
   c:	clz	x0, x0
  10:	add	w0, w1, w0
  14:	ret
  18:	mov	x0, x1
  1c:	mov	x1, #0x40                  	// #64
  20:	b	8 <__ctzti2+0x8>

_popcount_tab.o:     file format elf64-littleaarch64


_popcountsi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__popcountdi2>:
   0:	lsr	x1, x0, #1
   4:	and	x1, x1, #0x5555555555555555
   8:	sub	x0, x0, x1
   c:	and	x1, x0, #0x3333333333333333
  10:	lsr	x0, x0, #2
  14:	and	x0, x0, #0x3333333333333333
  18:	add	x0, x1, x0
  1c:	add	x0, x0, x0, lsr #4
  20:	and	x0, x0, #0xf0f0f0f0f0f0f0f
  24:	mov	x1, #0x101010101010101     	// #72340172838076673
  28:	mul	x0, x0, x1
  2c:	lsr	x0, x0, #56
  30:	ret

_popcountdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__popcountti2>:
   0:	lsr	x2, x0, #1
   4:	and	x2, x2, #0x5555555555555555
   8:	sub	x0, x0, x2
   c:	lsr	x2, x1, #1
  10:	and	x2, x2, #0x5555555555555555
  14:	sub	x2, x1, x2
  18:	and	x1, x0, #0x3333333333333333
  1c:	lsr	x0, x0, #2
  20:	and	x0, x0, #0x3333333333333333
  24:	add	x0, x1, x0
  28:	and	x1, x2, #0x3333333333333333
  2c:	lsr	x2, x2, #2
  30:	and	x2, x2, #0x3333333333333333
  34:	add	x1, x1, x2
  38:	add	x0, x0, x0, lsr #4
  3c:	and	x2, x0, #0xf0f0f0f0f0f0f0f
  40:	add	x0, x1, x1, lsr #4
  44:	and	x0, x0, #0xf0f0f0f0f0f0f0f
  48:	add	x0, x0, x2
  4c:	mov	x1, #0x101010101010101     	// #72340172838076673
  50:	mul	x0, x0, x1
  54:	lsr	x0, x0, #56
  58:	ret

_paritysi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__paritydi2>:
   0:	eor	x0, x0, x0, lsr #32
   4:	eor	x0, x0, x0, lsr #16
   8:	eor	x0, x0, x0, lsr #8
   c:	eor	x0, x0, x0, lsr #4
  10:	and	x0, x0, #0xf
  14:	mov	w1, #0x6996                	// #27030
  18:	asr	w0, w1, w0
  1c:	and	w0, w0, #0x1
  20:	ret

_paritydi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__parityti2>:
   0:	eor	x0, x0, x1
   4:	eor	x0, x0, x0, lsr #32
   8:	eor	x0, x0, x0, lsr #16
   c:	eor	x0, x0, x0, lsr #8
  10:	eor	x0, x0, x0, lsr #4
  14:	and	x0, x0, #0xf
  18:	mov	w1, #0x6996                	// #27030
  1c:	asr	w0, w1, w0
  20:	and	w0, w0, #0x1
  24:	ret

_powisf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__powisf2>:
   0:	fmov	s1, s0
   4:	cmp	w0, #0x0
   8:	cneg	w2, w0, lt  // lt = tstop
   c:	tst	x0, #0x1
  10:	fmov	s0, #1.000000000000000000e+00
  14:	fcsel	s0, s1, s0, ne  // ne = any
  18:	lsr	w1, w2, #1
  1c:	cmp	wzr, w2, lsr #1
  20:	b.ne	34 <__powisf2+0x34>  // b.any
  24:	tbnz	w0, #31, 44 <__powisf2+0x44>
  28:	ret
  2c:	lsr	w1, w1, #1
  30:	cbz	w1, 24 <__powisf2+0x24>
  34:	fmul	s1, s1, s1
  38:	tbz	w1, #0, 2c <__powisf2+0x2c>
  3c:	fmul	s0, s0, s1
  40:	b	2c <__powisf2+0x2c>
  44:	fmov	s1, #1.000000000000000000e+00
  48:	fdiv	s0, s1, s0
  4c:	b	28 <__powisf2+0x28>

_powidf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__powidf2>:
   0:	fmov	d1, d0
   4:	cmp	w0, #0x0
   8:	cneg	w2, w0, lt  // lt = tstop
   c:	tst	x0, #0x1
  10:	fmov	d0, #1.000000000000000000e+00
  14:	fcsel	d0, d1, d0, ne  // ne = any
  18:	lsr	w1, w2, #1
  1c:	cmp	wzr, w2, lsr #1
  20:	b.ne	34 <__powidf2+0x34>  // b.any
  24:	tbnz	w0, #31, 44 <__powidf2+0x44>
  28:	ret
  2c:	lsr	w1, w1, #1
  30:	cbz	w1, 24 <__powidf2+0x24>
  34:	fmul	d1, d1, d1
  38:	tbz	w1, #0, 2c <__powidf2+0x2c>
  3c:	fmul	d0, d0, d1
  40:	b	2c <__powidf2+0x2c>
  44:	fmov	d1, #1.000000000000000000e+00
  48:	fdiv	d0, d1, d0
  4c:	b	28 <__powidf2+0x28>

_powixf2.o:     file format elf64-littleaarch64


_powitf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__powitf2>:
   0:	stp	x29, x30, [sp, #-64]!
   4:	mov	x29, sp
   8:	stp	x19, x20, [sp, #16]
   c:	str	q0, [sp, #32]
  10:	mov	w20, w0
  14:	cmp	w0, #0x0
  18:	cneg	w0, w0, lt  // lt = tstop
  1c:	str	q0, [sp, #48]
  20:	tbnz	w20, #0, 34 <__powitf2+0x34>
  24:	adrp	x1, 0 <__powitf2>
  28:	add	x1, x1, #0x0
  2c:	ldr	q0, [x1]
  30:	str	q0, [sp, #48]
  34:	lsr	w19, w0, #1
  38:	cmp	wzr, w0, lsr #1
  3c:	b.ne	5c <__powitf2+0x5c>  // b.any
  40:	tbnz	w20, #31, 84 <__powitf2+0x84>
  44:	ldr	q0, [sp, #48]
  48:	ldp	x19, x20, [sp, #16]
  4c:	ldp	x29, x30, [sp], #64
  50:	ret
  54:	lsr	w19, w19, #1
  58:	cbz	w19, 40 <__powitf2+0x40>
  5c:	ldr	q0, [sp, #32]
  60:	mov	v1.16b, v0.16b
  64:	bl	0 <__multf3>
  68:	str	q0, [sp, #32]
  6c:	tbz	w19, #0, 54 <__powitf2+0x54>
  70:	mov	v1.16b, v0.16b
  74:	ldr	q0, [sp, #48]
  78:	bl	0 <__multf3>
  7c:	str	q0, [sp, #48]
  80:	b	54 <__powitf2+0x54>
  84:	ldr	q1, [sp, #48]
  88:	adrp	x0, 0 <__powitf2>
  8c:	add	x0, x0, #0x0
  90:	ldr	q0, [x0]
  94:	bl	0 <__divtf3>
  98:	str	q0, [sp, #48]
  9c:	b	44 <__powitf2+0x44>

_mulhc3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulhc3>:
   0:	mov	v17.h[0], v0.h[0]
   4:	mov	v16.h[0], v1.h[0]
   8:	fcvt	s5, h0
   c:	fcvt	s4, h2
  10:	fmul	s6, s5, s4
  14:	fcvt	h6, s6
  18:	fcvt	s0, h1
  1c:	fcvt	s1, h3
  20:	fmul	s18, s0, s1
  24:	fcvt	h18, s18
  28:	fmul	s5, s5, s1
  2c:	fcvt	h5, s5
  30:	fmul	s4, s4, s0
  34:	fcvt	h4, s4
  38:	fcvt	s1, h6
  3c:	fcvt	s0, h18
  40:	fsub	s1, s1, s0
  44:	fcvt	h0, s1
  48:	fcvt	s7, h5
  4c:	fcvt	s1, h4
  50:	fadd	s7, s7, s1
  54:	fcvt	h1, s7
  58:	fcvt	s7, h0
  5c:	fcmp	s7, s7
  60:	cset	w0, vs
  64:	fcvt	s7, h1
  68:	fcmp	s7, s7
  6c:	cset	w1, vs
  70:	ands	w0, w0, w1
  74:	b.eq	220 <__mulhc3+0x220>  // b.none
  78:	fcvt	s7, h17
  7c:	fabs	s7, s7
  80:	fcvt	h7, s7
  84:	fcvt	s20, h7
  88:	mov	w1, #0xe000                	// #57344
  8c:	movk	w1, #0x477f, lsl #16
  90:	fmov	s19, w1
  94:	fcmp	s20, s19
  98:	b.gt	b8 <__mulhc3+0xb8>
  9c:	fcvt	s19, h16
  a0:	fabs	s19, s19
  a4:	fcvt	h19, s19
  a8:	fcvt	s19, h19
  ac:	fmov	s20, w1
  b0:	fcmp	s19, s20
  b4:	b.le	24c <__mulhc3+0x24c>
  b8:	fcvt	s7, h7
  bc:	adrp	x1, 0 <__mulhc3>
  c0:	ldr	s19, [x1]
  c4:	fcmp	s7, s19
  c8:	cset	w1, gt
  cc:	scvtf	d7, w1
  d0:	umov	w2, v17.h[0]
  d4:	fcvt	h7, d7
  d8:	umov	w1, v7.h[0]
  dc:	bfxil	w2, w1, #0, #15
  e0:	dup	v17.4h, w2
  e4:	fcvt	s7, h16
  e8:	fabs	s7, s7
  ec:	fcvt	h7, s7
  f0:	fcvt	s7, h7
  f4:	fcmp	s7, s19
  f8:	cset	w1, gt
  fc:	scvtf	d7, w1
 100:	umov	w2, v16.h[0]
 104:	fcvt	h7, d7
 108:	umov	w1, v7.h[0]
 10c:	bfxil	w2, w1, #0, #15
 110:	dup	v16.4h, w2
 114:	fcvt	s7, h2
 118:	fcmp	s7, s7
 11c:	b.vs	224 <__mulhc3+0x224>
 120:	fcvt	s7, h3
 124:	fcmp	s7, s7
 128:	b.vs	238 <__mulhc3+0x238>
 12c:	fcvt	s7, h2
 130:	fabs	s7, s7
 134:	fcvt	h7, s7
 138:	fcvt	s20, h7
 13c:	mov	w1, #0xe000                	// #57344
 140:	movk	w1, #0x477f, lsl #16
 144:	fmov	s19, w1
 148:	fcmp	s20, s19
 14c:	b.gt	16c <__mulhc3+0x16c>
 150:	fcvt	s19, h3
 154:	fabs	s19, s19
 158:	fcvt	h19, s19
 15c:	fcvt	s19, h19
 160:	fmov	s20, w1
 164:	fcmp	s19, s20
 168:	b.le	27c <__mulhc3+0x27c>
 16c:	fcvt	s0, h17
 170:	fcmp	s0, s0
 174:	b.vs	254 <__mulhc3+0x254>
 178:	fcvt	s0, h16
 17c:	fcmp	s0, s0
 180:	b.vs	268 <__mulhc3+0x268>
 184:	fcvt	s7, h7
 188:	adrp	x0, 0 <__mulhc3>
 18c:	ldr	s1, [x0]
 190:	fcmp	s7, s1
 194:	cset	w0, gt
 198:	scvtf	d0, w0
 19c:	umov	w1, v2.h[0]
 1a0:	fcvt	h0, d0
 1a4:	umov	w0, v0.h[0]
 1a8:	bfxil	w1, w0, #0, #15
 1ac:	dup	v2.4h, w1
 1b0:	fcvt	s0, h3
 1b4:	fabs	s0, s0
 1b8:	fcvt	h0, s0
 1bc:	fcvt	s0, h0
 1c0:	fcmp	s0, s1
 1c4:	cset	w0, gt
 1c8:	scvtf	d0, w0
 1cc:	umov	w1, v3.h[0]
 1d0:	fcvt	h0, d0
 1d4:	umov	w0, v0.h[0]
 1d8:	bfxil	w1, w0, #0, #15
 1dc:	dup	v3.4h, w1
 1e0:	fcvt	s17, h17
 1e4:	fcvt	s2, h2
 1e8:	fcvt	s1, h16
 1ec:	fcvt	s3, h3
 1f0:	fmul	s0, s17, s2
 1f4:	fmul	s4, s1, s3
 1f8:	fsub	s0, s0, s4
 1fc:	adrp	x0, 0 <__mulhc3>
 200:	ldr	s4, [x0]
 204:	fmul	s0, s0, s4
 208:	fcvt	h0, s0
 20c:	fmul	s17, s17, s3
 210:	fmul	s2, s2, s1
 214:	fadd	s1, s17, s2
 218:	fmul	s1, s1, s4
 21c:	fcvt	h1, s1
 220:	ret
 224:	umov	w1, v2.h[0]
 228:	movi	v2.4h, #0x0
 22c:	tbz	w1, #15, 120 <__mulhc3+0x120>
 230:	movi	v2.4h, #0x80, lsl #8
 234:	b	120 <__mulhc3+0x120>
 238:	umov	w1, v3.h[0]
 23c:	movi	v3.4h, #0x0
 240:	tbz	w1, #15, 12c <__mulhc3+0x12c>
 244:	movi	v3.4h, #0x80, lsl #8
 248:	b	12c <__mulhc3+0x12c>
 24c:	mov	w0, #0x0                   	// #0
 250:	b	12c <__mulhc3+0x12c>
 254:	umov	w0, v17.h[0]
 258:	movi	v17.4h, #0x0
 25c:	tbz	w0, #15, 178 <__mulhc3+0x178>
 260:	movi	v17.4h, #0x80, lsl #8
 264:	b	178 <__mulhc3+0x178>
 268:	umov	w0, v16.h[0]
 26c:	movi	v16.4h, #0x0
 270:	tbz	w0, #15, 184 <__mulhc3+0x184>
 274:	movi	v16.4h, #0x80, lsl #8
 278:	b	184 <__mulhc3+0x184>
 27c:	cbnz	w0, 1e0 <__mulhc3+0x1e0>
 280:	fcvt	s6, h6
 284:	fabs	s6, s6
 288:	fcvt	h6, s6
 28c:	fcvt	s6, h6
 290:	mov	w0, #0xe000                	// #57344
 294:	movk	w0, #0x477f, lsl #16
 298:	fmov	s7, w0
 29c:	fcmp	s6, s7
 2a0:	b.gt	2ec <__mulhc3+0x2ec>
 2a4:	fcvt	s6, h18
 2a8:	fabs	s6, s6
 2ac:	fcvt	h6, s6
 2b0:	fcvt	s6, h6
 2b4:	fcmp	s6, s7
 2b8:	b.gt	2ec <__mulhc3+0x2ec>
 2bc:	fcvt	s5, h5
 2c0:	fabs	s5, s5
 2c4:	fcvt	h5, s5
 2c8:	fcvt	s5, h5
 2cc:	fcmp	s5, s7
 2d0:	b.gt	2ec <__mulhc3+0x2ec>
 2d4:	fcvt	s4, h4
 2d8:	fabs	s4, s4
 2dc:	fcvt	h4, s4
 2e0:	fcvt	s4, h4
 2e4:	fcmp	s4, s7
 2e8:	b.le	220 <__mulhc3+0x220>
 2ec:	fcvt	s0, h17
 2f0:	fcmp	s0, s0
 2f4:	b.vs	330 <__mulhc3+0x330>
 2f8:	fcvt	s0, h16
 2fc:	fcmp	s0, s0
 300:	b.vs	344 <__mulhc3+0x344>
 304:	fcvt	s0, h2
 308:	fcmp	s0, s0
 30c:	b.vs	358 <__mulhc3+0x358>
 310:	fcvt	s0, h3
 314:	fcmp	s0, s0
 318:	b.vc	1e0 <__mulhc3+0x1e0>
 31c:	umov	w0, v3.h[0]
 320:	movi	v3.4h, #0x0
 324:	tbz	w0, #15, 1e0 <__mulhc3+0x1e0>
 328:	movi	v3.4h, #0x80, lsl #8
 32c:	b	1e0 <__mulhc3+0x1e0>
 330:	umov	w0, v17.h[0]
 334:	movi	v17.4h, #0x0
 338:	tbz	w0, #15, 2f8 <__mulhc3+0x2f8>
 33c:	movi	v17.4h, #0x80, lsl #8
 340:	b	2f8 <__mulhc3+0x2f8>
 344:	umov	w0, v16.h[0]
 348:	movi	v16.4h, #0x0
 34c:	tbz	w0, #15, 304 <__mulhc3+0x304>
 350:	movi	v16.4h, #0x80, lsl #8
 354:	b	304 <__mulhc3+0x304>
 358:	umov	w0, v2.h[0]
 35c:	movi	v2.4h, #0x0
 360:	tbz	w0, #15, 310 <__mulhc3+0x310>
 364:	movi	v2.4h, #0x80, lsl #8
 368:	b	310 <__mulhc3+0x310>

_mulsc3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulsc3>:
   0:	fmov	s17, s0
   4:	fmov	s16, s1
   8:	fmul	s4, s0, s2
   c:	fmul	s5, s1, s3
  10:	fmul	s6, s0, s3
  14:	fmul	s7, s2, s1
  18:	fsub	s0, s4, s5
  1c:	fadd	s1, s6, s7
  20:	fcmp	s0, s0
  24:	cset	w0, vs
  28:	fcmp	s1, s1
  2c:	cset	w1, vs
  30:	ands	w0, w0, w1
  34:	b.eq	120 <__mulsc3+0x120>  // b.none
  38:	fabs	s18, s17
  3c:	mov	w1, #0x7f7fffff            	// #2139095039
  40:	fmov	s19, w1
  44:	fcmp	s18, s19
  48:	b.gt	58 <__mulsc3+0x58>
  4c:	fabs	s20, s16
  50:	fcmp	s20, s19
  54:	b.le	140 <__mulsc3+0x140>
  58:	adrp	x1, 0 <__mulsc3>
  5c:	ldr	s20, [x1]
  60:	fcmp	s18, s20
  64:	cset	w1, gt
  68:	scvtf	s18, w1
  6c:	movi	v19.2s, #0x80, lsl #24
  70:	bif	v17.8b, v18.8b, v19.8b
  74:	fabs	s18, s16
  78:	fcmp	s18, s20
  7c:	cset	w1, gt
  80:	scvtf	s18, w1
  84:	bif	v16.8b, v18.8b, v19.8b
  88:	fcmp	s2, s2
  8c:	b.vs	124 <__mulsc3+0x124>
  90:	fcmp	s3, s3
  94:	b.vs	130 <__mulsc3+0x130>
  98:	fabs	s18, s2
  9c:	mov	w1, #0x7f7fffff            	// #2139095039
  a0:	fmov	s19, w1
  a4:	fcmp	s18, s19
  a8:	b.gt	b8 <__mulsc3+0xb8>
  ac:	fabs	s20, s3
  b0:	fcmp	s20, s19
  b4:	b.le	168 <__mulsc3+0x168>
  b8:	fcmp	s17, s17
  bc:	b.vs	148 <__mulsc3+0x148>
  c0:	fcmp	s16, s16
  c4:	b.vs	158 <__mulsc3+0x158>
  c8:	adrp	x0, 0 <__mulsc3>
  cc:	ldr	s4, [x0]
  d0:	fcmp	s18, s4
  d4:	cset	w0, gt
  d8:	scvtf	s0, w0
  dc:	movi	v1.2s, #0x80, lsl #24
  e0:	bif	v2.8b, v0.8b, v1.8b
  e4:	fabs	s0, s3
  e8:	fcmp	s0, s4
  ec:	cset	w0, gt
  f0:	scvtf	s0, w0
  f4:	bif	v3.8b, v0.8b, v1.8b
  f8:	fmul	s0, s17, s2
  fc:	fmul	s1, s16, s3
 100:	fsub	s0, s0, s1
 104:	adrp	x0, 0 <__mulsc3>
 108:	ldr	s4, [x0]
 10c:	fmul	s0, s0, s4
 110:	fmul	s3, s17, s3
 114:	fmul	s1, s16, s2
 118:	fadd	s1, s3, s1
 11c:	fmul	s1, s1, s4
 120:	ret
 124:	movi	v18.2s, #0x0
 128:	bif	v2.8b, v18.8b, v19.8b
 12c:	b	90 <__mulsc3+0x90>
 130:	movi	v18.2s, #0x0
 134:	movi	v19.2s, #0x80, lsl #24
 138:	bif	v3.8b, v18.8b, v19.8b
 13c:	b	98 <__mulsc3+0x98>
 140:	mov	w0, #0x0                   	// #0
 144:	b	98 <__mulsc3+0x98>
 148:	movi	v0.2s, #0x0
 14c:	movi	v1.2s, #0x80, lsl #24
 150:	bif	v17.8b, v0.8b, v1.8b
 154:	b	c0 <__mulsc3+0xc0>
 158:	movi	v0.2s, #0x0
 15c:	movi	v1.2s, #0x80, lsl #24
 160:	bif	v16.8b, v0.8b, v1.8b
 164:	b	c8 <__mulsc3+0xc8>
 168:	cbnz	w0, f8 <__mulsc3+0xf8>
 16c:	fabs	s4, s4
 170:	mov	w0, #0x7f7fffff            	// #2139095039
 174:	fmov	s18, w0
 178:	fcmp	s4, s18
 17c:	b.gt	1a4 <__mulsc3+0x1a4>
 180:	fabs	s5, s5
 184:	fcmp	s5, s18
 188:	b.gt	1a4 <__mulsc3+0x1a4>
 18c:	fabs	s6, s6
 190:	fcmp	s6, s18
 194:	b.gt	1a4 <__mulsc3+0x1a4>
 198:	fabs	s7, s7
 19c:	fcmp	s7, s18
 1a0:	b.le	120 <__mulsc3+0x120>
 1a4:	fcmp	s17, s17
 1a8:	b.vs	1d4 <__mulsc3+0x1d4>
 1ac:	fcmp	s16, s16
 1b0:	b.vs	1e4 <__mulsc3+0x1e4>
 1b4:	fcmp	s2, s2
 1b8:	b.vs	1f4 <__mulsc3+0x1f4>
 1bc:	fcmp	s3, s3
 1c0:	b.vc	f8 <__mulsc3+0xf8>
 1c4:	movi	v0.2s, #0x0
 1c8:	movi	v1.2s, #0x80, lsl #24
 1cc:	bif	v3.8b, v0.8b, v1.8b
 1d0:	b	f8 <__mulsc3+0xf8>
 1d4:	movi	v0.2s, #0x0
 1d8:	movi	v1.2s, #0x80, lsl #24
 1dc:	bif	v17.8b, v0.8b, v1.8b
 1e0:	b	1ac <__mulsc3+0x1ac>
 1e4:	movi	v0.2s, #0x0
 1e8:	movi	v1.2s, #0x80, lsl #24
 1ec:	bif	v16.8b, v0.8b, v1.8b
 1f0:	b	1b4 <__mulsc3+0x1b4>
 1f4:	movi	v0.2s, #0x0
 1f8:	movi	v1.2s, #0x80, lsl #24
 1fc:	bif	v2.8b, v0.8b, v1.8b
 200:	b	1bc <__mulsc3+0x1bc>

_muldc3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__muldc3>:
   0:	fmov	d17, d0
   4:	fmov	d16, d1
   8:	fmul	d4, d0, d2
   c:	fmul	d5, d1, d3
  10:	fmul	d6, d0, d3
  14:	fmul	d7, d2, d1
  18:	fsub	d0, d4, d5
  1c:	fadd	d1, d6, d7
  20:	fcmp	d0, d0
  24:	cset	w0, vs
  28:	fcmp	d1, d1
  2c:	cset	w1, vs
  30:	ands	w0, w0, w1
  34:	b.eq	128 <__muldc3+0x128>  // b.none
  38:	fabs	d18, d17
  3c:	mov	x1, #0x7fefffffffffffff    	// #9218868437227405311
  40:	fmov	d19, x1
  44:	fcmp	d18, d19
  48:	b.gt	58 <__muldc3+0x58>
  4c:	fabs	d20, d16
  50:	fcmp	d20, d19
  54:	b.le	14c <__muldc3+0x14c>
  58:	adrp	x1, 0 <__muldc3>
  5c:	ldr	d20, [x1]
  60:	fcmp	d18, d20
  64:	cset	w1, gt
  68:	scvtf	d18, w1
  6c:	mov	x1, #0x8000000000000000    	// #-9223372036854775808
  70:	fmov	d19, x1
  74:	bif	v17.8b, v18.8b, v19.8b
  78:	fabs	d18, d16
  7c:	fcmp	d18, d20
  80:	cset	w1, gt
  84:	scvtf	d18, w1
  88:	bif	v16.8b, v18.8b, v19.8b
  8c:	fcmp	d2, d2
  90:	b.vs	12c <__muldc3+0x12c>
  94:	fcmp	d3, d3
  98:	b.vs	138 <__muldc3+0x138>
  9c:	fabs	d18, d2
  a0:	mov	x1, #0x7fefffffffffffff    	// #9218868437227405311
  a4:	fmov	d19, x1
  a8:	fcmp	d18, d19
  ac:	b.gt	bc <__muldc3+0xbc>
  b0:	fabs	d20, d3
  b4:	fcmp	d20, d19
  b8:	b.le	17c <__muldc3+0x17c>
  bc:	fcmp	d17, d17
  c0:	b.vs	154 <__muldc3+0x154>
  c4:	fcmp	d16, d16
  c8:	b.vs	168 <__muldc3+0x168>
  cc:	adrp	x0, 0 <__muldc3>
  d0:	ldr	d4, [x0]
  d4:	fcmp	d18, d4
  d8:	cset	w0, gt
  dc:	scvtf	d0, w0
  e0:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
  e4:	fmov	d1, x0
  e8:	bif	v2.8b, v0.8b, v1.8b
  ec:	fabs	d0, d3
  f0:	fcmp	d0, d4
  f4:	cset	w0, gt
  f8:	scvtf	d0, w0
  fc:	bif	v3.8b, v0.8b, v1.8b
 100:	fmul	d0, d17, d2
 104:	fmul	d1, d16, d3
 108:	fsub	d0, d0, d1
 10c:	adrp	x0, 0 <__muldc3>
 110:	ldr	d4, [x0]
 114:	fmul	d0, d0, d4
 118:	fmul	d3, d17, d3
 11c:	fmul	d1, d16, d2
 120:	fadd	d1, d3, d1
 124:	fmul	d1, d1, d4
 128:	ret
 12c:	movi	d18, #0x0
 130:	bif	v2.8b, v18.8b, v19.8b
 134:	b	94 <__muldc3+0x94>
 138:	movi	d18, #0x0
 13c:	mov	x1, #0x8000000000000000    	// #-9223372036854775808
 140:	fmov	d19, x1
 144:	bif	v3.8b, v18.8b, v19.8b
 148:	b	9c <__muldc3+0x9c>
 14c:	mov	w0, #0x0                   	// #0
 150:	b	9c <__muldc3+0x9c>
 154:	movi	d0, #0x0
 158:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 15c:	fmov	d1, x0
 160:	bif	v17.8b, v0.8b, v1.8b
 164:	b	c4 <__muldc3+0xc4>
 168:	movi	d0, #0x0
 16c:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 170:	fmov	d1, x0
 174:	bif	v16.8b, v0.8b, v1.8b
 178:	b	cc <__muldc3+0xcc>
 17c:	cbnz	w0, 100 <__muldc3+0x100>
 180:	fabs	d4, d4
 184:	mov	x0, #0x7fefffffffffffff    	// #9218868437227405311
 188:	fmov	d18, x0
 18c:	fcmp	d4, d18
 190:	b.gt	1b8 <__muldc3+0x1b8>
 194:	fabs	d5, d5
 198:	fcmp	d5, d18
 19c:	b.gt	1b8 <__muldc3+0x1b8>
 1a0:	fabs	d6, d6
 1a4:	fcmp	d6, d18
 1a8:	b.gt	1b8 <__muldc3+0x1b8>
 1ac:	fabs	d7, d7
 1b0:	fcmp	d7, d18
 1b4:	b.le	128 <__muldc3+0x128>
 1b8:	fcmp	d17, d17
 1bc:	b.vs	1ec <__muldc3+0x1ec>
 1c0:	fcmp	d16, d16
 1c4:	b.vs	200 <__muldc3+0x200>
 1c8:	fcmp	d2, d2
 1cc:	b.vs	214 <__muldc3+0x214>
 1d0:	fcmp	d3, d3
 1d4:	b.vc	100 <__muldc3+0x100>
 1d8:	movi	d0, #0x0
 1dc:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 1e0:	fmov	d1, x0
 1e4:	bif	v3.8b, v0.8b, v1.8b
 1e8:	b	100 <__muldc3+0x100>
 1ec:	movi	d0, #0x0
 1f0:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 1f4:	fmov	d1, x0
 1f8:	bif	v17.8b, v0.8b, v1.8b
 1fc:	b	1c0 <__muldc3+0x1c0>
 200:	movi	d0, #0x0
 204:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 208:	fmov	d1, x0
 20c:	bif	v16.8b, v0.8b, v1.8b
 210:	b	1c8 <__muldc3+0x1c8>
 214:	movi	d0, #0x0
 218:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 21c:	fmov	d1, x0
 220:	bif	v2.8b, v0.8b, v1.8b
 224:	b	1d0 <__muldc3+0x1d0>

_mulxc3.o:     file format elf64-littleaarch64


_multc3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__multc3>:
   0:	stp	x29, x30, [sp, #-240]!
   4:	mov	x29, sp
   8:	stp	x19, x20, [sp, #16]
   c:	stp	x21, x22, [sp, #32]
  10:	stp	x23, x24, [sp, #48]
  14:	stp	x25, x26, [sp, #64]
  18:	stp	x27, x28, [sp, #80]
  1c:	str	q0, [sp, #96]
  20:	ldr	x19, [sp, #96]
  24:	ldr	x24, [sp, #104]
  28:	str	q1, [sp, #96]
  2c:	ldr	x20, [sp, #96]
  30:	ldr	x23, [sp, #104]
  34:	str	q2, [sp, #96]
  38:	ldr	x21, [sp, #96]
  3c:	ldr	x26, [sp, #104]
  40:	str	q3, [sp, #96]
  44:	ldr	x22, [sp, #96]
  48:	ldr	x25, [sp, #104]
  4c:	str	x21, [sp, #96]
  50:	str	x26, [sp, #104]
  54:	ldr	q1, [sp, #96]
  58:	str	x19, [sp, #96]
  5c:	str	x24, [sp, #104]
  60:	ldr	q0, [sp, #96]
  64:	bl	0 <__multf3>
  68:	str	q0, [sp, #96]
  6c:	ldr	x1, [sp, #96]
  70:	ldr	x0, [sp, #104]
  74:	str	x1, [sp, #128]
  78:	str	x0, [sp, #144]
  7c:	str	x22, [sp, #96]
  80:	str	x25, [sp, #104]
  84:	ldr	q1, [sp, #96]
  88:	str	x20, [sp, #96]
  8c:	str	x23, [sp, #104]
  90:	ldr	q0, [sp, #96]
  94:	bl	0 <__multf3>
  98:	str	q0, [sp, #96]
  9c:	ldr	x1, [sp, #96]
  a0:	ldr	x0, [sp, #104]
  a4:	mov	x27, x1
  a8:	str	x1, [sp, #208]
  ac:	mov	x28, x0
  b0:	str	x0, [sp, #216]
  b4:	str	x22, [sp, #96]
  b8:	str	x25, [sp, #104]
  bc:	ldr	q1, [sp, #96]
  c0:	str	x19, [sp, #96]
  c4:	str	x24, [sp, #104]
  c8:	ldr	q0, [sp, #96]
  cc:	bl	0 <__multf3>
  d0:	str	q0, [sp, #96]
  d4:	ldr	x1, [sp, #96]
  d8:	ldr	x0, [sp, #104]
  dc:	str	x1, [sp, #160]
  e0:	str	x0, [sp, #168]
  e4:	str	x20, [sp, #96]
  e8:	str	x23, [sp, #104]
  ec:	ldr	q1, [sp, #96]
  f0:	str	x21, [sp, #96]
  f4:	str	x26, [sp, #104]
  f8:	ldr	q0, [sp, #96]
  fc:	bl	0 <__multf3>
 100:	str	q0, [sp, #96]
 104:	ldr	x1, [sp, #96]
 108:	ldr	x0, [sp, #104]
 10c:	str	x1, [sp, #176]
 110:	str	x0, [sp, #184]
 114:	str	x27, [sp, #96]
 118:	str	x28, [sp, #104]
 11c:	ldr	q1, [sp, #96]
 120:	ldr	x2, [sp, #128]
 124:	str	x2, [sp, #96]
 128:	ldr	x2, [sp, #144]
 12c:	str	x2, [sp, #104]
 130:	ldr	q0, [sp, #96]
 134:	bl	0 <__subtf3>
 138:	str	q0, [sp, #112]
 13c:	ldr	x2, [sp, #176]
 140:	str	x2, [sp, #96]
 144:	ldr	x2, [sp, #184]
 148:	str	x2, [sp, #104]
 14c:	ldr	q1, [sp, #96]
 150:	ldr	x1, [sp, #160]
 154:	str	x1, [sp, #96]
 158:	ldr	x0, [sp, #168]
 15c:	str	x0, [sp, #104]
 160:	ldr	q0, [sp, #96]
 164:	bl	0 <__addtf3>
 168:	str	q0, [sp, #96]
 16c:	ldr	q1, [sp, #112]
 170:	mov	v0.16b, v1.16b
 174:	bl	0 <__unordtf2>
 178:	cmp	w0, #0x0
 17c:	cset	w27, ne  // ne = any
 180:	ldr	q0, [sp, #96]
 184:	mov	v1.16b, v0.16b
 188:	bl	0 <__unordtf2>
 18c:	cmp	w0, #0x0
 190:	cset	w0, ne  // ne = any
 194:	ands	w27, w0, w27
 198:	b.eq	4f8 <__multc3+0x4f8>  // b.none
 19c:	str	x19, [sp, #224]
 1a0:	and	x28, x24, #0x7fffffffffffffff
 1a4:	adrp	x0, 0 <__multc3>
 1a8:	add	x0, x0, #0x0
 1ac:	ldr	q1, [x0]
 1b0:	str	x19, [sp, #192]
 1b4:	str	x28, [sp, #200]
 1b8:	ldr	q0, [sp, #192]
 1bc:	bl	0 <__unordtf2>
 1c0:	cbnz	w0, 51c <__multc3+0x51c>
 1c4:	adrp	x0, 0 <__multc3>
 1c8:	add	x0, x0, #0x0
 1cc:	ldr	q1, [x0]
 1d0:	str	x19, [sp, #192]
 1d4:	str	x28, [sp, #200]
 1d8:	ldr	q0, [sp, #192]
 1dc:	bl	0 <__letf2>
 1e0:	cmp	w0, #0x0
 1e4:	b.le	51c <__multc3+0x51c>
 1e8:	mov	w19, #0x1                   	// #1
 1ec:	adrp	x0, 0 <__multc3>
 1f0:	add	x0, x0, #0x0
 1f4:	ldr	q1, [x0]
 1f8:	ldr	x0, [sp, #224]
 1fc:	str	x0, [sp, #192]
 200:	str	x28, [sp, #200]
 204:	ldr	q0, [sp, #192]
 208:	bl	0 <__unordtf2>
 20c:	cbnz	w0, 238 <__multc3+0x238>
 210:	adrp	x1, 0 <__multc3>
 214:	add	x1, x1, #0x0
 218:	ldr	q1, [x1]
 21c:	ldr	x0, [sp, #224]
 220:	str	x0, [sp, #192]
 224:	str	x28, [sp, #200]
 228:	ldr	q0, [sp, #192]
 22c:	bl	0 <__letf2>
 230:	cmp	w0, #0x0
 234:	csel	w19, w19, wzr, le
 238:	eor	w0, w19, #0x1
 23c:	and	w0, w0, #0x1
 240:	bl	0 <__floatsitf>
 244:	str	q0, [sp, #192]
 248:	ldr	x19, [sp, #192]
 24c:	ldr	x0, [sp, #200]
 250:	bfxil	x24, x0, #0, #63
 254:	and	x1, x23, #0x7fffffffffffffff
 258:	mov	w28, #0x1                   	// #1
 25c:	adrp	x0, 0 <__multc3>
 260:	add	x0, x0, #0x0
 264:	ldr	q1, [x0]
 268:	str	x20, [sp, #192]
 26c:	str	x1, [sp, #224]
 270:	str	x1, [sp, #200]
 274:	ldr	q0, [sp, #192]
 278:	bl	0 <__unordtf2>
 27c:	cbnz	w0, 2a8 <__multc3+0x2a8>
 280:	adrp	x0, 0 <__multc3>
 284:	add	x0, x0, #0x0
 288:	ldr	q1, [x0]
 28c:	str	x20, [sp, #192]
 290:	ldr	x1, [sp, #224]
 294:	str	x1, [sp, #200]
 298:	ldr	q0, [sp, #192]
 29c:	bl	0 <__letf2>
 2a0:	cmp	w0, #0x0
 2a4:	csel	w28, w28, wzr, le
 2a8:	eor	w0, w28, #0x1
 2ac:	and	w0, w0, #0x1
 2b0:	bl	0 <__floatsitf>
 2b4:	str	q0, [sp, #192]
 2b8:	ldr	x20, [sp, #192]
 2bc:	ldr	x0, [sp, #200]
 2c0:	bfxil	x23, x0, #0, #63
 2c4:	str	x21, [sp, #192]
 2c8:	str	x26, [sp, #200]
 2cc:	ldr	q1, [sp, #192]
 2d0:	ldr	q0, [sp, #192]
 2d4:	bl	0 <__unordtf2>
 2d8:	cbnz	w0, 574 <__multc3+0x574>
 2dc:	str	x22, [sp, #192]
 2e0:	str	x25, [sp, #200]
 2e4:	ldr	q1, [sp, #192]
 2e8:	ldr	q0, [sp, #192]
 2ec:	bl	0 <__unordtf2>
 2f0:	cbnz	w0, 58c <__multc3+0x58c>
 2f4:	str	x21, [sp, #224]
 2f8:	and	x28, x26, #0x7fffffffffffffff
 2fc:	adrp	x0, 0 <__multc3>
 300:	add	x0, x0, #0x0
 304:	ldr	q1, [x0]
 308:	str	x21, [sp, #192]
 30c:	str	x28, [sp, #200]
 310:	ldr	q0, [sp, #192]
 314:	bl	0 <__unordtf2>
 318:	cbnz	w0, 5a4 <__multc3+0x5a4>
 31c:	adrp	x0, 0 <__multc3>
 320:	add	x0, x0, #0x0
 324:	ldr	q1, [x0]
 328:	str	x21, [sp, #192]
 32c:	str	x28, [sp, #200]
 330:	ldr	q0, [sp, #192]
 334:	bl	0 <__letf2>
 338:	cmp	w0, #0x0
 33c:	b.le	5a4 <__multc3+0x5a4>
 340:	str	x19, [sp, #96]
 344:	str	x24, [sp, #104]
 348:	ldr	q1, [sp, #96]
 34c:	ldr	q0, [sp, #96]
 350:	bl	0 <__unordtf2>
 354:	cbnz	w0, 6c0 <__multc3+0x6c0>
 358:	str	x20, [sp, #96]
 35c:	str	x23, [sp, #104]
 360:	ldr	q1, [sp, #96]
 364:	ldr	q0, [sp, #96]
 368:	bl	0 <__unordtf2>
 36c:	cbnz	w0, 6d8 <__multc3+0x6d8>
 370:	mov	w21, #0x1                   	// #1
 374:	adrp	x0, 0 <__multc3>
 378:	add	x0, x0, #0x0
 37c:	ldr	q1, [x0]
 380:	ldr	x27, [sp, #224]
 384:	str	x27, [sp, #96]
 388:	str	x28, [sp, #104]
 38c:	ldr	q0, [sp, #96]
 390:	bl	0 <__unordtf2>
 394:	cbnz	w0, 3bc <__multc3+0x3bc>
 398:	adrp	x0, 0 <__multc3>
 39c:	add	x0, x0, #0x0
 3a0:	ldr	q1, [x0]
 3a4:	str	x27, [sp, #96]
 3a8:	str	x28, [sp, #104]
 3ac:	ldr	q0, [sp, #96]
 3b0:	bl	0 <__letf2>
 3b4:	cmp	w0, #0x0
 3b8:	csel	w21, w21, wzr, le
 3bc:	eor	w0, w21, #0x1
 3c0:	and	w0, w0, #0x1
 3c4:	bl	0 <__floatsitf>
 3c8:	str	q0, [sp, #96]
 3cc:	ldr	x21, [sp, #96]
 3d0:	ldr	x0, [sp, #104]
 3d4:	bfxil	x26, x0, #0, #63
 3d8:	and	x28, x25, #0x7fffffffffffffff
 3dc:	mov	w27, #0x1                   	// #1
 3e0:	adrp	x0, 0 <__multc3>
 3e4:	add	x0, x0, #0x0
 3e8:	ldr	q1, [x0]
 3ec:	str	x22, [sp, #96]
 3f0:	str	x28, [sp, #104]
 3f4:	ldr	q0, [sp, #96]
 3f8:	bl	0 <__unordtf2>
 3fc:	cbnz	w0, 424 <__multc3+0x424>
 400:	adrp	x0, 0 <__multc3>
 404:	add	x0, x0, #0x0
 408:	ldr	q1, [x0]
 40c:	str	x22, [sp, #96]
 410:	str	x28, [sp, #104]
 414:	ldr	q0, [sp, #96]
 418:	bl	0 <__letf2>
 41c:	cmp	w0, #0x0
 420:	csel	w27, w27, wzr, le
 424:	eor	w0, w27, #0x1
 428:	and	w0, w0, #0x1
 42c:	bl	0 <__floatsitf>
 430:	str	q0, [sp, #96]
 434:	ldr	x22, [sp, #96]
 438:	ldr	x0, [sp, #104]
 43c:	bfxil	x25, x0, #0, #63
 440:	str	x21, [sp, #96]
 444:	str	x26, [sp, #104]
 448:	ldr	q1, [sp, #96]
 44c:	str	x19, [sp, #96]
 450:	str	x24, [sp, #104]
 454:	ldr	q0, [sp, #96]
 458:	bl	0 <__multf3>
 45c:	str	q0, [sp, #112]
 460:	str	x22, [sp, #96]
 464:	str	x25, [sp, #104]
 468:	ldr	q1, [sp, #96]
 46c:	str	x20, [sp, #96]
 470:	str	x23, [sp, #104]
 474:	ldr	q0, [sp, #96]
 478:	bl	0 <__multf3>
 47c:	mov	v1.16b, v0.16b
 480:	ldr	q0, [sp, #112]
 484:	bl	0 <__subtf3>
 488:	adrp	x0, 0 <__multc3>
 48c:	add	x0, x0, #0x0
 490:	ldr	q1, [x0]
 494:	bl	0 <__multf3>
 498:	str	q0, [sp, #112]
 49c:	str	x22, [sp, #96]
 4a0:	str	x25, [sp, #104]
 4a4:	ldr	q1, [sp, #96]
 4a8:	str	x19, [sp, #96]
 4ac:	str	x24, [sp, #104]
 4b0:	ldr	q0, [sp, #96]
 4b4:	bl	0 <__multf3>
 4b8:	str	q0, [sp, #128]
 4bc:	str	x21, [sp, #96]
 4c0:	str	x26, [sp, #104]
 4c4:	ldr	q1, [sp, #96]
 4c8:	str	x20, [sp, #96]
 4cc:	str	x23, [sp, #104]
 4d0:	ldr	q0, [sp, #96]
 4d4:	bl	0 <__multf3>
 4d8:	mov	v1.16b, v0.16b
 4dc:	ldr	q0, [sp, #128]
 4e0:	bl	0 <__addtf3>
 4e4:	adrp	x0, 0 <__multc3>
 4e8:	add	x0, x0, #0x0
 4ec:	ldr	q1, [x0]
 4f0:	bl	0 <__multf3>
 4f4:	str	q0, [sp, #96]
 4f8:	ldr	q0, [sp, #112]
 4fc:	ldr	q1, [sp, #96]
 500:	ldp	x19, x20, [sp, #16]
 504:	ldp	x21, x22, [sp, #32]
 508:	ldp	x23, x24, [sp, #48]
 50c:	ldp	x25, x26, [sp, #64]
 510:	ldp	x27, x28, [sp, #80]
 514:	ldp	x29, x30, [sp], #240
 518:	ret
 51c:	and	x1, x23, #0x7fffffffffffffff
 520:	adrp	x0, 0 <__multc3>
 524:	add	x0, x0, #0x0
 528:	ldr	q1, [x0]
 52c:	str	x20, [sp, #192]
 530:	str	x1, [sp, #232]
 534:	str	x1, [sp, #200]
 538:	ldr	q0, [sp, #192]
 53c:	bl	0 <__unordtf2>
 540:	cbnz	w0, 56c <__multc3+0x56c>
 544:	adrp	x0, 0 <__multc3>
 548:	add	x0, x0, #0x0
 54c:	ldr	q1, [x0]
 550:	str	x20, [sp, #192]
 554:	ldr	x1, [sp, #232]
 558:	str	x1, [sp, #200]
 55c:	ldr	q0, [sp, #192]
 560:	bl	0 <__letf2>
 564:	cmp	w0, #0x0
 568:	b.gt	1e8 <__multc3+0x1e8>
 56c:	mov	w27, #0x0                   	// #0
 570:	b	2f4 <__multc3+0x2f4>
 574:	mov	x21, #0x0                   	// #0
 578:	mov	x0, #0x0                   	// #0
 57c:	tbz	x26, #63, 584 <__multc3+0x584>
 580:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 584:	mov	x26, x0
 588:	b	2dc <__multc3+0x2dc>
 58c:	mov	x22, #0x0                   	// #0
 590:	mov	x0, #0x0                   	// #0
 594:	tbz	x25, #63, 59c <__multc3+0x59c>
 598:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 59c:	mov	x25, x0
 5a0:	b	2f4 <__multc3+0x2f4>
 5a4:	and	x1, x25, #0x7fffffffffffffff
 5a8:	adrp	x0, 0 <__multc3>
 5ac:	add	x0, x0, #0x0
 5b0:	ldr	q1, [x0]
 5b4:	str	x22, [sp, #192]
 5b8:	str	x1, [sp, #232]
 5bc:	str	x1, [sp, #200]
 5c0:	ldr	q0, [sp, #192]
 5c4:	bl	0 <__unordtf2>
 5c8:	cbnz	w0, 5f4 <__multc3+0x5f4>
 5cc:	adrp	x0, 0 <__multc3>
 5d0:	add	x0, x0, #0x0
 5d4:	ldr	q1, [x0]
 5d8:	str	x22, [sp, #192]
 5dc:	ldr	x1, [sp, #232]
 5e0:	str	x1, [sp, #200]
 5e4:	ldr	q0, [sp, #192]
 5e8:	bl	0 <__letf2>
 5ec:	cmp	w0, #0x0
 5f0:	b.gt	340 <__multc3+0x340>
 5f4:	cbnz	w27, 440 <__multc3+0x440>
 5f8:	ldr	x0, [sp, #144]
 5fc:	and	x27, x0, #0x7fffffffffffffff
 600:	adrp	x0, 0 <__multc3>
 604:	add	x0, x0, #0x0
 608:	ldr	q1, [x0]
 60c:	ldr	x28, [sp, #128]
 610:	str	x28, [sp, #144]
 614:	str	x27, [sp, #152]
 618:	ldr	q0, [sp, #144]
 61c:	bl	0 <__unordtf2>
 620:	cbnz	w0, 6f0 <__multc3+0x6f0>
 624:	adrp	x0, 0 <__multc3>
 628:	add	x0, x0, #0x0
 62c:	ldr	q1, [x0]
 630:	str	x28, [sp, #128]
 634:	str	x27, [sp, #136]
 638:	ldr	q0, [sp, #128]
 63c:	bl	0 <__letf2>
 640:	cmp	w0, #0x0
 644:	b.le	6f0 <__multc3+0x6f0>
 648:	str	x19, [sp, #96]
 64c:	str	x24, [sp, #104]
 650:	ldr	q1, [sp, #96]
 654:	ldr	q0, [sp, #96]
 658:	bl	0 <__unordtf2>
 65c:	cbnz	w0, 7e4 <__multc3+0x7e4>
 660:	str	x20, [sp, #96]
 664:	str	x23, [sp, #104]
 668:	ldr	q1, [sp, #96]
 66c:	ldr	q0, [sp, #96]
 670:	bl	0 <__unordtf2>
 674:	cbnz	w0, 7fc <__multc3+0x7fc>
 678:	str	x21, [sp, #96]
 67c:	str	x26, [sp, #104]
 680:	ldr	q1, [sp, #96]
 684:	ldr	q0, [sp, #96]
 688:	bl	0 <__unordtf2>
 68c:	cbnz	w0, 814 <__multc3+0x814>
 690:	str	x22, [sp, #96]
 694:	str	x25, [sp, #104]
 698:	ldr	q1, [sp, #96]
 69c:	ldr	q0, [sp, #96]
 6a0:	bl	0 <__unordtf2>
 6a4:	cbz	w0, 440 <__multc3+0x440>
 6a8:	mov	x22, #0x0                   	// #0
 6ac:	mov	x0, #0x0                   	// #0
 6b0:	tbz	x25, #63, 6b8 <__multc3+0x6b8>
 6b4:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 6b8:	mov	x25, x0
 6bc:	b	440 <__multc3+0x440>
 6c0:	mov	x19, #0x0                   	// #0
 6c4:	mov	x0, #0x0                   	// #0
 6c8:	tbz	x24, #63, 6d0 <__multc3+0x6d0>
 6cc:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 6d0:	mov	x24, x0
 6d4:	b	358 <__multc3+0x358>
 6d8:	mov	x20, #0x0                   	// #0
 6dc:	mov	x0, #0x0                   	// #0
 6e0:	tbz	x23, #63, 6e8 <__multc3+0x6e8>
 6e4:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 6e8:	mov	x23, x0
 6ec:	b	370 <__multc3+0x370>
 6f0:	ldr	x0, [sp, #216]
 6f4:	and	x27, x0, #0x7fffffffffffffff
 6f8:	adrp	x0, 0 <__multc3>
 6fc:	add	x0, x0, #0x0
 700:	ldr	q1, [x0]
 704:	ldr	x28, [sp, #208]
 708:	str	x28, [sp, #128]
 70c:	str	x27, [sp, #136]
 710:	ldr	q0, [sp, #128]
 714:	bl	0 <__unordtf2>
 718:	cbnz	w0, 740 <__multc3+0x740>
 71c:	adrp	x0, 0 <__multc3>
 720:	add	x0, x0, #0x0
 724:	ldr	q1, [x0]
 728:	str	x28, [sp, #128]
 72c:	str	x27, [sp, #136]
 730:	ldr	q0, [sp, #128]
 734:	bl	0 <__letf2>
 738:	cmp	w0, #0x0
 73c:	b.gt	648 <__multc3+0x648>
 740:	ldr	x0, [sp, #168]
 744:	and	x27, x0, #0x7fffffffffffffff
 748:	adrp	x0, 0 <__multc3>
 74c:	add	x0, x0, #0x0
 750:	ldr	q1, [x0]
 754:	ldr	x28, [sp, #160]
 758:	str	x28, [sp, #128]
 75c:	str	x27, [sp, #136]
 760:	ldr	q0, [sp, #128]
 764:	bl	0 <__unordtf2>
 768:	cbnz	w0, 790 <__multc3+0x790>
 76c:	adrp	x0, 0 <__multc3>
 770:	add	x0, x0, #0x0
 774:	ldr	q1, [x0]
 778:	str	x28, [sp, #128]
 77c:	str	x27, [sp, #136]
 780:	ldr	q0, [sp, #128]
 784:	bl	0 <__letf2>
 788:	cmp	w0, #0x0
 78c:	b.gt	648 <__multc3+0x648>
 790:	ldr	x0, [sp, #184]
 794:	and	x27, x0, #0x7fffffffffffffff
 798:	adrp	x0, 0 <__multc3>
 79c:	add	x0, x0, #0x0
 7a0:	ldr	q1, [x0]
 7a4:	ldr	x28, [sp, #176]
 7a8:	str	x28, [sp, #128]
 7ac:	str	x27, [sp, #136]
 7b0:	ldr	q0, [sp, #128]
 7b4:	bl	0 <__unordtf2>
 7b8:	cbnz	w0, 4f8 <__multc3+0x4f8>
 7bc:	adrp	x0, 0 <__multc3>
 7c0:	add	x0, x0, #0x0
 7c4:	ldr	q1, [x0]
 7c8:	str	x28, [sp, #128]
 7cc:	str	x27, [sp, #136]
 7d0:	ldr	q0, [sp, #128]
 7d4:	bl	0 <__letf2>
 7d8:	cmp	w0, #0x0
 7dc:	b.gt	648 <__multc3+0x648>
 7e0:	b	4f8 <__multc3+0x4f8>
 7e4:	mov	x19, #0x0                   	// #0
 7e8:	mov	x0, #0x0                   	// #0
 7ec:	tbz	x24, #63, 7f4 <__multc3+0x7f4>
 7f0:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 7f4:	mov	x24, x0
 7f8:	b	660 <__multc3+0x660>
 7fc:	mov	x20, #0x0                   	// #0
 800:	mov	x0, #0x0                   	// #0
 804:	tbz	x23, #63, 80c <__multc3+0x80c>
 808:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 80c:	mov	x23, x0
 810:	b	678 <__multc3+0x678>
 814:	mov	x21, #0x0                   	// #0
 818:	mov	x0, #0x0                   	// #0
 81c:	tbz	x26, #63, 824 <__multc3+0x824>
 820:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
 824:	mov	x26, x0
 828:	b	690 <__multc3+0x690>

_divhc3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divhc3>:
   0:	mov	v7.h[0], v0.h[0]
   4:	mov	v16.h[0], v1.h[0]
   8:	fcvt	s17, h2
   c:	fabs	s17, s17
  10:	fcvt	h17, s17
  14:	fcvt	s18, h3
  18:	fabs	s18, s18
  1c:	fcvt	h18, s18
  20:	fcvt	s1, h17
  24:	fcvt	s0, h18
  28:	fcmpe	s1, s0
  2c:	b.pl	104 <__divhc3+0x104>  // b.nfrst
  30:	fcvt	s5, h2
  34:	fcvt	s0, h3
  38:	fdiv	s4, s5, s0
  3c:	fcvt	h4, s4
  40:	fcvt	s4, h4
  44:	fcvt	s1, h7
  48:	fcvt	s6, h16
  4c:	fmul	s5, s5, s4
  50:	fadd	s5, s5, s0
  54:	fcvt	h5, s5
  58:	fcvt	s5, h5
  5c:	fmul	s0, s4, s1
  60:	fadd	s0, s0, s6
  64:	fdiv	s0, s0, s5
  68:	fcvt	h0, s0
  6c:	fmul	s4, s4, s6
  70:	fsub	s4, s4, s1
  74:	fdiv	s4, s4, s5
  78:	fcvt	h1, s4
  7c:	fcvt	s4, h0
  80:	fcmp	s4, s4
  84:	cset	w1, vs
  88:	fcvt	s4, h1
  8c:	fcmp	s4, s4
  90:	cset	w0, vs
  94:	tst	w1, w0
  98:	b.eq	250 <__divhc3+0x250>  // b.none
  9c:	fcvt	s6, h2
  a0:	fcmp	s6, #0.0
  a4:	b.ne	154 <__divhc3+0x154>  // b.any
  a8:	fcvt	s4, h3
  ac:	fcmp	s4, #0.0
  b0:	b.ne	154 <__divhc3+0x154>  // b.any
  b4:	fcvt	s4, h7
  b8:	fcmp	s4, s4
  bc:	cset	w0, vc
  c0:	fcvt	s4, h16
  c4:	fcmp	s4, s4
  c8:	cset	w1, vc
  cc:	orr	w0, w0, w1
  d0:	cbz	w0, 154 <__divhc3+0x154>
  d4:	umov	w0, v2.h[0]
  d8:	movi	v1.4h, #0x7c, lsl #8
  dc:	tbz	w0, #15, e4 <__divhc3+0xe4>
  e0:	movi	v1.4h, #0xfc, lsl #8
  e4:	fcvt	s1, h1
  e8:	fcvt	s0, h7
  ec:	fmul	s0, s0, s1
  f0:	fcvt	h0, s0
  f4:	fcvt	s16, h16
  f8:	fmul	s1, s16, s1
  fc:	fcvt	h1, s1
 100:	b	250 <__divhc3+0x250>
 104:	fcvt	s5, h3
 108:	fcvt	s0, h2
 10c:	fdiv	s6, s5, s0
 110:	fcvt	h6, s6
 114:	fcvt	s6, h6
 118:	fcvt	s1, h16
 11c:	fcvt	s19, h7
 120:	fmul	s4, s5, s6
 124:	fadd	s4, s4, s0
 128:	fcvt	h4, s4
 12c:	fcvt	s4, h4
 130:	fmul	s0, s6, s1
 134:	fadd	s0, s0, s19
 138:	fdiv	s0, s0, s4
 13c:	fcvt	h0, s0
 140:	fmul	s6, s6, s19
 144:	fsub	s6, s1, s6
 148:	fdiv	s4, s6, s4
 14c:	fcvt	h1, s4
 150:	b	7c <__divhc3+0x7c>
 154:	fcvt	s4, h7
 158:	fabs	s4, s4
 15c:	fcvt	h4, s4
 160:	fcvt	s19, h4
 164:	mov	w0, #0xe000                	// #57344
 168:	movk	w0, #0x477f, lsl #16
 16c:	fmov	s5, w0
 170:	fcmp	s19, s5
 174:	b.gt	194 <__divhc3+0x194>
 178:	fcvt	s5, h16
 17c:	fabs	s5, s5
 180:	fcvt	h5, s5
 184:	fcvt	s5, h5
 188:	fmov	s19, w0
 18c:	fcmp	s5, s19
 190:	b.le	254 <__divhc3+0x254>
 194:	fcvt	s5, h17
 198:	mov	w0, #0xe000                	// #57344
 19c:	movk	w0, #0x477f, lsl #16
 1a0:	fmov	s19, w0
 1a4:	fcmp	s5, s19
 1a8:	b.hi	254 <__divhc3+0x254>  // b.pmore
 1ac:	fcvt	s5, h18
 1b0:	fcmp	s5, s19
 1b4:	b.hi	254 <__divhc3+0x254>  // b.pmore
 1b8:	fcvt	s4, h4
 1bc:	adrp	x0, 0 <__divhc3>
 1c0:	ldr	s1, [x0]
 1c4:	fcmp	s4, s1
 1c8:	cset	w0, gt
 1cc:	scvtf	d0, w0
 1d0:	umov	w0, v7.h[0]
 1d4:	fcvt	h0, d0
 1d8:	umov	w1, v0.h[0]
 1dc:	bfxil	w0, w1, #0, #15
 1e0:	dup	v2.4h, w0
 1e4:	fcvt	s0, h16
 1e8:	fabs	s0, s0
 1ec:	fcvt	h0, s0
 1f0:	fcvt	s0, h0
 1f4:	fcmp	s0, s1
 1f8:	cset	w0, gt
 1fc:	scvtf	d0, w0
 200:	umov	w0, v16.h[0]
 204:	fcvt	h0, d0
 208:	umov	w1, v0.h[0]
 20c:	bfxil	w0, w1, #0, #15
 210:	dup	v1.4h, w0
 214:	fcvt	s2, h2
 218:	fcvt	s1, h1
 21c:	fcvt	s3, h3
 220:	fmul	s0, s6, s2
 224:	fmul	s4, s1, s3
 228:	fadd	s0, s0, s4
 22c:	adrp	x0, 0 <__divhc3>
 230:	ldr	s4, [x0]
 234:	fmul	s0, s0, s4
 238:	fcvt	h0, s0
 23c:	fmul	s6, s6, s1
 240:	fmul	s1, s2, s3
 244:	fsub	s1, s6, s1
 248:	fmul	s1, s1, s4
 24c:	fcvt	h1, s1
 250:	ret
 254:	fcvt	s17, h17
 258:	adrp	x0, 0 <__divhc3>
 25c:	ldr	s5, [x0]
 260:	fcmp	s17, s5
 264:	cset	w0, le
 268:	fcvt	s18, h18
 26c:	fcmp	s18, s5
 270:	cset	w1, le
 274:	cmp	w0, #0x0
 278:	ccmp	w1, #0x0, #0x4, ne  // ne = any
 27c:	b.ne	250 <__divhc3+0x250>  // b.any
 280:	fcvt	s4, h4
 284:	mov	w2, #0xe000                	// #57344
 288:	movk	w2, #0x477f, lsl #16
 28c:	fmov	s5, w2
 290:	fcmp	s4, s5
 294:	b.hi	250 <__divhc3+0x250>  // b.pmore
 298:	fcvt	s4, h16
 29c:	fabs	s4, s4
 2a0:	fcvt	h4, s4
 2a4:	fcvt	s4, h4
 2a8:	fcmp	s4, s5
 2ac:	b.hi	250 <__divhc3+0x250>  // b.pmore
 2b0:	eor	w0, w0, #0x1
 2b4:	scvtf	d0, w0
 2b8:	umov	w0, v2.h[0]
 2bc:	fcvt	h0, d0
 2c0:	umov	w2, v0.h[0]
 2c4:	bfxil	w0, w2, #0, #15
 2c8:	dup	v4.4h, w0
 2cc:	eor	w1, w1, #0x1
 2d0:	scvtf	d0, w1
 2d4:	umov	w0, v3.h[0]
 2d8:	fcvt	h0, d0
 2dc:	umov	w1, v0.h[0]
 2e0:	bfxil	w0, w1, #0, #15
 2e4:	dup	v3.4h, w0
 2e8:	fcvt	s7, h7
 2ec:	fcvt	s2, h4
 2f0:	fcvt	s1, h16
 2f4:	fcvt	s3, h3
 2f8:	fmul	s0, s7, s2
 2fc:	fmul	s4, s1, s3
 300:	fadd	s0, s0, s4
 304:	fcvt	d0, s0
 308:	movi	d4, #0x0
 30c:	fmul	d0, d0, d4
 310:	fcvt	h0, d0
 314:	fmul	s2, s2, s1
 318:	fmul	s1, s7, s3
 31c:	fsub	s1, s2, s1
 320:	fcvt	d1, s1
 324:	fmul	d1, d1, d4
 328:	fcvt	h1, d1
 32c:	b	250 <__divhc3+0x250>

_divsc3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divsc3>:
   0:	fmov	s18, s0
   4:	fmov	s17, s1
   8:	fabs	s5, s2
   c:	fabs	s7, s3
  10:	fcmpe	s5, s7
  14:	b.pl	80 <__divsc3+0x80>  // b.nfrst
  18:	fdiv	s4, s2, s3
  1c:	fmul	s6, s2, s4
  20:	fadd	s6, s6, s3
  24:	fmul	s16, s0, s4
  28:	fadd	s16, s16, s1
  2c:	fdiv	s0, s16, s6
  30:	fmul	s4, s1, s4
  34:	fsub	s4, s4, s18
  38:	fdiv	s1, s4, s6
  3c:	fcmp	s0, s0
  40:	fccmp	s1, s1, #0x0, vs
  44:	b.vc	7c <__divsc3+0x7c>
  48:	fcmp	s2, #0.0
  4c:	movi	v4.2s, #0x0
  50:	fccmp	s3, s4, #0x0, eq  // eq = none
  54:	b.ne	a8 <__divsc3+0xa8>  // b.any
  58:	fcmp	s18, s18
  5c:	fccmp	s17, s17, #0x0, vs
  60:	b.vs	a8 <__divsc3+0xa8>
  64:	mov	w0, #0x7f800000            	// #2139095040
  68:	fmov	s3, w0
  6c:	movi	v1.2s, #0x80, lsl #24
  70:	bif	v2.8b, v3.8b, v1.8b
  74:	fmul	s0, s2, s18
  78:	fmul	s1, s2, s17
  7c:	ret
  80:	fdiv	s4, s3, s2
  84:	fmul	s6, s3, s4
  88:	fadd	s6, s6, s2
  8c:	fmul	s16, s4, s1
  90:	fadd	s16, s16, s0
  94:	fdiv	s0, s16, s6
  98:	fmul	s4, s4, s18
  9c:	fsub	s4, s1, s4
  a0:	fdiv	s1, s4, s6
  a4:	b	3c <__divsc3+0x3c>
  a8:	fabs	s4, s18
  ac:	mov	w0, #0x7f7fffff            	// #2139095039
  b0:	fmov	s6, w0
  b4:	fcmp	s4, s6
  b8:	b.gt	c8 <__divsc3+0xc8>
  bc:	fabs	s16, s17
  c0:	fcmp	s16, s6
  c4:	b.le	13c <__divsc3+0x13c>
  c8:	mov	w0, #0x7f7fffff            	// #2139095039
  cc:	fmov	s6, w0
  d0:	fcmp	s5, s6
  d4:	b.hi	13c <__divsc3+0x13c>  // b.pmore
  d8:	fcmp	s7, s6
  dc:	b.hi	13c <__divsc3+0x13c>  // b.pmore
  e0:	adrp	x0, 0 <__divsc3>
  e4:	ldr	s0, [x0]
  e8:	fcmp	s4, s0
  ec:	cset	w0, gt
  f0:	scvtf	s1, w0
  f4:	movi	v4.2s, #0x80, lsl #24
  f8:	bit	v1.8b, v18.8b, v4.8b
  fc:	fabs	s5, s17
 100:	fcmp	s5, s0
 104:	cset	w0, gt
 108:	scvtf	s0, w0
 10c:	bsl	v4.8b, v17.8b, v0.8b
 110:	fmul	s0, s2, s1
 114:	fmul	s5, s3, s4
 118:	fadd	s0, s0, s5
 11c:	adrp	x0, 0 <__divsc3>
 120:	ldr	s5, [x0]
 124:	fmul	s0, s0, s5
 128:	fmul	s4, s2, s4
 12c:	fmul	s1, s3, s1
 130:	fsub	s1, s4, s1
 134:	fmul	s1, s1, s5
 138:	b	7c <__divsc3+0x7c>
 13c:	adrp	x0, 0 <__divsc3>
 140:	ldr	s6, [x0]
 144:	fcmp	s5, s6
 148:	cset	w1, le
 14c:	fcmp	s7, s6
 150:	cset	w0, le
 154:	cmp	w1, #0x0
 158:	ccmp	w0, #0x0, #0x4, ne  // ne = any
 15c:	b.ne	7c <__divsc3+0x7c>  // b.any
 160:	mov	w2, #0x7f7fffff            	// #2139095039
 164:	fmov	s5, w2
 168:	fcmp	s4, s5
 16c:	b.hi	7c <__divsc3+0x7c>  // b.pmore
 170:	fabs	s5, s17
 174:	fmov	s4, w2
 178:	fcmp	s5, s4
 17c:	b.hi	7c <__divsc3+0x7c>  // b.pmore
 180:	eor	w1, w1, #0x1
 184:	scvtf	s4, w1
 188:	movi	v0.2s, #0x80, lsl #24
 18c:	bit	v4.8b, v2.8b, v0.8b
 190:	eor	w0, w0, #0x1
 194:	scvtf	s1, w0
 198:	bit	v1.8b, v3.8b, v0.8b
 19c:	fmul	s0, s18, s4
 1a0:	fmul	s2, s17, s1
 1a4:	fadd	s0, s0, s2
 1a8:	movi	v3.2s, #0x0
 1ac:	fmul	s0, s0, s3
 1b0:	fmul	s4, s17, s4
 1b4:	fmul	s1, s18, s1
 1b8:	fsub	s1, s4, s1
 1bc:	fmul	s1, s1, s3
 1c0:	b	7c <__divsc3+0x7c>

_divdc3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divdc3>:
   0:	fmov	d18, d0
   4:	fmov	d17, d1
   8:	fabs	d5, d2
   c:	fabs	d7, d3
  10:	fcmpe	d5, d7
  14:	b.pl	84 <__divdc3+0x84>  // b.nfrst
  18:	fdiv	d4, d2, d3
  1c:	fmul	d6, d2, d4
  20:	fadd	d6, d6, d3
  24:	fmul	d16, d0, d4
  28:	fadd	d16, d16, d1
  2c:	fdiv	d0, d16, d6
  30:	fmul	d4, d1, d4
  34:	fsub	d4, d4, d18
  38:	fdiv	d1, d4, d6
  3c:	fcmp	d0, d0
  40:	fccmp	d1, d1, #0x0, vs
  44:	b.vc	80 <__divdc3+0x80>
  48:	fcmp	d2, #0.0
  4c:	movi	d4, #0x0
  50:	fccmp	d3, d4, #0x0, eq  // eq = none
  54:	b.ne	ac <__divdc3+0xac>  // b.any
  58:	fcmp	d18, d18
  5c:	fccmp	d17, d17, #0x0, vs
  60:	b.vs	ac <__divdc3+0xac>
  64:	mov	x0, #0x7ff0000000000000    	// #9218868437227405312
  68:	fmov	d3, x0
  6c:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
  70:	fmov	d1, x0
  74:	bif	v2.8b, v3.8b, v1.8b
  78:	fmul	d0, d2, d18
  7c:	fmul	d1, d2, d17
  80:	ret
  84:	fdiv	d4, d3, d2
  88:	fmul	d6, d3, d4
  8c:	fadd	d6, d6, d2
  90:	fmul	d16, d4, d1
  94:	fadd	d16, d16, d0
  98:	fdiv	d0, d16, d6
  9c:	fmul	d4, d4, d18
  a0:	fsub	d4, d1, d4
  a4:	fdiv	d1, d4, d6
  a8:	b	3c <__divdc3+0x3c>
  ac:	fabs	d4, d18
  b0:	mov	x0, #0x7fefffffffffffff    	// #9218868437227405311
  b4:	fmov	d6, x0
  b8:	fcmp	d4, d6
  bc:	b.gt	cc <__divdc3+0xcc>
  c0:	fabs	d16, d17
  c4:	fcmp	d16, d6
  c8:	b.le	144 <__divdc3+0x144>
  cc:	mov	x0, #0x7fefffffffffffff    	// #9218868437227405311
  d0:	fmov	d6, x0
  d4:	fcmp	d5, d6
  d8:	b.hi	144 <__divdc3+0x144>  // b.pmore
  dc:	fcmp	d7, d6
  e0:	b.hi	144 <__divdc3+0x144>  // b.pmore
  e4:	adrp	x0, 0 <__divdc3>
  e8:	ldr	d0, [x0]
  ec:	fcmp	d4, d0
  f0:	cset	w0, gt
  f4:	scvtf	d1, w0
  f8:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
  fc:	fmov	d4, x0
 100:	bit	v1.8b, v18.8b, v4.8b
 104:	fabs	d5, d17
 108:	fcmp	d5, d0
 10c:	cset	w0, gt
 110:	scvtf	d0, w0
 114:	bsl	v4.8b, v17.8b, v0.8b
 118:	fmul	d0, d2, d1
 11c:	fmul	d5, d3, d4
 120:	fadd	d0, d0, d5
 124:	adrp	x0, 0 <__divdc3>
 128:	ldr	d5, [x0]
 12c:	fmul	d0, d0, d5
 130:	fmul	d4, d2, d4
 134:	fmul	d1, d3, d1
 138:	fsub	d1, d4, d1
 13c:	fmul	d1, d1, d5
 140:	b	80 <__divdc3+0x80>
 144:	adrp	x0, 0 <__divdc3>
 148:	ldr	d6, [x0]
 14c:	fcmp	d5, d6
 150:	cset	w1, le
 154:	fcmp	d7, d6
 158:	cset	w0, le
 15c:	cmp	w1, #0x0
 160:	ccmp	w0, #0x0, #0x4, ne  // ne = any
 164:	b.ne	80 <__divdc3+0x80>  // b.any
 168:	mov	x2, #0x7fefffffffffffff    	// #9218868437227405311
 16c:	fmov	d5, x2
 170:	fcmp	d4, d5
 174:	b.hi	80 <__divdc3+0x80>  // b.pmore
 178:	fabs	d5, d17
 17c:	fmov	d4, x2
 180:	fcmp	d5, d4
 184:	b.hi	80 <__divdc3+0x80>  // b.pmore
 188:	eor	w1, w1, #0x1
 18c:	scvtf	d4, w1
 190:	mov	x1, #0x8000000000000000    	// #-9223372036854775808
 194:	fmov	d0, x1
 198:	bit	v4.8b, v2.8b, v0.8b
 19c:	eor	w0, w0, #0x1
 1a0:	scvtf	d1, w0
 1a4:	bit	v1.8b, v3.8b, v0.8b
 1a8:	fmul	d0, d18, d4
 1ac:	fmul	d2, d17, d1
 1b0:	fadd	d0, d0, d2
 1b4:	movi	d3, #0x0
 1b8:	fmul	d0, d0, d3
 1bc:	fmul	d4, d17, d4
 1c0:	fmul	d1, d18, d1
 1c4:	fsub	d1, d4, d1
 1c8:	fmul	d1, d1, d3
 1cc:	b	80 <__divdc3+0x80>

_divxc3.o:     file format elf64-littleaarch64


_divtc3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divtc3>:
   0:	stp	x29, x30, [sp, #-176]!
   4:	mov	x29, sp
   8:	stp	x19, x20, [sp, #16]
   c:	stp	x21, x22, [sp, #32]
  10:	stp	x23, x24, [sp, #48]
  14:	stp	x25, x26, [sp, #64]
  18:	stp	x27, x28, [sp, #80]
  1c:	str	q0, [sp, #96]
  20:	ldr	x21, [sp, #96]
  24:	ldr	x24, [sp, #104]
  28:	str	q1, [sp, #96]
  2c:	ldr	x0, [sp, #96]
  30:	ldr	x25, [sp, #104]
  34:	mov	x28, x0
  38:	str	x0, [sp, #128]
  3c:	str	q2, [sp, #96]
  40:	ldr	x19, [sp, #96]
  44:	ldr	x22, [sp, #104]
  48:	str	q3, [sp, #96]
  4c:	ldr	x20, [sp, #96]
  50:	ldr	x23, [sp, #104]
  54:	and	x26, x22, #0x7fffffffffffffff
  58:	and	x27, x23, #0x7fffffffffffffff
  5c:	str	x27, [sp, #104]
  60:	ldr	q1, [sp, #96]
  64:	str	x19, [sp, #96]
  68:	str	x26, [sp, #104]
  6c:	ldr	q0, [sp, #96]
  70:	bl	0 <__lttf2>
  74:	tbz	w0, #31, 254 <__divtc3+0x254>
  78:	str	x20, [sp, #96]
  7c:	str	x23, [sp, #104]
  80:	ldr	q1, [sp, #96]
  84:	str	x19, [sp, #96]
  88:	str	x22, [sp, #104]
  8c:	ldr	q0, [sp, #96]
  90:	bl	0 <__divtf3>
  94:	str	q0, [sp, #112]
  98:	mov	v1.16b, v0.16b
  9c:	str	x19, [sp, #96]
  a0:	str	x22, [sp, #104]
  a4:	ldr	q0, [sp, #96]
  a8:	bl	0 <__multf3>
  ac:	str	x20, [sp, #96]
  b0:	str	x23, [sp, #104]
  b4:	ldr	q1, [sp, #96]
  b8:	bl	0 <__addtf3>
  bc:	str	q0, [sp, #144]
  c0:	ldr	q1, [sp, #112]
  c4:	str	x21, [sp, #96]
  c8:	str	x24, [sp, #104]
  cc:	ldr	q0, [sp, #96]
  d0:	bl	0 <__multf3>
  d4:	str	x28, [sp, #96]
  d8:	str	x25, [sp, #104]
  dc:	ldr	q1, [sp, #96]
  e0:	bl	0 <__addtf3>
  e4:	ldr	q1, [sp, #144]
  e8:	bl	0 <__divtf3>
  ec:	str	q0, [sp, #96]
  f0:	ldr	q1, [sp, #112]
  f4:	str	x28, [sp, #112]
  f8:	str	x25, [sp, #120]
  fc:	ldr	q0, [sp, #112]
 100:	bl	0 <__multf3>
 104:	str	x21, [sp, #112]
 108:	str	x24, [sp, #120]
 10c:	ldr	q1, [sp, #112]
 110:	bl	0 <__subtf3>
 114:	ldr	q1, [sp, #144]
 118:	bl	0 <__divtf3>
 11c:	str	q0, [sp, #112]
 120:	ldr	q0, [sp, #96]
 124:	mov	v1.16b, v0.16b
 128:	bl	0 <__unordtf2>
 12c:	cmp	w0, #0x0
 130:	cset	w28, ne  // ne = any
 134:	ldr	q0, [sp, #112]
 138:	mov	v1.16b, v0.16b
 13c:	bl	0 <__unordtf2>
 140:	cmp	w0, #0x0
 144:	cset	w0, ne  // ne = any
 148:	tst	w0, w28
 14c:	b.eq	230 <__divtc3+0x230>  // b.none
 150:	movi	v1.2d, #0x0
 154:	str	x19, [sp, #144]
 158:	str	x22, [sp, #152]
 15c:	ldr	q0, [sp, #144]
 160:	bl	0 <__eqtf2>
 164:	cmp	w0, #0x0
 168:	cset	w28, eq  // eq = none
 16c:	movi	v1.2d, #0x0
 170:	str	x20, [sp, #144]
 174:	str	x23, [sp, #152]
 178:	ldr	q0, [sp, #144]
 17c:	bl	0 <__eqtf2>
 180:	cmp	w0, #0x0
 184:	cset	w0, eq  // eq = none
 188:	tst	w0, w28
 18c:	b.eq	308 <__divtc3+0x308>  // b.none
 190:	str	x21, [sp, #144]
 194:	str	x24, [sp, #152]
 198:	ldr	q1, [sp, #144]
 19c:	ldr	q0, [sp, #144]
 1a0:	bl	0 <__unordtf2>
 1a4:	cmp	w0, #0x0
 1a8:	cset	w28, eq  // eq = none
 1ac:	ldr	x0, [sp, #128]
 1b0:	str	x0, [sp, #144]
 1b4:	str	x25, [sp, #152]
 1b8:	ldr	q1, [sp, #144]
 1bc:	ldr	q0, [sp, #144]
 1c0:	bl	0 <__unordtf2>
 1c4:	cmp	w0, #0x0
 1c8:	cset	w0, eq  // eq = none
 1cc:	orr	w28, w28, w0
 1d0:	tst	w28, #0xff
 1d4:	b.eq	308 <__divtc3+0x308>  // b.none
 1d8:	adrp	x0, 0 <__divtc3>
 1dc:	add	x0, x0, #0x0
 1e0:	ldr	q0, [x0]
 1e4:	str	q0, [sp, #144]
 1e8:	tbz	x22, #63, 1fc <__divtc3+0x1fc>
 1ec:	adrp	x0, 0 <__divtc3>
 1f0:	add	x0, x0, #0x0
 1f4:	ldr	q0, [x0]
 1f8:	str	q0, [sp, #144]
 1fc:	str	x21, [sp, #96]
 200:	str	x24, [sp, #104]
 204:	ldr	q1, [sp, #96]
 208:	ldr	q0, [sp, #144]
 20c:	bl	0 <__multf3>
 210:	str	q0, [sp, #96]
 214:	ldr	x0, [sp, #128]
 218:	str	x0, [sp, #112]
 21c:	str	x25, [sp, #120]
 220:	ldr	q1, [sp, #112]
 224:	ldr	q0, [sp, #144]
 228:	bl	0 <__multf3>
 22c:	str	q0, [sp, #112]
 230:	ldr	q0, [sp, #96]
 234:	ldr	q1, [sp, #112]
 238:	ldp	x19, x20, [sp, #16]
 23c:	ldp	x21, x22, [sp, #32]
 240:	ldp	x23, x24, [sp, #48]
 244:	ldp	x25, x26, [sp, #64]
 248:	ldp	x27, x28, [sp, #80]
 24c:	ldp	x29, x30, [sp], #176
 250:	ret
 254:	str	x19, [sp, #96]
 258:	str	x22, [sp, #104]
 25c:	ldr	q1, [sp, #96]
 260:	str	x20, [sp, #96]
 264:	str	x23, [sp, #104]
 268:	ldr	q0, [sp, #96]
 26c:	bl	0 <__divtf3>
 270:	str	q0, [sp, #144]
 274:	mov	v1.16b, v0.16b
 278:	str	x20, [sp, #96]
 27c:	str	x23, [sp, #104]
 280:	ldr	q0, [sp, #96]
 284:	bl	0 <__multf3>
 288:	str	x19, [sp, #96]
 28c:	str	x22, [sp, #104]
 290:	ldr	q1, [sp, #96]
 294:	bl	0 <__addtf3>
 298:	str	q0, [sp, #160]
 29c:	ldr	x28, [sp, #128]
 2a0:	str	x28, [sp, #96]
 2a4:	str	x25, [sp, #104]
 2a8:	ldr	q1, [sp, #96]
 2ac:	ldr	q0, [sp, #144]
 2b0:	bl	0 <__multf3>
 2b4:	str	x21, [sp, #96]
 2b8:	str	x24, [sp, #104]
 2bc:	ldr	q1, [sp, #96]
 2c0:	bl	0 <__addtf3>
 2c4:	ldr	q1, [sp, #160]
 2c8:	bl	0 <__divtf3>
 2cc:	str	q0, [sp, #96]
 2d0:	str	x21, [sp, #112]
 2d4:	str	x24, [sp, #120]
 2d8:	ldr	q1, [sp, #112]
 2dc:	ldr	q0, [sp, #144]
 2e0:	bl	0 <__multf3>
 2e4:	mov	v1.16b, v0.16b
 2e8:	str	x28, [sp, #112]
 2ec:	str	x25, [sp, #120]
 2f0:	ldr	q0, [sp, #112]
 2f4:	bl	0 <__subtf3>
 2f8:	ldr	q1, [sp, #160]
 2fc:	bl	0 <__divtf3>
 300:	str	q0, [sp, #112]
 304:	b	120 <__divtc3+0x120>
 308:	and	x28, x24, #0x7fffffffffffffff
 30c:	adrp	x0, 0 <__divtc3>
 310:	add	x0, x0, #0x0
 314:	ldr	q1, [x0]
 318:	str	x21, [sp, #144]
 31c:	str	x28, [sp, #152]
 320:	ldr	q0, [sp, #144]
 324:	bl	0 <__unordtf2>
 328:	cbnz	w0, 564 <__divtc3+0x564>
 32c:	adrp	x0, 0 <__divtc3>
 330:	add	x0, x0, #0x0
 334:	ldr	q1, [x0]
 338:	str	x21, [sp, #144]
 33c:	str	x28, [sp, #152]
 340:	ldr	q0, [sp, #144]
 344:	bl	0 <__letf2>
 348:	cmp	w0, #0x0
 34c:	b.le	564 <__divtc3+0x564>
 350:	adrp	x0, 0 <__divtc3>
 354:	add	x0, x0, #0x0
 358:	ldr	q1, [x0]
 35c:	str	x19, [sp, #144]
 360:	str	x26, [sp, #152]
 364:	ldr	q0, [sp, #144]
 368:	bl	0 <__unordtf2>
 36c:	cbnz	w0, 5bc <__divtc3+0x5bc>
 370:	adrp	x0, 0 <__divtc3>
 374:	add	x0, x0, #0x0
 378:	ldr	q1, [x0]
 37c:	str	x19, [sp, #144]
 380:	str	x26, [sp, #152]
 384:	ldr	q0, [sp, #144]
 388:	bl	0 <__gttf2>
 38c:	cmp	w0, #0x0
 390:	b.gt	5bc <__divtc3+0x5bc>
 394:	adrp	x0, 0 <__divtc3>
 398:	add	x0, x0, #0x0
 39c:	ldr	q1, [x0]
 3a0:	str	x20, [sp, #144]
 3a4:	str	x27, [sp, #152]
 3a8:	ldr	q0, [sp, #144]
 3ac:	bl	0 <__unordtf2>
 3b0:	cbnz	w0, 5bc <__divtc3+0x5bc>
 3b4:	adrp	x0, 0 <__divtc3>
 3b8:	add	x0, x0, #0x0
 3bc:	ldr	q1, [x0]
 3c0:	str	x20, [sp, #144]
 3c4:	str	x27, [sp, #152]
 3c8:	ldr	q0, [sp, #144]
 3cc:	bl	0 <__gttf2>
 3d0:	cmp	w0, #0x0
 3d4:	b.gt	5bc <__divtc3+0x5bc>
 3d8:	mov	w26, #0x1                   	// #1
 3dc:	adrp	x0, 0 <__divtc3>
 3e0:	add	x0, x0, #0x0
 3e4:	ldr	q1, [x0]
 3e8:	str	x21, [sp, #96]
 3ec:	str	x28, [sp, #104]
 3f0:	ldr	q0, [sp, #96]
 3f4:	bl	0 <__unordtf2>
 3f8:	cbnz	w0, 420 <__divtc3+0x420>
 3fc:	adrp	x0, 0 <__divtc3>
 400:	add	x0, x0, #0x0
 404:	ldr	q1, [x0]
 408:	str	x21, [sp, #96]
 40c:	str	x28, [sp, #104]
 410:	ldr	q0, [sp, #96]
 414:	bl	0 <__letf2>
 418:	cmp	w0, #0x0
 41c:	csel	w26, w26, wzr, le
 420:	eor	w0, w26, #0x1
 424:	and	w0, w0, #0x1
 428:	bl	0 <__floatsitf>
 42c:	str	q0, [sp, #96]
 430:	ldr	x21, [sp, #96]
 434:	ldr	x0, [sp, #104]
 438:	bfxil	x24, x0, #0, #63
 43c:	and	x27, x25, #0x7fffffffffffffff
 440:	mov	w26, #0x1                   	// #1
 444:	adrp	x0, 0 <__divtc3>
 448:	add	x0, x0, #0x0
 44c:	ldr	q1, [x0]
 450:	ldr	x28, [sp, #128]
 454:	str	x28, [sp, #96]
 458:	str	x27, [sp, #104]
 45c:	ldr	q0, [sp, #96]
 460:	bl	0 <__unordtf2>
 464:	cbnz	w0, 48c <__divtc3+0x48c>
 468:	adrp	x0, 0 <__divtc3>
 46c:	add	x0, x0, #0x0
 470:	ldr	q1, [x0]
 474:	str	x28, [sp, #96]
 478:	str	x27, [sp, #104]
 47c:	ldr	q0, [sp, #96]
 480:	bl	0 <__letf2>
 484:	cmp	w0, #0x0
 488:	csel	w26, w26, wzr, le
 48c:	eor	w0, w26, #0x1
 490:	and	w0, w0, #0x1
 494:	bl	0 <__floatsitf>
 498:	str	q0, [sp, #96]
 49c:	ldr	x26, [sp, #96]
 4a0:	ldr	x0, [sp, #104]
 4a4:	bfxil	x25, x0, #0, #63
 4a8:	str	x21, [sp, #96]
 4ac:	str	x24, [sp, #104]
 4b0:	ldr	q1, [sp, #96]
 4b4:	str	x19, [sp, #96]
 4b8:	str	x22, [sp, #104]
 4bc:	ldr	q0, [sp, #96]
 4c0:	bl	0 <__multf3>
 4c4:	str	q0, [sp, #112]
 4c8:	str	x26, [sp, #96]
 4cc:	str	x25, [sp, #104]
 4d0:	ldr	q1, [sp, #96]
 4d4:	str	x20, [sp, #96]
 4d8:	str	x23, [sp, #104]
 4dc:	ldr	q0, [sp, #96]
 4e0:	bl	0 <__multf3>
 4e4:	mov	v1.16b, v0.16b
 4e8:	ldr	q0, [sp, #112]
 4ec:	bl	0 <__addtf3>
 4f0:	adrp	x0, 0 <__divtc3>
 4f4:	add	x0, x0, #0x0
 4f8:	ldr	q1, [x0]
 4fc:	bl	0 <__multf3>
 500:	str	q0, [sp, #96]
 504:	str	x26, [sp, #112]
 508:	str	x25, [sp, #120]
 50c:	ldr	q1, [sp, #112]
 510:	str	x19, [sp, #112]
 514:	str	x22, [sp, #120]
 518:	ldr	q0, [sp, #112]
 51c:	bl	0 <__multf3>
 520:	str	q0, [sp, #128]
 524:	str	x21, [sp, #112]
 528:	str	x24, [sp, #120]
 52c:	ldr	q1, [sp, #112]
 530:	str	x20, [sp, #112]
 534:	str	x23, [sp, #120]
 538:	ldr	q0, [sp, #112]
 53c:	bl	0 <__multf3>
 540:	mov	v1.16b, v0.16b
 544:	ldr	q0, [sp, #128]
 548:	bl	0 <__subtf3>
 54c:	adrp	x0, 0 <__divtc3>
 550:	add	x0, x0, #0x0
 554:	ldr	q1, [x0]
 558:	bl	0 <__multf3>
 55c:	str	q0, [sp, #112]
 560:	b	230 <__divtc3+0x230>
 564:	and	x1, x25, #0x7fffffffffffffff
 568:	adrp	x0, 0 <__divtc3>
 56c:	add	x0, x0, #0x0
 570:	ldr	q1, [x0]
 574:	ldr	x0, [sp, #128]
 578:	str	x0, [sp, #144]
 57c:	str	x1, [sp, #160]
 580:	str	x1, [sp, #152]
 584:	ldr	q0, [sp, #144]
 588:	bl	0 <__unordtf2>
 58c:	cbnz	w0, 5bc <__divtc3+0x5bc>
 590:	adrp	x2, 0 <__divtc3>
 594:	add	x2, x2, #0x0
 598:	ldr	q1, [x2]
 59c:	ldr	x0, [sp, #128]
 5a0:	str	x0, [sp, #144]
 5a4:	ldr	x1, [sp, #160]
 5a8:	str	x1, [sp, #152]
 5ac:	ldr	q0, [sp, #144]
 5b0:	bl	0 <__letf2>
 5b4:	cmp	w0, #0x0
 5b8:	b.gt	350 <__divtc3+0x350>
 5bc:	mov	w0, #0x1                   	// #1
 5c0:	strb	w0, [sp, #160]
 5c4:	adrp	x0, 0 <__divtc3>
 5c8:	add	x0, x0, #0x0
 5cc:	ldr	q1, [x0]
 5d0:	str	x19, [sp, #144]
 5d4:	str	x26, [sp, #152]
 5d8:	ldr	q0, [sp, #144]
 5dc:	bl	0 <__unordtf2>
 5e0:	cbnz	w0, 610 <__divtc3+0x610>
 5e4:	adrp	x1, 0 <__divtc3>
 5e8:	add	x1, x1, #0x0
 5ec:	ldr	q1, [x1]
 5f0:	str	x19, [sp, #144]
 5f4:	str	x26, [sp, #152]
 5f8:	ldr	q0, [sp, #144]
 5fc:	bl	0 <__letf2>
 600:	cmp	w0, #0x0
 604:	ldrb	w0, [sp, #160]
 608:	csel	w0, w0, wzr, le
 60c:	strb	w0, [sp, #160]
 610:	ldrb	w26, [sp, #160]
 614:	mov	w19, #0x1                   	// #1
 618:	adrp	x0, 0 <__divtc3>
 61c:	add	x0, x0, #0x0
 620:	ldr	q1, [x0]
 624:	str	x20, [sp, #144]
 628:	str	x27, [sp, #152]
 62c:	ldr	q0, [sp, #144]
 630:	bl	0 <__unordtf2>
 634:	cbnz	w0, 65c <__divtc3+0x65c>
 638:	adrp	x0, 0 <__divtc3>
 63c:	add	x0, x0, #0x0
 640:	ldr	q1, [x0]
 644:	str	x20, [sp, #144]
 648:	str	x27, [sp, #152]
 64c:	ldr	q0, [sp, #144]
 650:	bl	0 <__letf2>
 654:	cmp	w0, #0x0
 658:	csel	w19, w19, wzr, le
 65c:	and	w19, w19, #0xff
 660:	cmp	w26, #0x0
 664:	ccmp	w19, #0x0, #0x4, ne  // ne = any
 668:	b.ne	230 <__divtc3+0x230>  // b.any
 66c:	adrp	x0, 0 <__divtc3>
 670:	add	x0, x0, #0x0
 674:	ldr	q1, [x0]
 678:	str	x21, [sp, #144]
 67c:	str	x28, [sp, #152]
 680:	ldr	q0, [sp, #144]
 684:	bl	0 <__unordtf2>
 688:	cbnz	w0, 230 <__divtc3+0x230>
 68c:	adrp	x0, 0 <__divtc3>
 690:	add	x0, x0, #0x0
 694:	ldr	q1, [x0]
 698:	str	x21, [sp, #144]
 69c:	str	x28, [sp, #152]
 6a0:	ldr	q0, [sp, #144]
 6a4:	bl	0 <__gttf2>
 6a8:	cmp	w0, #0x0
 6ac:	b.gt	230 <__divtc3+0x230>
 6b0:	and	x20, x25, #0x7fffffffffffffff
 6b4:	adrp	x0, 0 <__divtc3>
 6b8:	add	x0, x0, #0x0
 6bc:	ldr	q1, [x0]
 6c0:	ldr	x27, [sp, #128]
 6c4:	str	x27, [sp, #144]
 6c8:	str	x20, [sp, #152]
 6cc:	ldr	q0, [sp, #144]
 6d0:	bl	0 <__unordtf2>
 6d4:	cbnz	w0, 230 <__divtc3+0x230>
 6d8:	adrp	x0, 0 <__divtc3>
 6dc:	add	x0, x0, #0x0
 6e0:	ldr	q1, [x0]
 6e4:	str	x27, [sp, #128]
 6e8:	str	x20, [sp, #136]
 6ec:	ldr	q0, [sp, #128]
 6f0:	bl	0 <__gttf2>
 6f4:	cmp	w0, #0x0
 6f8:	b.gt	230 <__divtc3+0x230>
 6fc:	eor	w0, w26, #0x1
 700:	bl	0 <__floatsitf>
 704:	str	q0, [sp, #96]
 708:	ldr	x20, [sp, #96]
 70c:	ldr	x0, [sp, #104]
 710:	bfxil	x22, x0, #0, #63
 714:	eor	w0, w19, #0x1
 718:	bl	0 <__floatsitf>
 71c:	str	q0, [sp, #96]
 720:	ldr	x19, [sp, #96]
 724:	ldr	x0, [sp, #104]
 728:	bfxil	x23, x0, #0, #63
 72c:	str	x20, [sp, #96]
 730:	str	x22, [sp, #104]
 734:	ldr	q1, [sp, #96]
 738:	str	x21, [sp, #96]
 73c:	str	x24, [sp, #104]
 740:	ldr	q0, [sp, #96]
 744:	bl	0 <__multf3>
 748:	str	q0, [sp, #112]
 74c:	str	x19, [sp, #96]
 750:	str	x23, [sp, #104]
 754:	ldr	q1, [sp, #96]
 758:	str	x27, [sp, #96]
 75c:	str	x25, [sp, #104]
 760:	ldr	q0, [sp, #96]
 764:	bl	0 <__multf3>
 768:	mov	v1.16b, v0.16b
 76c:	ldr	q0, [sp, #112]
 770:	bl	0 <__addtf3>
 774:	movi	v1.2d, #0x0
 778:	bl	0 <__multf3>
 77c:	str	q0, [sp, #96]
 780:	str	x20, [sp, #112]
 784:	str	x22, [sp, #120]
 788:	ldr	q1, [sp, #112]
 78c:	str	x27, [sp, #112]
 790:	str	x25, [sp, #120]
 794:	ldr	q0, [sp, #112]
 798:	bl	0 <__multf3>
 79c:	str	q0, [sp, #128]
 7a0:	str	x19, [sp, #112]
 7a4:	str	x23, [sp, #120]
 7a8:	ldr	q1, [sp, #112]
 7ac:	str	x21, [sp, #112]
 7b0:	str	x24, [sp, #120]
 7b4:	ldr	q0, [sp, #112]
 7b8:	bl	0 <__multf3>
 7bc:	mov	v1.16b, v0.16b
 7c0:	ldr	q0, [sp, #128]
 7c4:	bl	0 <__subtf3>
 7c8:	movi	v1.2d, #0x0
 7cc:	bl	0 <__multf3>
 7d0:	str	q0, [sp, #112]
 7d4:	b	230 <__divtc3+0x230>

_bswapsi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__bswapsi2>:
   0:	asr	w1, w0, #8
   4:	and	w1, w1, #0xff00
   8:	lsl	w2, w0, #8
   c:	and	w2, w2, #0xff0000
  10:	orr	w1, w1, w2
  14:	lsl	w2, w0, #24
  18:	orr	w0, w2, w0, lsr #24
  1c:	orr	w0, w1, w0
  20:	ret

_bswapdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__bswapdi2>:
   0:	lsr	x2, x0, #40
   4:	and	x2, x2, #0xff00
   8:	lsr	x1, x0, #24
   c:	and	x1, x1, #0xff0000
  10:	orr	x2, x2, x1
  14:	lsl	x1, x0, #56
  18:	orr	x1, x1, x0, lsr #56
  1c:	orr	x2, x2, x1
  20:	lsr	x1, x0, #8
  24:	and	x1, x1, #0xff000000
  28:	lsl	x3, x0, #8
  2c:	and	x3, x3, #0xff00000000
  30:	orr	x1, x1, x3
  34:	orr	x2, x2, x1
  38:	lsl	x3, x0, #24
  3c:	and	x3, x3, #0xff0000000000
  40:	lsl	x1, x0, #40
  44:	and	x1, x1, #0xff000000000000
  48:	orr	x0, x3, x1
  4c:	orr	x0, x2, x0
  50:	ret

_clrsbsi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__clrsbdi2>:
   0:	eor	x1, x0, x0, asr #63
   4:	clz	x0, x1
   8:	sub	w0, w0, #0x1
   c:	cmp	x1, #0x0
  10:	mov	w1, #0x3f                  	// #63
  14:	csel	w0, w0, w1, ne  // ne = any
  18:	ret

_clrsbdi2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__clrsbti2>:
   0:	cbz	x1, 20 <__clrsbti2+0x20>
   4:	mvn	x0, x0
   8:	cmn	x1, #0x1
   c:	b.eq	20 <__clrsbti2+0x20>  // b.none
  10:	eor	x0, x1, x1, asr #63
  14:	mov	x2, #0x0                   	// #0
  18:	clz	x1, x0
  1c:	b	2c <__clrsbti2+0x2c>
  20:	mov	x2, #0x40                  	// #64
  24:	mov	x1, x2
  28:	cbnz	x0, 18 <__clrsbti2+0x18>
  2c:	add	w0, w1, w2
  30:	sub	w0, w0, #0x1
  34:	ret

_fixunssfsi.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunssfdi>:
   0:	movi	v1.2s, #0x5f, lsl #24
   4:	fcmpe	s0, s1
   8:	b.ge	14 <__fixunssfdi+0x14>  // b.tcont
   c:	fcvtzs	x0, s0
  10:	ret
  14:	fsub	s0, s0, s1
  18:	fcvtzs	x0, s0
  1c:	mov	x1, #0x8000000000000000    	// #-9223372036854775808
  20:	add	x0, x0, x1
  24:	b	10 <__fixunssfdi+0x10>

_fixunsdfsi.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunsdfdi>:
   0:	mov	x0, #0x43e0000000000000    	// #4890909195324358656
   4:	fmov	d1, x0
   8:	fcmpe	d0, d1
   c:	b.ge	18 <__fixunsdfdi+0x18>  // b.tcont
  10:	fcvtzs	x0, d0
  14:	ret
  18:	fsub	d0, d0, d1
  1c:	fcvtzs	d0, d0
  20:	mov	x0, #0x8000000000000000    	// #-9223372036854775808
  24:	fmov	x1, d0
  28:	add	x0, x1, x0
  2c:	b	14 <__fixunsdfdi+0x14>

_fixunsxfsi.o:     file format elf64-littleaarch64


_fixsfdi.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixsfti>:
   0:	stp	x29, x30, [sp, #-16]!
   4:	mov	x29, sp
   8:	fcmpe	s0, #0.0
   c:	b.mi	1c <__fixsfti+0x1c>  // b.first
  10:	bl	0 <__fixunssfti>
  14:	ldp	x29, x30, [sp], #16
  18:	ret
  1c:	fneg	s0, s0
  20:	bl	0 <__fixunssfti>
  24:	negs	x0, x0
  28:	ngc	x1, x1
  2c:	b	14 <__fixsfti+0x14>

_fixdfdi.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixdfti>:
   0:	stp	x29, x30, [sp, #-16]!
   4:	mov	x29, sp
   8:	fcmpe	d0, #0.0
   c:	b.mi	1c <__fixdfti+0x1c>  // b.first
  10:	bl	0 <__fixunsdfti>
  14:	ldp	x29, x30, [sp], #16
  18:	ret
  1c:	fneg	d0, d0
  20:	bl	0 <__fixunsdfti>
  24:	negs	x0, x0
  28:	ngc	x1, x1
  2c:	b	14 <__fixdfti+0x14>

_fixxfdi.o:     file format elf64-littleaarch64


_fixunssfdi.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunssfti>:
   0:	fcvt	d0, s0
   4:	mov	x0, #0x3bf0000000000000    	// #4318952042648305664
   8:	fmov	d1, x0
   c:	fmul	d1, d0, d1
  10:	fcvtzu	x1, d1
  14:	ucvtf	d1, x1
  18:	mov	x0, #0x43f0000000000000    	// #4895412794951729152
  1c:	fmov	d2, x0
  20:	fmul	d1, d1, d2
  24:	fsub	d0, d0, d1
  28:	fcvtzu	x0, d0
  2c:	ret

_fixunsdfdi.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunsdfti>:
   0:	mov	x0, #0x3bf0000000000000    	// #4318952042648305664
   4:	fmov	d1, x0
   8:	fmul	d1, d0, d1
   c:	fcvtzu	x1, d1
  10:	ucvtf	d1, x1
  14:	mov	x0, #0x43f0000000000000    	// #4895412794951729152
  18:	fmov	d2, x0
  1c:	fmul	d1, d1, d2
  20:	fsub	d0, d0, d1
  24:	fcvtzu	x0, d0
  28:	ret

_fixunsxfdi.o:     file format elf64-littleaarch64


_floatdisf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floattisf>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	mov	x19, x0
  10:	mov	x0, x1
  14:	mov	x4, x19
  18:	mov	x1, #0xffffffffffffffff    	// #-1
  1c:	adds	x2, x19, x1
  20:	mov	x1, #0x1ffffffffffff       	// #562949953421311
  24:	adc	x1, x0, x1
  28:	mov	x3, #0x3ffffffffffff       	// #1125899906842623
  2c:	cmp	x1, x3
  30:	b.hi	40 <__floattisf+0x40>  // b.pmore
  34:	b.ne	50 <__floattisf+0x50>  // b.any
  38:	cmn	x2, #0x2
  3c:	b.ls	50 <__floattisf+0x50>  // b.plast
  40:	and	x1, x19, #0xffffffffffff8000
  44:	orr	x1, x1, #0x8000
  48:	tst	x4, #0x7fff
  4c:	csel	x19, x1, x19, ne  // ne = any
  50:	bl	0 <__floatditf>
  54:	adrp	x0, 0 <__floattisf>
  58:	add	x0, x0, #0x0
  5c:	ldr	q1, [x0]
  60:	bl	0 <__multf3>
  64:	str	q0, [sp, #32]
  68:	mov	x0, x19
  6c:	bl	0 <__floatunditf>
  70:	ldr	q1, [sp, #32]
  74:	bl	0 <__addtf3>
  78:	bl	0 <__trunctfsf2>
  7c:	ldr	x19, [sp, #16]
  80:	ldp	x29, x30, [sp], #48
  84:	ret

_floatdidf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floattidf>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	mov	x19, x0
  10:	mov	x0, x1
  14:	mov	x4, x19
  18:	mov	x1, #0xffffffffffffffff    	// #-1
  1c:	adds	x2, x19, x1
  20:	mov	x1, #0x1ffffffffffff       	// #562949953421311
  24:	adc	x1, x0, x1
  28:	mov	x3, #0x3ffffffffffff       	// #1125899906842623
  2c:	cmp	x1, x3
  30:	b.hi	40 <__floattidf+0x40>  // b.pmore
  34:	b.ne	50 <__floattidf+0x50>  // b.any
  38:	cmn	x2, #0x2
  3c:	b.ls	50 <__floattidf+0x50>  // b.plast
  40:	and	x1, x19, #0xffffffffffff8000
  44:	orr	x1, x1, #0x8000
  48:	tst	x4, #0x7fff
  4c:	csel	x19, x1, x19, ne  // ne = any
  50:	bl	0 <__floatditf>
  54:	adrp	x0, 0 <__floattidf>
  58:	add	x0, x0, #0x0
  5c:	ldr	q1, [x0]
  60:	bl	0 <__multf3>
  64:	str	q0, [sp, #32]
  68:	mov	x0, x19
  6c:	bl	0 <__floatunditf>
  70:	ldr	q1, [sp, #32]
  74:	bl	0 <__addtf3>
  78:	bl	0 <__trunctfdf2>
  7c:	ldr	x19, [sp, #16]
  80:	ldp	x29, x30, [sp], #48
  84:	ret

_floatdixf.o:     file format elf64-littleaarch64


_floatundisf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatuntisf>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	mov	x19, x0
  10:	mov	x0, x1
  14:	mov	x1, #0x1ffffffffffff       	// #562949953421311
  18:	cmp	x0, x1
  1c:	b.ls	30 <__floatuntisf+0x30>  // b.plast
  20:	and	x1, x19, #0xffffffffffff8000
  24:	orr	x1, x1, #0x8000
  28:	tst	x19, #0x7fff
  2c:	csel	x19, x1, x19, ne  // ne = any
  30:	bl	0 <__floatunditf>
  34:	adrp	x0, 0 <__floatuntisf>
  38:	add	x0, x0, #0x0
  3c:	ldr	q1, [x0]
  40:	bl	0 <__multf3>
  44:	str	q0, [sp, #32]
  48:	mov	x0, x19
  4c:	bl	0 <__floatunditf>
  50:	ldr	q1, [sp, #32]
  54:	bl	0 <__addtf3>
  58:	bl	0 <__trunctfsf2>
  5c:	ldr	x19, [sp, #16]
  60:	ldp	x29, x30, [sp], #48
  64:	ret

_floatundidf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatuntidf>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	mov	x19, x0
  10:	mov	x0, x1
  14:	mov	x1, #0x1ffffffffffff       	// #562949953421311
  18:	cmp	x0, x1
  1c:	b.ls	30 <__floatuntidf+0x30>  // b.plast
  20:	and	x1, x19, #0xffffffffffff8000
  24:	orr	x1, x1, #0x8000
  28:	tst	x19, #0x7fff
  2c:	csel	x19, x1, x19, ne  // ne = any
  30:	bl	0 <__floatunditf>
  34:	adrp	x0, 0 <__floatuntidf>
  38:	add	x0, x0, #0x0
  3c:	ldr	q1, [x0]
  40:	bl	0 <__multf3>
  44:	str	q0, [sp, #32]
  48:	mov	x0, x19
  4c:	bl	0 <__floatunditf>
  50:	ldr	q1, [sp, #32]
  54:	bl	0 <__addtf3>
  58:	bl	0 <__trunctfdf2>
  5c:	ldr	x19, [sp, #16]
  60:	ldp	x29, x30, [sp], #48
  64:	ret

_floatundixf.o:     file format elf64-littleaarch64


_eprintf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__eprintf>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	adrp	x19, 0 <stderr>
  10:	ldr	x19, [x19]
  14:	mov	x4, x3
  18:	mov	w3, w2
  1c:	mov	x2, x1
  20:	mov	x1, x0
  24:	ldr	x0, [x19]
  28:	bl	0 <fprintf>
  2c:	ldr	x0, [x19]
  30:	bl	0 <fflush>
  34:	bl	0 <abort>

__gcc_bcmp.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__gcc_bcmp>:
   0:	cbz	x2, 34 <__gcc_bcmp+0x34>
   4:	mov	x3, #0x0                   	// #0
   8:	ldrb	w4, [x0, x3]
   c:	ldrb	w5, [x1, x3]
  10:	cmp	w4, w5
  14:	b.ne	2c <__gcc_bcmp+0x2c>  // b.any
  18:	add	x3, x3, #0x1
  1c:	cmp	x2, x3
  20:	b.ne	8 <__gcc_bcmp+0x8>  // b.any
  24:	mov	w0, #0x0                   	// #0
  28:	b	30 <__gcc_bcmp+0x30>
  2c:	sub	w0, w4, w5
  30:	ret
  34:	mov	w0, #0x0                   	// #0
  38:	b	30 <__gcc_bcmp+0x30>

_divdi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divti3>:
   0:	mov	x4, x1
   4:	mov	x7, #0x0                   	// #0
   8:	tbnz	x1, #63, c0 <__divti3+0xc0>
   c:	tbnz	x3, #63, d0 <__divti3+0xd0>
  10:	mov	x5, x2
  14:	mov	x1, x3
  18:	mov	x6, x0
  1c:	mov	x0, x4
  20:	cbnz	x3, 23c <__divti3+0x23c>
  24:	cmp	x2, x4
  28:	b.ls	ec <__divti3+0xec>  // b.plast
  2c:	clz	x2, x2
  30:	cbz	x2, 4c <__divti3+0x4c>
  34:	lsl	x5, x5, x2
  38:	lsl	x0, x4, x2
  3c:	neg	w3, w2
  40:	lsr	x3, x6, x3
  44:	orr	x0, x3, x0
  48:	lsl	x6, x6, x2
  4c:	lsr	x3, x5, #32
  50:	and	x4, x5, #0xffffffff
  54:	udiv	x8, x0, x3
  58:	msub	x0, x8, x3, x0
  5c:	mov	x2, x8
  60:	mul	x9, x4, x8
  64:	extr	x0, x0, x6, #32
  68:	cmp	x9, x0
  6c:	b.ls	84 <__divti3+0x84>  // b.plast
  70:	add	x0, x0, x5
  74:	cmp	x9, x0
  78:	ccmp	x5, x0, #0x2, hi  // hi = pmore
  7c:	b.ls	e0 <__divti3+0xe0>  // b.plast
  80:	sub	x2, x8, #0x1
  84:	sub	x0, x0, x9
  88:	udiv	x8, x0, x3
  8c:	msub	x0, x8, x3, x0
  90:	mov	x3, x8
  94:	mul	x4, x4, x8
  98:	bfi	x6, x0, #32, #32
  9c:	cmp	x4, x6
  a0:	b.ls	b8 <__divti3+0xb8>  // b.plast
  a4:	add	x0, x5, x6
  a8:	cmp	x4, x0
  ac:	ccmp	x5, x0, #0x2, hi  // hi = pmore
  b0:	cinc	x3, x8, hi  // hi = pmore
  b4:	sub	x3, x3, #0x2
  b8:	orr	x0, x3, x2, lsl #32
  bc:	b	384 <__divti3+0x384>
  c0:	negs	x0, x0
  c4:	ngc	x4, x1
  c8:	mov	x7, #0xffffffffffffffff    	// #-1
  cc:	b	c <__divti3+0xc>
  d0:	mvn	x7, x7
  d4:	negs	x2, x2
  d8:	ngc	x3, x3
  dc:	b	10 <__divti3+0x10>
  e0:	sub	x2, x8, #0x2
  e4:	add	x0, x0, x5
  e8:	b	84 <__divti3+0x84>
  ec:	cbnz	x2, fc <__divti3+0xfc>
  f0:	mov	x5, #0x1                   	// #1
  f4:	mov	x1, #0x0                   	// #0
  f8:	udiv	x5, x5, x1
  fc:	clz	x2, x5
 100:	cbnz	x2, 180 <__divti3+0x180>
 104:	sub	x0, x0, x5
 108:	mov	x1, #0x1                   	// #1
 10c:	lsr	x3, x5, #32
 110:	and	x4, x5, #0xffffffff
 114:	udiv	x8, x0, x3
 118:	msub	x0, x8, x3, x0
 11c:	mov	x2, x8
 120:	mul	x9, x4, x8
 124:	extr	x0, x0, x6, #32
 128:	cmp	x9, x0
 12c:	b.ls	144 <__divti3+0x144>  // b.plast
 130:	add	x0, x0, x5
 134:	cmp	x9, x0
 138:	ccmp	x5, x0, #0x2, hi  // hi = pmore
 13c:	b.ls	230 <__divti3+0x230>  // b.plast
 140:	sub	x2, x8, #0x1
 144:	sub	x0, x0, x9
 148:	udiv	x8, x0, x3
 14c:	msub	x0, x8, x3, x0
 150:	mov	x3, x8
 154:	mul	x4, x4, x8
 158:	bfi	x6, x0, #32, #32
 15c:	cmp	x4, x6
 160:	b.ls	178 <__divti3+0x178>  // b.plast
 164:	add	x0, x5, x6
 168:	cmp	x4, x0
 16c:	ccmp	x5, x0, #0x2, hi  // hi = pmore
 170:	cinc	x3, x8, hi  // hi = pmore
 174:	sub	x3, x3, #0x2
 178:	orr	x0, x3, x2, lsl #32
 17c:	b	384 <__divti3+0x384>
 180:	lsl	x5, x5, x2
 184:	mov	x1, #0x40                  	// #64
 188:	sub	x1, x1, x2
 18c:	lsr	x3, x0, x1
 190:	lsl	x0, x0, x2
 194:	lsr	x1, x6, x1
 198:	orr	x0, x1, x0
 19c:	lsl	x6, x6, x2
 1a0:	lsr	x4, x5, #32
 1a4:	and	x8, x5, #0xffffffff
 1a8:	udiv	x9, x3, x4
 1ac:	msub	x3, x9, x4, x3
 1b0:	mov	x11, x9
 1b4:	mul	x10, x8, x9
 1b8:	extr	x2, x3, x0, #32
 1bc:	cmp	x10, x2
 1c0:	b.ls	1d8 <__divti3+0x1d8>  // b.plast
 1c4:	add	x2, x2, x5
 1c8:	cmp	x10, x2
 1cc:	ccmp	x5, x2, #0x2, hi  // hi = pmore
 1d0:	b.ls	218 <__divti3+0x218>  // b.plast
 1d4:	sub	x11, x9, #0x1
 1d8:	sub	x2, x2, x10
 1dc:	udiv	x9, x2, x4
 1e0:	msub	x2, x9, x4, x2
 1e4:	mov	x1, x9
 1e8:	mul	x3, x8, x9
 1ec:	bfi	x0, x2, #32, #32
 1f0:	cmp	x3, x0
 1f4:	b.ls	20c <__divti3+0x20c>  // b.plast
 1f8:	add	x0, x0, x5
 1fc:	cmp	x3, x0
 200:	ccmp	x5, x0, #0x2, hi  // hi = pmore
 204:	b.ls	224 <__divti3+0x224>  // b.plast
 208:	sub	x1, x9, #0x1
 20c:	sub	x0, x0, x3
 210:	orr	x1, x1, x11, lsl #32
 214:	b	10c <__divti3+0x10c>
 218:	sub	x11, x9, #0x2
 21c:	add	x2, x2, x5
 220:	b	1d8 <__divti3+0x1d8>
 224:	sub	x1, x9, #0x2
 228:	add	x0, x0, x5
 22c:	b	20c <__divti3+0x20c>
 230:	sub	x2, x8, #0x2
 234:	add	x0, x0, x5
 238:	b	144 <__divti3+0x144>
 23c:	cmp	x3, x4
 240:	b.hi	37c <__divti3+0x37c>  // b.pmore
 244:	clz	x8, x3
 248:	cbnz	x8, 260 <__divti3+0x260>
 24c:	cmp	x3, x4
 250:	ccmp	x2, x6, #0x0, cs  // cs = hs, nlast
 254:	cset	x0, ls  // ls = plast
 258:	mov	x1, x8
 25c:	b	384 <__divti3+0x384>
 260:	lsl	x1, x3, x8
 264:	mov	x2, #0x40                  	// #64
 268:	sub	x2, x2, x8
 26c:	lsr	x9, x5, x2
 270:	orr	x9, x9, x1
 274:	lsl	x5, x5, x8
 278:	lsr	x1, x4, x2
 27c:	lsl	x0, x4, x8
 280:	lsr	x2, x6, x2
 284:	orr	x0, x2, x0
 288:	lsr	x4, x9, #32
 28c:	and	x2, x9, #0xffffffff
 290:	udiv	x10, x1, x4
 294:	msub	x3, x10, x4, x1
 298:	mov	x1, x10
 29c:	mul	x11, x2, x10
 2a0:	extr	x3, x3, x0, #32
 2a4:	cmp	x11, x3
 2a8:	b.ls	2c0 <__divti3+0x2c0>  // b.plast
 2ac:	add	x3, x3, x9
 2b0:	cmp	x11, x3
 2b4:	ccmp	x9, x3, #0x2, hi  // hi = pmore
 2b8:	b.ls	364 <__divti3+0x364>  // b.plast
 2bc:	sub	x1, x10, #0x1
 2c0:	sub	x3, x3, x11
 2c4:	udiv	x10, x3, x4
 2c8:	msub	x3, x10, x4, x3
 2cc:	mov	x4, x10
 2d0:	mul	x2, x2, x10
 2d4:	bfi	x0, x3, #32, #32
 2d8:	cmp	x2, x0
 2dc:	b.ls	2f4 <__divti3+0x2f4>  // b.plast
 2e0:	add	x0, x0, x9
 2e4:	cmp	x2, x0
 2e8:	ccmp	x9, x0, #0x2, hi  // hi = pmore
 2ec:	b.ls	370 <__divti3+0x370>  // b.plast
 2f0:	sub	x4, x10, #0x1
 2f4:	sub	x2, x0, x2
 2f8:	orr	x0, x4, x1, lsl #32
 2fc:	mov	w4, w4
 300:	lsr	x1, x0, #32
 304:	and	x3, x5, #0xffffffff
 308:	lsr	x5, x5, #32
 30c:	mul	x9, x4, x3
 310:	mul	x3, x1, x3
 314:	mul	x1, x1, x5
 318:	madd	x5, x4, x5, x3
 31c:	add	x5, x5, x9, lsr #32
 320:	mov	x4, #0x100000000           	// #4294967296
 324:	add	x4, x1, x4
 328:	cmp	x3, x5
 32c:	csel	x1, x4, x1, hi  // hi = pmore
 330:	add	x3, x1, x5, lsr #32
 334:	cmp	x2, x3
 338:	b.cc	358 <__divti3+0x358>  // b.lo, b.ul, b.last
 33c:	lsl	x6, x6, x8
 340:	and	x9, x9, #0xffffffff
 344:	add	x5, x9, x5, lsl #32
 348:	cmp	x6, x5
 34c:	mov	x1, #0x0                   	// #0
 350:	ccmp	x2, x3, #0x0, cc  // cc = lo, ul, last
 354:	b.ne	384 <__divti3+0x384>  // b.any
 358:	sub	x0, x0, #0x1
 35c:	mov	x1, #0x0                   	// #0
 360:	b	384 <__divti3+0x384>
 364:	sub	x1, x10, #0x2
 368:	add	x3, x3, x9
 36c:	b	2c0 <__divti3+0x2c0>
 370:	sub	x4, x10, #0x2
 374:	add	x0, x0, x9
 378:	b	2f4 <__divti3+0x2f4>
 37c:	mov	x1, #0x0                   	// #0
 380:	mov	x0, #0x0                   	// #0
 384:	cbz	x7, 390 <__divti3+0x390>
 388:	negs	x0, x0
 38c:	ngc	x1, x1
 390:	ret

_moddi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__modti3>:
   0:	mov	x7, #0x0                   	// #0
   4:	tbnz	x1, #63, c8 <__modti3+0xc8>
   8:	tbnz	x3, #63, d8 <__modti3+0xd8>
   c:	mov	x4, x2
  10:	mov	x8, x0
  14:	mov	x5, x1
  18:	cbnz	x3, 1fc <__modti3+0x1fc>
  1c:	cmp	x2, x1
  20:	b.ls	e4 <__modti3+0xe4>  // b.plast
  24:	clz	x2, x2
  28:	cbz	x2, 44 <__modti3+0x44>
  2c:	lsl	x4, x4, x2
  30:	lsl	x5, x1, x2
  34:	neg	w1, w2
  38:	lsr	x1, x0, x1
  3c:	orr	x5, x1, x5
  40:	lsl	x8, x0, x2
  44:	lsr	x1, x4, #32
  48:	and	x0, x4, #0xffffffff
  4c:	udiv	x3, x5, x1
  50:	msub	x5, x3, x1, x5
  54:	mul	x3, x0, x3
  58:	extr	x5, x5, x8, #32
  5c:	cmp	x3, x5
  60:	b.ls	78 <__modti3+0x78>  // b.plast
  64:	add	x5, x5, x4
  68:	cmp	x3, x5
  6c:	add	x6, x5, x4
  70:	ccmp	x4, x5, #0x2, hi  // hi = pmore
  74:	csel	x5, x6, x5, ls  // ls = plast
  78:	sub	x5, x5, x3
  7c:	udiv	x3, x5, x1
  80:	msub	x5, x3, x1, x5
  84:	mul	x1, x0, x3
  88:	mov	x0, x8
  8c:	bfi	x0, x5, #32, #32
  90:	cmp	x1, x0
  94:	b.ls	ac <__modti3+0xac>  // b.plast
  98:	add	x0, x0, x4
  9c:	cmp	x1, x0
  a0:	add	x3, x0, x4
  a4:	ccmp	x4, x0, #0x2, hi  // hi = pmore
  a8:	csel	x0, x3, x0, ls  // ls = plast
  ac:	sub	x0, x0, x1
  b0:	lsr	x0, x0, x2
  b4:	mov	x1, #0x0                   	// #0
  b8:	cbz	x7, c4 <__modti3+0xc4>
  bc:	negs	x0, x0
  c0:	ngc	x1, x1
  c4:	ret
  c8:	negs	x0, x0
  cc:	ngc	x1, x1
  d0:	mov	x7, #0xffffffffffffffff    	// #-1
  d4:	b	8 <__modti3+0x8>
  d8:	negs	x2, x2
  dc:	ngc	x3, x3
  e0:	b	c <__modti3+0xc>
  e4:	cbnz	x2, f4 <__modti3+0xf4>
  e8:	mov	x4, #0x1                   	// #1
  ec:	mov	x0, #0x0                   	// #0
  f0:	udiv	x4, x4, x0
  f4:	clz	x2, x4
  f8:	cbnz	x2, 170 <__modti3+0x170>
  fc:	sub	x5, x5, x4
 100:	lsr	x1, x4, #32
 104:	and	x0, x4, #0xffffffff
 108:	udiv	x3, x5, x1
 10c:	msub	x5, x3, x1, x5
 110:	mul	x3, x0, x3
 114:	extr	x5, x5, x8, #32
 118:	cmp	x3, x5
 11c:	b.ls	134 <__modti3+0x134>  // b.plast
 120:	add	x5, x5, x4
 124:	cmp	x3, x5
 128:	add	x6, x5, x4
 12c:	ccmp	x4, x5, #0x2, hi  // hi = pmore
 130:	csel	x5, x6, x5, ls  // ls = plast
 134:	sub	x5, x5, x3
 138:	udiv	x3, x5, x1
 13c:	msub	x5, x3, x1, x5
 140:	mul	x1, x0, x3
 144:	mov	x0, x8
 148:	bfi	x0, x5, #32, #32
 14c:	cmp	x1, x0
 150:	b.ls	168 <__modti3+0x168>  // b.plast
 154:	add	x0, x0, x4
 158:	cmp	x1, x0
 15c:	add	x3, x0, x4
 160:	ccmp	x4, x0, #0x2, hi  // hi = pmore
 164:	csel	x0, x3, x0, ls  // ls = plast
 168:	sub	x0, x0, x1
 16c:	b	b0 <__modti3+0xb0>
 170:	lsl	x4, x4, x2
 174:	mov	x1, #0x40                  	// #64
 178:	sub	x1, x1, x2
 17c:	lsr	x3, x5, x1
 180:	lsl	x5, x5, x2
 184:	lsr	x1, x8, x1
 188:	orr	x5, x1, x5
 18c:	lsl	x8, x8, x2
 190:	lsr	x1, x4, #32
 194:	and	x6, x4, #0xffffffff
 198:	udiv	x0, x3, x1
 19c:	msub	x3, x0, x1, x3
 1a0:	mul	x9, x6, x0
 1a4:	extr	x0, x3, x5, #32
 1a8:	cmp	x9, x0
 1ac:	b.ls	1c4 <__modti3+0x1c4>  // b.plast
 1b0:	add	x0, x0, x4
 1b4:	cmp	x9, x0
 1b8:	add	x3, x0, x4
 1bc:	ccmp	x4, x0, #0x2, hi  // hi = pmore
 1c0:	csel	x0, x3, x0, ls  // ls = plast
 1c4:	sub	x0, x0, x9
 1c8:	udiv	x3, x0, x1
 1cc:	msub	x0, x3, x1, x0
 1d0:	mul	x1, x6, x3
 1d4:	bfi	x5, x0, #32, #32
 1d8:	cmp	x1, x5
 1dc:	b.ls	1f4 <__modti3+0x1f4>  // b.plast
 1e0:	add	x5, x5, x4
 1e4:	cmp	x1, x5
 1e8:	add	x0, x5, x4
 1ec:	ccmp	x4, x5, #0x2, hi  // hi = pmore
 1f0:	csel	x5, x0, x5, ls  // ls = plast
 1f4:	sub	x5, x5, x1
 1f8:	b	100 <__modti3+0x100>
 1fc:	cmp	x3, x1
 200:	b.hi	b8 <__modti3+0xb8>  // b.pmore
 204:	clz	x11, x3
 208:	cbnz	x11, 234 <__modti3+0x234>
 20c:	cmp	x3, x1
 210:	ccmp	x2, x0, #0x0, cs  // cs = hs, nlast
 214:	b.hi	228 <__modti3+0x228>  // b.pmore
 218:	sub	x4, x0, x2
 21c:	cmp	x0, x4
 220:	sbc	x5, x1, x3
 224:	mov	x8, x4
 228:	mov	x0, x8
 22c:	mov	x1, x5
 230:	b	b8 <__modti3+0xb8>
 234:	lsl	x9, x3, x11
 238:	mov	x2, #0x40                  	// #64
 23c:	sub	x2, x2, x11
 240:	lsr	x0, x4, x2
 244:	orr	x9, x0, x9
 248:	lsl	x4, x4, x11
 24c:	lsr	x10, x1, x2
 250:	lsl	x5, x1, x11
 254:	lsr	x3, x8, x2
 258:	orr	x5, x3, x5
 25c:	lsl	x0, x8, x11
 260:	lsr	x1, x9, #32
 264:	and	x8, x9, #0xffffffff
 268:	udiv	x12, x10, x1
 26c:	msub	x10, x12, x1, x10
 270:	mov	x3, x12
 274:	mul	x13, x8, x12
 278:	extr	x6, x10, x5, #32
 27c:	cmp	x13, x6
 280:	b.ls	298 <__modti3+0x298>  // b.plast
 284:	add	x6, x6, x9
 288:	cmp	x13, x6
 28c:	ccmp	x9, x6, #0x2, hi  // hi = pmore
 290:	b.ls	358 <__modti3+0x358>  // b.plast
 294:	sub	x3, x12, #0x1
 298:	sub	x6, x6, x13
 29c:	udiv	x10, x6, x1
 2a0:	msub	x1, x10, x1, x6
 2a4:	mov	x6, x10
 2a8:	mul	x8, x8, x10
 2ac:	bfi	x5, x1, #32, #32
 2b0:	cmp	x8, x5
 2b4:	b.ls	2cc <__modti3+0x2cc>  // b.plast
 2b8:	add	x5, x5, x9
 2bc:	cmp	x8, x5
 2c0:	ccmp	x9, x5, #0x2, hi  // hi = pmore
 2c4:	b.ls	364 <__modti3+0x364>  // b.plast
 2c8:	sub	x6, x10, #0x1
 2cc:	sub	x5, x5, x8
 2d0:	orr	x3, x6, x3, lsl #32
 2d4:	mov	w6, w6
 2d8:	lsr	x3, x3, #32
 2dc:	and	x1, x4, #0xffffffff
 2e0:	lsr	x10, x4, #32
 2e4:	mul	x8, x6, x1
 2e8:	mul	x1, x3, x1
 2ec:	mul	x3, x3, x10
 2f0:	madd	x6, x6, x10, x1
 2f4:	add	x6, x6, x8, lsr #32
 2f8:	mov	x10, #0x100000000           	// #4294967296
 2fc:	add	x10, x3, x10
 300:	cmp	x1, x6
 304:	csel	x3, x10, x3, hi  // hi = pmore
 308:	add	x1, x3, x6, lsr #32
 30c:	and	x8, x8, #0xffffffff
 310:	add	x6, x8, x6, lsl #32
 314:	cmp	x5, x1
 318:	b.cc	328 <__modti3+0x328>  // b.lo, b.ul, b.last
 31c:	mov	x3, x6
 320:	ccmp	x0, x6, #0x2, eq  // eq = none
 324:	b.cs	338 <__modti3+0x338>  // b.hs, b.nlast
 328:	sub	x3, x6, x4
 32c:	cmp	x6, x3
 330:	cinc	x9, x9, cc  // cc = lo, ul, last
 334:	sub	x1, x1, x9
 338:	sub	x3, x0, x3
 33c:	cmp	x0, x3
 340:	sbc	x5, x5, x1
 344:	lsl	x0, x5, x2
 348:	lsr	x3, x3, x11
 34c:	orr	x0, x0, x3
 350:	lsr	x1, x5, x11
 354:	b	b8 <__modti3+0xb8>
 358:	sub	x3, x12, #0x2
 35c:	add	x6, x6, x9
 360:	b	298 <__modti3+0x298>
 364:	sub	x6, x10, #0x2
 368:	add	x5, x5, x9
 36c:	b	2cc <__modti3+0x2cc>

_divmoddi4.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divmodti4>:
   0:	mov	x8, #0x0                   	// #0
   4:	tbnz	x1, #63, f4 <__divmodti4+0xf4>
   8:	mov	x9, x8
   c:	tbnz	x3, #63, 104 <__divmodti4+0x104>
  10:	mov	x6, x2
  14:	mov	x5, x3
  18:	mov	x11, x0
  1c:	mov	x7, x1
  20:	cbnz	x3, 290 <__divmodti4+0x290>
  24:	cmp	x2, x1
  28:	b.ls	12c <__divmodti4+0x12c>  // b.plast
  2c:	clz	x3, x2
  30:	cbz	x3, 4c <__divmodti4+0x4c>
  34:	lsl	x6, x2, x3
  38:	lsl	x7, x1, x3
  3c:	neg	w0, w3
  40:	lsr	x0, x11, x0
  44:	orr	x7, x0, x7
  48:	lsl	x11, x11, x3
  4c:	lsr	x1, x6, #32
  50:	and	x2, x6, #0xffffffff
  54:	udiv	x10, x7, x1
  58:	msub	x7, x10, x1, x7
  5c:	mov	x13, x10
  60:	mul	x12, x2, x10
  64:	extr	x7, x7, x11, #32
  68:	cmp	x12, x7
  6c:	b.ls	84 <__divmodti4+0x84>  // b.plast
  70:	add	x7, x7, x6
  74:	cmp	x12, x7
  78:	ccmp	x6, x7, #0x2, hi  // hi = pmore
  7c:	b.ls	114 <__divmodti4+0x114>  // b.plast
  80:	sub	x13, x10, #0x1
  84:	sub	x7, x7, x12
  88:	udiv	x10, x7, x1
  8c:	msub	x7, x10, x1, x7
  90:	mov	x0, x10
  94:	mul	x1, x2, x10
  98:	mov	x2, x11
  9c:	bfi	x2, x7, #32, #32
  a0:	cmp	x1, x2
  a4:	b.ls	bc <__divmodti4+0xbc>  // b.plast
  a8:	add	x2, x2, x6
  ac:	cmp	x1, x2
  b0:	ccmp	x6, x2, #0x2, hi  // hi = pmore
  b4:	b.ls	120 <__divmodti4+0x120>  // b.plast
  b8:	sub	x0, x10, #0x1
  bc:	sub	x2, x2, x1
  c0:	orr	x0, x0, x13, lsl #32
  c4:	lsr	x2, x2, x3
  c8:	mov	x7, #0x0                   	// #0
  cc:	mov	x1, x5
  d0:	cbz	x9, dc <__divmodti4+0xdc>
  d4:	negs	x0, x0
  d8:	ngc	x1, x5
  dc:	cbz	x8, e8 <__divmodti4+0xe8>
  e0:	negs	x2, x2
  e4:	ngc	x7, x7
  e8:	str	x2, [x4]
  ec:	str	x7, [x4, #8]
  f0:	ret
  f4:	negs	x0, x0
  f8:	ngc	x1, x1
  fc:	mov	x8, #0xffffffffffffffff    	// #-1
 100:	b	8 <__divmodti4+0x8>
 104:	mvn	x9, x8
 108:	negs	x2, x2
 10c:	ngc	x3, x3
 110:	b	10 <__divmodti4+0x10>
 114:	sub	x13, x10, #0x2
 118:	add	x7, x7, x6
 11c:	b	84 <__divmodti4+0x84>
 120:	sub	x0, x10, #0x2
 124:	add	x2, x2, x6
 128:	b	bc <__divmodti4+0xbc>
 12c:	cbnz	x2, 13c <__divmodti4+0x13c>
 130:	mov	x6, #0x1                   	// #1
 134:	mov	x0, #0x0                   	// #0
 138:	udiv	x6, x6, x0
 13c:	clz	x3, x6
 140:	cbnz	x3, 1c8 <__divmodti4+0x1c8>
 144:	sub	x7, x7, x6
 148:	mov	x5, #0x1                   	// #1
 14c:	lsr	x1, x6, #32
 150:	and	x2, x6, #0xffffffff
 154:	udiv	x10, x7, x1
 158:	msub	x7, x10, x1, x7
 15c:	mov	x13, x10
 160:	mul	x12, x2, x10
 164:	extr	x7, x7, x11, #32
 168:	cmp	x12, x7
 16c:	b.ls	184 <__divmodti4+0x184>  // b.plast
 170:	add	x7, x7, x6
 174:	cmp	x12, x7
 178:	ccmp	x6, x7, #0x2, hi  // hi = pmore
 17c:	b.ls	278 <__divmodti4+0x278>  // b.plast
 180:	sub	x13, x10, #0x1
 184:	sub	x7, x7, x12
 188:	udiv	x10, x7, x1
 18c:	msub	x7, x10, x1, x7
 190:	mov	x0, x10
 194:	mul	x1, x2, x10
 198:	mov	x2, x11
 19c:	bfi	x2, x7, #32, #32
 1a0:	cmp	x1, x2
 1a4:	b.ls	1bc <__divmodti4+0x1bc>  // b.plast
 1a8:	add	x2, x2, x6
 1ac:	cmp	x1, x2
 1b0:	ccmp	x6, x2, #0x2, hi  // hi = pmore
 1b4:	b.ls	284 <__divmodti4+0x284>  // b.plast
 1b8:	sub	x0, x10, #0x1
 1bc:	sub	x2, x2, x1
 1c0:	orr	x0, x0, x13, lsl #32
 1c4:	b	c4 <__divmodti4+0xc4>
 1c8:	lsl	x6, x6, x3
 1cc:	mov	x1, #0x40                  	// #64
 1d0:	sub	x1, x1, x3
 1d4:	lsr	x2, x7, x1
 1d8:	lsl	x0, x7, x3
 1dc:	lsr	x7, x11, x1
 1e0:	orr	x7, x7, x0
 1e4:	lsl	x11, x11, x3
 1e8:	lsr	x10, x6, #32
 1ec:	and	x12, x6, #0xffffffff
 1f0:	udiv	x13, x2, x10
 1f4:	msub	x2, x13, x10, x2
 1f8:	mov	x5, x13
 1fc:	mul	x14, x12, x13
 200:	extr	x0, x2, x7, #32
 204:	cmp	x14, x0
 208:	b.ls	220 <__divmodti4+0x220>  // b.plast
 20c:	add	x0, x0, x6
 210:	cmp	x14, x0
 214:	ccmp	x6, x0, #0x2, hi  // hi = pmore
 218:	b.ls	260 <__divmodti4+0x260>  // b.plast
 21c:	sub	x5, x13, #0x1
 220:	sub	x0, x0, x14
 224:	udiv	x13, x0, x10
 228:	msub	x0, x13, x10, x0
 22c:	mov	x1, x13
 230:	mul	x2, x12, x13
 234:	bfi	x7, x0, #32, #32
 238:	cmp	x2, x7
 23c:	b.ls	254 <__divmodti4+0x254>  // b.plast
 240:	add	x7, x7, x6
 244:	cmp	x2, x7
 248:	ccmp	x6, x7, #0x2, hi  // hi = pmore
 24c:	b.ls	26c <__divmodti4+0x26c>  // b.plast
 250:	sub	x1, x13, #0x1
 254:	sub	x7, x7, x2
 258:	orr	x5, x1, x5, lsl #32
 25c:	b	14c <__divmodti4+0x14c>
 260:	sub	x5, x13, #0x2
 264:	add	x0, x0, x6
 268:	b	220 <__divmodti4+0x220>
 26c:	sub	x1, x13, #0x2
 270:	add	x7, x7, x6
 274:	b	254 <__divmodti4+0x254>
 278:	sub	x13, x10, #0x2
 27c:	add	x7, x7, x6
 280:	b	184 <__divmodti4+0x184>
 284:	sub	x0, x10, #0x2
 288:	add	x2, x2, x6
 28c:	b	1bc <__divmodti4+0x1bc>
 290:	cmp	x3, x1
 294:	b.ls	2a8 <__divmodti4+0x2a8>  // b.plast
 298:	mov	x2, x0
 29c:	mov	x5, #0x0                   	// #0
 2a0:	mov	x0, #0x0                   	// #0
 2a4:	b	cc <__divmodti4+0xcc>
 2a8:	clz	x10, x3
 2ac:	cbnz	x10, 2e0 <__divmodti4+0x2e0>
 2b0:	cmp	x3, x1
 2b4:	mov	x0, x10
 2b8:	ccmp	x2, x11, #0x0, cs  // cs = hs, nlast
 2bc:	b.hi	2d4 <__divmodti4+0x2d4>  // b.pmore
 2c0:	sub	x6, x11, x2
 2c4:	cmp	x11, x6
 2c8:	sbc	x7, x1, x3
 2cc:	mov	x11, x6
 2d0:	mov	x0, #0x1                   	// #1
 2d4:	mov	x2, x11
 2d8:	mov	x5, x10
 2dc:	b	cc <__divmodti4+0xcc>
 2e0:	lsl	x5, x3, x10
 2e4:	mov	x1, #0x40                  	// #64
 2e8:	sub	x1, x1, x10
 2ec:	lsr	x12, x2, x1
 2f0:	orr	x12, x12, x5
 2f4:	lsl	x6, x2, x10
 2f8:	lsr	x0, x7, x1
 2fc:	lsl	x7, x7, x10
 300:	lsr	x2, x11, x1
 304:	orr	x7, x2, x7
 308:	lsl	x2, x11, x10
 30c:	lsr	x5, x12, #32
 310:	and	x11, x12, #0xffffffff
 314:	udiv	x13, x0, x5
 318:	msub	x3, x13, x5, x0
 31c:	mov	x0, x13
 320:	mul	x14, x11, x13
 324:	extr	x3, x3, x7, #32
 328:	cmp	x14, x3
 32c:	b.ls	344 <__divmodti4+0x344>  // b.plast
 330:	add	x3, x3, x12
 334:	cmp	x14, x3
 338:	ccmp	x12, x3, #0x2, hi  // hi = pmore
 33c:	b.ls	40c <__divmodti4+0x40c>  // b.plast
 340:	sub	x0, x13, #0x1
 344:	sub	x3, x3, x14
 348:	udiv	x13, x3, x5
 34c:	msub	x5, x13, x5, x3
 350:	mov	x3, x13
 354:	mul	x11, x11, x13
 358:	bfi	x7, x5, #32, #32
 35c:	cmp	x11, x7
 360:	b.ls	378 <__divmodti4+0x378>  // b.plast
 364:	add	x7, x7, x12
 368:	cmp	x11, x7
 36c:	ccmp	x12, x7, #0x2, hi  // hi = pmore
 370:	b.ls	418 <__divmodti4+0x418>  // b.plast
 374:	sub	x3, x13, #0x1
 378:	sub	x7, x7, x11
 37c:	orr	x0, x3, x0, lsl #32
 380:	mov	w3, w3
 384:	lsr	x5, x0, #32
 388:	and	x13, x6, #0xffffffff
 38c:	lsr	x14, x6, #32
 390:	mul	x11, x3, x13
 394:	mul	x13, x5, x13
 398:	mul	x5, x5, x14
 39c:	madd	x3, x3, x14, x13
 3a0:	add	x3, x3, x11, lsr #32
 3a4:	mov	x14, #0x100000000           	// #4294967296
 3a8:	add	x14, x5, x14
 3ac:	cmp	x13, x3
 3b0:	csel	x5, x14, x5, hi  // hi = pmore
 3b4:	add	x5, x5, x3, lsr #32
 3b8:	and	x11, x11, #0xffffffff
 3bc:	add	x3, x11, x3, lsl #32
 3c0:	cmp	x7, x5
 3c4:	b.cc	3d4 <__divmodti4+0x3d4>  // b.lo, b.ul, b.last
 3c8:	mov	x13, x3
 3cc:	ccmp	x2, x3, #0x2, eq  // eq = none
 3d0:	b.cs	3e8 <__divmodti4+0x3e8>  // b.hs, b.nlast
 3d4:	sub	x0, x0, #0x1
 3d8:	sub	x13, x3, x6
 3dc:	cmp	x3, x13
 3e0:	cinc	x12, x12, cc  // cc = lo, ul, last
 3e4:	sub	x5, x5, x12
 3e8:	sub	x3, x2, x13
 3ec:	cmp	x2, x3
 3f0:	sbc	x7, x7, x5
 3f4:	lsl	x1, x7, x1
 3f8:	lsr	x2, x3, x10
 3fc:	orr	x2, x1, x2
 400:	lsr	x7, x7, x10
 404:	mov	x5, #0x0                   	// #0
 408:	b	cc <__divmodti4+0xcc>
 40c:	sub	x0, x13, #0x2
 410:	add	x3, x3, x12
 414:	b	344 <__divmodti4+0x344>
 418:	sub	x3, x13, #0x2
 41c:	add	x7, x7, x12
 420:	b	378 <__divmodti4+0x378>

_udivdi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__udivti3>:
   0:	mov	x5, x0
   4:	mov	x4, x1
   8:	mov	x6, x2
   c:	mov	x1, x3
  10:	mov	x7, x0
  14:	mov	x0, x4
  18:	cbnz	x3, 214 <__udivti3+0x214>
  1c:	cmp	x2, x4
  20:	b.ls	c4 <__udivti3+0xc4>  // b.plast
  24:	clz	x3, x2
  28:	cbz	x3, 44 <__udivti3+0x44>
  2c:	lsl	x6, x2, x3
  30:	lsl	x4, x4, x3
  34:	neg	w0, w3
  38:	lsr	x0, x5, x0
  3c:	orr	x0, x0, x4
  40:	lsl	x7, x5, x3
  44:	lsr	x2, x6, #32
  48:	and	x3, x6, #0xffffffff
  4c:	udiv	x5, x0, x2
  50:	msub	x4, x5, x2, x0
  54:	mov	x0, x5
  58:	mul	x8, x3, x5
  5c:	extr	x4, x4, x7, #32
  60:	cmp	x8, x4
  64:	b.ls	7c <__udivti3+0x7c>  // b.plast
  68:	add	x4, x4, x6
  6c:	cmp	x8, x4
  70:	ccmp	x6, x4, #0x2, hi  // hi = pmore
  74:	b.ls	b8 <__udivti3+0xb8>  // b.plast
  78:	sub	x0, x5, #0x1
  7c:	sub	x4, x4, x8
  80:	udiv	x5, x4, x2
  84:	msub	x4, x5, x2, x4
  88:	mov	x2, x5
  8c:	mul	x3, x3, x5
  90:	bfi	x7, x4, #32, #32
  94:	cmp	x3, x7
  98:	b.ls	b0 <__udivti3+0xb0>  // b.plast
  9c:	add	x7, x6, x7
  a0:	cmp	x3, x7
  a4:	ccmp	x6, x7, #0x2, hi  // hi = pmore
  a8:	cinc	x2, x5, hi  // hi = pmore
  ac:	sub	x2, x2, #0x2
  b0:	orr	x0, x2, x0, lsl #32
  b4:	b	354 <__udivti3+0x354>
  b8:	sub	x0, x5, #0x2
  bc:	add	x4, x4, x6
  c0:	b	7c <__udivti3+0x7c>
  c4:	cbnz	x2, d4 <__udivti3+0xd4>
  c8:	mov	x6, #0x1                   	// #1
  cc:	mov	x0, #0x0                   	// #0
  d0:	udiv	x6, x6, x0
  d4:	clz	x0, x6
  d8:	cbnz	x0, 158 <__udivti3+0x158>
  dc:	sub	x4, x4, x6
  e0:	mov	x1, #0x1                   	// #1
  e4:	lsr	x2, x6, #32
  e8:	and	x3, x6, #0xffffffff
  ec:	udiv	x5, x4, x2
  f0:	msub	x4, x5, x2, x4
  f4:	mov	x0, x5
  f8:	mul	x8, x3, x5
  fc:	extr	x4, x4, x7, #32
 100:	cmp	x8, x4
 104:	b.ls	11c <__udivti3+0x11c>  // b.plast
 108:	add	x4, x4, x6
 10c:	cmp	x8, x4
 110:	ccmp	x6, x4, #0x2, hi  // hi = pmore
 114:	b.ls	208 <__udivti3+0x208>  // b.plast
 118:	sub	x0, x5, #0x1
 11c:	sub	x4, x4, x8
 120:	udiv	x5, x4, x2
 124:	msub	x4, x5, x2, x4
 128:	mov	x2, x5
 12c:	mul	x3, x3, x5
 130:	bfi	x7, x4, #32, #32
 134:	cmp	x3, x7
 138:	b.ls	150 <__udivti3+0x150>  // b.plast
 13c:	add	x7, x6, x7
 140:	cmp	x3, x7
 144:	ccmp	x6, x7, #0x2, hi  // hi = pmore
 148:	cinc	x2, x5, hi  // hi = pmore
 14c:	sub	x2, x2, #0x2
 150:	orr	x0, x2, x0, lsl #32
 154:	b	354 <__udivti3+0x354>
 158:	lsl	x6, x6, x0
 15c:	mov	x1, #0x40                  	// #64
 160:	sub	x1, x1, x0
 164:	lsr	x2, x4, x1
 168:	lsl	x4, x4, x0
 16c:	lsr	x1, x5, x1
 170:	orr	x4, x1, x4
 174:	lsl	x7, x5, x0
 178:	lsr	x3, x6, #32
 17c:	and	x5, x6, #0xffffffff
 180:	udiv	x8, x2, x3
 184:	msub	x2, x8, x3, x2
 188:	mov	x10, x8
 18c:	mul	x9, x5, x8
 190:	extr	x0, x2, x4, #32
 194:	cmp	x9, x0
 198:	b.ls	1b0 <__udivti3+0x1b0>  // b.plast
 19c:	add	x0, x0, x6
 1a0:	cmp	x9, x0
 1a4:	ccmp	x6, x0, #0x2, hi  // hi = pmore
 1a8:	b.ls	1f0 <__udivti3+0x1f0>  // b.plast
 1ac:	sub	x10, x8, #0x1
 1b0:	sub	x0, x0, x9
 1b4:	udiv	x8, x0, x3
 1b8:	msub	x0, x8, x3, x0
 1bc:	mov	x1, x8
 1c0:	mul	x2, x5, x8
 1c4:	bfi	x4, x0, #32, #32
 1c8:	cmp	x2, x4
 1cc:	b.ls	1e4 <__udivti3+0x1e4>  // b.plast
 1d0:	add	x4, x4, x6
 1d4:	cmp	x2, x4
 1d8:	ccmp	x6, x4, #0x2, hi  // hi = pmore
 1dc:	b.ls	1fc <__udivti3+0x1fc>  // b.plast
 1e0:	sub	x1, x8, #0x1
 1e4:	sub	x4, x4, x2
 1e8:	orr	x1, x1, x10, lsl #32
 1ec:	b	e4 <__udivti3+0xe4>
 1f0:	sub	x10, x8, #0x2
 1f4:	add	x0, x0, x6
 1f8:	b	1b0 <__udivti3+0x1b0>
 1fc:	sub	x1, x8, #0x2
 200:	add	x4, x4, x6
 204:	b	1e4 <__udivti3+0x1e4>
 208:	sub	x0, x5, #0x2
 20c:	add	x4, x4, x6
 210:	b	11c <__udivti3+0x11c>
 214:	cmp	x3, x4
 218:	b.hi	34c <__udivti3+0x34c>  // b.pmore
 21c:	clz	x1, x3
 220:	cbnz	x1, 230 <__udivti3+0x230>
 224:	ccmp	x2, x5, #0x0, cs  // cs = hs, nlast
 228:	cset	x0, ls  // ls = plast
 22c:	b	354 <__udivti3+0x354>
 230:	lsl	x3, x3, x1
 234:	mov	x0, #0x40                  	// #64
 238:	sub	x0, x0, x1
 23c:	lsr	x6, x2, x0
 240:	orr	x3, x6, x3
 244:	lsl	x2, x2, x1
 248:	lsr	x7, x4, x0
 24c:	lsl	x4, x4, x1
 250:	lsr	x0, x5, x0
 254:	orr	x4, x0, x4
 258:	lsr	x8, x3, #32
 25c:	and	x9, x3, #0xffffffff
 260:	udiv	x10, x7, x8
 264:	msub	x7, x10, x8, x7
 268:	mov	x0, x10
 26c:	mul	x11, x9, x10
 270:	extr	x6, x7, x4, #32
 274:	cmp	x11, x6
 278:	b.ls	290 <__udivti3+0x290>  // b.plast
 27c:	add	x6, x6, x3
 280:	cmp	x11, x6
 284:	ccmp	x3, x6, #0x2, hi  // hi = pmore
 288:	b.ls	334 <__udivti3+0x334>  // b.plast
 28c:	sub	x0, x10, #0x1
 290:	sub	x6, x6, x11
 294:	udiv	x10, x6, x8
 298:	msub	x6, x10, x8, x6
 29c:	mov	x7, x10
 2a0:	mul	x8, x9, x10
 2a4:	bfi	x4, x6, #32, #32
 2a8:	cmp	x8, x4
 2ac:	b.ls	2c4 <__udivti3+0x2c4>  // b.plast
 2b0:	add	x4, x4, x3
 2b4:	cmp	x8, x4
 2b8:	ccmp	x3, x4, #0x2, hi  // hi = pmore
 2bc:	b.ls	340 <__udivti3+0x340>  // b.plast
 2c0:	sub	x7, x10, #0x1
 2c4:	sub	x4, x4, x8
 2c8:	orr	x0, x7, x0, lsl #32
 2cc:	mov	w7, w7
 2d0:	lsr	x3, x0, #32
 2d4:	and	x6, x2, #0xffffffff
 2d8:	lsr	x2, x2, #32
 2dc:	mul	x8, x7, x6
 2e0:	mul	x6, x3, x6
 2e4:	mul	x3, x3, x2
 2e8:	madd	x2, x7, x2, x6
 2ec:	add	x2, x2, x8, lsr #32
 2f0:	mov	x7, #0x100000000           	// #4294967296
 2f4:	add	x7, x3, x7
 2f8:	cmp	x6, x2
 2fc:	csel	x3, x7, x3, hi  // hi = pmore
 300:	add	x3, x3, x2, lsr #32
 304:	cmp	x4, x3
 308:	b.cc	328 <__udivti3+0x328>  // b.lo, b.ul, b.last
 30c:	lsl	x5, x5, x1
 310:	and	x8, x8, #0xffffffff
 314:	add	x2, x8, x2, lsl #32
 318:	cmp	x5, x2
 31c:	mov	x1, #0x0                   	// #0
 320:	ccmp	x4, x3, #0x0, cc  // cc = lo, ul, last
 324:	b.ne	354 <__udivti3+0x354>  // b.any
 328:	sub	x0, x0, #0x1
 32c:	mov	x1, #0x0                   	// #0
 330:	b	354 <__udivti3+0x354>
 334:	sub	x0, x10, #0x2
 338:	add	x6, x6, x3
 33c:	b	290 <__udivti3+0x290>
 340:	sub	x7, x10, #0x2
 344:	add	x4, x4, x3
 348:	b	2c4 <__udivti3+0x2c4>
 34c:	mov	x1, #0x0                   	// #0
 350:	mov	x0, #0x0                   	// #0
 354:	ret

_umoddi3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__umodti3>:
   0:	mov	x5, x2
   4:	mov	x6, x0
   8:	mov	x4, x1
   c:	cbnz	x3, 1c4 <__umodti3+0x1c4>
  10:	cmp	x2, x1
  14:	b.ls	b0 <__umodti3+0xb0>  // b.plast
  18:	clz	x3, x2
  1c:	cbz	x3, 38 <__umodti3+0x38>
  20:	lsl	x5, x2, x3
  24:	lsl	x1, x1, x3
  28:	neg	w4, w3
  2c:	lsr	x4, x0, x4
  30:	orr	x4, x4, x1
  34:	lsl	x6, x0, x3
  38:	lsr	x2, x5, #32
  3c:	and	x0, x5, #0xffffffff
  40:	udiv	x7, x4, x2
  44:	msub	x1, x7, x2, x4
  48:	mul	x4, x0, x7
  4c:	extr	x1, x1, x6, #32
  50:	cmp	x4, x1
  54:	b.ls	6c <__umodti3+0x6c>  // b.plast
  58:	add	x1, x1, x5
  5c:	cmp	x4, x1
  60:	add	x7, x1, x5
  64:	ccmp	x5, x1, #0x2, hi  // hi = pmore
  68:	csel	x1, x7, x1, ls  // ls = plast
  6c:	sub	x1, x1, x4
  70:	udiv	x4, x1, x2
  74:	msub	x1, x4, x2, x1
  78:	mul	x2, x0, x4
  7c:	mov	x0, x6
  80:	bfi	x0, x1, #32, #32
  84:	cmp	x2, x0
  88:	b.ls	a0 <__umodti3+0xa0>  // b.plast
  8c:	add	x0, x0, x5
  90:	cmp	x2, x0
  94:	add	x1, x0, x5
  98:	ccmp	x5, x0, #0x2, hi  // hi = pmore
  9c:	csel	x0, x1, x0, ls  // ls = plast
  a0:	sub	x0, x0, x2
  a4:	lsr	x0, x0, x3
  a8:	mov	x1, #0x0                   	// #0
  ac:	ret
  b0:	cbnz	x2, bc <__umodti3+0xbc>
  b4:	mov	x5, #0x1                   	// #1
  b8:	udiv	x5, x5, x2
  bc:	clz	x3, x5
  c0:	cbnz	x3, 138 <__umodti3+0x138>
  c4:	sub	x1, x1, x5
  c8:	lsr	x2, x5, #32
  cc:	and	x0, x5, #0xffffffff
  d0:	udiv	x4, x1, x2
  d4:	msub	x1, x4, x2, x1
  d8:	mul	x4, x0, x4
  dc:	extr	x1, x1, x6, #32
  e0:	cmp	x4, x1
  e4:	b.ls	fc <__umodti3+0xfc>  // b.plast
  e8:	add	x1, x1, x5
  ec:	cmp	x4, x1
  f0:	add	x7, x1, x5
  f4:	ccmp	x5, x1, #0x2, hi  // hi = pmore
  f8:	csel	x1, x7, x1, ls  // ls = plast
  fc:	sub	x1, x1, x4
 100:	udiv	x4, x1, x2
 104:	msub	x1, x4, x2, x1
 108:	mul	x2, x0, x4
 10c:	mov	x0, x6
 110:	bfi	x0, x1, #32, #32
 114:	cmp	x2, x0
 118:	b.ls	130 <__umodti3+0x130>  // b.plast
 11c:	add	x0, x0, x5
 120:	cmp	x2, x0
 124:	add	x1, x0, x5
 128:	ccmp	x5, x0, #0x2, hi  // hi = pmore
 12c:	csel	x0, x1, x0, ls  // ls = plast
 130:	sub	x0, x0, x2
 134:	b	a4 <__umodti3+0xa4>
 138:	lsl	x5, x5, x3
 13c:	mov	x2, #0x40                  	// #64
 140:	sub	x2, x2, x3
 144:	lsr	x4, x1, x2
 148:	lsl	x1, x1, x3
 14c:	lsr	x2, x0, x2
 150:	orr	x1, x2, x1
 154:	lsl	x6, x0, x3
 158:	lsr	x2, x5, #32
 15c:	and	x7, x5, #0xffffffff
 160:	udiv	x0, x4, x2
 164:	msub	x4, x0, x2, x4
 168:	mul	x8, x7, x0
 16c:	extr	x0, x4, x1, #32
 170:	cmp	x8, x0
 174:	b.ls	18c <__umodti3+0x18c>  // b.plast
 178:	add	x0, x0, x5
 17c:	cmp	x8, x0
 180:	add	x4, x0, x5
 184:	ccmp	x5, x0, #0x2, hi  // hi = pmore
 188:	csel	x0, x4, x0, ls  // ls = plast
 18c:	sub	x0, x0, x8
 190:	udiv	x4, x0, x2
 194:	msub	x0, x4, x2, x0
 198:	mul	x2, x7, x4
 19c:	bfi	x1, x0, #32, #32
 1a0:	cmp	x2, x1
 1a4:	b.ls	1bc <__umodti3+0x1bc>  // b.plast
 1a8:	add	x1, x1, x5
 1ac:	cmp	x2, x1
 1b0:	add	x0, x1, x5
 1b4:	ccmp	x5, x1, #0x2, hi  // hi = pmore
 1b8:	csel	x1, x0, x1, ls  // ls = plast
 1bc:	sub	x1, x1, x2
 1c0:	b	c8 <__umodti3+0xc8>
 1c4:	cmp	x3, x1
 1c8:	b.hi	ac <__umodti3+0xac>  // b.pmore
 1cc:	clz	x7, x3
 1d0:	cbnz	x7, 1f8 <__umodti3+0x1f8>
 1d4:	ccmp	x2, x0, #0x0, cs  // cs = hs, nlast
 1d8:	b.hi	1ec <__umodti3+0x1ec>  // b.pmore
 1dc:	sub	x2, x0, x2
 1e0:	cmp	x0, x2
 1e4:	sbc	x4, x1, x3
 1e8:	mov	x6, x2
 1ec:	mov	x0, x6
 1f0:	mov	x1, x4
 1f4:	b	ac <__umodti3+0xac>
 1f8:	lsl	x3, x3, x7
 1fc:	mov	x8, #0x40                  	// #64
 200:	sub	x8, x8, x7
 204:	lsr	x6, x2, x8
 208:	orr	x6, x6, x3
 20c:	lsl	x3, x2, x7
 210:	lsr	x2, x1, x8
 214:	lsl	x1, x1, x7
 218:	lsr	x4, x0, x8
 21c:	orr	x1, x4, x1
 220:	lsl	x0, x0, x7
 224:	lsr	x5, x6, #32
 228:	and	x9, x6, #0xffffffff
 22c:	udiv	x10, x2, x5
 230:	msub	x4, x10, x5, x2
 234:	mov	x2, x10
 238:	mul	x11, x9, x10
 23c:	extr	x4, x4, x1, #32
 240:	cmp	x11, x4
 244:	b.ls	25c <__umodti3+0x25c>  // b.plast
 248:	add	x4, x4, x6
 24c:	cmp	x11, x4
 250:	ccmp	x6, x4, #0x2, hi  // hi = pmore
 254:	b.ls	31c <__umodti3+0x31c>  // b.plast
 258:	sub	x2, x10, #0x1
 25c:	sub	x4, x4, x11
 260:	udiv	x10, x4, x5
 264:	msub	x5, x10, x5, x4
 268:	mov	x4, x10
 26c:	mul	x9, x9, x10
 270:	bfi	x1, x5, #32, #32
 274:	cmp	x9, x1
 278:	b.ls	290 <__umodti3+0x290>  // b.plast
 27c:	add	x1, x1, x6
 280:	cmp	x9, x1
 284:	ccmp	x6, x1, #0x2, hi  // hi = pmore
 288:	b.ls	328 <__umodti3+0x328>  // b.plast
 28c:	sub	x4, x10, #0x1
 290:	sub	x1, x1, x9
 294:	orr	x2, x4, x2, lsl #32
 298:	mov	w4, w4
 29c:	lsr	x2, x2, #32
 2a0:	and	x9, x3, #0xffffffff
 2a4:	lsr	x5, x3, #32
 2a8:	mul	x10, x4, x9
 2ac:	mul	x9, x2, x9
 2b0:	mul	x2, x2, x5
 2b4:	madd	x4, x4, x5, x9
 2b8:	add	x5, x4, x10, lsr #32
 2bc:	mov	x4, #0x100000000           	// #4294967296
 2c0:	add	x4, x2, x4
 2c4:	cmp	x9, x5
 2c8:	csel	x2, x4, x2, hi  // hi = pmore
 2cc:	add	x4, x2, x5, lsr #32
 2d0:	and	x10, x10, #0xffffffff
 2d4:	add	x5, x10, x5, lsl #32
 2d8:	cmp	x1, x4
 2dc:	b.cc	2ec <__umodti3+0x2ec>  // b.lo, b.ul, b.last
 2e0:	mov	x2, x5
 2e4:	ccmp	x0, x5, #0x2, eq  // eq = none
 2e8:	b.cs	2fc <__umodti3+0x2fc>  // b.hs, b.nlast
 2ec:	sub	x2, x5, x3
 2f0:	cmp	x5, x2
 2f4:	cinc	x3, x6, cc  // cc = lo, ul, last
 2f8:	sub	x4, x4, x3
 2fc:	sub	x2, x0, x2
 300:	cmp	x0, x2
 304:	sbc	x1, x1, x4
 308:	lsl	x8, x1, x8
 30c:	lsr	x0, x2, x7
 310:	orr	x0, x8, x0
 314:	lsr	x1, x1, x7
 318:	b	ac <__umodti3+0xac>
 31c:	sub	x2, x10, #0x2
 320:	add	x4, x4, x6
 324:	b	25c <__umodti3+0x25c>
 328:	sub	x4, x10, #0x2
 32c:	add	x1, x1, x6
 330:	b	290 <__umodti3+0x290>

_udivmoddi4.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__udivmodti4>:
   0:	mov	x8, x0
   4:	mov	x5, x1
   8:	mov	x9, x2
   c:	mov	x1, x3
  10:	mov	x7, x0
  14:	mov	x6, x5
  18:	cbnz	x3, 24c <__udivmodti4+0x24c>
  1c:	cmp	x2, x5
  20:	b.ls	e8 <__udivmodti4+0xe8>  // b.plast
  24:	clz	x3, x2
  28:	cbz	x3, 44 <__udivmodti4+0x44>
  2c:	lsl	x9, x2, x3
  30:	lsl	x5, x5, x3
  34:	neg	w6, w3
  38:	lsr	x6, x0, x6
  3c:	orr	x6, x6, x5
  40:	lsl	x7, x0, x3
  44:	lsr	x5, x9, #32
  48:	and	x2, x9, #0xffffffff
  4c:	udiv	x8, x6, x5
  50:	msub	x6, x8, x5, x6
  54:	mov	x11, x8
  58:	mul	x10, x2, x8
  5c:	extr	x6, x6, x7, #32
  60:	cmp	x10, x6
  64:	b.ls	7c <__udivmodti4+0x7c>  // b.plast
  68:	add	x6, x6, x9
  6c:	cmp	x10, x6
  70:	ccmp	x9, x6, #0x2, hi  // hi = pmore
  74:	b.ls	d0 <__udivmodti4+0xd0>  // b.plast
  78:	sub	x11, x8, #0x1
  7c:	sub	x6, x6, x10
  80:	udiv	x8, x6, x5
  84:	msub	x6, x8, x5, x6
  88:	mov	x0, x8
  8c:	mul	x5, x2, x8
  90:	mov	x2, x7
  94:	bfi	x2, x6, #32, #32
  98:	cmp	x5, x2
  9c:	b.ls	b4 <__udivmodti4+0xb4>  // b.plast
  a0:	add	x2, x2, x9
  a4:	cmp	x5, x2
  a8:	ccmp	x9, x2, #0x2, hi  // hi = pmore
  ac:	b.ls	dc <__udivmodti4+0xdc>  // b.plast
  b0:	sub	x0, x8, #0x1
  b4:	sub	x2, x2, x5
  b8:	orr	x0, x0, x11, lsl #32
  bc:	cbz	x4, cc <__udivmodti4+0xcc>
  c0:	lsr	x2, x2, x3
  c4:	str	x2, [x4]
  c8:	str	xzr, [x4, #8]
  cc:	ret
  d0:	sub	x11, x8, #0x2
  d4:	add	x6, x6, x9
  d8:	b	7c <__udivmodti4+0x7c>
  dc:	sub	x0, x8, #0x2
  e0:	add	x2, x2, x9
  e4:	b	b4 <__udivmodti4+0xb4>
  e8:	cbnz	x2, f8 <__udivmodti4+0xf8>
  ec:	mov	x9, #0x1                   	// #1
  f0:	mov	x0, #0x0                   	// #0
  f4:	udiv	x9, x9, x0
  f8:	clz	x3, x9
  fc:	cbnz	x3, 184 <__udivmodti4+0x184>
 100:	sub	x5, x5, x9
 104:	mov	x1, #0x1                   	// #1
 108:	lsr	x6, x9, #32
 10c:	and	x2, x9, #0xffffffff
 110:	udiv	x8, x5, x6
 114:	msub	x5, x8, x6, x5
 118:	mov	x11, x8
 11c:	mul	x10, x2, x8
 120:	extr	x5, x5, x7, #32
 124:	cmp	x10, x5
 128:	b.ls	140 <__udivmodti4+0x140>  // b.plast
 12c:	add	x5, x5, x9
 130:	cmp	x10, x5
 134:	ccmp	x9, x5, #0x2, hi  // hi = pmore
 138:	b.ls	234 <__udivmodti4+0x234>  // b.plast
 13c:	sub	x11, x8, #0x1
 140:	sub	x5, x5, x10
 144:	udiv	x8, x5, x6
 148:	msub	x5, x8, x6, x5
 14c:	mov	x0, x8
 150:	mul	x6, x2, x8
 154:	mov	x2, x7
 158:	bfi	x2, x5, #32, #32
 15c:	cmp	x6, x2
 160:	b.ls	178 <__udivmodti4+0x178>  // b.plast
 164:	add	x2, x2, x9
 168:	cmp	x6, x2
 16c:	ccmp	x9, x2, #0x2, hi  // hi = pmore
 170:	b.ls	240 <__udivmodti4+0x240>  // b.plast
 174:	sub	x0, x8, #0x1
 178:	sub	x2, x2, x6
 17c:	orr	x0, x0, x11, lsl #32
 180:	b	bc <__udivmodti4+0xbc>
 184:	lsl	x9, x9, x3
 188:	mov	x2, #0x40                  	// #64
 18c:	sub	x2, x2, x3
 190:	lsr	x6, x5, x2
 194:	lsl	x1, x5, x3
 198:	lsr	x5, x8, x2
 19c:	orr	x5, x5, x1
 1a0:	lsl	x7, x8, x3
 1a4:	lsr	x2, x9, #32
 1a8:	and	x8, x9, #0xffffffff
 1ac:	udiv	x10, x6, x2
 1b0:	msub	x6, x10, x2, x6
 1b4:	mov	x12, x10
 1b8:	mul	x11, x8, x10
 1bc:	extr	x0, x6, x5, #32
 1c0:	cmp	x11, x0
 1c4:	b.ls	1dc <__udivmodti4+0x1dc>  // b.plast
 1c8:	add	x0, x0, x9
 1cc:	cmp	x11, x0
 1d0:	ccmp	x9, x0, #0x2, hi  // hi = pmore
 1d4:	b.ls	21c <__udivmodti4+0x21c>  // b.plast
 1d8:	sub	x12, x10, #0x1
 1dc:	sub	x0, x0, x11
 1e0:	udiv	x6, x0, x2
 1e4:	msub	x0, x6, x2, x0
 1e8:	mov	x1, x6
 1ec:	mul	x2, x8, x6
 1f0:	bfi	x5, x0, #32, #32
 1f4:	cmp	x2, x5
 1f8:	b.ls	210 <__udivmodti4+0x210>  // b.plast
 1fc:	add	x5, x5, x9
 200:	cmp	x2, x5
 204:	ccmp	x9, x5, #0x2, hi  // hi = pmore
 208:	b.ls	228 <__udivmodti4+0x228>  // b.plast
 20c:	sub	x1, x6, #0x1
 210:	sub	x5, x5, x2
 214:	orr	x1, x1, x12, lsl #32
 218:	b	108 <__udivmodti4+0x108>
 21c:	sub	x12, x10, #0x2
 220:	add	x0, x0, x9
 224:	b	1dc <__udivmodti4+0x1dc>
 228:	sub	x1, x6, #0x2
 22c:	add	x5, x5, x9
 230:	b	210 <__udivmodti4+0x210>
 234:	sub	x11, x8, #0x2
 238:	add	x5, x5, x9
 23c:	b	140 <__udivmodti4+0x140>
 240:	sub	x0, x8, #0x2
 244:	add	x2, x2, x9
 248:	b	178 <__udivmodti4+0x178>
 24c:	cmp	x3, x5
 250:	b.ls	26c <__udivmodti4+0x26c>  // b.plast
 254:	cbz	x4, 3f8 <__udivmodti4+0x3f8>
 258:	str	x0, [x4]
 25c:	str	x5, [x4, #8]
 260:	mov	x1, #0x0                   	// #0
 264:	mov	x0, #0x0                   	// #0
 268:	b	cc <__udivmodti4+0xcc>
 26c:	clz	x9, x3
 270:	cbnz	x9, 2a8 <__udivmodti4+0x2a8>
 274:	mov	x0, x9
 278:	ccmp	x2, x8, #0x0, cs  // cs = hs, nlast
 27c:	b.hi	294 <__udivmodti4+0x294>  // b.pmore
 280:	sub	x2, x8, x2
 284:	cmp	x8, x2
 288:	sbc	x6, x5, x3
 28c:	mov	x7, x2
 290:	mov	x0, #0x1                   	// #1
 294:	mov	x1, x9
 298:	cbz	x4, cc <__udivmodti4+0xcc>
 29c:	str	x7, [x4]
 2a0:	str	x6, [x4, #8]
 2a4:	b	cc <__udivmodti4+0xcc>
 2a8:	lsl	x3, x3, x9
 2ac:	mov	x7, #0x40                  	// #64
 2b0:	sub	x7, x7, x9
 2b4:	lsr	x0, x2, x7
 2b8:	orr	x3, x0, x3
 2bc:	lsl	x2, x2, x9
 2c0:	lsr	x6, x5, x7
 2c4:	lsl	x5, x5, x9
 2c8:	lsr	x1, x8, x7
 2cc:	orr	x5, x1, x5
 2d0:	lsl	x8, x8, x9
 2d4:	lsr	x10, x3, #32
 2d8:	and	x11, x3, #0xffffffff
 2dc:	udiv	x12, x6, x10
 2e0:	msub	x6, x12, x10, x6
 2e4:	mov	x0, x12
 2e8:	mul	x13, x11, x12
 2ec:	extr	x1, x6, x5, #32
 2f0:	cmp	x13, x1
 2f4:	b.ls	30c <__udivmodti4+0x30c>  // b.plast
 2f8:	add	x1, x1, x3
 2fc:	cmp	x13, x1
 300:	ccmp	x3, x1, #0x2, hi  // hi = pmore
 304:	b.ls	3e0 <__udivmodti4+0x3e0>  // b.plast
 308:	sub	x0, x12, #0x1
 30c:	sub	x1, x1, x13
 310:	udiv	x12, x1, x10
 314:	msub	x10, x12, x10, x1
 318:	mov	x1, x12
 31c:	mul	x6, x11, x12
 320:	bfi	x5, x10, #32, #32
 324:	cmp	x6, x5
 328:	b.ls	340 <__udivmodti4+0x340>  // b.plast
 32c:	add	x5, x5, x3
 330:	cmp	x6, x5
 334:	ccmp	x3, x5, #0x2, hi  // hi = pmore
 338:	b.ls	3ec <__udivmodti4+0x3ec>  // b.plast
 33c:	sub	x1, x12, #0x1
 340:	sub	x5, x5, x6
 344:	orr	x0, x1, x0, lsl #32
 348:	mov	w1, w1
 34c:	lsr	x6, x0, #32
 350:	and	x10, x2, #0xffffffff
 354:	lsr	x12, x2, #32
 358:	mul	x11, x1, x10
 35c:	mul	x10, x6, x10
 360:	mul	x6, x6, x12
 364:	madd	x1, x1, x12, x10
 368:	add	x1, x1, x11, lsr #32
 36c:	mov	x12, #0x100000000           	// #4294967296
 370:	add	x12, x6, x12
 374:	cmp	x10, x1
 378:	csel	x6, x12, x6, hi  // hi = pmore
 37c:	add	x6, x6, x1, lsr #32
 380:	and	x11, x11, #0xffffffff
 384:	add	x1, x11, x1, lsl #32
 388:	cmp	x5, x6
 38c:	b.cc	39c <__udivmodti4+0x39c>  // b.lo, b.ul, b.last
 390:	mov	x10, x1
 394:	ccmp	x8, x1, #0x2, eq  // eq = none
 398:	b.cs	3b0 <__udivmodti4+0x3b0>  // b.hs, b.nlast
 39c:	sub	x0, x0, #0x1
 3a0:	sub	x10, x1, x2
 3a4:	cmp	x1, x10
 3a8:	cinc	x3, x3, cc  // cc = lo, ul, last
 3ac:	sub	x6, x6, x3
 3b0:	mov	x1, #0x0                   	// #0
 3b4:	cbz	x4, cc <__udivmodti4+0xcc>
 3b8:	sub	x10, x8, x10
 3bc:	cmp	x8, x10
 3c0:	sbc	x5, x5, x6
 3c4:	lsl	x7, x5, x7
 3c8:	lsr	x10, x10, x9
 3cc:	orr	x7, x7, x10
 3d0:	lsr	x5, x5, x9
 3d4:	str	x7, [x4]
 3d8:	str	x5, [x4, #8]
 3dc:	b	cc <__udivmodti4+0xcc>
 3e0:	sub	x0, x12, #0x2
 3e4:	add	x1, x1, x3
 3e8:	b	30c <__udivmodti4+0x30c>
 3ec:	sub	x1, x12, #0x2
 3f0:	add	x5, x5, x3
 3f4:	b	340 <__udivmodti4+0x340>
 3f8:	mov	x1, #0x0                   	// #0
 3fc:	mov	x0, #0x0                   	// #0
 400:	b	cc <__udivmodti4+0xcc>

_udiv_w_sdiv.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__udiv_w_sdiv>:
   0:	mov	x0, #0x0                   	// #0
   4:	ret

sync-cache.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__aarch64_sync_cache_range>:
   0:	adrp	x2, 0 <__aarch64_sync_cache_range>
   4:	ldr	w2, [x2]
   8:	cbnz	w2, 18 <__aarch64_sync_cache_range+0x18>
   c:	mrs	x3, ctr_el0
  10:	adrp	x2, 0 <__aarch64_sync_cache_range>
  14:	str	w3, [x2]
  18:	adrp	x2, 0 <__aarch64_sync_cache_range>
  1c:	ldr	w5, [x2]
  20:	and	w2, w5, #0xf
  24:	mov	w3, #0x4                   	// #4
  28:	lsl	w4, w3, w2
  2c:	ubfx	x5, x5, #16, #4
  30:	lsl	w3, w3, w5
  34:	sub	w2, w3, #0x1
  38:	bic	x2, x0, x2
  3c:	cmp	x2, x1
  40:	b.cs	58 <__aarch64_sync_cache_range+0x58>  // b.hs, b.nlast
  44:	mov	w3, w3
  48:	dc	cvau, x2
  4c:	add	x2, x2, x3
  50:	cmp	x1, x2
  54:	b.hi	48 <__aarch64_sync_cache_range+0x48>  // b.pmore
  58:	dsb	ish
  5c:	sub	w2, w4, #0x1
  60:	bic	x0, x0, x2
  64:	cmp	x1, x0
  68:	b.ls	80 <__aarch64_sync_cache_range+0x80>  // b.plast
  6c:	mov	w2, w4
  70:	ic	ivau, x0
  74:	add	x0, x0, x2
  78:	cmp	x1, x0
  7c:	b.hi	70 <__aarch64_sync_cache_range+0x70>  // b.pmore
  80:	dsb	ish
  84:	isb
  88:	ret

sfp-exceptions.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__sfp_handle_exceptions>:
   0:	tbz	w0, #0, 10 <__sfp_handle_exceptions+0x10>
   4:	movi	v1.2s, #0x0
   8:	fdiv	s0, s1, s1
   c:	mrs	x1, fpsr
  10:	tbz	w0, #1, 24 <__sfp_handle_exceptions+0x24>
  14:	fmov	s1, #1.000000000000000000e+00
  18:	movi	v2.2s, #0x0
  1c:	fdiv	s0, s1, s2
  20:	mrs	x1, fpsr
  24:	tbz	w0, #2, 44 <__sfp_handle_exceptions+0x44>
  28:	mov	w1, #0x7f7fffff            	// #2139095039
  2c:	fmov	s1, w1
  30:	mov	w1, #0xc5ae                	// #50606
  34:	movk	w1, #0x749d, lsl #16
  38:	fmov	s2, w1
  3c:	fadd	s0, s1, s2
  40:	mrs	x1, fpsr
  44:	tbz	w0, #3, 54 <__sfp_handle_exceptions+0x54>
  48:	movi	v1.2s, #0x80, lsl #16
  4c:	fmul	s0, s1, s1
  50:	mrs	x1, fpsr
  54:	tbz	w0, #4, 6c <__sfp_handle_exceptions+0x6c>
  58:	mov	w0, #0x7f7fffff            	// #2139095039
  5c:	fmov	s1, w0
  60:	fmov	s2, #1.000000000000000000e+00
  64:	fsub	s0, s1, s2
  68:	mrs	x0, fpsr
  6c:	ret

addtf3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__addtf3>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	q0, [sp, #16]
   c:	ldr	x6, [sp, #16]
  10:	ldr	x4, [sp, #24]
  14:	str	q1, [sp, #16]
  18:	ldr	x7, [sp, #16]
  1c:	ldr	x0, [sp, #24]
  20:	mrs	x11, fpcr
  24:	ubfx	x5, x4, #48, #15
  28:	mov	x9, x5
  2c:	lsr	x10, x4, #63
  30:	ubfiz	x1, x4, #3, #48
  34:	orr	x1, x1, x6, lsr #61
  38:	lsl	x3, x6, #3
  3c:	ubfx	x8, x0, #48, #15
  40:	mov	x13, x8
  44:	lsr	x14, x0, #63
  48:	ubfiz	x0, x0, #3, #48
  4c:	orr	x2, x0, x7, lsr #61
  50:	lsl	x12, x7, #3
  54:	cmp	x14, x4, lsr #63
  58:	b.eq	a0 <__addtf3+0xa0>  // b.none
  5c:	sub	w0, w5, w8
  60:	cmp	w0, #0x0
  64:	b.le	608 <__addtf3+0x608>
  68:	cbnz	x8, 4f8 <__addtf3+0x4f8>
  6c:	orr	x4, x2, x12
  70:	cbz	x4, 4c0 <__addtf3+0x4c0>
  74:	subs	w0, w0, #0x1
  78:	b.eq	4e8 <__addtf3+0x4e8>  // b.none
  7c:	mov	x4, #0x7fff                	// #32767
  80:	cmp	x5, x4
  84:	b.ne	508 <__addtf3+0x508>  // b.any
  88:	orr	x0, x1, x3
  8c:	cbz	x0, c08 <__addtf3+0xc08>
  90:	lsr	x0, x1, #50
  94:	eor	x0, x0, #0x1
  98:	and	w0, w0, #0x1
  9c:	b	ab4 <__addtf3+0xab4>
  a0:	sub	w0, w5, w8
  a4:	cmp	w0, #0x0
  a8:	b.le	1e4 <__addtf3+0x1e4>
  ac:	cbnz	x8, 118 <__addtf3+0x118>
  b0:	orr	x4, x2, x12
  b4:	cbz	x4, e4 <__addtf3+0xe4>
  b8:	subs	w0, w0, #0x1
  bc:	b.eq	10c <__addtf3+0x10c>  // b.none
  c0:	mov	x4, #0x7fff                	// #32767
  c4:	cmp	x5, x4
  c8:	b.ne	128 <__addtf3+0x128>  // b.any
  cc:	orr	x0, x1, x3
  d0:	cbz	x0, b54 <__addtf3+0xb54>
  d4:	lsr	x0, x1, #50
  d8:	eor	x0, x0, #0x1
  dc:	and	w0, w0, #0x1
  e0:	b	ab4 <__addtf3+0xab4>
  e4:	mov	x4, x3
  e8:	mov	x0, #0x7fff                	// #32767
  ec:	cmp	x5, x0
  f0:	b.ne	978 <__addtf3+0x978>  // b.any
  f4:	orr	x0, x1, x3
  f8:	cbz	x0, b44 <__addtf3+0xb44>
  fc:	lsr	x0, x1, #50
 100:	eor	x0, x0, #0x1
 104:	and	w0, w0, #0x1
 108:	b	ab4 <__addtf3+0xab4>
 10c:	adds	x4, x3, x12
 110:	adc	x1, x2, x1
 114:	b	168 <__addtf3+0x168>
 118:	orr	x2, x2, #0x8000000000000
 11c:	mov	x4, #0x7fff                	// #32767
 120:	cmp	x5, x4
 124:	b.eq	198 <__addtf3+0x198>  // b.none
 128:	cmp	w0, #0x74
 12c:	b.gt	b00 <__addtf3+0xb00>
 130:	cmp	w0, #0x3f
 134:	b.gt	1b0 <__addtf3+0x1b0>
 138:	mov	w5, #0x40                  	// #64
 13c:	sub	w5, w5, w0
 140:	lsl	x4, x2, x5
 144:	lsr	x6, x12, x0
 148:	orr	x4, x4, x6
 14c:	lsl	x5, x12, x5
 150:	cmp	x5, #0x0
 154:	cset	x5, ne  // ne = any
 158:	orr	x4, x4, x5
 15c:	lsr	x0, x2, x0
 160:	adds	x4, x4, x3
 164:	adc	x1, x0, x1
 168:	tbz	x1, #51, 978 <__addtf3+0x978>
 16c:	add	x9, x9, #0x1
 170:	mov	x0, #0x7fff                	// #32767
 174:	cmp	x9, x0
 178:	b.eq	488 <__addtf3+0x488>  // b.none
 17c:	and	x0, x1, #0xfff7ffffffffffff
 180:	and	x3, x4, #0x1
 184:	orr	x3, x3, x4, lsr #1
 188:	orr	x3, x3, x1, lsl #63
 18c:	lsr	x1, x0, #1
 190:	mov	w0, #0x0                   	// #0
 194:	b	ab4 <__addtf3+0xab4>
 198:	orr	x0, x1, x3
 19c:	cbz	x0, b64 <__addtf3+0xb64>
 1a0:	lsr	x0, x1, #50
 1a4:	eor	x0, x0, #0x1
 1a8:	and	w0, w0, #0x1
 1ac:	b	ab4 <__addtf3+0xab4>
 1b0:	sub	w4, w0, #0x40
 1b4:	lsr	x4, x2, x4
 1b8:	mov	w5, #0x80                  	// #128
 1bc:	sub	w5, w5, w0
 1c0:	lsl	x2, x2, x5
 1c4:	cmp	w0, #0x40
 1c8:	csel	x0, x2, xzr, ne  // ne = any
 1cc:	orr	x12, x0, x12
 1d0:	cmp	x12, #0x0
 1d4:	cset	x0, ne  // ne = any
 1d8:	orr	x4, x4, x0
 1dc:	mov	x0, #0x0                   	// #0
 1e0:	b	160 <__addtf3+0x160>
 1e4:	tbnz	w0, #31, 228 <__addtf3+0x228>
 1e8:	add	x0, x5, #0x1
 1ec:	tst	x0, #0x7ffe
 1f0:	b.ne	428 <__addtf3+0x428>  // b.any
 1f4:	cbnz	x5, 374 <__addtf3+0x374>
 1f8:	orr	x0, x1, x3
 1fc:	cbz	x0, af4 <__addtf3+0xaf4>
 200:	orr	x0, x2, x12
 204:	cbz	x0, c68 <__addtf3+0xc68>
 208:	adds	x4, x3, x12
 20c:	adc	x1, x2, x1
 210:	tbz	x1, #51, 97c <__addtf3+0x97c>
 214:	and	x1, x1, #0xfff7ffffffffffff
 218:	mov	x3, x4
 21c:	mov	x9, #0x1                   	// #1
 220:	mov	w0, #0x0                   	// #0
 224:	b	ab4 <__addtf3+0xab4>
 228:	cbnz	x5, 2c0 <__addtf3+0x2c0>
 22c:	orr	x4, x1, x3
 230:	cbz	x4, 270 <__addtf3+0x270>
 234:	cmn	w0, #0x1
 238:	b.eq	2b0 <__addtf3+0x2b0>  // b.none
 23c:	mvn	w0, w0
 240:	mov	x4, #0x7fff                	// #32767
 244:	cmp	x8, x4
 248:	b.ne	2d4 <__addtf3+0x2d4>  // b.any
 24c:	orr	x3, x2, x12
 250:	cbz	x3, b80 <__addtf3+0xb80>
 254:	lsr	x0, x2, #50
 258:	eor	x0, x0, #0x1
 25c:	and	w0, w0, #0x1
 260:	mov	x1, x2
 264:	mov	x3, x12
 268:	mov	x9, x8
 26c:	b	ab4 <__addtf3+0xab4>
 270:	mov	x0, #0x7fff                	// #32767
 274:	cmp	x8, x0
 278:	b.eq	28c <__addtf3+0x28c>  // b.none
 27c:	mov	x1, x2
 280:	mov	x4, x12
 284:	mov	x9, x8
 288:	b	978 <__addtf3+0x978>
 28c:	orr	x3, x2, x12
 290:	cbz	x3, b74 <__addtf3+0xb74>
 294:	lsr	x0, x2, #50
 298:	eor	x0, x0, #0x1
 29c:	and	w0, w0, #0x1
 2a0:	mov	x1, x2
 2a4:	mov	x3, x12
 2a8:	mov	x9, x8
 2ac:	b	ab4 <__addtf3+0xab4>
 2b0:	adds	x4, x3, x12
 2b4:	adc	x1, x2, x1
 2b8:	mov	x9, x8
 2bc:	b	168 <__addtf3+0x168>
 2c0:	neg	w0, w0
 2c4:	orr	x1, x1, #0x8000000000000
 2c8:	mov	x4, #0x7fff                	// #32767
 2cc:	cmp	x8, x4
 2d0:	b.eq	31c <__addtf3+0x31c>  // b.none
 2d4:	cmp	w0, #0x74
 2d8:	b.gt	b0c <__addtf3+0xb0c>
 2dc:	cmp	w0, #0x3f
 2e0:	b.gt	340 <__addtf3+0x340>
 2e4:	mov	w5, #0x40                  	// #64
 2e8:	sub	w5, w5, w0
 2ec:	lsl	x4, x1, x5
 2f0:	lsr	x6, x3, x0
 2f4:	orr	x4, x4, x6
 2f8:	lsl	x3, x3, x5
 2fc:	cmp	x3, #0x0
 300:	cset	x3, ne  // ne = any
 304:	orr	x4, x4, x3
 308:	lsr	x1, x1, x0
 30c:	adds	x4, x4, x12
 310:	adc	x1, x1, x2
 314:	mov	x9, x13
 318:	b	168 <__addtf3+0x168>
 31c:	orr	x3, x2, x12
 320:	cbz	x3, b8c <__addtf3+0xb8c>
 324:	lsr	x0, x2, #50
 328:	eor	x0, x0, #0x1
 32c:	and	w0, w0, #0x1
 330:	mov	x1, x2
 334:	mov	x3, x12
 338:	mov	x9, x8
 33c:	b	ab4 <__addtf3+0xab4>
 340:	sub	w4, w0, #0x40
 344:	lsr	x4, x1, x4
 348:	mov	w5, #0x80                  	// #128
 34c:	sub	w5, w5, w0
 350:	lsl	x1, x1, x5
 354:	cmp	w0, #0x40
 358:	csel	x0, x1, xzr, ne  // ne = any
 35c:	orr	x3, x0, x3
 360:	cmp	x3, #0x0
 364:	cset	x0, ne  // ne = any
 368:	orr	x4, x4, x0
 36c:	mov	x1, #0x0                   	// #0
 370:	b	30c <__addtf3+0x30c>
 374:	mov	x0, #0x7fff                	// #32767
 378:	cmp	x5, x0
 37c:	b.eq	3d8 <__addtf3+0x3d8>  // b.none
 380:	mov	w0, #0x0                   	// #0
 384:	mov	x4, #0x7fff                	// #32767
 388:	cmp	x8, x4
 38c:	b.eq	3f8 <__addtf3+0x3f8>  // b.none
 390:	orr	x4, x1, x3
 394:	cbz	x4, ae4 <__addtf3+0xae4>
 398:	orr	x12, x2, x12
 39c:	mov	x9, #0x7fff                	// #32767
 3a0:	cbz	x12, ab4 <__addtf3+0xab4>
 3a4:	bfi	x6, x1, #61, #3
 3a8:	lsr	x3, x1, #3
 3ac:	tbz	x1, #50, 3c8 <__addtf3+0x3c8>
 3b0:	lsr	x1, x2, #3
 3b4:	tbnz	x2, #50, 3c8 <__addtf3+0x3c8>
 3b8:	mov	x6, x7
 3bc:	bfi	x6, x2, #61, #3
 3c0:	mov	x3, x1
 3c4:	mov	x10, x14
 3c8:	extr	x1, x3, x6, #61
 3cc:	lsl	x3, x6, #3
 3d0:	mov	x9, #0x7fff                	// #32767
 3d4:	b	ab4 <__addtf3+0xab4>
 3d8:	orr	x0, x1, x3
 3dc:	cbz	x0, c94 <__addtf3+0xc94>
 3e0:	lsr	x0, x1, #50
 3e4:	eor	x0, x0, #0x1
 3e8:	and	w0, w0, #0x1
 3ec:	mov	x4, #0x7fff                	// #32767
 3f0:	cmp	x8, x4
 3f4:	b.ne	398 <__addtf3+0x398>  // b.any
 3f8:	orr	x4, x2, x12
 3fc:	cbz	x4, 390 <__addtf3+0x390>
 400:	tst	x2, #0x4000000000000
 404:	csinc	w0, w0, wzr, ne  // ne = any
 408:	orr	x3, x1, x3
 40c:	cbnz	x3, 3a4 <__addtf3+0x3a4>
 410:	mov	x1, x2
 414:	mov	x3, x12
 418:	mov	x9, #0x7fff                	// #32767
 41c:	b	ab4 <__addtf3+0xab4>
 420:	mov	w0, #0x0                   	// #0
 424:	b	3f8 <__addtf3+0x3f8>
 428:	mov	x4, #0x7fff                	// #32767
 42c:	cmp	x0, x4
 430:	b.eq	450 <__addtf3+0x450>  // b.none
 434:	adds	x3, x3, x12
 438:	adc	x1, x2, x1
 43c:	extr	x3, x1, x3, #1
 440:	lsr	x1, x1, #1
 444:	mov	x9, x0
 448:	mov	w0, #0x0                   	// #0
 44c:	b	ab4 <__addtf3+0xab4>
 450:	ands	x3, x11, #0xc00000
 454:	b.eq	b98 <__addtf3+0xb98>  // b.none
 458:	cmp	x3, #0x400, lsl #12
 45c:	ccmp	x10, #0x0, #0x0, eq  // eq = none
 460:	b.eq	ba4 <__addtf3+0xba4>  // b.none
 464:	cmp	x3, #0x800, lsl #12
 468:	ccmp	x10, #0x0, #0x4, eq  // eq = none
 46c:	b.ne	bb8 <__addtf3+0xbb8>  // b.any
 470:	mov	w4, #0x0                   	// #0
 474:	mov	x1, #0xffffffffffffffff    	// #-1
 478:	mov	x3, x1
 47c:	mov	x9, #0x7ffe                	// #32766
 480:	mov	w0, #0x14                  	// #20
 484:	b	ac0 <__addtf3+0xac0>
 488:	ands	x3, x11, #0xc00000
 48c:	b.eq	bc8 <__addtf3+0xbc8>  // b.none
 490:	cmp	x3, #0x400, lsl #12
 494:	ccmp	x10, #0x0, #0x0, eq  // eq = none
 498:	b.eq	bd4 <__addtf3+0xbd4>  // b.none
 49c:	cmp	x3, #0x800, lsl #12
 4a0:	ccmp	x10, #0x0, #0x4, eq  // eq = none
 4a4:	b.ne	be8 <__addtf3+0xbe8>  // b.any
 4a8:	mov	w4, #0x0                   	// #0
 4ac:	mov	x1, #0xffffffffffffffff    	// #-1
 4b0:	mov	x3, x1
 4b4:	mov	x9, #0x7ffe                	// #32766
 4b8:	mov	w0, #0x14                  	// #20
 4bc:	b	ac0 <__addtf3+0xac0>
 4c0:	mov	x4, x3
 4c4:	mov	x0, #0x7fff                	// #32767
 4c8:	cmp	x5, x0
 4cc:	b.ne	978 <__addtf3+0x978>  // b.any
 4d0:	orr	x0, x1, x3
 4d4:	cbz	x0, bf8 <__addtf3+0xbf8>
 4d8:	lsr	x0, x1, #50
 4dc:	eor	x0, x0, #0x1
 4e0:	and	w0, w0, #0x1
 4e4:	b	ab4 <__addtf3+0xab4>
 4e8:	sub	x4, x3, x12
 4ec:	cmp	x3, x4
 4f0:	sbc	x1, x1, x2
 4f4:	b	54c <__addtf3+0x54c>
 4f8:	orr	x2, x2, #0x8000000000000
 4fc:	mov	x4, #0x7fff                	// #32767
 500:	cmp	x5, x4
 504:	b.eq	5bc <__addtf3+0x5bc>  // b.none
 508:	cmp	w0, #0x74
 50c:	b.gt	b18 <__addtf3+0xb18>
 510:	cmp	w0, #0x3f
 514:	b.gt	5d4 <__addtf3+0x5d4>
 518:	mov	w5, #0x40                  	// #64
 51c:	sub	w5, w5, w0
 520:	lsl	x4, x2, x5
 524:	lsr	x6, x12, x0
 528:	orr	x4, x4, x6
 52c:	lsl	x12, x12, x5
 530:	cmp	x12, #0x0
 534:	cset	x5, ne  // ne = any
 538:	orr	x4, x4, x5
 53c:	lsr	x0, x2, x0
 540:	sub	x4, x3, x4
 544:	cmp	x3, x4
 548:	sbc	x1, x1, x0
 54c:	tbz	x1, #51, 978 <__addtf3+0x978>
 550:	and	x5, x1, #0x7ffffffffffff
 554:	cbz	x5, 91c <__addtf3+0x91c>
 558:	clz	x0, x5
 55c:	sub	w0, w0, #0xc
 560:	lsl	x5, x5, x0
 564:	neg	w1, w0
 568:	lsr	x1, x4, x1
 56c:	orr	x1, x1, x5
 570:	lsl	x5, x4, x0
 574:	sxtw	x2, w0
 578:	cmp	x9, w0, sxtw
 57c:	b.gt	96c <__addtf3+0x96c>
 580:	sub	w9, w0, w9
 584:	add	w6, w9, #0x1
 588:	cmp	w6, #0x3f
 58c:	b.gt	938 <__addtf3+0x938>
 590:	mov	w0, #0x40                  	// #64
 594:	sub	w0, w0, w6
 598:	lsl	x4, x1, x0
 59c:	lsr	x2, x5, x6
 5a0:	orr	x4, x4, x2
 5a4:	lsl	x5, x5, x0
 5a8:	cmp	x5, #0x0
 5ac:	cset	x3, ne  // ne = any
 5b0:	orr	x4, x4, x3
 5b4:	lsr	x1, x1, x6
 5b8:	b	97c <__addtf3+0x97c>
 5bc:	orr	x0, x1, x3
 5c0:	cbz	x0, c18 <__addtf3+0xc18>
 5c4:	lsr	x0, x1, #50
 5c8:	eor	x0, x0, #0x1
 5cc:	and	w0, w0, #0x1
 5d0:	b	ab4 <__addtf3+0xab4>
 5d4:	sub	w4, w0, #0x40
 5d8:	lsr	x4, x2, x4
 5dc:	mov	w5, #0x80                  	// #128
 5e0:	sub	w5, w5, w0
 5e4:	lsl	x2, x2, x5
 5e8:	cmp	w0, #0x40
 5ec:	csel	x2, x2, xzr, ne  // ne = any
 5f0:	orr	x12, x2, x12
 5f4:	cmp	x12, #0x0
 5f8:	cset	x0, ne  // ne = any
 5fc:	orr	x4, x4, x0
 600:	mov	x0, #0x0                   	// #0
 604:	b	540 <__addtf3+0x540>
 608:	tbnz	w0, #31, 650 <__addtf3+0x650>
 60c:	add	x0, x5, #0x1
 610:	ands	x4, x0, #0x7ffe
 614:	b.ne	8dc <__addtf3+0x8dc>  // b.any
 618:	cbnz	x5, 7f4 <__addtf3+0x7f4>
 61c:	orr	x0, x1, x3
 620:	cbz	x0, 7bc <__addtf3+0x7bc>
 624:	orr	x0, x2, x12
 628:	cbz	x0, c68 <__addtf3+0xc68>
 62c:	sub	x0, x3, x12
 630:	cmp	x3, x0
 634:	sbc	x5, x1, x2
 638:	tbz	x5, #51, 7d8 <__addtf3+0x7d8>
 63c:	sub	x4, x12, x3
 640:	cmp	x12, x4
 644:	sbc	x1, x2, x1
 648:	mov	x10, x14
 64c:	b	97c <__addtf3+0x97c>
 650:	cbnz	x5, 6fc <__addtf3+0x6fc>
 654:	orr	x4, x1, x3
 658:	cbz	x4, 69c <__addtf3+0x69c>
 65c:	cmn	w0, #0x1
 660:	b.eq	6e4 <__addtf3+0x6e4>  // b.none
 664:	mvn	w0, w0
 668:	mov	x4, #0x7fff                	// #32767
 66c:	cmp	x8, x4
 670:	b.ne	710 <__addtf3+0x710>  // b.any
 674:	orr	x3, x2, x12
 678:	cbz	x3, c3c <__addtf3+0xc3c>
 67c:	lsr	x0, x2, #50
 680:	eor	x0, x0, #0x1
 684:	and	w0, w0, #0x1
 688:	mov	x1, x2
 68c:	mov	x3, x12
 690:	mov	x9, x8
 694:	mov	x10, x14
 698:	b	ab4 <__addtf3+0xab4>
 69c:	mov	x0, #0x7fff                	// #32767
 6a0:	cmp	x8, x0
 6a4:	b.eq	6bc <__addtf3+0x6bc>  // b.none
 6a8:	mov	x1, x2
 6ac:	mov	x4, x12
 6b0:	mov	x9, x8
 6b4:	mov	x10, x14
 6b8:	b	978 <__addtf3+0x978>
 6bc:	orr	x3, x2, x12
 6c0:	cbz	x3, c2c <__addtf3+0xc2c>
 6c4:	lsr	x0, x2, #50
 6c8:	eor	x0, x0, #0x1
 6cc:	and	w0, w0, #0x1
 6d0:	mov	x1, x2
 6d4:	mov	x3, x12
 6d8:	mov	x9, x8
 6dc:	mov	x10, x14
 6e0:	b	ab4 <__addtf3+0xab4>
 6e4:	sub	x4, x12, x3
 6e8:	cmp	x12, x4
 6ec:	sbc	x1, x2, x1
 6f0:	mov	x9, x8
 6f4:	mov	x10, x14
 6f8:	b	54c <__addtf3+0x54c>
 6fc:	neg	w0, w0
 700:	orr	x1, x1, #0x8000000000000
 704:	mov	x4, #0x7fff                	// #32767
 708:	cmp	x8, x4
 70c:	b.eq	760 <__addtf3+0x760>  // b.none
 710:	cmp	w0, #0x74
 714:	b.gt	b24 <__addtf3+0xb24>
 718:	cmp	w0, #0x3f
 71c:	b.gt	788 <__addtf3+0x788>
 720:	mov	w5, #0x40                  	// #64
 724:	sub	w5, w5, w0
 728:	lsl	x4, x1, x5
 72c:	lsr	x6, x3, x0
 730:	orr	x4, x4, x6
 734:	lsl	x3, x3, x5
 738:	cmp	x3, #0x0
 73c:	cset	x3, ne  // ne = any
 740:	orr	x4, x4, x3
 744:	lsr	x1, x1, x0
 748:	sub	x4, x12, x4
 74c:	cmp	x12, x4
 750:	sbc	x1, x2, x1
 754:	mov	x9, x13
 758:	mov	x10, x14
 75c:	b	54c <__addtf3+0x54c>
 760:	orr	x3, x2, x12
 764:	cbz	x3, c4c <__addtf3+0xc4c>
 768:	lsr	x0, x2, #50
 76c:	eor	x0, x0, #0x1
 770:	and	w0, w0, #0x1
 774:	mov	x1, x2
 778:	mov	x3, x12
 77c:	mov	x9, x8
 780:	mov	x10, x14
 784:	b	ab4 <__addtf3+0xab4>
 788:	sub	w4, w0, #0x40
 78c:	lsr	x4, x1, x4
 790:	mov	w5, #0x80                  	// #128
 794:	sub	w5, w5, w0
 798:	lsl	x1, x1, x5
 79c:	cmp	w0, #0x40
 7a0:	csel	x0, x1, xzr, ne  // ne = any
 7a4:	orr	x3, x0, x3
 7a8:	cmp	x3, #0x0
 7ac:	cset	x0, ne  // ne = any
 7b0:	orr	x4, x4, x0
 7b4:	mov	x1, #0x0                   	// #0
 7b8:	b	748 <__addtf3+0x748>
 7bc:	orr	x4, x2, x12
 7c0:	cbnz	x4, c5c <__addtf3+0xc5c>
 7c4:	and	x0, x11, #0xc00000
 7c8:	cmp	x0, #0x800, lsl #12
 7cc:	cset	x10, eq  // eq = none
 7d0:	mov	x1, x4
 7d4:	b	97c <__addtf3+0x97c>
 7d8:	orr	x4, x0, x5
 7dc:	cbnz	x4, c88 <__addtf3+0xc88>
 7e0:	and	x0, x11, #0xc00000
 7e4:	cmp	x0, #0x800, lsl #12
 7e8:	cset	x10, eq  // eq = none
 7ec:	mov	x1, x4
 7f0:	b	97c <__addtf3+0x97c>
 7f4:	mov	x0, #0x7fff                	// #32767
 7f8:	cmp	x5, x0
 7fc:	b.eq	834 <__addtf3+0x834>  // b.none
 800:	mov	w0, #0x0                   	// #0
 804:	mov	x5, #0x7fff                	// #32767
 808:	cmp	x8, x5
 80c:	b.eq	888 <__addtf3+0x888>  // b.none
 810:	orr	x5, x1, x3
 814:	cbnz	x5, 854 <__addtf3+0x854>
 818:	orr	x1, x2, x12
 81c:	cbnz	x1, 8b4 <__addtf3+0x8b4>
 820:	mov	x10, x4
 824:	mov	x1, #0x7ffffffffffff       	// #2251799813685247
 828:	mov	x3, #0xfffffffffffffff8    	// #-8
 82c:	mov	w0, #0x1                   	// #1
 830:	b	c24 <__addtf3+0xc24>
 834:	orr	x0, x1, x3
 838:	cbz	x0, b30 <__addtf3+0xb30>
 83c:	lsr	x0, x1, #50
 840:	eor	x0, x0, #0x1
 844:	and	w0, w0, #0x1
 848:	mov	x5, #0x7fff                	// #32767
 84c:	cmp	x8, x5
 850:	b.eq	888 <__addtf3+0x888>  // b.none
 854:	orr	x12, x2, x12
 858:	mov	x9, #0x7fff                	// #32767
 85c:	cbz	x12, ab4 <__addtf3+0xab4>
 860:	lsr	x3, x1, #3
 864:	tbz	x1, #50, 8c8 <__addtf3+0x8c8>
 868:	lsr	x4, x2, #3
 86c:	tbnz	x2, #50, 8c8 <__addtf3+0x8c8>
 870:	mov	x6, x7
 874:	bfi	x6, x2, #61, #3
 878:	mov	x3, x4
 87c:	mov	x10, x14
 880:	b	8cc <__addtf3+0x8cc>
 884:	mov	w0, #0x0                   	// #0
 888:	orr	x5, x2, x12
 88c:	cbz	x5, 810 <__addtf3+0x810>
 890:	tst	x2, #0x4000000000000
 894:	csinc	w0, w0, wzr, ne  // ne = any
 898:	orr	x4, x1, x3
 89c:	cbnz	x4, 854 <__addtf3+0x854>
 8a0:	mov	x1, x2
 8a4:	mov	x3, x12
 8a8:	mov	x10, x14
 8ac:	mov	x9, #0x7fff                	// #32767
 8b0:	b	ab4 <__addtf3+0xab4>
 8b4:	mov	x1, x2
 8b8:	mov	x3, x12
 8bc:	mov	x10, x14
 8c0:	mov	x9, #0x7fff                	// #32767
 8c4:	b	ab4 <__addtf3+0xab4>
 8c8:	bfi	x6, x1, #61, #3
 8cc:	extr	x1, x3, x6, #61
 8d0:	lsl	x3, x6, #3
 8d4:	mov	x9, #0x7fff                	// #32767
 8d8:	b	ab4 <__addtf3+0xab4>
 8dc:	sub	x4, x3, x12
 8e0:	cmp	x3, x4
 8e4:	sbc	x5, x1, x2
 8e8:	tbnz	x5, #51, 908 <__addtf3+0x908>
 8ec:	orr	x1, x4, x5
 8f0:	cbnz	x1, 554 <__addtf3+0x554>
 8f4:	and	x0, x11, #0xc00000
 8f8:	cmp	x0, #0x800, lsl #12
 8fc:	cset	x10, eq  // eq = none
 900:	mov	x4, x1
 904:	b	97c <__addtf3+0x97c>
 908:	sub	x4, x12, x3
 90c:	cmp	x12, x4
 910:	sbc	x5, x2, x1
 914:	mov	x10, x14
 918:	b	554 <__addtf3+0x554>
 91c:	clz	x1, x4
 920:	add	w0, w1, #0x34
 924:	cmp	w0, #0x3f
 928:	b.le	560 <__addtf3+0x560>
 92c:	sub	w1, w1, #0xc
 930:	lsl	x1, x4, x1
 934:	b	574 <__addtf3+0x574>
 938:	sub	w9, w9, #0x3f
 93c:	lsr	x0, x1, x9
 940:	mov	w2, #0x80                  	// #128
 944:	sub	w2, w2, w6
 948:	lsl	x1, x1, x2
 94c:	cmp	w6, #0x40
 950:	csel	x2, x1, xzr, ne  // ne = any
 954:	orr	x2, x5, x2
 958:	cmp	x2, #0x0
 95c:	cset	x4, ne  // ne = any
 960:	orr	x4, x0, x4
 964:	mov	x1, #0x0                   	// #0
 968:	b	97c <__addtf3+0x97c>
 96c:	sub	x9, x9, x2
 970:	and	x1, x1, #0xfff7ffffffffffff
 974:	mov	x4, x5
 978:	cbnz	x9, aac <__addtf3+0xaac>
 97c:	orr	x3, x4, x1
 980:	cbnz	x3, c6c <__addtf3+0xc6c>
 984:	mov	x1, x3
 988:	mov	x9, #0x0                   	// #0
 98c:	mov	w0, #0x0                   	// #0
 990:	b	9c4 <__addtf3+0x9c4>
 994:	mov	x3, x4
 998:	mov	w4, #0x1                   	// #1
 99c:	mov	x9, #0x0                   	// #0
 9a0:	mov	w0, #0x0                   	// #0
 9a4:	b	ac0 <__addtf3+0xac0>
 9a8:	and	x2, x3, #0xf
 9ac:	cmp	x2, #0x4
 9b0:	b.eq	9bc <__addtf3+0x9bc>  // b.none
 9b4:	adds	x3, x3, #0x4
 9b8:	cinc	x1, x1, cs  // cs = hs, nlast
 9bc:	cbz	w4, 9c4 <__addtf3+0x9c4>
 9c0:	orr	w0, w0, #0x8
 9c4:	tbz	x1, #51, a70 <__addtf3+0xa70>
 9c8:	add	x9, x9, #0x1
 9cc:	mov	x2, #0x7fff                	// #32767
 9d0:	cmp	x9, x2
 9d4:	b.eq	a3c <__addtf3+0xa3c>  // b.none
 9d8:	and	x2, x1, #0xfff7ffffffffffff
 9dc:	extr	x4, x1, x3, #3
 9e0:	lsr	x1, x2, #3
 9e4:	mov	x3, #0x0                   	// #0
 9e8:	mov	x2, x4
 9ec:	bfxil	x3, x1, #0, #48
 9f0:	bfi	x3, x9, #48, #15
 9f4:	bfi	x3, x10, #63, #1
 9f8:	stp	x2, x3, [sp, #16]
 9fc:	cbnz	w0, aa4 <__addtf3+0xaa4>
 a00:	ldr	q0, [sp, #16]
 a04:	ldp	x29, x30, [sp], #32
 a08:	ret
 a0c:	cbnz	x10, 9bc <__addtf3+0x9bc>
 a10:	adds	x3, x3, #0x8
 a14:	cinc	x1, x1, cs  // cs = hs, nlast
 a18:	b	9bc <__addtf3+0x9bc>
 a1c:	cbz	x10, 9bc <__addtf3+0x9bc>
 a20:	adds	x3, x3, #0x8
 a24:	cinc	x1, x1, cs  // cs = hs, nlast
 a28:	b	9bc <__addtf3+0x9bc>
 a2c:	mov	x3, x4
 a30:	mov	x9, #0x0                   	// #0
 a34:	mov	w0, #0x0                   	// #0
 a38:	b	9c0 <__addtf3+0x9c0>
 a3c:	ands	x3, x11, #0xc00000
 a40:	b.eq	a64 <__addtf3+0xa64>  // b.none
 a44:	cmp	x3, #0x400, lsl #12
 a48:	ccmp	x10, #0x0, #0x0, eq  // eq = none
 a4c:	b.eq	a9c <__addtf3+0xa9c>  // b.none
 a50:	cmp	x3, #0x800, lsl #12
 a54:	ccmp	x10, #0x0, #0x4, eq  // eq = none
 a58:	csetm	x3, eq  // eq = none
 a5c:	mov	x1, #0x7ffe                	// #32766
 a60:	csel	x9, x9, x1, ne  // ne = any
 a64:	mov	w1, #0x14                  	// #20
 a68:	orr	w0, w0, w1
 a6c:	mov	x1, x3
 a70:	extr	x4, x1, x3, #3
 a74:	lsr	x1, x1, #3
 a78:	mov	x2, #0x7fff                	// #32767
 a7c:	cmp	x9, x2
 a80:	b.ne	9e4 <__addtf3+0x9e4>  // b.any
 a84:	orr	x2, x4, x1
 a88:	orr	x1, x1, #0x800000000000
 a8c:	cbnz	x2, 9e4 <__addtf3+0x9e4>
 a90:	mov	x4, x2
 a94:	mov	x1, x2
 a98:	b	9e4 <__addtf3+0x9e4>
 a9c:	mov	x3, #0x0                   	// #0
 aa0:	b	a64 <__addtf3+0xa64>
 aa4:	bl	0 <__sfp_handle_exceptions>
 aa8:	b	a00 <__addtf3+0xa00>
 aac:	mov	x3, x4
 ab0:	mov	w0, #0x0                   	// #0
 ab4:	mov	w4, #0x0                   	// #0
 ab8:	tst	x3, #0x7
 abc:	b.eq	9c4 <__addtf3+0x9c4>  // b.none
 ac0:	orr	w0, w0, #0x10
 ac4:	and	x2, x11, #0xc00000
 ac8:	cmp	x2, #0x400, lsl #12
 acc:	b.eq	a0c <__addtf3+0xa0c>  // b.none
 ad0:	cmp	x2, #0x800, lsl #12
 ad4:	b.eq	a1c <__addtf3+0xa1c>  // b.none
 ad8:	cbz	x2, 9a8 <__addtf3+0x9a8>
 adc:	cbnz	w4, 9c0 <__addtf3+0x9c0>
 ae0:	b	9c4 <__addtf3+0x9c4>
 ae4:	mov	x1, x2
 ae8:	mov	x3, x12
 aec:	mov	x9, #0x7fff                	// #32767
 af0:	b	ab4 <__addtf3+0xab4>
 af4:	mov	x1, x2
 af8:	mov	x4, x12
 afc:	b	97c <__addtf3+0x97c>
 b00:	mov	x0, #0x0                   	// #0
 b04:	mov	x4, #0x1                   	// #1
 b08:	b	160 <__addtf3+0x160>
 b0c:	mov	x1, #0x0                   	// #0
 b10:	mov	x4, #0x1                   	// #1
 b14:	b	30c <__addtf3+0x30c>
 b18:	mov	x0, #0x0                   	// #0
 b1c:	mov	x4, #0x1                   	// #1
 b20:	b	540 <__addtf3+0x540>
 b24:	mov	x1, #0x0                   	// #0
 b28:	mov	x4, #0x1                   	// #1
 b2c:	b	748 <__addtf3+0x748>
 b30:	mov	x0, #0x7fff                	// #32767
 b34:	cmp	x8, x0
 b38:	b.eq	884 <__addtf3+0x884>  // b.none
 b3c:	mov	w0, #0x0                   	// #0
 b40:	b	818 <__addtf3+0x818>
 b44:	mov	x1, x0
 b48:	mov	x3, x0
 b4c:	mov	w0, #0x0                   	// #0
 b50:	b	c24 <__addtf3+0xc24>
 b54:	mov	x1, x0
 b58:	mov	x3, x0
 b5c:	mov	w0, #0x0                   	// #0
 b60:	b	c24 <__addtf3+0xc24>
 b64:	mov	x1, x0
 b68:	mov	x3, x0
 b6c:	mov	w0, #0x0                   	// #0
 b70:	b	c24 <__addtf3+0xc24>
 b74:	mov	x1, x3
 b78:	mov	w0, #0x0                   	// #0
 b7c:	b	c24 <__addtf3+0xc24>
 b80:	mov	x1, x3
 b84:	mov	w0, #0x0                   	// #0
 b88:	b	c24 <__addtf3+0xc24>
 b8c:	mov	x1, x3
 b90:	mov	w0, #0x0                   	// #0
 b94:	b	c24 <__addtf3+0xc24>
 b98:	mov	x1, x3
 b9c:	mov	w0, #0x14                  	// #20
 ba0:	b	c24 <__addtf3+0xc24>
 ba4:	mov	x1, #0x0                   	// #0
 ba8:	mov	x3, #0x0                   	// #0
 bac:	mov	x10, #0x0                   	// #0
 bb0:	mov	w0, #0x14                  	// #20
 bb4:	b	c24 <__addtf3+0xc24>
 bb8:	mov	x1, #0x0                   	// #0
 bbc:	mov	x3, #0x0                   	// #0
 bc0:	mov	w0, #0x14                  	// #20
 bc4:	b	c24 <__addtf3+0xc24>
 bc8:	mov	x1, x3
 bcc:	mov	w0, #0x14                  	// #20
 bd0:	b	c24 <__addtf3+0xc24>
 bd4:	mov	x1, #0x0                   	// #0
 bd8:	mov	x3, #0x0                   	// #0
 bdc:	mov	x10, #0x0                   	// #0
 be0:	mov	w0, #0x14                  	// #20
 be4:	b	c24 <__addtf3+0xc24>
 be8:	mov	x1, #0x0                   	// #0
 bec:	mov	x3, #0x0                   	// #0
 bf0:	mov	w0, #0x14                  	// #20
 bf4:	b	c24 <__addtf3+0xc24>
 bf8:	mov	x1, x0
 bfc:	mov	x3, x0
 c00:	mov	w0, #0x0                   	// #0
 c04:	b	c24 <__addtf3+0xc24>
 c08:	mov	x1, x0
 c0c:	mov	x3, x0
 c10:	mov	w0, #0x0                   	// #0
 c14:	b	c24 <__addtf3+0xc24>
 c18:	mov	x1, x0
 c1c:	mov	x3, x0
 c20:	mov	w0, #0x0                   	// #0
 c24:	mov	x9, #0x7fff                	// #32767
 c28:	b	9c4 <__addtf3+0x9c4>
 c2c:	mov	x1, x3
 c30:	mov	x10, x14
 c34:	mov	w0, #0x0                   	// #0
 c38:	b	c24 <__addtf3+0xc24>
 c3c:	mov	x1, x3
 c40:	mov	x10, x14
 c44:	mov	w0, #0x0                   	// #0
 c48:	b	c24 <__addtf3+0xc24>
 c4c:	mov	x1, x3
 c50:	mov	x10, x14
 c54:	mov	w0, #0x0                   	// #0
 c58:	b	c24 <__addtf3+0xc24>
 c5c:	mov	x1, x2
 c60:	mov	x3, x12
 c64:	mov	x10, x14
 c68:	mov	x4, x3
 c6c:	tst	x4, #0x7
 c70:	b.ne	994 <__addtf3+0x994>  // b.any
 c74:	tbnz	w11, #11, a2c <__addtf3+0xa2c>
 c78:	mov	x3, x4
 c7c:	mov	x9, #0x0                   	// #0
 c80:	mov	w0, #0x0                   	// #0
 c84:	b	9c4 <__addtf3+0x9c4>
 c88:	mov	x1, x5
 c8c:	mov	x3, x0
 c90:	b	c68 <__addtf3+0xc68>
 c94:	mov	x0, #0x7fff                	// #32767
 c98:	cmp	x8, x0
 c9c:	b.eq	420 <__addtf3+0x420>  // b.none
 ca0:	mov	x1, x2
 ca4:	mov	x3, x12
 ca8:	mov	w0, #0x0                   	// #0
 cac:	b	ab4 <__addtf3+0xab4>

divtf3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divtf3>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	q0, [sp, #16]
   c:	ldr	x2, [sp, #16]
  10:	ldr	x0, [sp, #24]
  14:	str	q1, [sp, #16]
  18:	ldr	x7, [sp, #16]
  1c:	ldr	x1, [sp, #24]
  20:	mrs	x12, fpcr
  24:	ubfx	x3, x0, #0, #48
  28:	ubfx	x6, x0, #48, #15
  2c:	lsr	x0, x0, #63
  30:	and	w9, w0, #0xff
  34:	cbz	w6, e8 <__divtf3+0xe8>
  38:	mov	x10, x3
  3c:	mov	w5, #0x7fff                	// #32767
  40:	cmp	w6, w5
  44:	b.eq	150 <__divtf3+0x150>  // b.none
  48:	extr	x3, x3, x2, #61
  4c:	orr	x10, x3, #0x8000000000000
  50:	lsl	x13, x2, #3
  54:	and	x6, x6, #0xffff
  58:	sub	x6, x6, #0x3, lsl #12
  5c:	sub	x6, x6, #0xfff
  60:	mov	x14, #0x0                   	// #0
  64:	mov	w3, #0x0                   	// #0
  68:	ubfx	x8, x1, #0, #48
  6c:	mov	x4, x8
  70:	ubfx	x11, x1, #48, #15
  74:	lsr	x2, x1, #63
  78:	and	w1, w2, #0xff
  7c:	cbz	w11, 198 <__divtf3+0x198>
  80:	mov	w15, #0x7fff                	// #32767
  84:	cmp	w11, w15
  88:	b.eq	1f8 <__divtf3+0x1f8>  // b.none
  8c:	extr	x4, x8, x7, #61
  90:	orr	x4, x4, #0x8000000000000
  94:	lsl	x5, x7, #3
  98:	and	x11, x11, #0xffff
  9c:	sub	x11, x11, #0x3, lsl #12
  a0:	sub	x11, x11, #0xfff
  a4:	eor	w9, w9, w1
  a8:	and	x9, x9, #0xff
  ac:	sub	x6, x6, x11
  b0:	lsl	x1, x14, #2
  b4:	mov	x7, #0x0                   	// #0
  b8:	cmp	x1, #0x7
  bc:	b.le	250 <__divtf3+0x250>
  c0:	cmp	x1, #0xe
  c4:	b.gt	5bc <__divtf3+0x5bc>
  c8:	cmp	x1, #0xb
  cc:	b.gt	5e0 <__divtf3+0x5e0>
  d0:	cmp	x1, #0x9
  d4:	b.gt	31c <__divtf3+0x31c>
  d8:	mov	x4, #0x0                   	// #0
  dc:	mov	x5, #0x0                   	// #0
  e0:	mov	x6, #0x7fff                	// #32767
  e4:	b	84c <__divtf3+0x84c>
  e8:	orr	x13, x3, x2
  ec:	cbz	x13, 170 <__divtf3+0x170>
  f0:	cbz	x3, 12c <__divtf3+0x12c>
  f4:	clz	x6, x3
  f8:	sub	x10, x6, #0xf
  fc:	add	w13, w10, #0x3
 100:	lsl	x3, x3, x13
 104:	mov	w4, #0x3d                  	// #61
 108:	sub	w10, w4, w10
 10c:	lsr	x10, x2, x10
 110:	orr	x10, x10, x3
 114:	lsl	x13, x2, x13
 118:	mov	x2, #0xffffffffffffc011    	// #-16367
 11c:	sub	x6, x2, x6
 120:	mov	x14, #0x0                   	// #0
 124:	mov	w3, #0x0                   	// #0
 128:	b	68 <__divtf3+0x68>
 12c:	clz	x10, x2
 130:	add	x6, x10, #0x40
 134:	add	x10, x10, #0x31
 138:	cmp	x10, #0x3c
 13c:	b.le	fc <__divtf3+0xfc>
 140:	sub	w10, w10, #0x3d
 144:	mov	x13, x3
 148:	lsl	x10, x2, x10
 14c:	b	118 <__divtf3+0x118>
 150:	orr	x13, x3, x2
 154:	cbz	x13, 184 <__divtf3+0x184>
 158:	lsr	x3, x3, #47
 15c:	eor	w3, w3, #0x1
 160:	mov	x13, x2
 164:	mov	x6, #0x7fff                	// #32767
 168:	mov	x14, #0x3                   	// #3
 16c:	b	68 <__divtf3+0x68>
 170:	mov	x10, x13
 174:	mov	x6, #0x0                   	// #0
 178:	mov	x14, #0x1                   	// #1
 17c:	mov	w3, #0x0                   	// #0
 180:	b	68 <__divtf3+0x68>
 184:	mov	x10, x13
 188:	mov	x6, #0x7fff                	// #32767
 18c:	mov	x14, #0x2                   	// #2
 190:	mov	w3, #0x0                   	// #0
 194:	b	68 <__divtf3+0x68>
 198:	orr	x5, x8, x7
 19c:	cbz	x5, 218 <__divtf3+0x218>
 1a0:	cbz	x8, 1d4 <__divtf3+0x1d4>
 1a4:	clz	x16, x8
 1a8:	sub	x4, x16, #0xf
 1ac:	add	w5, w4, #0x3
 1b0:	lsl	x8, x8, x5
 1b4:	mov	w15, #0x3d                  	// #61
 1b8:	sub	w4, w15, w4
 1bc:	lsr	x4, x7, x4
 1c0:	orr	x4, x4, x8
 1c4:	lsl	x5, x7, x5
 1c8:	mov	x11, #0xffffffffffffc011    	// #-16367
 1cc:	sub	x11, x11, x16
 1d0:	b	a4 <__divtf3+0xa4>
 1d4:	clz	x4, x7
 1d8:	add	x16, x4, #0x40
 1dc:	add	x4, x4, #0x31
 1e0:	cmp	x4, #0x3c
 1e4:	b.le	1ac <__divtf3+0x1ac>
 1e8:	sub	w4, w4, #0x3d
 1ec:	mov	x5, x8
 1f0:	lsl	x4, x7, x4
 1f4:	b	1c8 <__divtf3+0x1c8>
 1f8:	orr	x5, x8, x7
 1fc:	cbz	x5, 240 <__divtf3+0x240>
 200:	mov	x5, x7
 204:	mov	x11, #0x7fff                	// #32767
 208:	mov	x7, #0x3                   	// #3
 20c:	tst	x8, #0x800000000000
 210:	csinc	w3, w3, wzr, ne  // ne = any
 214:	b	224 <__divtf3+0x224>
 218:	mov	x4, x5
 21c:	mov	x11, #0x0                   	// #0
 220:	mov	x7, #0x1                   	// #1
 224:	eor	w9, w9, w1
 228:	and	x9, x9, #0xff
 22c:	sub	x6, x6, x11
 230:	orr	x1, x7, x14, lsl #2
 234:	cmp	x1, #0x7
 238:	b.ne	b8 <__divtf3+0xb8>  // b.any
 23c:	b	298 <__divtf3+0x298>
 240:	mov	x4, x5
 244:	mov	x11, #0x7fff                	// #32767
 248:	mov	x7, #0x2                   	// #2
 24c:	b	224 <__divtf3+0x224>
 250:	cmp	x1, #0x1
 254:	b.eq	5d8 <__divtf3+0x5d8>  // b.none
 258:	b.le	338 <__divtf3+0x338>
 25c:	cmp	x1, #0x4
 260:	b.eq	830 <__divtf3+0x830>  // b.none
 264:	b.le	290 <__divtf3+0x290>
 268:	cmp	x1, #0x5
 26c:	b.ne	30c <__divtf3+0x30c>  // b.any
 270:	mov	x4, #0xffffffffffff        	// #281474976710655
 274:	mov	x5, #0xffffffffffffffff    	// #-1
 278:	mov	x2, #0x0                   	// #0
 27c:	mov	w3, #0x1                   	// #1
 280:	orr	x4, x4, #0x800000000000
 284:	mov	x9, x2
 288:	mov	x6, #0x7fff                	// #32767
 28c:	b	84c <__divtf3+0x84c>
 290:	cmp	x1, #0x2
 294:	b.eq	840 <__divtf3+0x840>  // b.none
 298:	cmp	x7, #0x1
 29c:	b.eq	874 <__divtf3+0x874>  // b.none
 2a0:	b.gt	5f4 <__divtf3+0x5f4>
 2a4:	mov	x9, x2
 2a8:	cbnz	x7, 84c <__divtf3+0x84c>
 2ac:	add	x0, x6, #0x3, lsl #12
 2b0:	add	x0, x0, #0xfff
 2b4:	cmp	x0, #0x0
 2b8:	b.le	6c0 <__divtf3+0x6c0>
 2bc:	tst	x5, #0x7
 2c0:	b.eq	2e0 <__divtf3+0x2e0>  // b.none
 2c4:	orr	w3, w3, #0x10
 2c8:	and	x1, x12, #0xc00000
 2cc:	cmp	x1, #0x400, lsl #12
 2d0:	b.eq	61c <__divtf3+0x61c>  // b.none
 2d4:	cmp	x1, #0x800, lsl #12
 2d8:	b.eq	62c <__divtf3+0x62c>  // b.none
 2dc:	cbz	x1, 604 <__divtf3+0x604>
 2e0:	tbz	x4, #52, 2ec <__divtf3+0x2ec>
 2e4:	and	x4, x4, #0xffefffffffffffff
 2e8:	add	x0, x6, #0x4, lsl #12
 2ec:	mov	x1, #0x7ffe                	// #32766
 2f0:	cmp	x0, x1
 2f4:	b.gt	63c <__divtf3+0x63c>
 2f8:	extr	x5, x4, x5, #3
 2fc:	lsr	x4, x4, #3
 300:	mov	x9, x2
 304:	mov	x6, x0
 308:	b	84c <__divtf3+0x84c>
 30c:	mov	x4, #0x0                   	// #0
 310:	mov	x5, #0x0                   	// #0
 314:	mov	x6, #0x0                   	// #0
 318:	b	84c <__divtf3+0x84c>
 31c:	cmp	x1, #0xa
 320:	b.ne	298 <__divtf3+0x298>  // b.any
 324:	mov	x4, #0xffffffffffff        	// #281474976710655
 328:	mov	x5, #0xffffffffffffffff    	// #-1
 32c:	mov	x2, #0x0                   	// #0
 330:	mov	w3, #0x1                   	// #1
 334:	b	280 <__divtf3+0x280>
 338:	cmp	x10, x4
 33c:	b.hi	348 <__divtf3+0x348>  // b.pmore
 340:	ccmp	x13, x5, #0x0, eq  // eq = none
 344:	b.cc	56c <__divtf3+0x56c>  // b.lo, b.ul, b.last
 348:	lsr	x2, x10, #1
 34c:	extr	x0, x10, x13, #1
 350:	lsl	x13, x13, #63
 354:	extr	x7, x4, x5, #52
 358:	lsl	x8, x5, #12
 35c:	ubfx	x10, x4, #20, #32
 360:	and	x11, x7, #0xffffffff
 364:	udiv	x4, x2, x10
 368:	mul	x5, x11, x4
 36c:	msub	x2, x4, x10, x2
 370:	extr	x1, x2, x0, #32
 374:	cmp	x5, x1
 378:	b.ls	390 <__divtf3+0x390>  // b.plast
 37c:	add	x1, x1, x7
 380:	cmp	x5, x1
 384:	ccmp	x7, x1, #0x2, hi  // hi = pmore
 388:	b.ls	580 <__divtf3+0x580>  // b.plast
 38c:	sub	x4, x4, #0x1
 390:	sub	x1, x1, x5
 394:	udiv	x15, x1, x10
 398:	mul	x2, x11, x15
 39c:	msub	x1, x15, x10, x1
 3a0:	bfi	x0, x1, #32, #32
 3a4:	cmp	x2, x0
 3a8:	b.ls	3c0 <__divtf3+0x3c0>  // b.plast
 3ac:	add	x0, x0, x7
 3b0:	cmp	x2, x0
 3b4:	ccmp	x7, x0, #0x2, hi  // hi = pmore
 3b8:	b.ls	58c <__divtf3+0x58c>  // b.plast
 3bc:	sub	x15, x15, #0x1
 3c0:	sub	x0, x0, x2
 3c4:	orr	x15, x15, x4, lsl #32
 3c8:	lsr	x1, x15, #32
 3cc:	lsr	x14, x8, #32
 3d0:	and	x2, x15, #0xffffffff
 3d4:	and	x16, x8, #0xffffffff
 3d8:	mul	x4, x2, x16
 3dc:	mul	x17, x1, x16
 3e0:	mul	x1, x1, x14
 3e4:	madd	x2, x14, x2, x17
 3e8:	add	x2, x2, x4, lsr #32
 3ec:	mov	x5, #0x100000000           	// #4294967296
 3f0:	add	x5, x1, x5
 3f4:	cmp	x17, x2
 3f8:	csel	x1, x5, x1, hi  // hi = pmore
 3fc:	add	x1, x1, x2, lsr #32
 400:	and	x4, x4, #0xffffffff
 404:	add	x2, x4, x2, lsl #32
 408:	cmp	x0, x1
 40c:	b.cc	41c <__divtf3+0x41c>  // b.lo, b.ul, b.last
 410:	mov	x4, x15
 414:	ccmp	x13, x2, #0x2, eq  // eq = none
 418:	b.cs	454 <__divtf3+0x454>  // b.hs, b.nlast
 41c:	sub	x4, x15, #0x1
 420:	adds	x13, x13, x8
 424:	adc	x0, x0, x7
 428:	cmp	x7, x0
 42c:	b.cc	438 <__divtf3+0x438>  // b.lo, b.ul, b.last
 430:	ccmp	x8, x13, #0x2, eq  // eq = none
 434:	b.hi	454 <__divtf3+0x454>  // b.pmore
 438:	cmp	x1, x0
 43c:	b.hi	448 <__divtf3+0x448>  // b.pmore
 440:	ccmp	x2, x13, #0x0, eq  // eq = none
 444:	b.ls	454 <__divtf3+0x454>  // b.plast
 448:	sub	x4, x15, #0x2
 44c:	adds	x13, x13, x8
 450:	adc	x0, x0, x7
 454:	sub	x2, x13, x2
 458:	cmp	x13, x2
 45c:	sbc	x0, x0, x1
 460:	mov	x5, #0xffffffffffffffff    	// #-1
 464:	cmp	x7, x0
 468:	b.eq	564 <__divtf3+0x564>  // b.none
 46c:	udiv	x1, x0, x10
 470:	mul	x5, x11, x1
 474:	msub	x0, x1, x10, x0
 478:	extr	x0, x0, x2, #32
 47c:	cmp	x5, x0
 480:	b.ls	498 <__divtf3+0x498>  // b.plast
 484:	add	x0, x0, x7
 488:	cmp	x5, x0
 48c:	ccmp	x7, x0, #0x2, hi  // hi = pmore
 490:	b.ls	598 <__divtf3+0x598>  // b.plast
 494:	sub	x1, x1, #0x1
 498:	sub	x0, x0, x5
 49c:	udiv	x5, x0, x10
 4a0:	mul	x11, x11, x5
 4a4:	msub	x0, x5, x10, x0
 4a8:	bfi	x2, x0, #32, #32
 4ac:	mov	x0, x2
 4b0:	cmp	x11, x2
 4b4:	b.ls	4cc <__divtf3+0x4cc>  // b.plast
 4b8:	add	x0, x2, x7
 4bc:	cmp	x11, x0
 4c0:	ccmp	x7, x0, #0x2, hi  // hi = pmore
 4c4:	b.ls	5a4 <__divtf3+0x5a4>  // b.plast
 4c8:	sub	x5, x5, #0x1
 4cc:	sub	x0, x0, x11
 4d0:	orr	x2, x5, x1, lsl #32
 4d4:	lsr	x1, x2, #32
 4d8:	and	x10, x2, #0xffffffff
 4dc:	mul	x5, x16, x10
 4e0:	mul	x16, x1, x16
 4e4:	mul	x1, x14, x1
 4e8:	madd	x14, x14, x10, x16
 4ec:	add	x14, x14, x5, lsr #32
 4f0:	mov	x10, #0x100000000           	// #4294967296
 4f4:	add	x10, x1, x10
 4f8:	cmp	x16, x14
 4fc:	csel	x1, x10, x1, hi  // hi = pmore
 500:	add	x1, x1, x14, lsr #32
 504:	and	x5, x5, #0xffffffff
 508:	add	x14, x5, x14, lsl #32
 50c:	cmp	x0, x1
 510:	b.cc	520 <__divtf3+0x520>  // b.lo, b.ul, b.last
 514:	cmp	x14, #0x0
 518:	ccmp	x0, x1, #0x0, ne  // ne = any
 51c:	b.ne	5b0 <__divtf3+0x5b0>  // b.any
 520:	sub	x5, x2, #0x1
 524:	adds	x0, x0, x7
 528:	b.cs	554 <__divtf3+0x554>  // b.hs, b.nlast
 52c:	cmp	x0, x1
 530:	b.cc	53c <__divtf3+0x53c>  // b.lo, b.ul, b.last
 534:	ccmp	x8, x14, #0x2, eq  // eq = none
 538:	b.cs	554 <__divtf3+0x554>  // b.hs, b.nlast
 53c:	sub	x5, x2, #0x2
 540:	lsl	x2, x8, #1
 544:	cmp	x8, x2
 548:	cinc	x7, x7, hi  // hi = pmore
 54c:	add	x0, x0, x7
 550:	mov	x8, x2
 554:	cmp	x0, x1
 558:	orr	x0, x5, #0x1
 55c:	ccmp	x8, x14, #0x0, eq  // eq = none
 560:	csel	x5, x0, x5, ne  // ne = any
 564:	mov	x2, x9
 568:	b	2ac <__divtf3+0x2ac>
 56c:	sub	x6, x6, #0x1
 570:	mov	x0, x13
 574:	mov	x2, x10
 578:	mov	x13, #0x0                   	// #0
 57c:	b	354 <__divtf3+0x354>
 580:	sub	x4, x4, #0x2
 584:	add	x1, x1, x7
 588:	b	390 <__divtf3+0x390>
 58c:	sub	x15, x15, #0x2
 590:	add	x0, x0, x7
 594:	b	3c0 <__divtf3+0x3c0>
 598:	sub	x1, x1, #0x2
 59c:	add	x0, x0, x7
 5a0:	b	498 <__divtf3+0x498>
 5a4:	sub	x5, x5, #0x2
 5a8:	add	x0, x0, x7
 5ac:	b	4cc <__divtf3+0x4cc>
 5b0:	mov	x5, x2
 5b4:	mov	x8, #0x0                   	// #0
 5b8:	b	554 <__divtf3+0x554>
 5bc:	tbz	x10, #47, 894 <__divtf3+0x894>
 5c0:	ands	x1, x4, #0x800000000000
 5c4:	csel	x4, x10, x4, ne  // ne = any
 5c8:	cmp	x1, #0x0
 5cc:	csel	x5, x13, x5, ne  // ne = any
 5d0:	csel	x2, x0, x2, ne  // ne = any
 5d4:	b	280 <__divtf3+0x280>
 5d8:	orr	w3, w3, #0x2
 5dc:	b	d8 <__divtf3+0xd8>
 5e0:	mov	x4, x10
 5e4:	mov	x5, x13
 5e8:	mov	x2, x0
 5ec:	mov	x7, x14
 5f0:	b	298 <__divtf3+0x298>
 5f4:	cmp	x7, #0x2
 5f8:	b.ne	280 <__divtf3+0x280>  // b.any
 5fc:	mov	x9, x2
 600:	b	d8 <__divtf3+0xd8>
 604:	and	x1, x5, #0xf
 608:	cmp	x1, #0x4
 60c:	b.eq	2e0 <__divtf3+0x2e0>  // b.none
 610:	adds	x5, x5, #0x4
 614:	cinc	x4, x4, cs  // cs = hs, nlast
 618:	b	2e0 <__divtf3+0x2e0>
 61c:	cbnz	x2, 2e0 <__divtf3+0x2e0>
 620:	adds	x5, x5, #0x8
 624:	cinc	x4, x4, cs  // cs = hs, nlast
 628:	b	2e0 <__divtf3+0x2e0>
 62c:	cbz	x2, 2e0 <__divtf3+0x2e0>
 630:	adds	x5, x5, #0x8
 634:	cinc	x4, x4, cs  // cs = hs, nlast
 638:	b	2e0 <__divtf3+0x2e0>
 63c:	and	x5, x12, #0xc00000
 640:	cmp	x5, #0x400, lsl #12
 644:	b.eq	690 <__divtf3+0x690>  // b.none
 648:	cmp	x5, #0x800, lsl #12
 64c:	b.eq	6a8 <__divtf3+0x6a8>  // b.none
 650:	mov	x6, #0x7fff                	// #32767
 654:	cbz	x5, 660 <__divtf3+0x660>
 658:	mov	x5, #0xffffffffffffffff    	// #-1
 65c:	mov	x6, #0x7ffe                	// #32766
 660:	mov	w0, #0x14                  	// #20
 664:	orr	w3, w3, w0
 668:	mov	x4, x5
 66c:	mov	x1, #0x0                   	// #0
 670:	mov	x0, x5
 674:	bfxil	x1, x4, #0, #48
 678:	bfi	x1, x6, #48, #15
 67c:	bfi	x1, x2, #63, #1
 680:	stp	x0, x1, [sp, #16]
 684:	mov	w0, w3
 688:	bl	0 <__sfp_handle_exceptions>
 68c:	b	868 <__divtf3+0x868>
 690:	cmp	x2, #0x0
 694:	csetm	x5, ne  // ne = any
 698:	mov	x6, #0x7ffe                	// #32766
 69c:	mov	x0, #0x7fff                	// #32767
 6a0:	csel	x6, x6, x0, ne  // ne = any
 6a4:	b	660 <__divtf3+0x660>
 6a8:	cmp	x2, #0x0
 6ac:	csetm	x5, eq  // eq = none
 6b0:	mov	x6, #0x7ffe                	// #32766
 6b4:	mov	x0, #0x7fff                	// #32767
 6b8:	csel	x6, x6, x0, eq  // eq = none
 6bc:	b	660 <__divtf3+0x660>
 6c0:	mov	x1, #0x1                   	// #1
 6c4:	sub	x0, x1, x0
 6c8:	cmp	x0, #0x74
 6cc:	b.gt	7d0 <__divtf3+0x7d0>
 6d0:	cmp	x0, #0x3f
 6d4:	b.gt	718 <__divtf3+0x718>
 6d8:	mov	w6, #0x40                  	// #64
 6dc:	sub	w6, w6, w0
 6e0:	lsl	x1, x4, x6
 6e4:	lsr	x7, x5, x0
 6e8:	orr	x1, x1, x7
 6ec:	lsl	x5, x5, x6
 6f0:	cmp	x5, #0x0
 6f4:	cset	x5, ne  // ne = any
 6f8:	orr	x1, x1, x5
 6fc:	lsr	x0, x4, x0
 700:	tst	x1, #0x7
 704:	b.ne	760 <__divtf3+0x760>  // b.any
 708:	tbnz	x0, #51, 780 <__divtf3+0x780>
 70c:	extr	x5, x0, x1, #3
 710:	lsr	x4, x0, #3
 714:	b	750 <__divtf3+0x750>
 718:	sub	w6, w0, #0x40
 71c:	lsr	x6, x4, x6
 720:	mov	w1, #0x80                  	// #128
 724:	sub	w1, w1, w0
 728:	lsl	x4, x4, x1
 72c:	cmp	x0, #0x40
 730:	csel	x0, x4, xzr, ne  // ne = any
 734:	orr	x5, x0, x5
 738:	cmp	x5, #0x0
 73c:	cset	x1, ne  // ne = any
 740:	orr	x1, x6, x1
 744:	lsr	x5, x6, #3
 748:	ands	x4, x1, #0x7
 74c:	b.ne	75c <__divtf3+0x75c>  // b.any
 750:	tbz	w12, #11, 888 <__divtf3+0x888>
 754:	mov	x6, #0x0                   	// #0
 758:	b	790 <__divtf3+0x790>
 75c:	mov	x0, #0x0                   	// #0
 760:	orr	w3, w3, #0x10
 764:	and	x12, x12, #0xc00000
 768:	cmp	x12, #0x400, lsl #12
 76c:	b.eq	7b0 <__divtf3+0x7b0>  // b.none
 770:	cmp	x12, #0x800, lsl #12
 774:	b.eq	7c0 <__divtf3+0x7c0>  // b.none
 778:	cbz	x12, 798 <__divtf3+0x798>
 77c:	tbz	x0, #51, 8a4 <__divtf3+0x8a4>
 780:	orr	w3, w3, #0x10
 784:	mov	x4, #0x0                   	// #0
 788:	mov	x5, #0x0                   	// #0
 78c:	mov	x6, #0x1                   	// #1
 790:	orr	w3, w3, #0x8
 794:	b	66c <__divtf3+0x66c>
 798:	and	x4, x1, #0xf
 79c:	cmp	x4, #0x4
 7a0:	b.eq	77c <__divtf3+0x77c>  // b.none
 7a4:	adds	x1, x1, #0x4
 7a8:	cinc	x0, x0, cs  // cs = hs, nlast
 7ac:	b	77c <__divtf3+0x77c>
 7b0:	cbnz	x2, 77c <__divtf3+0x77c>
 7b4:	adds	x1, x1, #0x8
 7b8:	cinc	x0, x0, cs  // cs = hs, nlast
 7bc:	b	77c <__divtf3+0x77c>
 7c0:	cbz	x2, 77c <__divtf3+0x77c>
 7c4:	adds	x1, x1, #0x8
 7c8:	cinc	x0, x0, cs  // cs = hs, nlast
 7cc:	b	77c <__divtf3+0x77c>
 7d0:	orr	x5, x5, x4
 7d4:	cbz	x5, 800 <__divtf3+0x800>
 7d8:	orr	w3, w3, #0x10
 7dc:	and	x12, x12, #0xc00000
 7e0:	cmp	x12, #0x400, lsl #12
 7e4:	b.eq	810 <__divtf3+0x810>  // b.none
 7e8:	cmp	x12, #0x800, lsl #12
 7ec:	b.eq	820 <__divtf3+0x820>  // b.none
 7f0:	cmp	x12, #0x0
 7f4:	mov	x5, #0x5                   	// #5
 7f8:	csinc	x5, x5, xzr, eq  // eq = none
 7fc:	lsr	x5, x5, #3
 800:	orr	w3, w3, #0x8
 804:	mov	x4, #0x0                   	// #0
 808:	mov	x6, #0x0                   	// #0
 80c:	b	66c <__divtf3+0x66c>
 810:	cmp	x2, #0x0
 814:	mov	x5, #0x9                   	// #9
 818:	csinc	x5, x5, xzr, eq  // eq = none
 81c:	b	7fc <__divtf3+0x7fc>
 820:	cmp	x2, #0x0
 824:	mov	x5, #0x9                   	// #9
 828:	csinc	x5, x5, xzr, ne  // ne = any
 82c:	b	7fc <__divtf3+0x7fc>
 830:	mov	x4, #0x0                   	// #0
 834:	mov	x5, #0x0                   	// #0
 838:	mov	x6, #0x0                   	// #0
 83c:	b	84c <__divtf3+0x84c>
 840:	mov	x4, #0x0                   	// #0
 844:	mov	x5, #0x0                   	// #0
 848:	mov	x6, #0x0                   	// #0
 84c:	mov	x1, #0x0                   	// #0
 850:	mov	x0, x5
 854:	bfxil	x1, x4, #0, #48
 858:	bfi	x1, x6, #48, #15
 85c:	bfi	x1, x9, #63, #1
 860:	stp	x0, x1, [sp, #16]
 864:	cbnz	w3, 684 <__divtf3+0x684>
 868:	ldr	q0, [sp, #16]
 86c:	ldp	x29, x30, [sp], #32
 870:	ret
 874:	mov	x9, x2
 878:	mov	x4, #0x0                   	// #0
 87c:	mov	x5, #0x0                   	// #0
 880:	mov	x6, #0x0                   	// #0
 884:	b	84c <__divtf3+0x84c>
 888:	mov	x9, x2
 88c:	mov	x6, #0x0                   	// #0
 890:	b	84c <__divtf3+0x84c>
 894:	mov	x4, x10
 898:	mov	x5, x13
 89c:	mov	x2, x0
 8a0:	b	280 <__divtf3+0x280>
 8a4:	extr	x5, x0, x1, #3
 8a8:	lsr	x4, x0, #3
 8ac:	mov	x6, #0x0                   	// #0
 8b0:	b	790 <__divtf3+0x790>

eqtf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__eqtf2>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	q0, [sp, #16]
   c:	ldr	x5, [sp, #16]
  10:	ldr	x0, [sp, #24]
  14:	str	q1, [sp, #16]
  18:	ldr	x6, [sp, #16]
  1c:	ldr	x2, [sp, #24]
  20:	mrs	x1, fpcr
  24:	mov	x10, x5
  28:	ubfx	x7, x0, #0, #48
  2c:	ubfx	x3, x0, #48, #15
  30:	lsr	x0, x0, #63
  34:	and	w1, w0, #0xff
  38:	mov	x9, x6
  3c:	ubfx	x8, x2, #0, #48
  40:	ubfx	x4, x2, #48, #15
  44:	lsr	x0, x2, #63
  48:	and	w2, w0, #0xff
  4c:	mov	x0, #0x7fff                	// #32767
  50:	cmp	x3, x0
  54:	b.eq	78 <__eqtf2+0x78>  // b.none
  58:	mov	x0, #0x7fff                	// #32767
  5c:	cmp	x4, x0
  60:	b.eq	94 <__eqtf2+0x94>  // b.none
  64:	mov	w0, #0x1                   	// #1
  68:	cmp	x3, x4
  6c:	b.eq	c4 <__eqtf2+0xc4>  // b.none
  70:	ldp	x29, x30, [sp], #32
  74:	ret
  78:	orr	x0, x7, x5
  7c:	cbnz	x0, fc <__eqtf2+0xfc>
  80:	mov	x0, #0x7fff                	// #32767
  84:	cmp	x4, x0
  88:	b.eq	94 <__eqtf2+0x94>  // b.none
  8c:	mov	w0, #0x1                   	// #1
  90:	b	70 <__eqtf2+0x70>
  94:	orr	x0, x8, x9
  98:	cbz	x0, 64 <__eqtf2+0x64>
  9c:	mov	x0, #0x7fff                	// #32767
  a0:	cmp	x3, x0
  a4:	b.eq	f4 <__eqtf2+0xf4>  // b.none
  a8:	mov	w0, #0x1                   	// #1
  ac:	tst	x8, #0x800000000000
  b0:	b.ne	70 <__eqtf2+0x70>  // b.any
  b4:	mov	w0, #0x1                   	// #1
  b8:	bl	0 <__sfp_handle_exceptions>
  bc:	mov	w0, #0x1                   	// #1
  c0:	b	70 <__eqtf2+0x70>
  c4:	cmp	x7, x8
  c8:	ccmp	x5, x6, #0x0, eq  // eq = none
  cc:	b.ne	70 <__eqtf2+0x70>  // b.any
  d0:	mov	w0, #0x0                   	// #0
  d4:	cmp	w1, w2
  d8:	b.eq	70 <__eqtf2+0x70>  // b.none
  dc:	mov	w0, #0x1                   	// #1
  e0:	cbnz	x3, 70 <__eqtf2+0x70>
  e4:	orr	x7, x7, x10
  e8:	cmp	x7, #0x0
  ec:	cset	w0, ne  // ne = any
  f0:	b	70 <__eqtf2+0x70>
  f4:	orr	x10, x7, x10
  f8:	cbz	x10, 114 <__eqtf2+0x114>
  fc:	tst	x7, #0x800000000000
 100:	b.eq	b4 <__eqtf2+0xb4>  // b.none
 104:	mov	w0, #0x1                   	// #1
 108:	mov	x1, #0x7fff                	// #32767
 10c:	cmp	x4, x1
 110:	b.ne	70 <__eqtf2+0x70>  // b.any
 114:	orr	x9, x8, x9
 118:	mov	w0, #0x1                   	// #1
 11c:	cbz	x9, 70 <__eqtf2+0x70>
 120:	b	a8 <__eqtf2+0xa8>

getf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__getf2>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	q0, [sp, #16]
   c:	ldr	x7, [sp, #16]
  10:	ldr	x1, [sp, #24]
  14:	str	q1, [sp, #16]
  18:	ldr	x8, [sp, #16]
  1c:	ldr	x0, [sp, #24]
  20:	mrs	x2, fpcr
  24:	mov	x5, x7
  28:	ubfx	x9, x1, #0, #48
  2c:	ubfx	x4, x1, #48, #15
  30:	lsr	x1, x1, #63
  34:	and	w2, w1, #0xff
  38:	mov	x6, x8
  3c:	ubfx	x10, x0, #0, #48
  40:	ubfx	x3, x0, #48, #15
  44:	lsr	x0, x0, #63
  48:	and	w1, w0, #0xff
  4c:	mov	x0, #0x7fff                	// #32767
  50:	cmp	x4, x0
  54:	b.eq	94 <__getf2+0x94>  // b.none
  58:	mov	x0, #0x7fff                	// #32767
  5c:	cmp	x3, x0
  60:	b.eq	b0 <__getf2+0xb0>  // b.none
  64:	mov	w0, #0x0                   	// #0
  68:	cbnz	x4, 78 <__getf2+0x78>
  6c:	orr	x5, x5, x9
  70:	cmp	x5, #0x0
  74:	cset	w0, eq  // eq = none
  78:	cbnz	x3, c0 <__getf2+0xc0>
  7c:	orr	x6, x10, x6
  80:	cbnz	x6, c0 <__getf2+0xc0>
  84:	cbz	w0, d4 <__getf2+0xd4>
  88:	mov	w0, #0x0                   	// #0
  8c:	ldp	x29, x30, [sp], #32
  90:	ret
  94:	orr	x0, x7, x9
  98:	cbnz	x0, 15c <__getf2+0x15c>
  9c:	mov	x0, #0x7fff                	// #32767
  a0:	cmp	x3, x0
  a4:	b.eq	b0 <__getf2+0xb0>  // b.none
  a8:	mov	w0, #0x0                   	// #0
  ac:	b	78 <__getf2+0x78>
  b0:	orr	x0, x10, x6
  b4:	cbnz	x0, 15c <__getf2+0x15c>
  b8:	mov	w0, #0x0                   	// #0
  bc:	cbz	x4, 6c <__getf2+0x6c>
  c0:	and	x1, x1, #0xff
  c4:	cbz	w0, 16c <__getf2+0x16c>
  c8:	cmp	x1, #0x0
  cc:	csinv	w0, w0, wzr, ne  // ne = any
  d0:	b	8c <__getf2+0x8c>
  d4:	mov	w0, #0x1                   	// #1
  d8:	cmp	w2, #0x0
  dc:	cneg	w0, w0, ne  // ne = any
  e0:	b	8c <__getf2+0x8c>
  e4:	cmp	x4, x3
  e8:	b.le	fc <__getf2+0xfc>
  ec:	mov	w0, #0x1                   	// #1
  f0:	cmp	x5, #0x0
  f4:	cneg	w0, w0, ne  // ne = any
  f8:	b	8c <__getf2+0x8c>
  fc:	b.ge	110 <__getf2+0x110>  // b.tcont
 100:	mov	w0, #0xffffffff            	// #-1
 104:	cmp	x5, #0x0
 108:	cneg	w0, w0, ne  // ne = any
 10c:	b	8c <__getf2+0x8c>
 110:	cmp	x9, x10
 114:	b.hi	128 <__getf2+0x128>  // b.pmore
 118:	cset	w1, eq  // eq = none
 11c:	cmp	w1, #0x0
 120:	ccmp	x7, x8, #0x0, ne  // ne = any
 124:	b.ls	138 <__getf2+0x138>  // b.plast
 128:	mov	w0, #0x1                   	// #1
 12c:	cmp	x5, #0x0
 130:	cneg	w0, w0, ne  // ne = any
 134:	b	8c <__getf2+0x8c>
 138:	cmp	x9, x10
 13c:	b.cc	14c <__getf2+0x14c>  // b.lo, b.ul, b.last
 140:	cmp	w1, #0x0
 144:	ccmp	x7, x8, #0x2, ne  // ne = any
 148:	b.cs	8c <__getf2+0x8c>  // b.hs, b.nlast
 14c:	mov	w0, #0xffffffff            	// #-1
 150:	cmp	x5, #0x0
 154:	cneg	w0, w0, ne  // ne = any
 158:	b	8c <__getf2+0x8c>
 15c:	mov	w0, #0x1                   	// #1
 160:	bl	0 <__sfp_handle_exceptions>
 164:	mov	w0, #0xfffffffe            	// #-2
 168:	b	8c <__getf2+0x8c>
 16c:	and	x5, x2, #0xff
 170:	cmp	x1, w2, uxtb
 174:	b.eq	e4 <__getf2+0xe4>  // b.none
 178:	mov	w0, #0x1                   	// #1
 17c:	cmp	x5, #0x0
 180:	cneg	w0, w0, ne  // ne = any
 184:	b	8c <__getf2+0x8c>

letf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__letf2>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	q0, [sp, #16]
   c:	ldr	x7, [sp, #16]
  10:	ldr	x1, [sp, #24]
  14:	str	q1, [sp, #16]
  18:	ldr	x8, [sp, #16]
  1c:	ldr	x0, [sp, #24]
  20:	mrs	x2, fpcr
  24:	mov	x5, x7
  28:	ubfx	x9, x1, #0, #48
  2c:	ubfx	x3, x1, #48, #15
  30:	lsr	x1, x1, #63
  34:	and	w2, w1, #0xff
  38:	mov	x6, x8
  3c:	ubfx	x10, x0, #0, #48
  40:	ubfx	x4, x0, #48, #15
  44:	lsr	x0, x0, #63
  48:	and	w1, w0, #0xff
  4c:	mov	x0, #0x7fff                	// #32767
  50:	cmp	x3, x0
  54:	b.eq	94 <__letf2+0x94>  // b.none
  58:	mov	x0, #0x7fff                	// #32767
  5c:	cmp	x4, x0
  60:	b.eq	b0 <__letf2+0xb0>  // b.none
  64:	mov	w0, #0x0                   	// #0
  68:	cbnz	x3, 78 <__letf2+0x78>
  6c:	orr	x5, x5, x9
  70:	cmp	x5, #0x0
  74:	cset	w0, eq  // eq = none
  78:	cbnz	x4, c0 <__letf2+0xc0>
  7c:	orr	x6, x10, x6
  80:	cbnz	x6, c0 <__letf2+0xc0>
  84:	cbz	w0, d4 <__letf2+0xd4>
  88:	mov	w0, #0x0                   	// #0
  8c:	ldp	x29, x30, [sp], #32
  90:	ret
  94:	orr	x0, x7, x9
  98:	cbnz	x0, 15c <__letf2+0x15c>
  9c:	mov	x0, #0x7fff                	// #32767
  a0:	cmp	x4, x0
  a4:	b.eq	b0 <__letf2+0xb0>  // b.none
  a8:	mov	w0, #0x0                   	// #0
  ac:	b	78 <__letf2+0x78>
  b0:	orr	x0, x10, x6
  b4:	cbnz	x0, 15c <__letf2+0x15c>
  b8:	mov	w0, #0x0                   	// #0
  bc:	cbz	x3, 6c <__letf2+0x6c>
  c0:	and	x1, x1, #0xff
  c4:	cbz	w0, 16c <__letf2+0x16c>
  c8:	cmp	x1, #0x0
  cc:	csinv	w0, w0, wzr, ne  // ne = any
  d0:	b	8c <__letf2+0x8c>
  d4:	mov	w0, #0x1                   	// #1
  d8:	cmp	w2, #0x0
  dc:	cneg	w0, w0, ne  // ne = any
  e0:	b	8c <__letf2+0x8c>
  e4:	cmp	x3, x4
  e8:	b.le	fc <__letf2+0xfc>
  ec:	mov	w0, #0x1                   	// #1
  f0:	cmp	x5, #0x0
  f4:	cneg	w0, w0, ne  // ne = any
  f8:	b	8c <__letf2+0x8c>
  fc:	b.ge	110 <__letf2+0x110>  // b.tcont
 100:	mov	w0, #0xffffffff            	// #-1
 104:	cmp	x5, #0x0
 108:	cneg	w0, w0, ne  // ne = any
 10c:	b	8c <__letf2+0x8c>
 110:	cmp	x9, x10
 114:	b.hi	128 <__letf2+0x128>  // b.pmore
 118:	cset	w1, eq  // eq = none
 11c:	cmp	w1, #0x0
 120:	ccmp	x7, x8, #0x0, ne  // ne = any
 124:	b.ls	138 <__letf2+0x138>  // b.plast
 128:	mov	w0, #0x1                   	// #1
 12c:	cmp	x5, #0x0
 130:	cneg	w0, w0, ne  // ne = any
 134:	b	8c <__letf2+0x8c>
 138:	cmp	x9, x10
 13c:	b.cc	14c <__letf2+0x14c>  // b.lo, b.ul, b.last
 140:	cmp	w1, #0x0
 144:	ccmp	x7, x8, #0x2, ne  // ne = any
 148:	b.cs	8c <__letf2+0x8c>  // b.hs, b.nlast
 14c:	mov	w0, #0xffffffff            	// #-1
 150:	cmp	x5, #0x0
 154:	cneg	w0, w0, ne  // ne = any
 158:	b	8c <__letf2+0x8c>
 15c:	mov	w0, #0x1                   	// #1
 160:	bl	0 <__sfp_handle_exceptions>
 164:	mov	w0, #0x2                   	// #2
 168:	b	8c <__letf2+0x8c>
 16c:	and	x5, x2, #0xff
 170:	cmp	x1, w2, uxtb
 174:	b.eq	e4 <__letf2+0xe4>  // b.none
 178:	mov	w0, #0x1                   	// #1
 17c:	cmp	x5, #0x0
 180:	cneg	w0, w0, ne  // ne = any
 184:	b	8c <__letf2+0x8c>

multf3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__multf3>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	q0, [sp, #16]
   c:	ldr	x2, [sp, #16]
  10:	ldr	x0, [sp, #24]
  14:	str	q1, [sp, #16]
  18:	ldr	x7, [sp, #16]
  1c:	ldr	x1, [sp, #24]
  20:	mrs	x13, fpcr
  24:	ubfx	x8, x0, #0, #48
  28:	ubfx	x9, x0, #48, #15
  2c:	lsr	x0, x0, #63
  30:	and	w11, w0, #0xff
  34:	cbz	w9, 11c <__multf3+0x11c>
  38:	mov	x4, x8
  3c:	mov	w5, #0x7fff                	// #32767
  40:	cmp	w9, w5
  44:	b.eq	184 <__multf3+0x184>  // b.none
  48:	extr	x4, x8, x2, #61
  4c:	orr	x4, x4, #0x8000000000000
  50:	lsl	x5, x2, #3
  54:	and	x9, x9, #0xffff
  58:	sub	x9, x9, #0x3, lsl #12
  5c:	sub	x9, x9, #0xfff
  60:	mov	x6, #0x0                   	// #0
  64:	mov	w8, #0x0                   	// #0
  68:	ubfx	x14, x1, #0, #48
  6c:	ubfx	x12, x1, #48, #15
  70:	lsr	x1, x1, #63
  74:	and	w3, w1, #0xff
  78:	cbz	w12, 1cc <__multf3+0x1cc>
  7c:	mov	w10, #0x7fff                	// #32767
  80:	cmp	w12, w10
  84:	b.eq	230 <__multf3+0x230>  // b.none
  88:	extr	x10, x14, x7, #61
  8c:	orr	x10, x10, #0x8000000000000
  90:	lsl	x7, x7, #3
  94:	and	x12, x12, #0xffff
  98:	sub	x12, x12, #0x3, lsl #12
  9c:	sub	x12, x12, #0xfff
  a0:	mov	x14, #0x0                   	// #0
  a4:	eor	w11, w11, w3
  a8:	and	x11, x11, #0xff
  ac:	add	x12, x9, x12
  b0:	add	x9, x12, #0x1
  b4:	orr	x3, x14, x6, lsl #2
  b8:	cmp	x3, #0xa
  bc:	b.le	2d0 <__multf3+0x2d0>
  c0:	cmp	x3, #0xc
  c4:	csel	x1, x1, x0, lt  // lt = tstop
  c8:	csel	x4, x10, x4, lt  // lt = tstop
  cc:	csel	x5, x7, x5, lt  // lt = tstop
  d0:	csel	x6, x14, x6, lt  // lt = tstop
  d4:	cmp	x6, #0x2
  d8:	b.eq	6b8 <__multf3+0x6b8>  // b.none
  dc:	b.gt	31c <__multf3+0x31c>
  e0:	cbz	x6, 6d8 <__multf3+0x6d8>
  e4:	cmp	x6, #0x1
  e8:	csel	x4, x4, xzr, ne  // ne = any
  ec:	csel	x5, x5, xzr, ne  // ne = any
  f0:	csel	x9, x9, xzr, ne  // ne = any
  f4:	mov	x3, #0x0                   	// #0
  f8:	mov	x2, x5
  fc:	bfxil	x3, x4, #0, #48
 100:	bfi	x3, x9, #48, #15
 104:	bfi	x3, x1, #63, #1
 108:	stp	x2, x3, [sp, #16]
 10c:	cbnz	w8, 50c <__multf3+0x50c>
 110:	ldr	q0, [sp, #16]
 114:	ldp	x29, x30, [sp], #32
 118:	ret
 11c:	orr	x5, x8, x2
 120:	cbz	x5, 1a4 <__multf3+0x1a4>
 124:	cbz	x8, 160 <__multf3+0x160>
 128:	clz	x6, x8
 12c:	sub	x4, x6, #0xf
 130:	add	w5, w4, #0x3
 134:	lsl	x8, x8, x5
 138:	mov	w3, #0x3d                  	// #61
 13c:	sub	w4, w3, w4
 140:	lsr	x4, x2, x4
 144:	orr	x4, x4, x8
 148:	lsl	x5, x2, x5
 14c:	mov	x9, #0xffffffffffffc011    	// #-16367
 150:	sub	x9, x9, x6
 154:	mov	x6, #0x0                   	// #0
 158:	mov	w8, #0x0                   	// #0
 15c:	b	68 <__multf3+0x68>
 160:	clz	x4, x2
 164:	add	x6, x4, #0x40
 168:	add	x4, x4, #0x31
 16c:	cmp	x4, #0x3c
 170:	b.le	130 <__multf3+0x130>
 174:	sub	w4, w4, #0x3d
 178:	mov	x5, x8
 17c:	lsl	x4, x2, x4
 180:	b	14c <__multf3+0x14c>
 184:	orr	x5, x8, x2
 188:	cbz	x5, 1b8 <__multf3+0x1b8>
 18c:	lsr	x8, x8, #47
 190:	eor	w8, w8, #0x1
 194:	mov	x5, x2
 198:	mov	x9, #0x7fff                	// #32767
 19c:	mov	x6, #0x3                   	// #3
 1a0:	b	68 <__multf3+0x68>
 1a4:	mov	x4, x5
 1a8:	mov	x9, #0x0                   	// #0
 1ac:	mov	x6, #0x1                   	// #1
 1b0:	mov	w8, #0x0                   	// #0
 1b4:	b	68 <__multf3+0x68>
 1b8:	mov	x4, x5
 1bc:	mov	x9, #0x7fff                	// #32767
 1c0:	mov	x6, #0x2                   	// #2
 1c4:	mov	w8, #0x0                   	// #0
 1c8:	b	68 <__multf3+0x68>
 1cc:	orr	x10, x14, x7
 1d0:	cbz	x10, 744 <__multf3+0x744>
 1d4:	cbz	x14, 20c <__multf3+0x20c>
 1d8:	clz	x15, x14
 1dc:	sub	x10, x15, #0xf
 1e0:	add	w12, w10, #0x3
 1e4:	lsl	x14, x14, x12
 1e8:	mov	w2, #0x3d                  	// #61
 1ec:	sub	w10, w2, w10
 1f0:	lsr	x10, x7, x10
 1f4:	orr	x10, x10, x14
 1f8:	lsl	x7, x7, x12
 1fc:	mov	x12, #0xffffffffffffc011    	// #-16367
 200:	sub	x12, x12, x15
 204:	mov	x14, #0x0                   	// #0
 208:	b	a4 <__multf3+0xa4>
 20c:	clz	x10, x7
 210:	add	x15, x10, #0x40
 214:	add	x10, x10, #0x31
 218:	cmp	x10, #0x3c
 21c:	b.le	1e0 <__multf3+0x1e0>
 220:	sub	w10, w10, #0x3d
 224:	lsl	x10, x7, x10
 228:	mov	x7, x14
 22c:	b	1fc <__multf3+0x1fc>
 230:	orr	x10, x14, x7
 234:	cbz	x10, 2a4 <__multf3+0x2a4>
 238:	tst	x14, #0x800000000000
 23c:	csinc	w8, w8, wzr, ne  // ne = any
 240:	eor	w11, w11, w3
 244:	and	x11, x11, #0xff
 248:	add	x9, x9, #0x8, lsl #12
 24c:	lsl	x2, x6, #2
 250:	orr	x3, x2, #0x3
 254:	cmp	x3, #0xa
 258:	b.gt	328 <__multf3+0x328>
 25c:	mov	x10, x14
 260:	mov	x14, #0x3                   	// #3
 264:	mov	x2, #0x1                   	// #1
 268:	lsl	x2, x2, x3
 26c:	mov	x0, #0x530                 	// #1328
 270:	tst	x2, x0
 274:	b.ne	484 <__multf3+0x484>  // b.any
 278:	mov	x0, #0x240                 	// #576
 27c:	ands	x2, x2, x0
 280:	mov	x4, #0xffffffffffff        	// #281474976710655
 284:	csel	x4, x10, x4, eq  // eq = none
 288:	cmp	x2, #0x0
 28c:	csinv	x5, x7, xzr, eq  // eq = none
 290:	csel	x1, x1, xzr, eq  // eq = none
 294:	mov	x6, #0x3                   	// #3
 298:	csel	x6, x14, x6, eq  // eq = none
 29c:	csinc	w8, w8, wzr, eq  // eq = none
 2a0:	b	d4 <__multf3+0xd4>
 2a4:	eor	w11, w11, w3
 2a8:	and	x11, x11, #0xff
 2ac:	add	x12, x9, #0x7, lsl #12
 2b0:	add	x12, x12, #0xfff
 2b4:	add	x9, x9, #0x8, lsl #12
 2b8:	lsl	x2, x6, #2
 2bc:	orr	x3, x2, #0x2
 2c0:	cmp	x3, #0xa
 2c4:	b.gt	2f0 <__multf3+0x2f0>
 2c8:	mov	x7, x10
 2cc:	mov	x14, #0x2                   	// #2
 2d0:	cmp	x3, #0x2
 2d4:	b.gt	264 <__multf3+0x264>
 2d8:	cbz	x3, 334 <__multf3+0x334>
 2dc:	mov	x4, x10
 2e0:	mov	x5, x7
 2e4:	mov	x1, x11
 2e8:	mov	x6, x14
 2ec:	b	d4 <__multf3+0xd4>
 2f0:	mov	x7, x10
 2f4:	mov	x14, #0x2                   	// #2
 2f8:	cmp	x3, #0xe
 2fc:	b.le	c0 <__multf3+0xc0>
 300:	tbz	x4, #47, 318 <__multf3+0x318>
 304:	ands	x2, x10, #0x800000000000
 308:	csel	x4, x4, x10, ne  // ne = any
 30c:	cmp	x2, #0x0
 310:	csel	x5, x5, x7, ne  // ne = any
 314:	csel	x0, x0, x1, ne  // ne = any
 318:	mov	x1, x0
 31c:	orr	x4, x4, #0x800000000000
 320:	mov	x9, #0x7fff                	// #32767
 324:	b	f4 <__multf3+0xf4>
 328:	mov	x10, x14
 32c:	mov	x14, #0x3                   	// #3
 330:	b	2f8 <__multf3+0x2f8>
 334:	lsr	x6, x5, #32
 338:	lsr	x1, x7, #32
 33c:	and	x2, x5, #0xffffffff
 340:	and	x7, x7, #0xffffffff
 344:	mul	x14, x7, x2
 348:	mul	x3, x6, x7
 34c:	mul	x5, x6, x1
 350:	madd	x16, x1, x2, x3
 354:	add	x16, x16, x14, lsr #32
 358:	mov	x0, #0x100000000           	// #4294967296
 35c:	add	x0, x5, x0
 360:	cmp	x3, x16
 364:	csel	x5, x0, x5, hi  // hi = pmore
 368:	and	x14, x14, #0xffffffff
 36c:	add	x14, x14, x16, lsl #32
 370:	lsr	x0, x10, #32
 374:	and	x10, x10, #0xffffffff
 378:	mul	x3, x2, x10
 37c:	mul	x17, x6, x10
 380:	mul	x6, x6, x0
 384:	madd	x2, x0, x2, x17
 388:	add	x2, x2, x3, lsr #32
 38c:	mov	x15, #0x100000000           	// #4294967296
 390:	add	x15, x6, x15
 394:	cmp	x17, x2
 398:	csel	x6, x15, x6, hi  // hi = pmore
 39c:	add	x15, x6, x2, lsr #32
 3a0:	and	x3, x3, #0xffffffff
 3a4:	add	x3, x3, x2, lsl #32
 3a8:	add	x16, x3, x16, lsr #32
 3ac:	lsr	x2, x4, #32
 3b0:	and	x4, x4, #0xffffffff
 3b4:	mul	x6, x7, x4
 3b8:	mul	x7, x2, x7
 3bc:	mul	x17, x1, x2
 3c0:	madd	x1, x1, x4, x7
 3c4:	add	x1, x1, x6, lsr #32
 3c8:	mov	x18, #0x100000000           	// #4294967296
 3cc:	add	x18, x17, x18
 3d0:	cmp	x7, x1
 3d4:	csel	x17, x18, x17, hi  // hi = pmore
 3d8:	add	x7, x17, x1, lsr #32
 3dc:	and	x6, x6, #0xffffffff
 3e0:	add	x1, x6, x1, lsl #32
 3e4:	mul	x6, x4, x10
 3e8:	mul	x10, x2, x10
 3ec:	mul	x2, x0, x2
 3f0:	madd	x0, x0, x4, x10
 3f4:	add	x0, x0, x6, lsr #32
 3f8:	mov	x4, #0x100000000           	// #4294967296
 3fc:	add	x4, x2, x4
 400:	cmp	x10, x0
 404:	csel	x2, x4, x2, hi  // hi = pmore
 408:	add	x5, x5, x16
 40c:	cmp	x5, x3
 410:	cset	x16, cc  // cc = lo, ul, last
 414:	and	x3, x6, #0xffffffff
 418:	add	x3, x3, x0, lsl #32
 41c:	add	x3, x3, x15
 420:	cinc	x10, x3, cc  // cc = lo, ul, last
 424:	adds	x1, x5, x1
 428:	cset	x5, cs  // cs = hs, nlast
 42c:	add	x4, x10, x7
 430:	cinc	x6, x4, cs  // cs = hs, nlast
 434:	cmp	x3, x15
 438:	ccmp	x10, x16, #0x0, cs  // cs = hs, nlast
 43c:	lsr	x0, x0, #32
 440:	cinc	x0, x0, cc  // cc = lo, ul, last
 444:	cmp	x4, x7
 448:	ccmp	x6, x5, #0x0, cs  // cs = hs, nlast
 44c:	cinc	x2, x2, cc  // cc = lo, ul, last
 450:	add	x0, x0, x2
 454:	extr	x4, x0, x6, #51
 458:	orr	x14, x14, x1, lsl #13
 45c:	cmp	x14, #0x0
 460:	cset	x5, ne  // ne = any
 464:	extr	x1, x6, x1, #51
 468:	orr	x5, x5, x1
 46c:	tbz	x0, #39, 6d0 <__multf3+0x6d0>
 470:	and	x0, x5, #0x1
 474:	orr	x5, x0, x5, lsr #1
 478:	orr	x5, x5, x4, lsl #63
 47c:	lsr	x4, x4, #1
 480:	b	6d4 <__multf3+0x6d4>
 484:	mov	x1, x11
 488:	b	d4 <__multf3+0xd4>
 48c:	and	x2, x5, #0xf
 490:	cmp	x2, #0x4
 494:	b.eq	70c <__multf3+0x70c>  // b.none
 498:	adds	x5, x5, #0x4
 49c:	cinc	x4, x4, cs  // cs = hs, nlast
 4a0:	b	70c <__multf3+0x70c>
 4a4:	cbnz	x1, 70c <__multf3+0x70c>
 4a8:	adds	x5, x5, #0x8
 4ac:	cinc	x4, x4, cs  // cs = hs, nlast
 4b0:	b	70c <__multf3+0x70c>
 4b4:	cbz	x1, 70c <__multf3+0x70c>
 4b8:	adds	x5, x5, #0x8
 4bc:	cinc	x4, x4, cs  // cs = hs, nlast
 4c0:	b	70c <__multf3+0x70c>
 4c4:	and	x5, x13, #0xc00000
 4c8:	cmp	x5, #0x400, lsl #12
 4cc:	b.eq	518 <__multf3+0x518>  // b.none
 4d0:	cmp	x5, #0x800, lsl #12
 4d4:	b.eq	530 <__multf3+0x530>  // b.none
 4d8:	mov	x0, #0x7fff                	// #32767
 4dc:	cbz	x5, 4e8 <__multf3+0x4e8>
 4e0:	mov	x5, #0xffffffffffffffff    	// #-1
 4e4:	mov	x0, #0x7ffe                	// #32766
 4e8:	mov	w2, #0x14                  	// #20
 4ec:	orr	w8, w8, w2
 4f0:	mov	x4, x5
 4f4:	mov	x3, #0x0                   	// #0
 4f8:	mov	x2, x5
 4fc:	bfxil	x3, x4, #0, #48
 500:	bfi	x3, x0, #48, #15
 504:	bfi	x3, x1, #63, #1
 508:	stp	x2, x3, [sp, #16]
 50c:	mov	w0, w8
 510:	bl	0 <__sfp_handle_exceptions>
 514:	b	110 <__multf3+0x110>
 518:	cmp	x1, #0x0
 51c:	csetm	x5, ne  // ne = any
 520:	mov	x0, #0x7ffe                	// #32766
 524:	mov	x2, #0x7fff                	// #32767
 528:	csel	x0, x0, x2, ne  // ne = any
 52c:	b	4e8 <__multf3+0x4e8>
 530:	cmp	x1, #0x0
 534:	csetm	x5, eq  // eq = none
 538:	mov	x0, #0x7ffe                	// #32766
 53c:	mov	x2, #0x7fff                	// #32767
 540:	csel	x0, x0, x2, eq  // eq = none
 544:	b	4e8 <__multf3+0x4e8>
 548:	mov	x2, #0x1                   	// #1
 54c:	sub	x0, x2, x0
 550:	cmp	x0, #0x74
 554:	b.gt	658 <__multf3+0x658>
 558:	cmp	x0, #0x3f
 55c:	b.gt	5a0 <__multf3+0x5a0>
 560:	mov	w3, #0x40                  	// #64
 564:	sub	w3, w3, w0
 568:	lsl	x2, x4, x3
 56c:	lsr	x6, x5, x0
 570:	orr	x2, x2, x6
 574:	lsl	x3, x5, x3
 578:	cmp	x3, #0x0
 57c:	cset	x3, ne  // ne = any
 580:	orr	x2, x2, x3
 584:	lsr	x0, x4, x0
 588:	tst	x2, #0x7
 58c:	b.ne	5e8 <__multf3+0x5e8>  // b.any
 590:	tbnz	x0, #51, 608 <__multf3+0x608>
 594:	extr	x5, x0, x2, #3
 598:	lsr	x4, x0, #3
 59c:	b	5d8 <__multf3+0x5d8>
 5a0:	sub	w3, w0, #0x40
 5a4:	lsr	x3, x4, x3
 5a8:	mov	w2, #0x80                  	// #128
 5ac:	sub	w2, w2, w0
 5b0:	lsl	x4, x4, x2
 5b4:	cmp	x0, #0x40
 5b8:	csel	x0, x4, xzr, ne  // ne = any
 5bc:	orr	x5, x0, x5
 5c0:	cmp	x5, #0x0
 5c4:	cset	x2, ne  // ne = any
 5c8:	orr	x2, x3, x2
 5cc:	lsr	x5, x3, #3
 5d0:	ands	x4, x2, #0x7
 5d4:	b.ne	5e4 <__multf3+0x5e4>  // b.any
 5d8:	tbz	w13, #11, 6c8 <__multf3+0x6c8>
 5dc:	mov	x0, #0x0                   	// #0
 5e0:	b	618 <__multf3+0x618>
 5e4:	mov	x0, #0x0                   	// #0
 5e8:	orr	w8, w8, #0x10
 5ec:	and	x13, x13, #0xc00000
 5f0:	cmp	x13, #0x400, lsl #12
 5f4:	b.eq	638 <__multf3+0x638>  // b.none
 5f8:	cmp	x13, #0x800, lsl #12
 5fc:	b.eq	648 <__multf3+0x648>  // b.none
 600:	cbz	x13, 620 <__multf3+0x620>
 604:	tbz	x0, #51, 734 <__multf3+0x734>
 608:	orr	w8, w8, #0x10
 60c:	mov	x4, #0x0                   	// #0
 610:	mov	x5, #0x0                   	// #0
 614:	mov	x0, #0x1                   	// #1
 618:	orr	w8, w8, #0x8
 61c:	b	4f4 <__multf3+0x4f4>
 620:	and	x3, x2, #0xf
 624:	cmp	x3, #0x4
 628:	b.eq	604 <__multf3+0x604>  // b.none
 62c:	adds	x2, x2, #0x4
 630:	cinc	x0, x0, cs  // cs = hs, nlast
 634:	b	604 <__multf3+0x604>
 638:	cbnz	x1, 604 <__multf3+0x604>
 63c:	adds	x2, x2, #0x8
 640:	cinc	x0, x0, cs  // cs = hs, nlast
 644:	b	604 <__multf3+0x604>
 648:	cbz	x1, 604 <__multf3+0x604>
 64c:	adds	x2, x2, #0x8
 650:	cinc	x0, x0, cs  // cs = hs, nlast
 654:	b	604 <__multf3+0x604>
 658:	orr	x5, x5, x4
 65c:	cbz	x5, 688 <__multf3+0x688>
 660:	orr	w8, w8, #0x10
 664:	and	x13, x13, #0xc00000
 668:	cmp	x13, #0x400, lsl #12
 66c:	b.eq	698 <__multf3+0x698>  // b.none
 670:	cmp	x13, #0x800, lsl #12
 674:	b.eq	6a8 <__multf3+0x6a8>  // b.none
 678:	cmp	x13, #0x0
 67c:	mov	x5, #0x5                   	// #5
 680:	csinc	x5, x5, xzr, eq  // eq = none
 684:	lsr	x5, x5, #3
 688:	orr	w8, w8, #0x8
 68c:	mov	x4, #0x0                   	// #0
 690:	mov	x0, #0x0                   	// #0
 694:	b	4f4 <__multf3+0x4f4>
 698:	cmp	x1, #0x0
 69c:	mov	x5, #0x9                   	// #9
 6a0:	csinc	x5, x5, xzr, eq  // eq = none
 6a4:	b	684 <__multf3+0x684>
 6a8:	cmp	x1, #0x0
 6ac:	mov	x5, #0x9                   	// #9
 6b0:	csinc	x5, x5, xzr, ne  // ne = any
 6b4:	b	684 <__multf3+0x684>
 6b8:	mov	x4, #0x0                   	// #0
 6bc:	mov	x5, #0x0                   	// #0
 6c0:	mov	x9, #0x7fff                	// #32767
 6c4:	b	f4 <__multf3+0xf4>
 6c8:	mov	x9, #0x0                   	// #0
 6cc:	b	f4 <__multf3+0xf4>
 6d0:	mov	x9, x12
 6d4:	mov	x1, x11
 6d8:	add	x0, x9, #0x3, lsl #12
 6dc:	add	x0, x0, #0xfff
 6e0:	cmp	x0, #0x0
 6e4:	b.le	548 <__multf3+0x548>
 6e8:	tst	x5, #0x7
 6ec:	b.eq	70c <__multf3+0x70c>  // b.none
 6f0:	orr	w8, w8, #0x10
 6f4:	and	x2, x13, #0xc00000
 6f8:	cmp	x2, #0x400, lsl #12
 6fc:	b.eq	4a4 <__multf3+0x4a4>  // b.none
 700:	cmp	x2, #0x800, lsl #12
 704:	b.eq	4b4 <__multf3+0x4b4>  // b.none
 708:	cbz	x2, 48c <__multf3+0x48c>
 70c:	tbz	x4, #52, 718 <__multf3+0x718>
 710:	and	x4, x4, #0xffefffffffffffff
 714:	add	x0, x9, #0x4, lsl #12
 718:	mov	x2, #0x7ffe                	// #32766
 71c:	cmp	x0, x2
 720:	b.gt	4c4 <__multf3+0x4c4>
 724:	extr	x5, x4, x5, #3
 728:	lsr	x4, x4, #3
 72c:	mov	x9, x0
 730:	b	f4 <__multf3+0xf4>
 734:	extr	x5, x0, x2, #3
 738:	lsr	x4, x0, #3
 73c:	mov	x0, #0x0                   	// #0
 740:	b	618 <__multf3+0x618>
 744:	mov	x7, x10
 748:	mov	x12, #0x0                   	// #0
 74c:	mov	x14, #0x1                   	// #1
 750:	b	a4 <__multf3+0xa4>

negtf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negtf2>:
   0:	sub	sp, sp, #0x10
   4:	str	q0, [sp]
   8:	ldr	x4, [sp]
   c:	ldr	x2, [sp, #8]
  10:	lsr	x3, x2, #63
  14:	and	w3, w3, #0xff
  18:	mov	x1, #0x0                   	// #0
  1c:	bfxil	x1, x2, #0, #48
  20:	ubfx	x2, x2, #48, #15
  24:	bfi	x1, x2, #48, #15
  28:	eor	w2, w3, #0x1
  2c:	bfi	x1, x2, #63, #1
  30:	fmov	d0, x4
  34:	fmov	v0.d[1], x1
  38:	add	sp, sp, #0x10
  3c:	ret

subtf3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__subtf3>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	q0, [sp, #16]
   c:	ldr	x3, [sp, #16]
  10:	ldr	x1, [sp, #24]
  14:	str	q1, [sp, #16]
  18:	ldr	x6, [sp, #16]
  1c:	ldr	x0, [sp, #24]
  20:	mrs	x9, fpcr
  24:	mov	x14, x3
  28:	ubfx	x4, x1, #48, #15
  2c:	mov	x7, x4
  30:	lsr	x8, x1, #63
  34:	ubfiz	x1, x1, #3, #48
  38:	orr	x1, x1, x3, lsr #61
  3c:	lsl	x3, x3, #3
  40:	ubfx	x11, x0, #48, #15
  44:	mov	x13, x11
  48:	lsr	x5, x0, #63
  4c:	and	w5, w5, #0xff
  50:	ubfiz	x0, x0, #3, #48
  54:	orr	x2, x0, x6, lsr #61
  58:	lsl	x12, x6, #3
  5c:	mov	x10, #0x7fff                	// #32767
  60:	cmp	x11, x10
  64:	b.eq	bc <__subtf3+0xbc>  // b.none
  68:	eor	w5, w5, #0x1
  6c:	and	x10, x5, #0xff
  70:	cmp	x8, w5, uxtb
  74:	b.eq	11c <__subtf3+0x11c>  // b.none
  78:	sub	w0, w4, w11
  7c:	cmp	w0, #0x0
  80:	b.le	d4 <__subtf3+0xd4>
  84:	cbnz	x13, 534 <__subtf3+0x534>
  88:	orr	x4, x2, x12
  8c:	cbz	x4, 4fc <__subtf3+0x4fc>
  90:	subs	w0, w0, #0x1
  94:	b.eq	524 <__subtf3+0x524>  // b.none
  98:	mov	x4, #0x7fff                	// #32767
  9c:	cmp	x7, x4
  a0:	b.ne	544 <__subtf3+0x544>  // b.any
  a4:	orr	x0, x1, x3
  a8:	cbz	x0, c4c <__subtf3+0xc4c>
  ac:	lsr	x0, x1, #50
  b0:	eor	x0, x0, #0x1
  b4:	and	w0, w0, #0x1
  b8:	b	aac <__subtf3+0xaac>
  bc:	orr	x0, x2, x12
  c0:	cbz	x0, cf4 <__subtf3+0xcf4>
  c4:	and	x10, x5, #0xff
  c8:	sub	w0, w4, w11
  cc:	cmp	x8, w5, uxtb
  d0:	b.eq	b3c <__subtf3+0xb3c>  // b.none
  d4:	tbnz	w0, #31, 644 <__subtf3+0x644>
  d8:	add	x0, x7, #0x1
  dc:	ands	x4, x0, #0x7ffe
  e0:	b.ne	8d4 <__subtf3+0x8d4>  // b.any
  e4:	cbnz	x7, 7e8 <__subtf3+0x7e8>
  e8:	orr	x0, x1, x3
  ec:	cbz	x0, 7b0 <__subtf3+0x7b0>
  f0:	orr	x0, x2, x12
  f4:	cbz	x0, cac <__subtf3+0xcac>
  f8:	sub	x0, x3, x12
  fc:	cmp	x3, x0
 100:	sbc	x5, x1, x2
 104:	tbz	x5, #51, 7cc <__subtf3+0x7cc>
 108:	sub	x4, x12, x3
 10c:	cmp	x12, x4
 110:	sbc	x1, x2, x1
 114:	mov	x8, x10
 118:	b	974 <__subtf3+0x974>
 11c:	sub	w0, w4, w11
 120:	cmp	w0, #0x0
 124:	b.le	b44 <__subtf3+0xb44>
 128:	cbnz	x11, 194 <__subtf3+0x194>
 12c:	orr	x4, x2, x12
 130:	cbz	x4, 160 <__subtf3+0x160>
 134:	subs	w0, w0, #0x1
 138:	b.eq	188 <__subtf3+0x188>  // b.none
 13c:	mov	x4, #0x7fff                	// #32767
 140:	cmp	x7, x4
 144:	b.ne	1a4 <__subtf3+0x1a4>  // b.any
 148:	orr	x0, x1, x3
 14c:	cbz	x0, b98 <__subtf3+0xb98>
 150:	lsr	x0, x1, #50
 154:	eor	x0, x0, #0x1
 158:	and	w0, w0, #0x1
 15c:	b	aac <__subtf3+0xaac>
 160:	mov	x4, x3
 164:	mov	x0, #0x7fff                	// #32767
 168:	cmp	x7, x0
 16c:	b.ne	970 <__subtf3+0x970>  // b.any
 170:	orr	x0, x1, x3
 174:	cbz	x0, b88 <__subtf3+0xb88>
 178:	lsr	x0, x1, #50
 17c:	eor	x0, x0, #0x1
 180:	and	w0, w0, #0x1
 184:	b	aac <__subtf3+0xaac>
 188:	adds	x4, x3, x12
 18c:	adc	x1, x2, x1
 190:	b	1e4 <__subtf3+0x1e4>
 194:	orr	x2, x2, #0x8000000000000
 198:	mov	x4, #0x7fff                	// #32767
 19c:	cmp	x7, x4
 1a0:	b.eq	214 <__subtf3+0x214>  // b.none
 1a4:	cmp	w0, #0x74
 1a8:	b.gt	af8 <__subtf3+0xaf8>
 1ac:	cmp	w0, #0x3f
 1b0:	b.gt	22c <__subtf3+0x22c>
 1b4:	mov	w5, #0x40                  	// #64
 1b8:	sub	w5, w5, w0
 1bc:	lsl	x4, x2, x5
 1c0:	lsr	x6, x12, x0
 1c4:	orr	x4, x4, x6
 1c8:	lsl	x5, x12, x5
 1cc:	cmp	x5, #0x0
 1d0:	cset	x5, ne  // ne = any
 1d4:	orr	x4, x4, x5
 1d8:	lsr	x0, x2, x0
 1dc:	adds	x4, x4, x3
 1e0:	adc	x1, x0, x1
 1e4:	tbz	x1, #51, 970 <__subtf3+0x970>
 1e8:	add	x7, x7, #0x1
 1ec:	mov	x0, #0x7fff                	// #32767
 1f0:	cmp	x7, x0
 1f4:	b.eq	4c4 <__subtf3+0x4c4>  // b.none
 1f8:	and	x0, x1, #0xfff7ffffffffffff
 1fc:	and	x3, x4, #0x1
 200:	orr	x3, x3, x4, lsr #1
 204:	orr	x3, x3, x1, lsl #63
 208:	lsr	x1, x0, #1
 20c:	mov	w0, #0x0                   	// #0
 210:	b	aac <__subtf3+0xaac>
 214:	orr	x0, x1, x3
 218:	cbz	x0, ba8 <__subtf3+0xba8>
 21c:	lsr	x0, x1, #50
 220:	eor	x0, x0, #0x1
 224:	and	w0, w0, #0x1
 228:	b	aac <__subtf3+0xaac>
 22c:	sub	w4, w0, #0x40
 230:	lsr	x4, x2, x4
 234:	mov	w5, #0x80                  	// #128
 238:	sub	w5, w5, w0
 23c:	lsl	x2, x2, x5
 240:	cmp	w0, #0x40
 244:	csel	x0, x2, xzr, ne  // ne = any
 248:	orr	x12, x0, x12
 24c:	cmp	x12, #0x0
 250:	cset	x0, ne  // ne = any
 254:	orr	x4, x4, x0
 258:	mov	x0, #0x0                   	// #0
 25c:	b	1dc <__subtf3+0x1dc>
 260:	cbnz	x7, 2f8 <__subtf3+0x2f8>
 264:	orr	x4, x1, x3
 268:	cbz	x4, 2a8 <__subtf3+0x2a8>
 26c:	cmn	w0, #0x1
 270:	b.eq	2e8 <__subtf3+0x2e8>  // b.none
 274:	mvn	w0, w0
 278:	mov	x4, #0x7fff                	// #32767
 27c:	cmp	x13, x4
 280:	b.ne	30c <__subtf3+0x30c>  // b.any
 284:	orr	x3, x2, x12
 288:	cbz	x3, bc4 <__subtf3+0xbc4>
 28c:	lsr	x0, x2, #50
 290:	eor	x0, x0, #0x1
 294:	and	w0, w0, #0x1
 298:	mov	x1, x2
 29c:	mov	x3, x12
 2a0:	mov	x7, x13
 2a4:	b	aac <__subtf3+0xaac>
 2a8:	mov	x0, #0x7fff                	// #32767
 2ac:	cmp	x13, x0
 2b0:	b.eq	2c4 <__subtf3+0x2c4>  // b.none
 2b4:	mov	x1, x2
 2b8:	mov	x4, x12
 2bc:	mov	x7, x13
 2c0:	b	970 <__subtf3+0x970>
 2c4:	orr	x3, x2, x12
 2c8:	cbz	x3, bb8 <__subtf3+0xbb8>
 2cc:	lsr	x0, x2, #50
 2d0:	eor	x0, x0, #0x1
 2d4:	and	w0, w0, #0x1
 2d8:	mov	x1, x2
 2dc:	mov	x3, x12
 2e0:	mov	x7, x13
 2e4:	b	aac <__subtf3+0xaac>
 2e8:	adds	x4, x3, x12
 2ec:	adc	x1, x2, x1
 2f0:	mov	x7, x13
 2f4:	b	1e4 <__subtf3+0x1e4>
 2f8:	neg	w0, w0
 2fc:	orr	x1, x1, #0x8000000000000
 300:	mov	x4, #0x7fff                	// #32767
 304:	cmp	x13, x4
 308:	b.eq	354 <__subtf3+0x354>  // b.none
 30c:	cmp	w0, #0x74
 310:	b.gt	b04 <__subtf3+0xb04>
 314:	cmp	w0, #0x3f
 318:	b.gt	378 <__subtf3+0x378>
 31c:	mov	w5, #0x40                  	// #64
 320:	sub	w5, w5, w0
 324:	lsl	x4, x1, x5
 328:	lsr	x6, x3, x0
 32c:	orr	x4, x4, x6
 330:	lsl	x3, x3, x5
 334:	cmp	x3, #0x0
 338:	cset	x3, ne  // ne = any
 33c:	orr	x4, x4, x3
 340:	lsr	x1, x1, x0
 344:	adds	x4, x4, x12
 348:	adc	x1, x1, x2
 34c:	mov	x7, x13
 350:	b	1e4 <__subtf3+0x1e4>
 354:	orr	x3, x2, x12
 358:	cbz	x3, bd0 <__subtf3+0xbd0>
 35c:	lsr	x0, x2, #50
 360:	eor	x0, x0, #0x1
 364:	and	w0, w0, #0x1
 368:	mov	x1, x2
 36c:	mov	x3, x12
 370:	mov	x7, x13
 374:	b	aac <__subtf3+0xaac>
 378:	sub	w4, w0, #0x40
 37c:	lsr	x4, x1, x4
 380:	mov	w5, #0x80                  	// #128
 384:	sub	w5, w5, w0
 388:	lsl	x1, x1, x5
 38c:	cmp	w0, #0x40
 390:	csel	x0, x1, xzr, ne  // ne = any
 394:	orr	x3, x0, x3
 398:	cmp	x3, #0x0
 39c:	cset	x0, ne  // ne = any
 3a0:	orr	x4, x4, x0
 3a4:	mov	x1, #0x0                   	// #0
 3a8:	b	344 <__subtf3+0x344>
 3ac:	mov	x0, #0x7fff                	// #32767
 3b0:	cmp	x7, x0
 3b4:	b.eq	414 <__subtf3+0x414>  // b.none
 3b8:	mov	w0, #0x0                   	// #0
 3bc:	mov	x4, #0x7fff                	// #32767
 3c0:	cmp	x13, x4
 3c4:	b.eq	434 <__subtf3+0x434>  // b.none
 3c8:	orr	x4, x1, x3
 3cc:	cbz	x4, ae8 <__subtf3+0xae8>
 3d0:	orr	x12, x2, x12
 3d4:	mov	x7, #0x7fff                	// #32767
 3d8:	cbz	x12, aac <__subtf3+0xaac>
 3dc:	mov	x3, x14
 3e0:	bfi	x3, x1, #61, #3
 3e4:	lsr	x4, x1, #3
 3e8:	tbz	x1, #50, 404 <__subtf3+0x404>
 3ec:	lsr	x1, x2, #3
 3f0:	tbnz	x2, #50, 404 <__subtf3+0x404>
 3f4:	mov	x3, x6
 3f8:	bfi	x3, x2, #61, #3
 3fc:	mov	x4, x1
 400:	mov	x8, x10
 404:	extr	x1, x4, x3, #61
 408:	lsl	x3, x3, #3
 40c:	mov	x7, #0x7fff                	// #32767
 410:	b	aac <__subtf3+0xaac>
 414:	orr	x0, x1, x3
 418:	cbz	x0, cd8 <__subtf3+0xcd8>
 41c:	lsr	x0, x1, #50
 420:	eor	x0, x0, #0x1
 424:	and	w0, w0, #0x1
 428:	mov	x4, #0x7fff                	// #32767
 42c:	cmp	x13, x4
 430:	b.ne	3d0 <__subtf3+0x3d0>  // b.any
 434:	orr	x4, x2, x12
 438:	cbz	x4, 3c8 <__subtf3+0x3c8>
 43c:	tst	x2, #0x4000000000000
 440:	csinc	w0, w0, wzr, ne  // ne = any
 444:	orr	x3, x1, x3
 448:	cbnz	x3, 3dc <__subtf3+0x3dc>
 44c:	mov	x1, x2
 450:	mov	x3, x12
 454:	mov	x7, #0x7fff                	// #32767
 458:	b	aac <__subtf3+0xaac>
 45c:	mov	w0, #0x0                   	// #0
 460:	b	434 <__subtf3+0x434>
 464:	mov	x4, #0x7fff                	// #32767
 468:	cmp	x0, x4
 46c:	b.eq	48c <__subtf3+0x48c>  // b.none
 470:	adds	x3, x3, x12
 474:	adc	x1, x2, x1
 478:	extr	x3, x1, x3, #1
 47c:	lsr	x1, x1, #1
 480:	mov	x7, x0
 484:	mov	w0, #0x0                   	// #0
 488:	b	aac <__subtf3+0xaac>
 48c:	ands	x3, x9, #0xc00000
 490:	b.eq	bdc <__subtf3+0xbdc>  // b.none
 494:	cmp	x3, #0x400, lsl #12
 498:	ccmp	x8, #0x0, #0x0, eq  // eq = none
 49c:	b.eq	be8 <__subtf3+0xbe8>  // b.none
 4a0:	cmp	x3, #0x800, lsl #12
 4a4:	ccmp	x8, #0x0, #0x4, eq  // eq = none
 4a8:	b.ne	bfc <__subtf3+0xbfc>  // b.any
 4ac:	mov	w4, #0x0                   	// #0
 4b0:	mov	x1, #0xffffffffffffffff    	// #-1
 4b4:	mov	x3, x1
 4b8:	mov	x7, #0x7ffe                	// #32766
 4bc:	mov	w0, #0x14                  	// #20
 4c0:	b	ab8 <__subtf3+0xab8>
 4c4:	ands	x3, x9, #0xc00000
 4c8:	b.eq	c0c <__subtf3+0xc0c>  // b.none
 4cc:	cmp	x3, #0x400, lsl #12
 4d0:	ccmp	x8, #0x0, #0x0, eq  // eq = none
 4d4:	b.eq	c18 <__subtf3+0xc18>  // b.none
 4d8:	cmp	x3, #0x800, lsl #12
 4dc:	ccmp	x8, #0x0, #0x4, eq  // eq = none
 4e0:	b.ne	c2c <__subtf3+0xc2c>  // b.any
 4e4:	mov	w4, #0x0                   	// #0
 4e8:	mov	x1, #0xffffffffffffffff    	// #-1
 4ec:	mov	x3, x1
 4f0:	mov	x7, #0x7ffe                	// #32766
 4f4:	mov	w0, #0x14                  	// #20
 4f8:	b	ab8 <__subtf3+0xab8>
 4fc:	mov	x4, x3
 500:	mov	x0, #0x7fff                	// #32767
 504:	cmp	x7, x0
 508:	b.ne	970 <__subtf3+0x970>  // b.any
 50c:	orr	x0, x1, x3
 510:	cbz	x0, c3c <__subtf3+0xc3c>
 514:	lsr	x0, x1, #50
 518:	eor	x0, x0, #0x1
 51c:	and	w0, w0, #0x1
 520:	b	aac <__subtf3+0xaac>
 524:	sub	x4, x3, x12
 528:	cmp	x3, x4
 52c:	sbc	x1, x1, x2
 530:	b	588 <__subtf3+0x588>
 534:	orr	x2, x2, #0x8000000000000
 538:	mov	x4, #0x7fff                	// #32767
 53c:	cmp	x7, x4
 540:	b.eq	5f8 <__subtf3+0x5f8>  // b.none
 544:	cmp	w0, #0x74
 548:	b.gt	b10 <__subtf3+0xb10>
 54c:	cmp	w0, #0x3f
 550:	b.gt	610 <__subtf3+0x610>
 554:	mov	w5, #0x40                  	// #64
 558:	sub	w5, w5, w0
 55c:	lsl	x4, x2, x5
 560:	lsr	x6, x12, x0
 564:	orr	x4, x4, x6
 568:	lsl	x12, x12, x5
 56c:	cmp	x12, #0x0
 570:	cset	x5, ne  // ne = any
 574:	orr	x4, x4, x5
 578:	lsr	x0, x2, x0
 57c:	sub	x4, x3, x4
 580:	cmp	x3, x4
 584:	sbc	x1, x1, x0
 588:	tbz	x1, #51, 970 <__subtf3+0x970>
 58c:	and	x5, x1, #0x7ffffffffffff
 590:	cbz	x5, 914 <__subtf3+0x914>
 594:	clz	x0, x5
 598:	sub	w0, w0, #0xc
 59c:	lsl	x5, x5, x0
 5a0:	neg	w1, w0
 5a4:	lsr	x1, x4, x1
 5a8:	orr	x1, x1, x5
 5ac:	lsl	x5, x4, x0
 5b0:	sxtw	x2, w0
 5b4:	cmp	x7, w0, sxtw
 5b8:	b.gt	964 <__subtf3+0x964>
 5bc:	sub	w7, w0, w7
 5c0:	add	w6, w7, #0x1
 5c4:	cmp	w6, #0x3f
 5c8:	b.gt	930 <__subtf3+0x930>
 5cc:	mov	w0, #0x40                  	// #64
 5d0:	sub	w0, w0, w6
 5d4:	lsl	x4, x1, x0
 5d8:	lsr	x2, x5, x6
 5dc:	orr	x4, x4, x2
 5e0:	lsl	x5, x5, x0
 5e4:	cmp	x5, #0x0
 5e8:	cset	x3, ne  // ne = any
 5ec:	orr	x4, x4, x3
 5f0:	lsr	x1, x1, x6
 5f4:	b	974 <__subtf3+0x974>
 5f8:	orr	x0, x1, x3
 5fc:	cbz	x0, c5c <__subtf3+0xc5c>
 600:	lsr	x0, x1, #50
 604:	eor	x0, x0, #0x1
 608:	and	w0, w0, #0x1
 60c:	b	aac <__subtf3+0xaac>
 610:	sub	w4, w0, #0x40
 614:	lsr	x4, x2, x4
 618:	mov	w5, #0x80                  	// #128
 61c:	sub	w5, w5, w0
 620:	lsl	x2, x2, x5
 624:	cmp	w0, #0x40
 628:	csel	x2, x2, xzr, ne  // ne = any
 62c:	orr	x12, x2, x12
 630:	cmp	x12, #0x0
 634:	cset	x0, ne  // ne = any
 638:	orr	x4, x4, x0
 63c:	mov	x0, #0x0                   	// #0
 640:	b	57c <__subtf3+0x57c>
 644:	cbnz	x7, 6f0 <__subtf3+0x6f0>
 648:	orr	x4, x1, x3
 64c:	cbz	x4, 690 <__subtf3+0x690>
 650:	cmn	w0, #0x1
 654:	b.eq	6d8 <__subtf3+0x6d8>  // b.none
 658:	mvn	w0, w0
 65c:	mov	x4, #0x7fff                	// #32767
 660:	cmp	x13, x4
 664:	b.ne	704 <__subtf3+0x704>  // b.any
 668:	orr	x3, x2, x12
 66c:	cbz	x3, c80 <__subtf3+0xc80>
 670:	lsr	x0, x2, #50
 674:	eor	x0, x0, #0x1
 678:	and	w0, w0, #0x1
 67c:	mov	x1, x2
 680:	mov	x3, x12
 684:	mov	x7, x13
 688:	mov	x8, x10
 68c:	b	aac <__subtf3+0xaac>
 690:	mov	x0, #0x7fff                	// #32767
 694:	cmp	x13, x0
 698:	b.eq	6b0 <__subtf3+0x6b0>  // b.none
 69c:	mov	x1, x2
 6a0:	mov	x4, x12
 6a4:	mov	x7, x13
 6a8:	mov	x8, x10
 6ac:	b	970 <__subtf3+0x970>
 6b0:	orr	x3, x2, x12
 6b4:	cbz	x3, c70 <__subtf3+0xc70>
 6b8:	lsr	x0, x2, #50
 6bc:	eor	x0, x0, #0x1
 6c0:	and	w0, w0, #0x1
 6c4:	mov	x1, x2
 6c8:	mov	x3, x12
 6cc:	mov	x7, x13
 6d0:	mov	x8, x10
 6d4:	b	aac <__subtf3+0xaac>
 6d8:	sub	x4, x12, x3
 6dc:	cmp	x12, x4
 6e0:	sbc	x1, x2, x1
 6e4:	mov	x7, x13
 6e8:	mov	x8, x10
 6ec:	b	588 <__subtf3+0x588>
 6f0:	neg	w0, w0
 6f4:	orr	x1, x1, #0x8000000000000
 6f8:	mov	x4, #0x7fff                	// #32767
 6fc:	cmp	x13, x4
 700:	b.eq	754 <__subtf3+0x754>  // b.none
 704:	cmp	w0, #0x74
 708:	b.gt	b1c <__subtf3+0xb1c>
 70c:	cmp	w0, #0x3f
 710:	b.gt	77c <__subtf3+0x77c>
 714:	mov	w5, #0x40                  	// #64
 718:	sub	w5, w5, w0
 71c:	lsl	x4, x1, x5
 720:	lsr	x6, x3, x0
 724:	orr	x4, x4, x6
 728:	lsl	x3, x3, x5
 72c:	cmp	x3, #0x0
 730:	cset	x3, ne  // ne = any
 734:	orr	x4, x4, x3
 738:	lsr	x1, x1, x0
 73c:	sub	x4, x12, x4
 740:	cmp	x12, x4
 744:	sbc	x1, x2, x1
 748:	mov	x7, x13
 74c:	mov	x8, x10
 750:	b	588 <__subtf3+0x588>
 754:	orr	x3, x2, x12
 758:	cbz	x3, c90 <__subtf3+0xc90>
 75c:	lsr	x0, x2, #50
 760:	eor	x0, x0, #0x1
 764:	and	w0, w0, #0x1
 768:	mov	x1, x2
 76c:	mov	x3, x12
 770:	mov	x7, x13
 774:	mov	x8, x10
 778:	b	aac <__subtf3+0xaac>
 77c:	sub	w4, w0, #0x40
 780:	lsr	x4, x1, x4
 784:	mov	w5, #0x80                  	// #128
 788:	sub	w5, w5, w0
 78c:	lsl	x1, x1, x5
 790:	cmp	w0, #0x40
 794:	csel	x0, x1, xzr, ne  // ne = any
 798:	orr	x3, x0, x3
 79c:	cmp	x3, #0x0
 7a0:	cset	x0, ne  // ne = any
 7a4:	orr	x4, x4, x0
 7a8:	mov	x1, #0x0                   	// #0
 7ac:	b	73c <__subtf3+0x73c>
 7b0:	orr	x4, x2, x12
 7b4:	cbnz	x4, ca0 <__subtf3+0xca0>
 7b8:	and	x0, x9, #0xc00000
 7bc:	cmp	x0, #0x800, lsl #12
 7c0:	cset	x8, eq  // eq = none
 7c4:	mov	x1, x4
 7c8:	b	974 <__subtf3+0x974>
 7cc:	orr	x4, x0, x5
 7d0:	cbnz	x4, ccc <__subtf3+0xccc>
 7d4:	and	x0, x9, #0xc00000
 7d8:	cmp	x0, #0x800, lsl #12
 7dc:	cset	x8, eq  // eq = none
 7e0:	mov	x1, x4
 7e4:	b	974 <__subtf3+0x974>
 7e8:	mov	x0, #0x7fff                	// #32767
 7ec:	cmp	x7, x0
 7f0:	b.eq	828 <__subtf3+0x828>  // b.none
 7f4:	mov	w0, #0x0                   	// #0
 7f8:	mov	x5, #0x7fff                	// #32767
 7fc:	cmp	x13, x5
 800:	b.eq	87c <__subtf3+0x87c>  // b.none
 804:	orr	x5, x1, x3
 808:	cbnz	x5, 848 <__subtf3+0x848>
 80c:	orr	x1, x2, x12
 810:	cbnz	x1, 8a8 <__subtf3+0x8a8>
 814:	mov	x8, x4
 818:	mov	x1, #0x7ffffffffffff       	// #2251799813685247
 81c:	mov	x3, #0xfffffffffffffff8    	// #-8
 820:	mov	w0, #0x1                   	// #1
 824:	b	c68 <__subtf3+0xc68>
 828:	orr	x0, x1, x3
 82c:	cbz	x0, b28 <__subtf3+0xb28>
 830:	lsr	x0, x1, #50
 834:	eor	x0, x0, #0x1
 838:	and	w0, w0, #0x1
 83c:	mov	x5, #0x7fff                	// #32767
 840:	cmp	x13, x5
 844:	b.eq	87c <__subtf3+0x87c>  // b.none
 848:	orr	x12, x2, x12
 84c:	mov	x7, #0x7fff                	// #32767
 850:	cbz	x12, aac <__subtf3+0xaac>
 854:	lsr	x4, x1, #3
 858:	tbz	x1, #50, 8bc <__subtf3+0x8bc>
 85c:	lsr	x5, x2, #3
 860:	tbnz	x2, #50, 8bc <__subtf3+0x8bc>
 864:	mov	x3, x6
 868:	bfi	x3, x2, #61, #3
 86c:	mov	x4, x5
 870:	mov	x8, x10
 874:	b	8c4 <__subtf3+0x8c4>
 878:	mov	w0, #0x0                   	// #0
 87c:	orr	x5, x2, x12
 880:	cbz	x5, 804 <__subtf3+0x804>
 884:	tst	x2, #0x4000000000000
 888:	csinc	w0, w0, wzr, ne  // ne = any
 88c:	orr	x4, x1, x3
 890:	cbnz	x4, 848 <__subtf3+0x848>
 894:	mov	x1, x2
 898:	mov	x3, x12
 89c:	mov	x8, x10
 8a0:	mov	x7, #0x7fff                	// #32767
 8a4:	b	aac <__subtf3+0xaac>
 8a8:	mov	x1, x2
 8ac:	mov	x3, x12
 8b0:	mov	x8, x10
 8b4:	mov	x7, #0x7fff                	// #32767
 8b8:	b	aac <__subtf3+0xaac>
 8bc:	mov	x3, x14
 8c0:	bfi	x3, x1, #61, #3
 8c4:	extr	x1, x4, x3, #61
 8c8:	lsl	x3, x3, #3
 8cc:	mov	x7, #0x7fff                	// #32767
 8d0:	b	aac <__subtf3+0xaac>
 8d4:	sub	x4, x3, x12
 8d8:	cmp	x3, x4
 8dc:	sbc	x5, x1, x2
 8e0:	tbnz	x5, #51, 900 <__subtf3+0x900>
 8e4:	orr	x1, x4, x5
 8e8:	cbnz	x1, 590 <__subtf3+0x590>
 8ec:	and	x0, x9, #0xc00000
 8f0:	cmp	x0, #0x800, lsl #12
 8f4:	cset	x8, eq  // eq = none
 8f8:	mov	x4, x1
 8fc:	b	974 <__subtf3+0x974>
 900:	sub	x4, x12, x3
 904:	cmp	x12, x4
 908:	sbc	x5, x2, x1
 90c:	mov	x8, x10
 910:	b	590 <__subtf3+0x590>
 914:	clz	x1, x4
 918:	add	w0, w1, #0x34
 91c:	cmp	w0, #0x3f
 920:	b.le	59c <__subtf3+0x59c>
 924:	sub	w1, w1, #0xc
 928:	lsl	x1, x4, x1
 92c:	b	5b0 <__subtf3+0x5b0>
 930:	sub	w7, w7, #0x3f
 934:	lsr	x0, x1, x7
 938:	mov	w2, #0x80                  	// #128
 93c:	sub	w2, w2, w6
 940:	lsl	x1, x1, x2
 944:	cmp	w6, #0x40
 948:	csel	x2, x1, xzr, ne  // ne = any
 94c:	orr	x2, x5, x2
 950:	cmp	x2, #0x0
 954:	cset	x4, ne  // ne = any
 958:	orr	x4, x0, x4
 95c:	mov	x1, #0x0                   	// #0
 960:	b	974 <__subtf3+0x974>
 964:	sub	x7, x7, x2
 968:	and	x1, x1, #0xfff7ffffffffffff
 96c:	mov	x4, x5
 970:	cbnz	x7, aa4 <__subtf3+0xaa4>
 974:	orr	x3, x4, x1
 978:	cbnz	x3, cb0 <__subtf3+0xcb0>
 97c:	mov	x1, x3
 980:	mov	x7, #0x0                   	// #0
 984:	mov	w0, #0x0                   	// #0
 988:	b	9bc <__subtf3+0x9bc>
 98c:	mov	x3, x4
 990:	mov	w4, #0x1                   	// #1
 994:	mov	x7, #0x0                   	// #0
 998:	mov	w0, #0x0                   	// #0
 99c:	b	ab8 <__subtf3+0xab8>
 9a0:	and	x2, x3, #0xf
 9a4:	cmp	x2, #0x4
 9a8:	b.eq	9b4 <__subtf3+0x9b4>  // b.none
 9ac:	adds	x3, x3, #0x4
 9b0:	cinc	x1, x1, cs  // cs = hs, nlast
 9b4:	cbz	w4, 9bc <__subtf3+0x9bc>
 9b8:	orr	w0, w0, #0x8
 9bc:	tbz	x1, #51, a68 <__subtf3+0xa68>
 9c0:	add	x7, x7, #0x1
 9c4:	mov	x2, #0x7fff                	// #32767
 9c8:	cmp	x7, x2
 9cc:	b.eq	a34 <__subtf3+0xa34>  // b.none
 9d0:	and	x2, x1, #0xfff7ffffffffffff
 9d4:	extr	x4, x1, x3, #3
 9d8:	lsr	x1, x2, #3
 9dc:	mov	x3, #0x0                   	// #0
 9e0:	mov	x2, x4
 9e4:	bfxil	x3, x1, #0, #48
 9e8:	bfi	x3, x7, #48, #15
 9ec:	bfi	x3, x8, #63, #1
 9f0:	stp	x2, x3, [sp, #16]
 9f4:	cbnz	w0, a9c <__subtf3+0xa9c>
 9f8:	ldr	q0, [sp, #16]
 9fc:	ldp	x29, x30, [sp], #32
 a00:	ret
 a04:	cbnz	x8, 9b4 <__subtf3+0x9b4>
 a08:	adds	x3, x3, #0x8
 a0c:	cinc	x1, x1, cs  // cs = hs, nlast
 a10:	b	9b4 <__subtf3+0x9b4>
 a14:	cbz	x8, 9b4 <__subtf3+0x9b4>
 a18:	adds	x3, x3, #0x8
 a1c:	cinc	x1, x1, cs  // cs = hs, nlast
 a20:	b	9b4 <__subtf3+0x9b4>
 a24:	mov	x3, x4
 a28:	mov	x7, #0x0                   	// #0
 a2c:	mov	w0, #0x0                   	// #0
 a30:	b	9b8 <__subtf3+0x9b8>
 a34:	ands	x3, x9, #0xc00000
 a38:	b.eq	a5c <__subtf3+0xa5c>  // b.none
 a3c:	cmp	x3, #0x400, lsl #12
 a40:	ccmp	x8, #0x0, #0x0, eq  // eq = none
 a44:	b.eq	a94 <__subtf3+0xa94>  // b.none
 a48:	cmp	x3, #0x800, lsl #12
 a4c:	ccmp	x8, #0x0, #0x4, eq  // eq = none
 a50:	csetm	x3, eq  // eq = none
 a54:	mov	x1, #0x7ffe                	// #32766
 a58:	csel	x7, x7, x1, ne  // ne = any
 a5c:	mov	w1, #0x14                  	// #20
 a60:	orr	w0, w0, w1
 a64:	mov	x1, x3
 a68:	extr	x4, x1, x3, #3
 a6c:	lsr	x1, x1, #3
 a70:	mov	x2, #0x7fff                	// #32767
 a74:	cmp	x7, x2
 a78:	b.ne	9dc <__subtf3+0x9dc>  // b.any
 a7c:	orr	x2, x4, x1
 a80:	orr	x1, x1, #0x800000000000
 a84:	cbnz	x2, 9dc <__subtf3+0x9dc>
 a88:	mov	x4, x2
 a8c:	mov	x1, x2
 a90:	b	9dc <__subtf3+0x9dc>
 a94:	mov	x3, #0x0                   	// #0
 a98:	b	a5c <__subtf3+0xa5c>
 a9c:	bl	0 <__sfp_handle_exceptions>
 aa0:	b	9f8 <__subtf3+0x9f8>
 aa4:	mov	x3, x4
 aa8:	mov	w0, #0x0                   	// #0
 aac:	mov	w4, #0x0                   	// #0
 ab0:	tst	x3, #0x7
 ab4:	b.eq	9bc <__subtf3+0x9bc>  // b.none
 ab8:	orr	w0, w0, #0x10
 abc:	and	x2, x9, #0xc00000
 ac0:	cmp	x2, #0x400, lsl #12
 ac4:	b.eq	a04 <__subtf3+0xa04>  // b.none
 ac8:	cmp	x2, #0x800, lsl #12
 acc:	b.eq	a14 <__subtf3+0xa14>  // b.none
 ad0:	cbz	x2, 9a0 <__subtf3+0x9a0>
 ad4:	cbnz	w4, 9b8 <__subtf3+0x9b8>
 ad8:	b	9bc <__subtf3+0x9bc>
 adc:	mov	x1, x2
 ae0:	mov	x4, x12
 ae4:	b	974 <__subtf3+0x974>
 ae8:	mov	x1, x2
 aec:	mov	x3, x12
 af0:	mov	x7, #0x7fff                	// #32767
 af4:	b	aac <__subtf3+0xaac>
 af8:	mov	x0, #0x0                   	// #0
 afc:	mov	x4, #0x1                   	// #1
 b00:	b	1dc <__subtf3+0x1dc>
 b04:	mov	x1, #0x0                   	// #0
 b08:	mov	x4, #0x1                   	// #1
 b0c:	b	344 <__subtf3+0x344>
 b10:	mov	x0, #0x0                   	// #0
 b14:	mov	x4, #0x1                   	// #1
 b18:	b	57c <__subtf3+0x57c>
 b1c:	mov	x1, #0x0                   	// #0
 b20:	mov	x4, #0x1                   	// #1
 b24:	b	73c <__subtf3+0x73c>
 b28:	mov	x0, #0x7fff                	// #32767
 b2c:	cmp	x13, x0
 b30:	b.eq	878 <__subtf3+0x878>  // b.none
 b34:	mov	w0, #0x0                   	// #0
 b38:	b	80c <__subtf3+0x80c>
 b3c:	sub	w0, w4, #0x7, lsl #12
 b40:	sub	w0, w0, #0xfff
 b44:	tbnz	w0, #31, 260 <__subtf3+0x260>
 b48:	add	x0, x7, #0x1
 b4c:	tst	x0, #0x7ffe
 b50:	b.ne	464 <__subtf3+0x464>  // b.any
 b54:	cbnz	x7, 3ac <__subtf3+0x3ac>
 b58:	orr	x0, x1, x3
 b5c:	cbz	x0, adc <__subtf3+0xadc>
 b60:	orr	x0, x2, x12
 b64:	cbz	x0, cac <__subtf3+0xcac>
 b68:	adds	x4, x3, x12
 b6c:	adc	x1, x2, x1
 b70:	tbz	x1, #51, 974 <__subtf3+0x974>
 b74:	and	x1, x1, #0xfff7ffffffffffff
 b78:	mov	x3, x4
 b7c:	mov	x7, #0x1                   	// #1
 b80:	mov	w0, #0x0                   	// #0
 b84:	b	aac <__subtf3+0xaac>
 b88:	mov	x1, x0
 b8c:	mov	x3, x0
 b90:	mov	w0, #0x0                   	// #0
 b94:	b	c68 <__subtf3+0xc68>
 b98:	mov	x1, x0
 b9c:	mov	x3, x0
 ba0:	mov	w0, #0x0                   	// #0
 ba4:	b	c68 <__subtf3+0xc68>
 ba8:	mov	x1, x0
 bac:	mov	x3, x0
 bb0:	mov	w0, #0x0                   	// #0
 bb4:	b	c68 <__subtf3+0xc68>
 bb8:	mov	x1, x3
 bbc:	mov	w0, #0x0                   	// #0
 bc0:	b	c68 <__subtf3+0xc68>
 bc4:	mov	x1, x3
 bc8:	mov	w0, #0x0                   	// #0
 bcc:	b	c68 <__subtf3+0xc68>
 bd0:	mov	x1, x3
 bd4:	mov	w0, #0x0                   	// #0
 bd8:	b	c68 <__subtf3+0xc68>
 bdc:	mov	x1, x3
 be0:	mov	w0, #0x14                  	// #20
 be4:	b	c68 <__subtf3+0xc68>
 be8:	mov	x1, #0x0                   	// #0
 bec:	mov	x3, #0x0                   	// #0
 bf0:	mov	x8, #0x0                   	// #0
 bf4:	mov	w0, #0x14                  	// #20
 bf8:	b	c68 <__subtf3+0xc68>
 bfc:	mov	x1, #0x0                   	// #0
 c00:	mov	x3, #0x0                   	// #0
 c04:	mov	w0, #0x14                  	// #20
 c08:	b	c68 <__subtf3+0xc68>
 c0c:	mov	x1, x3
 c10:	mov	w0, #0x14                  	// #20
 c14:	b	c68 <__subtf3+0xc68>
 c18:	mov	x1, #0x0                   	// #0
 c1c:	mov	x3, #0x0                   	// #0
 c20:	mov	x8, #0x0                   	// #0
 c24:	mov	w0, #0x14                  	// #20
 c28:	b	c68 <__subtf3+0xc68>
 c2c:	mov	x1, #0x0                   	// #0
 c30:	mov	x3, #0x0                   	// #0
 c34:	mov	w0, #0x14                  	// #20
 c38:	b	c68 <__subtf3+0xc68>
 c3c:	mov	x1, x0
 c40:	mov	x3, x0
 c44:	mov	w0, #0x0                   	// #0
 c48:	b	c68 <__subtf3+0xc68>
 c4c:	mov	x1, x0
 c50:	mov	x3, x0
 c54:	mov	w0, #0x0                   	// #0
 c58:	b	c68 <__subtf3+0xc68>
 c5c:	mov	x1, x0
 c60:	mov	x3, x0
 c64:	mov	w0, #0x0                   	// #0
 c68:	mov	x7, #0x7fff                	// #32767
 c6c:	b	9bc <__subtf3+0x9bc>
 c70:	mov	x1, x3
 c74:	mov	x8, x10
 c78:	mov	w0, #0x0                   	// #0
 c7c:	b	c68 <__subtf3+0xc68>
 c80:	mov	x1, x3
 c84:	mov	x8, x10
 c88:	mov	w0, #0x0                   	// #0
 c8c:	b	c68 <__subtf3+0xc68>
 c90:	mov	x1, x3
 c94:	mov	x8, x10
 c98:	mov	w0, #0x0                   	// #0
 c9c:	b	c68 <__subtf3+0xc68>
 ca0:	mov	x1, x2
 ca4:	mov	x3, x12
 ca8:	mov	x8, x10
 cac:	mov	x4, x3
 cb0:	tst	x4, #0x7
 cb4:	b.ne	98c <__subtf3+0x98c>  // b.any
 cb8:	tbnz	w9, #11, a24 <__subtf3+0xa24>
 cbc:	mov	x3, x4
 cc0:	mov	x7, #0x0                   	// #0
 cc4:	mov	w0, #0x0                   	// #0
 cc8:	b	9bc <__subtf3+0x9bc>
 ccc:	mov	x1, x5
 cd0:	mov	x3, x0
 cd4:	b	cac <__subtf3+0xcac>
 cd8:	mov	x0, #0x7fff                	// #32767
 cdc:	cmp	x13, x0
 ce0:	b.eq	45c <__subtf3+0x45c>  // b.none
 ce4:	mov	x1, x2
 ce8:	mov	x3, x12
 cec:	mov	w0, #0x0                   	// #0
 cf0:	b	aac <__subtf3+0xaac>
 cf4:	eor	w5, w5, #0x1
 cf8:	and	x10, x5, #0xff
 cfc:	cmp	x8, w5, uxtb
 d00:	b.ne	78 <__subtf3+0x78>  // b.any
 d04:	sub	w0, w4, w11
 d08:	b	b44 <__subtf3+0xb44>

unordtf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__unordtf2>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	q0, [sp, #16]
   c:	ldr	x1, [sp, #16]
  10:	ldr	x0, [sp, #24]
  14:	str	q1, [sp, #16]
  18:	ldr	x3, [sp, #16]
  1c:	ldr	x2, [sp, #24]
  20:	mrs	x4, fpcr
  24:	mov	x4, x1
  28:	ubfx	x7, x0, #0, #48
  2c:	ubfx	x1, x0, #48, #15
  30:	ubfx	x6, x2, #0, #48
  34:	ubfx	x2, x2, #48, #15
  38:	mov	x0, #0x7fff                	// #32767
  3c:	cmp	x1, x0
  40:	b.eq	5c <__unordtf2+0x5c>  // b.none
  44:	mov	w0, #0x0                   	// #0
  48:	mov	x5, #0x7fff                	// #32767
  4c:	cmp	x2, x5
  50:	b.eq	8c <__unordtf2+0x8c>  // b.none
  54:	ldp	x29, x30, [sp], #32
  58:	ret
  5c:	orr	x0, x7, x4
  60:	cbz	x0, 44 <__unordtf2+0x44>
  64:	tst	x7, #0x800000000000
  68:	b.eq	a8 <__unordtf2+0xa8>  // b.none
  6c:	mov	w0, #0x1                   	// #1
  70:	mov	x1, #0x7fff                	// #32767
  74:	cmp	x2, x1
  78:	b.ne	54 <__unordtf2+0x54>  // b.any
  7c:	orr	x3, x3, x6
  80:	mov	w0, #0x1                   	// #1
  84:	cbz	x3, 54 <__unordtf2+0x54>
  88:	b	a0 <__unordtf2+0xa0>
  8c:	orr	x0, x3, x6
  90:	cbz	x0, 54 <__unordtf2+0x54>
  94:	mov	x0, #0x7fff                	// #32767
  98:	cmp	x1, x0
  9c:	b.eq	c0 <__unordtf2+0xc0>  // b.none
  a0:	tst	x6, #0x800000000000
  a4:	b.ne	b8 <__unordtf2+0xb8>  // b.any
  a8:	mov	w0, #0x1                   	// #1
  ac:	bl	0 <__sfp_handle_exceptions>
  b0:	mov	w0, #0x1                   	// #1
  b4:	b	54 <__unordtf2+0x54>
  b8:	mov	w0, #0x1                   	// #1
  bc:	b	54 <__unordtf2+0x54>
  c0:	orr	x1, x7, x4
  c4:	cbz	x1, 7c <__unordtf2+0x7c>
  c8:	b	64 <__unordtf2+0x64>

fixtfsi.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixtfsi>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	str	q0, [sp, #32]
  10:	ldr	x1, [sp, #32]
  14:	ldr	x0, [sp, #40]
  18:	mrs	x2, fpcr
  1c:	ubfx	x3, x0, #0, #48
  20:	ubfx	x5, x0, #48, #15
  24:	mov	x4, #0x3ffe                	// #16382
  28:	cmp	x5, x4
  2c:	b.gt	4c <__fixtfsi+0x4c>
  30:	cbnz	x5, d0 <__fixtfsi+0xd0>
  34:	orr	x1, x1, x3
  38:	mov	w19, #0x0                   	// #0
  3c:	cbz	x1, c0 <__fixtfsi+0xc0>
  40:	mov	w19, #0x0                   	// #0
  44:	mov	w0, #0x10                  	// #16
  48:	b	d8 <__fixtfsi+0xd8>
  4c:	lsr	x0, x0, #63
  50:	and	w0, w0, #0xff
  54:	and	x4, x0, #0xff
  58:	mov	x6, #0x401d                	// #16413
  5c:	cmp	x5, x6
  60:	b.le	94 <__fixtfsi+0x94>
  64:	mov	w19, #0x7fffffff            	// #2147483647
  68:	add	w19, w0, w19
  6c:	cmp	x4, #0x0
  70:	mov	x0, #0x401e                	// #16414
  74:	ccmp	x5, x0, #0x0, ne  // ne = any
  78:	b.ne	e0 <__fixtfsi+0xe0>  // b.any
  7c:	cmp	xzr, x3, lsr #17
  80:	b.ne	e8 <__fixtfsi+0xe8>  // b.any
  84:	orr	x1, x1, x3, lsl #47
  88:	cbz	x1, c0 <__fixtfsi+0xc0>
  8c:	mov	w0, #0x10                  	// #16
  90:	b	d8 <__fixtfsi+0xd8>
  94:	orr	x3, x3, #0x1000000000000
  98:	sub	w0, w5, #0x3, lsl #12
  9c:	sub	w0, w0, #0xfef
  a0:	lsl	x0, x3, x0
  a4:	orr	x1, x0, x1
  a8:	mov	w19, #0x402f                	// #16431
  ac:	sub	w19, w19, w5
  b0:	lsr	x19, x3, x19
  b4:	cmp	x4, #0x0
  b8:	cneg	w19, w19, ne  // ne = any
  bc:	cbnz	x1, f0 <__fixtfsi+0xf0>
  c0:	mov	w0, w19
  c4:	ldr	x19, [sp, #16]
  c8:	ldp	x29, x30, [sp], #48
  cc:	ret
  d0:	mov	w19, #0x0                   	// #0
  d4:	mov	w0, #0x10                  	// #16
  d8:	bl	0 <__sfp_handle_exceptions>
  dc:	b	c0 <__fixtfsi+0xc0>
  e0:	mov	w0, #0x1                   	// #1
  e4:	b	d8 <__fixtfsi+0xd8>
  e8:	mov	w0, #0x1                   	// #1
  ec:	b	d8 <__fixtfsi+0xd8>
  f0:	mov	w0, #0x10                  	// #16
  f4:	b	d8 <__fixtfsi+0xd8>

fixunstfsi.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunstfsi>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	str	q0, [sp, #32]
  10:	ldr	x1, [sp, #32]
  14:	ldr	x0, [sp, #40]
  18:	mrs	x2, fpcr
  1c:	ubfx	x3, x0, #0, #48
  20:	ubfx	x5, x0, #48, #15
  24:	mov	x4, #0x3ffe                	// #16382
  28:	cmp	x5, x4
  2c:	b.gt	4c <__fixunstfsi+0x4c>
  30:	cbnz	x5, b0 <__fixunstfsi+0xb0>
  34:	orr	x1, x1, x3
  38:	mov	w19, #0x0                   	// #0
  3c:	cbz	x1, 74 <__fixunstfsi+0x74>
  40:	mov	w19, #0x0                   	// #0
  44:	mov	w0, #0x10                  	// #16
  48:	b	70 <__fixunstfsi+0x70>
  4c:	lsr	x0, x0, #63
  50:	and	w0, w0, #0xff
  54:	mov	x4, #0x401e                	// #16414
  58:	cmp	x5, x4
  5c:	cset	w2, gt
  60:	orr	w2, w0, w2
  64:	cbz	w2, 84 <__fixunstfsi+0x84>
  68:	sub	w19, w0, #0x1
  6c:	mov	w0, #0x1                   	// #1
  70:	bl	0 <__sfp_handle_exceptions>
  74:	mov	w0, w19
  78:	ldr	x19, [sp, #16]
  7c:	ldp	x29, x30, [sp], #48
  80:	ret
  84:	orr	x3, x3, #0x1000000000000
  88:	mov	w19, #0x402f                	// #16431
  8c:	sub	w19, w19, w5
  90:	lsr	x19, x3, x19
  94:	sub	w5, w5, #0x3, lsl #12
  98:	sub	w5, w5, #0xfef
  9c:	lsl	x3, x3, x5
  a0:	orr	x1, x3, x1
  a4:	cbz	x1, 74 <__fixunstfsi+0x74>
  a8:	mov	w0, #0x10                  	// #16
  ac:	b	70 <__fixunstfsi+0x70>
  b0:	mov	w19, #0x0                   	// #0
  b4:	mov	w0, #0x10                  	// #16
  b8:	b	70 <__fixunstfsi+0x70>

floatsitf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatsitf>:
   0:	cbz	w0, 4c <__floatsitf+0x4c>
   4:	lsr	w4, w0, #31
   8:	cmp	w0, #0x0
   c:	cneg	w0, w0, lt  // lt = tstop
  10:	clz	x2, x0
  14:	mov	w1, #0x403e                	// #16446
  18:	sub	w1, w1, w2
  1c:	sxtw	x5, w1
  20:	mov	w2, #0x402f                	// #16431
  24:	sub	w1, w2, w1
  28:	lsl	x0, x0, x1
  2c:	mov	x2, #0x0                   	// #0
  30:	mov	x3, #0x0                   	// #0
  34:	bfxil	x3, x0, #0, #48
  38:	bfi	x3, x5, #48, #15
  3c:	bfi	x3, x4, #63, #1
  40:	fmov	d0, x2
  44:	fmov	v0.d[1], x3
  48:	ret
  4c:	mov	x0, #0x0                   	// #0
  50:	mov	x5, #0x0                   	// #0
  54:	mov	x4, #0x0                   	// #0
  58:	b	2c <__floatsitf+0x2c>

floatunsitf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatunsitf>:
   0:	cbz	w0, 44 <__floatunsitf+0x44>
   4:	mov	w0, w0
   8:	clz	x2, x0
   c:	mov	w1, #0x403e                	// #16446
  10:	sub	w1, w1, w2
  14:	sxtw	x3, w1
  18:	mov	w2, #0x402f                	// #16431
  1c:	sub	w2, w2, w1
  20:	lsl	x2, x0, x2
  24:	mov	x0, #0x0                   	// #0
  28:	mov	x1, #0x0                   	// #0
  2c:	bfxil	x1, x2, #0, #48
  30:	bfi	x1, x3, #48, #15
  34:	and	x1, x1, #0x7fffffffffffffff
  38:	fmov	d0, x0
  3c:	fmov	v0.d[1], x1
  40:	ret
  44:	mov	x2, #0x0                   	// #0
  48:	mov	x3, #0x0                   	// #0
  4c:	b	24 <__floatunsitf+0x24>

fixtfdi.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixtfdi>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	str	q0, [sp, #32]
  10:	ldr	x19, [sp, #32]
  14:	ldr	x0, [sp, #40]
  18:	mrs	x1, fpcr
  1c:	mov	x1, x19
  20:	ubfx	x3, x0, #0, #48
  24:	ubfx	x5, x0, #48, #15
  28:	mov	x4, #0x3ffe                	// #16382
  2c:	cmp	x5, x4
  30:	b.gt	50 <__fixtfdi+0x50>
  34:	cbnz	x5, 118 <__fixtfdi+0x118>
  38:	orr	x19, x19, x3
  3c:	cbnz	x19, 128 <__fixtfdi+0x128>
  40:	mov	x0, x19
  44:	ldr	x19, [sp, #16]
  48:	ldp	x29, x30, [sp], #48
  4c:	ret
  50:	lsr	x0, x0, #63
  54:	and	w0, w0, #0xff
  58:	and	x4, x0, #0xff
  5c:	mov	x6, #0x403d                	// #16445
  60:	cmp	x5, x6
  64:	b.le	98 <__fixtfdi+0x98>
  68:	mov	x19, #0x7fffffffffffffff    	// #9223372036854775807
  6c:	add	x19, x4, x19
  70:	cmp	x4, #0x0
  74:	mov	x0, #0x403e                	// #16446
  78:	ccmp	x5, x0, #0x0, ne  // ne = any
  7c:	b.ne	134 <__fixtfdi+0x134>  // b.any
  80:	extr	x3, x3, x1, #49
  84:	cbnz	x3, 13c <__fixtfdi+0x13c>
  88:	cmp	xzr, x1, lsl #15
  8c:	b.eq	40 <__fixtfdi+0x40>  // b.none
  90:	mov	w0, #0x10                  	// #16
  94:	b	120 <__fixtfdi+0x120>
  98:	orr	x3, x3, #0x1000000000000
  9c:	mov	x0, #0x406f                	// #16495
  a0:	sub	x2, x0, x5
  a4:	cmp	x2, #0x3f
  a8:	b.gt	e8 <__fixtfdi+0xe8>
  ac:	sub	w2, w5, #0x4, lsl #12
  b0:	sub	w2, w2, #0x2f
  b4:	lsl	x0, x19, x2
  b8:	cmp	x0, #0x0
  bc:	cset	w0, ne  // ne = any
  c0:	mov	w19, #0x406f                	// #16495
  c4:	sub	w19, w19, w5
  c8:	lsr	x19, x1, x19
  cc:	lsl	x3, x3, x2
  d0:	orr	x19, x19, x3
  d4:	cmp	x4, #0x0
  d8:	cneg	x19, x19, ne  // ne = any
  dc:	cbz	w0, 40 <__fixtfdi+0x40>
  e0:	mov	w0, #0x10                  	// #16
  e4:	b	120 <__fixtfdi+0x120>
  e8:	sub	w19, w5, #0x3, lsl #12
  ec:	sub	w19, w19, #0xfef
  f0:	lsl	x19, x3, x19
  f4:	cmp	x2, #0x40
  f8:	csel	x19, x19, xzr, ne  // ne = any
  fc:	orr	x19, x19, x1
 100:	cmp	x19, #0x0
 104:	cset	w0, ne  // ne = any
 108:	mov	w19, #0x402f                	// #16431
 10c:	sub	w19, w19, w5
 110:	lsr	x19, x3, x19
 114:	b	d4 <__fixtfdi+0xd4>
 118:	mov	x19, #0x0                   	// #0
 11c:	mov	w0, #0x10                  	// #16
 120:	bl	0 <__sfp_handle_exceptions>
 124:	b	40 <__fixtfdi+0x40>
 128:	mov	x19, #0x0                   	// #0
 12c:	mov	w0, #0x10                  	// #16
 130:	b	120 <__fixtfdi+0x120>
 134:	mov	w0, #0x1                   	// #1
 138:	b	120 <__fixtfdi+0x120>
 13c:	mov	w0, #0x1                   	// #1
 140:	b	120 <__fixtfdi+0x120>

fixunstfdi.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunstfdi>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	str	q0, [sp, #32]
  10:	ldr	x19, [sp, #32]
  14:	ldr	x1, [sp, #40]
  18:	mrs	x0, fpcr
  1c:	ubfx	x3, x1, #0, #48
  20:	ubfx	x4, x1, #48, #15
  24:	mov	x2, #0x3ffe                	// #16382
  28:	cmp	x4, x2
  2c:	b.gt	4c <__fixunstfdi+0x4c>
  30:	cbnz	x4, f4 <__fixunstfdi+0xf4>
  34:	orr	x19, x19, x3
  38:	cbnz	x19, 100 <__fixunstfdi+0x100>
  3c:	mov	x0, x19
  40:	ldr	x19, [sp, #16]
  44:	ldp	x29, x30, [sp], #48
  48:	ret
  4c:	lsr	x1, x1, #63
  50:	and	w1, w1, #0xff
  54:	mov	x2, #0x403e                	// #16446
  58:	cmp	x4, x2
  5c:	cset	w2, gt
  60:	orr	w2, w1, w2
  64:	cbz	w2, 7c <__fixunstfdi+0x7c>
  68:	eor	w1, w1, #0x1
  6c:	sbfx	x19, x1, #0, #1
  70:	mov	w0, #0x1                   	// #1
  74:	bl	0 <__sfp_handle_exceptions>
  78:	b	3c <__fixunstfdi+0x3c>
  7c:	orr	x3, x3, #0x1000000000000
  80:	mov	x1, #0x406f                	// #16495
  84:	sub	x0, x1, x4
  88:	cmp	x0, #0x3f
  8c:	b.gt	c4 <__fixunstfdi+0xc4>
  90:	sub	w2, w4, #0x4, lsl #12
  94:	sub	w2, w2, #0x2f
  98:	lsl	x0, x19, x2
  9c:	cmp	x0, #0x0
  a0:	cset	w1, ne  // ne = any
  a4:	mov	w0, #0x406f                	// #16495
  a8:	sub	w0, w0, w4
  ac:	lsr	x19, x19, x0
  b0:	lsl	x3, x3, x2
  b4:	orr	x19, x19, x3
  b8:	cbz	w1, 3c <__fixunstfdi+0x3c>
  bc:	mov	w0, #0x10                  	// #16
  c0:	b	74 <__fixunstfdi+0x74>
  c4:	sub	w1, w4, #0x3, lsl #12
  c8:	sub	w1, w1, #0xfef
  cc:	lsl	x1, x3, x1
  d0:	cmp	x0, #0x40
  d4:	csel	x0, x1, xzr, ne  // ne = any
  d8:	orr	x19, x0, x19
  dc:	cmp	x19, #0x0
  e0:	cset	w1, ne  // ne = any
  e4:	mov	w0, #0x402f                	// #16431
  e8:	sub	w0, w0, w4
  ec:	lsr	x19, x3, x0
  f0:	b	b8 <__fixunstfdi+0xb8>
  f4:	mov	x19, #0x0                   	// #0
  f8:	mov	w0, #0x10                  	// #16
  fc:	b	74 <__fixunstfdi+0x74>
 100:	mov	x19, #0x0                   	// #0
 104:	mov	w0, #0x10                  	// #16
 108:	b	74 <__fixunstfdi+0x74>

floatditf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatditf>:
   0:	cbz	x0, 68 <__floatditf+0x68>
   4:	lsr	x3, x0, #63
   8:	cmp	x0, #0x0
   c:	cneg	x0, x0, lt  // lt = tstop
  10:	clz	x2, x0
  14:	mov	w1, #0x403e                	// #16446
  18:	sub	w2, w1, w2
  1c:	sxtw	x4, w2
  20:	mov	x1, #0x406f                	// #16495
  24:	sub	x1, x1, x4
  28:	cmp	x1, #0x3f
  2c:	b.gt	50 <__floatditf+0x50>
  30:	sub	w1, w2, #0x4, lsl #12
  34:	sub	w1, w1, #0x2f
  38:	lsr	x1, x0, x1
  3c:	mov	w5, #0x406f                	// #16495
  40:	sub	w2, w5, w2
  44:	lsl	x5, x0, x2
  48:	mov	x0, x3
  4c:	b	74 <__floatditf+0x74>
  50:	mov	w1, #0x402f                	// #16431
  54:	sub	w1, w1, w2
  58:	lsl	x1, x0, x1
  5c:	mov	x0, x3
  60:	mov	x5, #0x0                   	// #0
  64:	b	74 <__floatditf+0x74>
  68:	mov	x4, x0
  6c:	mov	x1, #0x0                   	// #0
  70:	mov	x5, #0x0                   	// #0
  74:	mov	x3, #0x0                   	// #0
  78:	bfxil	x3, x1, #0, #48
  7c:	bfi	x3, x4, #48, #15
  80:	bfi	x3, x0, #63, #1
  84:	fmov	d0, x5
  88:	fmov	v0.d[1], x3
  8c:	ret

floatunditf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatunditf>:
   0:	cbz	x0, 54 <__floatunditf+0x54>
   4:	clz	x2, x0
   8:	mov	w1, #0x403e                	// #16446
   c:	sub	w2, w1, w2
  10:	sxtw	x4, w2
  14:	mov	x1, #0x406f                	// #16495
  18:	sub	x1, x1, x4
  1c:	cmp	x1, #0x3f
  20:	b.gt	40 <__floatunditf+0x40>
  24:	sub	w1, w2, #0x4, lsl #12
  28:	sub	w1, w1, #0x2f
  2c:	lsr	x1, x0, x1
  30:	mov	w3, #0x406f                	// #16495
  34:	sub	w2, w3, w2
  38:	lsl	x0, x0, x2
  3c:	b	5c <__floatunditf+0x5c>
  40:	mov	w1, #0x402f                	// #16431
  44:	sub	w1, w1, w2
  48:	lsl	x1, x0, x1
  4c:	mov	x0, #0x0                   	// #0
  50:	b	5c <__floatunditf+0x5c>
  54:	mov	x1, x0
  58:	mov	x4, #0x0                   	// #0
  5c:	mov	x3, #0x0                   	// #0
  60:	bfxil	x3, x1, #0, #48
  64:	bfi	x3, x4, #48, #15
  68:	and	x3, x3, #0x7fffffffffffffff
  6c:	fmov	d0, x0
  70:	fmov	v0.d[1], x3
  74:	ret

fixtfti.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixtfti>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	stp	x19, x20, [sp, #16]
   c:	str	q0, [sp, #32]
  10:	ldr	x0, [sp, #32]
  14:	ldr	x2, [sp, #40]
  18:	mrs	x1, fpcr
  1c:	ubfx	x3, x2, #0, #48
  20:	ubfx	x5, x2, #48, #15
  24:	mov	x4, x5
  28:	mov	x1, #0x3ffe                	// #16382
  2c:	cmp	x5, x1
  30:	b.gt	4c <__fixtfti+0x4c>
  34:	cbnz	x5, 1a0 <__fixtfti+0x1a0>
  38:	orr	x0, x0, x3
  3c:	cbnz	x0, 1b4 <__fixtfti+0x1b4>
  40:	mov	x19, #0x0                   	// #0
  44:	mov	x20, #0x0                   	// #0
  48:	b	a0 <__fixtfti+0xa0>
  4c:	lsr	x2, x2, #63
  50:	and	w2, w2, #0xff
  54:	and	x2, x2, #0xff
  58:	mov	x1, #0x407d                	// #16509
  5c:	cmp	x5, x1
  60:	b.le	b4 <__fixtfti+0xb4>
  64:	mov	x5, #0x1                   	// #1
  68:	sub	x5, x5, x2
  6c:	asr	x1, x5, #63
  70:	adrp	x6, 0 <__fixtfti>
  74:	add	x7, x6, #0x0
  78:	ldr	x19, [x6]
  7c:	ldr	x20, [x7, #8]
  80:	subs	x19, x19, x5
  84:	sbc	x20, x20, x1
  88:	cmp	x2, #0x0
  8c:	mov	x1, #0x407e                	// #16510
  90:	ccmp	x4, x1, #0x0, ne  // ne = any
  94:	b.ne	1c4 <__fixtfti+0x1c4>  // b.any
  98:	orr	x0, x0, x3
  9c:	cbnz	x0, 198 <__fixtfti+0x198>
  a0:	mov	x0, x19
  a4:	mov	x1, x20
  a8:	ldp	x19, x20, [sp, #16]
  ac:	ldp	x29, x30, [sp], #48
  b0:	ret
  b4:	orr	x3, x3, #0x1000000000000
  b8:	mov	x1, #0x406e                	// #16494
  bc:	cmp	x5, x1
  c0:	b.le	10c <__fixtfti+0x10c>
  c4:	sub	w1, w5, #0x4, lsl #12
  c8:	sub	w1, w1, #0x6f
  cc:	sub	w5, w5, #0x4, lsl #12
  d0:	sub	w5, w5, #0xaf
  d4:	lsl	x7, x0, x5
  d8:	lsr	x4, x0, #1
  dc:	mov	w6, #0x3f                  	// #63
  e0:	sub	w6, w6, w1
  e4:	lsr	x4, x4, x6
  e8:	lsl	x20, x3, x1
  ec:	orr	x20, x4, x20
  f0:	lsl	x19, x0, x1
  f4:	cmp	w5, #0x0
  f8:	csel	x20, x7, x20, ge  // ge = tcont
  fc:	csel	x19, xzr, x19, ge  // ge = tcont
 100:	cbz	x2, a0 <__fixtfti+0xa0>
 104:	mov	w1, #0x0                   	// #0
 108:	b	150 <__fixtfti+0x150>
 10c:	mov	x1, #0x406f                	// #16495
 110:	sub	x4, x1, x5
 114:	cmp	x4, #0x3f
 118:	b.gt	164 <__fixtfti+0x164>
 11c:	sub	w19, w5, #0x4, lsl #12
 120:	sub	w19, w19, #0x2f
 124:	lsl	x1, x0, x19
 128:	cmp	x1, #0x0
 12c:	cset	w1, ne  // ne = any
 130:	mov	w4, #0x406f                	// #16495
 134:	sub	w5, w4, w5
 138:	lsl	x19, x3, x19
 13c:	lsr	x0, x0, x5
 140:	orr	x19, x19, x0
 144:	lsr	x3, x3, x5
 148:	mov	x20, x3
 14c:	cbz	x2, 158 <__fixtfti+0x158>
 150:	negs	x19, x19
 154:	ngc	x20, x20
 158:	mov	w0, #0x10                  	// #16
 15c:	cbnz	w1, 1ac <__fixtfti+0x1ac>
 160:	b	a0 <__fixtfti+0xa0>
 164:	sub	w1, w5, #0x3, lsl #12
 168:	sub	w1, w1, #0xfef
 16c:	lsl	x1, x3, x1
 170:	cmp	x4, #0x40
 174:	csel	x1, x1, xzr, ne  // ne = any
 178:	orr	x0, x1, x0
 17c:	cmp	x0, #0x0
 180:	cset	w1, ne  // ne = any
 184:	mov	w19, #0x402f                	// #16431
 188:	sub	w19, w19, w5
 18c:	lsr	x19, x3, x19
 190:	mov	x3, #0x0                   	// #0
 194:	b	148 <__fixtfti+0x148>
 198:	mov	w0, #0x1                   	// #1
 19c:	b	1ac <__fixtfti+0x1ac>
 1a0:	mov	x19, #0x0                   	// #0
 1a4:	mov	x20, #0x0                   	// #0
 1a8:	mov	w0, #0x10                  	// #16
 1ac:	bl	0 <__sfp_handle_exceptions>
 1b0:	b	a0 <__fixtfti+0xa0>
 1b4:	mov	x19, #0x0                   	// #0
 1b8:	mov	x20, #0x0                   	// #0
 1bc:	mov	w0, #0x10                  	// #16
 1c0:	b	1ac <__fixtfti+0x1ac>
 1c4:	mov	w0, #0x1                   	// #1
 1c8:	b	1ac <__fixtfti+0x1ac>

fixunstfti.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunstfti>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	stp	x19, x20, [sp, #16]
   c:	str	q0, [sp, #32]
  10:	ldr	x20, [sp, #32]
  14:	ldr	x0, [sp, #40]
  18:	mrs	x1, fpcr
  1c:	ubfx	x19, x0, #0, #48
  20:	ubfx	x3, x0, #48, #15
  24:	mov	x2, #0x3ffe                	// #16382
  28:	cmp	x3, x2
  2c:	b.gt	50 <__fixunstfti+0x50>
  30:	cbnz	x3, 160 <__fixunstfti+0x160>
  34:	orr	x20, x20, x19
  38:	mov	x19, #0x0                   	// #0
  3c:	cbz	x20, 80 <__fixunstfti+0x80>
  40:	mov	x20, #0x0                   	// #0
  44:	mov	x19, #0x0                   	// #0
  48:	mov	w0, #0x10                  	// #16
  4c:	b	7c <__fixunstfti+0x7c>
  50:	lsr	x0, x0, #63
  54:	and	w0, w0, #0xff
  58:	mov	x2, #0x407e                	// #16510
  5c:	cmp	x3, x2
  60:	cset	w2, gt
  64:	orr	w2, w0, w2
  68:	cbz	w2, 94 <__fixunstfti+0x94>
  6c:	eor	w0, w0, #0x1
  70:	sbfx	x20, x0, #0, #1
  74:	mov	x19, x20
  78:	mov	w0, #0x1                   	// #1
  7c:	bl	0 <__sfp_handle_exceptions>
  80:	mov	x0, x20
  84:	mov	x1, x19
  88:	ldp	x19, x20, [sp, #16]
  8c:	ldp	x29, x30, [sp], #48
  90:	ret
  94:	orr	x2, x19, #0x1000000000000
  98:	mov	x0, #0x406e                	// #16494
  9c:	cmp	x3, x0
  a0:	b.le	e4 <__fixunstfti+0xe4>
  a4:	sub	w1, w3, #0x4, lsl #12
  a8:	sub	w1, w1, #0x6f
  ac:	sub	w0, w3, #0x4, lsl #12
  b0:	sub	w0, w0, #0xaf
  b4:	lsl	x5, x20, x0
  b8:	lsr	x3, x20, #1
  bc:	mov	w4, #0x3f                  	// #63
  c0:	sub	w4, w4, w1
  c4:	lsr	x3, x3, x4
  c8:	lsl	x19, x2, x1
  cc:	orr	x19, x3, x19
  d0:	lsl	x20, x20, x1
  d4:	cmp	w0, #0x0
  d8:	csel	x19, x5, x19, ge  // ge = tcont
  dc:	csel	x20, xzr, x20, ge  // ge = tcont
  e0:	b	80 <__fixunstfti+0x80>
  e4:	mov	x0, #0x406f                	// #16495
  e8:	sub	x1, x0, x3
  ec:	cmp	x1, #0x3f
  f0:	b.gt	12c <__fixunstfti+0x12c>
  f4:	sub	w0, w3, #0x4, lsl #12
  f8:	sub	w0, w0, #0x2f
  fc:	lsl	x1, x20, x0
 100:	cmp	x1, #0x0
 104:	cset	w1, ne  // ne = any
 108:	mov	w19, #0x406f                	// #16495
 10c:	sub	w19, w19, w3
 110:	lsl	x0, x2, x0
 114:	lsr	x20, x20, x19
 118:	orr	x20, x0, x20
 11c:	lsr	x19, x2, x19
 120:	cbz	w1, 80 <__fixunstfti+0x80>
 124:	mov	w0, #0x10                  	// #16
 128:	b	7c <__fixunstfti+0x7c>
 12c:	sub	w0, w3, #0x3, lsl #12
 130:	sub	w0, w0, #0xfef
 134:	lsl	x0, x2, x0
 138:	cmp	x1, #0x40
 13c:	csel	x0, x0, xzr, ne  // ne = any
 140:	orr	x0, x20, x0
 144:	cmp	x0, #0x0
 148:	cset	w1, ne  // ne = any
 14c:	mov	w0, #0x402f                	// #16431
 150:	sub	w0, w0, w3
 154:	lsr	x20, x2, x0
 158:	mov	x19, #0x0                   	// #0
 15c:	b	120 <__fixunstfti+0x120>
 160:	mov	x20, #0x0                   	// #0
 164:	mov	x19, #0x0                   	// #0
 168:	mov	w0, #0x10                  	// #16
 16c:	b	7c <__fixunstfti+0x7c>

floattitf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floattitf>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	mrs	x8, fpcr
   c:	orr	x2, x0, x1
  10:	cbz	x2, 20c <__floattitf+0x20c>
  14:	mov	x2, x1
  18:	lsr	x5, x1, #63
  1c:	and	w9, w5, #0xff
  20:	tbnz	x1, #63, 130 <__floattitf+0x130>
  24:	mov	x4, x2
  28:	cbz	x2, 13c <__floattitf+0x13c>
  2c:	clz	x3, x2
  30:	mov	w6, #0x407e                	// #16510
  34:	sub	w3, w6, w3
  38:	sxtw	x7, w3
  3c:	mov	x6, #0x406f                	// #16495
  40:	cmp	x6, w3, sxtw
  44:	b.ge	240 <__floattitf+0x240>  // b.tcont
  48:	mov	x5, #0x4072                	// #16498
  4c:	cmp	x7, x5
  50:	b.le	194 <__floattitf+0x194>
  54:	sub	w4, w3, #0x4, lsl #12
  58:	sub	w4, w4, #0x72
  5c:	sub	w6, w3, #0x4, lsl #12
  60:	sub	w6, w6, #0xb2
  64:	lsr	x12, x2, x6
  68:	lsl	x11, x2, #1
  6c:	mov	w10, #0x3f                  	// #63
  70:	sub	w5, w10, w4
  74:	lsl	x11, x11, x5
  78:	lsr	x5, x0, x4
  7c:	orr	x5, x11, x5
  80:	lsr	x4, x2, x4
  84:	cmp	w6, #0x0
  88:	csel	x5, x12, x5, ge  // ge = tcont
  8c:	csel	x4, xzr, x4, ge  // ge = tcont
  90:	mov	w6, #0x40f2                	// #16626
  94:	sub	w3, w6, w3
  98:	subs	w6, w3, #0x40
  9c:	lsl	x12, x0, x6
  a0:	lsr	x11, x0, #1
  a4:	sub	w10, w10, w3
  a8:	lsr	x10, x11, x10
  ac:	lsl	x2, x2, x3
  b0:	orr	x2, x10, x2
  b4:	lsl	x0, x0, x3
  b8:	csel	x2, x12, x2, pl  // pl = nfrst
  bc:	csel	x0, xzr, x0, pl  // pl = nfrst
  c0:	orr	x0, x0, x2
  c4:	cmp	x0, #0x0
  c8:	cset	x0, ne  // ne = any
  cc:	orr	x5, x5, x0
  d0:	and	x4, x4, #0xfff7ffffffffffff
  d4:	mov	w0, #0x0                   	// #0
  d8:	tst	x5, #0x7
  dc:	b.eq	fc <__floattitf+0xfc>  // b.none
  e0:	and	x2, x8, #0xc00000
  e4:	cmp	x2, #0x400, lsl #12
  e8:	b.eq	1e4 <__floattitf+0x1e4>  // b.none
  ec:	cmp	x2, #0x800, lsl #12
  f0:	b.eq	1f8 <__floattitf+0x1f8>  // b.none
  f4:	mov	w0, #0x10                  	// #16
  f8:	cbz	x2, 1cc <__floattitf+0x1cc>
  fc:	tbz	x4, #51, 108 <__floattitf+0x108>
 100:	and	x4, x4, #0xfff7ffffffffffff
 104:	add	x7, x7, #0x1
 108:	mov	x3, #0x0                   	// #0
 10c:	extr	x2, x4, x5, #3
 110:	lsr	x4, x4, #3
 114:	bfxil	x3, x4, #0, #48
 118:	bfi	x3, x7, #48, #15
 11c:	bfi	x3, x9, #63, #1
 120:	stp	x2, x3, [sp, #16]
 124:	cbz	w0, 234 <__floattitf+0x234>
 128:	bl	0 <__sfp_handle_exceptions>
 12c:	b	234 <__floattitf+0x234>
 130:	negs	x0, x0
 134:	ngc	x2, x1
 138:	b	24 <__floattitf+0x24>
 13c:	clz	x3, x0
 140:	mov	w1, #0x403e                	// #16446
 144:	sub	w3, w1, w3
 148:	sxtw	x7, w3
 14c:	mov	x2, x0
 150:	mov	x1, #0x406f                	// #16495
 154:	sub	x1, x1, x7
 158:	cmp	x1, #0x3f
 15c:	b.gt	184 <__floattitf+0x184>
 160:	mov	w0, #0x406f                	// #16495
 164:	sub	w0, w0, w3
 168:	sub	w1, w3, #0x4, lsl #12
 16c:	sub	w1, w1, #0x2f
 170:	lsr	x1, x2, x1
 174:	lsl	x4, x4, x0
 178:	orr	x1, x1, x4
 17c:	lsl	x4, x2, x0
 180:	b	21c <__floattitf+0x21c>
 184:	mov	w1, #0x402f                	// #16431
 188:	sub	w3, w1, w3
 18c:	lsl	x1, x0, x3
 190:	b	21c <__floattitf+0x21c>
 194:	mov	x5, x0
 198:	mov	x2, #0x4072                	// #16498
 19c:	sub	x2, x2, x7
 1a0:	cmp	x2, #0x0
 1a4:	b.le	d0 <__floattitf+0xd0>
 1a8:	mov	w5, #0x4072                	// #16498
 1ac:	sub	w5, w5, w3
 1b0:	sub	w3, w3, #0x4, lsl #12
 1b4:	sub	w3, w3, #0x32
 1b8:	lsr	x3, x0, x3
 1bc:	lsl	x4, x4, x5
 1c0:	orr	x4, x3, x4
 1c4:	lsl	x5, x0, x5
 1c8:	b	d0 <__floattitf+0xd0>
 1cc:	and	x1, x5, #0xf
 1d0:	cmp	x1, #0x4
 1d4:	b.eq	fc <__floattitf+0xfc>  // b.none
 1d8:	adds	x5, x5, #0x4
 1dc:	cinc	x4, x4, cs  // cs = hs, nlast
 1e0:	b	fc <__floattitf+0xfc>
 1e4:	mov	w0, #0x10                  	// #16
 1e8:	tbnz	x1, #63, fc <__floattitf+0xfc>
 1ec:	adds	x5, x5, #0x8
 1f0:	cinc	x4, x4, cs  // cs = hs, nlast
 1f4:	b	fc <__floattitf+0xfc>
 1f8:	mov	w0, #0x10                  	// #16
 1fc:	tbz	x1, #63, fc <__floattitf+0xfc>
 200:	adds	x5, x5, #0x8
 204:	cinc	x4, x4, cs  // cs = hs, nlast
 208:	b	fc <__floattitf+0xfc>
 20c:	mov	x1, #0x0                   	// #0
 210:	mov	x4, #0x0                   	// #0
 214:	mov	x7, #0x0                   	// #0
 218:	mov	x5, #0x0                   	// #0
 21c:	mov	x3, #0x0                   	// #0
 220:	mov	x2, x4
 224:	bfxil	x3, x1, #0, #48
 228:	bfi	x3, x7, #48, #15
 22c:	bfi	x3, x5, #63, #1
 230:	stp	x2, x3, [sp, #16]
 234:	ldr	q0, [sp, #16]
 238:	ldp	x29, x30, [sp], #32
 23c:	ret
 240:	mov	x2, x0
 244:	mov	x1, #0x406f                	// #16495
 248:	sub	x1, x1, x7
 24c:	cmp	x1, #0x0
 250:	b.gt	160 <__floattitf+0x160>
 254:	mov	x1, x4
 258:	mov	x4, x0
 25c:	b	21c <__floattitf+0x21c>

floatuntitf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatuntitf>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	mrs	x8, fpcr
   c:	orr	x2, x0, x1
  10:	cbz	x2, 1d4 <__floatuntitf+0x1d4>
  14:	mov	x4, x1
  18:	cbz	x1, 118 <__floatuntitf+0x118>
  1c:	clz	x2, x1
  20:	mov	w3, #0x407e                	// #16510
  24:	sub	w2, w3, w2
  28:	sxtw	x5, w2
  2c:	mov	x3, #0x406f                	// #16495
  30:	cmp	x3, w2, sxtw
  34:	b.ge	204 <__floatuntitf+0x204>  // b.tcont
  38:	mov	x3, #0x4072                	// #16498
  3c:	cmp	x5, x3
  40:	b.le	170 <__floatuntitf+0x170>
  44:	mov	w3, #0x40f2                	// #16626
  48:	sub	w3, w3, w2
  4c:	subs	w6, w3, #0x40
  50:	lsl	x10, x0, x6
  54:	lsr	x9, x0, #1
  58:	mov	w7, #0x3f                  	// #63
  5c:	sub	w4, w7, w3
  60:	lsr	x9, x9, x4
  64:	lsl	x4, x1, x3
  68:	orr	x4, x9, x4
  6c:	lsl	x3, x0, x3
  70:	csel	x4, x10, x4, pl  // pl = nfrst
  74:	csel	x3, xzr, x3, pl  // pl = nfrst
  78:	orr	x3, x3, x4
  7c:	cmp	x3, #0x0
  80:	cset	x6, ne  // ne = any
  84:	sub	w4, w2, #0x4, lsl #12
  88:	sub	w4, w4, #0x72
  8c:	sub	w2, w2, #0x4, lsl #12
  90:	sub	w2, w2, #0xb2
  94:	lsr	x9, x1, x2
  98:	lsl	x3, x1, #1
  9c:	sub	w7, w7, w4
  a0:	lsl	x7, x3, x7
  a4:	lsr	x0, x0, x4
  a8:	orr	x0, x7, x0
  ac:	lsr	x4, x1, x4
  b0:	cmp	w2, #0x0
  b4:	csel	x0, x9, x0, ge  // ge = tcont
  b8:	orr	x6, x6, x0
  bc:	csel	x4, xzr, x4, ge  // ge = tcont
  c0:	and	x4, x4, #0xfff7ffffffffffff
  c4:	mov	w0, #0x0                   	// #0
  c8:	tst	x6, #0x7
  cc:	b.eq	e4 <__floatuntitf+0xe4>  // b.none
  d0:	ands	x0, x8, #0xc00000
  d4:	b.eq	1a8 <__floatuntitf+0x1a8>  // b.none
  d8:	cmp	x0, #0x400, lsl #12
  dc:	b.eq	1c4 <__floatuntitf+0x1c4>  // b.none
  e0:	mov	w0, #0x10                  	// #16
  e4:	tbz	x4, #51, f0 <__floatuntitf+0xf0>
  e8:	and	x4, x4, #0xfff7ffffffffffff
  ec:	add	x5, x5, #0x1
  f0:	mov	x3, #0x0                   	// #0
  f4:	extr	x2, x4, x6, #3
  f8:	lsr	x4, x4, #3
  fc:	bfxil	x3, x4, #0, #48
 100:	bfi	x3, x5, #48, #15
 104:	and	x3, x3, #0x7fffffffffffffff
 108:	stp	x2, x3, [sp, #16]
 10c:	cbz	w0, 1f8 <__floatuntitf+0x1f8>
 110:	bl	0 <__sfp_handle_exceptions>
 114:	b	1f8 <__floatuntitf+0x1f8>
 118:	clz	x2, x0
 11c:	mov	w3, #0x403e                	// #16446
 120:	sub	w2, w3, w2
 124:	sxtw	x5, w2
 128:	mov	x6, x0
 12c:	mov	x3, #0x406f                	// #16495
 130:	sub	x3, x3, x5
 134:	cmp	x3, #0x3f
 138:	b.gt	160 <__floatuntitf+0x160>
 13c:	mov	w4, #0x406f                	// #16495
 140:	sub	w4, w4, w2
 144:	sub	w2, w2, #0x4, lsl #12
 148:	sub	w2, w2, #0x2f
 14c:	lsr	x2, x6, x2
 150:	lsl	x1, x1, x4
 154:	orr	x1, x2, x1
 158:	lsl	x4, x6, x4
 15c:	b	1e0 <__floatuntitf+0x1e0>
 160:	mov	w1, #0x402f                	// #16431
 164:	sub	w1, w1, w2
 168:	lsl	x1, x0, x1
 16c:	b	1e0 <__floatuntitf+0x1e0>
 170:	mov	x6, x0
 174:	mov	x3, #0x4072                	// #16498
 178:	sub	x3, x3, x5
 17c:	cmp	x3, #0x0
 180:	b.le	c0 <__floatuntitf+0xc0>
 184:	mov	w6, #0x4072                	// #16498
 188:	sub	w6, w6, w2
 18c:	sub	w4, w2, #0x4, lsl #12
 190:	sub	w4, w4, #0x32
 194:	lsr	x4, x0, x4
 198:	lsl	x1, x1, x6
 19c:	orr	x4, x4, x1
 1a0:	lsl	x6, x0, x6
 1a4:	b	c0 <__floatuntitf+0xc0>
 1a8:	and	x1, x6, #0xf
 1ac:	mov	w0, #0x10                  	// #16
 1b0:	cmp	x1, #0x4
 1b4:	b.eq	e4 <__floatuntitf+0xe4>  // b.none
 1b8:	adds	x6, x6, #0x4
 1bc:	cinc	x4, x4, cs  // cs = hs, nlast
 1c0:	b	e4 <__floatuntitf+0xe4>
 1c4:	adds	x6, x6, #0x8
 1c8:	cinc	x4, x4, cs  // cs = hs, nlast
 1cc:	mov	w0, #0x10                  	// #16
 1d0:	b	e4 <__floatuntitf+0xe4>
 1d4:	mov	x1, #0x0                   	// #0
 1d8:	mov	x4, #0x0                   	// #0
 1dc:	mov	x5, #0x0                   	// #0
 1e0:	mov	x3, #0x0                   	// #0
 1e4:	mov	x2, x4
 1e8:	bfxil	x3, x1, #0, #48
 1ec:	bfi	x3, x5, #48, #15
 1f0:	and	x3, x3, #0x7fffffffffffffff
 1f4:	stp	x2, x3, [sp, #16]
 1f8:	ldr	q0, [sp, #16]
 1fc:	ldp	x29, x30, [sp], #32
 200:	ret
 204:	mov	x6, x0
 208:	mov	x3, #0x406f                	// #16495
 20c:	sub	x3, x3, x5
 210:	cmp	x3, #0x0
 214:	b.gt	13c <__floatuntitf+0x13c>
 218:	mov	x4, x0
 21c:	b	1e0 <__floatuntitf+0x1e0>

extendsftf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__extendsftf2>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	mrs	x0, fpcr
   c:	fmov	w0, s0
  10:	ubfx	x5, x0, #0, #23
  14:	and	x4, x0, #0x7fffff
  18:	ubfx	x1, x0, #23, #8
  1c:	lsr	w0, w0, #31
  20:	add	x2, x1, #0x1
  24:	tst	x2, #0xfe
  28:	b.eq	5c <__extendsftf2+0x5c>  // b.none
  2c:	add	x1, x1, #0x3, lsl #12
  30:	add	x1, x1, #0xf80
  34:	lsl	x4, x4, #25
  38:	mov	x2, #0x0                   	// #0
  3c:	mov	x3, #0x0                   	// #0
  40:	bfxil	x3, x4, #0, #48
  44:	bfi	x3, x1, #48, #15
  48:	bfi	x3, x0, #63, #1
  4c:	stp	x2, x3, [sp, #16]
  50:	ldr	q0, [sp, #16]
  54:	ldp	x29, x30, [sp], #32
  58:	ret
  5c:	cbnz	x1, 80 <__extendsftf2+0x80>
  60:	cbz	x4, 38 <__extendsftf2+0x38>
  64:	clz	x2, x4
  68:	sub	w1, w2, #0xf
  6c:	lsl	x4, x4, x1
  70:	mov	w1, #0x3fa9                	// #16297
  74:	sub	w1, w1, w2
  78:	sxtw	x1, w1
  7c:	b	38 <__extendsftf2+0x38>
  80:	cbz	x4, b4 <__extendsftf2+0xb4>
  84:	lsl	x4, x4, #25
  88:	mov	x2, #0x0                   	// #0
  8c:	mov	x3, #0x0                   	// #0
  90:	orr	x4, x4, #0x800000000000
  94:	bfxil	x3, x4, #0, #48
  98:	orr	x3, x3, #0x7fff000000000000
  9c:	bfi	x3, x0, #63, #1
  a0:	stp	x2, x3, [sp, #16]
  a4:	tbnz	w5, #22, 50 <__extendsftf2+0x50>
  a8:	mov	w0, #0x1                   	// #1
  ac:	bl	0 <__sfp_handle_exceptions>
  b0:	b	50 <__extendsftf2+0x50>
  b4:	mov	x1, #0x7fff                	// #32767
  b8:	b	38 <__extendsftf2+0x38>

extenddftf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__extenddftf2>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	mrs	x0, fpcr
   c:	fmov	x0, d0
  10:	ubfx	x4, x0, #0, #52
  14:	ubfx	x1, x0, #52, #11
  18:	lsr	x0, x0, #63
  1c:	and	w0, w0, #0xff
  20:	add	x2, x1, #0x1
  24:	tst	x2, #0x7fe
  28:	b.eq	60 <__extenddftf2+0x60>  // b.none
  2c:	add	x1, x1, #0x3, lsl #12
  30:	add	x1, x1, #0xc00
  34:	lsr	x6, x4, #4
  38:	lsl	x5, x4, #60
  3c:	mov	x3, #0x0                   	// #0
  40:	mov	x2, x5
  44:	bfxil	x3, x6, #0, #48
  48:	bfi	x3, x1, #48, #15
  4c:	bfi	x3, x0, #63, #1
  50:	stp	x2, x3, [sp, #16]
  54:	ldr	q0, [sp, #16]
  58:	ldp	x29, x30, [sp], #32
  5c:	ret
  60:	mov	x5, x4
  64:	cbnz	x1, b0 <__extenddftf2+0xb0>
  68:	mov	x6, x4
  6c:	cbz	x4, 3c <__extenddftf2+0x3c>
  70:	clz	x2, x4
  74:	cmp	w2, #0xe
  78:	b.gt	a0 <__extenddftf2+0xa0>
  7c:	mov	w6, #0xf                   	// #15
  80:	sub	w6, w6, w2
  84:	lsr	x6, x4, x6
  88:	add	w5, w2, #0x31
  8c:	lsl	x5, x4, x5
  90:	mov	w1, #0x3c0c                	// #15372
  94:	sub	w1, w1, w2
  98:	sxtw	x1, w1
  9c:	b	3c <__extenddftf2+0x3c>
  a0:	sub	w6, w2, #0xf
  a4:	lsl	x6, x4, x6
  a8:	mov	x5, #0x0                   	// #0
  ac:	b	90 <__extenddftf2+0x90>
  b0:	cbz	x4, e8 <__extenddftf2+0xe8>
  b4:	mov	x3, #0x0                   	// #0
  b8:	lsl	x2, x4, #60
  bc:	lsr	x1, x4, #4
  c0:	orr	x1, x1, #0x800000000000
  c4:	bfxil	x3, x1, #0, #48
  c8:	orr	x3, x3, #0x7fff000000000000
  cc:	bfi	x3, x0, #63, #1
  d0:	stp	x2, x3, [sp, #16]
  d4:	tst	x4, #0x8000000000000
  d8:	b.ne	54 <__extenddftf2+0x54>  // b.any
  dc:	mov	w0, #0x1                   	// #1
  e0:	bl	0 <__sfp_handle_exceptions>
  e4:	b	54 <__extenddftf2+0x54>
  e8:	mov	x6, x4
  ec:	mov	x1, #0x7fff                	// #32767
  f0:	b	3c <__extenddftf2+0x3c>

extendhftf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__extendhftf2>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	mrs	x0, fpcr
   c:	umov	w1, v0.h[0]
  10:	mov	w0, #0x0                   	// #0
  14:	bfxil	w0, w1, #0, #16
  18:	and	w5, w0, #0x3ff
  1c:	and	x4, x0, #0x3ff
  20:	ubfx	x1, x0, #10, #5
  24:	ubfx	x0, x0, #15, #1
  28:	add	x2, x1, #0x1
  2c:	tst	x2, #0x1e
  30:	b.eq	64 <__extendhftf2+0x64>  // b.none
  34:	add	x1, x1, #0x3, lsl #12
  38:	add	x1, x1, #0xff0
  3c:	lsl	x4, x4, #38
  40:	mov	x2, #0x0                   	// #0
  44:	mov	x3, #0x0                   	// #0
  48:	bfxil	x3, x4, #0, #48
  4c:	bfi	x3, x1, #48, #15
  50:	bfi	x3, x0, #63, #1
  54:	stp	x2, x3, [sp, #16]
  58:	ldr	q0, [sp, #16]
  5c:	ldp	x29, x30, [sp], #32
  60:	ret
  64:	cbnz	x1, 88 <__extendhftf2+0x88>
  68:	cbz	x4, 40 <__extendhftf2+0x40>
  6c:	clz	x2, x4
  70:	sub	w1, w2, #0xf
  74:	lsl	x4, x4, x1
  78:	mov	w1, #0x4026                	// #16422
  7c:	sub	w1, w1, w2
  80:	sxtw	x1, w1
  84:	b	40 <__extendhftf2+0x40>
  88:	cbz	x4, bc <__extendhftf2+0xbc>
  8c:	lsl	x4, x4, #38
  90:	mov	x2, #0x0                   	// #0
  94:	mov	x3, #0x0                   	// #0
  98:	orr	x4, x4, #0x800000000000
  9c:	bfxil	x3, x4, #0, #48
  a0:	orr	x3, x3, #0x7fff000000000000
  a4:	bfi	x3, x0, #63, #1
  a8:	stp	x2, x3, [sp, #16]
  ac:	tbnz	w5, #9, 58 <__extendhftf2+0x58>
  b0:	mov	w0, #0x1                   	// #1
  b4:	bl	0 <__sfp_handle_exceptions>
  b8:	b	58 <__extendhftf2+0x58>
  bc:	mov	x1, #0x7fff                	// #32767
  c0:	b	40 <__extendhftf2+0x40>

trunctfsf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__trunctfsf2>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	str	q0, [sp, #32]
  10:	ldr	x2, [sp, #32]
  14:	ldr	x0, [sp, #40]
  18:	mrs	x5, fpcr
  1c:	ubfx	x3, x0, #48, #15
  20:	lsr	x4, x0, #63
  24:	and	w4, w4, #0xff
  28:	ubfiz	x0, x0, #3, #48
  2c:	orr	x1, x0, x2, lsr #61
  30:	lsl	x2, x2, #3
  34:	add	x0, x3, #0x1
  38:	tst	x0, #0x7ffe
  3c:	b.eq	100 <__trunctfsf2+0x100>  // b.none
  40:	sub	x3, x3, #0x3, lsl #12
  44:	sub	x3, x3, #0xf80
  48:	cmp	x3, #0xfe
  4c:	b.le	88 <__trunctfsf2+0x88>
  50:	ands	x0, x5, #0xc00000
  54:	b.eq	254 <__trunctfsf2+0x254>  // b.none
  58:	cmp	x0, #0x400, lsl #12
  5c:	csinc	w1, w4, wzr, eq  // eq = none
  60:	cbz	w1, 264 <__trunctfsf2+0x264>
  64:	cmp	x0, #0x800, lsl #12
  68:	csel	w0, w4, wzr, eq  // eq = none
  6c:	cbnz	w0, 26c <__trunctfsf2+0x26c>
  70:	mov	x2, #0xffffffffffffffff    	// #-1
  74:	mov	x3, #0xfe                  	// #254
  78:	mov	w0, #0x14                  	// #20
  7c:	cmp	x3, #0x0
  80:	cset	w6, eq  // eq = none
  84:	b	11c <__trunctfsf2+0x11c>
  88:	cmp	x3, #0x0
  8c:	b.le	b8 <__trunctfsf2+0xb8>
  90:	orr	x2, x2, x1, lsl #39
  94:	cmp	x2, #0x0
  98:	cset	x2, ne  // ne = any
  9c:	orr	x2, x2, x1, lsr #25
  a0:	mov	w0, #0x0                   	// #0
  a4:	tst	x2, #0x7
  a8:	b.eq	208 <__trunctfsf2+0x208>  // b.none
  ac:	cmp	x3, #0x0
  b0:	cset	w6, eq  // eq = none
  b4:	b	11c <__trunctfsf2+0x11c>
  b8:	cmn	x3, #0x17
  bc:	b.lt	27c <__trunctfsf2+0x27c>  // b.tstop
  c0:	orr	x0, x1, #0x8000000000000
  c4:	add	w1, w3, #0x26
  c8:	lsl	x1, x0, x1
  cc:	orr	x2, x1, x2
  d0:	cmp	x2, #0x0
  d4:	cset	x2, ne  // ne = any
  d8:	mov	w1, #0x1a                  	// #26
  dc:	sub	w1, w1, w3
  e0:	lsr	x1, x0, x1
  e4:	orr	x2, x1, x2
  e8:	tst	x2, #0x7
  ec:	b.eq	28c <__trunctfsf2+0x28c>  // b.none
  f0:	mov	w0, #0x0                   	// #0
  f4:	mov	w6, #0x1                   	// #1
  f8:	mov	x3, #0x0                   	// #0
  fc:	b	11c <__trunctfsf2+0x11c>
 100:	cbnz	x3, 140 <__trunctfsf2+0x140>
 104:	orr	x1, x1, x2
 108:	cmp	x1, #0x0
 10c:	cset	x2, ne  // ne = any
 110:	mov	w0, #0x0                   	// #0
 114:	mov	w6, #0x1                   	// #1
 118:	cbz	x1, 188 <__trunctfsf2+0x188>
 11c:	orr	w0, w0, #0x10
 120:	and	x1, x5, #0xc00000
 124:	cmp	x1, #0x400, lsl #12
 128:	b.eq	1a8 <__trunctfsf2+0x1a8>  // b.none
 12c:	cmp	x1, #0x800, lsl #12
 130:	b.eq	1b8 <__trunctfsf2+0x1b8>  // b.none
 134:	cbz	x1, 170 <__trunctfsf2+0x170>
 138:	cbnz	w6, 184 <__trunctfsf2+0x184>
 13c:	b	188 <__trunctfsf2+0x188>
 140:	orr	x2, x1, x2
 144:	cbz	x2, 274 <__trunctfsf2+0x274>
 148:	lsr	x0, x1, #50
 14c:	eor	w0, w0, #0x1
 150:	mov	x2, #0x7fff                	// #32767
 154:	cmp	x3, x2
 158:	csel	w0, w0, wzr, eq  // eq = none
 15c:	lsr	x1, x1, #25
 160:	and	x1, x1, #0xfffffffffffffff8
 164:	orr	x2, x1, #0x2000000
 168:	mov	x3, #0xff                  	// #255
 16c:	b	a4 <__trunctfsf2+0xa4>
 170:	and	x7, x2, #0xf
 174:	add	x1, x2, #0x4
 178:	cmp	x7, #0x4
 17c:	csel	x2, x1, x2, ne  // ne = any
 180:	cbz	w6, 188 <__trunctfsf2+0x188>
 184:	orr	w0, w0, #0x8
 188:	tbz	w2, #26, 208 <__trunctfsf2+0x208>
 18c:	add	x3, x3, #0x1
 190:	cmp	x3, #0xff
 194:	b.eq	1d4 <__trunctfsf2+0x1d4>  // b.none
 198:	mov	x1, #0xffffffffff7fffff    	// #-8388609
 19c:	movk	x1, #0x1fff, lsl #48
 1a0:	and	x1, x1, x2, lsr #3
 1a4:	b	21c <__trunctfsf2+0x21c>
 1a8:	add	x1, x2, #0x8
 1ac:	cmp	w4, #0x0
 1b0:	csel	x2, x1, x2, eq  // eq = none
 1b4:	b	180 <__trunctfsf2+0x180>
 1b8:	add	x1, x2, #0x8
 1bc:	cmp	w4, #0x0
 1c0:	csel	x2, x1, x2, ne  // ne = any
 1c4:	b	180 <__trunctfsf2+0x180>
 1c8:	mov	w0, #0x0                   	// #0
 1cc:	mov	x3, #0x0                   	// #0
 1d0:	b	184 <__trunctfsf2+0x184>
 1d4:	ands	x2, x5, #0xc00000
 1d8:	b.eq	200 <__trunctfsf2+0x200>  // b.none
 1dc:	cmp	x2, #0x400, lsl #12
 1e0:	csinc	w1, w4, wzr, eq  // eq = none
 1e4:	cbz	w1, 244 <__trunctfsf2+0x244>
 1e8:	cmp	x2, #0x800, lsl #12
 1ec:	csel	w1, w4, wzr, eq  // eq = none
 1f0:	cmp	w1, #0x0
 1f4:	csetm	x2, eq  // eq = none
 1f8:	mov	x1, #0xfe                  	// #254
 1fc:	csel	x3, x3, x1, ne  // ne = any
 200:	mov	w1, #0x14                  	// #20
 204:	orr	w0, w0, w1
 208:	lsr	x1, x2, #3
 20c:	cmp	x3, #0xff
 210:	orr	x2, x1, #0x400000
 214:	ccmp	x1, #0x0, #0x4, eq  // eq = none
 218:	csel	x1, x2, x1, ne  // ne = any
 21c:	mov	w2, #0x0                   	// #0
 220:	bfxil	w2, w1, #0, #23
 224:	bfi	w2, w3, #23, #8
 228:	bfi	w2, w4, #31, #1
 22c:	mov	w19, w2
 230:	cbnz	w0, 24c <__trunctfsf2+0x24c>
 234:	fmov	s0, w19
 238:	ldr	x19, [sp, #16]
 23c:	ldp	x29, x30, [sp], #48
 240:	ret
 244:	mov	x2, #0x0                   	// #0
 248:	b	200 <__trunctfsf2+0x200>
 24c:	bl	0 <__sfp_handle_exceptions>
 250:	b	234 <__trunctfsf2+0x234>
 254:	mov	w0, #0x14                  	// #20
 258:	mov	x3, #0xff                  	// #255
 25c:	mov	x2, #0x0                   	// #0
 260:	b	188 <__trunctfsf2+0x188>
 264:	mov	w0, #0x14                  	// #20
 268:	b	258 <__trunctfsf2+0x258>
 26c:	mov	w0, #0x14                  	// #20
 270:	b	258 <__trunctfsf2+0x258>
 274:	mov	w0, #0x0                   	// #0
 278:	b	258 <__trunctfsf2+0x258>
 27c:	mov	x2, #0x1                   	// #1
 280:	mov	x3, #0x0                   	// #0
 284:	mov	w0, #0x0                   	// #0
 288:	b	7c <__trunctfsf2+0x7c>
 28c:	tbnz	w5, #11, 1c8 <__trunctfsf2+0x1c8>
 290:	mov	x3, #0x0                   	// #0
 294:	mov	w0, #0x0                   	// #0
 298:	b	188 <__trunctfsf2+0x188>

trunctfdf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__trunctfdf2>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	d8, [sp, #16]
   c:	str	q0, [sp, #32]
  10:	ldr	x0, [sp, #32]
  14:	ldr	x1, [sp, #40]
  18:	mrs	x3, fpcr
  1c:	ubfx	x2, x1, #48, #15
  20:	lsr	x4, x1, #63
  24:	and	w4, w4, #0xff
  28:	ubfiz	x1, x1, #3, #48
  2c:	orr	x1, x1, x0, lsr #61
  30:	lsl	x5, x0, #3
  34:	add	x6, x2, #0x1
  38:	tst	x6, #0x7ffe
  3c:	b.eq	130 <__trunctfdf2+0x130>  // b.none
  40:	sub	x2, x2, #0x3, lsl #12
  44:	sub	x2, x2, #0xc00
  48:	cmp	x2, #0x7fe
  4c:	b.le	88 <__trunctfdf2+0x88>
  50:	ands	x0, x3, #0xc00000
  54:	b.eq	28c <__trunctfdf2+0x28c>  // b.none
  58:	cmp	x0, #0x400, lsl #12
  5c:	csinc	w1, w4, wzr, eq  // eq = none
  60:	cbz	w1, 29c <__trunctfdf2+0x29c>
  64:	cmp	x0, #0x800, lsl #12
  68:	csel	w0, w4, wzr, eq  // eq = none
  6c:	cbnz	w0, 2a4 <__trunctfdf2+0x2a4>
  70:	mov	x1, #0xffffffffffffffff    	// #-1
  74:	mov	x2, #0x7fe                 	// #2046
  78:	mov	w0, #0x14                  	// #20
  7c:	cmp	x2, #0x0
  80:	cset	w6, eq  // eq = none
  84:	b	158 <__trunctfdf2+0x158>
  88:	cmp	x2, #0x0
  8c:	b.le	b8 <__trunctfdf2+0xb8>
  90:	cmp	xzr, x0, lsl #7
  94:	cset	x0, ne  // ne = any
  98:	orr	x0, x0, x5, lsr #60
  9c:	orr	x1, x0, x1, lsl #4
  a0:	mov	w0, #0x0                   	// #0
  a4:	tst	x1, #0x7
  a8:	b.eq	240 <__trunctfdf2+0x240>  // b.none
  ac:	cmp	x2, #0x0
  b0:	cset	w6, eq  // eq = none
  b4:	b	158 <__trunctfdf2+0x158>
  b8:	cmn	x2, #0x34
  bc:	b.lt	2b4 <__trunctfdf2+0x2b4>  // b.tstop
  c0:	orr	x0, x1, #0x8000000000000
  c4:	mov	x1, #0x3d                  	// #61
  c8:	sub	x1, x1, x2
  cc:	cmp	x1, #0x3f
  d0:	b.gt	100 <__trunctfdf2+0x100>
  d4:	add	w6, w2, #0x3
  d8:	mov	w1, #0x3d                  	// #61
  dc:	sub	w2, w1, w2
  e0:	lsr	x2, x5, x2
  e4:	lsl	x1, x5, x6
  e8:	cmp	x1, #0x0
  ec:	cset	x1, ne  // ne = any
  f0:	orr	x2, x2, x1
  f4:	lsl	x1, x0, x6
  f8:	orr	x1, x1, x2
  fc:	b	140 <__trunctfdf2+0x140>
 100:	mov	w6, #0xfffffffd            	// #-3
 104:	sub	w6, w6, w2
 108:	lsr	x6, x0, x6
 10c:	add	w2, w2, #0x43
 110:	lsl	x0, x0, x2
 114:	cmp	x1, #0x40
 118:	csel	x0, x0, xzr, ne  // ne = any
 11c:	orr	x0, x0, x5
 120:	cmp	x0, #0x0
 124:	cset	x1, ne  // ne = any
 128:	orr	x1, x6, x1
 12c:	b	140 <__trunctfdf2+0x140>
 130:	cbnz	x2, 17c <__trunctfdf2+0x17c>
 134:	orr	x1, x1, x5
 138:	cmp	x1, #0x0
 13c:	cset	x1, ne  // ne = any
 140:	cmp	x1, #0x0
 144:	cset	w6, ne  // ne = any
 148:	tst	x1, #0x7
 14c:	b.eq	2d4 <__trunctfdf2+0x2d4>  // b.none
 150:	mov	w0, #0x0                   	// #0
 154:	mov	x2, #0x0                   	// #0
 158:	orr	w0, w0, #0x10
 15c:	and	x5, x3, #0xc00000
 160:	cmp	x5, #0x400, lsl #12
 164:	b.eq	1e0 <__trunctfdf2+0x1e0>  // b.none
 168:	cmp	x5, #0x800, lsl #12
 16c:	b.eq	1f0 <__trunctfdf2+0x1f0>  // b.none
 170:	cbz	x5, 1ac <__trunctfdf2+0x1ac>
 174:	cbnz	w6, 1c0 <__trunctfdf2+0x1c0>
 178:	b	1c4 <__trunctfdf2+0x1c4>
 17c:	orr	x0, x1, x5
 180:	cbz	x0, 2ac <__trunctfdf2+0x2ac>
 184:	lsr	x0, x1, #50
 188:	eor	w0, w0, #0x1
 18c:	mov	x6, #0x7fff                	// #32767
 190:	cmp	x2, x6
 194:	csel	w0, w0, wzr, eq  // eq = none
 198:	extr	x1, x1, x5, #60
 19c:	and	x1, x1, #0xfffffffffffffff8
 1a0:	orr	x1, x1, #0x40000000000000
 1a4:	mov	x2, #0x7ff                 	// #2047
 1a8:	b	a4 <__trunctfdf2+0xa4>
 1ac:	and	x7, x1, #0xf
 1b0:	add	x5, x1, #0x4
 1b4:	cmp	x7, #0x4
 1b8:	csel	x1, x5, x1, ne  // ne = any
 1bc:	cbz	w6, 1c4 <__trunctfdf2+0x1c4>
 1c0:	orr	w0, w0, #0x8
 1c4:	tbz	x1, #55, 240 <__trunctfdf2+0x240>
 1c8:	add	x2, x2, #0x1
 1cc:	cmp	x2, #0x7ff
 1d0:	b.eq	20c <__trunctfdf2+0x20c>  // b.none
 1d4:	mov	x3, #0x1fefffffffffffff    	// #2301339409586323455
 1d8:	and	x1, x3, x1, lsr #3
 1dc:	b	254 <__trunctfdf2+0x254>
 1e0:	add	x5, x1, #0x8
 1e4:	cmp	w4, #0x0
 1e8:	csel	x1, x5, x1, eq  // eq = none
 1ec:	b	1bc <__trunctfdf2+0x1bc>
 1f0:	add	x5, x1, #0x8
 1f4:	cmp	w4, #0x0
 1f8:	csel	x1, x5, x1, ne  // ne = any
 1fc:	b	1bc <__trunctfdf2+0x1bc>
 200:	mov	w0, #0x0                   	// #0
 204:	mov	x2, #0x0                   	// #0
 208:	b	1c0 <__trunctfdf2+0x1c0>
 20c:	ands	x1, x3, #0xc00000
 210:	b.eq	238 <__trunctfdf2+0x238>  // b.none
 214:	cmp	x1, #0x400, lsl #12
 218:	csinc	w3, w4, wzr, eq  // eq = none
 21c:	cbz	w3, 27c <__trunctfdf2+0x27c>
 220:	cmp	x1, #0x800, lsl #12
 224:	csel	w3, w4, wzr, eq  // eq = none
 228:	cmp	w3, #0x0
 22c:	csetm	x1, eq  // eq = none
 230:	mov	x3, #0x7fe                 	// #2046
 234:	csel	x2, x2, x3, ne  // ne = any
 238:	mov	w3, #0x14                  	// #20
 23c:	orr	w0, w0, w3
 240:	lsr	x1, x1, #3
 244:	cmp	x2, #0x7ff
 248:	orr	x3, x1, #0x8000000000000
 24c:	ccmp	x1, #0x0, #0x4, eq  // eq = none
 250:	csel	x1, x3, x1, ne  // ne = any
 254:	mov	x3, #0x0                   	// #0
 258:	bfxil	x3, x1, #0, #52
 25c:	bfi	x3, x2, #52, #11
 260:	bfi	x3, x4, #63, #1
 264:	fmov	d8, x3
 268:	cbnz	w0, 284 <__trunctfdf2+0x284>
 26c:	fmov	d0, d8
 270:	ldr	d8, [sp, #16]
 274:	ldp	x29, x30, [sp], #48
 278:	ret
 27c:	mov	x1, #0x0                   	// #0
 280:	b	238 <__trunctfdf2+0x238>
 284:	bl	0 <__sfp_handle_exceptions>
 288:	b	26c <__trunctfdf2+0x26c>
 28c:	mov	w0, #0x14                  	// #20
 290:	mov	x2, #0x7ff                 	// #2047
 294:	mov	x1, #0x0                   	// #0
 298:	b	1c4 <__trunctfdf2+0x1c4>
 29c:	mov	w0, #0x14                  	// #20
 2a0:	b	290 <__trunctfdf2+0x290>
 2a4:	mov	w0, #0x14                  	// #20
 2a8:	b	290 <__trunctfdf2+0x290>
 2ac:	mov	w0, #0x0                   	// #0
 2b0:	b	290 <__trunctfdf2+0x290>
 2b4:	mov	x1, #0x1                   	// #1
 2b8:	mov	x2, #0x0                   	// #0
 2bc:	mov	w0, #0x0                   	// #0
 2c0:	b	7c <__trunctfdf2+0x7c>
 2c4:	tbnz	w3, #11, 200 <__trunctfdf2+0x200>
 2c8:	mov	x2, #0x0                   	// #0
 2cc:	mov	w0, #0x0                   	// #0
 2d0:	b	1c4 <__trunctfdf2+0x1c4>
 2d4:	cbnz	x1, 2c4 <__trunctfdf2+0x2c4>
 2d8:	mov	x2, #0x0                   	// #0
 2dc:	mov	w0, #0x0                   	// #0
 2e0:	b	1c4 <__trunctfdf2+0x1c4>

trunctfhf2.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__trunctfhf2>:
   0:	stp	x29, x30, [sp, #-48]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	str	q0, [sp, #32]
  10:	ldr	x2, [sp, #32]
  14:	ldr	x0, [sp, #40]
  18:	mrs	x5, fpcr
  1c:	ubfx	x3, x0, #48, #15
  20:	lsr	x4, x0, #63
  24:	and	w4, w4, #0xff
  28:	ubfiz	x0, x0, #3, #48
  2c:	orr	x1, x0, x2, lsr #61
  30:	lsl	x2, x2, #3
  34:	add	x0, x3, #0x1
  38:	tst	x0, #0x7ffe
  3c:	b.eq	100 <__trunctfhf2+0x100>  // b.none
  40:	sub	x3, x3, #0x3, lsl #12
  44:	sub	x3, x3, #0xff0
  48:	cmp	x3, #0x1e
  4c:	b.le	88 <__trunctfhf2+0x88>
  50:	ands	x0, x5, #0xc00000
  54:	b.eq	254 <__trunctfhf2+0x254>  // b.none
  58:	cmp	x0, #0x400, lsl #12
  5c:	csinc	w1, w4, wzr, eq  // eq = none
  60:	cbz	w1, 264 <__trunctfhf2+0x264>
  64:	cmp	x0, #0x800, lsl #12
  68:	csel	w0, w4, wzr, eq  // eq = none
  6c:	cbnz	w0, 26c <__trunctfhf2+0x26c>
  70:	mov	x2, #0xffffffffffffffff    	// #-1
  74:	mov	x3, #0x1e                  	// #30
  78:	mov	w0, #0x14                  	// #20
  7c:	cmp	x3, #0x0
  80:	cset	w6, eq  // eq = none
  84:	b	11c <__trunctfhf2+0x11c>
  88:	cmp	x3, #0x0
  8c:	b.le	b8 <__trunctfhf2+0xb8>
  90:	orr	x2, x2, x1, lsl #26
  94:	cmp	x2, #0x0
  98:	cset	x2, ne  // ne = any
  9c:	orr	x2, x2, x1, lsr #38
  a0:	mov	w0, #0x0                   	// #0
  a4:	tst	x2, #0x7
  a8:	b.eq	208 <__trunctfhf2+0x208>  // b.none
  ac:	cmp	x3, #0x0
  b0:	cset	w6, eq  // eq = none
  b4:	b	11c <__trunctfhf2+0x11c>
  b8:	cmn	x3, #0xa
  bc:	b.lt	27c <__trunctfhf2+0x27c>  // b.tstop
  c0:	orr	x0, x1, #0x8000000000000
  c4:	add	w1, w3, #0x19
  c8:	lsl	x1, x0, x1
  cc:	orr	x2, x1, x2
  d0:	cmp	x2, #0x0
  d4:	cset	x2, ne  // ne = any
  d8:	mov	w1, #0x27                  	// #39
  dc:	sub	w1, w1, w3
  e0:	lsr	x1, x0, x1
  e4:	orr	x2, x1, x2
  e8:	tst	x2, #0x7
  ec:	b.eq	28c <__trunctfhf2+0x28c>  // b.none
  f0:	mov	w0, #0x0                   	// #0
  f4:	mov	w6, #0x1                   	// #1
  f8:	mov	x3, #0x0                   	// #0
  fc:	b	11c <__trunctfhf2+0x11c>
 100:	cbnz	x3, 140 <__trunctfhf2+0x140>
 104:	orr	x1, x1, x2
 108:	cmp	x1, #0x0
 10c:	cset	x2, ne  // ne = any
 110:	mov	w0, #0x0                   	// #0
 114:	mov	w6, #0x1                   	// #1
 118:	cbz	x1, 188 <__trunctfhf2+0x188>
 11c:	orr	w0, w0, #0x10
 120:	and	x1, x5, #0xc00000
 124:	cmp	x1, #0x400, lsl #12
 128:	b.eq	1a8 <__trunctfhf2+0x1a8>  // b.none
 12c:	cmp	x1, #0x800, lsl #12
 130:	b.eq	1b8 <__trunctfhf2+0x1b8>  // b.none
 134:	cbz	x1, 170 <__trunctfhf2+0x170>
 138:	cbnz	w6, 184 <__trunctfhf2+0x184>
 13c:	b	188 <__trunctfhf2+0x188>
 140:	orr	x2, x1, x2
 144:	cbz	x2, 274 <__trunctfhf2+0x274>
 148:	lsr	x0, x1, #50
 14c:	eor	w0, w0, #0x1
 150:	mov	x2, #0x7fff                	// #32767
 154:	cmp	x3, x2
 158:	csel	w0, w0, wzr, eq  // eq = none
 15c:	lsr	x1, x1, #38
 160:	and	x1, x1, #0xfffffffffffffff8
 164:	orr	x2, x1, #0x1000
 168:	mov	x3, #0x1f                  	// #31
 16c:	b	a4 <__trunctfhf2+0xa4>
 170:	and	x7, x2, #0xf
 174:	add	x1, x2, #0x4
 178:	cmp	x7, #0x4
 17c:	csel	x2, x1, x2, ne  // ne = any
 180:	cbz	w6, 188 <__trunctfhf2+0x188>
 184:	orr	w0, w0, #0x8
 188:	tbz	w2, #13, 208 <__trunctfhf2+0x208>
 18c:	add	x3, x3, #0x1
 190:	cmp	x3, #0x1f
 194:	b.eq	1d4 <__trunctfhf2+0x1d4>  // b.none
 198:	mov	x1, #0xfffffffffffffbff    	// #-1025
 19c:	movk	x1, #0x1fff, lsl #48
 1a0:	and	x1, x1, x2, lsr #3
 1a4:	b	21c <__trunctfhf2+0x21c>
 1a8:	add	x1, x2, #0x8
 1ac:	cmp	w4, #0x0
 1b0:	csel	x2, x1, x2, eq  // eq = none
 1b4:	b	180 <__trunctfhf2+0x180>
 1b8:	add	x1, x2, #0x8
 1bc:	cmp	w4, #0x0
 1c0:	csel	x2, x1, x2, ne  // ne = any
 1c4:	b	180 <__trunctfhf2+0x180>
 1c8:	mov	w0, #0x0                   	// #0
 1cc:	mov	x3, #0x0                   	// #0
 1d0:	b	184 <__trunctfhf2+0x184>
 1d4:	ands	x2, x5, #0xc00000
 1d8:	b.eq	200 <__trunctfhf2+0x200>  // b.none
 1dc:	cmp	x2, #0x400, lsl #12
 1e0:	csinc	w1, w4, wzr, eq  // eq = none
 1e4:	cbz	w1, 244 <__trunctfhf2+0x244>
 1e8:	cmp	x2, #0x800, lsl #12
 1ec:	csel	w1, w4, wzr, eq  // eq = none
 1f0:	cmp	w1, #0x0
 1f4:	csetm	x2, eq  // eq = none
 1f8:	mov	x1, #0x1e                  	// #30
 1fc:	csel	x3, x3, x1, ne  // ne = any
 200:	mov	w1, #0x14                  	// #20
 204:	orr	w0, w0, w1
 208:	lsr	x1, x2, #3
 20c:	cmp	x1, #0x0
 210:	orr	x2, x1, #0x200
 214:	ccmp	x3, #0x1f, #0x0, ne  // ne = any
 218:	csel	x1, x2, x1, eq  // eq = none
 21c:	mov	w2, #0x0                   	// #0
 220:	bfxil	w2, w1, #0, #10
 224:	bfi	w2, w3, #10, #5
 228:	bfi	w2, w4, #15, #1
 22c:	sxth	x19, w2
 230:	cbnz	w0, 24c <__trunctfhf2+0x24c>
 234:	dup	v0.4h, w19
 238:	ldr	x19, [sp, #16]
 23c:	ldp	x29, x30, [sp], #48
 240:	ret
 244:	mov	x2, #0x0                   	// #0
 248:	b	200 <__trunctfhf2+0x200>
 24c:	bl	0 <__sfp_handle_exceptions>
 250:	b	234 <__trunctfhf2+0x234>
 254:	mov	w0, #0x14                  	// #20
 258:	mov	x3, #0x1f                  	// #31
 25c:	mov	x2, #0x0                   	// #0
 260:	b	188 <__trunctfhf2+0x188>
 264:	mov	w0, #0x14                  	// #20
 268:	b	258 <__trunctfhf2+0x258>
 26c:	mov	w0, #0x14                  	// #20
 270:	b	258 <__trunctfhf2+0x258>
 274:	mov	w0, #0x0                   	// #0
 278:	b	258 <__trunctfhf2+0x258>
 27c:	mov	x2, #0x1                   	// #1
 280:	mov	x3, #0x0                   	// #0
 284:	mov	w0, #0x0                   	// #0
 288:	b	7c <__trunctfhf2+0x7c>
 28c:	tbnz	w5, #11, 1c8 <__trunctfhf2+0x1c8>
 290:	mov	x3, #0x0                   	// #0
 294:	mov	w0, #0x0                   	// #0
 298:	b	188 <__trunctfhf2+0x188>

fixhfti.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixhfti>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	stp	x19, x20, [sp, #16]
   c:	mrs	x0, fpcr
  10:	umov	w0, v0.h[0]
  14:	mov	w1, #0x0                   	// #0
  18:	bfxil	w1, w0, #0, #16
  1c:	and	x19, x1, #0x3ff
  20:	ubfx	x0, x1, #10, #5
  24:	ubfx	x1, x1, #15, #1
  28:	cmp	x0, #0xe
  2c:	b.gt	58 <__fixhfti+0x58>
  30:	and	x0, x0, #0xff
  34:	orr	x0, x0, x19
  38:	cbnz	x0, 10c <__fixhfti+0x10c>
  3c:	mov	x19, #0x0                   	// #0
  40:	mov	x20, #0x0                   	// #0
  44:	mov	x0, x19
  48:	mov	x1, x20
  4c:	ldp	x19, x20, [sp, #16]
  50:	ldp	x29, x30, [sp], #32
  54:	ret
  58:	mov	x3, x0
  5c:	and	x1, x1, #0xff
  60:	cmp	x0, #0x1e
  64:	b.le	94 <__fixhfti+0x94>
  68:	mov	x0, #0x1                   	// #1
  6c:	sub	x1, x0, x1
  70:	asr	x3, x1, #63
  74:	adrp	x2, 0 <__fixhfti>
  78:	add	x4, x2, #0x0
  7c:	ldr	x19, [x2]
  80:	ldr	x20, [x4, #8]
  84:	subs	x19, x19, x1
  88:	sbc	x20, x20, x3
  8c:	bl	0 <__sfp_handle_exceptions>
  90:	b	44 <__fixhfti+0x44>
  94:	orr	x19, x19, #0x400
  98:	cmp	x0, #0x18
  9c:	b.le	d4 <__fixhfti+0xd4>
  a0:	sub	w4, w0, #0x19
  a4:	subs	w3, w0, #0x59
  a8:	lsl	x20, x19, x3
  ac:	lsr	x0, x19, #1
  b0:	mov	w2, #0x3f                  	// #63
  b4:	sub	w2, w2, w4
  b8:	lsr	x0, x0, x2
  bc:	lsl	x19, x19, x4
  c0:	csel	x20, x20, x0, pl  // pl = nfrst
  c4:	csel	x19, xzr, x19, pl  // pl = nfrst
  c8:	cbz	x1, 44 <__fixhfti+0x44>
  cc:	mov	w2, #0x0                   	// #0
  d0:	b	f8 <__fixhfti+0xf8>
  d4:	add	w0, w0, #0x27
  d8:	lsl	x0, x19, x0
  dc:	cmp	x0, #0x0
  e0:	cset	w2, ne  // ne = any
  e4:	mov	w0, #0x19                  	// #25
  e8:	sub	w3, w0, w3
  ec:	lsr	x19, x19, x3
  f0:	mov	x20, #0x0                   	// #0
  f4:	cbz	x1, 100 <__fixhfti+0x100>
  f8:	negs	x19, x19
  fc:	ngc	x20, x20
 100:	mov	w0, #0x10                  	// #16
 104:	cbnz	w2, 8c <__fixhfti+0x8c>
 108:	b	44 <__fixhfti+0x44>
 10c:	mov	x19, #0x0                   	// #0
 110:	mov	x20, #0x0                   	// #0
 114:	mov	w0, #0x10                  	// #16
 118:	b	8c <__fixhfti+0x8c>

fixunshfti.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunshfti>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	stp	x19, x20, [sp, #16]
   c:	mrs	x0, fpcr
  10:	umov	w1, v0.h[0]
  14:	mov	w0, #0x0                   	// #0
  18:	bfxil	w0, w1, #0, #16
  1c:	and	x2, x0, #0x3ff
  20:	ubfx	x1, x0, #10, #5
  24:	ubfx	x0, x0, #15, #1
  28:	cmp	x1, #0xe
  2c:	b.gt	58 <__fixunshfti+0x58>
  30:	and	x1, x1, #0xff
  34:	orr	x1, x1, x2
  38:	cbnz	x1, d8 <__fixunshfti+0xd8>
  3c:	mov	x20, #0x0                   	// #0
  40:	mov	x19, #0x0                   	// #0
  44:	mov	x0, x20
  48:	mov	x1, x19
  4c:	ldp	x19, x20, [sp, #16]
  50:	ldp	x29, x30, [sp], #32
  54:	ret
  58:	mov	x4, x1
  5c:	ands	x0, x0, #0xff
  60:	ccmp	x1, #0x1e, #0x0, eq  // eq = none
  64:	b.le	7c <__fixunshfti+0x7c>
  68:	sub	x20, x0, #0x1
  6c:	mov	x19, x20
  70:	mov	w0, #0x1                   	// #1
  74:	bl	0 <__sfp_handle_exceptions>
  78:	b	44 <__fixunshfti+0x44>
  7c:	orr	x1, x2, #0x400
  80:	cmp	x4, #0x18
  84:	b.le	b4 <__fixunshfti+0xb4>
  88:	sub	w20, w4, #0x19
  8c:	subs	w4, w4, #0x59
  90:	lsl	x19, x1, x4
  94:	lsr	x0, x1, #1
  98:	mov	w2, #0x3f                  	// #63
  9c:	sub	w2, w2, w20
  a0:	lsr	x0, x0, x2
  a4:	lsl	x20, x1, x20
  a8:	csel	x19, x19, x0, pl  // pl = nfrst
  ac:	csel	x20, xzr, x20, pl  // pl = nfrst
  b0:	b	44 <__fixunshfti+0x44>
  b4:	mov	w20, #0x19                  	// #25
  b8:	sub	w20, w20, w4
  bc:	lsr	x20, x1, x20
  c0:	mov	x19, #0x0                   	// #0
  c4:	add	w4, w4, #0x27
  c8:	lsl	x1, x1, x4
  cc:	cbz	x1, 44 <__fixunshfti+0x44>
  d0:	mov	w0, #0x10                  	// #16
  d4:	b	74 <__fixunshfti+0x74>
  d8:	mov	x20, #0x0                   	// #0
  dc:	mov	x19, #0x0                   	// #0
  e0:	mov	w0, #0x10                  	// #16
  e4:	b	74 <__fixunshfti+0x74>

floattihf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floattihf>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	mrs	x8, fpcr
  10:	orr	x3, x0, x1
  14:	cbz	x3, 268 <__floattihf+0x268>
  18:	mov	x7, x1
  1c:	lsr	x4, x1, #63
  20:	and	w9, w4, #0xff
  24:	tbnz	x1, #63, 70 <__floattihf+0x70>
  28:	cbnz	x7, 7c <__floattihf+0x7c>
  2c:	mov	x3, x0
  30:	clz	x5, x0
  34:	mov	w6, #0x4e                  	// #78
  38:	sub	w5, w6, w5
  3c:	sxtw	x6, w5
  40:	cmp	w5, #0x1e
  44:	b.gt	7c <__floattihf+0x7c>
  48:	cmp	x6, #0x19
  4c:	b.gt	b8 <__floattihf+0xb8>
  50:	mov	x1, #0x19                  	// #25
  54:	sub	x1, x1, x6
  58:	mov	w0, #0x19                  	// #25
  5c:	sub	w5, w0, w5
  60:	lsl	x5, x3, x5
  64:	cmp	x1, #0x0
  68:	csel	x3, x5, x3, gt
  6c:	b	274 <__floattihf+0x274>
  70:	negs	x0, x0
  74:	ngc	x7, x1
  78:	b	28 <__floattihf+0x28>
  7c:	ands	x2, x8, #0xc00000
  80:	b.eq	208 <__floattihf+0x208>  // b.none
  84:	cmp	x2, #0x400, lsl #12
  88:	cset	w3, eq  // eq = none
  8c:	mvn	x0, x1
  90:	lsr	x0, x0, #63
  94:	tst	w3, w0
  98:	b.ne	248 <__floattihf+0x248>  // b.any
  9c:	cmp	x2, #0x800, lsl #12
  a0:	ccmp	w9, #0x0, #0x4, eq  // eq = none
  a4:	b.ne	258 <__floattihf+0x258>  // b.any
  a8:	mov	x2, #0xffffffffffffffff    	// #-1
  ac:	mov	w0, #0x14                  	// #20
  b0:	mov	x6, #0x1e                  	// #30
  b4:	b	158 <__floattihf+0x158>
  b8:	cmp	x6, #0x1c
  bc:	b.le	12c <__floattihf+0x12c>
  c0:	sub	w3, w5, #0x1c
  c4:	subs	w10, w5, #0x5c
  c8:	lsr	x11, x7, x10
  cc:	lsl	x2, x7, #1
  d0:	mov	w4, #0x3f                  	// #63
  d4:	sub	w12, w4, w3
  d8:	lsl	x2, x2, x12
  dc:	lsr	x3, x0, x3
  e0:	orr	x3, x2, x3
  e4:	csel	x3, x11, x3, pl  // pl = nfrst
  e8:	mov	w2, #0x9c                  	// #156
  ec:	sub	w5, w2, w5
  f0:	subs	w2, w5, #0x40
  f4:	lsl	x11, x0, x2
  f8:	lsr	x10, x0, #1
  fc:	sub	w4, w4, w5
 100:	lsr	x4, x10, x4
 104:	lsl	x7, x7, x5
 108:	orr	x7, x4, x7
 10c:	lsl	x0, x0, x5
 110:	csel	x7, x11, x7, pl  // pl = nfrst
 114:	csel	x0, xzr, x0, pl  // pl = nfrst
 118:	orr	x0, x0, x7
 11c:	cmp	x0, #0x0
 120:	cset	x0, ne  // ne = any
 124:	orr	x3, x3, x0
 128:	b	148 <__floattihf+0x148>
 12c:	mov	x0, #0x1c                  	// #28
 130:	sub	x0, x0, x6
 134:	cmp	x0, #0x0
 138:	b.le	148 <__floattihf+0x148>
 13c:	mov	w0, #0x1c                  	// #28
 140:	sub	w5, w0, w5
 144:	lsl	x3, x3, x5
 148:	and	x2, x3, #0xffffffffffffdfff
 14c:	tst	x3, #0x7
 150:	b.eq	2a0 <__floattihf+0x2a0>  // b.none
 154:	mov	w0, #0x0                   	// #0
 158:	orr	w0, w0, #0x10
 15c:	and	x3, x8, #0xc00000
 160:	cmp	x3, #0x400, lsl #12
 164:	b.eq	1a8 <__floattihf+0x1a8>  // b.none
 168:	cmp	x3, #0x800, lsl #12
 16c:	b.eq	1b8 <__floattihf+0x1b8>  // b.none
 170:	cbz	x3, 194 <__floattihf+0x194>
 174:	tbz	w2, #13, 210 <__floattihf+0x210>
 178:	add	x6, x6, #0x1
 17c:	cmp	x6, #0x1f
 180:	b.eq	1c8 <__floattihf+0x1c8>  // b.none
 184:	mov	x1, #0xfffffffffffffbff    	// #-1025
 188:	movk	x1, #0x1fff, lsl #48
 18c:	and	x2, x1, x2, lsr #3
 190:	b	228 <__floattihf+0x228>
 194:	and	x4, x2, #0xf
 198:	add	x3, x2, #0x4
 19c:	cmp	x4, #0x4
 1a0:	csel	x2, x3, x2, ne  // ne = any
 1a4:	b	174 <__floattihf+0x174>
 1a8:	add	x3, x2, #0x8
 1ac:	cmp	x1, #0x0
 1b0:	csel	x2, x3, x2, ge  // ge = tcont
 1b4:	b	174 <__floattihf+0x174>
 1b8:	add	x3, x2, #0x8
 1bc:	cmp	x1, #0x0
 1c0:	csel	x2, x3, x2, lt  // lt = tstop
 1c4:	b	174 <__floattihf+0x174>
 1c8:	ands	x2, x8, #0xc00000
 1cc:	b.eq	1fc <__floattihf+0x1fc>  // b.none
 1d0:	mvn	x0, x1
 1d4:	lsr	x0, x0, #63
 1d8:	cmp	x2, #0x400, lsl #12
 1dc:	cset	w1, eq  // eq = none
 1e0:	tst	w1, w0
 1e4:	b.ne	298 <__floattihf+0x298>  // b.any
 1e8:	cmp	x2, #0x800, lsl #12
 1ec:	ccmp	w9, #0x0, #0x4, eq  // eq = none
 1f0:	csetm	x2, eq  // eq = none
 1f4:	mov	x0, #0x1e                  	// #30
 1f8:	csel	x6, x6, x0, ne  // ne = any
 1fc:	lsr	x2, x2, #3
 200:	mov	w0, #0x14                  	// #20
 204:	b	228 <__floattihf+0x228>
 208:	mov	x6, #0x1f                  	// #31
 20c:	mov	w0, #0x14                  	// #20
 210:	lsr	x2, x2, #3
 214:	cmp	x2, #0x0
 218:	ccmp	x6, #0x1f, #0x0, ne  // ne = any
 21c:	mov	x1, x2
 220:	orr	x2, x2, #0x200
 224:	csel	x2, x2, x1, eq  // eq = none
 228:	mov	w1, #0x0                   	// #0
 22c:	bfxil	w1, w2, #0, #10
 230:	bfi	w1, w6, #10, #5
 234:	bfi	w1, w9, #15, #1
 238:	sxth	x19, w1
 23c:	cbz	w0, 288 <__floattihf+0x288>
 240:	bl	0 <__sfp_handle_exceptions>
 244:	b	288 <__floattihf+0x288>
 248:	mov	x2, #0x0                   	// #0
 24c:	mov	x6, #0x1f                  	// #31
 250:	mov	w0, #0x14                  	// #20
 254:	b	210 <__floattihf+0x210>
 258:	mov	x2, #0x0                   	// #0
 25c:	mov	x6, #0x1f                  	// #31
 260:	mov	w0, #0x14                  	// #20
 264:	b	210 <__floattihf+0x210>
 268:	mov	x3, #0x0                   	// #0
 26c:	mov	x6, #0x0                   	// #0
 270:	mov	x4, #0x0                   	// #0
 274:	mov	w1, #0x0                   	// #0
 278:	bfxil	w1, w3, #0, #10
 27c:	bfi	w1, w6, #10, #5
 280:	bfi	w1, w4, #15, #1
 284:	sxth	x19, w1
 288:	dup	v0.4h, w19
 28c:	ldr	x19, [sp, #16]
 290:	ldp	x29, x30, [sp], #32
 294:	ret
 298:	mov	x2, #0x0                   	// #0
 29c:	b	1fc <__floattihf+0x1fc>
 2a0:	lsr	x2, x2, #3
 2a4:	mov	w0, #0x0                   	// #0
 2a8:	b	228 <__floattihf+0x228>

floatuntihf.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatuntihf>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	mov	x29, sp
   8:	str	x19, [sp, #16]
   c:	mrs	x6, fpcr
  10:	orr	x2, x0, x1
  14:	cbz	x2, 1b0 <__floatuntihf+0x1b0>
  18:	cbnz	x1, 60 <__floatuntihf+0x60>
  1c:	mov	x2, x0
  20:	clz	x4, x0
  24:	mov	w3, #0x4e                  	// #78
  28:	sub	w4, w3, w4
  2c:	sxtw	x5, w4
  30:	cmp	w4, #0x1e
  34:	b.gt	60 <__floatuntihf+0x60>
  38:	cmp	x5, #0x19
  3c:	b.gt	a0 <__floatuntihf+0xa0>
  40:	mov	x3, #0x19                  	// #25
  44:	sub	x3, x3, x5
  48:	mov	w1, #0x19                  	// #25
  4c:	sub	w4, w1, w4
  50:	lsl	x0, x0, x4
  54:	cmp	x3, #0x0
  58:	csel	x2, x0, x2, gt
  5c:	b	1b8 <__floatuntihf+0x1b8>
  60:	mov	x5, #0x1f                  	// #31
  64:	mov	w0, #0x14                  	// #20
  68:	and	x1, x6, #0x800000
  6c:	tbnz	w6, #23, 1f0 <__floatuntihf+0x1f0>
  70:	lsr	x2, x1, #3
  74:	cmp	x2, #0x0
  78:	ccmp	x5, #0x1f, #0x0, ne  // ne = any
  7c:	orr	x1, x2, #0x200
  80:	csel	x2, x1, x2, eq  // eq = none
  84:	mov	w1, #0x0                   	// #0
  88:	bfxil	w1, w2, #0, #10
  8c:	bfi	w1, w5, #10, #5
  90:	and	x19, x1, #0x7fff
  94:	cbz	w0, 1c8 <__floatuntihf+0x1c8>
  98:	bl	0 <__sfp_handle_exceptions>
  9c:	b	1c8 <__floatuntihf+0x1c8>
  a0:	cmp	x5, #0x1c
  a4:	b.le	114 <__floatuntihf+0x114>
  a8:	mov	w2, #0x9c                  	// #156
  ac:	sub	w2, w2, w4
  b0:	subs	w7, w2, #0x40
  b4:	lsl	x10, x0, x7
  b8:	lsr	x9, x0, #1
  bc:	mov	w8, #0x3f                  	// #63
  c0:	sub	w3, w8, w2
  c4:	lsr	x9, x9, x3
  c8:	lsl	x3, x1, x2
  cc:	orr	x3, x9, x3
  d0:	lsl	x2, x0, x2
  d4:	csel	x3, x10, x3, pl  // pl = nfrst
  d8:	csel	x2, xzr, x2, pl  // pl = nfrst
  dc:	orr	x2, x2, x3
  e0:	cmp	x2, #0x0
  e4:	cset	x3, ne  // ne = any
  e8:	sub	w7, w4, #0x1c
  ec:	subs	w2, w4, #0x5c
  f0:	lsr	x4, x1, x2
  f4:	lsl	x1, x1, #1
  f8:	sub	w8, w8, w7
  fc:	lsl	x1, x1, x8
 100:	lsr	x0, x0, x7
 104:	orr	x0, x1, x0
 108:	csel	x0, x4, x0, pl  // pl = nfrst
 10c:	orr	x2, x3, x0
 110:	b	130 <__floatuntihf+0x130>
 114:	mov	x1, #0x1c                  	// #28
 118:	sub	x1, x1, x5
 11c:	cmp	x1, #0x0
 120:	b.le	130 <__floatuntihf+0x130>
 124:	mov	w2, #0x1c                  	// #28
 128:	sub	w2, w2, w4
 12c:	lsl	x2, x0, x2
 130:	and	x1, x2, #0xffffffffffffdfff
 134:	tst	x2, #0x7
 138:	b.eq	1e4 <__floatuntihf+0x1e4>  // b.none
 13c:	ands	x3, x6, #0xc00000
 140:	b.eq	174 <__floatuntihf+0x174>  // b.none
 144:	mov	w0, #0x10                  	// #16
 148:	add	x2, x1, #0x8
 14c:	cmp	x3, #0x400, lsl #12
 150:	csel	x1, x2, x1, eq  // eq = none
 154:	tbz	w1, #13, 70 <__floatuntihf+0x70>
 158:	add	x5, x5, #0x1
 15c:	cmp	x5, #0x1f
 160:	b.eq	19c <__floatuntihf+0x19c>  // b.none
 164:	mov	x2, #0xfffffffffffffbff    	// #-1025
 168:	movk	x2, #0x1fff, lsl #48
 16c:	and	x2, x2, x1, lsr #3
 170:	b	84 <__floatuntihf+0x84>
 174:	and	x2, x2, #0xf
 178:	mov	w0, #0x10                  	// #16
 17c:	cmp	x2, #0x4
 180:	b.eq	154 <__floatuntihf+0x154>  // b.none
 184:	b	194 <__floatuntihf+0x194>
 188:	mov	x1, #0xffffffffffffffff    	// #-1
 18c:	mov	x5, #0x1e                  	// #30
 190:	mov	w0, #0x14                  	// #20
 194:	add	x1, x1, #0x4
 198:	b	154 <__floatuntihf+0x154>
 19c:	and	x1, x6, #0x800000
 1a0:	tbnz	w6, #23, 1d8 <__floatuntihf+0x1d8>
 1a4:	lsr	x2, x1, #3
 1a8:	mov	w0, #0x14                  	// #20
 1ac:	b	84 <__floatuntihf+0x84>
 1b0:	mov	x2, #0x0                   	// #0
 1b4:	mov	x5, #0x0                   	// #0
 1b8:	mov	w1, #0x0                   	// #0
 1bc:	bfxil	w1, w2, #0, #10
 1c0:	bfi	w1, w5, #10, #5
 1c4:	and	x19, x1, #0x7fff
 1c8:	dup	v0.4h, w19
 1cc:	ldr	x19, [sp, #16]
 1d0:	ldp	x29, x30, [sp], #32
 1d4:	ret
 1d8:	mov	x1, #0xffffffffffffffff    	// #-1
 1dc:	mov	x5, #0x1e                  	// #30
 1e0:	b	1a4 <__floatuntihf+0x1a4>
 1e4:	lsr	x2, x1, #3
 1e8:	mov	w0, #0x0                   	// #0
 1ec:	b	84 <__floatuntihf+0x84>
 1f0:	ands	x3, x6, #0xc00000
 1f4:	b.eq	188 <__floatuntihf+0x188>  // b.none
 1f8:	mov	x1, #0xffffffffffffffff    	// #-1
 1fc:	mov	x5, #0x1e                  	// #30
 200:	mov	w0, #0x14                  	// #20
 204:	b	148 <__floatuntihf+0x148>

enable-execute-stack.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__enable_execute_stack>:
   0:	ret
