
/home/anony/Documents/anonymous--anonymous/pizzolotto-binaries//libgmp.so.10.4.0_clang_-Os:     file format elf64-littleaarch64


Disassembly of section .init:

000000000000bea8 <.init>:
    bea8:	stp	x29, x30, [sp, #-16]!
    beac:	mov	x29, sp
    beb0:	bl	d500 <__gmpn_cnd_add_n@plt+0x10>
    beb4:	ldp	x29, x30, [sp], #16
    beb8:	ret

Disassembly of section .plt:

000000000000bec0 <memcpy@plt-0x20>:
    bec0:	stp	x16, x30, [sp, #-16]!
    bec4:	adrp	x16, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    bec8:	ldr	x17, [x16, #4088]
    becc:	add	x16, x16, #0xff8
    bed0:	br	x17
    bed4:	nop
    bed8:	nop
    bedc:	nop

000000000000bee0 <memcpy@plt>:
    bee0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bee4:	ldr	x17, [x16]
    bee8:	add	x16, x16, #0x0
    beec:	br	x17

000000000000bef0 <__gmpz_tdiv_r_2exp@plt>:
    bef0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bef4:	ldr	x17, [x16, #8]
    bef8:	add	x16, x16, #0x8
    befc:	br	x17

000000000000bf00 <__gmp_tmp_reentrant_free@plt>:
    bf00:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bf04:	ldr	x17, [x16, #16]
    bf08:	add	x16, x16, #0x10
    bf0c:	br	x17

000000000000bf10 <__gmpn_tdiv_qr@plt>:
    bf10:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bf14:	ldr	x17, [x16, #24]
    bf18:	add	x16, x16, #0x18
    bf1c:	br	x17

000000000000bf20 <__gmpq_cmp_ui@plt>:
    bf20:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bf24:	ldr	x17, [x16, #32]
    bf28:	add	x16, x16, #0x20
    bf2c:	br	x17

000000000000bf30 <__gmpz_scan1@plt>:
    bf30:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bf34:	ldr	x17, [x16, #40]
    bf38:	add	x16, x16, #0x28
    bf3c:	br	x17

000000000000bf40 <__gmp_randinit_mt_noseed@plt>:
    bf40:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bf44:	ldr	x17, [x16, #48]
    bf48:	add	x16, x16, #0x30
    bf4c:	br	x17

000000000000bf50 <__gmpn_get_d@plt>:
    bf50:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bf54:	ldr	x17, [x16, #56]
    bf58:	add	x16, x16, #0x38
    bf5c:	br	x17

000000000000bf60 <__gmpn_sqrmod_bnm1@plt>:
    bf60:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bf64:	ldr	x17, [x16, #64]
    bf68:	add	x16, x16, #0x40
    bf6c:	br	x17

000000000000bf70 <strlen@plt>:
    bf70:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bf74:	ldr	x17, [x16, #72]
    bf78:	add	x16, x16, #0x48
    bf7c:	br	x17

000000000000bf80 <__gmpf_add@plt>:
    bf80:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bf84:	ldr	x17, [x16, #80]
    bf88:	add	x16, x16, #0x50
    bf8c:	br	x17

000000000000bf90 <__gmpz_init_set@plt>:
    bf90:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bf94:	ldr	x17, [x16, #88]
    bf98:	add	x16, x16, #0x58
    bf9c:	br	x17

000000000000bfa0 <__gmpn_gcd_1@plt>:
    bfa0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bfa4:	ldr	x17, [x16, #96]
    bfa8:	add	x16, x16, #0x60
    bfac:	br	x17

000000000000bfb0 <__gmpz_tdiv_ui@plt>:
    bfb0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bfb4:	ldr	x17, [x16, #104]
    bfb8:	add	x16, x16, #0x68
    bfbc:	br	x17

000000000000bfc0 <__gmpn_toom_interpolate_12pts@plt>:
    bfc0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bfc4:	ldr	x17, [x16, #112]
    bfc8:	add	x16, x16, #0x70
    bfcc:	br	x17

000000000000bfd0 <raise@plt>:
    bfd0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bfd4:	ldr	x17, [x16, #120]
    bfd8:	add	x16, x16, #0x78
    bfdc:	br	x17

000000000000bfe0 <__gmp_divide_by_zero@plt>:
    bfe0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bfe4:	ldr	x17, [x16, #128]
    bfe8:	add	x16, x16, #0x80
    bfec:	br	x17

000000000000bff0 <__gmpq_set_str@plt>:
    bff0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    bff4:	ldr	x17, [x16, #136]
    bff8:	add	x16, x16, #0x88
    bffc:	br	x17

000000000000c000 <__gmpz_tdiv_qr@plt>:
    c000:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c004:	ldr	x17, [x16, #144]
    c008:	add	x16, x16, #0x90
    c00c:	br	x17

000000000000c010 <__gmpn_copyd@plt>:
    c010:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c014:	ldr	x17, [x16, #152]
    c018:	add	x16, x16, #0x98
    c01c:	br	x17

000000000000c020 <__gmpn_matrix22_mul@plt>:
    c020:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c024:	ldr	x17, [x16, #160]
    c028:	add	x16, x16, #0xa0
    c02c:	br	x17

000000000000c030 <__gmpn_cnd_sub_n@plt>:
    c030:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c034:	ldr	x17, [x16, #168]
    c038:	add	x16, x16, #0xa8
    c03c:	br	x17

000000000000c040 <__gmpn_gcd_22@plt>:
    c040:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c044:	ldr	x17, [x16, #176]
    c048:	add	x16, x16, #0xb0
    c04c:	br	x17

000000000000c050 <__gmpz_tdiv_q@plt>:
    c050:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c054:	ldr	x17, [x16, #184]
    c058:	add	x16, x16, #0xb8
    c05c:	br	x17

000000000000c060 <__gmpn_toom2_sqr@plt>:
    c060:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c064:	ldr	x17, [x16, #192]
    c068:	add	x16, x16, #0xc0
    c06c:	br	x17

000000000000c070 <__gmpn_andn_n@plt>:
    c070:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c074:	ldr	x17, [x16, #200]
    c078:	add	x16, x16, #0xc8
    c07c:	br	x17

000000000000c080 <__gmpz_jacobi@plt>:
    c080:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c084:	ldr	x17, [x16, #208]
    c088:	add	x16, x16, #0xd0
    c08c:	br	x17

000000000000c090 <__gmpz_realloc@plt>:
    c090:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c094:	ldr	x17, [x16, #216]
    c098:	add	x16, x16, #0xd8
    c09c:	br	x17

000000000000c0a0 <__gmpn_set_str@plt>:
    c0a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c0a4:	ldr	x17, [x16, #224]
    c0a8:	add	x16, x16, #0xe0
    c0ac:	br	x17

000000000000c0b0 <__gmpn_toom33_mul@plt>:
    c0b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c0b4:	ldr	x17, [x16, #232]
    c0b8:	add	x16, x16, #0xe8
    c0bc:	br	x17

000000000000c0c0 <__gmpn_sqrlo_basecase@plt>:
    c0c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c0c4:	ldr	x17, [x16, #240]
    c0c8:	add	x16, x16, #0xf0
    c0cc:	br	x17

000000000000c0d0 <__gmpz_gcdext@plt>:
    c0d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c0d4:	ldr	x17, [x16, #248]
    c0d8:	add	x16, x16, #0xf8
    c0dc:	br	x17

000000000000c0e0 <__gmpz_set_str@plt>:
    c0e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c0e4:	ldr	x17, [x16, #256]
    c0e8:	add	x16, x16, #0x100
    c0ec:	br	x17

000000000000c0f0 <__gmpn_mu_divappr_q_itch@plt>:
    c0f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c0f4:	ldr	x17, [x16, #264]
    c0f8:	add	x16, x16, #0x108
    c0fc:	br	x17

000000000000c100 <__gmp_doscan@plt>:
    c100:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c104:	ldr	x17, [x16, #272]
    c108:	add	x16, x16, #0x110
    c10c:	br	x17

000000000000c110 <__gmpz_cmpabs_ui@plt>:
    c110:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c114:	ldr	x17, [x16, #280]
    c118:	add	x16, x16, #0x118
    c11c:	br	x17

000000000000c120 <__gmpn_bc_set_str@plt>:
    c120:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c124:	ldr	x17, [x16, #288]
    c128:	add	x16, x16, #0x120
    c12c:	br	x17

000000000000c130 <__gmpz_sub_ui@plt>:
    c130:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c134:	ldr	x17, [x16, #296]
    c138:	add	x16, x16, #0x128
    c13c:	br	x17

000000000000c140 <__gmpq_get_str@plt>:
    c140:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c144:	ldr	x17, [x16, #304]
    c148:	add	x16, x16, #0x130
    c14c:	br	x17

000000000000c150 <__gmpn_sec_div_r@plt>:
    c150:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c154:	ldr	x17, [x16, #312]
    c158:	add	x16, x16, #0x138
    c15c:	br	x17

000000000000c160 <__gmpf_set@plt>:
    c160:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c164:	ldr	x17, [x16, #320]
    c168:	add	x16, x16, #0x140
    c16c:	br	x17

000000000000c170 <__gmpn_sublsh2_n@plt>:
    c170:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c174:	ldr	x17, [x16, #328]
    c178:	add	x16, x16, #0x148
    c17c:	br	x17

000000000000c180 <__gmpz_set_ui@plt>:
    c180:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c184:	ldr	x17, [x16, #336]
    c188:	add	x16, x16, #0x150
    c18c:	br	x17

000000000000c190 <__gmpn_lshift@plt>:
    c190:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c194:	ldr	x17, [x16, #344]
    c198:	add	x16, x16, #0x158
    c19c:	br	x17

000000000000c1a0 <__gmpn_sqr_basecase@plt>:
    c1a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c1a4:	ldr	x17, [x16, #352]
    c1a8:	add	x16, x16, #0x160
    c1ac:	br	x17

000000000000c1b0 <__gmpn_rshift@plt>:
    c1b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c1b4:	ldr	x17, [x16, #360]
    c1b8:	add	x16, x16, #0x168
    c1bc:	br	x17

000000000000c1c0 <__gmp_invalid_operation@plt>:
    c1c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c1c4:	ldr	x17, [x16, #368]
    c1c8:	add	x16, x16, #0x170
    c1cc:	br	x17

000000000000c1d0 <__gmpf_set_str@plt>:
    c1d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c1d4:	ldr	x17, [x16, #376]
    c1d8:	add	x16, x16, #0x178
    c1dc:	br	x17

000000000000c1e0 <__cxa_finalize@plt>:
    c1e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c1e4:	ldr	x17, [x16, #384]
    c1e8:	add	x16, x16, #0x180
    c1ec:	br	x17

000000000000c1f0 <putc@plt>:
    c1f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c1f4:	ldr	x17, [x16, #392]
    c1f8:	add	x16, x16, #0x188
    c1fc:	br	x17

000000000000c200 <__gmpf_sub_ui@plt>:
    c200:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c204:	ldr	x17, [x16, #400]
    c208:	add	x16, x16, #0x190
    c20c:	br	x17

000000000000c210 <__gmpn_divrem_2@plt>:
    c210:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c214:	ldr	x17, [x16, #408]
    c218:	add	x16, x16, #0x198
    c21c:	br	x17

000000000000c220 <fputc@plt>:
    c220:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c224:	ldr	x17, [x16, #416]
    c228:	add	x16, x16, #0x1a0
    c22c:	br	x17

000000000000c230 <__gmpn_toom4_sqr@plt>:
    c230:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c234:	ldr	x17, [x16, #424]
    c238:	add	x16, x16, #0x1a8
    c23c:	br	x17

000000000000c240 <__gmpn_sec_powm_itch@plt>:
    c240:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c244:	ldr	x17, [x16, #432]
    c248:	add	x16, x16, #0x1b0
    c24c:	br	x17

000000000000c250 <__gmpn_perfect_power_p@plt>:
    c250:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c254:	ldr	x17, [x16, #440]
    c258:	add	x16, x16, #0x1b8
    c25c:	br	x17

000000000000c260 <__gmpn_mod_1_1p@plt>:
    c260:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c264:	ldr	x17, [x16, #448]
    c268:	add	x16, x16, #0x1c0
    c26c:	br	x17

000000000000c270 <__gmpz_sub@plt>:
    c270:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c274:	ldr	x17, [x16, #456]
    c278:	add	x16, x16, #0x1c8
    c27c:	br	x17

000000000000c280 <__gmpn_and_n@plt>:
    c280:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c284:	ldr	x17, [x16, #464]
    c288:	add	x16, x16, #0x1d0
    c28c:	br	x17

000000000000c290 <__gmpn_toom_eval_dgr3_pm1@plt>:
    c290:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c294:	ldr	x17, [x16, #472]
    c298:	add	x16, x16, #0x1d8
    c29c:	br	x17

000000000000c2a0 <__gmpn_com@plt>:
    c2a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c2a4:	ldr	x17, [x16, #480]
    c2a8:	add	x16, x16, #0x1e0
    c2ac:	br	x17

000000000000c2b0 <__gmpn_rootrem@plt>:
    c2b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c2b4:	ldr	x17, [x16, #488]
    c2b8:	add	x16, x16, #0x1e8
    c2bc:	br	x17

000000000000c2c0 <__gmpn_hgcd_step@plt>:
    c2c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c2c4:	ldr	x17, [x16, #496]
    c2c8:	add	x16, x16, #0x1f0
    c2cc:	br	x17

000000000000c2d0 <__gmpn_bdiv_dbm1c@plt>:
    c2d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c2d4:	ldr	x17, [x16, #504]
    c2d8:	add	x16, x16, #0x1f8
    c2dc:	br	x17

000000000000c2e0 <__gmpn_sub_n@plt>:
    c2e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c2e4:	ldr	x17, [x16, #512]
    c2e8:	add	x16, x16, #0x200
    c2ec:	br	x17

000000000000c2f0 <__gmpn_mu_div_q@plt>:
    c2f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c2f4:	ldr	x17, [x16, #520]
    c2f8:	add	x16, x16, #0x208
    c2fc:	br	x17

000000000000c300 <snprintf@plt>:
    c300:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c304:	ldr	x17, [x16, #528]
    c308:	add	x16, x16, #0x210
    c30c:	br	x17

000000000000c310 <__gmpn_bc_mulmod_bnm1@plt>:
    c310:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c314:	ldr	x17, [x16, #536]
    c318:	add	x16, x16, #0x218
    c31c:	br	x17

000000000000c320 <__gmpn_mul_fft@plt>:
    c320:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c324:	ldr	x17, [x16, #544]
    c328:	add	x16, x16, #0x220
    c32c:	br	x17

000000000000c330 <__gmpz_setbit@plt>:
    c330:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c334:	ldr	x17, [x16, #552]
    c338:	add	x16, x16, #0x228
    c33c:	br	x17

000000000000c340 <__gmpn_div_q@plt>:
    c340:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c344:	ldr	x17, [x16, #560]
    c348:	add	x16, x16, #0x230
    c34c:	br	x17

000000000000c350 <__gmpf_clear@plt>:
    c350:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c354:	ldr	x17, [x16, #568]
    c358:	add	x16, x16, #0x238
    c35c:	br	x17

000000000000c360 <__gmpz_n_pow_ui@plt>:
    c360:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c364:	ldr	x17, [x16, #576]
    c368:	add	x16, x16, #0x240
    c36c:	br	x17

000000000000c370 <__gmpf_get_prec@plt>:
    c370:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c374:	ldr	x17, [x16, #584]
    c378:	add	x16, x16, #0x248
    c37c:	br	x17

000000000000c380 <__gmpn_dc_set_str@plt>:
    c380:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c384:	ldr	x17, [x16, #592]
    c388:	add	x16, x16, #0x250
    c38c:	br	x17

000000000000c390 <__gmpz_powm@plt>:
    c390:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c394:	ldr	x17, [x16, #600]
    c398:	add	x16, x16, #0x258
    c39c:	br	x17

000000000000c3a0 <__gmpn_sec_add_1@plt>:
    c3a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c3a4:	ldr	x17, [x16, #608]
    c3a8:	add	x16, x16, #0x260
    c3ac:	br	x17

000000000000c3b0 <__gmpn_toom_eval_pm2exp@plt>:
    c3b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c3b4:	ldr	x17, [x16, #616]
    c3b8:	add	x16, x16, #0x268
    c3bc:	br	x17

000000000000c3c0 <__gmpz_get_str@plt>:
    c3c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c3c4:	ldr	x17, [x16, #624]
    c3c8:	add	x16, x16, #0x270
    c3cc:	br	x17

000000000000c3d0 <__gmpn_dcpi1_div_qr@plt>:
    c3d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c3d4:	ldr	x17, [x16, #632]
    c3d8:	add	x16, x16, #0x278
    c3dc:	br	x17

000000000000c3e0 <__gmpn_powlo@plt>:
    c3e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c3e4:	ldr	x17, [x16, #640]
    c3e8:	add	x16, x16, #0x280
    c3ec:	br	x17

000000000000c3f0 <__gmpz_oddfac_1@plt>:
    c3f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c3f4:	ldr	x17, [x16, #648]
    c3f8:	add	x16, x16, #0x288
    c3fc:	br	x17

000000000000c400 <__gmpn_mod_1@plt>:
    c400:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c404:	ldr	x17, [x16, #656]
    c408:	add	x16, x16, #0x290
    c40c:	br	x17

000000000000c410 <__gmpz_divexact@plt>:
    c410:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c414:	ldr	x17, [x16, #664]
    c418:	add	x16, x16, #0x298
    c41c:	br	x17

000000000000c420 <nl_langinfo@plt>:
    c420:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c424:	ldr	x17, [x16, #672]
    c428:	add	x16, x16, #0x2a0
    c42c:	br	x17

000000000000c430 <malloc@plt>:
    c430:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c434:	ldr	x17, [x16, #680]
    c438:	add	x16, x16, #0x2a8
    c43c:	br	x17

000000000000c440 <__gmpz_set@plt>:
    c440:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c444:	ldr	x17, [x16, #688]
    c448:	add	x16, x16, #0x2b0
    c44c:	br	x17

000000000000c450 <__gmpn_divexact@plt>:
    c450:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c454:	ldr	x17, [x16, #696]
    c458:	add	x16, x16, #0x2b8
    c45c:	br	x17

000000000000c460 <__gmpn_sublsh1_n@plt>:
    c460:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c464:	ldr	x17, [x16, #704]
    c468:	add	x16, x16, #0x2c0
    c46c:	br	x17

000000000000c470 <__gmpz_fac_ui@plt>:
    c470:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c474:	ldr	x17, [x16, #712]
    c478:	add	x16, x16, #0x2c8
    c47c:	br	x17

000000000000c480 <__gmpn_mulmid_basecase@plt>:
    c480:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c484:	ldr	x17, [x16, #720]
    c488:	add	x16, x16, #0x2d0
    c48c:	br	x17

000000000000c490 <__gmpn_div_qr_1n_pi1@plt>:
    c490:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c494:	ldr	x17, [x16, #728]
    c498:	add	x16, x16, #0x2d8
    c49c:	br	x17

000000000000c4a0 <__gmpz_tstbit@plt>:
    c4a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c4a4:	ldr	x17, [x16, #736]
    c4a8:	add	x16, x16, #0x2e0
    c4ac:	br	x17

000000000000c4b0 <__gmp_randclear@plt>:
    c4b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c4b4:	ldr	x17, [x16, #744]
    c4b8:	add	x16, x16, #0x2e8
    c4bc:	br	x17

000000000000c4c0 <__gmpf_set_d@plt>:
    c4c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c4c4:	ldr	x17, [x16, #752]
    c4c8:	add	x16, x16, #0x2f0
    c4cc:	br	x17

000000000000c4d0 <__gmpz_mul@plt>:
    c4d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c4d4:	ldr	x17, [x16, #760]
    c4d8:	add	x16, x16, #0x2f8
    c4dc:	br	x17

000000000000c4e0 <__gmpn_sec_tabselect@plt>:
    c4e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c4e4:	ldr	x17, [x16, #768]
    c4e8:	add	x16, x16, #0x300
    c4ec:	br	x17

000000000000c4f0 <__gmpn_dcpi1_divappr_q@plt>:
    c4f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c4f4:	ldr	x17, [x16, #776]
    c4f8:	add	x16, x16, #0x308
    c4fc:	br	x17

000000000000c500 <__gmpn_pi1_bdiv_q_1@plt>:
    c500:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c504:	ldr	x17, [x16, #784]
    c508:	add	x16, x16, #0x310
    c50c:	br	x17

000000000000c510 <__gmpn_matrix22_mul1_inverse_vector@plt>:
    c510:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c514:	ldr	x17, [x16, #792]
    c518:	add	x16, x16, #0x318
    c51c:	br	x17

000000000000c520 <__gmp_vasprintf@plt>:
    c520:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c524:	ldr	x17, [x16, #800]
    c528:	add	x16, x16, #0x320
    c52c:	br	x17

000000000000c530 <__gmpn_sbpi1_bdiv_q@plt>:
    c530:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c534:	ldr	x17, [x16, #808]
    c538:	add	x16, x16, #0x328
    c53c:	br	x17

000000000000c540 <__gmpz_lucas_mod@plt>:
    c540:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c544:	ldr	x17, [x16, #816]
    c548:	add	x16, x16, #0x330
    c54c:	br	x17

000000000000c550 <__gmpn_toom_eval_pm2@plt>:
    c550:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c554:	ldr	x17, [x16, #824]
    c558:	add	x16, x16, #0x338
    c55c:	br	x17

000000000000c560 <__gmpz_out_str@plt>:
    c560:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c564:	ldr	x17, [x16, #832]
    c568:	add	x16, x16, #0x340
    c56c:	br	x17

000000000000c570 <__gmpn_mul_basecase@plt>:
    c570:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c574:	ldr	x17, [x16, #840]
    c578:	add	x16, x16, #0x348
    c57c:	br	x17

000000000000c580 <__gmpn_gcdext@plt>:
    c580:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c584:	ldr	x17, [x16, #848]
    c588:	add	x16, x16, #0x350
    c58c:	br	x17

000000000000c590 <__isoc99_fscanf@plt>:
    c590:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c594:	ldr	x17, [x16, #856]
    c598:	add	x16, x16, #0x358
    c59c:	br	x17

000000000000c5a0 <__gmpz_swap@plt>:
    c5a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c5a4:	ldr	x17, [x16, #864]
    c5a8:	add	x16, x16, #0x360
    c5ac:	br	x17

000000000000c5b0 <__gmpn_hgcd_itch@plt>:
    c5b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c5b4:	ldr	x17, [x16, #872]
    c5b8:	add	x16, x16, #0x368
    c5bc:	br	x17

000000000000c5c0 <__gmpn_hgcd2@plt>:
    c5c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c5c4:	ldr	x17, [x16, #880]
    c5c8:	add	x16, x16, #0x370
    c5cc:	br	x17

000000000000c5d0 <fgetc@plt>:
    c5d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c5d4:	ldr	x17, [x16, #888]
    c5d8:	add	x16, x16, #0x378
    c5dc:	br	x17

000000000000c5e0 <__gmpz_mul_ui@plt>:
    c5e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c5e4:	ldr	x17, [x16, #896]
    c5e8:	add	x16, x16, #0x380
    c5ec:	br	x17

000000000000c5f0 <__gmpn_sqrmod_bnm1_next_size@plt>:
    c5f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c5f4:	ldr	x17, [x16, #904]
    c5f8:	add	x16, x16, #0x388
    c5fc:	br	x17

000000000000c600 <__gmpn_dcpi1_bdiv_qr@plt>:
    c600:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c604:	ldr	x17, [x16, #912]
    c608:	add	x16, x16, #0x390
    c60c:	br	x17

000000000000c610 <memset@plt>:
    c610:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c614:	ldr	x17, [x16, #920]
    c618:	add	x16, x16, #0x398
    c61c:	br	x17

000000000000c620 <__gmpz_2fac_ui@plt>:
    c620:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c624:	ldr	x17, [x16, #928]
    c628:	add	x16, x16, #0x3a0
    c62c:	br	x17

000000000000c630 <__gmpn_trialdiv@plt>:
    c630:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c634:	ldr	x17, [x16, #936]
    c638:	add	x16, x16, #0x3a8
    c63c:	br	x17

000000000000c640 <__gmpf_set_si@plt>:
    c640:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c644:	ldr	x17, [x16, #944]
    c648:	add	x16, x16, #0x3b0
    c64c:	br	x17

000000000000c650 <__gmpn_add_err2_n@plt>:
    c650:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c654:	ldr	x17, [x16, #952]
    c658:	add	x16, x16, #0x3b8
    c65c:	br	x17

000000000000c660 <__gmpn_sbpi1_div_qr@plt>:
    c660:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c664:	ldr	x17, [x16, #960]
    c668:	add	x16, x16, #0x3c0
    c66c:	br	x17

000000000000c670 <__gmpz_fdiv_q_2exp@plt>:
    c670:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c674:	ldr	x17, [x16, #968]
    c678:	add	x16, x16, #0x3c8
    c67c:	br	x17

000000000000c680 <__gmpn_cnd_swap@plt>:
    c680:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c684:	ldr	x17, [x16, #976]
    c688:	add	x16, x16, #0x3d0
    c68c:	br	x17

000000000000c690 <__gmpf_cmp@plt>:
    c690:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c694:	ldr	x17, [x16, #984]
    c698:	add	x16, x16, #0x3d8
    c69c:	br	x17

000000000000c6a0 <__gmpn_mod_1s_4p_cps@plt>:
    c6a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c6a4:	ldr	x17, [x16, #992]
    c6a8:	add	x16, x16, #0x3e0
    c6ac:	br	x17

000000000000c6b0 <__gmpn_scan0@plt>:
    c6b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c6b4:	ldr	x17, [x16, #1000]
    c6b8:	add	x16, x16, #0x3e8
    c6bc:	br	x17

000000000000c6c0 <__gmpf_set_ui@plt>:
    c6c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c6c4:	ldr	x17, [x16, #1008]
    c6c8:	add	x16, x16, #0x3f0
    c6cc:	br	x17

000000000000c6d0 <__gmpn_brootinv@plt>:
    c6d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c6d4:	ldr	x17, [x16, #1016]
    c6d8:	add	x16, x16, #0x3f8
    c6dc:	br	x17

000000000000c6e0 <__gmp_assert_fail@plt>:
    c6e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c6e4:	ldr	x17, [x16, #1024]
    c6e8:	add	x16, x16, #0x400
    c6ec:	br	x17

000000000000c6f0 <__gmpn_preinv_mod_1@plt>:
    c6f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c6f4:	ldr	x17, [x16, #1032]
    c6f8:	add	x16, x16, #0x408
    c6fc:	br	x17

000000000000c700 <__gmpz_mul_2exp@plt>:
    c700:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c704:	ldr	x17, [x16, #1040]
    c708:	add	x16, x16, #0x410
    c70c:	br	x17

000000000000c710 <__gmpn_sbpi1_divappr_q@plt>:
    c710:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c714:	ldr	x17, [x16, #1048]
    c718:	add	x16, x16, #0x418
    c71c:	br	x17

000000000000c720 <__gmpn_mulmid@plt>:
    c720:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c724:	ldr	x17, [x16, #1056]
    c728:	add	x16, x16, #0x420
    c72c:	br	x17

000000000000c730 <__gmpn_mu_divappr_q@plt>:
    c730:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c734:	ldr	x17, [x16, #1064]
    c738:	add	x16, x16, #0x428
    c73c:	br	x17

000000000000c740 <__gmpn_toom44_mul@plt>:
    c740:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c744:	ldr	x17, [x16, #1072]
    c748:	add	x16, x16, #0x430
    c74c:	br	x17

000000000000c750 <__gmpn_jacobi_base@plt>:
    c750:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c754:	ldr	x17, [x16, #1080]
    c758:	add	x16, x16, #0x438
    c75c:	br	x17

000000000000c760 <__gmpn_toom63_mul@plt>:
    c760:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c764:	ldr	x17, [x16, #1088]
    c768:	add	x16, x16, #0x440
    c76c:	br	x17

000000000000c770 <__gmpn_bsqrtinv@plt>:
    c770:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c774:	ldr	x17, [x16, #1096]
    c778:	add	x16, x16, #0x448
    c77c:	br	x17

000000000000c780 <__gmpn_sub_nc@plt>:
    c780:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c784:	ldr	x17, [x16, #1104]
    c788:	add	x16, x16, #0x450
    c78c:	br	x17

000000000000c790 <__gmpn_divexact_1@plt>:
    c790:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c794:	ldr	x17, [x16, #1112]
    c798:	add	x16, x16, #0x458
    c79c:	br	x17

000000000000c7a0 <__gmpn_hgcd_matrix_mul_1@plt>:
    c7a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c7a4:	ldr	x17, [x16, #1120]
    c7a8:	add	x16, x16, #0x460
    c7ac:	br	x17

000000000000c7b0 <__gmpn_toom42_mulmid@plt>:
    c7b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c7b4:	ldr	x17, [x16, #1128]
    c7b8:	add	x16, x16, #0x468
    c7bc:	br	x17

000000000000c7c0 <__gmp_randinit_default@plt>:
    c7c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c7c4:	ldr	x17, [x16, #1136]
    c7c8:	add	x16, x16, #0x470
    c7cc:	br	x17

000000000000c7d0 <__gmpn_toom_interpolate_8pts@plt>:
    c7d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c7d4:	ldr	x17, [x16, #1144]
    c7d8:	add	x16, x16, #0x478
    c7dc:	br	x17

000000000000c7e0 <realloc@plt>:
    c7e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c7e4:	ldr	x17, [x16, #1152]
    c7e8:	add	x16, x16, #0x480
    c7ec:	br	x17

000000000000c7f0 <__gmpn_redc_n@plt>:
    c7f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c7f4:	ldr	x17, [x16, #1160]
    c7f8:	add	x16, x16, #0x488
    c7fc:	br	x17

000000000000c800 <__gmpn_modexact_1c_odd@plt>:
    c800:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c804:	ldr	x17, [x16, #1168]
    c808:	add	x16, x16, #0x490
    c80c:	br	x17

000000000000c810 <getc@plt>:
    c810:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c814:	ldr	x17, [x16, #1176]
    c818:	add	x16, x16, #0x498
    c81c:	br	x17

000000000000c820 <__gmpn_sec_pi1_div_r@plt>:
    c820:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c824:	ldr	x17, [x16, #1184]
    c828:	add	x16, x16, #0x4a0
    c82c:	br	x17

000000000000c830 <__gmpn_toom_interpolate_7pts@plt>:
    c830:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c834:	ldr	x17, [x16, #1192]
    c838:	add	x16, x16, #0x4a8
    c83c:	br	x17

000000000000c840 <__gmpn_sbpi1_bdiv_qr@plt>:
    c840:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c844:	ldr	x17, [x16, #1200]
    c848:	add	x16, x16, #0x4b0
    c84c:	br	x17

000000000000c850 <__gmpn_hgcd_matrix_init@plt>:
    c850:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c854:	ldr	x17, [x16, #1208]
    c858:	add	x16, x16, #0x4b8
    c85c:	br	x17

000000000000c860 <__gmpn_rsh1sub_n@plt>:
    c860:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c864:	ldr	x17, [x16, #1216]
    c868:	add	x16, x16, #0x4c0
    c86c:	br	x17

000000000000c870 <__gmpn_toom32_mul@plt>:
    c870:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c874:	ldr	x17, [x16, #1224]
    c878:	add	x16, x16, #0x4c8
    c87c:	br	x17

000000000000c880 <__gmpn_mulmod_bnm1_next_size@plt>:
    c880:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c884:	ldr	x17, [x16, #1232]
    c888:	add	x16, x16, #0x4d0
    c88c:	br	x17

000000000000c890 <__gmpz_submul_ui@plt>:
    c890:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c894:	ldr	x17, [x16, #1240]
    c898:	add	x16, x16, #0x4d8
    c89c:	br	x17

000000000000c8a0 <__gmpn_mu_bdiv_q_itch@plt>:
    c8a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c8a4:	ldr	x17, [x16, #1248]
    c8a8:	add	x16, x16, #0x4e0
    c8ac:	br	x17

000000000000c8b0 <__gmpz_set_d@plt>:
    c8b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c8b4:	ldr	x17, [x16, #1256]
    c8b8:	add	x16, x16, #0x4e8
    c8bc:	br	x17

000000000000c8c0 <__gmpn_hgcd_matrix_adjust@plt>:
    c8c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c8c4:	ldr	x17, [x16, #1264]
    c8c8:	add	x16, x16, #0x4f0
    c8cc:	br	x17

000000000000c8d0 <__gmpz_add_ui@plt>:
    c8d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c8d4:	ldr	x17, [x16, #1272]
    c8d8:	add	x16, x16, #0x4f8
    c8dc:	br	x17

000000000000c8e0 <__gmpn_bdiv_qr_itch@plt>:
    c8e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c8e4:	ldr	x17, [x16, #1280]
    c8e8:	add	x16, x16, #0x500
    c8ec:	br	x17

000000000000c8f0 <__gmon_start__@plt>:
    c8f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c8f4:	ldr	x17, [x16, #1288]
    c8f8:	add	x16, x16, #0x508
    c8fc:	br	x17

000000000000c900 <__gmpn_sqr@plt>:
    c900:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c904:	ldr	x17, [x16, #1296]
    c908:	add	x16, x16, #0x510
    c90c:	br	x17

000000000000c910 <__gmpz_urandomm@plt>:
    c910:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c914:	ldr	x17, [x16, #1304]
    c918:	add	x16, x16, #0x518
    c91c:	br	x17

000000000000c920 <abort@plt>:
    c920:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c924:	ldr	x17, [x16, #1312]
    c928:	add	x16, x16, #0x520
    c92c:	br	x17

000000000000c930 <__gmpn_toom_interpolate_6pts@plt>:
    c930:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c934:	ldr	x17, [x16, #1320]
    c938:	add	x16, x16, #0x528
    c93c:	br	x17

000000000000c940 <__gmpn_div_qr_2n_pi1@plt>:
    c940:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c944:	ldr	x17, [x16, #1328]
    c948:	add	x16, x16, #0x530
    c94c:	br	x17

000000000000c950 <__gmpn_broot_invm1@plt>:
    c950:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c954:	ldr	x17, [x16, #1336]
    c958:	add	x16, x16, #0x538
    c95c:	br	x17

000000000000c960 <__gmpz_clrbit@plt>:
    c960:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c964:	ldr	x17, [x16, #1344]
    c968:	add	x16, x16, #0x540
    c96c:	br	x17

000000000000c970 <__gmpn_rsh1add_n@plt>:
    c970:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c974:	ldr	x17, [x16, #1352]
    c978:	add	x16, x16, #0x548
    c97c:	br	x17

000000000000c980 <__gmpn_mu_div_qr@plt>:
    c980:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c984:	ldr	x17, [x16, #1360]
    c988:	add	x16, x16, #0x550
    c98c:	br	x17

000000000000c990 <__gmpn_toom_couple_handling@plt>:
    c990:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c994:	ldr	x17, [x16, #1368]
    c998:	add	x16, x16, #0x558
    c99c:	br	x17

000000000000c9a0 <__gmpn_mulmod_bnm1@plt>:
    c9a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c9a4:	ldr	x17, [x16, #1376]
    c9a8:	add	x16, x16, #0x560
    c9ac:	br	x17

000000000000c9b0 <__gmpn_mul_n@plt>:
    c9b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c9b4:	ldr	x17, [x16, #1384]
    c9b8:	add	x16, x16, #0x568
    c9bc:	br	x17

000000000000c9c0 <__gmpz_scan0@plt>:
    c9c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c9c4:	ldr	x17, [x16, #1392]
    c9c8:	add	x16, x16, #0x570
    c9cc:	br	x17

000000000000c9d0 <puts@plt>:
    c9d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c9d4:	ldr	x17, [x16, #1400]
    c9d8:	add	x16, x16, #0x578
    c9dc:	br	x17

000000000000c9e0 <__gmpz_stronglucas@plt>:
    c9e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c9e4:	ldr	x17, [x16, #1408]
    c9e8:	add	x16, x16, #0x580
    c9ec:	br	x17

000000000000c9f0 <__gmpz_inp_str_nowhite@plt>:
    c9f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    c9f4:	ldr	x17, [x16, #1416]
    c9f8:	add	x16, x16, #0x588
    c9fc:	br	x17

000000000000ca00 <__gmpn_submul_1@plt>:
    ca00:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ca04:	ldr	x17, [x16, #1424]
    ca08:	add	x16, x16, #0x590
    ca0c:	br	x17

000000000000ca10 <__gmpn_sqrlo@plt>:
    ca10:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ca14:	ldr	x17, [x16, #1432]
    ca18:	add	x16, x16, #0x598
    ca1c:	br	x17

000000000000ca20 <__gmpz_divexact_gcd@plt>:
    ca20:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ca24:	ldr	x17, [x16, #1440]
    ca28:	add	x16, x16, #0x5a0
    ca2c:	br	x17

000000000000ca30 <__gmpz_ui_pow_ui@plt>:
    ca30:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ca34:	ldr	x17, [x16, #1448]
    ca38:	add	x16, x16, #0x5a8
    ca3c:	br	x17

000000000000ca40 <__gmpn_toom_interpolate_5pts@plt>:
    ca40:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ca44:	ldr	x17, [x16, #1456]
    ca48:	add	x16, x16, #0x5b0
    ca4c:	br	x17

000000000000ca50 <__gmpn_bdiv_q@plt>:
    ca50:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ca54:	ldr	x17, [x16, #1464]
    ca58:	add	x16, x16, #0x5b8
    ca5c:	br	x17

000000000000ca60 <__gmpn_toom53_mul@plt>:
    ca60:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ca64:	ldr	x17, [x16, #1472]
    ca68:	add	x16, x16, #0x5c0
    ca6c:	br	x17

000000000000ca70 <__gmpn_copyi@plt>:
    ca70:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ca74:	ldr	x17, [x16, #1480]
    ca78:	add	x16, x16, #0x5c8
    ca7c:	br	x17

000000000000ca80 <__gmpq_set_ui@plt>:
    ca80:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ca84:	ldr	x17, [x16, #1488]
    ca88:	add	x16, x16, #0x5d0
    ca8c:	br	x17

000000000000ca90 <__gmpn_add_n@plt>:
    ca90:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ca94:	ldr	x17, [x16, #1496]
    ca98:	add	x16, x16, #0x5d8
    ca9c:	br	x17

000000000000caa0 <__gmpz_tdiv_r@plt>:
    caa0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    caa4:	ldr	x17, [x16, #1504]
    caa8:	add	x16, x16, #0x5e0
    caac:	br	x17

000000000000cab0 <__gmpn_get_str@plt>:
    cab0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cab4:	ldr	x17, [x16, #1512]
    cab8:	add	x16, x16, #0x5e8
    cabc:	br	x17

000000000000cac0 <__gmpn_dcpi1_div_q@plt>:
    cac0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cac4:	ldr	x17, [x16, #1520]
    cac8:	add	x16, x16, #0x5f0
    cacc:	br	x17

000000000000cad0 <__gmpn_jacobi_2@plt>:
    cad0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cad4:	ldr	x17, [x16, #1528]
    cad8:	add	x16, x16, #0x5f8
    cadc:	br	x17

000000000000cae0 <__gmpn_mod_1_1p_cps@plt>:
    cae0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cae4:	ldr	x17, [x16, #1536]
    cae8:	add	x16, x16, #0x600
    caec:	br	x17

000000000000caf0 <__gmpn_fft_best_k@plt>:
    caf0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    caf4:	ldr	x17, [x16, #1544]
    caf8:	add	x16, x16, #0x608
    cafc:	br	x17

000000000000cb00 <__ctype_b_loc@plt>:
    cb00:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cb04:	ldr	x17, [x16, #1552]
    cb08:	add	x16, x16, #0x610
    cb0c:	br	x17

000000000000cb10 <__gmpn_hgcd2_jacobi@plt>:
    cb10:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cb14:	ldr	x17, [x16, #1560]
    cb18:	add	x16, x16, #0x618
    cb1c:	br	x17

000000000000cb20 <__gmp_randinit_mt@plt>:
    cb20:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cb24:	ldr	x17, [x16, #1568]
    cb28:	add	x16, x16, #0x620
    cb2c:	br	x17

000000000000cb30 <__gmpn_compute_powtab@plt>:
    cb30:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cb34:	ldr	x17, [x16, #1576]
    cb38:	add	x16, x16, #0x628
    cb3c:	br	x17

000000000000cb40 <__gmpn_toom8h_mul@plt>:
    cb40:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cb44:	ldr	x17, [x16, #1584]
    cb48:	add	x16, x16, #0x630
    cb4c:	br	x17

000000000000cb50 <__gmpz_kronecker_ui@plt>:
    cb50:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cb54:	ldr	x17, [x16, #1592]
    cb58:	add	x16, x16, #0x638
    cb5c:	br	x17

000000000000cb60 <__gmpn_xor_n@plt>:
    cb60:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cb64:	ldr	x17, [x16, #1600]
    cb68:	add	x16, x16, #0x640
    cb6c:	br	x17

000000000000cb70 <__gmpz_clear@plt>:
    cb70:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cb74:	ldr	x17, [x16, #1608]
    cb78:	add	x16, x16, #0x648
    cb7c:	br	x17

000000000000cb80 <strtol@plt>:
    cb80:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cb84:	ldr	x17, [x16, #1616]
    cb88:	add	x16, x16, #0x650
    cb8c:	br	x17

000000000000cb90 <__gmpq_set_si@plt>:
    cb90:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cb94:	ldr	x17, [x16, #1624]
    cb98:	add	x16, x16, #0x658
    cb9c:	br	x17

000000000000cba0 <__gmpz_millerrabin@plt>:
    cba0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cba4:	ldr	x17, [x16, #1632]
    cba8:	add	x16, x16, #0x660
    cbac:	br	x17

000000000000cbb0 <fread@plt>:
    cbb0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cbb4:	ldr	x17, [x16, #1640]
    cbb8:	add	x16, x16, #0x668
    cbbc:	br	x17

000000000000cbc0 <__gmpn_addlsh2_n@plt>:
    cbc0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cbc4:	ldr	x17, [x16, #1648]
    cbc8:	add	x16, x16, #0x670
    cbcc:	br	x17

000000000000cbd0 <__gmpz_mul_si@plt>:
    cbd0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cbd4:	ldr	x17, [x16, #1656]
    cbd8:	add	x16, x16, #0x678
    cbdc:	br	x17

000000000000cbe0 <__gmp_tmp_reentrant_alloc@plt>:
    cbe0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cbe4:	ldr	x17, [x16, #1664]
    cbe8:	add	x16, x16, #0x680
    cbec:	br	x17

000000000000cbf0 <__gmpz_invert@plt>:
    cbf0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cbf4:	ldr	x17, [x16, #1672]
    cbf8:	add	x16, x16, #0x688
    cbfc:	br	x17

000000000000cc00 <__gmpn_rsblsh2_n@plt>:
    cc00:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cc04:	ldr	x17, [x16, #1680]
    cc08:	add	x16, x16, #0x690
    cc0c:	br	x17

000000000000cc10 <__gmpf_neg@plt>:
    cc10:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cc14:	ldr	x17, [x16, #1688]
    cc18:	add	x16, x16, #0x698
    cc1c:	br	x17

000000000000cc20 <__gmpn_ior_n@plt>:
    cc20:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cc24:	ldr	x17, [x16, #1696]
    cc28:	add	x16, x16, #0x6a0
    cc2c:	br	x17

000000000000cc30 <__gmpn_gcd@plt>:
    cc30:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cc34:	ldr	x17, [x16, #1704]
    cc38:	add	x16, x16, #0x6a8
    cc3c:	br	x17

000000000000cc40 <__gmpn_toom6h_mul@plt>:
    cc40:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cc44:	ldr	x17, [x16, #1712]
    cc48:	add	x16, x16, #0x6b0
    cc4c:	br	x17

000000000000cc50 <free@plt>:
    cc50:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cc54:	ldr	x17, [x16, #1720]
    cc58:	add	x16, x16, #0x6b8
    cc5c:	br	x17

000000000000cc60 <__gmpn_addlsh1_n@plt>:
    cc60:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cc64:	ldr	x17, [x16, #1728]
    cc68:	add	x16, x16, #0x6c0
    cc6c:	br	x17

000000000000cc70 <ungetc@plt>:
    cc70:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cc74:	ldr	x17, [x16, #1736]
    cc78:	add	x16, x16, #0x6c8
    cc7c:	br	x17

000000000000cc80 <__gmpn_sec_powm@plt>:
    cc80:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cc84:	ldr	x17, [x16, #1744]
    cc88:	add	x16, x16, #0x6d0
    cc8c:	br	x17

000000000000cc90 <__gmpz_tdiv_q_2exp@plt>:
    cc90:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cc94:	ldr	x17, [x16, #1752]
    cc98:	add	x16, x16, #0x6d8
    cc9c:	br	x17

000000000000cca0 <__gmp_nextprime@plt>:
    cca0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cca4:	ldr	x17, [x16, #1760]
    cca8:	add	x16, x16, #0x6e0
    ccac:	br	x17

000000000000ccb0 <__gmpz_roinit_n@plt>:
    ccb0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ccb4:	ldr	x17, [x16, #1768]
    ccb8:	add	x16, x16, #0x6e8
    ccbc:	br	x17

000000000000ccc0 <__gmpn_nussbaumer_mul@plt>:
    ccc0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ccc4:	ldr	x17, [x16, #1776]
    ccc8:	add	x16, x16, #0x6f0
    cccc:	br	x17

000000000000ccd0 <__gmpn_mu_bdiv_qr@plt>:
    ccd0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ccd4:	ldr	x17, [x16, #1784]
    ccd8:	add	x16, x16, #0x6f8
    ccdc:	br	x17

000000000000cce0 <__gmpn_mod_1s_2p_cps@plt>:
    cce0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cce4:	ldr	x17, [x16, #1792]
    cce8:	add	x16, x16, #0x700
    ccec:	br	x17

000000000000ccf0 <__gmpn_mul@plt>:
    ccf0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ccf4:	ldr	x17, [x16, #1800]
    ccf8:	add	x16, x16, #0x708
    ccfc:	br	x17

000000000000cd00 <__gmpn_preinv_divrem_1@plt>:
    cd00:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cd04:	ldr	x17, [x16, #1808]
    cd08:	add	x16, x16, #0x710
    cd0c:	br	x17

000000000000cd10 <__gmpn_add_err1_n@plt>:
    cd10:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cd14:	ldr	x17, [x16, #1816]
    cd18:	add	x16, x16, #0x718
    cd1c:	br	x17

000000000000cd20 <__gmpn_divrem_1@plt>:
    cd20:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cd24:	ldr	x17, [x16, #1824]
    cd28:	add	x16, x16, #0x720
    cd2c:	br	x17

000000000000cd30 <__gmp_doprnt_integer@plt>:
    cd30:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cd34:	ldr	x17, [x16, #1832]
    cd38:	add	x16, x16, #0x728
    cd3c:	br	x17

000000000000cd40 <__gmpn_binvert@plt>:
    cd40:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cd44:	ldr	x17, [x16, #1840]
    cd48:	add	x16, x16, #0x730
    cd4c:	br	x17

000000000000cd50 <__gmpf_mul@plt>:
    cd50:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cd54:	ldr	x17, [x16, #1848]
    cd58:	add	x16, x16, #0x738
    cd5c:	br	x17

000000000000cd60 <__gmpn_remove@plt>:
    cd60:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cd64:	ldr	x17, [x16, #1856]
    cd68:	add	x16, x16, #0x740
    cd6c:	br	x17

000000000000cd70 <__gmpn_hgcd_appr@plt>:
    cd70:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cd74:	ldr	x17, [x16, #1864]
    cd78:	add	x16, x16, #0x748
    cd7c:	br	x17

000000000000cd80 <__gmpn_toom_eval_dgr3_pm2@plt>:
    cd80:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cd84:	ldr	x17, [x16, #1872]
    cd88:	add	x16, x16, #0x750
    cd8c:	br	x17

000000000000cd90 <__gmpz_prodlimbs@plt>:
    cd90:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cd94:	ldr	x17, [x16, #1880]
    cd98:	add	x16, x16, #0x758
    cd9c:	br	x17

000000000000cda0 <__gmpn_popcount@plt>:
    cda0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cda4:	ldr	x17, [x16, #1888]
    cda8:	add	x16, x16, #0x760
    cdac:	br	x17

000000000000cdb0 <__gmpf_mul_2exp@plt>:
    cdb0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cdb4:	ldr	x17, [x16, #1896]
    cdb8:	add	x16, x16, #0x768
    cdbc:	br	x17

000000000000cdc0 <strchr@plt>:
    cdc0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cdc4:	ldr	x17, [x16, #1904]
    cdc8:	add	x16, x16, #0x770
    cdcc:	br	x17

000000000000cdd0 <__gmp_assert_header@plt>:
    cdd0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cdd4:	ldr	x17, [x16, #1912]
    cdd8:	add	x16, x16, #0x778
    cddc:	br	x17

000000000000cde0 <obstack_vprintf@plt>:
    cde0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cde4:	ldr	x17, [x16, #1920]
    cde8:	add	x16, x16, #0x780
    cdec:	br	x17

000000000000cdf0 <__gmpq_init@plt>:
    cdf0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cdf4:	ldr	x17, [x16, #1928]
    cdf8:	add	x16, x16, #0x788
    cdfc:	br	x17

000000000000ce00 <__gmpn_hgcd@plt>:
    ce00:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ce04:	ldr	x17, [x16, #1936]
    ce08:	add	x16, x16, #0x790
    ce0c:	br	x17

000000000000ce10 <__gmpz_mod@plt>:
    ce10:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ce14:	ldr	x17, [x16, #1944]
    ce18:	add	x16, x16, #0x798
    ce1c:	br	x17

000000000000ce20 <__gmpf_sub@plt>:
    ce20:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ce24:	ldr	x17, [x16, #1952]
    ce28:	add	x16, x16, #0x7a0
    ce2c:	br	x17

000000000000ce30 <__gmpn_dcpi1_bdiv_q@plt>:
    ce30:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ce34:	ldr	x17, [x16, #1960]
    ce38:	add	x16, x16, #0x7a8
    ce3c:	br	x17

000000000000ce40 <__gmpf_get_str@plt>:
    ce40:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ce44:	ldr	x17, [x16, #1968]
    ce48:	add	x16, x16, #0x7b0
    ce4c:	br	x17

000000000000ce50 <fwrite@plt>:
    ce50:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ce54:	ldr	x17, [x16, #1976]
    ce58:	add	x16, x16, #0x7b8
    ce5c:	br	x17

000000000000ce60 <__gmpn_hamdist@plt>:
    ce60:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ce64:	ldr	x17, [x16, #1984]
    ce68:	add	x16, x16, #0x7c0
    ce6c:	br	x17

000000000000ce70 <__gmpz_init_set_ui@plt>:
    ce70:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ce74:	ldr	x17, [x16, #1992]
    ce78:	add	x16, x16, #0x7c8
    ce7c:	br	x17

000000000000ce80 <__gmpf_init@plt>:
    ce80:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ce84:	ldr	x17, [x16, #2000]
    ce88:	add	x16, x16, #0x7d0
    ce8c:	br	x17

000000000000ce90 <__gmpz_cmp@plt>:
    ce90:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ce94:	ldr	x17, [x16, #2008]
    ce98:	add	x16, x16, #0x7d8
    ce9c:	br	x17

000000000000cea0 <__gmpn_mod_1s_2p@plt>:
    cea0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cea4:	ldr	x17, [x16, #2016]
    cea8:	add	x16, x16, #0x7e0
    ceac:	br	x17

000000000000ceb0 <__gmpn_add_nc@plt>:
    ceb0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ceb4:	ldr	x17, [x16, #2024]
    ceb8:	add	x16, x16, #0x7e8
    cebc:	br	x17

000000000000cec0 <__gmpn_jacobi_n@plt>:
    cec0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cec4:	ldr	x17, [x16, #2032]
    cec8:	add	x16, x16, #0x7f0
    cecc:	br	x17

000000000000ced0 <__gmpf_init2@plt>:
    ced0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    ced4:	ldr	x17, [x16, #2040]
    ced8:	add	x16, x16, #0x7f8
    cedc:	br	x17

000000000000cee0 <__gmpn_mullo_n@plt>:
    cee0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cee4:	ldr	x17, [x16, #2048]
    cee8:	add	x16, x16, #0x800
    ceec:	br	x17

000000000000cef0 <__gmpf_div@plt>:
    cef0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cef4:	ldr	x17, [x16, #2056]
    cef8:	add	x16, x16, #0x808
    cefc:	br	x17

000000000000cf00 <__gmpn_sbpi1_div_q@plt>:
    cf00:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cf04:	ldr	x17, [x16, #2064]
    cf08:	add	x16, x16, #0x810
    cf0c:	br	x17

000000000000cf10 <__gmpn_sec_pi1_div_qr@plt>:
    cf10:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cf14:	ldr	x17, [x16, #2072]
    cf18:	add	x16, x16, #0x818
    cf1c:	br	x17

000000000000cf20 <__gmpn_toom43_mul@plt>:
    cf20:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cf24:	ldr	x17, [x16, #2080]
    cf28:	add	x16, x16, #0x820
    cf2c:	br	x17

000000000000cf30 <vsprintf@plt>:
    cf30:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cf34:	ldr	x17, [x16, #2088]
    cf38:	add	x16, x16, #0x828
    cf3c:	br	x17

000000000000cf40 <__gmpn_div_qr_2u_pi1@plt>:
    cf40:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cf44:	ldr	x17, [x16, #2096]
    cf48:	add	x16, x16, #0x830
    cf4c:	br	x17

000000000000cf50 <__gmpn_zero@plt>:
    cf50:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cf54:	ldr	x17, [x16, #2104]
    cf58:	add	x16, x16, #0x838
    cf5c:	br	x17

000000000000cf60 <__gmp_randinit_lc_2exp@plt>:
    cf60:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cf64:	ldr	x17, [x16, #2112]
    cf68:	add	x16, x16, #0x840
    cf6c:	br	x17

000000000000cf70 <__gmpn_bdiv_qr@plt>:
    cf70:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cf74:	ldr	x17, [x16, #2120]
    cf78:	add	x16, x16, #0x848
    cf7c:	br	x17

000000000000cf80 <__gmpn_mod_34lsub1@plt>:
    cf80:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cf84:	ldr	x17, [x16, #2128]
    cf88:	add	x16, x16, #0x850
    cf8c:	br	x17

000000000000cf90 <__gmpz_gcd@plt>:
    cf90:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cf94:	ldr	x17, [x16, #2136]
    cf98:	add	x16, x16, #0x858
    cf9c:	br	x17

000000000000cfa0 <__gmpz_aorsmul_1@plt>:
    cfa0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cfa4:	ldr	x17, [x16, #2144]
    cfa8:	add	x16, x16, #0x860
    cfac:	br	x17

000000000000cfb0 <__gmpz_add@plt>:
    cfb0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cfb4:	ldr	x17, [x16, #2152]
    cfb8:	add	x16, x16, #0x868
    cfbc:	br	x17

000000000000cfc0 <__gmpn_hgcd_matrix_mul@plt>:
    cfc0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cfc4:	ldr	x17, [x16, #2160]
    cfc8:	add	x16, x16, #0x870
    cfcc:	br	x17

000000000000cfd0 <__gmp_randseed@plt>:
    cfd0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cfd4:	ldr	x17, [x16, #2168]
    cfd8:	add	x16, x16, #0x878
    cfdc:	br	x17

000000000000cfe0 <__gmpn_toom_eval_pm1@plt>:
    cfe0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cfe4:	ldr	x17, [x16, #2176]
    cfe8:	add	x16, x16, #0x880
    cfec:	br	x17

000000000000cff0 <__gmpn_mu_div_q_itch@plt>:
    cff0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    cff4:	ldr	x17, [x16, #2184]
    cff8:	add	x16, x16, #0x888
    cffc:	br	x17

000000000000d000 <__gmpq_mul@plt>:
    d000:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d004:	ldr	x17, [x16, #2192]
    d008:	add	x16, x16, #0x890
    d00c:	br	x17

000000000000d010 <__gmp_sqrt_of_negative@plt>:
    d010:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d014:	ldr	x17, [x16, #2200]
    d018:	add	x16, x16, #0x898
    d01c:	br	x17

000000000000d020 <__gmpn_powm@plt>:
    d020:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d024:	ldr	x17, [x16, #2208]
    d028:	add	x16, x16, #0x8a0
    d02c:	br	x17

000000000000d030 <__gmpn_mu_div_qr_itch@plt>:
    d030:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d034:	ldr	x17, [x16, #2216]
    d038:	add	x16, x16, #0x8a8
    d03c:	br	x17

000000000000d040 <__gmpn_hgcd_matrix_update_q@plt>:
    d040:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d044:	ldr	x17, [x16, #2224]
    d048:	add	x16, x16, #0x8b0
    d04c:	br	x17

000000000000d050 <__gmp_doprnt@plt>:
    d050:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d054:	ldr	x17, [x16, #2232]
    d058:	add	x16, x16, #0x8b8
    d05c:	br	x17

000000000000d060 <_obstack_newchunk@plt>:
    d060:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d064:	ldr	x17, [x16, #2240]
    d068:	add	x16, x16, #0x8c0
    d06c:	br	x17

000000000000d070 <__gmpn_fib2m@plt>:
    d070:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d074:	ldr	x17, [x16, #2248]
    d078:	add	x16, x16, #0x8c8
    d07c:	br	x17

000000000000d080 <__gmpn_invertappr@plt>:
    d080:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d084:	ldr	x17, [x16, #2256]
    d088:	add	x16, x16, #0x8d0
    d08c:	br	x17

000000000000d090 <__gmpn_fib2_ui@plt>:
    d090:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d094:	ldr	x17, [x16, #2264]
    d098:	add	x16, x16, #0x8d8
    d09c:	br	x17

000000000000d0a0 <__gmpn_preinv_mu_div_qr@plt>:
    d0a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d0a4:	ldr	x17, [x16, #2272]
    d0a8:	add	x16, x16, #0x8e0
    d0ac:	br	x17

000000000000d0b0 <__gmpn_rsblsh1_n@plt>:
    d0b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d0b4:	ldr	x17, [x16, #2280]
    d0b8:	add	x16, x16, #0x8e8
    d0bc:	br	x17

000000000000d0c0 <__gmpz_init_set_str@plt>:
    d0c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d0c4:	ldr	x17, [x16, #2288]
    d0c8:	add	x16, x16, #0x8f0
    d0cc:	br	x17

000000000000d0d0 <__gmpn_perfect_square_p@plt>:
    d0d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d0d4:	ldr	x17, [x16, #2296]
    d0d8:	add	x16, x16, #0x8f8
    d0dc:	br	x17

000000000000d0e0 <__gmpz_fdiv_r_2exp@plt>:
    d0e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d0e4:	ldr	x17, [x16, #2304]
    d0e8:	add	x16, x16, #0x900
    d0ec:	br	x17

000000000000d0f0 <__gmpz_inp_str@plt>:
    d0f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d0f4:	ldr	x17, [x16, #2312]
    d0f8:	add	x16, x16, #0x908
    d0fc:	br	x17

000000000000d100 <__gmpn_toom_eval_pm2rexp@plt>:
    d100:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d104:	ldr	x17, [x16, #2320]
    d108:	add	x16, x16, #0x910
    d10c:	br	x17

000000000000d110 <__gmpn_redc_1@plt>:
    d110:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d114:	ldr	x17, [x16, #2328]
    d118:	add	x16, x16, #0x918
    d11c:	br	x17

000000000000d120 <__isoc99_sscanf@plt>:
    d120:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d124:	ldr	x17, [x16, #2336]
    d128:	add	x16, x16, #0x920
    d12c:	br	x17

000000000000d130 <vsnprintf@plt>:
    d130:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d134:	ldr	x17, [x16, #2344]
    d138:	add	x16, x16, #0x928
    d13c:	br	x17

000000000000d140 <__gmpn_strongfibo@plt>:
    d140:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d144:	ldr	x17, [x16, #2352]
    d148:	add	x16, x16, #0x930
    d14c:	br	x17

000000000000d150 <__gmpz_init2@plt>:
    d150:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d154:	ldr	x17, [x16, #2360]
    d158:	add	x16, x16, #0x938
    d15c:	br	x17

000000000000d160 <__gmpn_gcdext_1@plt>:
    d160:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d164:	ldr	x17, [x16, #2368]
    d168:	add	x16, x16, #0x940
    d16c:	br	x17

000000000000d170 <__gmpn_scan1@plt>:
    d170:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d174:	ldr	x17, [x16, #2376]
    d178:	add	x16, x16, #0x948
    d17c:	br	x17

000000000000d180 <__gmpn_lshiftc@plt>:
    d180:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d184:	ldr	x17, [x16, #2384]
    d188:	add	x16, x16, #0x950
    d18c:	br	x17

000000000000d190 <__gmpn_mu_bdiv_qr_itch@plt>:
    d190:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d194:	ldr	x17, [x16, #2392]
    d198:	add	x16, x16, #0x958
    d19c:	br	x17

000000000000d1a0 <__gmpn_ni_invertappr@plt>:
    d1a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d1a4:	ldr	x17, [x16, #2400]
    d1a8:	add	x16, x16, #0x960
    d1ac:	br	x17

000000000000d1b0 <__gmp_randinit_lc_2exp_size@plt>:
    d1b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d1b4:	ldr	x17, [x16, #2408]
    d1b8:	add	x16, x16, #0x968
    d1bc:	br	x17

000000000000d1c0 <__gmp_init_primesieve@plt>:
    d1c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d1c4:	ldr	x17, [x16, #2416]
    d1c8:	add	x16, x16, #0x970
    d1cc:	br	x17

000000000000d1d0 <__gmpn_gcdext_lehmer_n@plt>:
    d1d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d1d4:	ldr	x17, [x16, #2424]
    d1d8:	add	x16, x16, #0x978
    d1dc:	br	x17

000000000000d1e0 <__gmpn_random2@plt>:
    d1e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d1e4:	ldr	x17, [x16, #2432]
    d1e8:	add	x16, x16, #0x980
    d1ec:	br	x17

000000000000d1f0 <__gmpn_fft_next_size@plt>:
    d1f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d1f4:	ldr	x17, [x16, #2440]
    d1f8:	add	x16, x16, #0x988
    d1fc:	br	x17

000000000000d200 <__gmpn_binvert_itch@plt>:
    d200:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d204:	ldr	x17, [x16, #2448]
    d208:	add	x16, x16, #0x990
    d20c:	br	x17

000000000000d210 <__gmpz_cmp_ui@plt>:
    d210:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d214:	ldr	x17, [x16, #2456]
    d218:	add	x16, x16, #0x998
    d21c:	br	x17

000000000000d220 <__gmp_primesieve@plt>:
    d220:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d224:	ldr	x17, [x16, #2464]
    d228:	add	x16, x16, #0x9a0
    d22c:	br	x17

000000000000d230 <__gmpn_pow_1@plt>:
    d230:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d234:	ldr	x17, [x16, #2472]
    d238:	add	x16, x16, #0x9a8
    d23c:	br	x17

000000000000d240 <__gmpz_export@plt>:
    d240:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d244:	ldr	x17, [x16, #2480]
    d248:	add	x16, x16, #0x9b0
    d24c:	br	x17

000000000000d250 <__gmp_doprnt_mpf2@plt>:
    d250:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d254:	ldr	x17, [x16, #2488]
    d258:	add	x16, x16, #0x9b8
    d25c:	br	x17

000000000000d260 <__gmpn_mul_1c@plt>:
    d260:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d264:	ldr	x17, [x16, #2496]
    d268:	add	x16, x16, #0x9c0
    d26c:	br	x17

000000000000d270 <__gmpz_init@plt>:
    d270:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d274:	ldr	x17, [x16, #2504]
    d278:	add	x16, x16, #0x9c8
    d27c:	br	x17

000000000000d280 <__gmpz_sizeinbase@plt>:
    d280:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d284:	ldr	x17, [x16, #2512]
    d288:	add	x16, x16, #0x9d0
    d28c:	br	x17

000000000000d290 <__gmpz_set_si@plt>:
    d290:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d294:	ldr	x17, [x16, #2520]
    d298:	add	x16, x16, #0x9d8
    d29c:	br	x17

000000000000d2a0 <__gmp_extract_double@plt>:
    d2a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d2a4:	ldr	x17, [x16, #2528]
    d2a8:	add	x16, x16, #0x9e0
    d2ac:	br	x17

000000000000d2b0 <__gmpn_mullo_basecase@plt>:
    d2b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d2b4:	ldr	x17, [x16, #2536]
    d2b8:	add	x16, x16, #0x9e8
    d2bc:	br	x17

000000000000d2c0 <__gmpn_toom3_sqr@plt>:
    d2c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d2c4:	ldr	x17, [x16, #2544]
    d2c8:	add	x16, x16, #0x9f0
    d2cc:	br	x17

000000000000d2d0 <__gmpn_gcd_subdiv_step@plt>:
    d2d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d2d4:	ldr	x17, [x16, #2552]
    d2d8:	add	x16, x16, #0x9f8
    d2dc:	br	x17

000000000000d2e0 <__gmpz_powm_ui@plt>:
    d2e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d2e4:	ldr	x17, [x16, #2560]
    d2e8:	add	x16, x16, #0xa00
    d2ec:	br	x17

000000000000d2f0 <vfprintf@plt>:
    d2f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d2f4:	ldr	x17, [x16, #2568]
    d2f8:	add	x16, x16, #0xa08
    d2fc:	br	x17

000000000000d300 <printf@plt>:
    d300:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d304:	ldr	x17, [x16, #2576]
    d308:	add	x16, x16, #0xa10
    d30c:	br	x17

000000000000d310 <__gmpn_hgcd_reduce@plt>:
    d310:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d314:	ldr	x17, [x16, #2584]
    d318:	add	x16, x16, #0xa18
    d31c:	br	x17

000000000000d320 <__gmpn_dcpi1_bdiv_qr_n@plt>:
    d320:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d324:	ldr	x17, [x16, #2592]
    d328:	add	x16, x16, #0xa20
    d32c:	br	x17

000000000000d330 <putchar@plt>:
    d330:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d334:	ldr	x17, [x16, #2600]
    d338:	add	x16, x16, #0xa28
    d33c:	br	x17

000000000000d340 <__gmpz_addmul_ui@plt>:
    d340:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d344:	ldr	x17, [x16, #2608]
    d348:	add	x16, x16, #0xa30
    d34c:	br	x17

000000000000d350 <__gmpn_sqr_diag_addlsh1@plt>:
    d350:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d354:	ldr	x17, [x16, #2616]
    d358:	add	x16, x16, #0xa38
    d35c:	br	x17

000000000000d360 <__gmpn_gcd_11@plt>:
    d360:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d364:	ldr	x17, [x16, #2624]
    d368:	add	x16, x16, #0xa40
    d36c:	br	x17

000000000000d370 <__gmpn_toom_interpolate_16pts@plt>:
    d370:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d374:	ldr	x17, [x16, #2632]
    d378:	add	x16, x16, #0xa48
    d37c:	br	x17

000000000000d380 <__gmpn_divisible_p@plt>:
    d380:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d384:	ldr	x17, [x16, #2640]
    d388:	add	x16, x16, #0xa50
    d38c:	br	x17

000000000000d390 <__gmpn_sub_err2_n@plt>:
    d390:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d394:	ldr	x17, [x16, #2648]
    d398:	add	x16, x16, #0xa58
    d39c:	br	x17

000000000000d3a0 <__gmpn_bdiv_q_itch@plt>:
    d3a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d3a4:	ldr	x17, [x16, #2656]
    d3a8:	add	x16, x16, #0xa60
    d3ac:	br	x17

000000000000d3b0 <__gmpn_hgcd_jacobi@plt>:
    d3b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d3b4:	ldr	x17, [x16, #2664]
    d3b8:	add	x16, x16, #0xa68
    d3bc:	br	x17

000000000000d3c0 <__gmpn_divrem@plt>:
    d3c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d3c4:	ldr	x17, [x16, #2672]
    d3c8:	add	x16, x16, #0xa70
    d3cc:	br	x17

000000000000d3d0 <__gmpn_sqrtrem@plt>:
    d3d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d3d4:	ldr	x17, [x16, #2680]
    d3d8:	add	x16, x16, #0xa78
    d3dc:	br	x17

000000000000d3e0 <__gmpn_mu_bdiv_q@plt>:
    d3e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d3e4:	ldr	x17, [x16, #2688]
    d3e8:	add	x16, x16, #0xa80
    d3ec:	br	x17

000000000000d3f0 <__gmp_exception@plt>:
    d3f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d3f4:	ldr	x17, [x16, #2696]
    d3f8:	add	x16, x16, #0xa88
    d3fc:	br	x17

000000000000d400 <__gmpn_dcpi1_div_qr_n@plt>:
    d400:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d404:	ldr	x17, [x16, #2704]
    d408:	add	x16, x16, #0xa90
    d40c:	br	x17

000000000000d410 <__gmpn_invert_limb@plt>:
    d410:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d414:	ldr	x17, [x16, #2712]
    d418:	add	x16, x16, #0xa98
    d41c:	br	x17

000000000000d420 <__gmpn_addmul_1@plt>:
    d420:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d424:	ldr	x17, [x16, #2720]
    d428:	add	x16, x16, #0xaa0
    d42c:	br	x17

000000000000d430 <__gmpn_mod_1s_4p@plt>:
    d430:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d434:	ldr	x17, [x16, #2728]
    d438:	add	x16, x16, #0xaa8
    d43c:	br	x17

000000000000d440 <fprintf@plt>:
    d440:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d444:	ldr	x17, [x16, #2736]
    d448:	add	x16, x16, #0xab0
    d44c:	br	x17

000000000000d450 <__gmpz_urandomb@plt>:
    d450:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d454:	ldr	x17, [x16, #2744]
    d458:	add	x16, x16, #0xab8
    d45c:	br	x17

000000000000d460 <__gmpn_hgcd_mul_matrix1_vector@plt>:
    d460:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d464:	ldr	x17, [x16, #2752]
    d468:	add	x16, x16, #0xac0
    d46c:	br	x17

000000000000d470 <__gmpn_toom22_mul@plt>:
    d470:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d474:	ldr	x17, [x16, #2760]
    d478:	add	x16, x16, #0xac8
    d47c:	br	x17

000000000000d480 <__gmp_mt_recalc_buffer@plt>:
    d480:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d484:	ldr	x17, [x16, #2768]
    d488:	add	x16, x16, #0xad0
    d48c:	br	x17

000000000000d490 <__gmpn_toom6_sqr@plt>:
    d490:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d494:	ldr	x17, [x16, #2776]
    d498:	add	x16, x16, #0xad8
    d49c:	br	x17

000000000000d4a0 <__gmpn_toom42_mul@plt>:
    d4a0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d4a4:	ldr	x17, [x16, #2784]
    d4a8:	add	x16, x16, #0xae0
    d4ac:	br	x17

000000000000d4b0 <__gmpn_mul_1@plt>:
    d4b0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d4b4:	ldr	x17, [x16, #2792]
    d4b8:	add	x16, x16, #0xae8
    d4bc:	br	x17

000000000000d4c0 <ferror@plt>:
    d4c0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d4c4:	ldr	x17, [x16, #2800]
    d4c8:	add	x16, x16, #0xaf0
    d4cc:	br	x17

000000000000d4d0 <__gmpn_toom8_sqr@plt>:
    d4d0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d4d4:	ldr	x17, [x16, #2808]
    d4d8:	add	x16, x16, #0xaf8
    d4dc:	br	x17

000000000000d4e0 <__gmpf_div_2exp@plt>:
    d4e0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d4e4:	ldr	x17, [x16, #2816]
    d4e8:	add	x16, x16, #0xb00
    d4ec:	br	x17

000000000000d4f0 <__gmpn_cnd_add_n@plt>:
    d4f0:	adrp	x16, 6e000 <memcpy@GLIBC_2.17>
    d4f4:	ldr	x17, [x16, #2824]
    d4f8:	add	x16, x16, #0xb08
    d4fc:	br	x17

Disassembly of section .text:

000000000000d500 <__gmp_assert_header@@Base-0xd4>:
    d500:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d504:	ldr	x0, [x0, #3904]
    d508:	cbz	x0, d510 <__gmpn_cnd_add_n@plt+0x20>
    d50c:	b	c8f0 <__gmon_start__@plt>
    d510:	ret
    d514:	nop
    d518:	adrp	x0, 6e000 <memcpy@GLIBC_2.17>
    d51c:	add	x0, x0, #0xb38
    d520:	adrp	x1, 6e000 <memcpy@GLIBC_2.17>
    d524:	add	x1, x1, #0xb38
    d528:	cmp	x1, x0
    d52c:	b.eq	d544 <__gmpn_cnd_add_n@plt+0x54>  // b.none
    d530:	adrp	x1, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d534:	ldr	x1, [x1, #3784]
    d538:	cbz	x1, d544 <__gmpn_cnd_add_n@plt+0x54>
    d53c:	mov	x16, x1
    d540:	br	x16
    d544:	ret
    d548:	adrp	x0, 6e000 <memcpy@GLIBC_2.17>
    d54c:	add	x0, x0, #0xb38
    d550:	adrp	x1, 6e000 <memcpy@GLIBC_2.17>
    d554:	add	x1, x1, #0xb38
    d558:	sub	x1, x1, x0
    d55c:	lsr	x2, x1, #63
    d560:	add	x1, x2, x1, asr #3
    d564:	cmp	xzr, x1, asr #1
    d568:	asr	x1, x1, #1
    d56c:	b.eq	d584 <__gmpn_cnd_add_n@plt+0x94>  // b.none
    d570:	adrp	x2, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d574:	ldr	x2, [x2, #4056]
    d578:	cbz	x2, d584 <__gmpn_cnd_add_n@plt+0x94>
    d57c:	mov	x16, x2
    d580:	br	x16
    d584:	ret
    d588:	stp	x29, x30, [sp, #-32]!
    d58c:	mov	x29, sp
    d590:	str	x19, [sp, #16]
    d594:	adrp	x19, 6e000 <memcpy@GLIBC_2.17>
    d598:	ldrb	w0, [x19, #2872]
    d59c:	cbnz	w0, d5c4 <__gmpn_cnd_add_n@plt+0xd4>
    d5a0:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d5a4:	ldr	x0, [x0, #3800]
    d5a8:	cbz	x0, d5b8 <__gmpn_cnd_add_n@plt+0xc8>
    d5ac:	adrp	x0, 6e000 <memcpy@GLIBC_2.17>
    d5b0:	ldr	x0, [x0, #2832]
    d5b4:	bl	c1e0 <__cxa_finalize@plt>
    d5b8:	bl	d518 <__gmpn_cnd_add_n@plt+0x28>
    d5bc:	mov	w0, #0x1                   	// #1
    d5c0:	strb	w0, [x19, #2872]
    d5c4:	ldr	x19, [sp, #16]
    d5c8:	ldp	x29, x30, [sp], #32
    d5cc:	ret
    d5d0:	b	d548 <__gmpn_cnd_add_n@plt+0x58>

000000000000d5d4 <__gmp_assert_header@@Base>:
    d5d4:	stp	x29, x30, [sp, #-32]!
    d5d8:	stp	x20, x19, [sp, #16]
    d5dc:	mov	x29, sp
    d5e0:	cbz	x0, d5f0 <__gmp_assert_header@@Base+0x1c>
    d5e4:	ldrb	w8, [x0]
    d5e8:	mov	x2, x0
    d5ec:	cbnz	w8, d5fc <__gmp_assert_header@@Base+0x28>
    d5f0:	ldp	x20, x19, [sp, #16]
    d5f4:	ldp	x29, x30, [sp], #32
    d5f8:	ret
    d5fc:	adrp	x20, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d600:	ldr	x20, [x20, #3824]
    d604:	mov	w19, w1
    d608:	adrp	x1, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    d60c:	add	x1, x1, #0xa90
    d610:	ldr	x0, [x20]
    d614:	bl	d440 <fprintf@plt>
    d618:	cmn	w19, #0x1
    d61c:	b.eq	d5f0 <__gmp_assert_header@@Base+0x1c>  // b.none
    d620:	ldr	x0, [x20]
    d624:	mov	w2, w19
    d628:	ldp	x20, x19, [sp, #16]
    d62c:	adrp	x1, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    d630:	add	x1, x1, #0xa94
    d634:	ldp	x29, x30, [sp], #32
    d638:	b	d440 <fprintf@plt>

000000000000d63c <__gmp_assert_fail@@Base>:
    d63c:	stp	x29, x30, [sp, #-32]!
    d640:	str	x19, [sp, #16]
    d644:	mov	x29, sp
    d648:	mov	x19, x2
    d64c:	bl	cdd0 <__gmp_assert_header@plt>
    d650:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d654:	ldr	x8, [x8, #3824]
    d658:	adrp	x1, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    d65c:	add	x1, x1, #0xa99
    d660:	mov	x2, x19
    d664:	ldr	x0, [x8]
    d668:	bl	d440 <fprintf@plt>
    d66c:	bl	c920 <abort@plt>

000000000000d670 <__gmpn_divexact_by3@@Base>:
    d670:	stp	x29, x30, [sp, #-16]!
    d674:	mov	x3, #0x5555555555555555    	// #6148914691236517205
    d678:	mov	x4, xzr
    d67c:	mov	x29, sp
    d680:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
    d684:	and	x0, x0, #0x3
    d688:	ldp	x29, x30, [sp], #16
    d68c:	ret

000000000000d690 <__gmpn_divmod_1@@Base>:
    d690:	mov	x4, x3
    d694:	mov	x3, x2
    d698:	mov	x2, x1
    d69c:	mov	x1, xzr
    d6a0:	b	cd20 <__gmpn_divrem_1@plt>

000000000000d6a4 <__gmpz_legendre@@Base>:
    d6a4:	b	c080 <__gmpz_jacobi@plt>

000000000000d6a8 <__gmp_exception@@Base>:
    d6a8:	stp	x29, x30, [sp, #-16]!
    d6ac:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d6b0:	ldr	x8, [x8, #3896]
    d6b4:	mov	x29, sp
    d6b8:	ldr	w9, [x8]
    d6bc:	orr	w9, w9, w0
    d6c0:	mov	w0, #0x8                   	// #8
    d6c4:	str	w9, [x8]
    d6c8:	bl	bfd0 <raise@plt>
    d6cc:	bl	c920 <abort@plt>

000000000000d6d0 <__gmp_sqrt_of_negative@@Base>:
    d6d0:	stp	x29, x30, [sp, #-16]!
    d6d4:	mov	w0, #0x4                   	// #4
    d6d8:	mov	x29, sp
    d6dc:	bl	d3f0 <__gmp_exception@plt>

000000000000d6e0 <__gmp_divide_by_zero@@Base>:
    d6e0:	stp	x29, x30, [sp, #-16]!
    d6e4:	mov	w0, #0x2                   	// #2
    d6e8:	mov	x29, sp
    d6ec:	bl	d3f0 <__gmp_exception@plt>

000000000000d6f0 <__gmp_extract_double@@Base>:
    d6f0:	fcmp	d0, #0.0
    d6f4:	b.ne	d704 <__gmp_extract_double@@Base+0x14>  // b.any
    d6f8:	mov	w8, wzr
    d6fc:	stp	xzr, xzr, [x0]
    d700:	b	d764 <__gmp_extract_double@@Base+0x74>
    d704:	fmov	x9, d0
    d708:	ubfx	x8, x9, #52, #11
    d70c:	lsl	x9, x9, #11
    d710:	orr	x9, x9, #0x8000000000000000
    d714:	cbnz	x8, d728 <__gmp_extract_double@@Base+0x38>
    d718:	mov	w8, #0x1                   	// #1
    d71c:	lsl	x9, x9, #1
    d720:	sub	x8, x8, #0x1
    d724:	tbz	x9, #63, d71c <__gmp_extract_double@@Base+0x2c>
    d728:	add	x10, x8, #0xc02
    d72c:	add	x11, x8, #0xc41
    d730:	cmp	x10, #0x0
    d734:	and	w8, w10, #0x3f
    d738:	csel	x10, x11, x10, lt  // lt = tstop
    d73c:	asr	x11, x10, #6
    d740:	cbz	w8, d758 <__gmp_extract_double@@Base+0x68>
    d744:	neg	w12, w8
    d748:	lsl	x10, x9, x8
    d74c:	lsr	x9, x9, x12
    d750:	sub	x8, x11, #0x3f
    d754:	b	d760 <__gmp_extract_double@@Base+0x70>
    d758:	mov	x10, xzr
    d75c:	sub	x8, x11, #0x40
    d760:	stp	x10, x9, [x0]
    d764:	mov	w0, w8
    d768:	ret

000000000000d76c <__gmp_invalid_operation@@Base>:
    d76c:	stp	x29, x30, [sp, #-16]!
    d770:	mov	w0, #0x8                   	// #8
    d774:	mov	x29, sp
    d778:	bl	bfd0 <raise@plt>
    d77c:	bl	c920 <abort@plt>

000000000000d780 <__gmp_default_allocate@@Base>:
    d780:	stp	x29, x30, [sp, #-32]!
    d784:	str	x19, [sp, #16]
    d788:	mov	x29, sp
    d78c:	mov	x19, x0
    d790:	bl	c430 <malloc@plt>
    d794:	cbz	x0, d7a4 <__gmp_default_allocate@@Base+0x24>
    d798:	ldr	x19, [sp, #16]
    d79c:	ldp	x29, x30, [sp], #32
    d7a0:	ret
    d7a4:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d7a8:	ldr	x8, [x8, #3824]
    d7ac:	adrp	x1, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    d7b0:	add	x1, x1, #0xab6
    d7b4:	mov	x2, x19
    d7b8:	ldr	x0, [x8]
    d7bc:	bl	d440 <fprintf@plt>
    d7c0:	bl	c920 <abort@plt>

000000000000d7c4 <__gmp_default_reallocate@@Base>:
    d7c4:	stp	x29, x30, [sp, #-32]!
    d7c8:	stp	x20, x19, [sp, #16]
    d7cc:	mov	x20, x1
    d7d0:	mov	x1, x2
    d7d4:	mov	x29, sp
    d7d8:	mov	x19, x2
    d7dc:	bl	c7e0 <realloc@plt>
    d7e0:	cbz	x0, d7f0 <__gmp_default_reallocate@@Base+0x2c>
    d7e4:	ldp	x20, x19, [sp, #16]
    d7e8:	ldp	x29, x30, [sp], #32
    d7ec:	ret
    d7f0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d7f4:	ldr	x8, [x8, #3824]
    d7f8:	adrp	x1, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    d7fc:	add	x1, x1, #0xae1
    d800:	mov	x2, x20
    d804:	ldr	x0, [x8]
    d808:	mov	x3, x19
    d80c:	bl	d440 <fprintf@plt>
    d810:	bl	c920 <abort@plt>

000000000000d814 <__gmp_default_free@@Base>:
    d814:	b	cc50 <free@plt>

000000000000d818 <__gmp_get_memory_functions@@Base>:
    d818:	cbz	x0, d82c <__gmp_get_memory_functions@@Base+0x14>
    d81c:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d820:	ldr	x8, [x8, #3840]
    d824:	ldr	x8, [x8]
    d828:	str	x8, [x0]
    d82c:	cbz	x1, d840 <__gmp_get_memory_functions@@Base+0x28>
    d830:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d834:	ldr	x8, [x8, #3792]
    d838:	ldr	x8, [x8]
    d83c:	str	x8, [x1]
    d840:	cbz	x2, d854 <__gmp_get_memory_functions@@Base+0x3c>
    d844:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d848:	ldr	x8, [x8, #4016]
    d84c:	ldr	x8, [x8]
    d850:	str	x8, [x2]
    d854:	ret

000000000000d858 <__gmp_set_memory_functions@@Base>:
    d858:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d85c:	ldr	x8, [x8, #4008]
    d860:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d864:	ldr	x9, [x9, #3840]
    d868:	cmp	x0, #0x0
    d86c:	csel	x8, x8, x0, eq  // eq = none
    d870:	adrp	x10, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d874:	str	x8, [x9]
    d878:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d87c:	ldr	x8, [x8, #3912]
    d880:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d884:	ldr	x9, [x9, #4032]
    d888:	ldr	x10, [x10, #3792]
    d88c:	cmp	x1, #0x0
    d890:	csel	x8, x8, x1, eq  // eq = none
    d894:	cmp	x2, #0x0
    d898:	str	x8, [x10]
    d89c:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    d8a0:	ldr	x8, [x8, #4016]
    d8a4:	csel	x9, x9, x2, eq  // eq = none
    d8a8:	str	x9, [x8]
    d8ac:	ret

000000000000d8b0 <__gmp_nextprime@@Base>:
    d8b0:	stp	x29, x30, [sp, #-96]!
    d8b4:	stp	x28, x27, [sp, #16]
    d8b8:	stp	x26, x25, [sp, #32]
    d8bc:	stp	x24, x23, [sp, #48]
    d8c0:	stp	x22, x21, [sp, #64]
    d8c4:	stp	x20, x19, [sp, #80]
    d8c8:	mov	x20, x0
    d8cc:	ldr	x8, [x20], #24
    d8d0:	mov	x26, #0x2493                	// #9363
    d8d4:	movk	x26, #0x9249, lsl #16
    d8d8:	mov	x22, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
    d8dc:	movk	x26, #0x4924, lsl #32
    d8e0:	adrp	x27, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    d8e4:	mov	x19, x0
    d8e8:	add	x21, x0, #0x218
    d8ec:	movk	x22, #0xaaab
    d8f0:	mov	w23, #0x1                   	// #1
    d8f4:	mov	w25, #0x5                   	// #5
    d8f8:	movk	x26, #0x2492, lsl #48
    d8fc:	add	x27, x27, #0xd7e
    d900:	mov	w28, #0x30                  	// #48
    d904:	mov	x29, sp
    d908:	add	x9, x19, x8
    d90c:	ldrb	w9, [x9, #24]
    d910:	add	x8, x8, #0x1
    d914:	cbnz	w9, d908 <__gmp_nextprime@@Base+0x58>
    d918:	cmp	x8, #0x201
    d91c:	b.ne	db00 <__gmp_nextprime@@Base+0x250>  // b.any
    d920:	ldr	x24, [x19, #8]
    d924:	cmp	x24, #0x2
    d928:	b.ls	db20 <__gmp_nextprime@@Base+0x270>  // b.plast
    d92c:	mov	w2, #0x200                 	// #512
    d930:	mov	x0, x20
    d934:	mov	w1, wzr
    d938:	bl	c610 <memset@plt>
    d93c:	ldr	x9, [x19, #16]
    d940:	add	x8, x24, #0x400
    d944:	str	x8, [x19, #8]
    d948:	add	x10, x9, #0x1
    d94c:	mul	x11, x10, x10
    d950:	add	x10, x24, #0x7ff
    d954:	cmp	x11, x10
    d958:	b.hi	d974 <__gmp_nextprime@@Base+0xc4>  // b.pmore
    d95c:	add	x11, x9, #0x2
    d960:	mul	x11, x11, x11
    d964:	cmp	x11, x10
    d968:	add	x9, x9, #0x1
    d96c:	b.ls	d95c <__gmp_nextprime@@Base+0xac>  // b.plast
    d970:	str	x9, [x19, #16]
    d974:	add	x9, x24, #0x403
    d978:	lsr	x9, x9, #1
    d97c:	umulh	x10, x9, x22
    d980:	lsr	x11, x10, #1
    d984:	lsl	x11, x11, #1
    d988:	add	x10, x11, x10, lsr #1
    d98c:	subs	x9, x9, x10
    d990:	eor	x9, x9, #0x3
    d994:	csel	x9, xzr, x9, eq  // eq = none
    d998:	add	x8, x8, x9, lsl #1
    d99c:	add	x10, x9, #0x3
    d9a0:	cmp	x8, #0x4
    d9a4:	csel	x8, x10, x9, cc  // cc = lo, ul, last
    d9a8:	add	x8, x19, x8
    d9ac:	add	x8, x8, #0x18
    d9b0:	strb	w23, [x8], #3
    d9b4:	cmp	x8, x21
    d9b8:	b.cc	d9b0 <__gmp_nextprime@@Base+0x100>  // b.lo, b.ul, b.last
    d9bc:	ldr	x8, [x19, #8]
    d9c0:	mov	x10, #0xcccccccccccccccc    	// #-3689348814741910324
    d9c4:	movk	x10, #0xcccd
    d9c8:	add	x9, x8, #0x5
    d9cc:	lsr	x9, x9, #1
    d9d0:	umulh	x10, x9, x10
    d9d4:	lsr	x11, x10, #2
    d9d8:	lsl	x11, x11, #2
    d9dc:	add	x10, x11, x10, lsr #2
    d9e0:	subs	x9, x9, x10
    d9e4:	sub	x9, x25, x9
    d9e8:	csel	x9, xzr, x9, eq  // eq = none
    d9ec:	add	x10, x8, x9, lsl #1
    d9f0:	add	x11, x9, #0x5
    d9f4:	cmp	x10, #0x6
    d9f8:	csel	x9, x11, x9, cc  // cc = lo, ul, last
    d9fc:	cmp	x9, #0x1ff
    da00:	b.gt	da1c <__gmp_nextprime@@Base+0x16c>
    da04:	add	x8, x19, x9
    da08:	add	x8, x8, #0x18
    da0c:	strb	w23, [x8], #5
    da10:	cmp	x8, x21
    da14:	b.cc	da0c <__gmp_nextprime@@Base+0x15c>  // b.lo, b.ul, b.last
    da18:	ldr	x8, [x19, #8]
    da1c:	add	x9, x8, #0x7
    da20:	lsr	x10, x9, #1
    da24:	umulh	x11, x10, x26
    da28:	sub	x10, x10, x11
    da2c:	add	x10, x11, x10, lsr #1
    da30:	lsr	x10, x10, #2
    da34:	sub	x10, x10, x10, lsl #3
    da38:	add	x9, x10, x9, lsr #1
    da3c:	eor	x10, x9, #0x7
    da40:	cmp	x9, #0x0
    da44:	csel	x9, xzr, x10, eq  // eq = none
    da48:	add	x8, x8, x9, lsl #1
    da4c:	add	x10, x9, #0x7
    da50:	cmp	x8, #0x8
    da54:	csel	x8, x10, x9, cc  // cc = lo, ul, last
    da58:	add	x8, x19, x8
    da5c:	add	x8, x8, #0x18
    da60:	strb	w23, [x8], #7
    da64:	cmp	x8, x21
    da68:	b.cc	da60 <__gmp_nextprime@@Base+0x1b0>  // b.lo, b.ul, b.last
    da6c:	ldr	x9, [x19, #16]
    da70:	cmp	x9, #0xb
    da74:	b.cc	daf4 <__gmp_nextprime@@Base+0x244>  // b.lo, b.ul, b.last
    da78:	mov	x10, xzr
    da7c:	mov	w8, #0xb                   	// #11
    da80:	ldr	x11, [x19, #8]
    da84:	add	x12, x11, x8
    da88:	lsr	x12, x12, #1
    da8c:	udiv	x13, x12, x8
    da90:	msub	x12, x13, x8, x12
    da94:	sub	x13, x8, x12
    da98:	cmp	x12, #0x0
    da9c:	csel	x12, xzr, x13, eq  // eq = none
    daa0:	add	x11, x11, x12, lsl #1
    daa4:	cmp	x11, x8
    daa8:	csel	x11, xzr, x8, hi  // hi = pmore
    daac:	add	x11, x11, x12
    dab0:	cmp	x11, #0x1ff
    dab4:	b.gt	dad4 <__gmp_nextprime@@Base+0x224>
    dab8:	add	x9, x19, x11
    dabc:	add	x9, x9, #0x18
    dac0:	strb	w23, [x9]
    dac4:	add	x9, x9, x8
    dac8:	cmp	x9, x21
    dacc:	b.cc	dac0 <__gmp_nextprime@@Base+0x210>  // b.lo, b.ul, b.last
    dad0:	ldr	x9, [x19, #16]
    dad4:	ldrb	w11, [x27, x10]
    dad8:	add	x10, x10, #0x1
    dadc:	umulh	x12, x10, x22
    dae0:	add	x8, x8, x11
    dae4:	lsr	x11, x12, #5
    dae8:	cmp	x8, x9
    daec:	msub	x10, x11, x28, x10
    daf0:	b.ls	da80 <__gmp_nextprime@@Base+0x1d0>  // b.plast
    daf4:	mov	x8, xzr
    daf8:	str	xzr, [x19]
    dafc:	b	d908 <__gmp_nextprime@@Base+0x58>
    db00:	ldr	x9, [x19, #8]
    db04:	add	x8, x19, x8
    db08:	sub	x8, x8, x20
    db0c:	add	x10, x8, #0x18
    db10:	add	x8, x9, x8, lsl #1
    db14:	add	x0, x8, #0x2e
    db18:	str	x10, [x19]
    db1c:	b	db2c <__gmp_nextprime@@Base+0x27c>
    db20:	mov	x8, #0xfffffffffffffc03    	// #-1021
    db24:	str	x8, [x19, #8]
    db28:	mov	w0, #0x2                   	// #2
    db2c:	ldp	x20, x19, [sp, #80]
    db30:	ldp	x22, x21, [sp, #64]
    db34:	ldp	x24, x23, [sp, #48]
    db38:	ldp	x26, x25, [sp, #32]
    db3c:	ldp	x28, x27, [sp, #16]
    db40:	ldp	x29, x30, [sp], #96
    db44:	ret

000000000000db48 <__gmp_init_primesieve@@Base>:
    db48:	mov	w8, #0x200                 	// #512
    db4c:	stp	xzr, xzr, [x0, #8]
    db50:	str	x8, [x0]
    db54:	strb	wzr, [x0, #536]
    db58:	ret

000000000000db5c <__gmp_primesieve@@Base>:
    db5c:	stp	x29, x30, [sp, #-96]!
    db60:	sub	x8, x1, #0x5
    db64:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
    db68:	movk	x9, #0xaaab
    db6c:	orr	x8, x8, #0x1
    db70:	umulh	x9, x8, x9
    db74:	stp	x22, x21, [sp, #64]
    db78:	lsr	x22, x9, #7
    db7c:	stp	x24, x23, [sp, #48]
    db80:	stp	x20, x19, [sp, #80]
    db84:	mov	x19, x0
    db88:	lsr	x23, x9, #1
    db8c:	cmp	x8, #0xc0, lsl #12
    db90:	add	x20, x22, #0x1
    db94:	stp	x28, x27, [sp, #16]
    db98:	stp	x26, x25, [sp, #32]
    db9c:	mov	x29, sp
    dba0:	b.cc	dd50 <__gmp_primesieve@@Base+0x1f4>  // b.lo, b.ul, b.last
    dba4:	mov	w24, #0x800                 	// #2048
    dba8:	bfxil	x24, x20, #0, #11
    dbac:	add	x8, x24, x24, lsl #1
    dbb0:	mov	w1, #0x1                   	// #1
    dbb4:	bfi	x1, x8, #6, #14
    dbb8:	mov	x0, x19
    dbbc:	mov	w25, #0x1                   	// #1
    dbc0:	bl	dda8 <__gmp_primesieve@@Base+0x24c>
    dbc4:	mov	w26, #0x1ffff               	// #131071
    dbc8:	mov	w27, #0x40                  	// #64
    dbcc:	add	x21, x19, x24, lsl #3
    dbd0:	lsl	x28, x24, #6
    dbd4:	sub	x2, x28, #0x40
    dbd8:	mov	w1, #0x800                 	// #2048
    dbdc:	mov	x0, x21
    dbe0:	bl	df4c <__gmp_primesieve@@Base+0x3f0>
    dbe4:	mov	x8, xzr
    dbe8:	add	x9, x26, x24, lsl #6
    dbec:	mov	w12, #0x4                   	// #4
    dbf0:	mov	w10, #0x10                  	// #16
    dbf4:	ldr	x11, [x19, x8, lsl #3]
    dbf8:	tst	x11, x10
    dbfc:	add	x11, x12, #0x1
    dc00:	b.ne	dd2c <__gmp_primesieve@@Base+0x1d0>  // b.any
    dc04:	add	x14, x11, x11, lsl #1
    dc08:	and	x15, x11, #0x1
    dc0c:	add	x13, x12, #0x2
    dc10:	add	x12, x14, x15
    dc14:	neg	x16, x15
    dc18:	add	x17, x12, #0x2
    dc1c:	and	x13, x13, x16
    dc20:	madd	x13, x17, x11, x13
    dc24:	sub	x16, x13, #0x1
    dc28:	cmp	x16, x9
    dc2c:	b.gt	dd40 <__gmp_primesieve@@Base+0x1e4>
    dc30:	add	x12, x12, #0x1
    dc34:	lsl	x12, x12, #1
    dc38:	add	x13, x12, #0x3f
    dc3c:	cmp	x12, #0x0
    dc40:	csel	x13, x13, x12, lt  // lt = tstop
    dc44:	and	x13, x13, #0xffffffffffffffc0
    dc48:	cmp	x16, x28
    dc4c:	sub	x13, x12, x13
    dc50:	b.ge	dc68 <__gmp_primesieve@@Base+0x10c>  // b.tcont
    dc54:	mvn	x17, x16
    dc58:	add	x17, x28, x17
    dc5c:	sdiv	x17, x17, x12
    dc60:	add	x17, x17, #0x1
    dc64:	madd	x16, x17, x12, x16
    dc68:	sub	x16, x16, x28
    dc6c:	cmp	x16, #0x20, lsl #12
    dc70:	b.ge	dcb8 <__gmp_primesieve@@Base+0x15c>  // b.tcont
    dc74:	sub	w0, w27, w13
    dc78:	lsl	x17, x25, x16
    dc7c:	and	x18, x13, #0xfffffffe
    dc80:	and	x0, x0, #0xfffffffe
    dc84:	add	x1, x16, #0x3f
    dc88:	cmp	x16, #0x0
    dc8c:	csel	x1, x1, x16, lt  // lt = tstop
    dc90:	asr	x1, x1, #6
    dc94:	ldr	x3, [x21, x1, lsl #3]
    dc98:	lsl	x2, x17, x18
    dc9c:	lsr	x4, x17, x0
    dca0:	add	x16, x16, x12
    dca4:	orr	x17, x3, x17
    dca8:	cmp	x16, #0x20, lsl #12
    dcac:	str	x17, [x21, x1, lsl #3]
    dcb0:	orr	x17, x2, x4
    dcb4:	b.lt	dc84 <__gmp_primesieve@@Base+0x128>  // b.tstop
    dcb8:	add	x14, x14, #0x6
    dcbc:	madd	x14, x14, x11, x15
    dcc0:	cmp	x14, x28
    dcc4:	b.ge	dcdc <__gmp_primesieve@@Base+0x180>  // b.tcont
    dcc8:	mvn	x15, x14
    dccc:	add	x15, x28, x15
    dcd0:	sdiv	x15, x15, x12
    dcd4:	add	x15, x15, #0x1
    dcd8:	madd	x14, x15, x12, x14
    dcdc:	sub	x14, x14, x28
    dce0:	cmp	x14, #0x20, lsl #12
    dce4:	b.ge	dd2c <__gmp_primesieve@@Base+0x1d0>  // b.tcont
    dce8:	and	x16, x13, #0xfffffffe
    dcec:	sub	w13, w27, w13
    dcf0:	lsl	x15, x25, x14
    dcf4:	and	x13, x13, #0xfffffffe
    dcf8:	add	x17, x14, #0x3f
    dcfc:	cmp	x14, #0x0
    dd00:	csel	x17, x17, x14, lt  // lt = tstop
    dd04:	asr	x17, x17, #6
    dd08:	ldr	x0, [x21, x17, lsl #3]
    dd0c:	lsl	x18, x15, x16
    dd10:	lsr	x1, x15, x13
    dd14:	add	x14, x14, x12
    dd18:	orr	x15, x0, x15
    dd1c:	cmp	x14, #0x20, lsl #12
    dd20:	str	x15, [x21, x17, lsl #3]
    dd24:	orr	x15, x18, x1
    dd28:	b.lt	dcf8 <__gmp_primesieve@@Base+0x19c>  // b.tstop
    dd2c:	ror	x13, x10, #63
    dd30:	add	x8, x8, x10, lsr #63
    dd34:	mov	x12, x11
    dd38:	mov	x10, x13
    dd3c:	b	dbf4 <__gmp_primesieve@@Base+0x98>
    dd40:	add	x24, x24, #0x800
    dd44:	cmp	x24, x22
    dd48:	b.ls	dbcc <__gmp_primesieve@@Base+0x70>  // b.plast
    dd4c:	b	dd58 <__gmp_primesieve@@Base+0x1fc>
    dd50:	mov	x0, x19
    dd54:	bl	dda8 <__gmp_primesieve@@Base+0x24c>
    dd58:	add	w8, w23, #0x1
    dd5c:	ands	x8, x8, #0x3f
    dd60:	b.eq	dd78 <__gmp_primesieve@@Base+0x21c>  // b.none
    dd64:	ldr	x9, [x19, x22, lsl #3]
    dd68:	mov	x10, #0xffffffffffffffff    	// #-1
    dd6c:	lsl	x8, x10, x8
    dd70:	orr	x8, x9, x8
    dd74:	str	x8, [x19, x22, lsl #3]
    dd78:	mov	x0, x19
    dd7c:	mov	x1, x20
    dd80:	lsl	x21, x20, #6
    dd84:	bl	cda0 <__gmpn_popcount@plt>
    dd88:	sub	x0, x21, x0
    dd8c:	ldp	x20, x19, [sp, #80]
    dd90:	ldp	x22, x21, [sp, #64]
    dd94:	ldp	x24, x23, [sp, #48]
    dd98:	ldp	x26, x25, [sp, #32]
    dd9c:	ldp	x28, x27, [sp, #16]
    dda0:	ldp	x29, x30, [sp], #96
    dda4:	ret
    dda8:	stp	x29, x30, [sp, #-48]!
    ddac:	sub	x8, x1, #0x5
    ddb0:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
    ddb4:	movk	x9, #0xaaab
    ddb8:	orr	x10, x8, #0x1
    ddbc:	umulh	x8, x8, x9
    ddc0:	umulh	x9, x10, x9
    ddc4:	stp	x22, x21, [sp, #16]
    ddc8:	stp	x20, x19, [sp, #32]
    ddcc:	mov	x20, x1
    ddd0:	mov	x19, x0
    ddd4:	cmp	x10, #0xc0
    ddd8:	lsr	x22, x9, #1
    dddc:	lsr	x21, x8, #7
    dde0:	mov	x29, sp
    dde4:	b.cc	ddf8 <__gmp_primesieve@@Base+0x29c>  // b.lo, b.ul, b.last
    dde8:	add	x0, x19, #0x8
    ddec:	mov	x1, x21
    ddf0:	mov	x2, xzr
    ddf4:	bl	df4c <__gmp_primesieve@@Base+0x3f0>
    ddf8:	mov	x9, #0x8480                	// #33920
    ddfc:	movk	x9, #0x6912, lsl #16
    de00:	movk	x9, #0xc9e0, lsl #32
    de04:	add	w8, w22, #0x1
    de08:	movk	x9, #0x3294, lsl #48
    de0c:	ands	x8, x8, #0x3f
    de10:	str	x9, [x19]
    de14:	b.eq	de2c <__gmp_primesieve@@Base+0x2d0>  // b.none
    de18:	ldr	x9, [x19, x21, lsl #3]
    de1c:	mov	x10, #0xffffffffffffffff    	// #-1
    de20:	lsl	x8, x10, x8
    de24:	orr	x8, x9, x8
    de28:	str	x8, [x19, x21, lsl #3]
    de2c:	cmp	x20, #0xd3
    de30:	b.cc	df3c <__gmp_primesieve@@Base+0x3e0>  // b.lo, b.ul, b.last
    de34:	mov	x8, xzr
    de38:	mov	w13, #0x4                   	// #4
    de3c:	mov	w10, #0x10                  	// #16
    de40:	mov	w9, #0x1                   	// #1
    de44:	mov	w11, #0x40                  	// #64
    de48:	ldr	x12, [x19, x8, lsl #3]
    de4c:	tst	x12, x10
    de50:	add	x12, x13, #0x1
    de54:	b.ne	df28 <__gmp_primesieve@@Base+0x3cc>  // b.any
    de58:	add	x16, x12, x12, lsl #1
    de5c:	and	x17, x12, #0x1
    de60:	add	x14, x13, #0x2
    de64:	add	x13, x16, x17
    de68:	neg	x15, x17
    de6c:	add	x18, x13, #0x2
    de70:	and	x14, x14, x15
    de74:	madd	x14, x18, x12, x14
    de78:	sub	x18, x14, #0x1
    de7c:	cmp	x18, x22
    de80:	b.gt	df3c <__gmp_primesieve@@Base+0x3e0>
    de84:	add	x13, x13, #0x1
    de88:	lsl	x13, x13, #1
    de8c:	add	x14, x13, #0x3f
    de90:	cmp	x13, #0x0
    de94:	csel	x14, x14, x13, lt  // lt = tstop
    de98:	and	x14, x14, #0xffffffffffffffc0
    de9c:	sub	x15, x13, x14
    dea0:	lsl	x0, x9, x18
    dea4:	and	x14, x15, #0xfffffffe
    dea8:	sub	w15, w11, w15
    deac:	add	x1, x18, #0x3f
    deb0:	cmp	x18, #0x0
    deb4:	csel	x1, x1, x18, lt  // lt = tstop
    deb8:	asr	x1, x1, #6
    debc:	ldr	x3, [x19, x1, lsl #3]
    dec0:	lsl	x2, x0, x14
    dec4:	lsr	x4, x0, x15
    dec8:	add	x18, x18, x13
    decc:	orr	x0, x3, x0
    ded0:	cmp	x18, x22
    ded4:	str	x0, [x19, x1, lsl #3]
    ded8:	orr	x0, x2, x4
    dedc:	b.le	deac <__gmp_primesieve@@Base+0x350>
    dee0:	add	x16, x16, #0x6
    dee4:	madd	x16, x16, x12, x17
    dee8:	cmp	x16, x22
    deec:	b.gt	df28 <__gmp_primesieve@@Base+0x3cc>
    def0:	lsl	x17, x9, x16
    def4:	add	x18, x16, #0x3f
    def8:	cmp	x16, #0x0
    defc:	csel	x18, x18, x16, lt  // lt = tstop
    df00:	asr	x18, x18, #6
    df04:	ldr	x1, [x19, x18, lsl #3]
    df08:	lsl	x0, x17, x14
    df0c:	lsr	x2, x17, x15
    df10:	add	x16, x16, x13
    df14:	orr	x17, x1, x17
    df18:	cmp	x16, x22
    df1c:	str	x17, [x19, x18, lsl #3]
    df20:	orr	x17, x0, x2
    df24:	b.le	def4 <__gmp_primesieve@@Base+0x398>
    df28:	ror	x13, x10, #63
    df2c:	add	x8, x8, x10, lsr #63
    df30:	mov	x10, x13
    df34:	mov	x13, x12
    df38:	b	de48 <__gmp_primesieve@@Base+0x2ec>
    df3c:	ldp	x20, x19, [sp, #32]
    df40:	ldp	x22, x21, [sp, #16]
    df44:	ldp	x29, x30, [sp], #48
    df48:	ret
    df4c:	mov	x11, #0x184                 	// #388
    df50:	mov	x8, #0x2058                	// #8280
    df54:	mov	x13, #0x2120                	// #8480
    df58:	movk	x11, #0x4023, lsl #16
    df5c:	movk	x8, #0x489, lsl #16
    df60:	movk	x13, #0x8840, lsl #16
    df64:	mov	x10, #0x4421                	// #17441
    df68:	mov	x9, #0x1244                	// #4676
    df6c:	movk	x11, #0x180c, lsl #32
    df70:	movk	x8, #0x4a12, lsl #32
    df74:	movk	x13, #0x210, lsl #32
    df78:	movk	x10, #0x1008, lsl #16
    df7c:	movk	x9, #0x3068, lsl #16
    df80:	movk	x11, #0x9402, lsl #48
    df84:	movk	x8, #0x8121, lsl #48
    df88:	movk	x13, #0x285, lsl #48
    df8c:	movk	x10, #0xa412, lsl #32
    df90:	movk	x9, #0xc81, lsl #32
    df94:	cbz	x2, e0b0 <__gmp_primesieve@@Base+0x554>
    df98:	mov	x14, #0x7905                	// #30981
    df9c:	movk	x14, #0x904a, lsl #16
    dfa0:	movk	x14, #0x4a7, lsl #32
    dfa4:	lsr	x12, x2, #1
    dfa8:	movk	x14, #0x4a79, lsl #48
    dfac:	umulh	x14, x12, x14
    dfb0:	lsr	x14, x14, #4
    dfb4:	mov	w15, #0x6e                  	// #110
    dfb8:	msub	x14, x14, x15, x2
    dfbc:	cbz	x14, e03c <__gmp_primesieve@@Base+0x4e0>
    dfc0:	cmp	x14, #0x3f
    dfc4:	b.hi	dffc <__gmp_primesieve@@Base+0x4a0>  // b.pmore
    dfc8:	neg	x16, x14
    dfcc:	lsr	x15, x8, x14
    dfd0:	lsl	x17, x9, x16
    dfd4:	subs	x16, x14, #0x2e
    dfd8:	orr	x15, x17, x15
    dfdc:	b.hi	e024 <__gmp_primesieve@@Base+0x4c8>  // b.pmore
    dfe0:	mov	w16, #0x2e                  	// #46
    dfe4:	sub	x16, x16, x14
    dfe8:	lsl	x8, x8, x16
    dfec:	lsr	x9, x9, x14
    dff0:	orr	x9, x8, x9
    dff4:	mov	x8, x15
    dff8:	b	e03c <__gmp_primesieve@@Base+0x4e0>
    dffc:	mov	w15, #0x6e                  	// #110
    e000:	lsr	x16, x9, x14
    e004:	sub	x17, x14, #0x2e
    e008:	sub	x14, x15, x14
    e00c:	lsr	x15, x8, x17
    e010:	lsl	x8, x8, x14
    e014:	lsl	x9, x9, x14
    e018:	orr	x8, x8, x16
    e01c:	orr	x9, x9, x15
    e020:	b	e03c <__gmp_primesieve@@Base+0x4e0>
    e024:	mov	w9, #0x6e                  	// #110
    e028:	sub	x9, x9, x14
    e02c:	lsl	x9, x8, x9
    e030:	orr	x14, x15, x9
    e034:	lsr	x9, x8, x16
    e038:	mov	x8, x14
    e03c:	mov	x14, #0x2d03                	// #11523
    e040:	movk	x14, #0x2d0, lsl #16
    e044:	movk	x14, #0xd02d, lsl #32
    e048:	movk	x14, #0x2d02, lsl #48
    e04c:	umulh	x12, x12, x14
    e050:	lsr	x12, x12, #4
    e054:	mov	w14, #0xb6                  	// #182
    e058:	msub	x15, x12, x14, x2
    e05c:	cbz	x15, e0b0 <__gmp_primesieve@@Base+0x554>
    e060:	subs	x14, x15, #0x40
    e064:	b.hi	e118 <__gmp_primesieve@@Base+0x5bc>  // b.pmore
    e068:	neg	x12, x15
    e06c:	lsr	x14, x11, x15
    e070:	lsr	x16, x13, x15
    e074:	cmp	x15, #0x40
    e078:	lsl	x17, x13, x12
    e07c:	lsl	x18, x10, x12
    e080:	csel	x12, xzr, x14, eq  // eq = none
    e084:	csel	x14, xzr, x16, eq  // eq = none
    e088:	subs	x13, x15, #0x36
    e08c:	orr	x12, x17, x12
    e090:	orr	x14, x18, x14
    e094:	b.hi	e168 <__gmp_primesieve@@Base+0x60c>  // b.pmore
    e098:	mov	w13, #0x36                  	// #54
    e09c:	sub	x13, x13, x15
    e0a0:	lsl	x11, x11, x13
    e0a4:	lsr	x10, x10, x15
    e0a8:	orr	x10, x11, x10
    e0ac:	b	e0d0 <__gmp_primesieve@@Base+0x574>
    e0b0:	mov	x12, #0x184                 	// #388
    e0b4:	mov	x14, #0x2120                	// #8480
    e0b8:	movk	x12, #0x4023, lsl #16
    e0bc:	movk	x14, #0x8840, lsl #16
    e0c0:	movk	x12, #0x180c, lsl #32
    e0c4:	movk	x14, #0x210, lsl #32
    e0c8:	movk	x12, #0x9402, lsl #48
    e0cc:	movk	x14, #0x285, lsl #48
    e0d0:	orr	x11, x12, x8
    e0d4:	cmp	x1, #0x1
    e0d8:	str	x11, [x0]
    e0dc:	b.eq	e114 <__gmp_primesieve@@Base+0x5b8>  // b.none
    e0e0:	orr	x11, x9, x8, lsl #46
    e0e4:	extr	x8, x9, x8, #18
    e0e8:	lsr	x13, x14, #10
    e0ec:	orr	x9, x14, x11
    e0f0:	lsr	x11, x11, #18
    e0f4:	subs	x1, x1, #0x2
    e0f8:	extr	x14, x14, x12, #10
    e0fc:	orr	x12, x10, x12, lsl #54
    e100:	str	x9, [x0, #8]
    e104:	add	x0, x0, #0x10
    e108:	mov	x9, x11
    e10c:	mov	x10, x13
    e110:	b.ne	e0d0 <__gmp_primesieve@@Base+0x574>  // b.any
    e114:	ret
    e118:	cmp	x15, #0x7f
    e11c:	b.hi	e180 <__gmp_primesieve@@Base+0x624>  // b.pmore
    e120:	neg	x16, x15
    e124:	lsr	x12, x13, x15
    e128:	lsl	x17, x10, x16
    e12c:	subs	x16, x15, #0x76
    e130:	orr	x12, x12, x17
    e134:	b.hi	e1b4 <__gmp_primesieve@@Base+0x658>  // b.pmore
    e138:	lsr	x10, x10, x14
    e13c:	mov	w14, #0x76                  	// #118
    e140:	sub	x16, x14, x15
    e144:	lsl	x14, x11, x16
    e148:	cmp	x15, #0x76
    e14c:	orr	x14, x10, x14
    e150:	lsl	x10, x13, x16
    e154:	b.eq	e0d0 <__gmp_primesieve@@Base+0x574>  // b.none
    e158:	sub	x13, x15, #0x36
    e15c:	lsr	x11, x11, x13
    e160:	orr	x10, x10, x11
    e164:	b	e0d0 <__gmp_primesieve@@Base+0x574>
    e168:	mov	w10, #0x76                  	// #118
    e16c:	sub	x10, x10, x15
    e170:	lsl	x10, x11, x10
    e174:	orr	x14, x14, x10
    e178:	lsr	x10, x11, x13
    e17c:	b	e0d0 <__gmp_primesieve@@Base+0x574>
    e180:	mov	w12, #0xb6                  	// #182
    e184:	sub	x16, x15, #0x76
    e188:	sub	x12, x12, x15
    e18c:	lsr	x14, x10, x15
    e190:	lsr	x15, x11, x16
    e194:	lsr	x16, x13, x16
    e198:	lsl	x11, x11, x12
    e19c:	lsl	x13, x13, x12
    e1a0:	lsl	x10, x10, x12
    e1a4:	orr	x12, x11, x14
    e1a8:	orr	x14, x13, x15
    e1ac:	orr	x10, x10, x16
    e1b0:	b	e0d0 <__gmp_primesieve@@Base+0x574>
    e1b4:	mov	w10, #0xb6                  	// #182
    e1b8:	sub	x10, x10, x15
    e1bc:	lsr	x14, x11, x16
    e1c0:	lsl	x11, x11, x10
    e1c4:	lsl	x10, x13, x10
    e1c8:	orr	x12, x12, x11
    e1cc:	orr	x14, x10, x14
    e1d0:	lsr	x10, x13, x16
    e1d4:	b	e0d0 <__gmp_primesieve@@Base+0x574>

000000000000e1d8 <__gmp_tmp_reentrant_alloc@@Base>:
    e1d8:	stp	x29, x30, [sp, #-32]!
    e1dc:	stp	x20, x19, [sp, #16]
    e1e0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    e1e4:	ldr	x8, [x8, #3840]
    e1e8:	add	x20, x1, #0x10
    e1ec:	mov	x19, x0
    e1f0:	mov	x0, x20
    e1f4:	ldr	x8, [x8]
    e1f8:	mov	x29, sp
    e1fc:	blr	x8
    e200:	str	x20, [x0, #8]
    e204:	ldr	x9, [x19]
    e208:	add	x8, x0, #0x10
    e20c:	str	x9, [x0]
    e210:	str	x0, [x19]
    e214:	ldp	x20, x19, [sp, #16]
    e218:	mov	x0, x8
    e21c:	ldp	x29, x30, [sp], #32
    e220:	ret

000000000000e224 <__gmp_tmp_reentrant_free@@Base>:
    e224:	stp	x29, x30, [sp, #-32]!
    e228:	stp	x20, x19, [sp, #16]
    e22c:	mov	x29, sp
    e230:	cbz	x0, e250 <__gmp_tmp_reentrant_free@@Base+0x2c>
    e234:	adrp	x19, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    e238:	ldr	x19, [x19, #4016]
    e23c:	ldr	x8, [x19]
    e240:	ldp	x20, x1, [x0]
    e244:	blr	x8
    e248:	mov	x0, x20
    e24c:	cbnz	x20, e23c <__gmp_tmp_reentrant_free@@Base+0x18>
    e250:	ldp	x20, x19, [sp, #16]
    e254:	ldp	x29, x30, [sp], #32
    e258:	ret

000000000000e25c <__gmpf_init@@Base>:
    e25c:	stp	x29, x30, [sp, #-32]!
    e260:	str	x19, [sp, #16]
    e264:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    e268:	ldr	x8, [x8, #3960]
    e26c:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    e270:	mov	x19, x0
    e274:	mov	x29, sp
    e278:	ldr	x8, [x8]
    e27c:	str	xzr, [x0, #8]
    e280:	stp	w8, wzr, [x0]
    e284:	ldr	x9, [x9, #3840]
    e288:	lsl	x8, x8, #3
    e28c:	add	x0, x8, #0x8
    e290:	ldr	x9, [x9]
    e294:	blr	x9
    e298:	str	x0, [x19, #16]
    e29c:	ldr	x19, [sp, #16]
    e2a0:	ldp	x29, x30, [sp], #32
    e2a4:	ret

000000000000e2a8 <__gmpf_init2@@Base>:
    e2a8:	stp	x29, x30, [sp, #-32]!
    e2ac:	cmp	x1, #0x35
    e2b0:	mov	w8, #0x35                  	// #53
    e2b4:	csel	x8, x1, x8, hi  // hi = pmore
    e2b8:	add	x8, x8, #0x7f
    e2bc:	lsr	x8, x8, #6
    e2c0:	str	x19, [sp, #16]
    e2c4:	str	xzr, [x0, #8]
    e2c8:	stp	w8, wzr, [x0]
    e2cc:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    e2d0:	ldr	x9, [x9, #3840]
    e2d4:	lsl	x8, x8, #3
    e2d8:	mov	x19, x0
    e2dc:	add	x0, x8, #0x8
    e2e0:	ldr	x9, [x9]
    e2e4:	mov	x29, sp
    e2e8:	blr	x9
    e2ec:	str	x0, [x19, #16]
    e2f0:	ldr	x19, [sp, #16]
    e2f4:	ldp	x29, x30, [sp], #32
    e2f8:	ret

000000000000e2fc <__gmpf_inits@@Base>:
    e2fc:	sub	sp, sp, #0xf0
    e300:	stp	x29, x30, [sp, #224]
    e304:	add	x29, sp, #0xe0
    e308:	mov	x8, #0xffffffffffffffc8    	// #-56
    e30c:	mov	x9, sp
    e310:	sub	x10, x29, #0x58
    e314:	movk	x8, #0xff80, lsl #32
    e318:	add	x11, x29, #0x10
    e31c:	add	x9, x9, #0x80
    e320:	add	x10, x10, #0x38
    e324:	stp	x1, x2, [x29, #-88]
    e328:	stp	x3, x4, [x29, #-72]
    e32c:	stp	x5, x6, [x29, #-56]
    e330:	stur	x7, [x29, #-40]
    e334:	stp	q0, q1, [sp]
    e338:	stp	q2, q3, [sp, #32]
    e33c:	stp	q4, q5, [sp, #64]
    e340:	stp	q6, q7, [sp, #96]
    e344:	stp	x9, x8, [x29, #-16]
    e348:	stp	x11, x10, [x29, #-32]
    e34c:	bl	ce80 <__gmpf_init@plt>
    e350:	ldursw	x8, [x29, #-8]
    e354:	tbz	w8, #31, e374 <__gmpf_inits@@Base+0x78>
    e358:	add	w9, w8, #0x8
    e35c:	cmn	w8, #0x8
    e360:	stur	w9, [x29, #-8]
    e364:	b.gt	e374 <__gmpf_inits@@Base+0x78>
    e368:	ldur	x9, [x29, #-24]
    e36c:	add	x8, x9, x8
    e370:	b	e380 <__gmpf_inits@@Base+0x84>
    e374:	ldur	x8, [x29, #-32]
    e378:	add	x9, x8, #0x8
    e37c:	stur	x9, [x29, #-32]
    e380:	ldr	x0, [x8]
    e384:	cbnz	x0, e34c <__gmpf_inits@@Base+0x50>
    e388:	ldp	x29, x30, [sp, #224]
    e38c:	add	sp, sp, #0xf0
    e390:	ret

000000000000e394 <__gmpf_set@@Base>:
    e394:	ldrsw	x10, [x1, #4]
    e398:	ldrsw	x9, [x0]
    e39c:	ldp	x12, x11, [x1, #8]
    e3a0:	ldr	x8, [x0, #16]
    e3a4:	cmp	x10, #0x0
    e3a8:	add	x13, x9, #0x1
    e3ac:	str	x12, [x0, #8]
    e3b0:	cneg	x12, x10, mi  // mi = first
    e3b4:	subs	x13, x12, x13
    e3b8:	add	x13, x11, x13, lsl #3
    e3bc:	csinc	x2, x12, x9, le
    e3c0:	csel	x1, x13, x11, gt
    e3c4:	neg	w9, w2
    e3c8:	cmp	w10, #0x0
    e3cc:	csel	x9, x2, x9, ge  // ge = tcont
    e3d0:	str	w9, [x0, #4]
    e3d4:	mov	x0, x8
    e3d8:	b	ca70 <__gmpn_copyi@plt>

000000000000e3dc <__gmpf_set_ui@@Base>:
    e3dc:	ldr	x8, [x0, #16]
    e3e0:	cmp	x1, #0x0
    e3e4:	cset	w9, ne  // ne = any
    e3e8:	str	x1, [x8]
    e3ec:	str	w9, [x0, #4]
    e3f0:	str	x9, [x0, #8]
    e3f4:	ret

000000000000e3f8 <__gmpf_set_si@@Base>:
    e3f8:	ldr	x8, [x0, #16]
    e3fc:	cmp	x1, #0x0
    e400:	cset	w10, ne  // ne = any
    e404:	csetm	x11, ne  // ne = any
    e408:	cneg	x9, x1, mi  // mi = first
    e40c:	csel	x11, x10, x11, ge  // ge = tcont
    e410:	str	x9, [x8]
    e414:	str	x10, [x0, #8]
    e418:	str	w11, [x0, #4]
    e41c:	ret

000000000000e420 <__gmpf_set_str@@Base>:
    e420:	stp	x29, x30, [sp, #-96]!
    e424:	stp	x28, x27, [sp, #16]
    e428:	stp	x26, x25, [sp, #32]
    e42c:	stp	x24, x23, [sp, #48]
    e430:	stp	x22, x21, [sp, #64]
    e434:	stp	x20, x19, [sp, #80]
    e438:	mov	x29, sp
    e43c:	sub	sp, sp, #0x40
    e440:	mov	x19, x0
    e444:	mov	w0, #0x10000               	// #65536
    e448:	mov	w22, w2
    e44c:	mov	x20, x1
    e450:	bl	c420 <nl_langinfo@plt>
    e454:	mov	x21, x0
    e458:	bl	bf70 <strlen@plt>
    e45c:	mov	x23, x0
    e460:	bl	cb00 <__ctype_b_loc@plt>
    e464:	ldr	x9, [x0]
    e468:	mov	x24, x0
    e46c:	ldrb	w8, [x20], #1
    e470:	ldrh	w10, [x9, x8, lsl #1]
    e474:	tbnz	w10, #13, e46c <__gmpf_set_str@@Base+0x4c>
    e478:	cmp	w8, #0x2d
    e47c:	b.ne	e48c <__gmpf_set_str@@Base+0x6c>  // b.any
    e480:	ldrb	w8, [x20]
    e484:	mov	w28, #0x1                   	// #1
    e488:	b	e494 <__gmpf_set_str@@Base+0x74>
    e48c:	mov	w28, wzr
    e490:	sub	x20, x20, #0x1
    e494:	cmp	w22, #0x0
    e498:	mov	w9, #0xa                   	// #10
    e49c:	adrp	x26, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    e4a0:	csel	w10, w9, w22, eq  // eq = none
    e4a4:	ldr	x26, [x26, #3920]
    e4a8:	cmp	w10, #0x0
    e4ac:	cneg	w22, w10, mi  // mi = first
    e4b0:	csel	w13, w9, w10, lt  // lt = tstop
    e4b4:	cmp	w22, #0x25
    e4b8:	b.lt	e4c8 <__gmpf_set_str@@Base+0xa8>  // b.tstop
    e4bc:	cmp	w22, #0x3e
    e4c0:	b.gt	e764 <__gmpf_set_str@@Base+0x344>
    e4c4:	add	x26, x26, #0xd0
    e4c8:	ldrb	w9, [x26, w8, uxtw]
    e4cc:	cmp	w22, w9
    e4d0:	b.gt	e51c <__gmpf_set_str@@Base+0xfc>
    e4d4:	cbz	x23, e50c <__gmpf_set_str@@Base+0xec>
    e4d8:	ldrb	w9, [x21]
    e4dc:	cmp	w8, w9
    e4e0:	b.ne	e764 <__gmpf_set_str@@Base+0x344>  // b.any
    e4e4:	add	x8, x21, #0x1
    e4e8:	sub	x9, x23, #0x1
    e4ec:	add	x10, x20, #0x1
    e4f0:	cbz	x9, e50c <__gmpf_set_str@@Base+0xec>
    e4f4:	ldrb	w11, [x10], #1
    e4f8:	ldrb	w12, [x8], #1
    e4fc:	sub	x9, x9, #0x1
    e500:	cmp	w11, w12
    e504:	b.eq	e4f0 <__gmpf_set_str@@Base+0xd0>  // b.none
    e508:	b	e764 <__gmpf_set_str@@Base+0x344>
    e50c:	ldrb	w8, [x20, x23]
    e510:	ldrb	w8, [x26, x8]
    e514:	cmp	w22, w8
    e518:	b.le	e764 <__gmpf_set_str@@Base+0x344>
    e51c:	mov	x0, x20
    e520:	stur	x13, [x29, #-32]
    e524:	stur	x19, [x29, #-16]
    e528:	bl	bf70 <strlen@plt>
    e52c:	mov	x25, x0
    e530:	mov	x9, x0
    e534:	subs	x8, x9, #0x1
    e538:	b.eq	e570 <__gmpf_set_str@@Base+0x150>  // b.none
    e53c:	add	x27, x20, x9
    e540:	ldurb	w10, [x27, #-1]
    e544:	cmp	w10, #0x40
    e548:	b.eq	e568 <__gmpf_set_str@@Base+0x148>  // b.none
    e54c:	cmp	w22, #0xa
    e550:	mov	x9, x8
    e554:	b.gt	e534 <__gmpf_set_str@@Base+0x114>
    e558:	orr	w9, w10, #0x20
    e55c:	cmp	w9, #0x65
    e560:	mov	x9, x8
    e564:	b.ne	e534 <__gmpf_set_str@@Base+0x114>  // b.any
    e568:	mov	x25, x8
    e56c:	b	e574 <__gmpf_set_str@@Base+0x154>
    e570:	mov	x27, xzr
    e574:	add	x1, x25, #0x1
    e578:	mov	w8, #0x7f01                	// #32513
    e57c:	cmp	x1, x8
    e580:	stur	xzr, [x29, #-8]
    e584:	stur	w28, [x29, #-20]
    e588:	b.cs	eb14 <__gmpf_set_str@@Base+0x6f4>  // b.hs, b.nlast
    e58c:	add	x9, x1, #0xf
    e590:	mov	x8, sp
    e594:	and	x9, x9, #0xfffffffffffffff0
    e598:	sub	x1, x8, x9
    e59c:	mov	sp, x1
    e5a0:	cbz	x25, e65c <__gmpf_set_str@@Base+0x23c>
    e5a4:	mov	x8, xzr
    e5a8:	mov	x19, xzr
    e5ac:	mov	w9, wzr
    e5b0:	mov	x0, xzr
    e5b4:	sub	x10, x23, #0x1
    e5b8:	add	x11, x21, #0x1
    e5bc:	mov	w12, #0x1                   	// #1
    e5c0:	mov	x28, x1
    e5c4:	ldrb	w13, [x20]
    e5c8:	ldr	x14, [x24]
    e5cc:	ldrh	w14, [x14, x13, lsl #1]
    e5d0:	tbnz	w14, #13, e648 <__gmpf_set_str@@Base+0x228>
    e5d4:	cbz	x23, e638 <__gmpf_set_str@@Base+0x218>
    e5d8:	ldrb	w14, [x21]
    e5dc:	cmp	w13, w14
    e5e0:	b.ne	e608 <__gmpf_set_str@@Base+0x1e8>  // b.any
    e5e4:	add	x14, x20, #0x1
    e5e8:	mov	x15, x10
    e5ec:	mov	x16, x11
    e5f0:	cbz	x15, e638 <__gmpf_set_str@@Base+0x218>
    e5f4:	ldrb	w17, [x14], #1
    e5f8:	ldrb	w18, [x16], #1
    e5fc:	sub	x15, x15, #0x1
    e600:	cmp	w17, w18
    e604:	b.eq	e5f0 <__gmpf_set_str@@Base+0x1d0>  // b.none
    e608:	ldrb	w13, [x26, x13]
    e60c:	cmp	w22, w13
    e610:	b.le	e75c <__gmpf_set_str@@Base+0x33c>
    e614:	cmp	w13, #0x0
    e618:	strb	w13, [x28]
    e61c:	cset	w13, ne  // ne = any
    e620:	orr	w9, w9, w13
    e624:	add	x28, x28, w9, sxtw
    e628:	cbz	x19, e648 <__gmpf_set_str@@Base+0x228>
    e62c:	sub	w13, w12, w9
    e630:	add	x0, x0, w13, sxtw
    e634:	b	e648 <__gmpf_set_str@@Base+0x228>
    e638:	cbnz	x19, e75c <__gmpf_set_str@@Base+0x33c>
    e63c:	add	x20, x20, x10
    e640:	add	x8, x8, x10
    e644:	mov	x19, x28
    e648:	add	x8, x8, #0x1
    e64c:	cmp	x8, x25
    e650:	add	x20, x20, #0x1
    e654:	b.cc	e5c4 <__gmpf_set_str@@Base+0x1a4>  // b.lo, b.ul, b.last
    e658:	b	e668 <__gmpf_set_str@@Base+0x248>
    e65c:	mov	x0, xzr
    e660:	mov	x19, xzr
    e664:	mov	x28, x1
    e668:	ldur	x25, [x29, #-16]
    e66c:	subs	x21, x28, x1
    e670:	b.eq	e76c <__gmpf_set_str@@Base+0x34c>  // b.none
    e674:	stur	x0, [x29, #-40]
    e678:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    e67c:	ldrsw	x8, [x25]
    e680:	ldr	x9, [x9, #3936]
    e684:	mov	w10, #0x28                  	// #40
    e688:	add	x20, x8, #0x1
    e68c:	umaddl	x9, w22, w10, x9
    e690:	ldr	x9, [x9, #16]
    e694:	umulh	x8, x9, x21
    e698:	and	x8, x8, #0x1ffffffffffffff8
    e69c:	mov	w9, #0x7ef0                	// #32496
    e6a0:	cmp	x8, x9
    e6a4:	add	x8, x8, #0x10
    e6a8:	b.hi	eb34 <__gmpf_set_str@@Base+0x714>  // b.pmore
    e6ac:	add	x8, x8, #0xf
    e6b0:	mov	x9, sp
    e6b4:	and	x8, x8, #0x7ffffffffffffff0
    e6b8:	sub	x23, x9, x8
    e6bc:	mov	sp, x23
    e6c0:	mov	x0, x23
    e6c4:	mov	x2, x21
    e6c8:	mov	w3, w22
    e6cc:	bl	c0a0 <__gmpn_set_str@plt>
    e6d0:	subs	x8, x0, x20
    e6d4:	add	x9, x23, x8, lsl #3
    e6d8:	mov	x24, x0
    e6dc:	csel	x2, x20, x0, gt
    e6e0:	csel	x23, x9, x23, gt
    e6e4:	csel	x21, x8, xzr, gt
    e6e8:	cbz	x27, e778 <__gmpf_set_str@@Base+0x358>
    e6ec:	ldrb	w9, [x27]
    e6f0:	ldur	x13, [x29, #-32]
    e6f4:	cmp	w9, #0x2d
    e6f8:	cset	w10, eq  // eq = none
    e6fc:	csetm	x8, eq  // eq = none
    e700:	cmp	w9, #0x2b
    e704:	cset	w9, eq  // eq = none
    e708:	orr	w12, w10, w9
    e70c:	add	x10, x27, x12
    e710:	ldrb	w9, [x10]
    e714:	ldrb	w9, [x26, x9]
    e718:	cmp	x9, w13, sxtw
    e71c:	b.ge	e75c <__gmpf_set_str@@Base+0x33c>  // b.tcont
    e720:	ldrb	w10, [x10, #1]
    e724:	ldrb	w11, [x26, x10]
    e728:	sxtw	x10, w13
    e72c:	cmp	x11, x10
    e730:	b.ge	e750 <__gmpf_set_str@@Base+0x330>  // b.tcont
    e734:	add	x12, x12, x27
    e738:	add	x12, x12, #0x2
    e73c:	ldrb	w13, [x12], #1
    e740:	madd	x9, x9, x10, x11
    e744:	ldrb	w11, [x26, x13]
    e748:	cmp	x11, x10
    e74c:	b.lt	e73c <__gmpf_set_str@@Base+0x31c>  // b.tstop
    e750:	eor	x9, x9, x8
    e754:	sub	x8, x9, x8
    e758:	b	e77c <__gmpf_set_str@@Base+0x35c>
    e75c:	ldur	x0, [x29, #-8]
    e760:	cbnz	x0, eb50 <__gmpf_set_str@@Base+0x730>
    e764:	mov	w0, #0xffffffff            	// #-1
    e768:	b	eaf4 <__gmpf_set_str@@Base+0x6d4>
    e76c:	str	wzr, [x25, #4]
    e770:	str	xzr, [x25, #8]
    e774:	b	eae8 <__gmpf_set_str@@Base+0x6c8>
    e778:	mov	x8, xzr
    e77c:	ldur	x9, [x29, #-40]
    e780:	cmp	x19, #0x0
    e784:	sub	x9, x9, x19
    e788:	add	x9, x9, x28
    e78c:	csel	x9, xzr, x9, eq  // eq = none
    e790:	subs	x28, x8, x9
    e794:	cneg	x27, x28, mi  // mi = first
    e798:	cbz	x27, e7f8 <__gmpf_set_str@@Base+0x3d8>
    e79c:	add	x25, x20, #0x1
    e7a0:	lsl	x1, x25, #5
    e7a4:	mov	w8, #0x7f00                	// #32512
    e7a8:	cmp	x1, x8
    e7ac:	mov	w24, w22
    e7b0:	stur	x2, [x29, #-40]
    e7b4:	b.hi	eb58 <__gmpf_set_str@@Base+0x738>  // b.pmore
    e7b8:	add	x9, x1, #0xf
    e7bc:	mov	x8, sp
    e7c0:	and	x9, x9, #0xfffffffffffffff0
    e7c4:	sub	x26, x8, x9
    e7c8:	mov	sp, x26
    e7cc:	clz	x9, x27
    e7d0:	cmp	x9, #0x3f
    e7d4:	stur	x23, [x29, #-32]
    e7d8:	stp	x26, x21, [x29, #-56]
    e7dc:	str	x24, [x26]
    e7e0:	stur	x25, [x29, #-64]
    e7e4:	b.ne	e824 <__gmpf_set_str@@Base+0x404>  // b.any
    e7e8:	mov	x8, xzr
    e7ec:	mov	x19, xzr
    e7f0:	mov	w25, #0x1                   	// #1
    e7f4:	b	e8cc <__gmpf_set_str@@Base+0x4ac>
    e7f8:	ldr	x0, [x25, #16]
    e7fc:	mov	x1, x23
    e800:	mov	x19, x2
    e804:	bl	ca70 <__gmpn_copyi@plt>
    e808:	ldur	w9, [x29, #-20]
    e80c:	neg	w8, w19
    e810:	str	x24, [x25, #8]
    e814:	cmp	w9, #0x0
    e818:	csel	x8, x19, x8, eq  // eq = none
    e81c:	str	w8, [x25, #4]
    e820:	b	eae8 <__gmpf_set_str@@Base+0x6c8>
    e824:	lsl	x10, x25, #1
    e828:	mov	w11, #0x3e                  	// #62
    e82c:	mov	w12, #0x3f                  	// #63
    e830:	mov	x19, xzr
    e834:	mov	x8, xzr
    e838:	add	x22, x26, x10, lsl #3
    e83c:	sub	w23, w11, w9
    e840:	sub	w21, w12, w9
    e844:	mov	w25, #0x1                   	// #1
    e848:	mov	x9, x26
    e84c:	mov	x26, x22
    e850:	add	x1, x9, x8, lsl #3
    e854:	mov	x0, x26
    e858:	mov	x2, x25
    e85c:	mov	x22, x9
    e860:	bl	c900 <__gmpn_sqr@plt>
    e864:	add	x8, x26, x25, lsl #4
    e868:	ldur	x8, [x8, #-8]
    e86c:	lsl	x9, x25, #1
    e870:	cmp	x8, #0x0
    e874:	cset	w8, eq  // eq = none
    e878:	sub	x9, x9, x8
    e87c:	subs	x8, x9, x20
    e880:	csel	x8, x8, xzr, gt
    e884:	csel	x25, x20, x9, gt
    e888:	lsr	x9, x27, x23
    e88c:	add	x19, x8, x19, lsl #1
    e890:	tbz	w9, #0, e8b8 <__gmpf_set_str@@Base+0x498>
    e894:	add	x1, x26, x8, lsl #3
    e898:	mov	x0, x26
    e89c:	mov	x2, x25
    e8a0:	mov	x3, x24
    e8a4:	bl	d4b0 <__gmpn_mul_1@plt>
    e8a8:	cmp	x0, #0x0
    e8ac:	mov	x8, xzr
    e8b0:	str	x0, [x26, x25, lsl #3]
    e8b4:	cinc	x25, x25, ne  // ne = any
    e8b8:	sub	w21, w21, #0x1
    e8bc:	cmp	w21, #0x0
    e8c0:	sub	x23, x23, #0x1
    e8c4:	mov	x9, x26
    e8c8:	b.gt	e84c <__gmpf_set_str@@Base+0x42c>
    e8cc:	subs	x9, x25, x20
    e8d0:	add	x10, x26, x9, lsl #3
    e8d4:	csel	x9, x9, xzr, gt
    e8d8:	add	x27, x9, x19
    e8dc:	csel	x9, x10, x26, gt
    e8e0:	ldur	x26, [x29, #-56]
    e8e4:	csel	x24, x20, x25, gt
    e8e8:	add	x1, x9, x8, lsl #3
    e8ec:	mov	x2, x24
    e8f0:	mov	x0, x26
    e8f4:	bl	ca70 <__gmpn_copyi@plt>
    e8f8:	tbnz	x28, #63, e948 <__gmpf_set_str@@Base+0x528>
    e8fc:	ldp	x21, x4, [x29, #-48]
    e900:	mov	w8, #0x7f00                	// #32512
    e904:	add	x19, x24, x4
    e908:	lsl	x1, x19, #3
    e90c:	cmp	x1, x8
    e910:	b.hi	eb68 <__gmpf_set_str@@Base+0x748>  // b.pmore
    e914:	add	x9, x1, #0xf
    e918:	mov	x8, sp
    e91c:	and	x9, x9, #0xfffffffffffffff0
    e920:	sub	x25, x8, x9
    e924:	mov	sp, x25
    e928:	ldur	w22, [x29, #-20]
    e92c:	ldur	x3, [x29, #-32]
    e930:	mov	x0, x25
    e934:	cmp	x24, x4
    e938:	b.le	e9c0 <__gmpf_set_str@@Base+0x5a0>
    e93c:	mov	x1, x26
    e940:	mov	x2, x24
    e944:	b	e9d0 <__gmpf_set_str@@Base+0x5b0>
    e948:	ldp	x23, x10, [x29, #-48]
    e94c:	cmp	x24, x10
    e950:	b.le	ea08 <__gmpf_set_str@@Base+0x5e8>
    e954:	lsl	x19, x24, #3
    e958:	add	x1, x19, #0x8
    e95c:	mov	w8, #0x7f00                	// #32512
    e960:	cmp	x1, x8
    e964:	b.hi	eb94 <__gmpf_set_str@@Base+0x774>  // b.pmore
    e968:	add	x9, x1, #0xf
    e96c:	mov	x8, sp
    e970:	and	x9, x9, #0xfffffffffffffff0
    e974:	sub	x25, x8, x9
    e978:	mov	sp, x25
    e97c:	ldur	w22, [x29, #-20]
    e980:	subs	x21, x24, x10
    e984:	b.eq	e99c <__gmpf_set_str@@Base+0x57c>  // b.none
    e988:	sub	x2, x19, x10, lsl #3
    e98c:	mov	x0, x25
    e990:	mov	w1, wzr
    e994:	bl	c610 <memset@plt>
    e998:	ldur	x10, [x29, #-40]
    e99c:	ldur	x1, [x29, #-32]
    e9a0:	add	x8, x25, x24, lsl #3
    e9a4:	sub	x0, x8, x10, lsl #3
    e9a8:	mov	x2, x10
    e9ac:	bl	ca70 <__gmpn_copyi@plt>
    e9b0:	sub	x23, x23, x21
    e9b4:	mov	x10, x24
    e9b8:	stur	x25, [x29, #-32]
    e9bc:	b	ea0c <__gmpf_set_str@@Base+0x5ec>
    e9c0:	mov	x1, x3
    e9c4:	mov	x2, x4
    e9c8:	mov	x3, x26
    e9cc:	mov	x4, x24
    e9d0:	bl	ccf0 <__gmpn_mul@plt>
    e9d4:	add	x8, x25, x19, lsl #3
    e9d8:	ldur	x8, [x8, #-8]
    e9dc:	add	x10, x27, x21
    e9e0:	cmp	x8, #0x0
    e9e4:	cset	w8, eq  // eq = none
    e9e8:	sub	x8, x19, x8
    e9ec:	subs	x9, x8, x20
    e9f0:	add	x19, x10, x8
    e9f4:	b.le	ea00 <__gmpf_set_str@@Base+0x5e0>
    e9f8:	add	x25, x25, x9, lsl #3
    e9fc:	b	eac0 <__gmpf_set_str@@Base+0x6a0>
    ea00:	mov	x20, x8
    ea04:	b	eac0 <__gmpf_set_str@@Base+0x6a0>
    ea08:	ldur	w22, [x29, #-20]
    ea0c:	add	x8, x26, x24, lsl #3
    ea10:	ldur	x8, [x8, #-8]
    ea14:	tbnz	x8, #63, ea60 <__gmpf_set_str@@Base+0x640>
    ea18:	clz	x25, x8
    ea1c:	mov	x0, x26
    ea20:	mov	x1, x26
    ea24:	mov	x2, x24
    ea28:	mov	w3, w25
    ea2c:	mov	x19, x10
    ea30:	bl	c190 <__gmpn_lshift@plt>
    ea34:	ldur	x21, [x29, #-32]
    ea38:	mov	x2, x19
    ea3c:	mov	w3, w25
    ea40:	mov	x0, x21
    ea44:	mov	x1, x21
    ea48:	bl	c190 <__gmpn_lshift@plt>
    ea4c:	cbz	x0, ea5c <__gmpf_set_str@@Base+0x63c>
    ea50:	add	x10, x19, #0x1
    ea54:	str	x0, [x21, x19, lsl #3]
    ea58:	b	ea60 <__gmpf_set_str@@Base+0x640>
    ea5c:	mov	x10, x19
    ea60:	ldur	x8, [x29, #-64]
    ea64:	lsl	x1, x8, #3
    ea68:	mov	w8, #0x7f00                	// #32512
    ea6c:	cmp	x1, x8
    ea70:	b.hi	eb7c <__gmpf_set_str@@Base+0x75c>  // b.pmore
    ea74:	add	x9, x1, #0xf
    ea78:	mov	x8, sp
    ea7c:	and	x9, x9, #0xfffffffffffffff0
    ea80:	sub	x25, x8, x9
    ea84:	mov	sp, x25
    ea88:	ldur	x2, [x29, #-32]
    ea8c:	sub	x19, x10, x24
    ea90:	sub	x1, x20, x19
    ea94:	mov	x0, x25
    ea98:	mov	x3, x10
    ea9c:	mov	x4, x26
    eaa0:	mov	x5, x24
    eaa4:	bl	d3c0 <__gmpn_divrem@plt>
    eaa8:	sub	x8, x23, x27
    eaac:	add	x8, x19, x8
    eab0:	add	x19, x8, x0
    eab4:	cbz	x0, eac0 <__gmpf_set_str@@Base+0x6a0>
    eab8:	str	x0, [x25, x20, lsl #3]
    eabc:	add	x25, x25, #0x8
    eac0:	ldur	x21, [x29, #-16]
    eac4:	mov	x1, x25
    eac8:	mov	x2, x20
    eacc:	ldr	x0, [x21, #16]
    ead0:	bl	ca70 <__gmpn_copyi@plt>
    ead4:	neg	w8, w20
    ead8:	cmp	w22, #0x0
    eadc:	csel	x8, x20, x8, eq  // eq = none
    eae0:	str	w8, [x21, #4]
    eae4:	str	x19, [x21, #8]
    eae8:	ldur	x8, [x29, #-8]
    eaec:	mov	w0, wzr
    eaf0:	cbnz	x8, eb24 <__gmpf_set_str@@Base+0x704>
    eaf4:	mov	sp, x29
    eaf8:	ldp	x20, x19, [sp, #80]
    eafc:	ldp	x22, x21, [sp, #64]
    eb00:	ldp	x24, x23, [sp, #48]
    eb04:	ldp	x26, x25, [sp, #32]
    eb08:	ldp	x28, x27, [sp, #16]
    eb0c:	ldp	x29, x30, [sp], #96
    eb10:	ret
    eb14:	sub	x0, x29, #0x8
    eb18:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    eb1c:	mov	x1, x0
    eb20:	b	e5a4 <__gmpf_set_str@@Base+0x184>
    eb24:	mov	x0, x8
    eb28:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
    eb2c:	mov	w0, wzr
    eb30:	b	eaf4 <__gmpf_set_str@@Base+0x6d4>
    eb34:	sub	x0, x29, #0x8
    eb38:	mov	x23, x1
    eb3c:	mov	x1, x8
    eb40:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    eb44:	mov	x1, x23
    eb48:	mov	x23, x0
    eb4c:	b	e6c0 <__gmpf_set_str@@Base+0x2a0>
    eb50:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
    eb54:	b	e764 <__gmpf_set_str@@Base+0x344>
    eb58:	sub	x0, x29, #0x8
    eb5c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    eb60:	mov	x26, x0
    eb64:	b	e7cc <__gmpf_set_str@@Base+0x3ac>
    eb68:	sub	x0, x29, #0x8
    eb6c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    eb70:	ldur	x4, [x29, #-40]
    eb74:	mov	x25, x0
    eb78:	b	e928 <__gmpf_set_str@@Base+0x508>
    eb7c:	sub	x0, x29, #0x8
    eb80:	mov	x19, x10
    eb84:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    eb88:	mov	x10, x19
    eb8c:	mov	x25, x0
    eb90:	b	ea88 <__gmpf_set_str@@Base+0x668>
    eb94:	sub	x0, x29, #0x8
    eb98:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    eb9c:	ldur	x10, [x29, #-40]
    eba0:	mov	x25, x0
    eba4:	b	e97c <__gmpf_set_str@@Base+0x55c>

000000000000eba8 <__gmpf_set_d@@Base>:
    eba8:	stp	x29, x30, [sp, #-32]!
    ebac:	fmov	x8, d0
    ebb0:	mvn	x8, x8
    ebb4:	tst	x8, #0x7ff0000000000000
    ebb8:	str	x19, [sp, #16]
    ebbc:	mov	x29, sp
    ebc0:	b.eq	ec10 <__gmpf_set_d@@Base+0x68>  // b.none
    ebc4:	mov	x19, x0
    ebc8:	fcmp	d0, #0.0
    ebcc:	b.eq	ec04 <__gmpf_set_d@@Base+0x5c>  // b.none
    ebd0:	ldr	x0, [x19, #16]
    ebd4:	fneg	d1, d0
    ebd8:	mov	w8, #0x2                   	// #2
    ebdc:	mov	w9, #0xfffffffe            	// #-2
    ebe0:	fcsel	d0, d0, d1, ge  // ge = tcont
    ebe4:	csel	w8, w9, w8, mi  // mi = first
    ebe8:	str	w8, [x19, #4]
    ebec:	bl	d2a0 <__gmp_extract_double@plt>
    ebf0:	sxtw	x8, w0
    ebf4:	str	x8, [x19, #8]
    ebf8:	ldr	x19, [sp, #16]
    ebfc:	ldp	x29, x30, [sp], #32
    ec00:	ret
    ec04:	mov	x8, xzr
    ec08:	str	wzr, [x19, #4]
    ec0c:	b	ebf4 <__gmpf_set_d@@Base+0x4c>
    ec10:	bl	c1c0 <__gmp_invalid_operation@plt>

000000000000ec14 <__gmpf_set_z@@Base>:
    ec14:	ldrsw	x10, [x1, #4]
    ec18:	ldrsw	x9, [x0]
    ec1c:	ldr	x11, [x1, #8]
    ec20:	ldr	x8, [x0, #16]
    ec24:	cmp	x10, #0x0
    ec28:	add	x12, x9, #0x1
    ec2c:	cneg	x13, x10, mi  // mi = first
    ec30:	subs	x12, x13, x12
    ec34:	add	x12, x11, x12, lsl #3
    ec38:	csinc	x2, x13, x9, le
    ec3c:	csel	x1, x12, x11, gt
    ec40:	neg	w9, w2
    ec44:	cmp	w10, #0x0
    ec48:	csel	x9, x2, x9, ge  // ge = tcont
    ec4c:	str	x13, [x0, #8]
    ec50:	str	w9, [x0, #4]
    ec54:	mov	x0, x8
    ec58:	b	ca70 <__gmpn_copyi@plt>

000000000000ec5c <__gmpf_init_set@@Base>:
    ec5c:	stp	x29, x30, [sp, #-48]!
    ec60:	stp	x22, x21, [sp, #16]
    ec64:	stp	x20, x19, [sp, #32]
    ec68:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    ec6c:	ldr	x8, [x8, #3960]
    ec70:	mov	x20, x0
    ec74:	mov	x29, sp
    ec78:	mov	x19, x1
    ec7c:	ldr	x21, [x8]
    ec80:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    ec84:	ldr	x8, [x8, #3840]
    ec88:	add	x22, x21, #0x1
    ec8c:	lsl	x0, x22, #3
    ec90:	ldr	x8, [x8]
    ec94:	blr	x8
    ec98:	str	x0, [x20, #16]
    ec9c:	str	w21, [x20]
    eca0:	ldrsw	x8, [x19, #4]
    eca4:	ldp	x9, x10, [x19, #8]
    eca8:	cmp	x8, #0x0
    ecac:	str	x9, [x20, #8]
    ecb0:	cneg	x9, x8, mi  // mi = first
    ecb4:	subs	x11, x9, x22
    ecb8:	add	x11, x10, x11, lsl #3
    ecbc:	csinc	x2, x9, x21, le
    ecc0:	csel	x1, x11, x10, gt
    ecc4:	neg	w9, w2
    ecc8:	cmp	w8, #0x0
    eccc:	csel	x8, x2, x9, ge  // ge = tcont
    ecd0:	str	w8, [x20, #4]
    ecd4:	ldp	x20, x19, [sp, #32]
    ecd8:	ldp	x22, x21, [sp, #16]
    ecdc:	ldp	x29, x30, [sp], #48
    ece0:	b	ca70 <__gmpn_copyi@plt>

000000000000ece4 <__gmpf_init_set_ui@@Base>:
    ece4:	stp	x29, x30, [sp, #-32]!
    ece8:	stp	x20, x19, [sp, #16]
    ecec:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    ecf0:	ldr	x8, [x8, #3960]
    ecf4:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    ecf8:	mov	x20, x0
    ecfc:	mov	x29, sp
    ed00:	ldr	x8, [x8]
    ed04:	mov	x19, x1
    ed08:	str	w8, [x0]
    ed0c:	ldr	x9, [x9, #3840]
    ed10:	lsl	x8, x8, #3
    ed14:	add	x0, x8, #0x8
    ed18:	ldr	x9, [x9]
    ed1c:	blr	x9
    ed20:	cmp	x19, #0x0
    ed24:	cset	w8, ne  // ne = any
    ed28:	str	x0, [x20, #16]
    ed2c:	str	x19, [x0]
    ed30:	str	w8, [x20, #4]
    ed34:	str	x8, [x20, #8]
    ed38:	ldp	x20, x19, [sp, #16]
    ed3c:	ldp	x29, x30, [sp], #32
    ed40:	ret

000000000000ed44 <__gmpf_init_set_si@@Base>:
    ed44:	stp	x29, x30, [sp, #-32]!
    ed48:	stp	x20, x19, [sp, #16]
    ed4c:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    ed50:	ldr	x8, [x8, #3960]
    ed54:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    ed58:	mov	x20, x0
    ed5c:	mov	x29, sp
    ed60:	ldr	x8, [x8]
    ed64:	mov	x19, x1
    ed68:	str	w8, [x0]
    ed6c:	ldr	x9, [x9, #3840]
    ed70:	lsl	x8, x8, #3
    ed74:	add	x0, x8, #0x8
    ed78:	ldr	x9, [x9]
    ed7c:	blr	x9
    ed80:	cmp	x19, #0x0
    ed84:	cneg	x8, x19, mi  // mi = first
    ed88:	cset	w9, ne  // ne = any
    ed8c:	csetm	x10, ne  // ne = any
    ed90:	str	x0, [x20, #16]
    ed94:	str	x8, [x0]
    ed98:	csel	x8, x9, x10, ge  // ge = tcont
    ed9c:	str	x9, [x20, #8]
    eda0:	str	w8, [x20, #4]
    eda4:	ldp	x20, x19, [sp, #16]
    eda8:	ldp	x29, x30, [sp], #32
    edac:	ret

000000000000edb0 <__gmpf_init_set_str@@Base>:
    edb0:	stp	x29, x30, [sp, #-48]!
    edb4:	str	x21, [sp, #16]
    edb8:	stp	x20, x19, [sp, #32]
    edbc:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    edc0:	ldr	x8, [x8, #3960]
    edc4:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    edc8:	mov	x21, x0
    edcc:	mov	x29, sp
    edd0:	ldr	x8, [x8]
    edd4:	str	xzr, [x0, #8]
    edd8:	mov	w19, w2
    eddc:	mov	x20, x1
    ede0:	stp	w8, wzr, [x0]
    ede4:	ldr	x9, [x9, #3840]
    ede8:	lsl	x8, x8, #3
    edec:	add	x0, x8, #0x8
    edf0:	ldr	x9, [x9]
    edf4:	blr	x9
    edf8:	str	x0, [x21, #16]
    edfc:	mov	x0, x21
    ee00:	mov	x1, x20
    ee04:	mov	w2, w19
    ee08:	ldp	x20, x19, [sp, #32]
    ee0c:	ldr	x21, [sp, #16]
    ee10:	ldp	x29, x30, [sp], #48
    ee14:	b	c1d0 <__gmpf_set_str@plt>

000000000000ee18 <__gmpf_init_set_d@@Base>:
    ee18:	str	d8, [sp, #-32]!
    ee1c:	stp	x29, x30, [sp, #8]
    ee20:	str	x19, [sp, #24]
    ee24:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    ee28:	ldr	x8, [x8, #3960]
    ee2c:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    ee30:	mov	x19, x0
    ee34:	mov	x29, sp
    ee38:	ldr	x8, [x8]
    ee3c:	mov	v8.16b, v0.16b
    ee40:	str	w8, [x0]
    ee44:	ldr	x9, [x9, #3840]
    ee48:	lsl	x8, x8, #3
    ee4c:	add	x0, x8, #0x8
    ee50:	ldr	x9, [x9]
    ee54:	blr	x9
    ee58:	str	x0, [x19, #16]
    ee5c:	mov	x0, x19
    ee60:	ldr	x19, [sp, #24]
    ee64:	ldp	x29, x30, [sp, #8]
    ee68:	mov	v0.16b, v8.16b
    ee6c:	ldr	d8, [sp], #32
    ee70:	b	c4c0 <__gmpf_set_d@plt>

000000000000ee74 <__gmpf_clear@@Base>:
    ee74:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    ee78:	ldr	x8, [x8, #4016]
    ee7c:	ldrsw	x9, [x0]
    ee80:	ldr	x0, [x0, #16]
    ee84:	ldr	x2, [x8]
    ee88:	lsl	x8, x9, #3
    ee8c:	add	x1, x8, #0x8
    ee90:	br	x2

000000000000ee94 <__gmpf_clears@@Base>:
    ee94:	sub	sp, sp, #0x100
    ee98:	stp	x29, x30, [sp, #224]
    ee9c:	add	x29, sp, #0xe0
    eea0:	mov	x8, #0xffffffffffffffc8    	// #-56
    eea4:	mov	x9, sp
    eea8:	sub	x10, x29, #0x58
    eeac:	movk	x8, #0xff80, lsl #32
    eeb0:	add	x11, x29, #0x20
    eeb4:	add	x9, x9, #0x80
    eeb8:	add	x10, x10, #0x38
    eebc:	str	x19, [sp, #240]
    eec0:	stp	x1, x2, [x29, #-88]
    eec4:	stp	x3, x4, [x29, #-72]
    eec8:	stp	x5, x6, [x29, #-56]
    eecc:	stur	x7, [x29, #-40]
    eed0:	stp	q0, q1, [sp]
    eed4:	stp	q2, q3, [sp, #32]
    eed8:	stp	q4, q5, [sp, #64]
    eedc:	stp	q6, q7, [sp, #96]
    eee0:	stp	x9, x8, [x29, #-16]
    eee4:	stp	x11, x10, [x29, #-32]
    eee8:	adrp	x19, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    eeec:	ldr	x19, [x19, #4016]
    eef0:	ldrsw	x8, [x0]
    eef4:	ldr	x9, [x19]
    eef8:	ldr	x0, [x0, #16]
    eefc:	lsl	x8, x8, #3
    ef00:	add	x1, x8, #0x8
    ef04:	blr	x9
    ef08:	ldursw	x8, [x29, #-8]
    ef0c:	tbz	w8, #31, ef2c <__gmpf_clears@@Base+0x98>
    ef10:	add	w9, w8, #0x8
    ef14:	cmn	w8, #0x8
    ef18:	stur	w9, [x29, #-8]
    ef1c:	b.gt	ef2c <__gmpf_clears@@Base+0x98>
    ef20:	ldur	x9, [x29, #-24]
    ef24:	add	x8, x9, x8
    ef28:	b	ef38 <__gmpf_clears@@Base+0xa4>
    ef2c:	ldur	x8, [x29, #-32]
    ef30:	add	x9, x8, #0x8
    ef34:	stur	x9, [x29, #-32]
    ef38:	ldr	x0, [x8]
    ef3c:	cbnz	x0, eef0 <__gmpf_clears@@Base+0x5c>
    ef40:	ldr	x19, [sp, #240]
    ef44:	ldp	x29, x30, [sp, #224]
    ef48:	add	sp, sp, #0x100
    ef4c:	ret

000000000000ef50 <__gmpf_get_str@@Base>:
    ef50:	stp	x29, x30, [sp, #-96]!
    ef54:	stp	x28, x27, [sp, #16]
    ef58:	stp	x26, x25, [sp, #32]
    ef5c:	stp	x24, x23, [sp, #48]
    ef60:	stp	x22, x21, [sp, #64]
    ef64:	stp	x20, x19, [sp, #80]
    ef68:	mov	x29, sp
    ef6c:	sub	sp, sp, #0x60
    ef70:	ldr	w8, [x4, #4]
    ef74:	ldp	x11, x22, [x4, #8]
    ef78:	mov	x20, x4
    ef7c:	mov	w21, w2
    ef80:	cmp	w8, #0x0
    ef84:	mov	x23, x1
    ef88:	cneg	w25, w8, mi  // mi = first
    ef8c:	cmp	w2, #0x2
    ef90:	mov	x24, x0
    ef94:	b.lt	efac <__gmpf_get_str@@Base+0x5c>  // b.tstop
    ef98:	cmp	w21, #0x25
    ef9c:	b.ge	efbc <__gmpf_get_str@@Base+0x6c>  // b.tcont
    efa0:	adrp	x19, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    efa4:	add	x19, x19, #0xded
    efa8:	b	efdc <__gmpf_get_str@@Base+0x8c>
    efac:	cmn	w21, #0x2
    efb0:	b.le	efc8 <__gmpf_get_str@@Base+0x78>
    efb4:	mov	w21, #0xa                   	// #10
    efb8:	b	efd4 <__gmpf_get_str@@Base+0x84>
    efbc:	cmp	w21, #0x3e
    efc0:	b.le	efd4 <__gmpf_get_str@@Base+0x84>
    efc4:	b	f47c <__gmpf_get_str@@Base+0x52c>
    efc8:	cmn	w21, #0x24
    efcc:	b.lt	f47c <__gmpf_get_str@@Base+0x52c>  // b.tstop
    efd0:	neg	w21, w21
    efd4:	adrp	x19, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    efd8:	add	x19, x19, #0xdae
    efdc:	adrp	x26, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    efe0:	ldr	x26, [x26, #3936]
    efe4:	ldrsw	x9, [x20]
    efe8:	mov	w8, #0x28                  	// #40
    efec:	umaddl	x8, w21, w8, x26
    eff0:	ldr	x28, [x8, #8]
    eff4:	lsl	x8, x9, #6
    eff8:	sub	x8, x8, #0x40
    effc:	umulh	x8, x28, x8
    f000:	add	x8, x8, #0x2
    f004:	sub	x9, x3, #0x1
    f008:	cmp	x9, x8
    f00c:	csel	x9, x3, x8, cc  // cc = lo, ul, last
    f010:	stur	x9, [x29, #-24]
    f014:	cbz	x24, f1c4 <__gmpf_get_str@@Base+0x274>
    f018:	mov	x27, xzr
    f01c:	cbz	w25, f1ec <__gmpf_get_str@@Base+0x29c>
    f020:	ldur	x10, [x29, #-24]
    f024:	mov	w8, #0x7f00                	// #32512
    f028:	mov	w2, w21
    f02c:	stur	xzr, [x29, #-8]
    f030:	add	x1, x10, #0x83
    f034:	cmp	x1, x8
    f038:	stp	x23, x20, [x29, #-56]
    f03c:	stur	x27, [x29, #-72]
    f040:	b.hi	f42c <__gmpf_get_str@@Base+0x4dc>  // b.pmore
    f044:	add	x9, x1, #0xf
    f048:	mov	x8, sp
    f04c:	and	x9, x9, #0xfffffffffffffff0
    f050:	sub	x23, x8, x9
    f054:	mov	sp, x23
    f058:	mov	w8, #0x28                  	// #40
    f05c:	madd	x8, x2, x8, x26
    f060:	ldr	x8, [x8, #16]
    f064:	umulh	x8, x8, x10
    f068:	ubfx	x21, x8, #3, #58
    f06c:	add	x20, x21, #0x2
    f070:	subs	x8, x25, x20
    f074:	lsl	x9, x20, #1
    f078:	add	x8, x22, x8, lsl #3
    f07c:	csel	x27, x20, x25, hi  // hi = pmore
    f080:	add	x25, x9, #0x4
    f084:	csel	x8, x8, x22, hi  // hi = pmore
    f088:	cmp	x21, #0x3f4
    f08c:	lsl	x1, x25, #4
    f090:	stur	x8, [x29, #-64]
    f094:	stur	x24, [x29, #-80]
    f098:	b.hi	f450 <__gmpf_get_str@@Base+0x500>  // b.pmore
    f09c:	add	x9, x1, #0xf
    f0a0:	mov	x8, sp
    f0a4:	and	x9, x9, #0xfffffffffffffff0
    f0a8:	sub	x26, x8, x9
    f0ac:	mov	sp, x26
    f0b0:	subs	x24, x11, x20
    f0b4:	add	x25, x26, x25, lsl #3
    f0b8:	stp	x11, x2, [x29, #-40]
    f0bc:	b.le	f200 <__gmpf_get_str@@Base+0x2b0>
    f0c0:	add	x4, x21, #0x3
    f0c4:	sub	x1, x29, #0x10
    f0c8:	mov	x0, x26
    f0cc:	mov	x5, x25
    f0d0:	lsl	x8, x24, #6
    f0d4:	umulh	x3, x28, x8
    f0d8:	stur	x3, [x29, #-88]
    f0dc:	bl	f4a4 <__gmpf_get_str@@Base+0x554>
    f0e0:	ldur	x22, [x29, #-16]
    f0e4:	sub	x8, x24, x22
    f0e8:	add	x21, x8, x20
    f0ec:	lsl	x1, x21, #3
    f0f0:	mov	w8, #0x7f00                	// #32512
    f0f4:	cmp	x1, x8
    f0f8:	mov	x20, x0
    f0fc:	b.hi	f484 <__gmpf_get_str@@Base+0x534>  // b.pmore
    f100:	add	x9, x1, #0xf
    f104:	mov	x8, sp
    f108:	and	x9, x9, #0xfffffffffffffff0
    f10c:	sub	x28, x8, x9
    f110:	mov	sp, x28
    f114:	ldur	x8, [x29, #-40]
    f118:	subs	x24, x21, x27
    f11c:	b.eq	f138 <__gmpf_get_str@@Base+0x1e8>  // b.none
    f120:	sub	x8, x8, x22
    f124:	sub	x8, x8, x27
    f128:	lsl	x2, x8, #3
    f12c:	mov	x0, x28
    f130:	mov	w1, wzr
    f134:	bl	c610 <memset@plt>
    f138:	ldur	x1, [x29, #-64]
    f13c:	add	x0, x28, x24, lsl #3
    f140:	mov	x2, x27
    f144:	bl	ca70 <__gmpn_copyi@plt>
    f148:	lsl	x1, x20, #3
    f14c:	mov	w8, #0x7f00                	// #32512
    f150:	cmp	x1, x8
    f154:	b.hi	f494 <__gmpf_get_str@@Base+0x544>  // b.pmore
    f158:	add	x9, x1, #0xf
    f15c:	mov	x8, sp
    f160:	and	x9, x9, #0xfffffffffffffff0
    f164:	sub	x1, x8, x9
    f168:	mov	sp, x1
    f16c:	ldur	x24, [x29, #-80]
    f170:	ldp	x27, x22, [x29, #-56]
    f174:	mov	x0, x25
    f178:	mov	x2, xzr
    f17c:	mov	x3, x28
    f180:	mov	x4, x21
    f184:	mov	x5, x26
    f188:	mov	x6, x20
    f18c:	bl	bf10 <__gmpn_tdiv_qr@plt>
    f190:	sub	x8, x21, x20
    f194:	ldr	x9, [x25, x8, lsl #3]
    f198:	mov	x0, x23
    f19c:	ldur	x1, [x29, #-32]
    f1a0:	mov	x2, x25
    f1a4:	cmp	x9, #0x0
    f1a8:	cset	w9, eq  // eq = none
    f1ac:	sub	x8, x8, x9
    f1b0:	add	x3, x8, #0x1
    f1b4:	bl	cab0 <__gmpn_get_str@plt>
    f1b8:	ldur	x8, [x29, #-88]
    f1bc:	add	x8, x0, x8
    f1c0:	b	f2e0 <__gmpf_get_str@@Base+0x390>
    f1c4:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    f1c8:	ldr	x8, [x8, #3840]
    f1cc:	add	x27, x9, #0x2
    f1d0:	mov	x0, x27
    f1d4:	mov	x24, x11
    f1d8:	ldr	x8, [x8]
    f1dc:	blr	x8
    f1e0:	mov	x11, x24
    f1e4:	mov	x24, x0
    f1e8:	cbnz	w25, f020 <__gmpf_get_str@@Base+0xd0>
    f1ec:	mov	x21, xzr
    f1f0:	str	xzr, [x23]
    f1f4:	strb	wzr, [x24]
    f1f8:	cbnz	x27, f3e0 <__gmpf_get_str@@Base+0x490>
    f1fc:	b	f408 <__gmpf_get_str@@Base+0x4b8>
    f200:	sub	x8, x20, x11
    f204:	lsl	x8, x8, #6
    f208:	umulh	x28, x28, x8
    f20c:	add	x4, x21, #0x3
    f210:	sub	x1, x29, #0x10
    f214:	mov	x0, x26
    f218:	mov	x3, x28
    f21c:	mov	x5, x25
    f220:	bl	f4a4 <__gmpf_get_str@@Base+0x554>
    f224:	mov	x22, x0
    f228:	cmp	x27, x0
    f22c:	b.le	f248 <__gmpf_get_str@@Base+0x2f8>
    f230:	ldur	x1, [x29, #-64]
    f234:	mov	x0, x25
    f238:	mov	x2, x27
    f23c:	mov	x3, x26
    f240:	mov	x4, x22
    f244:	b	f25c <__gmpf_get_str@@Base+0x30c>
    f248:	ldur	x3, [x29, #-64]
    f24c:	mov	x0, x25
    f250:	mov	x1, x26
    f254:	mov	x2, x22
    f258:	mov	x4, x27
    f25c:	bl	ccf0 <__gmpn_mul@plt>
    f260:	add	x8, x22, x27
    f264:	add	x9, x25, x8, lsl #3
    f268:	ldur	x9, [x9, #-8]
    f26c:	ldur	x11, [x29, #-40]
    f270:	ldur	x10, [x29, #-16]
    f274:	ldur	x24, [x29, #-80]
    f278:	cmp	x9, #0x0
    f27c:	sub	x11, x27, x11
    f280:	cset	w9, eq  // eq = none
    f284:	subs	x20, x11, x10
    f288:	sub	x22, x8, x9
    f28c:	b.pl	f2c4 <__gmpf_get_str@@Base+0x374>  // b.nfrst
    f290:	neg	x8, x20
    f294:	sub	x0, x25, x20, lsl #3
    f298:	mov	x1, x25
    f29c:	mov	x2, x22
    f2a0:	lsl	x27, x8, #3
    f2a4:	bl	c010 <__gmpn_copyd@plt>
    f2a8:	add	x8, x26, x21, lsl #4
    f2ac:	add	x0, x8, #0x40
    f2b0:	mov	w1, wzr
    f2b4:	mov	x2, x27
    f2b8:	bl	c610 <memset@plt>
    f2bc:	sub	x22, x22, x20
    f2c0:	mov	x20, xzr
    f2c4:	add	x2, x25, x20, lsl #3
    f2c8:	sub	x3, x22, x20
    f2cc:	mov	x0, x23
    f2d0:	ldur	x1, [x29, #-32]
    f2d4:	bl	cab0 <__gmpn_get_str@plt>
    f2d8:	ldp	x27, x22, [x29, #-56]
    f2dc:	sub	x8, x0, x28
    f2e0:	ldur	x11, [x29, #-24]
    f2e4:	cmp	x0, x11
    f2e8:	b.ls	f354 <__gmpf_get_str@@Base+0x404>  // b.plast
    f2ec:	ldrb	w9, [x23, x11]
    f2f0:	ldur	x12, [x29, #-32]
    f2f4:	cmp	w12, w9, lsl #1
    f2f8:	b.gt	f354 <__gmpf_get_str@@Base+0x404>
    f2fc:	add	x9, x11, x23
    f300:	ldurb	w10, [x9, #-1]
    f304:	add	w10, w10, #0x1
    f308:	cmp	w12, w10, uxtb
    f30c:	sturb	w10, [x9, #-1]
    f310:	b.ne	f340 <__gmpf_get_str@@Base+0x3f0>  // b.any
    f314:	mov	x9, x11
    f318:	subs	x0, x9, #0x1
    f31c:	b.eq	f348 <__gmpf_get_str@@Base+0x3f8>  // b.none
    f320:	add	x9, x23, x9
    f324:	ldurb	w10, [x9, #-2]
    f328:	add	w10, w10, #0x1
    f32c:	cmp	w12, w10, uxtb
    f330:	sturb	w10, [x9, #-2]
    f334:	mov	x9, x0
    f338:	b.eq	f318 <__gmpf_get_str@@Base+0x3c8>  // b.none
    f33c:	b	f354 <__gmpf_get_str@@Base+0x404>
    f340:	mov	x0, x11
    f344:	b	f354 <__gmpf_get_str@@Base+0x404>
    f348:	mov	w0, #0x1                   	// #1
    f34c:	strb	w0, [x23]
    f350:	add	x8, x8, #0x1
    f354:	cmp	x11, x0
    f358:	csel	x9, x0, x11, hi  // hi = pmore
    f35c:	sub	x10, x23, #0x1
    f360:	cbz	x9, f3a4 <__gmpf_get_str@@Base+0x454>
    f364:	ldrb	w11, [x10, x9]
    f368:	sub	x12, x9, #0x1
    f36c:	mov	x9, x12
    f370:	cbz	w11, f360 <__gmpf_get_str@@Base+0x410>
    f374:	ldr	w11, [x22, #4]
    f378:	mov	x10, xzr
    f37c:	add	x21, x12, #0x1
    f380:	lsr	x9, x11, #31
    f384:	add	x11, x24, x11, lsr #31
    f388:	ldrb	w12, [x23, x10]
    f38c:	ldrb	w12, [x19, x12]
    f390:	strb	w12, [x11, x10]
    f394:	add	x10, x10, #0x1
    f398:	cmp	x21, x10
    f39c:	b.ne	f388 <__gmpf_get_str@@Base+0x438>  // b.any
    f3a0:	b	f3b0 <__gmpf_get_str@@Base+0x460>
    f3a4:	ldr	w9, [x22, #4]
    f3a8:	mov	x21, xzr
    f3ac:	lsr	x9, x9, #31
    f3b0:	add	x9, x24, x9
    f3b4:	strb	wzr, [x9, x21]
    f3b8:	str	x8, [x27]
    f3bc:	ldr	w8, [x22, #4]
    f3c0:	tbz	w8, #31, f3d0 <__gmpf_get_str@@Base+0x480>
    f3c4:	mov	w8, #0x2d                  	// #45
    f3c8:	add	x21, x21, #0x1
    f3cc:	strb	w8, [x24]
    f3d0:	ldur	x27, [x29, #-72]
    f3d4:	ldur	x0, [x29, #-8]
    f3d8:	cbnz	x0, f470 <__gmpf_get_str@@Base+0x520>
    f3dc:	cbz	x27, f408 <__gmpf_get_str@@Base+0x4b8>
    f3e0:	add	x2, x21, #0x1
    f3e4:	cmp	x27, x2
    f3e8:	b.eq	f408 <__gmpf_get_str@@Base+0x4b8>  // b.none
    f3ec:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    f3f0:	ldr	x8, [x8, #3792]
    f3f4:	mov	x0, x24
    f3f8:	mov	x1, x27
    f3fc:	ldr	x8, [x8]
    f400:	blr	x8
    f404:	mov	x24, x0
    f408:	mov	x0, x24
    f40c:	mov	sp, x29
    f410:	ldp	x20, x19, [sp, #80]
    f414:	ldp	x22, x21, [sp, #64]
    f418:	ldp	x24, x23, [sp, #48]
    f41c:	ldp	x26, x25, [sp, #32]
    f420:	ldp	x28, x27, [sp, #16]
    f424:	ldp	x29, x30, [sp], #96
    f428:	ret
    f42c:	sub	x0, x29, #0x8
    f430:	mov	x20, x2
    f434:	mov	x21, x11
    f438:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    f43c:	ldur	x10, [x29, #-24]
    f440:	mov	x11, x21
    f444:	mov	x2, x20
    f448:	mov	x23, x0
    f44c:	b	f058 <__gmpf_get_str@@Base+0x108>
    f450:	sub	x0, x29, #0x8
    f454:	mov	x22, x2
    f458:	mov	x24, x11
    f45c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    f460:	mov	x11, x24
    f464:	mov	x2, x22
    f468:	mov	x26, x0
    f46c:	b	f0b0 <__gmpf_get_str@@Base+0x160>
    f470:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
    f474:	cbnz	x27, f3e0 <__gmpf_get_str@@Base+0x490>
    f478:	b	f408 <__gmpf_get_str@@Base+0x4b8>
    f47c:	mov	x24, xzr
    f480:	b	f408 <__gmpf_get_str@@Base+0x4b8>
    f484:	sub	x0, x29, #0x8
    f488:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    f48c:	mov	x28, x0
    f490:	b	f114 <__gmpf_get_str@@Base+0x1c4>
    f494:	sub	x0, x29, #0x8
    f498:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    f49c:	mov	x1, x0
    f4a0:	b	f16c <__gmpf_get_str@@Base+0x21c>
    f4a4:	sub	sp, sp, #0x70
    f4a8:	stp	x20, x19, [sp, #96]
    f4ac:	mov	x20, x0
    f4b0:	stp	x29, x30, [sp, #16]
    f4b4:	stp	x28, x27, [sp, #32]
    f4b8:	stp	x26, x25, [sp, #48]
    f4bc:	stp	x24, x23, [sp, #64]
    f4c0:	stp	x22, x21, [sp, #80]
    f4c4:	add	x29, sp, #0x10
    f4c8:	cbz	x3, f500 <__gmpf_get_str@@Base+0x5b0>
    f4cc:	clz	x9, x3
    f4d0:	mov	x21, x4
    f4d4:	mov	x23, x3
    f4d8:	mov	x24, x2
    f4dc:	cmp	x9, #0x3f
    f4e0:	str	x2, [x20]
    f4e4:	str	x1, [sp, #8]
    f4e8:	b.ne	f510 <__gmpf_get_str@@Base+0x5c0>  // b.any
    f4ec:	mov	x8, xzr
    f4f0:	mov	x27, xzr
    f4f4:	mov	w25, #0x1                   	// #1
    f4f8:	mov	x26, x20
    f4fc:	b	f5b4 <__gmpf_get_str@@Base+0x664>
    f500:	mov	w21, #0x1                   	// #1
    f504:	mov	x19, xzr
    f508:	str	x21, [x20]
    f50c:	b	f5e8 <__gmpf_get_str@@Base+0x698>
    f510:	mov	w10, #0x3e                  	// #62
    f514:	mov	w11, #0x3f                  	// #63
    f518:	mov	x22, x5
    f51c:	mov	x27, xzr
    f520:	mov	x8, xzr
    f524:	sub	w28, w10, w9
    f528:	sub	w19, w11, w9
    f52c:	mov	w25, #0x1                   	// #1
    f530:	mov	x9, x20
    f534:	mov	x26, x22
    f538:	add	x1, x9, x8, lsl #3
    f53c:	mov	x0, x26
    f540:	mov	x2, x25
    f544:	mov	x22, x9
    f548:	bl	c900 <__gmpn_sqr@plt>
    f54c:	add	x8, x26, x25, lsl #4
    f550:	ldur	x8, [x8, #-8]
    f554:	lsl	x9, x25, #1
    f558:	lsr	x10, x23, x28
    f55c:	cmp	x8, #0x0
    f560:	cset	w8, eq  // eq = none
    f564:	sub	x9, x9, x8
    f568:	subs	x8, x9, x21
    f56c:	csel	x8, x8, xzr, gt
    f570:	add	x27, x8, x27, lsl #1
    f574:	csel	x25, x21, x9, gt
    f578:	tbz	w10, #0, f5a0 <__gmpf_get_str@@Base+0x650>
    f57c:	add	x1, x26, x8, lsl #3
    f580:	mov	x0, x26
    f584:	mov	x2, x25
    f588:	mov	x3, x24
    f58c:	bl	d4b0 <__gmpn_mul_1@plt>
    f590:	cmp	x0, #0x0
    f594:	mov	x8, xzr
    f598:	str	x0, [x26, x25, lsl #3]
    f59c:	cinc	x25, x25, ne  // ne = any
    f5a0:	sub	w19, w19, #0x1
    f5a4:	cmp	w19, #0x0
    f5a8:	sub	x28, x28, #0x1
    f5ac:	mov	x9, x26
    f5b0:	b.gt	f534 <__gmpf_get_str@@Base+0x5e4>
    f5b4:	subs	x9, x25, x21
    f5b8:	add	x10, x26, x9, lsl #3
    f5bc:	csel	x10, x10, x26, gt
    f5c0:	csel	x9, x9, xzr, gt
    f5c4:	add	x1, x10, x8, lsl #3
    f5c8:	csel	x21, x21, x25, gt
    f5cc:	cmp	x1, x20
    f5d0:	add	x19, x9, x27
    f5d4:	b.eq	f5e4 <__gmpf_get_str@@Base+0x694>  // b.none
    f5d8:	mov	x0, x20
    f5dc:	mov	x2, x21
    f5e0:	bl	ca70 <__gmpn_copyi@plt>
    f5e4:	ldr	x1, [sp, #8]
    f5e8:	str	x19, [x1]
    f5ec:	mov	x0, x21
    f5f0:	ldp	x20, x19, [sp, #96]
    f5f4:	ldp	x22, x21, [sp, #80]
    f5f8:	ldp	x24, x23, [sp, #64]
    f5fc:	ldp	x26, x25, [sp, #48]
    f600:	ldp	x28, x27, [sp, #32]
    f604:	ldp	x29, x30, [sp, #16]
    f608:	add	sp, sp, #0x70
    f60c:	ret

000000000000f610 <__gmpf_dump@@Base>:
    f610:	sub	sp, sp, #0x30
    f614:	mov	x4, x0
    f618:	add	x1, sp, #0x8
    f61c:	mov	w2, #0xa                   	// #10
    f620:	mov	x0, xzr
    f624:	mov	x3, xzr
    f628:	stp	x29, x30, [sp, #16]
    f62c:	stp	x20, x19, [sp, #32]
    f630:	add	x29, sp, #0x10
    f634:	bl	ce40 <__gmpf_get_str@plt>
    f638:	ldrb	w8, [x0]
    f63c:	mov	x19, x0
    f640:	cmp	w8, #0x2d
    f644:	b.ne	f65c <__gmpf_dump@@Base+0x4c>  // b.any
    f648:	ldr	x2, [sp, #8]
    f64c:	adrp	x0, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    f650:	add	x1, x19, #0x1
    f654:	add	x0, x0, #0xe12
    f658:	b	f66c <__gmpf_dump@@Base+0x5c>
    f65c:	ldr	x2, [sp, #8]
    f660:	adrp	x0, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    f664:	add	x0, x0, #0xe13
    f668:	mov	x1, x19
    f66c:	bl	d300 <printf@plt>
    f670:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    f674:	ldr	x8, [x8, #4016]
    f678:	mov	x0, x19
    f67c:	ldr	x20, [x8]
    f680:	bl	bf70 <strlen@plt>
    f684:	add	x1, x0, #0x1
    f688:	mov	x0, x19
    f68c:	blr	x20
    f690:	ldp	x20, x19, [sp, #32]
    f694:	ldp	x29, x30, [sp, #16]
    f698:	add	sp, sp, #0x30
    f69c:	ret

000000000000f6a0 <__gmpf_size@@Base>:
    f6a0:	ldr	w8, [x0, #4]
    f6a4:	cmp	w8, #0x0
    f6a8:	cneg	w0, w8, mi  // mi = first
    f6ac:	ret

000000000000f6b0 <__gmpf_eq@@Base>:
    f6b0:	ldrsw	x10, [x0, #4]
    f6b4:	ldrsw	x9, [x1, #4]
    f6b8:	eor	w11, w9, w10
    f6bc:	tbnz	w11, #31, f7cc <__gmpf_eq@@Base+0x11c>
    f6c0:	orr	w11, w9, w10
    f6c4:	cmp	w11, #0x0
    f6c8:	mov	x8, x0
    f6cc:	cset	w0, eq  // eq = none
    f6d0:	cbz	w10, f800 <__gmpf_eq@@Base+0x150>
    f6d4:	cbz	w9, f800 <__gmpf_eq@@Base+0x150>
    f6d8:	ldr	x11, [x8, #8]
    f6dc:	ldr	x12, [x1, #8]
    f6e0:	cmp	x11, x12
    f6e4:	b.ne	f7cc <__gmpf_eq@@Base+0x11c>  // b.any
    f6e8:	ldr	x8, [x8, #16]
    f6ec:	cmp	x10, #0x0
    f6f0:	ldr	x12, [x1, #16]
    f6f4:	cneg	x11, x10, mi  // mi = first
    f6f8:	add	x13, x8, x11, lsl #3
    f6fc:	cmp	x9, #0x0
    f700:	mov	x10, x13
    f704:	ldr	x8, [x10, #-8]!
    f708:	cneg	x9, x9, mi  // mi = first
    f70c:	add	x16, x12, x9, lsl #3
    f710:	ldur	x12, [x16, #-8]
    f714:	clz	x8, x8
    f718:	mov	w14, #0x3f                  	// #63
    f71c:	sub	w14, w14, w8
    f720:	lsr	x12, x12, x14
    f724:	cmp	x12, #0x1
    f728:	b.ne	f7cc <__gmpf_eq@@Base+0x11c>  // b.any
    f72c:	add	x8, x8, x2
    f730:	add	x12, x8, #0x3f
    f734:	lsr	x14, x12, #6
    f738:	cmp	x11, x12, lsr #6
    f73c:	csel	x11, x11, x14, lt  // lt = tstop
    f740:	cmp	x9, x12, lsr #6
    f744:	csel	x12, x9, x14, lt  // lt = tstop
    f748:	cmp	x11, x12
    f74c:	add	x9, x11, x12
    f750:	csel	x15, x11, x12, lt  // lt = tstop
    f754:	sub	x9, x9, x15
    f758:	sub	x13, x13, x15, lsl #3
    f75c:	sub	x14, x16, x15, lsl #3
    f760:	sub	x16, x16, #0x8
    f764:	mov	x17, x15
    f768:	cmp	x17, #0x2
    f76c:	b.lt	f788 <__gmpf_eq@@Base+0xd8>  // b.tstop
    f770:	ldr	x18, [x10], #-8
    f774:	ldr	x0, [x16], #-8
    f778:	sub	x17, x17, #0x1
    f77c:	cmp	x18, x0
    f780:	b.eq	f768 <__gmpf_eq@@Base+0xb8>  // b.none
    f784:	b	f7cc <__gmpf_eq@@Base+0x11c>
    f788:	ldr	x16, [x13]
    f78c:	ldr	x17, [x14]
    f790:	subs	x10, x9, x15
    f794:	b.eq	f7d4 <__gmpf_eq@@Base+0x124>  // b.none
    f798:	cmp	x16, x17
    f79c:	b.ne	f7cc <__gmpf_eq@@Base+0x11c>  // b.any
    f7a0:	cmp	x11, x12
    f7a4:	csel	x11, x13, x14, gt
    f7a8:	neg	x15, x10
    f7ac:	sub	x12, x11, #0x8
    f7b0:	cmp	x10, #0x2
    f7b4:	b.lt	f7dc <__gmpf_eq@@Base+0x12c>  // b.tstop
    f7b8:	ldr	x13, [x12], #-8
    f7bc:	mov	w0, wzr
    f7c0:	sub	x10, x10, #0x1
    f7c4:	cbz	x13, f7b0 <__gmpf_eq@@Base+0x100>
    f7c8:	b	f800 <__gmpf_eq@@Base+0x150>
    f7cc:	mov	w0, wzr
    f7d0:	ret
    f7d4:	eor	x10, x17, x16
    f7d8:	b	f7e0 <__gmpf_eq@@Base+0x130>
    f7dc:	ldr	x10, [x11, x15, lsl #3]
    f7e0:	sub	x8, x8, x9, lsl #6
    f7e4:	add	x8, x8, #0x40
    f7e8:	mov	w9, #0x40                  	// #64
    f7ec:	subs	x8, x9, x8
    f7f0:	csel	x8, xzr, x8, cc  // cc = lo, ul, last
    f7f4:	lsr	x8, x10, x8
    f7f8:	cmp	x8, #0x0
    f7fc:	cset	w0, eq  // eq = none
    f800:	ret

000000000000f804 <__gmpf_reldiff@@Base>:
    f804:	stp	x29, x30, [sp, #-48]!
    f808:	str	x21, [sp, #16]
    f80c:	stp	x20, x19, [sp, #32]
    f810:	mov	x29, sp
    f814:	sub	sp, sp, #0x20
    f818:	ldr	w8, [x1, #4]
    f81c:	mov	x21, x2
    f820:	mov	x19, x0
    f824:	cbz	w8, f8bc <__gmpf_reldiff@@Base+0xb8>
    f828:	str	xzr, [x29, #24]
    f82c:	ldr	w9, [x19]
    f830:	cmp	w8, #0x0
    f834:	cneg	w8, w8, mi  // mi = first
    f838:	mov	x20, x1
    f83c:	add	w8, w9, w8
    f840:	sbfiz	x9, x8, #3, #32
    f844:	add	x1, x9, #0x8
    f848:	mov	w9, #0x7f00                	// #32512
    f84c:	cmp	x1, x9
    f850:	stur	w8, [x29, #-24]
    f854:	b.hi	f8e0 <__gmpf_reldiff@@Base+0xdc>  // b.pmore
    f858:	add	x9, x1, #0xf
    f85c:	mov	x8, sp
    f860:	and	x9, x9, #0xfffffffffffffff0
    f864:	sub	x0, x8, x9
    f868:	mov	sp, x0
    f86c:	stur	x0, [x29, #-8]
    f870:	sub	x0, x29, #0x18
    f874:	mov	x1, x20
    f878:	mov	x2, x21
    f87c:	bl	ce20 <__gmpf_sub@plt>
    f880:	ldur	w8, [x29, #-20]
    f884:	sub	x1, x29, #0x18
    f888:	mov	x0, x19
    f88c:	mov	x2, x20
    f890:	cmp	w8, #0x0
    f894:	cneg	w8, w8, mi  // mi = first
    f898:	stur	w8, [x29, #-20]
    f89c:	bl	cef0 <__gmpf_div@plt>
    f8a0:	ldr	x0, [x29, #24]
    f8a4:	cbnz	x0, f8ec <__gmpf_reldiff@@Base+0xe8>
    f8a8:	mov	sp, x29
    f8ac:	ldp	x20, x19, [sp, #32]
    f8b0:	ldr	x21, [sp, #16]
    f8b4:	ldp	x29, x30, [sp], #48
    f8b8:	ret
    f8bc:	ldr	w8, [x21, #4]
    f8c0:	mov	x0, x19
    f8c4:	cmp	w8, #0x0
    f8c8:	cset	w1, ne  // ne = any
    f8cc:	mov	sp, x29
    f8d0:	ldp	x20, x19, [sp, #32]
    f8d4:	ldr	x21, [sp, #16]
    f8d8:	ldp	x29, x30, [sp], #48
    f8dc:	b	c6c0 <__gmpf_set_ui@plt>
    f8e0:	add	x0, x29, #0x18
    f8e4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    f8e8:	b	f86c <__gmpf_reldiff@@Base+0x68>
    f8ec:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
    f8f0:	b	f8a8 <__gmpf_reldiff@@Base+0xa4>

000000000000f8f4 <__gmpf_sqrt@@Base>:
    f8f4:	stp	x29, x30, [sp, #-80]!
    f8f8:	stp	x26, x25, [sp, #16]
    f8fc:	stp	x24, x23, [sp, #32]
    f900:	stp	x22, x21, [sp, #48]
    f904:	stp	x20, x19, [sp, #64]
    f908:	mov	x29, sp
    f90c:	sub	sp, sp, #0x10
    f910:	ldrsw	x20, [x1, #4]
    f914:	mov	x19, x0
    f918:	cmp	w20, #0x0
    f91c:	b.le	f9f4 <__gmpf_sqrt@@Base+0x100>
    f920:	stur	xzr, [x29, #-8]
    f924:	ldp	x8, x22, [x1, #8]
    f928:	ldrsw	x9, [x19]
    f92c:	mov	w10, #0x7f00                	// #32512
    f930:	and	x24, x8, #0x1
    f934:	lsl	x25, x9, #1
    f938:	add	x8, x24, x8
    f93c:	sub	x21, x25, x24
    f940:	cmp	x8, #0x0
    f944:	lsl	x1, x21, #3
    f948:	cinc	x8, x8, lt  // lt = tstop
    f94c:	cmp	x1, x10
    f950:	asr	x8, x8, #1
    f954:	str	w9, [x19, #4]
    f958:	str	x8, [x19, #8]
    f95c:	b.hi	fa04 <__gmpf_sqrt@@Base+0x110>  // b.pmore
    f960:	add	x9, x1, #0xf
    f964:	mov	x8, sp
    f968:	and	x9, x9, #0xfffffffffffffff0
    f96c:	sub	x23, x8, x9
    f970:	mov	sp, x23
    f974:	subs	x26, x21, x20
    f978:	b.ge	f990 <__gmpf_sqrt@@Base+0x9c>  // b.tcont
    f97c:	sub	x8, x20, x21
    f980:	add	x1, x22, x8, lsl #3
    f984:	mov	x0, x23
    f988:	mov	x2, x21
    f98c:	b	f9b8 <__gmpf_sqrt@@Base+0xc4>
    f990:	b.eq	f9ac <__gmpf_sqrt@@Base+0xb8>  // b.none
    f994:	sub	x8, x25, x20
    f998:	sub	x8, x8, x24
    f99c:	lsl	x2, x8, #3
    f9a0:	mov	x0, x23
    f9a4:	mov	w1, wzr
    f9a8:	bl	c610 <memset@plt>
    f9ac:	add	x0, x23, x26, lsl #3
    f9b0:	mov	x1, x22
    f9b4:	mov	x2, x20
    f9b8:	bl	ca70 <__gmpn_copyi@plt>
    f9bc:	ldr	x0, [x19, #16]
    f9c0:	mov	x1, xzr
    f9c4:	mov	x2, x23
    f9c8:	mov	x3, x21
    f9cc:	bl	d3d0 <__gmpn_sqrtrem@plt>
    f9d0:	ldur	x0, [x29, #-8]
    f9d4:	cbnz	x0, fa14 <__gmpf_sqrt@@Base+0x120>
    f9d8:	mov	sp, x29
    f9dc:	ldp	x20, x19, [sp, #64]
    f9e0:	ldp	x22, x21, [sp, #48]
    f9e4:	ldp	x24, x23, [sp, #32]
    f9e8:	ldp	x26, x25, [sp, #16]
    f9ec:	ldp	x29, x30, [sp], #80
    f9f0:	ret
    f9f4:	tbnz	w20, #31, fa1c <__gmpf_sqrt@@Base+0x128>
    f9f8:	str	wzr, [x19, #4]
    f9fc:	str	xzr, [x19, #8]
    fa00:	b	f9d8 <__gmpf_sqrt@@Base+0xe4>
    fa04:	sub	x0, x29, #0x8
    fa08:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    fa0c:	mov	x23, x0
    fa10:	b	f974 <__gmpf_sqrt@@Base+0x80>
    fa14:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
    fa18:	b	f9d8 <__gmpf_sqrt@@Base+0xe4>
    fa1c:	bl	d010 <__gmp_sqrt_of_negative@plt>

000000000000fa20 <__gmpf_random2@@Base>:
    fa20:	sub	sp, sp, #0x40
    fa24:	cmp	x1, #0x0
    fa28:	stp	x20, x19, [sp, #48]
    fa2c:	cneg	x8, x1, mi  // mi = first
    fa30:	mov	x19, x0
    fa34:	stp	x29, x30, [sp, #16]
    fa38:	stp	x22, x21, [sp, #32]
    fa3c:	add	x29, sp, #0x10
    fa40:	cbz	x8, fad8 <__gmpf_random2@@Base+0xb8>
    fa44:	ldrsw	x9, [x19]
    fa48:	ldr	x0, [x19, #16]
    fa4c:	mov	x20, x1
    fa50:	mov	x21, x2
    fa54:	add	x10, x9, #0x1
    fa58:	cmp	x8, x10
    fa5c:	csinc	x22, x8, x9, le
    fa60:	mov	x1, x22
    fa64:	bl	d1e0 <__gmpn_random2@plt>
    fa68:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    fa6c:	ldr	x8, [x8, #4040]
    fa70:	ldrb	w9, [x8]
    fa74:	cbnz	w9, fa8c <__gmpf_random2@@Base+0x6c>
    fa78:	mov	w9, #0x1                   	// #1
    fa7c:	strb	w9, [x8]
    fa80:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    fa84:	ldr	x0, [x0, #3976]
    fa88:	bl	bf40 <__gmp_randinit_mt_noseed@plt>
    fa8c:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    fa90:	ldr	x0, [x0, #3976]
    fa94:	add	x1, sp, #0x8
    fa98:	mov	w2, #0x40                  	// #64
    fa9c:	ldr	x8, [x0, #24]
    faa0:	ldr	x8, [x8, #8]
    faa4:	blr	x8
    faa8:	ldr	x8, [sp, #8]
    faac:	cmp	x21, #0x0
    fab0:	mov	w9, #0x1                   	// #1
    fab4:	cneg	x10, x21, mi  // mi = first
    fab8:	bfi	x9, x10, #1, #63
    fabc:	udiv	x11, x8, x9
    fac0:	msub	x8, x11, x9, x8
    fac4:	cmp	x20, #0x0
    fac8:	sub	x8, x8, x10
    facc:	str	x8, [x19, #8]
    fad0:	cneg	w8, w22, lt  // lt = tstop
    fad4:	b	fadc <__gmpf_random2@@Base+0xbc>
    fad8:	str	xzr, [x19, #8]
    fadc:	str	w8, [x19, #4]
    fae0:	ldp	x20, x19, [sp, #48]
    fae4:	ldp	x22, x21, [sp, #32]
    fae8:	ldp	x29, x30, [sp, #16]
    faec:	add	sp, sp, #0x40
    faf0:	ret

000000000000faf4 <__gmpf_inp_str@@Base>:
    faf4:	sub	sp, sp, #0x70
    faf8:	stp	x29, x30, [sp, #16]
    fafc:	add	x29, sp, #0x10
    fb00:	stp	x28, x27, [sp, #32]
    fb04:	stp	x26, x25, [sp, #48]
    fb08:	stp	x24, x23, [sp, #64]
    fb0c:	stp	x22, x21, [sp, #80]
    fb10:	stp	x20, x19, [sp, #96]
    fb14:	stur	w2, [x29, #-4]
    fb18:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    fb1c:	ldr	x8, [x8, #3888]
    fb20:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    fb24:	mov	x20, x0
    fb28:	cmp	x1, #0x0
    fb2c:	ldr	x8, [x8]
    fb30:	ldr	x9, [x9, #3840]
    fb34:	mov	w0, #0x64                  	// #100
    fb38:	csel	x22, x8, x1, eq  // eq = none
    fb3c:	ldr	x9, [x9]
    fb40:	blr	x9
    fb44:	mov	x21, x0
    fb48:	mov	x27, #0xffffffffffffffff    	// #-1
    fb4c:	mov	x0, x22
    fb50:	bl	c810 <getc@plt>
    fb54:	mov	w24, w0
    fb58:	bl	cb00 <__ctype_b_loc@plt>
    fb5c:	ldr	x8, [x0]
    fb60:	add	x27, x27, #0x1
    fb64:	ldrh	w8, [x8, w24, sxtw #1]
    fb68:	tbnz	w8, #13, fb4c <__gmpf_inp_str@@Base+0x58>
    fb6c:	adrp	x19, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    fb70:	ldr	x19, [x19, #3792]
    fb74:	mov	x25, x0
    fb78:	mov	x28, xzr
    fb7c:	mov	w23, #0x64                  	// #100
    fb80:	cmp	x28, x23
    fb84:	b.cc	fbac <__gmpf_inp_str@@Base+0xb8>  // b.lo, b.ul, b.last
    fb88:	ldr	x8, [x19]
    fb8c:	add	x9, x23, x23, lsl #1
    fb90:	lsr	x26, x9, #1
    fb94:	mov	x0, x21
    fb98:	mov	x1, x23
    fb9c:	mov	x2, x26
    fba0:	blr	x8
    fba4:	mov	x21, x0
    fba8:	mov	x23, x26
    fbac:	cmn	w24, #0x1
    fbb0:	b.eq	fbdc <__gmpf_inp_str@@Base+0xe8>  // b.none
    fbb4:	ldr	x8, [x25]
    fbb8:	ldrh	w8, [x8, w24, sxtw #1]
    fbbc:	tbnz	w8, #13, fbdc <__gmpf_inp_str@@Base+0xe8>
    fbc0:	mov	x0, x22
    fbc4:	add	x26, x28, #0x1
    fbc8:	strb	w24, [x21, x28]
    fbcc:	bl	c810 <getc@plt>
    fbd0:	mov	w24, w0
    fbd4:	mov	x28, x26
    fbd8:	b	fb80 <__gmpf_inp_str@@Base+0x8c>
    fbdc:	mov	w0, w24
    fbe0:	mov	x1, x22
    fbe4:	bl	cc70 <ungetc@plt>
    fbe8:	cmp	x28, x23
    fbec:	b.cc	fc14 <__gmpf_inp_str@@Base+0x120>  // b.lo, b.ul, b.last
    fbf0:	ldr	x8, [x19]
    fbf4:	add	x9, x23, x23, lsl #1
    fbf8:	lsr	x22, x9, #1
    fbfc:	mov	x0, x21
    fc00:	mov	x1, x23
    fc04:	mov	x2, x22
    fc08:	blr	x8
    fc0c:	mov	x21, x0
    fc10:	mov	x23, x22
    fc14:	ldur	w2, [x29, #-4]
    fc18:	mov	x0, x20
    fc1c:	mov	x1, x21
    fc20:	strb	wzr, [x21, x28]
    fc24:	bl	c1d0 <__gmpf_set_str@plt>
    fc28:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    fc2c:	ldr	x8, [x8, #4016]
    fc30:	mov	w19, w0
    fc34:	mov	x0, x21
    fc38:	mov	x1, x23
    fc3c:	ldr	x8, [x8]
    fc40:	blr	x8
    fc44:	add	x8, x27, x28
    fc48:	cmn	w19, #0x1
    fc4c:	ldp	x20, x19, [sp, #96]
    fc50:	ldp	x22, x21, [sp, #80]
    fc54:	ldp	x24, x23, [sp, #64]
    fc58:	ldp	x26, x25, [sp, #48]
    fc5c:	ldp	x28, x27, [sp, #32]
    fc60:	ldp	x29, x30, [sp, #16]
    fc64:	csel	x0, xzr, x8, eq  // eq = none
    fc68:	add	sp, sp, #0x70
    fc6c:	ret

000000000000fc70 <__gmpf_out_str@@Base>:
    fc70:	stp	x29, x30, [sp, #-80]!
    fc74:	str	x25, [sp, #16]
    fc78:	stp	x24, x23, [sp, #32]
    fc7c:	stp	x22, x21, [sp, #48]
    fc80:	stp	x20, x19, [sp, #64]
    fc84:	mov	x29, sp
    fc88:	sub	sp, sp, #0x10
    fc8c:	cmp	w1, #0x0
    fc90:	mov	w8, #0xa                   	// #10
    fc94:	mov	x22, x3
    fc98:	mov	x23, x2
    fc9c:	csel	w19, w8, w1, eq  // eq = none
    fca0:	stur	xzr, [x29, #-8]
    fca4:	cbnz	x2, fcd0 <__gmpf_out_str@@Base+0x60>
    fca8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    fcac:	ldr	x8, [x8, #3936]
    fcb0:	ldrsw	x10, [x22]
    fcb4:	mov	w9, #0x28                  	// #40
    fcb8:	smaddl	x8, w19, w9, x8
    fcbc:	ldr	x8, [x8, #8]
    fcc0:	lsl	x9, x10, #6
    fcc4:	sub	x9, x9, #0x40
    fcc8:	umulh	x8, x8, x9
    fccc:	add	x23, x8, #0x2
    fcd0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
    fcd4:	ldr	x8, [x8, #3856]
    fcd8:	cmp	x0, #0x0
    fcdc:	add	x1, x23, #0x2
    fce0:	mov	w9, #0x7f00                	// #32512
    fce4:	ldr	x8, [x8]
    fce8:	csel	x20, x8, x0, eq  // eq = none
    fcec:	cmp	x1, x9
    fcf0:	b.hi	fe0c <__gmpf_out_str@@Base+0x19c>  // b.pmore
    fcf4:	add	x9, x1, #0xf
    fcf8:	mov	x8, sp
    fcfc:	and	x9, x9, #0xfffffffffffffff0
    fd00:	sub	x21, x8, x9
    fd04:	mov	sp, x21
    fd08:	add	x1, x29, #0x18
    fd0c:	mov	x0, x21
    fd10:	mov	w2, w19
    fd14:	mov	x3, x23
    fd18:	mov	x4, x22
    fd1c:	bl	ce40 <__gmpf_get_str@plt>
    fd20:	mov	x0, x21
    fd24:	bl	bf70 <strlen@plt>
    fd28:	ldrb	w8, [x21]
    fd2c:	mov	x22, x0
    fd30:	cmp	w8, #0x2d
    fd34:	b.ne	fd54 <__gmpf_out_str@@Base+0xe4>  // b.any
    fd38:	mov	w0, #0x2d                  	// #45
    fd3c:	mov	x1, x20
    fd40:	add	x21, x21, #0x1
    fd44:	bl	c220 <fputc@plt>
    fd48:	sub	x22, x22, #0x1
    fd4c:	mov	w25, #0x2                   	// #2
    fd50:	b	fd58 <__gmpf_out_str@@Base+0xe8>
    fd54:	mov	w25, #0x1                   	// #1
    fd58:	mov	w0, #0x10000               	// #65536
    fd5c:	bl	c420 <nl_langinfo@plt>
    fd60:	mov	x23, x0
    fd64:	bl	bf70 <strlen@plt>
    fd68:	mov	x24, x0
    fd6c:	mov	w0, #0x30                  	// #48
    fd70:	mov	x1, x20
    fd74:	bl	c1f0 <putc@plt>
    fd78:	mov	w1, #0x1                   	// #1
    fd7c:	mov	x0, x23
    fd80:	mov	x2, x24
    fd84:	mov	x3, x20
    fd88:	bl	ce50 <fwrite@plt>
    fd8c:	mov	w1, #0x1                   	// #1
    fd90:	mov	x0, x21
    fd94:	mov	x2, x22
    fd98:	mov	x3, x20
    fd9c:	bl	ce50 <fwrite@plt>
    fda0:	ldr	x2, [x29, #24]
    fda4:	adrp	x8, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    fda8:	adrp	x9, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
    fdac:	add	x8, x8, #0xe22
    fdb0:	add	x9, x9, #0xe1d
    fdb4:	cmp	w19, #0xb
    fdb8:	mov	x21, x0
    fdbc:	csel	x1, x9, x8, lt  // lt = tstop
    fdc0:	mov	x0, x20
    fdc4:	bl	d440 <fprintf@plt>
    fdc8:	mov	w8, w0
    fdcc:	ldur	x0, [x29, #-8]
    fdd0:	add	x9, x25, x24
    fdd4:	add	x9, x9, x21
    fdd8:	add	x19, x9, w8, sxtw
    fddc:	cbnz	x0, fe1c <__gmpf_out_str@@Base+0x1ac>
    fde0:	mov	x0, x20
    fde4:	bl	d4c0 <ferror@plt>
    fde8:	cmp	w0, #0x0
    fdec:	csel	x0, x19, xzr, eq  // eq = none
    fdf0:	mov	sp, x29
    fdf4:	ldp	x20, x19, [sp, #64]
    fdf8:	ldp	x22, x21, [sp, #48]
    fdfc:	ldp	x24, x23, [sp, #32]
    fe00:	ldr	x25, [sp, #16]
    fe04:	ldp	x29, x30, [sp], #80
    fe08:	ret
    fe0c:	sub	x0, x29, #0x8
    fe10:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
    fe14:	mov	x21, x0
    fe18:	b	fd08 <__gmpf_out_str@@Base+0x98>
    fe1c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
    fe20:	b	fde0 <__gmpf_out_str@@Base+0x170>

000000000000fe24 <__gmpf_add@@Base>:
    fe24:	stp	x29, x30, [sp, #-96]!
    fe28:	stp	x28, x27, [sp, #16]
    fe2c:	stp	x26, x25, [sp, #32]
    fe30:	stp	x24, x23, [sp, #48]
    fe34:	stp	x22, x21, [sp, #64]
    fe38:	stp	x20, x19, [sp, #80]
    fe3c:	mov	x29, sp
    fe40:	sub	sp, sp, #0x30
    fe44:	ldr	w20, [x1, #4]
    fe48:	mov	x19, x0
    fe4c:	cbz	w20, ff94 <__gmpf_add@@Base+0x170>
    fe50:	ldr	w8, [x2, #4]
    fe54:	cbz	w8, ff90 <__gmpf_add@@Base+0x16c>
    fe58:	eor	w9, w8, w20
    fe5c:	tbnz	w9, #31, ffac <__gmpf_add@@Base+0x188>
    fe60:	stur	xzr, [x29, #-24]
    fe64:	ldr	x9, [x1, #8]
    fe68:	ldr	x10, [x2, #8]
    fe6c:	ldrsw	x28, [x19]
    fe70:	ldr	x0, [x19, #16]
    fe74:	mov	w11, #0x7f00                	// #32512
    fe78:	cmp	x9, x10
    fe7c:	csel	x10, x1, x2, lt  // lt = tstop
    fe80:	csel	x12, x2, x1, lt  // lt = tstop
    fe84:	csel	w9, w20, w8, lt  // lt = tstop
    fe88:	csel	w8, w8, w20, lt  // lt = tstop
    fe8c:	ldp	x14, x13, [x12, #8]
    fe90:	ldp	x23, x12, [x10, #8]
    fe94:	sxtw	x8, w8
    fe98:	sxtw	x9, w9
    fe9c:	cmp	x8, #0x0
    fea0:	cneg	x8, x8, mi  // mi = first
    fea4:	cmp	x9, #0x0
    fea8:	cneg	x9, x9, mi  // mi = first
    feac:	subs	x10, x8, x28
    feb0:	sub	x27, x14, x23
    feb4:	add	x10, x13, x10, lsl #3
    feb8:	csel	x22, x28, x8, gt
    febc:	add	x8, x27, x9
    fec0:	csel	x24, x10, x13, gt
    fec4:	subs	x8, x8, x28
    fec8:	sub	x10, x28, x27
    fecc:	add	x8, x12, x8, lsl #3
    fed0:	lsl	x1, x28, #3
    fed4:	csel	x25, x10, x9, gt
    fed8:	csel	x26, x8, x12, gt
    fedc:	cmp	x1, x11
    fee0:	stur	x14, [x29, #-32]
    fee4:	b.hi	10194 <__gmpf_add@@Base+0x370>  // b.pmore
    fee8:	add	x9, x1, #0xf
    feec:	mov	x8, sp
    fef0:	and	x9, x9, #0xfffffffffffffff0
    fef4:	sub	x21, x8, x9
    fef8:	mov	sp, x21
    fefc:	cmp	x27, x28
    ff00:	b.ge	ffcc <__gmpf_add@@Base+0x1a8>  // b.tcont
    ff04:	subs	x8, x22, x27
    ff08:	add	x9, x25, x27
    ff0c:	stur	x9, [x29, #-40]
    ff10:	b.le	ffe8 <__gmpf_add@@Base+0x1c4>
    ff14:	subs	x28, x9, x22
    ff18:	stur	x0, [x29, #-48]
    ff1c:	b.le	10038 <__gmpf_add@@Base+0x214>
    ff20:	mov	x0, x21
    ff24:	mov	x1, x26
    ff28:	mov	x2, x28
    ff2c:	bl	ca70 <__gmpn_copyi@plt>
    ff30:	subs	x25, x22, x27
    ff34:	add	x27, x21, x28, lsl #3
    ff38:	b.eq	100b0 <__gmpf_add@@Base+0x28c>  // b.none
    ff3c:	add	x2, x26, x28, lsl #3
    ff40:	mov	x0, x27
    ff44:	mov	x1, x24
    ff48:	mov	x3, x25
    ff4c:	bl	ca90 <__gmpn_add_n@plt>
    ff50:	cbz	x0, 100b0 <__gmpf_add@@Base+0x28c>
    ff54:	ldp	x12, x8, [x29, #-48]
    ff58:	mov	w26, #0x1                   	// #1
    ff5c:	add	x8, x23, x8
    ff60:	ldur	x23, [x29, #-32]
    ff64:	lsl	x8, x8, #3
    ff68:	sub	x8, x8, x23, lsl #3
    ff6c:	add	x8, x21, x8
    ff70:	cmp	x25, x22
    ff74:	b.ge	10134 <__gmpf_add@@Base+0x310>  // b.tcont
    ff78:	ldr	x9, [x24, x25, lsl #3]
    ff7c:	add	x25, x25, #0x1
    ff80:	adds	x9, x9, #0x1
    ff84:	str	x9, [x8], #8
    ff88:	b.cs	ff70 <__gmpf_add@@Base+0x14c>  // b.hs, b.nlast
    ff8c:	b	100b8 <__gmpf_add@@Base+0x294>
    ff90:	mov	x2, x1
    ff94:	cmp	x2, x19
    ff98:	b.eq	10174 <__gmpf_add@@Base+0x350>  // b.none
    ff9c:	mov	x0, x19
    ffa0:	mov	x1, x2
    ffa4:	bl	c160 <__gmpf_set@plt>
    ffa8:	b	10174 <__gmpf_add@@Base+0x350>
    ffac:	neg	w8, w8
    ffb0:	stur	w8, [x29, #-20]
    ffb4:	ldur	q0, [x2, #8]
    ffb8:	sub	x2, x29, #0x18
    ffbc:	mov	x0, x19
    ffc0:	stur	q0, [x29, #-16]
    ffc4:	bl	ce20 <__gmpf_sub@plt>
    ffc8:	b	10174 <__gmpf_add@@Base+0x350>
    ffcc:	cmp	x0, x24
    ffd0:	b.eq	ffe0 <__gmpf_add@@Base+0x1bc>  // b.none
    ffd4:	mov	x1, x24
    ffd8:	mov	x2, x22
    ffdc:	bl	ca70 <__gmpn_copyi@plt>
    ffe0:	ldur	x23, [x29, #-32]
    ffe4:	b	10158 <__gmpf_add@@Base+0x334>
    ffe8:	mov	x28, x0
    ffec:	mov	x0, x21
    fff0:	mov	x1, x26
    fff4:	mov	x2, x25
    fff8:	sub	x23, x9, x22
    fffc:	bl	ca70 <__gmpn_copyi@plt>
   10000:	subs	x8, x27, x22
   10004:	b.eq	10018 <__gmpf_add@@Base+0x1f4>  // b.none
   10008:	add	x0, x21, x25, lsl #3
   1000c:	lsl	x2, x8, #3
   10010:	mov	w1, wzr
   10014:	bl	c610 <memset@plt>
   10018:	add	x0, x21, x23, lsl #3
   1001c:	mov	x1, x24
   10020:	mov	x2, x22
   10024:	bl	ca70 <__gmpn_copyi@plt>
   10028:	ldur	x23, [x29, #-32]
   1002c:	mov	x26, xzr
   10030:	mov	x12, x28
   10034:	b	10134 <__gmpf_add@@Base+0x310>
   10038:	sub	x27, x8, x25
   1003c:	mov	x0, x21
   10040:	mov	x1, x24
   10044:	mov	x2, x27
   10048:	bl	ca70 <__gmpn_copyi@plt>
   1004c:	sub	x28, x22, x27
   10050:	cbz	x25, 100f0 <__gmpf_add@@Base+0x2cc>
   10054:	add	x0, x21, x27, lsl #3
   10058:	add	x1, x24, x27, lsl #3
   1005c:	mov	x2, x26
   10060:	mov	x3, x25
   10064:	bl	ca90 <__gmpn_add_n@plt>
   10068:	cbz	x0, 100f0 <__gmpf_add@@Base+0x2cc>
   1006c:	add	x8, x23, x22
   10070:	ldur	x23, [x29, #-32]
   10074:	ldur	x12, [x29, #-48]
   10078:	lsl	x9, x8, #3
   1007c:	mov	w26, #0x1                   	// #1
   10080:	sub	x8, x8, x23
   10084:	sub	x9, x9, x23, lsl #3
   10088:	add	x8, x24, x8, lsl #3
   1008c:	add	x9, x21, x9
   10090:	cmp	x25, x28
   10094:	b.ge	10130 <__gmpf_add@@Base+0x30c>  // b.tcont
   10098:	ldr	x10, [x8], #8
   1009c:	add	x25, x25, #0x1
   100a0:	adds	x10, x10, #0x1
   100a4:	str	x10, [x9], #8
   100a8:	b.cs	10090 <__gmpf_add@@Base+0x26c>  // b.hs, b.nlast
   100ac:	b	100f8 <__gmpf_add@@Base+0x2d4>
   100b0:	ldur	x23, [x29, #-32]
   100b4:	ldur	x12, [x29, #-48]
   100b8:	cmp	x27, x24
   100bc:	mov	x26, xzr
   100c0:	b.eq	10134 <__gmpf_add@@Base+0x310>  // b.none
   100c4:	subs	x8, x25, x22
   100c8:	b.ge	10134 <__gmpf_add@@Base+0x310>  // b.tcont
   100cc:	ldur	x9, [x29, #-40]
   100d0:	add	x10, x24, x25, lsl #3
   100d4:	add	x9, x21, x9, lsl #3
   100d8:	ldr	x11, [x10], #8
   100dc:	str	x11, [x9, x8, lsl #3]
   100e0:	adds	x8, x8, #0x1
   100e4:	b.cc	100d8 <__gmpf_add@@Base+0x2b4>  // b.lo, b.ul, b.last
   100e8:	mov	x26, xzr
   100ec:	b	10134 <__gmpf_add@@Base+0x310>
   100f0:	ldur	x23, [x29, #-32]
   100f4:	ldur	x12, [x29, #-48]
   100f8:	cmp	x24, x21
   100fc:	mov	x26, xzr
   10100:	b.eq	10130 <__gmpf_add@@Base+0x30c>  // b.none
   10104:	cmp	x25, x28
   10108:	b.ge	10130 <__gmpf_add@@Base+0x30c>  // b.tcont
   1010c:	ldur	x8, [x29, #-40]
   10110:	add	x9, x21, x22, lsl #3
   10114:	add	x10, x24, x22, lsl #3
   10118:	sub	x8, x25, x8
   1011c:	ldr	x11, [x10, x8, lsl #3]
   10120:	str	x11, [x9, x8, lsl #3]
   10124:	adds	x8, x8, #0x1
   10128:	b.cc	1011c <__gmpf_add@@Base+0x2f8>  // b.lo, b.ul, b.last
   1012c:	mov	x26, xzr
   10130:	stur	x22, [x29, #-40]
   10134:	mov	x1, x21
   10138:	ldur	x21, [x29, #-40]
   1013c:	mov	x0, x12
   10140:	mov	x22, x12
   10144:	mov	x2, x21
   10148:	bl	ca70 <__gmpn_copyi@plt>
   1014c:	str	x26, [x22, x21, lsl #3]
   10150:	add	x22, x26, x21
   10154:	add	x23, x26, x23
   10158:	neg	w8, w22
   1015c:	cmp	w20, #0x0
   10160:	csel	x8, x8, x22, lt  // lt = tstop
   10164:	str	w8, [x19, #4]
   10168:	str	x23, [x19, #8]
   1016c:	ldur	x0, [x29, #-24]
   10170:	cbnz	x0, 101ac <__gmpf_add@@Base+0x388>
   10174:	mov	sp, x29
   10178:	ldp	x20, x19, [sp, #80]
   1017c:	ldp	x22, x21, [sp, #64]
   10180:	ldp	x24, x23, [sp, #48]
   10184:	ldp	x26, x25, [sp, #32]
   10188:	ldp	x28, x27, [sp, #16]
   1018c:	ldp	x29, x30, [sp], #96
   10190:	ret
   10194:	stur	x0, [x29, #-48]
   10198:	sub	x0, x29, #0x18
   1019c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   101a0:	mov	x21, x0
   101a4:	ldur	x0, [x29, #-48]
   101a8:	b	fefc <__gmpf_add@@Base+0xd8>
   101ac:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   101b0:	b	10174 <__gmpf_add@@Base+0x350>

00000000000101b4 <__gmpf_add_ui@@Base>:
   101b4:	sub	sp, sp, #0x60
   101b8:	stp	x29, x30, [sp, #32]
   101bc:	stp	x24, x23, [sp, #48]
   101c0:	stp	x22, x21, [sp, #64]
   101c4:	stp	x20, x19, [sp, #80]
   101c8:	mov	x23, x1
   101cc:	ldrsw	x22, [x1, #4]
   101d0:	ldr	x1, [x1, #16]
   101d4:	ldr	x24, [x23, #8]
   101d8:	mov	x21, x2
   101dc:	cmp	w22, #0x0
   101e0:	mov	x19, x0
   101e4:	add	x29, sp, #0x20
   101e8:	b.le	10238 <__gmpf_add_ui@@Base+0x84>
   101ec:	ldr	x20, [x19, #16]
   101f0:	ldrsw	x8, [x19]
   101f4:	cbz	x21, 10208 <__gmpf_add_ui@@Base+0x54>
   101f8:	cmp	x24, #0x1
   101fc:	b.lt	10268 <__gmpf_add_ui@@Base+0xb4>  // b.tstop
   10200:	cmp	x24, x8
   10204:	b.le	102f4 <__gmpf_add_ui@@Base+0x140>
   10208:	cmp	x23, x19
   1020c:	b.eq	1043c <__gmpf_add_ui@@Base+0x288>  // b.none
   10210:	cmp	w22, w8
   10214:	csinc	x21, x22, x8, le
   10218:	add	x8, x1, x22, lsl #3
   1021c:	sub	x1, x8, x21, lsl #3
   10220:	mov	x0, x20
   10224:	mov	x2, x21
   10228:	bl	ca70 <__gmpn_copyi@plt>
   1022c:	str	w21, [x19, #4]
   10230:	ldr	x8, [x23, #8]
   10234:	b	10344 <__gmpf_add_ui@@Base+0x190>
   10238:	cbz	w22, 102d4 <__gmpf_add_ui@@Base+0x120>
   1023c:	neg	w8, w22
   10240:	stp	x24, x1, [sp, #16]
   10244:	add	x1, sp, #0x8
   10248:	mov	x0, x19
   1024c:	mov	x2, x21
   10250:	str	w8, [sp, #12]
   10254:	bl	c200 <__gmpf_sub_ui@plt>
   10258:	ldr	w8, [x19, #4]
   1025c:	neg	w8, w8
   10260:	str	w8, [x19, #4]
   10264:	b	1043c <__gmpf_add_ui@@Base+0x288>
   10268:	neg	x9, x24
   1026c:	cmp	x9, x8
   10270:	b.ge	10338 <__gmpf_add_ui@@Base+0x184>  // b.tcont
   10274:	add	x10, x8, x24
   10278:	sub	x9, x22, x24
   1027c:	sub	x10, x22, x10
   10280:	cmp	x9, x8
   10284:	add	x8, x10, #0x1
   10288:	add	x8, x1, x8, lsl #3
   1028c:	csinc	x9, xzr, x10, lt  // lt = tstop
   10290:	csel	x1, x1, x8, lt  // lt = tstop
   10294:	cmp	x20, x1
   10298:	sub	x22, x22, x9
   1029c:	b.eq	102ac <__gmpf_add_ui@@Base+0xf8>  // b.none
   102a0:	mov	x0, x20
   102a4:	mov	x2, x22
   102a8:	bl	ca70 <__gmpn_copyi@plt>
   102ac:	cbz	x24, 102c0 <__gmpf_add_ui@@Base+0x10c>
   102b0:	add	x0, x20, x22, lsl #3
   102b4:	neg	x2, x24, lsl #3
   102b8:	mov	w1, wzr
   102bc:	bl	c610 <memset@plt>
   102c0:	sub	x8, x22, x24
   102c4:	mov	w9, #0x1                   	// #1
   102c8:	str	x21, [x20, x8, lsl #3]
   102cc:	add	w8, w8, #0x1
   102d0:	b	10434 <__gmpf_add_ui@@Base+0x280>
   102d4:	mov	x0, x19
   102d8:	mov	x1, x21
   102dc:	ldp	x20, x19, [sp, #80]
   102e0:	ldp	x22, x21, [sp, #64]
   102e4:	ldp	x24, x23, [sp, #48]
   102e8:	ldp	x29, x30, [sp, #32]
   102ec:	add	sp, sp, #0x60
   102f0:	b	c6c0 <__gmpf_set_ui@plt>
   102f4:	cmp	x24, x22
   102f8:	b.le	1034c <__gmpf_add_ui@@Base+0x198>
   102fc:	add	x8, x20, x24, lsl #3
   10300:	sub	x0, x8, x22, lsl #3
   10304:	mov	x2, x22
   10308:	bl	c010 <__gmpn_copyd@plt>
   1030c:	mvn	x8, x22
   10310:	adds	x8, x24, x8
   10314:	str	x21, [x20]
   10318:	b.eq	1032c <__gmpf_add_ui@@Base+0x178>  // b.none
   1031c:	add	x0, x20, #0x8
   10320:	lsl	x2, x8, #3
   10324:	mov	w1, wzr
   10328:	bl	c610 <memset@plt>
   1032c:	str	w24, [x19, #4]
   10330:	str	x24, [x19, #8]
   10334:	b	1043c <__gmpf_add_ui@@Base+0x288>
   10338:	mov	w8, #0x1                   	// #1
   1033c:	str	x21, [x20]
   10340:	str	w8, [x19, #4]
   10344:	str	x8, [x19, #8]
   10348:	b	1043c <__gmpf_add_ui@@Base+0x288>
   1034c:	sub	x9, x22, x8
   10350:	cmp	w22, w8
   10354:	add	x9, x1, x9, lsl #3
   10358:	csel	w8, w22, w8, lt  // lt = tstop
   1035c:	csel	x22, x9, x1, gt
   10360:	cmp	x20, x22
   10364:	sxtw	x23, w8
   10368:	b.eq	1037c <__gmpf_add_ui@@Base+0x1c8>  // b.none
   1036c:	sub	x2, x23, x24
   10370:	mov	x0, x20
   10374:	mov	x1, x22
   10378:	bl	ca70 <__gmpn_copyi@plt>
   1037c:	add	x9, x22, x23, lsl #3
   10380:	sub	x11, x9, x24, lsl #3
   10384:	ldr	x10, [x11]
   10388:	add	x8, x20, x23, lsl #3
   1038c:	sub	x13, x8, x24, lsl #3
   10390:	adds	x10, x10, x21
   10394:	str	x10, [x13]
   10398:	b.cc	103f8 <__gmpf_add_ui@@Base+0x244>  // b.lo, b.ul, b.last
   1039c:	mov	w12, #0x2                   	// #2
   103a0:	mov	w10, #0x1                   	// #1
   103a4:	sub	x12, x12, x24
   103a8:	mov	w14, #0x1                   	// #1
   103ac:	cmp	x14, x24
   103b0:	b.ge	10428 <__gmpf_add_ui@@Base+0x274>  // b.tcont
   103b4:	ldr	x15, [x11, x14, lsl #3]
   103b8:	adds	x15, x15, #0x1
   103bc:	str	x15, [x13, x14, lsl #3]
   103c0:	add	x14, x14, #0x1
   103c4:	b.cs	103ac <__gmpf_add_ui@@Base+0x1f8>  // b.hs, b.nlast
   103c8:	cmp	x22, x20
   103cc:	mov	x10, xzr
   103d0:	b.eq	10428 <__gmpf_add_ui@@Base+0x274>  // b.none
   103d4:	cmp	x14, x24
   103d8:	b.ge	10428 <__gmpf_add_ui@@Base+0x274>  // b.tcont
   103dc:	add	x10, x12, x14
   103e0:	sub	x10, x10, #0x2
   103e4:	ldr	x11, [x9, x10, lsl #3]
   103e8:	str	x11, [x8, x10, lsl #3]
   103ec:	adds	x10, x10, #0x1
   103f0:	b.cc	103e4 <__gmpf_add_ui@@Base+0x230>  // b.lo, b.ul, b.last
   103f4:	b	10424 <__gmpf_add_ui@@Base+0x270>
   103f8:	cmp	x24, #0x2
   103fc:	mov	x10, xzr
   10400:	b.lt	10428 <__gmpf_add_ui@@Base+0x274>  // b.tstop
   10404:	cmp	x22, x20
   10408:	b.eq	10428 <__gmpf_add_ui@@Base+0x274>  // b.none
   1040c:	mov	w10, #0x1                   	// #1
   10410:	sub	x10, x10, x24
   10414:	ldr	x11, [x9, x10, lsl #3]
   10418:	str	x11, [x8, x10, lsl #3]
   1041c:	adds	x10, x10, #0x1
   10420:	b.cc	10414 <__gmpf_add_ui@@Base+0x260>  // b.lo, b.ul, b.last
   10424:	mov	x10, xzr
   10428:	str	x10, [x8]
   1042c:	add	w8, w23, w10
   10430:	add	x9, x10, x24
   10434:	str	w8, [x19, #4]
   10438:	str	x9, [x19, #8]
   1043c:	ldp	x20, x19, [sp, #80]
   10440:	ldp	x22, x21, [sp, #64]
   10444:	ldp	x24, x23, [sp, #48]
   10448:	ldp	x29, x30, [sp, #32]
   1044c:	add	sp, sp, #0x60
   10450:	ret

0000000000010454 <__gmpf_sub@@Base>:
   10454:	stp	x29, x30, [sp, #-96]!
   10458:	stp	x28, x27, [sp, #16]
   1045c:	stp	x26, x25, [sp, #32]
   10460:	stp	x24, x23, [sp, #48]
   10464:	stp	x22, x21, [sp, #64]
   10468:	stp	x20, x19, [sp, #80]
   1046c:	mov	x29, sp
   10470:	sub	sp, sp, #0x70
   10474:	ldr	w8, [x1, #4]
   10478:	mov	x24, x0
   1047c:	cbz	w8, 10604 <__gmpf_sub@@Base+0x1b0>
   10480:	ldr	w9, [x2, #4]
   10484:	cbz	w9, 10614 <__gmpf_sub@@Base+0x1c0>
   10488:	eor	w10, w9, w8
   1048c:	tbnz	w10, #31, 10628 <__gmpf_sub@@Base+0x1d4>
   10490:	stur	xzr, [x29, #-24]
   10494:	ldr	x10, [x1, #8]
   10498:	ldr	x11, [x2, #8]
   1049c:	ldrsw	x12, [x24]
   104a0:	ldr	x18, [x24, #16]
   104a4:	cmp	x10, x11
   104a8:	cset	w10, lt  // lt = tstop
   104ac:	csel	x13, x1, x2, lt  // lt = tstop
   104b0:	csel	x14, x2, x1, lt  // lt = tstop
   104b4:	csel	w11, w8, w9, lt  // lt = tstop
   104b8:	csel	w9, w9, w8, lt  // lt = tstop
   104bc:	eor	w25, w10, w8, lsr #31
   104c0:	ldp	x2, x23, [x14, #8]
   104c4:	ldp	x0, x8, [x13, #8]
   104c8:	sxtw	x9, w9
   104cc:	sxtw	x10, w11
   104d0:	cmp	x9, #0x0
   104d4:	cneg	x9, x9, mi  // mi = first
   104d8:	cmp	x10, #0x0
   104dc:	sub	x4, x2, x0
   104e0:	cneg	x10, x10, mi  // mi = first
   104e4:	cmp	x4, #0x1
   104e8:	add	x28, x12, #0x1
   104ec:	b.gt	10514 <__gmpf_sub@@Base+0xc0>
   104f0:	cbz	x4, 1065c <__gmpf_sub@@Base+0x208>
   104f4:	add	x11, x23, x9, lsl #3
   104f8:	ldur	x11, [x11, #-8]
   104fc:	cmp	x11, #0x1
   10500:	b.ne	10514 <__gmpf_sub@@Base+0xc0>  // b.any
   10504:	add	x11, x8, x10, lsl #3
   10508:	ldur	x11, [x11, #-8]
   1050c:	cmn	x11, #0x1
   10510:	b.eq	107c0 <__gmpf_sub@@Base+0x36c>  // b.none
   10514:	mov	x21, x2
   10518:	mov	x19, x10
   1051c:	subs	x10, x9, x28
   10520:	add	x10, x23, x10, lsl #3
   10524:	add	x11, x19, x4
   10528:	csel	x20, x28, x9, gt
   1052c:	csel	x14, x10, x23, gt
   10530:	subs	x9, x28, x4
   10534:	subs	x10, x11, x28
   10538:	add	x10, x8, x10, lsl #3
   1053c:	csel	x22, x9, x19, gt
   10540:	csel	x26, x10, x8, gt
   10544:	cmp	x28, x4
   10548:	b.le	10648 <__gmpf_sub@@Base+0x1f4>
   1054c:	lsl	x1, x28, #3
   10550:	mov	w8, #0x7f00                	// #32512
   10554:	cmp	x1, x8
   10558:	stp	x21, x20, [x29, #-40]
   1055c:	b.hi	10ed8 <__gmpf_sub@@Base+0xa84>  // b.pmore
   10560:	add	x9, x1, #0xf
   10564:	mov	x8, sp
   10568:	and	x9, x9, #0xfffffffffffffff0
   1056c:	sub	x1, x8, x9
   10570:	mov	sp, x1
   10574:	cbz	x22, 105e8 <__gmpf_sub@@Base+0x194>
   10578:	add	x8, x19, x2
   1057c:	ldur	x13, [x29, #-32]
   10580:	sub	x8, x8, x0
   10584:	cmp	x8, x28
   10588:	csel	x28, x8, x28, lt  // lt = tstop
   1058c:	lsl	x8, x28, #3
   10590:	add	x11, x0, x28
   10594:	lsl	x10, x13, #3
   10598:	sub	x8, x8, x13, lsl #3
   1059c:	lsl	x11, x11, #3
   105a0:	sub	x10, x10, x28, lsl #3
   105a4:	sub	x12, x13, x28
   105a8:	add	x19, x1, x8
   105ac:	sub	x8, x11, x2, lsl #3
   105b0:	lsl	x9, x2, #3
   105b4:	add	x20, x1, x10
   105b8:	add	x27, x1, x8
   105bc:	add	x21, x14, x12, lsl #3
   105c0:	ldr	x8, [x26]
   105c4:	cbnz	x8, 106b0 <__gmpf_sub@@Base+0x25c>
   105c8:	add	x26, x26, #0x8
   105cc:	sub	x22, x22, #0x1
   105d0:	sub	x19, x19, #0x8
   105d4:	sub	x27, x27, #0x8
   105d8:	sub	x28, x28, #0x1
   105dc:	add	x20, x20, #0x8
   105e0:	add	x21, x21, #0x8
   105e4:	cbnz	x22, 105c0 <__gmpf_sub@@Base+0x16c>
   105e8:	ldur	x20, [x29, #-32]
   105ec:	mov	x0, x18
   105f0:	mov	x1, x14
   105f4:	mov	x2, x20
   105f8:	bl	ca70 <__gmpn_copyi@plt>
   105fc:	ldur	x21, [x29, #-40]
   10600:	b	10f6c <__gmpf_sub@@Base+0xb18>
   10604:	mov	x0, x24
   10608:	mov	x1, x2
   1060c:	bl	cc10 <__gmpf_neg@plt>
   10610:	b	10fa0 <__gmpf_sub@@Base+0xb4c>
   10614:	cmp	x24, x1
   10618:	b.eq	10fa0 <__gmpf_sub@@Base+0xb4c>  // b.none
   1061c:	mov	x0, x24
   10620:	bl	c160 <__gmpf_set@plt>
   10624:	b	10fa0 <__gmpf_sub@@Base+0xb4c>
   10628:	neg	w8, w9
   1062c:	stur	w8, [x29, #-20]
   10630:	ldur	q0, [x2, #8]
   10634:	sub	x2, x29, #0x18
   10638:	mov	x0, x24
   1063c:	stur	q0, [x29, #-16]
   10640:	bl	bf80 <__gmpf_add@plt>
   10644:	b	10fa0 <__gmpf_sub@@Base+0xb4c>
   10648:	cmp	x18, x14
   1064c:	b.eq	10f6c <__gmpf_sub@@Base+0xb18>  // b.none
   10650:	mov	x0, x18
   10654:	mov	x1, x14
   10658:	b	107b4 <__gmpf_sub@@Base+0x360>
   1065c:	add	x14, x8, x10, lsl #3
   10660:	add	x15, x23, x9, lsl #3
   10664:	mov	x12, xzr
   10668:	sub	x11, x10, x9
   1066c:	sub	x13, x9, x10
   10670:	sub	x14, x14, #0x8
   10674:	sub	x15, x15, #0x8
   10678:	ldr	x16, [x15, x12, lsl #3]
   1067c:	ldr	x17, [x14, x12, lsl #3]
   10680:	cmp	x16, x17
   10684:	add	x16, x9, x12
   10688:	b.ne	1072c <__gmpf_sub@@Base+0x2d8>  // b.any
   1068c:	sub	x16, x16, #0x1
   10690:	cbz	x16, 10774 <__gmpf_sub@@Base+0x320>
   10694:	sub	x12, x12, #0x1
   10698:	cmn	x10, x12
   1069c:	b.ne	10678 <__gmpf_sub@@Base+0x224>  // b.any
   106a0:	mov	x9, x10
   106a4:	mov	x11, x13
   106a8:	mov	x8, x23
   106ac:	b	10778 <__gmpf_sub@@Base+0x324>
   106b0:	ldur	x10, [x29, #-32]
   106b4:	stur	w25, [x29, #-44]
   106b8:	stur	x24, [x29, #-56]
   106bc:	cbz	x10, 10704 <__gmpf_sub@@Base+0x2b0>
   106c0:	ldur	x3, [x29, #-32]
   106c4:	mov	w11, #0x1                   	// #1
   106c8:	mov	x24, x14
   106cc:	add	x10, x0, x3
   106d0:	lsl	x10, x10, #3
   106d4:	sub	x9, x10, x9
   106d8:	add	x23, x1, x9
   106dc:	sub	x25, x11, x3
   106e0:	ldr	x9, [x24]
   106e4:	cbnz	x9, 107e4 <__gmpf_sub@@Base+0x390>
   106e8:	add	x24, x24, #0x8
   106ec:	sub	x3, x3, #0x1
   106f0:	add	x19, x19, #0x8
   106f4:	sub	x20, x20, #0x8
   106f8:	sub	x23, x23, #0x8
   106fc:	add	x25, x25, #0x1
   10700:	cbnz	x3, 106e0 <__gmpf_sub@@Base+0x28c>
   10704:	mov	x0, x18
   10708:	mov	x1, x26
   1070c:	mov	x2, x22
   10710:	bl	ca70 <__gmpn_copyi@plt>
   10714:	ldur	w25, [x29, #-44]
   10718:	ldur	x24, [x29, #-56]
   1071c:	ldur	x21, [x29, #-40]
   10720:	mov	x20, x22
   10724:	eor	w25, w25, #0x1
   10728:	b	10f6c <__gmpf_sub@@Base+0xb18>
   1072c:	add	x9, x10, x12
   10730:	csel	x19, x16, x9, cc  // cc = lo, ul, last
   10734:	csel	x13, x23, x8, cc  // cc = lo, ul, last
   10738:	csel	x23, x8, x23, cc  // cc = lo, ul, last
   1073c:	csel	x9, x9, x16, cc  // cc = lo, ul, last
   10740:	sub	x10, x19, #0x1
   10744:	add	x8, x23, x9, lsl #3
   10748:	ldr	x11, [x13, x10, lsl #3]
   1074c:	ldur	x8, [x8, #-8]
   10750:	cset	w14, cc  // cc = lo, ul, last
   10754:	eor	w25, w25, w14
   10758:	add	x11, x11, #0x1
   1075c:	cmp	x8, x11
   10760:	add	x11, x2, x12
   10764:	mov	x8, x13
   10768:	mov	x21, x11
   1076c:	b.ne	1051c <__gmpf_sub@@Base+0xc8>  // b.any
   10770:	b	108c8 <__gmpf_sub@@Base+0x474>
   10774:	eor	w25, w25, #0x1
   10778:	sub	x21, x2, x9
   1077c:	cbz	x11, 107a0 <__gmpf_sub@@Base+0x34c>
   10780:	sub	x9, x21, x11
   10784:	sub	x10, x8, #0x8
   10788:	ldr	x12, [x10, x11, lsl #3]
   1078c:	cbnz	x12, 107a0 <__gmpf_sub@@Base+0x34c>
   10790:	sub	x11, x11, #0x1
   10794:	sub	x21, x21, #0x1
   10798:	cbnz	x11, 10788 <__gmpf_sub@@Base+0x334>
   1079c:	mov	x21, x9
   107a0:	subs	x9, x11, x28
   107a4:	add	x9, x8, x9, lsl #3
   107a8:	csel	x20, x28, x11, gt
   107ac:	csel	x1, x9, x8, gt
   107b0:	mov	x0, x18
   107b4:	mov	x2, x20
   107b8:	bl	ca70 <__gmpn_copyi@plt>
   107bc:	b	10f6c <__gmpf_sub@@Base+0xb18>
   107c0:	cmp	x9, #0x2
   107c4:	b.lt	108c4 <__gmpf_sub@@Base+0x470>  // b.tstop
   107c8:	add	x11, x23, x9, lsl #3
   107cc:	ldur	x12, [x11, #-16]
   107d0:	mov	x11, x2
   107d4:	mov	x21, x2
   107d8:	mov	x19, x10
   107dc:	cbnz	x12, 1051c <__gmpf_sub@@Base+0xc8>
   107e0:	b	108c8 <__gmpf_sub@@Base+0x474>
   107e4:	subs	x9, x3, x4
   107e8:	stur	x1, [x29, #-72]
   107ec:	b.le	1099c <__gmpf_sub@@Base+0x548>
   107f0:	cbz	x4, 10b38 <__gmpf_sub@@Base+0x6e4>
   107f4:	add	x10, x22, x4
   107f8:	subs	x25, x10, x3
   107fc:	stur	x2, [x29, #-80]
   10800:	stur	x18, [x29, #-64]
   10804:	b.le	10c80 <__gmpf_sub@@Base+0x82c>
   10808:	neg	x8, x8
   1080c:	subs	x2, x25, #0x1
   10810:	stur	x10, [x29, #-96]
   10814:	str	x8, [x1]
   10818:	b.eq	1084c <__gmpf_sub@@Base+0x3f8>  // b.none
   1081c:	mov	x20, x0
   10820:	add	x0, x1, #0x8
   10824:	add	x1, x26, #0x8
   10828:	mov	x21, x3
   1082c:	mov	x22, x4
   10830:	mov	x23, x14
   10834:	bl	c2a0 <__gmpn_com@plt>
   10838:	ldur	x1, [x29, #-72]
   1083c:	mov	x14, x23
   10840:	mov	x4, x22
   10844:	mov	x3, x21
   10848:	mov	x0, x20
   1084c:	ldur	x21, [x29, #-40]
   10850:	subs	x28, x3, x4
   10854:	add	x22, x1, x25, lsl #3
   10858:	b.eq	10e18 <__gmpf_sub@@Base+0x9c4>  // b.none
   1085c:	mov	x20, x0
   10860:	add	x2, x26, x25, lsl #3
   10864:	mov	x0, x22
   10868:	mov	x1, x24
   1086c:	mov	x23, x3
   10870:	mov	x3, x28
   10874:	stur	x14, [x29, #-88]
   10878:	bl	c2e0 <__gmpn_sub_n@plt>
   1087c:	ldp	x1, x14, [x29, #-72]
   10880:	ldur	w25, [x29, #-44]
   10884:	mov	x3, x23
   10888:	cbz	x0, 10e20 <__gmpf_sub@@Base+0x9cc>
   1088c:	ldp	x10, x8, [x29, #-88]
   10890:	ldur	x9, [x29, #-32]
   10894:	sub	x8, x20, x8
   10898:	add	x9, x10, x9, lsl #3
   1089c:	add	x10, x3, x8
   108a0:	cmp	x10, x3
   108a4:	b.ge	10e48 <__gmpf_sub@@Base+0x9f4>  // b.tcont
   108a8:	ldr	x10, [x9, x8, lsl #3]
   108ac:	add	x8, x8, #0x1
   108b0:	sub	x11, x10, #0x1
   108b4:	str	x11, [x27], #8
   108b8:	cbz	x10, 1089c <__gmpf_sub@@Base+0x448>
   108bc:	add	x28, x3, x8
   108c0:	b	10e20 <__gmpf_sub@@Base+0x9cc>
   108c4:	mov	x11, x2
   108c8:	add	x12, x8, x10, lsl #3
   108cc:	mov	w13, #0x8                   	// #8
   108d0:	lsl	x1, x28, #3
   108d4:	mov	x20, x24
   108d8:	mov	x0, xzr
   108dc:	sub	x16, x12, #0x8
   108e0:	sub	x2, x13, x10, lsl #3
   108e4:	add	x17, x23, x9, lsl #3
   108e8:	mov	x3, x1
   108ec:	stur	x18, [x29, #-64]
   108f0:	add	x18, x9, x0
   108f4:	mov	x15, x2
   108f8:	mov	x13, x0
   108fc:	mov	x14, x3
   10900:	add	x12, x10, x0
   10904:	sub	x24, x18, #0x1
   10908:	cbz	x12, 10934 <__gmpf_sub@@Base+0x4e0>
   1090c:	cbz	x24, 10934 <__gmpf_sub@@Base+0x4e0>
   10910:	add	x0, x17, x13, lsl #3
   10914:	ldur	x0, [x0, #-16]
   10918:	cbnz	x0, 10934 <__gmpf_sub@@Base+0x4e0>
   1091c:	ldr	x3, [x16, x13, lsl #3]
   10920:	add	x2, x15, #0x8
   10924:	sub	x0, x13, #0x1
   10928:	cmn	x3, #0x1
   1092c:	add	x3, x14, #0x8
   10930:	b.eq	108f0 <__gmpf_sub@@Base+0x49c>  // b.none
   10934:	add	x16, x11, x13
   10938:	sub	x27, x16, #0x1
   1093c:	cbz	x24, 1095c <__gmpf_sub@@Base+0x508>
   10940:	mov	w21, w25
   10944:	cmp	x18, x28
   10948:	b.le	10a88 <__gmpf_sub@@Base+0x634>
   1094c:	add	x9, x23, x9, lsl #3
   10950:	sub	x24, x28, #0x1
   10954:	sub	x23, x9, x14
   10958:	b	10a88 <__gmpf_sub@@Base+0x634>
   1095c:	cbz	x12, 10a60 <__gmpf_sub@@Base+0x60c>
   10960:	mov	x9, xzr
   10964:	sub	x14, x8, x15
   10968:	sub	x27, x27, x12
   1096c:	add	x12, x10, x13
   10970:	ldr	x15, [x14]
   10974:	cmn	x15, #0x1
   10978:	b.ne	10a6c <__gmpf_sub@@Base+0x618>  // b.any
   1097c:	add	x15, x12, x9
   10980:	sub	x9, x9, #0x1
   10984:	cmp	x15, #0x1
   10988:	sub	x14, x14, #0x8
   1098c:	b.ne	10970 <__gmpf_sub@@Base+0x51c>  // b.any
   10990:	mov	w21, w25
   10994:	mov	x12, xzr
   10998:	b	10a64 <__gmpf_sub@@Base+0x610>
   1099c:	add	x20, x22, x4
   109a0:	mov	x28, x0
   109a4:	mov	x27, x2
   109a8:	mov	x23, x18
   109ac:	neg	x8, x8
   109b0:	subs	x2, x22, #0x1
   109b4:	sub	x21, x20, x3
   109b8:	str	x8, [x1]
   109bc:	b.eq	109d8 <__gmpf_sub@@Base+0x584>  // b.none
   109c0:	add	x0, x1, #0x8
   109c4:	add	x1, x26, #0x8
   109c8:	mov	x26, x3
   109cc:	bl	c2a0 <__gmpn_com@plt>
   109d0:	ldur	x1, [x29, #-72]
   109d4:	mov	x3, x26
   109d8:	cmp	x22, x21
   109dc:	b.ge	10a04 <__gmpf_sub@@Base+0x5b0>  // b.tcont
   109e0:	add	x8, x3, x28
   109e4:	sub	x8, x27, x8
   109e8:	add	x0, x1, x22, lsl #3
   109ec:	lsl	x2, x8, #3
   109f0:	mov	w1, #0xff                  	// #255
   109f4:	mov	x22, x3
   109f8:	bl	c610 <memset@plt>
   109fc:	ldur	x1, [x29, #-72]
   10a00:	mov	x3, x22
   10a04:	ldr	x9, [x24]
   10a08:	add	x8, x1, x21, lsl #3
   10a0c:	sub	x10, x9, #0x1
   10a10:	str	x10, [x8]
   10a14:	cbz	x9, 10b98 <__gmpf_sub@@Base+0x744>
   10a18:	ldur	x21, [x29, #-40]
   10a1c:	cmp	x3, #0x2
   10a20:	mov	x14, x23
   10a24:	b.lt	10c00 <__gmpf_sub@@Base+0x7ac>  // b.tstop
   10a28:	ldur	w25, [x29, #-44]
   10a2c:	cmp	x8, x24
   10a30:	b.eq	10a58 <__gmpf_sub@@Base+0x604>  // b.none
   10a34:	mov	x8, xzr
   10a38:	sub	x9, x3, #0x1
   10a3c:	add	x10, x24, x8, lsl #3
   10a40:	ldr	x10, [x10, #8]
   10a44:	add	x11, x19, x8, lsl #3
   10a48:	add	x8, x8, #0x1
   10a4c:	cmp	x9, x8
   10a50:	str	x10, [x11, #8]
   10a54:	b.ne	10a3c <__gmpf_sub@@Base+0x5e8>  // b.any
   10a58:	mov	x22, x20
   10a5c:	b	10e5c <__gmpf_sub@@Base+0xa08>
   10a60:	mov	w21, w25
   10a64:	mov	x24, xzr
   10a68:	b	10a88 <__gmpf_sub@@Base+0x634>
   10a6c:	add	x10, x10, x13
   10a70:	add	x11, x11, x13
   10a74:	add	x12, x10, x9
   10a78:	add	x9, x11, x9
   10a7c:	mov	w21, w25
   10a80:	mov	x24, xzr
   10a84:	sub	x27, x9, #0x1
   10a88:	sub	x9, x28, #0x1
   10a8c:	cmp	x12, x28
   10a90:	sub	x11, x12, x9
   10a94:	mov	w10, #0x7f00                	// #32512
   10a98:	csel	x22, x12, x9, lt  // lt = tstop
   10a9c:	add	x9, x8, x11, lsl #3
   10aa0:	csel	x25, x8, x9, lt  // lt = tstop
   10aa4:	cmp	x1, x10
   10aa8:	b.hi	10f14 <__gmpf_sub@@Base+0xac0>  // b.pmore
   10aac:	add	x9, x1, #0xf
   10ab0:	mov	x8, sp
   10ab4:	and	x9, x9, #0xfffffffffffffff0
   10ab8:	sub	x1, x8, x9
   10abc:	mov	sp, x1
   10ac0:	cbz	x22, 10f24 <__gmpf_sub@@Base+0xad0>
   10ac4:	cbz	x24, 10aec <__gmpf_sub@@Base+0x698>
   10ac8:	subs	x26, x24, x22
   10acc:	b.ge	10b04 <__gmpf_sub@@Base+0x6b0>  // b.tcont
   10ad0:	ldr	x8, [x25]
   10ad4:	sub	x19, x22, x24
   10ad8:	cbz	x8, 10d14 <__gmpf_sub@@Base+0x8c0>
   10adc:	mov	x9, x1
   10ae0:	mov	x10, x25
   10ae4:	mov	x11, x19
   10ae8:	b	10d50 <__gmpf_sub@@Base+0x8fc>
   10aec:	ldr	x8, [x25]
   10af0:	cbz	x8, 10c10 <__gmpf_sub@@Base+0x7bc>
   10af4:	mov	x9, x1
   10af8:	mov	x10, x22
   10afc:	mov	x24, x20
   10b00:	b	10c50 <__gmpf_sub@@Base+0x7fc>
   10b04:	mov	x0, x1
   10b08:	mov	x19, x1
   10b0c:	mov	x1, x23
   10b10:	mov	x2, x26
   10b14:	bl	ca70 <__gmpn_copyi@plt>
   10b18:	add	x0, x19, x26, lsl #3
   10b1c:	add	x1, x23, x26, lsl #3
   10b20:	mov	x2, x25
   10b24:	mov	x3, x22
   10b28:	mov	x28, x19
   10b2c:	bl	c2e0 <__gmpn_sub_n@plt>
   10b30:	mov	x22, x24
   10b34:	b	10d90 <__gmpf_sub@@Base+0x93c>
   10b38:	mov	x20, x18
   10b3c:	subs	x25, x3, x22
   10b40:	b.ge	10dac <__gmpf_sub@@Base+0x958>  // b.tcont
   10b44:	ldur	x21, [x29, #-40]
   10b48:	sub	x19, x22, x3
   10b4c:	neg	x8, x8
   10b50:	subs	x2, x19, #0x1
   10b54:	str	x8, [x1]
   10b58:	b.eq	10b74 <__gmpf_sub@@Base+0x720>  // b.none
   10b5c:	add	x0, x1, #0x8
   10b60:	add	x1, x26, #0x8
   10b64:	mov	x23, x3
   10b68:	bl	c2a0 <__gmpn_com@plt>
   10b6c:	ldur	x1, [x29, #-72]
   10b70:	mov	x3, x23
   10b74:	add	x0, x1, x19, lsl #3
   10b78:	add	x2, x26, x19, lsl #3
   10b7c:	mov	w4, #0x1                   	// #1
   10b80:	mov	x1, x24
   10b84:	bl	c780 <__gmpn_sub_nc@plt>
   10b88:	ldur	x1, [x29, #-72]
   10b8c:	ldur	x24, [x29, #-56]
   10b90:	ldur	w25, [x29, #-44]
   10b94:	b	10dec <__gmpf_sub@@Base+0x998>
   10b98:	ldur	x21, [x29, #-40]
   10b9c:	mov	x11, xzr
   10ba0:	mov	w9, #0x8                   	// #8
   10ba4:	mov	x14, x23
   10ba8:	add	x10, x11, #0x1
   10bac:	cmp	x10, x3
   10bb0:	b.ge	10c00 <__gmpf_sub@@Base+0x7ac>  // b.tcont
   10bb4:	ldr	x12, [x24, x9]
   10bb8:	add	x11, x19, x11, lsl #3
   10bbc:	add	x9, x9, #0x8
   10bc0:	add	x25, x25, #0x1
   10bc4:	sub	x13, x12, #0x1
   10bc8:	str	x13, [x11, #8]
   10bcc:	mov	x11, x10
   10bd0:	cbz	x12, 10ba8 <__gmpf_sub@@Base+0x754>
   10bd4:	cmp	x8, x24
   10bd8:	b.eq	10c00 <__gmpf_sub@@Base+0x7ac>  // b.none
   10bdc:	add	x8, x10, #0x1
   10be0:	cmp	x8, x3
   10be4:	b.ge	10c00 <__gmpf_sub@@Base+0x7ac>  // b.tcont
   10be8:	add	x8, x24, x9
   10bec:	add	x9, x19, x9
   10bf0:	ldr	x10, [x8], #8
   10bf4:	adds	x25, x25, #0x1
   10bf8:	str	x10, [x9], #8
   10bfc:	b.cc	10bf0 <__gmpf_sub@@Base+0x79c>  // b.lo, b.ul, b.last
   10c00:	ldur	x24, [x29, #-56]
   10c04:	ldur	w25, [x29, #-44]
   10c08:	mov	x22, x20
   10c0c:	b	10eb0 <__gmpf_sub@@Base+0xa5c>
   10c10:	ldur	x14, [x29, #-64]
   10c14:	mov	x9, xzr
   10c18:	mov	x10, xzr
   10c1c:	sub	x11, x22, #0x1
   10c20:	mov	x24, x20
   10c24:	cmp	x11, x10
   10c28:	str	xzr, [x1, x10, lsl #3]
   10c2c:	b.eq	10df4 <__gmpf_sub@@Base+0x9a0>  // b.none
   10c30:	add	x8, x25, x10, lsl #3
   10c34:	ldr	x8, [x8, #8]
   10c38:	add	x10, x10, #0x1
   10c3c:	sub	x9, x9, #0x8
   10c40:	cbz	x8, 10c24 <__gmpf_sub@@Base+0x7d0>
   10c44:	sub	x10, x22, x10
   10c48:	sub	x25, x25, x9
   10c4c:	sub	x9, x1, x9
   10c50:	neg	x8, x8
   10c54:	subs	x2, x10, #0x1
   10c58:	str	x8, [x9]
   10c5c:	b.eq	10c74 <__gmpf_sub@@Base+0x820>  // b.none
   10c60:	add	x0, x9, #0x8
   10c64:	mov	x19, x1
   10c68:	add	x1, x25, #0x8
   10c6c:	bl	c2a0 <__gmpn_com@plt>
   10c70:	mov	x1, x19
   10c74:	ldur	x14, [x29, #-64]
   10c78:	mov	w25, w21
   10c7c:	b	10da4 <__gmpf_sub@@Base+0x950>
   10c80:	sub	x19, x9, x22
   10c84:	stur	x0, [x29, #-104]
   10c88:	mov	x0, x1
   10c8c:	mov	x25, x1
   10c90:	mov	x1, x24
   10c94:	mov	x2, x19
   10c98:	stur	x14, [x29, #-88]
   10c9c:	mov	x27, x3
   10ca0:	bl	ca70 <__gmpn_copyi@plt>
   10ca4:	add	x0, x25, x19, lsl #3
   10ca8:	add	x1, x24, x19, lsl #3
   10cac:	mov	x2, x26
   10cb0:	mov	x3, x22
   10cb4:	stur	x27, [x29, #-96]
   10cb8:	sub	x19, x27, x19
   10cbc:	bl	c2e0 <__gmpn_sub_n@plt>
   10cc0:	cbz	x0, 10e64 <__gmpf_sub@@Base+0xa10>
   10cc4:	ldp	x9, x12, [x29, #-104]
   10cc8:	ldur	x10, [x29, #-32]
   10ccc:	ldur	w25, [x29, #-44]
   10cd0:	ldur	x14, [x29, #-64]
   10cd4:	mov	x8, xzr
   10cd8:	add	x9, x9, x10
   10cdc:	ldp	x10, x1, [x29, #-80]
   10ce0:	sub	x9, x9, x10
   10ce4:	ldur	x10, [x29, #-88]
   10ce8:	add	x9, x10, x9, lsl #3
   10cec:	add	x10, x22, x8
   10cf0:	cmp	x10, x19
   10cf4:	b.ge	10ea4 <__gmpf_sub@@Base+0xa50>  // b.tcont
   10cf8:	ldr	x10, [x9, x8, lsl #3]
   10cfc:	add	x8, x8, #0x1
   10d00:	sub	x11, x10, #0x1
   10d04:	str	x11, [x23], #8
   10d08:	cbz	x10, 10cec <__gmpf_sub@@Base+0x898>
   10d0c:	add	x22, x22, x8
   10d10:	b	10e70 <__gmpf_sub@@Base+0xa1c>
   10d14:	mvn	x8, x24
   10d18:	mov	x9, xzr
   10d1c:	mov	x10, xzr
   10d20:	add	x11, x8, x22
   10d24:	cmp	x11, x10
   10d28:	str	xzr, [x1, x10, lsl #3]
   10d2c:	b.eq	10e10 <__gmpf_sub@@Base+0x9bc>  // b.none
   10d30:	add	x8, x25, x10, lsl #3
   10d34:	ldr	x8, [x8, #8]
   10d38:	add	x10, x10, #0x1
   10d3c:	sub	x9, x9, #0x8
   10d40:	cbz	x8, 10d24 <__gmpf_sub@@Base+0x8d0>
   10d44:	sub	x11, x19, x10
   10d48:	sub	x10, x25, x9
   10d4c:	sub	x9, x1, x9
   10d50:	neg	x8, x8
   10d54:	subs	x2, x11, #0x1
   10d58:	str	x8, [x9]
   10d5c:	b.eq	10d74 <__gmpf_sub@@Base+0x920>  // b.none
   10d60:	add	x0, x9, #0x8
   10d64:	mov	x26, x1
   10d68:	add	x1, x10, #0x8
   10d6c:	bl	c2a0 <__gmpn_com@plt>
   10d70:	mov	x1, x26
   10d74:	mov	w4, #0x1                   	// #1
   10d78:	mov	x28, x1
   10d7c:	add	x0, x1, x19, lsl #3
   10d80:	add	x2, x25, x19, lsl #3
   10d84:	mov	x1, x23
   10d88:	mov	x3, x24
   10d8c:	bl	c780 <__gmpn_sub_nc@plt>
   10d90:	ldur	x14, [x29, #-64]
   10d94:	mov	x24, x20
   10d98:	mov	w25, w21
   10d9c:	mov	x1, x28
   10da0:	cbz	x0, 10df8 <__gmpf_sub@@Base+0x9a4>
   10da4:	mov	x21, x27
   10da8:	b	10eb0 <__gmpf_sub@@Base+0xa5c>
   10dac:	mov	x0, x1
   10db0:	mov	x1, x24
   10db4:	mov	x2, x25
   10db8:	mov	x19, x3
   10dbc:	bl	ca70 <__gmpn_copyi@plt>
   10dc0:	ldur	x8, [x29, #-72]
   10dc4:	add	x1, x24, x25, lsl #3
   10dc8:	mov	x2, x26
   10dcc:	mov	x3, x22
   10dd0:	add	x0, x8, x25, lsl #3
   10dd4:	bl	c2e0 <__gmpn_sub_n@plt>
   10dd8:	ldur	x1, [x29, #-72]
   10ddc:	ldur	x24, [x29, #-56]
   10de0:	ldur	w25, [x29, #-44]
   10de4:	ldur	x21, [x29, #-40]
   10de8:	mov	x22, x19
   10dec:	mov	x14, x20
   10df0:	b	10eb0 <__gmpf_sub@@Base+0xa5c>
   10df4:	mov	w25, w21
   10df8:	mov	w8, #0x1                   	// #1
   10dfc:	mov	x21, x27
   10e00:	str	x8, [x1, x22, lsl #3]
   10e04:	add	x22, x22, #0x1
   10e08:	add	x21, x27, #0x1
   10e0c:	b	10f5c <__gmpf_sub@@Base+0xb08>
   10e10:	mov	x4, xzr
   10e14:	b	10d78 <__gmpf_sub@@Base+0x924>
   10e18:	ldur	w25, [x29, #-44]
   10e1c:	ldur	x14, [x29, #-64]
   10e20:	cmp	x22, x24
   10e24:	b.eq	10e48 <__gmpf_sub@@Base+0x9f4>  // b.none
   10e28:	cmp	x28, x3
   10e2c:	b.ge	10e48 <__gmpf_sub@@Base+0x9f4>  // b.tcont
   10e30:	add	x8, x19, x28, lsl #3
   10e34:	ldr	x9, [x24, x28, lsl #3]
   10e38:	add	x28, x28, #0x1
   10e3c:	cmp	x3, x28
   10e40:	str	x9, [x8], #8
   10e44:	b.ne	10e34 <__gmpf_sub@@Base+0x9e0>  // b.any
   10e48:	ldr	x8, [x22]
   10e4c:	sub	x9, x8, #0x1
   10e50:	str	x9, [x22], #8
   10e54:	cbz	x8, 10e48 <__gmpf_sub@@Base+0x9f4>
   10e58:	ldur	x22, [x29, #-96]
   10e5c:	ldur	x24, [x29, #-56]
   10e60:	b	10eb0 <__gmpf_sub@@Base+0xa5c>
   10e64:	ldur	w25, [x29, #-44]
   10e68:	ldp	x1, x14, [x29, #-72]
   10e6c:	ldur	x12, [x29, #-96]
   10e70:	cmp	x24, x1
   10e74:	b.eq	10ea4 <__gmpf_sub@@Base+0xa50>  // b.none
   10e78:	ldur	x24, [x29, #-56]
   10e7c:	cmp	x22, x19
   10e80:	b.ge	10ea8 <__gmpf_sub@@Base+0xa54>  // b.tcont
   10e84:	sub	x8, x28, x22
   10e88:	add	x9, x20, x22, lsl #3
   10e8c:	add	x10, x21, x22, lsl #3
   10e90:	ldr	x11, [x10], #8
   10e94:	subs	x8, x8, #0x1
   10e98:	str	x11, [x9], #8
   10e9c:	b.ne	10e90 <__gmpf_sub@@Base+0xa3c>  // b.any
   10ea0:	b	10ea8 <__gmpf_sub@@Base+0xa54>
   10ea4:	ldur	x24, [x29, #-56]
   10ea8:	ldur	x21, [x29, #-40]
   10eac:	mov	x22, x12
   10eb0:	cbz	x22, 10f5c <__gmpf_sub@@Base+0xb08>
   10eb4:	sub	x8, x21, x22
   10eb8:	add	x9, x1, x22, lsl #3
   10ebc:	ldur	x9, [x9, #-8]
   10ec0:	cbnz	x9, 10f5c <__gmpf_sub@@Base+0xb08>
   10ec4:	sub	x22, x22, #0x1
   10ec8:	sub	x21, x21, #0x1
   10ecc:	cbnz	x22, 10eb8 <__gmpf_sub@@Base+0xa64>
   10ed0:	mov	x21, x8
   10ed4:	b	10f5c <__gmpf_sub@@Base+0xb08>
   10ed8:	stur	x0, [x29, #-104]
   10edc:	sub	x0, x29, #0x18
   10ee0:	mov	x20, x18
   10ee4:	mov	x21, x2
   10ee8:	mov	x27, x4
   10eec:	mov	x23, x14
   10ef0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   10ef4:	mov	x1, x0
   10ef8:	ldur	x0, [x29, #-104]
   10efc:	mov	x14, x23
   10f00:	mov	x4, x27
   10f04:	mov	x2, x21
   10f08:	mov	x18, x20
   10f0c:	cbnz	x22, 10578 <__gmpf_sub@@Base+0x124>
   10f10:	b	105e8 <__gmpf_sub@@Base+0x194>
   10f14:	sub	x0, x29, #0x18
   10f18:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   10f1c:	mov	x1, x0
   10f20:	cbnz	x22, 10ac4 <__gmpf_sub@@Base+0x670>
   10f24:	mov	x0, x1
   10f28:	mov	x19, x1
   10f2c:	mov	x1, x23
   10f30:	mov	x2, x24
   10f34:	bl	ca70 <__gmpn_copyi@plt>
   10f38:	ldur	x14, [x29, #-64]
   10f3c:	mov	w8, #0x1                   	// #1
   10f40:	add	x27, x27, #0x1
   10f44:	mov	x1, x19
   10f48:	add	x22, x24, #0x1
   10f4c:	str	x8, [x19, x24, lsl #3]
   10f50:	mov	x24, x20
   10f54:	mov	w25, w21
   10f58:	mov	x21, x27
   10f5c:	mov	x0, x14
   10f60:	mov	x2, x22
   10f64:	bl	ca70 <__gmpn_copyi@plt>
   10f68:	mov	x20, x22
   10f6c:	ldur	x0, [x29, #-24]
   10f70:	cbnz	x0, 10f90 <__gmpf_sub@@Base+0xb3c>
   10f74:	cbz	x20, 10f98 <__gmpf_sub@@Base+0xb44>
   10f78:	neg	w8, w20
   10f7c:	cmp	w25, #0x0
   10f80:	csel	x8, x20, x8, eq  // eq = none
   10f84:	str	w8, [x24, #4]
   10f88:	str	x21, [x24, #8]
   10f8c:	b	10fa0 <__gmpf_sub@@Base+0xb4c>
   10f90:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   10f94:	cbnz	x20, 10f78 <__gmpf_sub@@Base+0xb24>
   10f98:	str	wzr, [x24, #4]
   10f9c:	str	xzr, [x24, #8]
   10fa0:	mov	sp, x29
   10fa4:	ldp	x20, x19, [sp, #80]
   10fa8:	ldp	x22, x21, [sp, #64]
   10fac:	ldp	x24, x23, [sp, #48]
   10fb0:	ldp	x26, x25, [sp, #32]
   10fb4:	ldp	x28, x27, [sp, #16]
   10fb8:	ldp	x29, x30, [sp], #96
   10fbc:	ret

0000000000010fc0 <__gmpf_sub_ui@@Base>:
   10fc0:	sub	sp, sp, #0x30
   10fc4:	stp	x29, x30, [sp, #32]
   10fc8:	add	x29, sp, #0x20
   10fcc:	cbz	x2, 10ff0 <__gmpf_sub_ui@@Base+0x30>
   10fd0:	str	x2, [sp]
   10fd4:	mov	w8, #0x1                   	// #1
   10fd8:	mov	x9, sp
   10fdc:	add	x2, sp, #0x8
   10fe0:	str	w8, [sp, #12]
   10fe4:	stp	x8, x9, [sp, #16]
   10fe8:	bl	ce20 <__gmpf_sub@plt>
   10fec:	b	10ff4 <__gmpf_sub_ui@@Base+0x34>
   10ff0:	bl	c160 <__gmpf_set@plt>
   10ff4:	ldp	x29, x30, [sp, #32]
   10ff8:	add	sp, sp, #0x30
   10ffc:	ret

0000000000011000 <__gmpf_ui_sub@@Base>:
   11000:	sub	sp, sp, #0x30
   11004:	stp	x29, x30, [sp, #32]
   11008:	add	x29, sp, #0x20
   1100c:	cbz	x1, 11030 <__gmpf_ui_sub@@Base+0x30>
   11010:	str	x1, [sp]
   11014:	mov	w8, #0x1                   	// #1
   11018:	mov	x9, sp
   1101c:	add	x1, sp, #0x8
   11020:	str	w8, [sp, #12]
   11024:	stp	x8, x9, [sp, #16]
   11028:	bl	ce20 <__gmpf_sub@plt>
   1102c:	b	11038 <__gmpf_ui_sub@@Base+0x38>
   11030:	mov	x1, x2
   11034:	bl	cc10 <__gmpf_neg@plt>
   11038:	ldp	x29, x30, [sp, #32]
   1103c:	add	sp, sp, #0x30
   11040:	ret

0000000000011044 <__gmpf_mul@@Base>:
   11044:	stp	x29, x30, [sp, #-96]!
   11048:	stp	x28, x27, [sp, #16]
   1104c:	stp	x26, x25, [sp, #32]
   11050:	stp	x24, x23, [sp, #48]
   11054:	stp	x22, x21, [sp, #64]
   11058:	stp	x20, x19, [sp, #80]
   1105c:	mov	x29, sp
   11060:	sub	sp, sp, #0x10
   11064:	ldrsw	x27, [x0]
   11068:	ldrsw	x8, [x1, #4]
   1106c:	mov	x20, x1
   11070:	mov	x19, x0
   11074:	mov	x21, x2
   11078:	cmp	x1, x2
   1107c:	b.eq	11118 <__gmpf_mul@@Base+0xd4>  // b.none
   11080:	ldrsw	x9, [x21, #4]
   11084:	ldr	x10, [x20, #16]
   11088:	cmp	x8, #0x0
   1108c:	ldr	x11, [x21, #16]
   11090:	cneg	x12, x8, mi  // mi = first
   11094:	cmp	x9, #0x0
   11098:	cneg	x13, x9, mi  // mi = first
   1109c:	subs	x14, x12, x27
   110a0:	add	x14, x10, x14, lsl #3
   110a4:	csel	x23, x27, x12, gt
   110a8:	csel	x24, x14, x10, gt
   110ac:	subs	x10, x13, x27
   110b0:	add	x10, x11, x10, lsl #3
   110b4:	csel	x26, x10, x11, gt
   110b8:	csel	x25, x27, x13, gt
   110bc:	cbz	x23, 11184 <__gmpf_mul@@Base+0x140>
   110c0:	cbz	x25, 11184 <__gmpf_mul@@Base+0x140>
   110c4:	eor	w8, w9, w8
   110c8:	add	x28, x25, x23
   110cc:	sxtw	x8, w8
   110d0:	stp	x8, xzr, [x29, #-16]
   110d4:	lsl	x1, x28, #3
   110d8:	mov	w8, #0x7f00                	// #32512
   110dc:	cmp	x1, x8
   110e0:	b.hi	11228 <__gmpf_mul@@Base+0x1e4>  // b.pmore
   110e4:	add	x9, x1, #0xf
   110e8:	mov	x8, sp
   110ec:	and	x9, x9, #0xfffffffffffffff0
   110f0:	sub	x22, x8, x9
   110f4:	mov	sp, x22
   110f8:	mov	x0, x22
   110fc:	cmp	x23, x25
   11100:	b.ge	11190 <__gmpf_mul@@Base+0x14c>  // b.tcont
   11104:	mov	x1, x26
   11108:	mov	x2, x25
   1110c:	mov	x3, x24
   11110:	mov	x4, x23
   11114:	b	111a0 <__gmpf_mul@@Base+0x15c>
   11118:	ldr	x9, [x20, #16]
   1111c:	cmp	x8, #0x0
   11120:	cneg	x8, x8, mi  // mi = first
   11124:	subs	x10, x8, x27
   11128:	add	x10, x9, x10, lsl #3
   1112c:	csel	x23, x27, x8, gt
   11130:	csel	x24, x10, x9, gt
   11134:	cbz	x23, 11184 <__gmpf_mul@@Base+0x140>
   11138:	lsl	x1, x23, #4
   1113c:	mov	w8, #0x7f00                	// #32512
   11140:	cmp	x1, x8
   11144:	lsl	x28, x23, #1
   11148:	stur	xzr, [x29, #-8]
   1114c:	b.hi	11238 <__gmpf_mul@@Base+0x1f4>  // b.pmore
   11150:	add	x9, x1, #0xf
   11154:	mov	x8, sp
   11158:	and	x9, x9, #0xfffffffffffffff0
   1115c:	sub	x22, x8, x9
   11160:	mov	sp, x22
   11164:	mov	x0, x22
   11168:	mov	x1, x24
   1116c:	mov	x2, x23
   11170:	bl	c900 <__gmpn_sqr@plt>
   11174:	add	x8, x22, x28, lsl #3
   11178:	ldur	x0, [x8, #-8]
   1117c:	mov	x25, xzr
   11180:	b	111a8 <__gmpf_mul@@Base+0x164>
   11184:	str	wzr, [x19, #4]
   11188:	str	xzr, [x19, #8]
   1118c:	b	11200 <__gmpf_mul@@Base+0x1bc>
   11190:	mov	x1, x24
   11194:	mov	x2, x23
   11198:	mov	x3, x26
   1119c:	mov	x4, x25
   111a0:	bl	ccf0 <__gmpn_mul@plt>
   111a4:	ldur	x25, [x29, #-16]
   111a8:	cmp	x0, #0x0
   111ac:	cset	w24, eq  // eq = none
   111b0:	add	x8, x27, #0x1
   111b4:	ldr	x0, [x19, #16]
   111b8:	sub	x9, x28, x24
   111bc:	subs	x8, x9, x8
   111c0:	add	x8, x22, x8, lsl #3
   111c4:	csinc	x23, x9, x27, le
   111c8:	csel	x1, x8, x22, gt
   111cc:	mov	x2, x23
   111d0:	bl	ca70 <__gmpn_copyi@plt>
   111d4:	ldr	x8, [x20, #8]
   111d8:	ldr	x9, [x21, #8]
   111dc:	neg	w10, w23
   111e0:	cmp	x25, #0x0
   111e4:	sub	x8, x8, x24
   111e8:	csel	x10, x23, x10, ge  // ge = tcont
   111ec:	add	x8, x8, x9
   111f0:	str	x8, [x19, #8]
   111f4:	str	w10, [x19, #4]
   111f8:	ldur	x0, [x29, #-8]
   111fc:	cbnz	x0, 11220 <__gmpf_mul@@Base+0x1dc>
   11200:	mov	sp, x29
   11204:	ldp	x20, x19, [sp, #80]
   11208:	ldp	x22, x21, [sp, #64]
   1120c:	ldp	x24, x23, [sp, #48]
   11210:	ldp	x26, x25, [sp, #32]
   11214:	ldp	x28, x27, [sp, #16]
   11218:	ldp	x29, x30, [sp], #96
   1121c:	ret
   11220:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   11224:	b	11200 <__gmpf_mul@@Base+0x1bc>
   11228:	sub	x0, x29, #0x8
   1122c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   11230:	mov	x22, x0
   11234:	b	110f8 <__gmpf_mul@@Base+0xb4>
   11238:	sub	x0, x29, #0x8
   1123c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   11240:	mov	x22, x0
   11244:	b	11164 <__gmpf_mul@@Base+0x120>

0000000000011248 <__gmpf_mul_ui@@Base>:
   11248:	stp	x29, x30, [sp, #-64]!
   1124c:	stp	x20, x19, [sp, #48]
   11250:	mov	x19, x0
   11254:	str	x23, [sp, #16]
   11258:	stp	x22, x21, [sp, #32]
   1125c:	mov	x29, sp
   11260:	cbz	x2, 11330 <__gmpf_mul_ui@@Base+0xe8>
   11264:	ldr	w8, [x1, #4]
   11268:	mov	x20, x1
   1126c:	cbz	w8, 11330 <__gmpf_mul_ui@@Base+0xe8>
   11270:	ldrsw	x21, [x19]
   11274:	sxtw	x23, w8
   11278:	cmp	w23, #0x0
   1127c:	ldr	x1, [x20, #16]
   11280:	cneg	x9, x23, lt  // lt = tstop
   11284:	sub	x8, x9, x21
   11288:	mov	x3, x2
   1128c:	cmp	x8, #0x1
   11290:	b.lt	112dc <__gmpf_mul_ui@@Base+0x94>  // b.tstop
   11294:	add	x9, x1, x8, lsl #3
   11298:	ldur	x9, [x9, #-8]
   1129c:	sub	x10, x1, #0x10
   112a0:	mov	x11, x8
   112a4:	umulh	x4, x9, x3
   112a8:	sub	x12, x11, #0x1
   112ac:	cmp	x12, #0x1
   112b0:	b.lt	112d4 <__gmpf_mul_ui@@Base+0x8c>  // b.tstop
   112b4:	mul	x13, x9, x3
   112b8:	ldr	x9, [x10, x11, lsl #3]
   112bc:	umulh	x11, x9, x3
   112c0:	adds	x11, x11, x13
   112c4:	cinc	x4, x4, cs  // cs = hs, nlast
   112c8:	cmn	x11, #0x1
   112cc:	mov	x11, x12
   112d0:	b.eq	112a8 <__gmpf_mul_ui@@Base+0x60>  // b.none
   112d4:	add	x1, x1, x8, lsl #3
   112d8:	b	112e4 <__gmpf_mul_ui@@Base+0x9c>
   112dc:	mov	x4, xzr
   112e0:	mov	x21, x9
   112e4:	ldr	x22, [x19, #16]
   112e8:	mov	x2, x21
   112ec:	mov	x0, x22
   112f0:	bl	d260 <__gmpn_mul_1c@plt>
   112f4:	str	x0, [x22, x21, lsl #3]
   112f8:	ldr	x8, [x20, #8]
   112fc:	cmp	x0, #0x0
   11300:	cinc	x9, x21, ne  // ne = any
   11304:	neg	w10, w9
   11308:	cinc	x8, x8, ne  // ne = any
   1130c:	cmp	w23, #0x0
   11310:	str	x8, [x19, #8]
   11314:	csel	x8, x9, x10, ge  // ge = tcont
   11318:	str	w8, [x19, #4]
   1131c:	ldp	x20, x19, [sp, #48]
   11320:	ldp	x22, x21, [sp, #32]
   11324:	ldr	x23, [sp, #16]
   11328:	ldp	x29, x30, [sp], #64
   1132c:	ret
   11330:	str	wzr, [x19, #4]
   11334:	str	xzr, [x19, #8]
   11338:	b	1131c <__gmpf_mul_ui@@Base+0xd4>

000000000001133c <__gmpf_div@@Base>:
   1133c:	stp	x29, x30, [sp, #-96]!
   11340:	stp	x28, x27, [sp, #16]
   11344:	stp	x26, x25, [sp, #32]
   11348:	stp	x24, x23, [sp, #48]
   1134c:	stp	x22, x21, [sp, #64]
   11350:	stp	x20, x19, [sp, #80]
   11354:	mov	x29, sp
   11358:	sub	sp, sp, #0x30
   1135c:	ldrsw	x27, [x2, #4]
   11360:	cbz	w27, 11580 <__gmpf_div@@Base+0x244>
   11364:	ldrsw	x28, [x1, #4]
   11368:	mov	x19, x0
   1136c:	cbz	w28, 113ec <__gmpf_div@@Base+0xb0>
   11370:	ldr	x8, [x2, #8]
   11374:	cmp	x28, #0x0
   11378:	ldrsw	x26, [x19]
   1137c:	cneg	x11, x28, mi  // mi = first
   11380:	cmp	x27, #0x0
   11384:	cneg	x21, x27, mi  // mi = first
   11388:	ldr	x20, [x19, #16]
   1138c:	ldp	x23, x10, [x1, #8]
   11390:	stp	x8, xzr, [x29, #-16]
   11394:	sub	x8, x21, x11
   11398:	ldr	x24, [x2, #16]
   1139c:	add	x8, x8, x26
   113a0:	neg	x9, x8
   113a4:	and	x9, x9, x8, asr #63
   113a8:	cmp	x8, #0x0
   113ac:	add	x12, x10, x9, lsl #3
   113b0:	sub	x22, x11, x9
   113b4:	b.gt	113f8 <__gmpf_div@@Base+0xbc>
   113b8:	cmp	x20, x10
   113bc:	b.eq	113f8 <__gmpf_div@@Base+0xbc>  // b.none
   113c0:	lsl	x8, x22, #3
   113c4:	add	x1, x8, #0x8
   113c8:	mov	w8, #0x7f00                	// #32512
   113cc:	cmp	x1, x8
   113d0:	b.hi	11534 <__gmpf_div@@Base+0x1f8>  // b.pmore
   113d4:	add	x9, x1, #0xf
   113d8:	mov	x8, sp
   113dc:	and	x9, x9, #0xfffffffffffffff0
   113e0:	sub	x25, x8, x9
   113e4:	mov	sp, x25
   113e8:	b	11470 <__gmpf_div@@Base+0x134>
   113ec:	str	wzr, [x19, #4]
   113f0:	str	xzr, [x19, #8]
   113f4:	b	1150c <__gmpf_div@@Base+0x1d0>
   113f8:	add	x10, x21, x26
   113fc:	stp	x10, x23, [x29, #-32]
   11400:	lsl	x10, x10, #3
   11404:	add	x1, x10, #0x8
   11408:	mov	w10, #0x7f00                	// #32512
   1140c:	cmp	x1, x10
   11410:	add	x23, x9, x8
   11414:	b.hi	11554 <__gmpf_div@@Base+0x218>  // b.pmore
   11418:	add	x9, x1, #0xf
   1141c:	mov	x8, sp
   11420:	and	x9, x9, #0xfffffffffffffff0
   11424:	sub	x25, x8, x9
   11428:	mov	sp, x25
   1142c:	cbz	x23, 11458 <__gmpf_div@@Base+0x11c>
   11430:	lsl	x2, x23, #3
   11434:	mov	x0, x25
   11438:	mov	w1, wzr
   1143c:	stur	x26, [x29, #-40]
   11440:	mov	x26, x22
   11444:	mov	x22, x12
   11448:	bl	c610 <memset@plt>
   1144c:	mov	x12, x22
   11450:	mov	x22, x26
   11454:	ldur	x26, [x29, #-40]
   11458:	add	x0, x25, x23, lsl #3
   1145c:	mov	x1, x12
   11460:	mov	x2, x22
   11464:	bl	ca70 <__gmpn_copyi@plt>
   11468:	ldp	x22, x23, [x29, #-32]
   1146c:	mov	x12, x25
   11470:	eor	w27, w27, w28
   11474:	cmp	x20, x24
   11478:	add	x28, x26, #0x1
   1147c:	b.ne	114b8 <__gmpf_div@@Base+0x17c>  // b.any
   11480:	cmp	x21, #0xfe0
   11484:	lsl	x1, x21, #3
   11488:	stur	x12, [x29, #-24]
   1148c:	b.hi	11570 <__gmpf_div@@Base+0x234>  // b.pmore
   11490:	add	x9, x1, #0xf
   11494:	mov	x8, sp
   11498:	and	x9, x9, #0xfffffffffffffff0
   1149c:	sub	x24, x8, x9
   114a0:	mov	sp, x24
   114a4:	mov	x0, x24
   114a8:	mov	x1, x20
   114ac:	mov	x2, x21
   114b0:	bl	ca70 <__gmpn_copyi@plt>
   114b4:	ldur	x12, [x29, #-24]
   114b8:	mov	x0, x20
   114bc:	mov	x1, x12
   114c0:	mov	x2, x22
   114c4:	mov	x3, x24
   114c8:	mov	x4, x21
   114cc:	mov	x5, x25
   114d0:	bl	c340 <__gmpn_div_q@plt>
   114d4:	ldr	x8, [x20, x26, lsl #3]
   114d8:	ldp	x9, x0, [x29, #-16]
   114dc:	cmp	x8, #0x0
   114e0:	cset	w8, eq  // eq = none
   114e4:	sub	x9, x23, x9
   114e8:	sub	x10, x28, x8
   114ec:	cmp	w27, #0x0
   114f0:	sub	x8, x9, x8
   114f4:	neg	w9, w10
   114f8:	add	x8, x8, #0x1
   114fc:	csel	x9, x10, x9, ge  // ge = tcont
   11500:	str	w9, [x19, #4]
   11504:	str	x8, [x19, #8]
   11508:	cbnz	x0, 1152c <__gmpf_div@@Base+0x1f0>
   1150c:	mov	sp, x29
   11510:	ldp	x20, x19, [sp, #80]
   11514:	ldp	x22, x21, [sp, #64]
   11518:	ldp	x24, x23, [sp, #48]
   1151c:	ldp	x26, x25, [sp, #32]
   11520:	ldp	x28, x27, [sp, #16]
   11524:	ldp	x29, x30, [sp], #96
   11528:	ret
   1152c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   11530:	b	1150c <__gmpf_div@@Base+0x1d0>
   11534:	sub	x0, x29, #0x8
   11538:	mov	x25, x22
   1153c:	mov	x22, x12
   11540:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   11544:	mov	x12, x22
   11548:	mov	x22, x25
   1154c:	mov	x25, x0
   11550:	b	11470 <__gmpf_div@@Base+0x134>
   11554:	sub	x0, x29, #0x8
   11558:	mov	x25, x12
   1155c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   11560:	mov	x12, x25
   11564:	mov	x25, x0
   11568:	cbnz	x23, 11430 <__gmpf_div@@Base+0xf4>
   1156c:	b	11458 <__gmpf_div@@Base+0x11c>
   11570:	sub	x0, x29, #0x8
   11574:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   11578:	mov	x24, x0
   1157c:	b	114a4 <__gmpf_div@@Base+0x168>
   11580:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000011584 <__gmpf_div_ui@@Base>:
   11584:	stp	x29, x30, [sp, #-96]!
   11588:	stp	x28, x27, [sp, #16]
   1158c:	stp	x26, x25, [sp, #32]
   11590:	stp	x24, x23, [sp, #48]
   11594:	stp	x22, x21, [sp, #64]
   11598:	stp	x20, x19, [sp, #80]
   1159c:	mov	x29, sp
   115a0:	sub	sp, sp, #0x10
   115a4:	cbz	x2, 116d8 <__gmpf_div_ui@@Base+0x154>
   115a8:	ldrsw	x27, [x1, #4]
   115ac:	mov	x20, x1
   115b0:	mov	x19, x0
   115b4:	cbz	w27, 11618 <__gmpf_div_ui@@Base+0x94>
   115b8:	ldrsw	x28, [x19]
   115bc:	stur	xzr, [x29, #-8]
   115c0:	ldr	x23, [x19, #16]
   115c4:	ldr	x24, [x20, #16]
   115c8:	lsl	x8, x28, #3
   115cc:	cmp	w27, #0x0
   115d0:	add	x1, x8, #0x10
   115d4:	mov	w8, #0x7f00                	// #32512
   115d8:	mov	x21, x2
   115dc:	cneg	x25, x27, lt  // lt = tstop
   115e0:	cmp	x1, x8
   115e4:	add	x22, x28, #0x1
   115e8:	b.hi	116c0 <__gmpf_div_ui@@Base+0x13c>  // b.pmore
   115ec:	add	x9, x1, #0xf
   115f0:	mov	x8, sp
   115f4:	and	x9, x9, #0xfffffffffffffff0
   115f8:	sub	x26, x8, x9
   115fc:	mov	sp, x26
   11600:	subs	x8, x25, x22
   11604:	b.le	11624 <__gmpf_div_ui@@Base+0xa0>
   11608:	add	x24, x24, x8, lsl #3
   1160c:	mov	x25, x22
   11610:	mov	x0, x26
   11614:	b	11648 <__gmpf_div_ui@@Base+0xc4>
   11618:	str	wzr, [x19, #4]
   1161c:	str	xzr, [x19, #8]
   11620:	b	116a0 <__gmpf_div_ui@@Base+0x11c>
   11624:	stur	x23, [x29, #-16]
   11628:	subs	x23, x22, x25
   1162c:	b.eq	11640 <__gmpf_div_ui@@Base+0xbc>  // b.none
   11630:	lsl	x2, x23, #3
   11634:	mov	x0, x26
   11638:	mov	w1, wzr
   1163c:	bl	c610 <memset@plt>
   11640:	add	x0, x26, x23, lsl #3
   11644:	ldur	x23, [x29, #-16]
   11648:	mov	x1, x24
   1164c:	mov	x2, x25
   11650:	bl	ca70 <__gmpn_copyi@plt>
   11654:	mov	x0, x23
   11658:	mov	x1, xzr
   1165c:	mov	x2, x26
   11660:	mov	x3, x22
   11664:	mov	x4, x21
   11668:	bl	cd20 <__gmpn_divrem_1@plt>
   1166c:	ldr	x8, [x23, x28, lsl #3]
   11670:	ldr	x9, [x20, #8]
   11674:	cmp	x8, #0x0
   11678:	cset	w8, eq  // eq = none
   1167c:	sub	x10, x22, x8
   11680:	cmp	w27, #0x0
   11684:	sub	x8, x9, x8
   11688:	neg	w9, w10
   1168c:	csel	x9, x10, x9, ge  // ge = tcont
   11690:	str	w9, [x19, #4]
   11694:	str	x8, [x19, #8]
   11698:	ldur	x0, [x29, #-8]
   1169c:	cbnz	x0, 116d0 <__gmpf_div_ui@@Base+0x14c>
   116a0:	mov	sp, x29
   116a4:	ldp	x20, x19, [sp, #80]
   116a8:	ldp	x22, x21, [sp, #64]
   116ac:	ldp	x24, x23, [sp, #48]
   116b0:	ldp	x26, x25, [sp, #32]
   116b4:	ldp	x28, x27, [sp, #16]
   116b8:	ldp	x29, x30, [sp], #96
   116bc:	ret
   116c0:	sub	x0, x29, #0x8
   116c4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   116c8:	mov	x26, x0
   116cc:	b	11600 <__gmpf_div_ui@@Base+0x7c>
   116d0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   116d4:	b	116a0 <__gmpf_div_ui@@Base+0x11c>
   116d8:	bl	bfe0 <__gmp_divide_by_zero@plt>

00000000000116dc <__gmpf_cmp_z@@Base>:
   116dc:	sub	sp, sp, #0x30
   116e0:	stp	x29, x30, [sp, #32]
   116e4:	ldrsw	x8, [x1, #4]
   116e8:	add	x29, sp, #0x20
   116ec:	cmp	x8, #0x0
   116f0:	str	w8, [sp, #12]
   116f4:	cneg	x8, x8, mi  // mi = first
   116f8:	str	x8, [sp, #16]
   116fc:	ldr	x8, [x1, #8]
   11700:	add	x1, sp, #0x8
   11704:	str	x8, [sp, #24]
   11708:	bl	c690 <__gmpf_cmp@plt>
   1170c:	ldp	x29, x30, [sp, #32]
   11710:	add	sp, sp, #0x30
   11714:	ret

0000000000011718 <__gmpf_cmp@@Base>:
   11718:	ldrsw	x12, [x0, #4]
   1171c:	ldrsw	x9, [x1, #4]
   11720:	mov	w10, #0x1                   	// #1
   11724:	mov	x8, x0
   11728:	cmp	w12, #0x0
   1172c:	eor	w11, w9, w12
   11730:	cneg	w0, w10, lt  // lt = tstop
   11734:	tbnz	w11, #31, 11750 <__gmpf_cmp@@Base+0x38>
   11738:	cbz	w12, 11754 <__gmpf_cmp@@Base+0x3c>
   1173c:	cbz	w9, 11760 <__gmpf_cmp@@Base+0x48>
   11740:	ldr	x10, [x8, #8]
   11744:	ldr	x11, [x1, #8]
   11748:	cmp	x10, x11
   1174c:	b.le	11768 <__gmpf_cmp@@Base+0x50>
   11750:	ret
   11754:	cmp	w9, #0x0
   11758:	csetm	w0, ne  // ne = any
   1175c:	ret
   11760:	mov	w0, #0x1                   	// #1
   11764:	ret
   11768:	b.ge	11774 <__gmpf_cmp@@Base+0x5c>  // b.tcont
   1176c:	neg	w0, w0
   11770:	ret
   11774:	ldr	x10, [x8, #16]
   11778:	ldr	x11, [x1, #16]
   1177c:	cmp	w12, #0x0
   11780:	cneg	x8, x12, lt  // lt = tstop
   11784:	ldr	x13, [x10]
   11788:	cmp	x9, #0x0
   1178c:	cneg	x9, x9, mi  // mi = first
   11790:	cbnz	x13, 117a0 <__gmpf_cmp@@Base+0x88>
   11794:	ldr	x12, [x10, #8]!
   11798:	sub	x8, x8, #0x1
   1179c:	cbz	x12, 11794 <__gmpf_cmp@@Base+0x7c>
   117a0:	ldr	x12, [x11]
   117a4:	cbnz	x12, 117b4 <__gmpf_cmp@@Base+0x9c>
   117a8:	ldr	x12, [x11, #8]!
   117ac:	sub	x9, x9, #0x1
   117b0:	cbz	x12, 117a8 <__gmpf_cmp@@Base+0x90>
   117b4:	cmp	x8, x9
   117b8:	b.le	117e8 <__gmpf_cmp@@Base+0xd0>
   117bc:	add	x8, x10, x8, lsl #3
   117c0:	sub	x11, x11, #0x8
   117c4:	sub	x8, x8, #0x8
   117c8:	subs	x10, x9, #0x1
   117cc:	b.lt	11750 <__gmpf_cmp@@Base+0x38>  // b.tstop
   117d0:	ldr	x12, [x8], #-8
   117d4:	ldr	x9, [x11, x9, lsl #3]
   117d8:	cmp	x12, x9
   117dc:	mov	x9, x10
   117e0:	b.eq	117c8 <__gmpf_cmp@@Base+0xb0>  // b.none
   117e4:	b	11840 <__gmpf_cmp@@Base+0x128>
   117e8:	cmp	x9, x8
   117ec:	b.le	1181c <__gmpf_cmp@@Base+0x104>
   117f0:	add	x9, x11, x9, lsl #3
   117f4:	sub	x9, x9, #0x8
   117f8:	sub	x10, x10, #0x8
   117fc:	subs	x11, x8, #0x1
   11800:	b.lt	1176c <__gmpf_cmp@@Base+0x54>  // b.tstop
   11804:	ldr	x8, [x10, x8, lsl #3]
   11808:	ldr	x12, [x9], #-8
   1180c:	cmp	x8, x12
   11810:	mov	x8, x11
   11814:	b.eq	117fc <__gmpf_cmp@@Base+0xe4>  // b.none
   11818:	b	11840 <__gmpf_cmp@@Base+0x128>
   1181c:	sub	x9, x11, #0x8
   11820:	sub	x10, x10, #0x8
   11824:	subs	x11, x8, #0x1
   11828:	b.lt	11848 <__gmpf_cmp@@Base+0x130>  // b.tstop
   1182c:	ldr	x12, [x10, x8, lsl #3]
   11830:	ldr	x8, [x9, x8, lsl #3]
   11834:	cmp	x12, x8
   11838:	mov	x8, x11
   1183c:	b.eq	11824 <__gmpf_cmp@@Base+0x10c>  // b.none
   11840:	b.hi	11750 <__gmpf_cmp@@Base+0x38>  // b.pmore
   11844:	b	1176c <__gmpf_cmp@@Base+0x54>
   11848:	mov	w0, wzr
   1184c:	ret

0000000000011850 <__gmpf_cmp_d@@Base>:
   11850:	sub	sp, sp, #0x50
   11854:	fmov	x8, d0
   11858:	mvn	x9, x8
   1185c:	tst	x9, #0x7ff0000000000000
   11860:	stp	x29, x30, [sp, #48]
   11864:	str	x19, [sp, #64]
   11868:	add	x29, sp, #0x30
   1186c:	b.eq	118d0 <__gmpf_cmp_d@@Base+0x80>  // b.none
   11870:	mov	x19, x0
   11874:	fcmp	d0, #0.0
   11878:	b.ne	11884 <__gmpf_cmp_d@@Base+0x34>  // b.any
   1187c:	ldr	w0, [x19, #4]
   11880:	b	118c0 <__gmpf_cmp_d@@Base+0x70>
   11884:	sub	x8, x29, #0x10
   11888:	mov	w9, #0xfffffffe            	// #-2
   1188c:	mov	w10, #0x2                   	// #2
   11890:	fneg	d1, d0
   11894:	str	x8, [sp, #24]
   11898:	csel	w8, w10, w9, ge  // ge = tcont
   1189c:	fcsel	d0, d0, d1, ge  // ge = tcont
   118a0:	sub	x0, x29, #0x10
   118a4:	str	w8, [sp, #12]
   118a8:	bl	d2a0 <__gmp_extract_double@plt>
   118ac:	sxtw	x8, w0
   118b0:	add	x1, sp, #0x8
   118b4:	mov	x0, x19
   118b8:	str	x8, [sp, #16]
   118bc:	bl	c690 <__gmpf_cmp@plt>
   118c0:	ldr	x19, [sp, #64]
   118c4:	ldp	x29, x30, [sp, #48]
   118c8:	add	sp, sp, #0x50
   118cc:	ret
   118d0:	tst	x8, #0xfffffffffffff
   118d4:	b.ne	118e8 <__gmpf_cmp_d@@Base+0x98>  // b.any
   118d8:	fcmp	d0, #0.0
   118dc:	mov	w8, #0xffffffff            	// #-1
   118e0:	csinc	w0, w8, wzr, pl  // pl = nfrst
   118e4:	b	118c0 <__gmpf_cmp_d@@Base+0x70>
   118e8:	bl	c1c0 <__gmp_invalid_operation@plt>

00000000000118ec <__gmpf_cmp_ui@@Base>:
   118ec:	ldrsw	x8, [x0, #4]
   118f0:	tbnz	w8, #31, 1193c <__gmpf_cmp_ui@@Base+0x50>
   118f4:	cbz	x1, 11944 <__gmpf_cmp_ui@@Base+0x58>
   118f8:	ldr	x9, [x0, #8]
   118fc:	cmp	x9, #0x1
   11900:	b.ne	11950 <__gmpf_cmp_ui@@Base+0x64>  // b.any
   11904:	ldr	x9, [x0, #16]
   11908:	sub	x8, x8, #0x1
   1190c:	ldr	x10, [x9, x8, lsl #3]
   11910:	cmp	x10, x1
   11914:	b.ne	1195c <__gmpf_cmp_ui@@Base+0x70>  // b.any
   11918:	ldr	x10, [x9]
   1191c:	cbnz	x10, 11930 <__gmpf_cmp_ui@@Base+0x44>
   11920:	add	x9, x9, #0x8
   11924:	ldr	x10, [x9], #8
   11928:	sub	x8, x8, #0x1
   1192c:	cbz	x10, 11924 <__gmpf_cmp_ui@@Base+0x38>
   11930:	cmp	x8, #0x0
   11934:	cset	w0, gt
   11938:	ret
   1193c:	mov	w0, #0xffffffff            	// #-1
   11940:	ret
   11944:	cmp	w8, #0x0
   11948:	cset	w0, ne  // ne = any
   1194c:	ret
   11950:	mov	w8, #0xffffffff            	// #-1
   11954:	cneg	w0, w8, ge  // ge = tcont
   11958:	ret
   1195c:	mov	w8, #0xffffffff            	// #-1
   11960:	cneg	w0, w8, cs  // cs = hs, nlast
   11964:	ret

0000000000011968 <__gmpf_cmp_si@@Base>:
   11968:	ldrsw	x10, [x0, #4]
   1196c:	lsr	x9, x1, #63
   11970:	cmp	w9, w10, lsr #31
   11974:	b.ne	119e4 <__gmpf_cmp_si@@Base+0x7c>  // b.any
   11978:	cbz	w10, 119f4 <__gmpf_cmp_si@@Base+0x8c>
   1197c:	mov	x8, x0
   11980:	mov	w0, #0x1                   	// #1
   11984:	cbz	x1, 119e0 <__gmpf_cmp_si@@Base+0x78>
   11988:	ldr	x11, [x8, #8]
   1198c:	cmp	w10, #0x0
   11990:	cneg	w9, w0, lt  // lt = tstop
   11994:	cmp	x1, #0x0
   11998:	cneg	x12, x1, mi  // mi = first
   1199c:	cmp	x11, #0x1
   119a0:	b.ne	11a00 <__gmpf_cmp_si@@Base+0x98>  // b.any
   119a4:	ldr	x11, [x8, #16]
   119a8:	cmp	w10, #0x0
   119ac:	cneg	x8, x10, lt  // lt = tstop
   119b0:	sub	x8, x8, #0x1
   119b4:	ldr	x10, [x11, x8, lsl #3]
   119b8:	cmp	x10, x12
   119bc:	b.ne	11a08 <__gmpf_cmp_si@@Base+0xa0>  // b.any
   119c0:	ldr	x10, [x11]
   119c4:	cbnz	x10, 119d8 <__gmpf_cmp_si@@Base+0x70>
   119c8:	add	x10, x11, #0x8
   119cc:	ldr	x11, [x10], #8
   119d0:	sub	x8, x8, #0x1
   119d4:	cbz	x11, 119cc <__gmpf_cmp_si@@Base+0x64>
   119d8:	cmp	x8, #0x0
   119dc:	csel	w0, w9, wzr, gt
   119e0:	ret
   119e4:	cmp	w10, #0x0
   119e8:	mov	w8, #0x1                   	// #1
   119ec:	cneg	w0, w8, lt  // lt = tstop
   119f0:	ret
   119f4:	cmp	x1, #0x0
   119f8:	csetm	w0, ne  // ne = any
   119fc:	ret
   11a00:	cneg	w0, w9, lt  // lt = tstop
   11a04:	ret
   11a08:	cneg	w0, w9, cc  // cc = lo, ul, last
   11a0c:	ret

0000000000011a10 <__gmpf_mul_2exp@@Base>:
   11a10:	stp	x29, x30, [sp, #-80]!
   11a14:	stp	x24, x23, [sp, #32]
   11a18:	stp	x22, x21, [sp, #48]
   11a1c:	stp	x20, x19, [sp, #64]
   11a20:	ldrsw	x24, [x1, #4]
   11a24:	mov	x19, x0
   11a28:	str	x25, [sp, #16]
   11a2c:	mov	x29, sp
   11a30:	cbz	w24, 11b00 <__gmpf_mul_2exp@@Base+0xf0>
   11a34:	ldr	x21, [x19, #16]
   11a38:	ldrsw	x22, [x19]
   11a3c:	ldp	x25, x1, [x1, #8]
   11a40:	cmp	w24, #0x0
   11a44:	mov	x20, x2
   11a48:	cneg	x23, x24, lt  // lt = tstop
   11a4c:	ands	x3, x2, #0x3f
   11a50:	b.eq	11a80 <__gmpf_mul_2exp@@Base+0x70>  // b.none
   11a54:	subs	x8, x23, x22
   11a58:	b.le	11ab0 <__gmpf_mul_2exp@@Base+0xa0>
   11a5c:	add	x1, x1, x8, lsl #3
   11a60:	mov	w8, #0x40                  	// #64
   11a64:	add	x0, x21, #0x8
   11a68:	sub	w3, w8, w3
   11a6c:	mov	x2, x22
   11a70:	bl	c1b0 <__gmpn_rshift@plt>
   11a74:	str	x0, [x21]
   11a78:	ldr	x0, [x21, x22, lsl #3]
   11a7c:	b	11ac4 <__gmpf_mul_2exp@@Base+0xb4>
   11a80:	add	x8, x22, #0x1
   11a84:	subs	x8, x23, x8
   11a88:	add	x8, x1, x8, lsl #3
   11a8c:	csel	x1, x8, x1, gt
   11a90:	csinc	x22, x23, x22, le
   11a94:	cmp	x21, x1
   11a98:	b.eq	11aa8 <__gmpf_mul_2exp@@Base+0x98>  // b.none
   11a9c:	mov	x0, x21
   11aa0:	mov	x2, x22
   11aa4:	bl	ca70 <__gmpn_copyi@plt>
   11aa8:	add	x8, x25, x20, lsr #6
   11aac:	b	11ad4 <__gmpf_mul_2exp@@Base+0xc4>
   11ab0:	mov	x0, x21
   11ab4:	mov	x2, x23
   11ab8:	bl	c190 <__gmpn_lshift@plt>
   11abc:	mov	x22, x23
   11ac0:	str	x0, [x21, x23, lsl #3]
   11ac4:	cmp	x0, #0x0
   11ac8:	add	x8, x25, x20, lsr #6
   11acc:	cinc	x22, x22, ne  // ne = any
   11ad0:	cinc	x8, x8, ne  // ne = any
   11ad4:	str	x8, [x19, #8]
   11ad8:	neg	w8, w22
   11adc:	cmp	w24, #0x0
   11ae0:	csel	x8, x22, x8, ge  // ge = tcont
   11ae4:	str	w8, [x19, #4]
   11ae8:	ldp	x20, x19, [sp, #64]
   11aec:	ldp	x22, x21, [sp, #48]
   11af0:	ldp	x24, x23, [sp, #32]
   11af4:	ldr	x25, [sp, #16]
   11af8:	ldp	x29, x30, [sp], #80
   11afc:	ret
   11b00:	str	wzr, [x19, #4]
   11b04:	str	xzr, [x19, #8]
   11b08:	b	11ae8 <__gmpf_mul_2exp@@Base+0xd8>

0000000000011b0c <__gmpf_div_2exp@@Base>:
   11b0c:	stp	x29, x30, [sp, #-80]!
   11b10:	stp	x24, x23, [sp, #32]
   11b14:	stp	x22, x21, [sp, #48]
   11b18:	stp	x20, x19, [sp, #64]
   11b1c:	ldrsw	x24, [x1, #4]
   11b20:	mov	x19, x0
   11b24:	str	x25, [sp, #16]
   11b28:	mov	x29, sp
   11b2c:	cbz	w24, 11c08 <__gmpf_div_2exp@@Base+0xfc>
   11b30:	ldr	x21, [x19, #16]
   11b34:	ldrsw	x22, [x19]
   11b38:	ldp	x25, x1, [x1, #8]
   11b3c:	cmp	w24, #0x0
   11b40:	mov	x20, x2
   11b44:	cneg	x23, x24, lt  // lt = tstop
   11b48:	ands	x3, x2, #0x3f
   11b4c:	b.eq	11b74 <__gmpf_div_2exp@@Base+0x68>  // b.none
   11b50:	subs	x8, x23, x22
   11b54:	b.le	11ba4 <__gmpf_div_2exp@@Base+0x98>
   11b58:	add	x1, x1, x8, lsl #3
   11b5c:	add	x0, x21, #0x8
   11b60:	mov	x2, x22
   11b64:	bl	c1b0 <__gmpn_rshift@plt>
   11b68:	str	x0, [x21]
   11b6c:	ldr	x0, [x21, x22, lsl #3]
   11b70:	b	11bc0 <__gmpf_div_2exp@@Base+0xb4>
   11b74:	add	x8, x22, #0x1
   11b78:	subs	x8, x23, x8
   11b7c:	add	x8, x1, x8, lsl #3
   11b80:	csel	x1, x8, x1, gt
   11b84:	csinc	x22, x23, x22, le
   11b88:	cmp	x21, x1
   11b8c:	b.eq	11b9c <__gmpf_div_2exp@@Base+0x90>  // b.none
   11b90:	mov	x0, x21
   11b94:	mov	x2, x22
   11b98:	bl	ca70 <__gmpn_copyi@plt>
   11b9c:	sub	x8, x25, x20, lsr #6
   11ba0:	b	11bdc <__gmpf_div_2exp@@Base+0xd0>
   11ba4:	mov	w8, #0x40                  	// #64
   11ba8:	sub	w3, w8, w3
   11bac:	mov	x0, x21
   11bb0:	mov	x2, x23
   11bb4:	bl	c190 <__gmpn_lshift@plt>
   11bb8:	mov	x22, x23
   11bbc:	str	x0, [x21, x23, lsl #3]
   11bc0:	mov	x9, #0xffffffffffffffff    	// #-1
   11bc4:	eor	x9, x9, x20, lsr #6
   11bc8:	sub	x8, x25, x20, lsr #6
   11bcc:	cmp	x0, #0x0
   11bd0:	add	x9, x25, x9
   11bd4:	cinc	x22, x22, ne  // ne = any
   11bd8:	csel	x8, x9, x8, eq  // eq = none
   11bdc:	str	x8, [x19, #8]
   11be0:	neg	w8, w22
   11be4:	cmp	w24, #0x0
   11be8:	csel	x8, x22, x8, ge  // ge = tcont
   11bec:	str	w8, [x19, #4]
   11bf0:	ldp	x20, x19, [sp, #64]
   11bf4:	ldp	x22, x21, [sp, #48]
   11bf8:	ldp	x24, x23, [sp, #32]
   11bfc:	ldr	x25, [sp, #16]
   11c00:	ldp	x29, x30, [sp], #80
   11c04:	ret
   11c08:	str	wzr, [x19, #4]
   11c0c:	str	xzr, [x19, #8]
   11c10:	b	11bf0 <__gmpf_div_2exp@@Base+0xe4>

0000000000011c14 <__gmpf_abs@@Base>:
   11c14:	stp	x29, x30, [sp, #-48]!
   11c18:	stp	x20, x19, [sp, #32]
   11c1c:	ldr	w8, [x1, #4]
   11c20:	mov	x19, x0
   11c24:	str	x21, [sp, #16]
   11c28:	mov	x29, sp
   11c2c:	cmp	w8, #0x0
   11c30:	cneg	w20, w8, mi  // mi = first
   11c34:	cmp	x0, x1
   11c38:	b.eq	11c70 <__gmpf_abs@@Base+0x5c>  // b.none
   11c3c:	ldrsw	x8, [x19]
   11c40:	ldr	x9, [x1, #16]
   11c44:	ldr	x0, [x19, #16]
   11c48:	mov	x21, x1
   11c4c:	add	x10, x8, #0x1
   11c50:	subs	x10, x20, x10
   11c54:	add	x10, x9, x10, lsl #3
   11c58:	csinc	x20, x20, x8, le
   11c5c:	csel	x1, x10, x9, gt
   11c60:	mov	x2, x20
   11c64:	bl	ca70 <__gmpn_copyi@plt>
   11c68:	ldr	x8, [x21, #8]
   11c6c:	str	x8, [x19, #8]
   11c70:	str	w20, [x19, #4]
   11c74:	ldp	x20, x19, [sp, #32]
   11c78:	ldr	x21, [sp, #16]
   11c7c:	ldp	x29, x30, [sp], #48
   11c80:	ret

0000000000011c84 <__gmpf_neg@@Base>:
   11c84:	stp	x29, x30, [sp, #-48]!
   11c88:	stp	x20, x19, [sp, #32]
   11c8c:	ldrsw	x8, [x1, #4]
   11c90:	str	x21, [sp, #16]
   11c94:	mov	x19, x0
   11c98:	cmp	x0, x1
   11c9c:	neg	x21, x8
   11ca0:	mov	x29, sp
   11ca4:	b.eq	11ce8 <__gmpf_neg@@Base+0x64>  // b.none
   11ca8:	ldrsw	x9, [x19]
   11cac:	ldr	x10, [x1, #16]
   11cb0:	cmp	w8, #0x1
   11cb4:	ldr	x0, [x19, #16]
   11cb8:	cneg	x11, x21, ge  // ge = tcont
   11cbc:	add	x12, x9, #0x1
   11cc0:	subs	x12, x11, x12
   11cc4:	add	x12, x10, x12, lsl #3
   11cc8:	mov	x20, x1
   11ccc:	csinc	x2, x11, x9, le
   11cd0:	csel	x1, x12, x10, gt
   11cd4:	cmp	w8, #0x1
   11cd8:	cneg	x21, x2, ge  // ge = tcont
   11cdc:	bl	ca70 <__gmpn_copyi@plt>
   11ce0:	ldr	x8, [x20, #8]
   11ce4:	str	x8, [x19, #8]
   11ce8:	str	w21, [x19, #4]
   11cec:	ldp	x20, x19, [sp, #32]
   11cf0:	ldr	x21, [sp, #16]
   11cf4:	ldp	x29, x30, [sp], #48
   11cf8:	ret

0000000000011cfc <__gmpf_set_q@@Base>:
   11cfc:	stp	x29, x30, [sp, #-96]!
   11d00:	stp	x28, x27, [sp, #16]
   11d04:	stp	x26, x25, [sp, #32]
   11d08:	stp	x24, x23, [sp, #48]
   11d0c:	stp	x22, x21, [sp, #64]
   11d10:	stp	x20, x19, [sp, #80]
   11d14:	mov	x29, sp
   11d18:	sub	sp, sp, #0x20
   11d1c:	ldrsw	x27, [x1, #4]
   11d20:	mov	x19, x0
   11d24:	cbz	w27, 11e3c <__gmpf_set_q@@Base+0x140>
   11d28:	ldrsw	x20, [x1, #20]
   11d2c:	ldr	x8, [x19, #16]
   11d30:	ldrsw	x22, [x19]
   11d34:	cmp	w27, #0x0
   11d38:	cneg	x24, x27, lt  // lt = tstop
   11d3c:	stur	x8, [x29, #-24]
   11d40:	sub	x8, x24, x20
   11d44:	add	x8, x8, #0x1
   11d48:	add	x9, x22, #0x1
   11d4c:	sub	x28, x9, x8
   11d50:	ldr	x25, [x1, #8]
   11d54:	ldr	x3, [x1, #24]
   11d58:	add	x23, x28, x24
   11d5c:	stp	x8, xzr, [x29, #-16]
   11d60:	lsl	x8, x23, #3
   11d64:	add	x1, x8, #0x8
   11d68:	mov	w8, #0x7f00                	// #32512
   11d6c:	cmp	x1, x8
   11d70:	stur	x9, [x29, #-32]
   11d74:	b.hi	11e48 <__gmpf_set_q@@Base+0x14c>  // b.pmore
   11d78:	add	x9, x1, #0xf
   11d7c:	mov	x8, sp
   11d80:	and	x9, x9, #0xfffffffffffffff0
   11d84:	sub	x26, x8, x9
   11d88:	mov	sp, x26
   11d8c:	cmp	x28, #0x1
   11d90:	b.lt	11dcc <__gmpf_set_q@@Base+0xd0>  // b.tstop
   11d94:	add	x8, x20, x22
   11d98:	sub	x8, x8, x24
   11d9c:	lsl	x2, x8, #3
   11da0:	mov	x0, x26
   11da4:	mov	w1, wzr
   11da8:	mov	x21, x3
   11dac:	bl	c610 <memset@plt>
   11db0:	add	x0, x26, x28, lsl #3
   11db4:	mov	x1, x25
   11db8:	mov	x2, x24
   11dbc:	bl	ca70 <__gmpn_copyi@plt>
   11dc0:	mov	x3, x21
   11dc4:	mov	x1, x26
   11dc8:	b	11dd0 <__gmpf_set_q@@Base+0xd4>
   11dcc:	sub	x1, x25, x28, lsl #3
   11dd0:	ldur	x21, [x29, #-24]
   11dd4:	mov	x2, x23
   11dd8:	mov	x4, x20
   11ddc:	mov	x5, x26
   11de0:	mov	x0, x21
   11de4:	bl	c340 <__gmpn_div_q@plt>
   11de8:	ldr	x8, [x21, x22, lsl #3]
   11dec:	ldur	x9, [x29, #-32]
   11df0:	ldp	x10, x0, [x29, #-16]
   11df4:	cmp	x8, #0x0
   11df8:	cset	w8, eq  // eq = none
   11dfc:	sub	x9, x9, x8
   11e00:	sub	x8, x10, x8
   11e04:	str	x8, [x19, #8]
   11e08:	neg	w8, w9
   11e0c:	cmp	w27, #0x0
   11e10:	csel	x8, x9, x8, ge  // ge = tcont
   11e14:	str	w8, [x19, #4]
   11e18:	cbnz	x0, 11e60 <__gmpf_set_q@@Base+0x164>
   11e1c:	mov	sp, x29
   11e20:	ldp	x20, x19, [sp, #80]
   11e24:	ldp	x22, x21, [sp, #64]
   11e28:	ldp	x24, x23, [sp, #48]
   11e2c:	ldp	x26, x25, [sp, #32]
   11e30:	ldp	x28, x27, [sp, #16]
   11e34:	ldp	x29, x30, [sp], #96
   11e38:	ret
   11e3c:	str	wzr, [x19, #4]
   11e40:	str	xzr, [x19, #8]
   11e44:	b	11e1c <__gmpf_set_q@@Base+0x120>
   11e48:	sub	x0, x29, #0x8
   11e4c:	mov	x21, x3
   11e50:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   11e54:	mov	x3, x21
   11e58:	mov	x26, x0
   11e5c:	b	11d8c <__gmpf_set_q@@Base+0x90>
   11e60:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   11e64:	b	11e1c <__gmpf_set_q@@Base+0x120>

0000000000011e68 <__gmpf_get_d@@Base>:
   11e68:	ldrsw	x2, [x0, #4]
   11e6c:	cbz	w2, 11e88 <__gmpf_get_d@@Base+0x20>
   11e70:	ldp	x8, x0, [x0, #8]
   11e74:	cmp	x2, #0x0
   11e78:	cneg	x1, x2, mi  // mi = first
   11e7c:	sub	x8, x8, x1
   11e80:	lsl	x3, x8, #6
   11e84:	b	bf50 <__gmpn_get_d@plt>
   11e88:	fmov	d0, xzr
   11e8c:	ret

0000000000011e90 <__gmpf_get_d_2exp@@Base>:
   11e90:	ldrsw	x2, [x1, #4]
   11e94:	cbz	w2, 11ec8 <__gmpf_get_d_2exp@@Base+0x38>
   11e98:	ldp	x9, x8, [x1, #8]
   11e9c:	cmp	x2, #0x0
   11ea0:	cneg	x1, x2, mi  // mi = first
   11ea4:	add	x10, x8, x1, lsl #3
   11ea8:	ldur	x10, [x10, #-8]
   11eac:	lsl	x9, x9, #6
   11eb0:	clz	x10, x10
   11eb4:	sub	x9, x9, x10
   11eb8:	sub	x3, x10, x1, lsl #6
   11ebc:	str	x9, [x0]
   11ec0:	mov	x0, x8
   11ec4:	b	bf50 <__gmpn_get_d@plt>
   11ec8:	fmov	d0, xzr
   11ecc:	str	xzr, [x0]
   11ed0:	ret

0000000000011ed4 <__gmpf_set_default_prec@@Base>:
   11ed4:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   11ed8:	cmp	x0, #0x35
   11edc:	mov	w8, #0x35                  	// #53
   11ee0:	ldr	x9, [x9, #3960]
   11ee4:	csel	x8, x0, x8, hi  // hi = pmore
   11ee8:	add	x8, x8, #0x7f
   11eec:	lsr	x8, x8, #6
   11ef0:	str	x8, [x9]
   11ef4:	ret

0000000000011ef8 <__gmpf_set_prec@@Base>:
   11ef8:	stp	x29, x30, [sp, #-48]!
   11efc:	stp	x22, x21, [sp, #16]
   11f00:	stp	x20, x19, [sp, #32]
   11f04:	cmp	x1, #0x35
   11f08:	mov	w8, #0x35                  	// #53
   11f0c:	ldrsw	x22, [x0]
   11f10:	csel	x8, x1, x8, hi  // hi = pmore
   11f14:	add	x8, x8, #0x7f
   11f18:	lsr	x8, x8, #6
   11f1c:	cmp	x8, x22
   11f20:	mov	x29, sp
   11f24:	b.eq	11f94 <__gmpf_set_prec@@Base+0x9c>  // b.none
   11f28:	ldrsw	x10, [x0, #4]
   11f2c:	ldr	x21, [x0, #16]
   11f30:	add	x20, x8, #0x1
   11f34:	mov	x19, x0
   11f38:	cmp	x10, #0x0
   11f3c:	cneg	x9, x10, mi  // mi = first
   11f40:	cmp	x9, x20
   11f44:	str	w8, [x0]
   11f48:	b.le	11f70 <__gmpf_set_prec@@Base+0x78>
   11f4c:	mvn	x11, x8
   11f50:	cmp	w10, #0x0
   11f54:	add	x9, x21, x9, lsl #3
   11f58:	csinv	x8, x20, x8, ge  // ge = tcont
   11f5c:	add	x1, x9, x11, lsl #3
   11f60:	mov	x0, x21
   11f64:	mov	x2, x20
   11f68:	str	w8, [x19, #4]
   11f6c:	bl	ca70 <__gmpn_copyi@plt>
   11f70:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   11f74:	ldr	x8, [x8, #3792]
   11f78:	lsl	x9, x22, #3
   11f7c:	add	x1, x9, #0x8
   11f80:	lsl	x2, x20, #3
   11f84:	ldr	x8, [x8]
   11f88:	mov	x0, x21
   11f8c:	blr	x8
   11f90:	str	x0, [x19, #16]
   11f94:	ldp	x20, x19, [sp, #32]
   11f98:	ldp	x22, x21, [sp, #16]
   11f9c:	ldp	x29, x30, [sp], #48
   11fa0:	ret

0000000000011fa4 <__gmpf_set_prec_raw@@Base>:
   11fa4:	cmp	x1, #0x35
   11fa8:	mov	w8, #0x35                  	// #53
   11fac:	csel	x8, x1, x8, hi  // hi = pmore
   11fb0:	add	x8, x8, #0x7f
   11fb4:	lsr	x8, x8, #6
   11fb8:	str	w8, [x0]
   11fbc:	ret

0000000000011fc0 <__gmpf_get_default_prec@@Base>:
   11fc0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   11fc4:	ldr	x8, [x8, #3960]
   11fc8:	ldr	x8, [x8]
   11fcc:	lsl	x8, x8, #6
   11fd0:	sub	x0, x8, #0x40
   11fd4:	ret

0000000000011fd8 <__gmpf_get_prec@@Base>:
   11fd8:	ldrsw	x8, [x0]
   11fdc:	lsl	x8, x8, #6
   11fe0:	sub	x0, x8, #0x40
   11fe4:	ret

0000000000011fe8 <__gmpf_ui_div@@Base>:
   11fe8:	stp	x29, x30, [sp, #-96]!
   11fec:	stp	x28, x27, [sp, #16]
   11ff0:	stp	x26, x25, [sp, #32]
   11ff4:	stp	x24, x23, [sp, #48]
   11ff8:	stp	x22, x21, [sp, #64]
   11ffc:	stp	x20, x19, [sp, #80]
   12000:	mov	x29, sp
   12004:	sub	sp, sp, #0x30
   12008:	ldrsw	x27, [x2, #4]
   1200c:	cbz	w27, 12180 <__gmpf_ui_div@@Base+0x198>
   12010:	mov	x11, x1
   12014:	mov	x19, x0
   12018:	cbz	x1, 12150 <__gmpf_ui_div@@Base+0x168>
   1201c:	ldrsw	x12, [x19]
   12020:	ldr	x21, [x19, #16]
   12024:	ldp	x13, x23, [x2, #8]
   12028:	cmp	w27, #0x0
   1202c:	cneg	x22, x27, lt  // lt = tstop
   12030:	add	x10, x12, #0x1
   12034:	add	x20, x22, x10
   12038:	cmp	x21, x23
   1203c:	sub	x24, x20, #0x1
   12040:	csel	x8, x22, xzr, eq  // eq = none
   12044:	add	x9, x24, x22
   12048:	add	x8, x9, x8
   1204c:	lsl	x1, x8, #3
   12050:	mov	w8, #0x7f00                	// #32512
   12054:	cmp	x1, x8
   12058:	mov	w14, #0x2                   	// #2
   1205c:	stp	x10, xzr, [x29, #-16]
   12060:	stp	x12, x11, [x29, #-32]
   12064:	b.hi	1215c <__gmpf_ui_div@@Base+0x174>  // b.pmore
   12068:	add	x9, x1, #0xf
   1206c:	mov	x8, sp
   12070:	and	x9, x9, #0xfffffffffffffff0
   12074:	sub	x25, x8, x9
   12078:	mov	sp, x25
   1207c:	sub	x28, x20, #0x2
   12080:	cmp	x21, x23
   12084:	add	x26, x25, x22, lsl #3
   12088:	b.ne	120ac <__gmpf_ui_div@@Base+0xc4>  // b.any
   1208c:	add	x23, x26, x24, lsl #3
   12090:	mov	x0, x23
   12094:	mov	x1, x21
   12098:	mov	x2, x22
   1209c:	mov	x20, x13
   120a0:	bl	ca70 <__gmpn_copyi@plt>
   120a4:	mov	w14, #0x2                   	// #2
   120a8:	mov	x13, x20
   120ac:	ldur	x20, [x29, #-32]
   120b0:	sub	x8, x14, x13
   120b4:	stur	x8, [x29, #-40]
   120b8:	cbz	x28, 120d4 <__gmpf_ui_div@@Base+0xec>
   120bc:	add	x8, x22, x20
   120c0:	lsl	x8, x8, #3
   120c4:	add	x0, x25, x22, lsl #3
   120c8:	sub	x2, x8, #0x8
   120cc:	mov	w1, wzr
   120d0:	bl	c610 <memset@plt>
   120d4:	ldur	x8, [x29, #-24]
   120d8:	mov	x0, x21
   120dc:	mov	x1, x25
   120e0:	mov	x2, xzr
   120e4:	mov	x3, x26
   120e8:	mov	x4, x24
   120ec:	mov	x5, x23
   120f0:	mov	x6, x22
   120f4:	str	x8, [x26, x28, lsl #3]
   120f8:	bl	bf10 <__gmpn_tdiv_qr@plt>
   120fc:	ldr	x8, [x21, x20, lsl #3]
   12100:	ldp	x9, x0, [x29, #-16]
   12104:	ldur	x10, [x29, #-40]
   12108:	cmp	x8, #0x0
   1210c:	cset	w8, eq  // eq = none
   12110:	sub	x9, x9, x8
   12114:	cmp	w27, #0x0
   12118:	sub	x8, x10, x8
   1211c:	neg	w10, w9
   12120:	csel	x9, x9, x10, ge  // ge = tcont
   12124:	str	w9, [x19, #4]
   12128:	str	x8, [x19, #8]
   1212c:	cbnz	x0, 12178 <__gmpf_ui_div@@Base+0x190>
   12130:	mov	sp, x29
   12134:	ldp	x20, x19, [sp, #80]
   12138:	ldp	x22, x21, [sp, #64]
   1213c:	ldp	x24, x23, [sp, #48]
   12140:	ldp	x26, x25, [sp, #32]
   12144:	ldp	x28, x27, [sp, #16]
   12148:	ldp	x29, x30, [sp], #96
   1214c:	ret
   12150:	str	wzr, [x19, #4]
   12154:	str	xzr, [x19, #8]
   12158:	b	12130 <__gmpf_ui_div@@Base+0x148>
   1215c:	sub	x0, x29, #0x8
   12160:	mov	x25, x13
   12164:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   12168:	mov	w14, #0x2                   	// #2
   1216c:	mov	x13, x25
   12170:	mov	x25, x0
   12174:	b	1207c <__gmpf_ui_div@@Base+0x94>
   12178:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1217c:	b	12130 <__gmpf_ui_div@@Base+0x148>
   12180:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000012184 <__gmpf_sqrt_ui@@Base>:
   12184:	stp	x29, x30, [sp, #-64]!
   12188:	stp	x24, x23, [sp, #16]
   1218c:	stp	x22, x21, [sp, #32]
   12190:	stp	x20, x19, [sp, #48]
   12194:	mov	x29, sp
   12198:	sub	sp, sp, #0x10
   1219c:	mov	x20, x1
   121a0:	cmp	x1, #0x1
   121a4:	mov	x19, x0
   121a8:	b.ls	12244 <__gmpf_sqrt_ui@@Base+0xc0>  // b.plast
   121ac:	stur	xzr, [x29, #-8]
   121b0:	ldr	w23, [x19]
   121b4:	mov	w9, #0x7f00                	// #32512
   121b8:	sbfiz	x8, x23, #1, #32
   121bc:	sub	x21, x8, #0x1
   121c0:	lsl	x1, x21, #3
   121c4:	cmp	x1, x9
   121c8:	sub	x24, x8, #0x2
   121cc:	b.hi	12258 <__gmpf_sqrt_ui@@Base+0xd4>  // b.pmore
   121d0:	add	x9, x1, #0xf
   121d4:	mov	x8, sp
   121d8:	and	x9, x9, #0xfffffffffffffff0
   121dc:	sub	x22, x8, x9
   121e0:	mov	sp, x22
   121e4:	cbz	x24, 12200 <__gmpf_sqrt_ui@@Base+0x7c>
   121e8:	sxtw	x8, w23
   121ec:	lsl	x8, x8, #4
   121f0:	sub	x2, x8, #0x10
   121f4:	mov	x0, x22
   121f8:	mov	w1, wzr
   121fc:	bl	c610 <memset@plt>
   12200:	str	x20, [x22, x24, lsl #3]
   12204:	ldr	x0, [x19, #16]
   12208:	mov	x1, xzr
   1220c:	mov	x2, x22
   12210:	mov	x3, x21
   12214:	bl	d3d0 <__gmpn_sqrtrem@plt>
   12218:	mov	w8, #0x1                   	// #1
   1221c:	str	w23, [x19, #4]
   12220:	str	x8, [x19, #8]
   12224:	ldur	x0, [x29, #-8]
   12228:	cbnz	x0, 1226c <__gmpf_sqrt_ui@@Base+0xe8>
   1222c:	mov	sp, x29
   12230:	ldp	x20, x19, [sp, #48]
   12234:	ldp	x22, x21, [sp, #32]
   12238:	ldp	x24, x23, [sp, #16]
   1223c:	ldp	x29, x30, [sp], #64
   12240:	ret
   12244:	ldr	x8, [x19, #16]
   12248:	str	x20, [x19, #8]
   1224c:	str	w20, [x19, #4]
   12250:	str	x20, [x8]
   12254:	b	1222c <__gmpf_sqrt_ui@@Base+0xa8>
   12258:	sub	x0, x29, #0x8
   1225c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   12260:	mov	x22, x0
   12264:	cbnz	x24, 121e8 <__gmpf_sqrt_ui@@Base+0x64>
   12268:	b	12200 <__gmpf_sqrt_ui@@Base+0x7c>
   1226c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   12270:	b	1222c <__gmpf_sqrt_ui@@Base+0xa8>

0000000000012274 <__gmpf_ceil@@Base>:
   12274:	mov	w2, #0x1                   	// #1
   12278:	b	1227c <__gmpf_ceil@@Base+0x8>
   1227c:	ldrsw	x10, [x1, #4]
   12280:	cbz	w10, 1232c <__gmpf_ceil@@Base+0xb8>
   12284:	ldr	x11, [x1, #8]
   12288:	ldr	x8, [x0, #16]
   1228c:	mov	w9, w2
   12290:	cmp	x11, #0x0
   12294:	b.le	12310 <__gmpf_ceil@@Base+0x9c>
   12298:	ldrsw	x14, [x0]
   1229c:	str	x11, [x0, #8]
   122a0:	cmp	w10, #0x0
   122a4:	ldr	x12, [x1, #16]
   122a8:	cneg	x13, x10, lt  // lt = tstop
   122ac:	cmp	x13, x11
   122b0:	csel	x15, x13, x11, lt  // lt = tstop
   122b4:	add	x16, x14, #0x1
   122b8:	cmp	x15, x16
   122bc:	add	x11, x12, x13, lsl #3
   122c0:	csinc	x2, x15, x14, lt  // lt = tstop
   122c4:	eor	w9, w10, w9
   122c8:	sub	x1, x11, x2, lsl #3
   122cc:	tbnz	w9, #31, 122f0 <__gmpf_ceil@@Base+0x7c>
   122d0:	cmp	x12, x1
   122d4:	b.eq	122f0 <__gmpf_ceil@@Base+0x7c>  // b.none
   122d8:	lsl	x9, x13, #3
   122dc:	sub	x9, x9, x2, lsl #3
   122e0:	ldr	x13, [x12], #8
   122e4:	cbnz	x13, 12338 <__gmpf_ceil@@Base+0xc4>
   122e8:	subs	x9, x9, #0x8
   122ec:	b.ne	122e0 <__gmpf_ceil@@Base+0x6c>  // b.any
   122f0:	neg	x9, x2
   122f4:	cmp	w10, #0x0
   122f8:	csel	x9, x2, x9, ge  // ge = tcont
   122fc:	cmp	x8, x1
   12300:	str	w9, [x0, #4]
   12304:	b.eq	12334 <__gmpf_ceil@@Base+0xc0>  // b.none
   12308:	mov	x0, x8
   1230c:	b	ca70 <__gmpn_copyi@plt>
   12310:	eor	w10, w10, w9
   12314:	tbnz	w10, #31, 1232c <__gmpf_ceil@@Base+0xb8>
   12318:	mov	w10, #0x1                   	// #1
   1231c:	str	x10, [x8]
   12320:	str	x10, [x0, #8]
   12324:	str	w9, [x0, #4]
   12328:	ret
   1232c:	str	wzr, [x0, #4]
   12330:	str	xzr, [x0, #8]
   12334:	ret
   12338:	ldr	x9, [x1]
   1233c:	adds	x9, x9, #0x1
   12340:	str	x9, [x8]
   12344:	b.cc	123a0 <__gmpf_ceil@@Base+0x12c>  // b.lo, b.ul, b.last
   12348:	mov	w12, #0x2                   	// #2
   1234c:	add	x9, x8, #0x8
   12350:	sub	x12, x12, x2
   12354:	mov	w13, #0x1                   	// #1
   12358:	cmp	x13, x2
   1235c:	b.ge	123d0 <__gmpf_ceil@@Base+0x15c>  // b.tcont
   12360:	ldr	x14, [x1, x13, lsl #3]
   12364:	add	x13, x13, #0x1
   12368:	adds	x14, x14, #0x1
   1236c:	str	x14, [x9], #8
   12370:	b.cs	12358 <__gmpf_ceil@@Base+0xe4>  // b.hs, b.nlast
   12374:	cmp	x1, x8
   12378:	b.eq	123e4 <__gmpf_ceil@@Base+0x170>  // b.none
   1237c:	cmp	x13, x2
   12380:	b.ge	123e4 <__gmpf_ceil@@Base+0x170>  // b.tcont
   12384:	add	x8, x12, x13
   12388:	sub	x8, x8, #0x2
   1238c:	ldr	x12, [x11, x8, lsl #3]
   12390:	adds	x8, x8, #0x1
   12394:	str	x12, [x9], #8
   12398:	b.cc	1238c <__gmpf_ceil@@Base+0x118>  // b.lo, b.ul, b.last
   1239c:	b	123e4 <__gmpf_ceil@@Base+0x170>
   123a0:	cmp	x2, #0x2
   123a4:	b.lt	123e4 <__gmpf_ceil@@Base+0x170>  // b.tstop
   123a8:	cmp	x1, x8
   123ac:	b.eq	123e4 <__gmpf_ceil@@Base+0x170>  // b.none
   123b0:	mov	w9, #0x1                   	// #1
   123b4:	sub	x9, x9, x2
   123b8:	add	x8, x8, #0x8
   123bc:	ldr	x12, [x11, x9, lsl #3]
   123c0:	adds	x9, x9, #0x1
   123c4:	str	x12, [x8], #8
   123c8:	b.cc	123bc <__gmpf_ceil@@Base+0x148>  // b.lo, b.ul, b.last
   123cc:	b	123e4 <__gmpf_ceil@@Base+0x170>
   123d0:	mov	w2, #0x1                   	// #1
   123d4:	str	x2, [x8]
   123d8:	ldr	x8, [x0, #8]
   123dc:	add	x8, x8, #0x1
   123e0:	str	x8, [x0, #8]
   123e4:	neg	w8, w2
   123e8:	cmp	w10, #0x0
   123ec:	csel	x8, x2, x8, ge  // ge = tcont
   123f0:	str	w8, [x0, #4]
   123f4:	ret

00000000000123f8 <__gmpf_floor@@Base>:
   123f8:	mov	w2, #0xffffffff            	// #-1
   123fc:	b	1227c <__gmpf_ceil@@Base+0x8>

0000000000012400 <__gmpf_trunc@@Base>:
   12400:	ldr	x9, [x1, #8]
   12404:	cmp	x9, #0x1
   12408:	b.lt	1246c <__gmpf_trunc@@Base+0x6c>  // b.tstop
   1240c:	ldr	w8, [x1, #4]
   12410:	cbz	w8, 1246c <__gmpf_trunc@@Base+0x6c>
   12414:	sxtw	x10, w8
   12418:	ldrsw	x11, [x0]
   1241c:	cmp	w10, #0x0
   12420:	ldr	x12, [x1, #16]
   12424:	cneg	x13, x10, lt  // lt = tstop
   12428:	cmp	x13, x9
   1242c:	str	x9, [x0, #8]
   12430:	ldr	x8, [x0, #16]
   12434:	csel	x9, x13, x9, lt  // lt = tstop
   12438:	add	x14, x11, #0x1
   1243c:	cmp	x9, x14
   12440:	add	x12, x12, x13, lsl #3
   12444:	csinc	x2, x9, x11, lt  // lt = tstop
   12448:	cmp	w10, #0x0
   1244c:	neg	w9, w2
   12450:	sub	x1, x12, x2, lsl #3
   12454:	csel	x9, x2, x9, ge  // ge = tcont
   12458:	cmp	x8, x1
   1245c:	str	w9, [x0, #4]
   12460:	b.eq	12474 <__gmpf_trunc@@Base+0x74>  // b.none
   12464:	mov	x0, x8
   12468:	b	ca70 <__gmpn_copyi@plt>
   1246c:	str	wzr, [x0, #4]
   12470:	str	xzr, [x0, #8]
   12474:	ret

0000000000012478 <__gmpf_pow_ui@@Base>:
   12478:	sub	sp, sp, #0x60
   1247c:	stp	x22, x21, [sp, #64]
   12480:	stp	x20, x19, [sp, #80]
   12484:	mov	x21, x2
   12488:	mov	x20, x1
   1248c:	cmp	x2, #0x1
   12490:	mov	x19, x0
   12494:	stp	x29, x30, [sp, #32]
   12498:	str	x23, [sp, #48]
   1249c:	add	x29, sp, #0x20
   124a0:	b.hi	124b8 <__gmpf_pow_ui@@Base+0x40>  // b.pmore
   124a4:	cbz	x21, 12570 <__gmpf_pow_ui@@Base+0xf8>
   124a8:	mov	x0, x19
   124ac:	mov	x1, x20
   124b0:	bl	c160 <__gmpf_set@plt>
   124b4:	b	1257c <__gmpf_pow_ui@@Base+0x104>
   124b8:	mov	x0, x19
   124bc:	clz	x23, x21
   124c0:	bl	c370 <__gmpf_get_prec@plt>
   124c4:	sub	x8, x0, x23
   124c8:	add	x1, x8, #0x3f
   124cc:	add	x0, sp, #0x8
   124d0:	bl	ced0 <__gmpf_init2@plt>
   124d4:	add	x0, sp, #0x8
   124d8:	mov	x1, x20
   124dc:	bl	c160 <__gmpf_set@plt>
   124e0:	cmp	w23, #0x3d
   124e4:	b.hi	12530 <__gmpf_pow_ui@@Base+0xb8>  // b.pmore
   124e8:	mov	w8, #0x3e                  	// #62
   124ec:	mov	w9, #0x3f                  	// #63
   124f0:	sub	w22, w8, w23
   124f4:	sub	w23, w9, w23
   124f8:	add	x0, sp, #0x8
   124fc:	add	x1, sp, #0x8
   12500:	add	x2, sp, #0x8
   12504:	bl	cd50 <__gmpf_mul@plt>
   12508:	lsr	x8, x21, x22
   1250c:	tbz	w8, #0, 12520 <__gmpf_pow_ui@@Base+0xa8>
   12510:	add	x0, sp, #0x8
   12514:	add	x1, sp, #0x8
   12518:	mov	x2, x20
   1251c:	bl	cd50 <__gmpf_mul@plt>
   12520:	sub	w23, w23, #0x1
   12524:	cmp	w23, #0x1
   12528:	sub	x22, x22, #0x1
   1252c:	b.gt	124f8 <__gmpf_pow_ui@@Base+0x80>
   12530:	tbnz	w21, #0, 12544 <__gmpf_pow_ui@@Base+0xcc>
   12534:	add	x1, sp, #0x8
   12538:	add	x2, sp, #0x8
   1253c:	mov	x0, x19
   12540:	b	12560 <__gmpf_pow_ui@@Base+0xe8>
   12544:	add	x0, sp, #0x8
   12548:	add	x1, sp, #0x8
   1254c:	add	x2, sp, #0x8
   12550:	bl	cd50 <__gmpf_mul@plt>
   12554:	add	x1, sp, #0x8
   12558:	mov	x0, x19
   1255c:	mov	x2, x20
   12560:	bl	cd50 <__gmpf_mul@plt>
   12564:	add	x0, sp, #0x8
   12568:	bl	c350 <__gmpf_clear@plt>
   1256c:	b	1257c <__gmpf_pow_ui@@Base+0x104>
   12570:	mov	w1, #0x1                   	// #1
   12574:	mov	x0, x19
   12578:	bl	c6c0 <__gmpf_set_ui@plt>
   1257c:	ldp	x20, x19, [sp, #80]
   12580:	ldp	x22, x21, [sp, #64]
   12584:	ldr	x23, [sp, #48]
   12588:	ldp	x29, x30, [sp, #32]
   1258c:	add	sp, sp, #0x60
   12590:	ret

0000000000012594 <__gmpf_urandomb@@Base>:
   12594:	stp	x29, x30, [sp, #-48]!
   12598:	stp	x22, x21, [sp, #16]
   1259c:	stp	x20, x19, [sp, #32]
   125a0:	ldrsw	x8, [x0]
   125a4:	add	x9, x2, #0x3f
   125a8:	ldr	x10, [x1, #24]
   125ac:	lsr	x9, x9, #6
   125b0:	add	x11, x8, #0x1
   125b4:	cmp	x9, x11
   125b8:	cset	w12, gt
   125bc:	cmp	x9, #0x0
   125c0:	cset	w13, eq  // eq = none
   125c4:	ldr	x21, [x0, #16]
   125c8:	orr	w12, w13, w12
   125cc:	ldr	x10, [x10, #8]
   125d0:	lsl	x11, x11, #6
   125d4:	cmp	w12, #0x0
   125d8:	csel	x22, x11, x2, ne  // ne = any
   125dc:	mov	x19, x0
   125e0:	mov	x0, x1
   125e4:	mov	x1, x21
   125e8:	mov	x2, x22
   125ec:	mov	x29, sp
   125f0:	csinc	x20, x9, x8, eq  // eq = none
   125f4:	blr	x10
   125f8:	ands	x8, x22, #0x3f
   125fc:	b.eq	12618 <__gmpf_urandomb@@Base+0x84>  // b.none
   12600:	mov	w9, #0x40                  	// #64
   12604:	sub	w3, w9, w8
   12608:	mov	x0, x21
   1260c:	mov	x1, x21
   12610:	mov	x2, x20
   12614:	bl	c190 <__gmpn_lshift@plt>
   12618:	cbz	x20, 12644 <__gmpf_urandomb@@Base+0xb0>
   1261c:	add	x10, x21, x20, lsl #3
   12620:	mov	x9, xzr
   12624:	neg	x8, x20
   12628:	sub	x10, x10, #0x8
   1262c:	ldr	x11, [x10, x9, lsl #3]
   12630:	cbnz	x11, 12650 <__gmpf_urandomb@@Base+0xbc>
   12634:	sub	x9, x9, #0x1
   12638:	cmn	x20, x9
   1263c:	b.ne	1262c <__gmpf_urandomb@@Base+0x98>  // b.any
   12640:	b	12648 <__gmpf_urandomb@@Base+0xb4>
   12644:	mov	x8, xzr
   12648:	mov	x10, xzr
   1264c:	b	12658 <__gmpf_urandomb@@Base+0xc4>
   12650:	add	x10, x20, x9
   12654:	mov	x8, x9
   12658:	str	x8, [x19, #8]
   1265c:	str	w10, [x19, #4]
   12660:	ldp	x20, x19, [sp, #32]
   12664:	ldp	x22, x21, [sp, #16]
   12668:	ldp	x29, x30, [sp], #48
   1266c:	ret

0000000000012670 <__gmpf_swap@@Base>:
   12670:	ldr	x8, [x1]
   12674:	ldr	x9, [x0]
   12678:	str	x8, [x0]
   1267c:	str	x9, [x1]
   12680:	ldur	q0, [x1, #8]
   12684:	ldur	q1, [x0, #8]
   12688:	stur	q0, [x0, #8]
   1268c:	stur	q1, [x1, #8]
   12690:	ret

0000000000012694 <__gmpf_fits_sint_p@@Base>:
   12694:	ldr	x8, [x0, #8]
   12698:	cmp	x8, #0x1
   1269c:	b.lt	126d4 <__gmpf_fits_sint_p@@Base+0x40>  // b.tstop
   126a0:	cmp	x8, #0x1
   126a4:	b.ne	126dc <__gmpf_fits_sint_p@@Base+0x48>  // b.any
   126a8:	ldrsw	x8, [x0, #4]
   126ac:	ldr	x9, [x0, #16]
   126b0:	cmp	w8, #0x0
   126b4:	cneg	x8, x8, lt  // lt = tstop
   126b8:	add	x8, x9, x8, lsl #3
   126bc:	ldur	x8, [x8, #-8]
   126c0:	mov	w9, #0x7fffffff            	// #2147483647
   126c4:	cinc	x9, x9, lt  // lt = tstop
   126c8:	cmp	x8, x9
   126cc:	cset	w0, ls  // ls = plast
   126d0:	ret
   126d4:	mov	w0, #0x1                   	// #1
   126d8:	ret
   126dc:	mov	w0, wzr
   126e0:	ret

00000000000126e4 <__gmpf_fits_slong_p@@Base>:
   126e4:	ldr	x8, [x0, #8]
   126e8:	cmp	x8, #0x1
   126ec:	b.lt	12724 <__gmpf_fits_slong_p@@Base+0x40>  // b.tstop
   126f0:	cmp	x8, #0x1
   126f4:	b.ne	1272c <__gmpf_fits_slong_p@@Base+0x48>  // b.any
   126f8:	ldrsw	x8, [x0, #4]
   126fc:	ldr	x9, [x0, #16]
   12700:	cmp	w8, #0x0
   12704:	cneg	x8, x8, lt  // lt = tstop
   12708:	add	x8, x9, x8, lsl #3
   1270c:	ldur	x8, [x8, #-8]
   12710:	mov	x9, #0x7fffffffffffffff    	// #9223372036854775807
   12714:	cinv	x9, x9, lt  // lt = tstop
   12718:	cmp	x8, x9
   1271c:	cset	w0, ls  // ls = plast
   12720:	ret
   12724:	mov	w0, #0x1                   	// #1
   12728:	ret
   1272c:	mov	w0, wzr
   12730:	ret

0000000000012734 <__gmpf_fits_sshort_p@@Base>:
   12734:	ldr	x8, [x0, #8]
   12738:	cmp	x8, #0x1
   1273c:	b.lt	12774 <__gmpf_fits_sshort_p@@Base+0x40>  // b.tstop
   12740:	cmp	x8, #0x1
   12744:	b.ne	1277c <__gmpf_fits_sshort_p@@Base+0x48>  // b.any
   12748:	ldrsw	x8, [x0, #4]
   1274c:	ldr	x9, [x0, #16]
   12750:	cmp	w8, #0x0
   12754:	cneg	x8, x8, lt  // lt = tstop
   12758:	add	x8, x9, x8, lsl #3
   1275c:	ldur	x8, [x8, #-8]
   12760:	mov	w9, #0x7fff                	// #32767
   12764:	cinc	x9, x9, lt  // lt = tstop
   12768:	cmp	x8, x9
   1276c:	cset	w0, ls  // ls = plast
   12770:	ret
   12774:	mov	w0, #0x1                   	// #1
   12778:	ret
   1277c:	mov	w0, wzr
   12780:	ret

0000000000012784 <__gmpf_fits_uint_p@@Base>:
   12784:	ldr	x9, [x0, #8]
   12788:	cmp	x9, #0x1
   1278c:	b.lt	127c0 <__gmpf_fits_uint_p@@Base+0x3c>  // b.tstop
   12790:	mov	x8, x0
   12794:	cmp	x9, #0x1
   12798:	mov	w0, wzr
   1279c:	b.ne	127bc <__gmpf_fits_uint_p@@Base+0x38>  // b.any
   127a0:	ldr	w9, [x8, #4]
   127a4:	tbnz	w9, #31, 127bc <__gmpf_fits_uint_p@@Base+0x38>
   127a8:	ldr	x8, [x8, #16]
   127ac:	add	x8, x8, x9, lsl #3
   127b0:	ldur	w8, [x8, #-4]
   127b4:	cmp	w8, #0x0
   127b8:	cset	w0, eq  // eq = none
   127bc:	ret
   127c0:	mov	w0, #0x1                   	// #1
   127c4:	ret

00000000000127c8 <__gmpf_fits_ulong_p@@Base>:
   127c8:	ldr	x8, [x0, #8]
   127cc:	cmp	x8, #0x1
   127d0:	b.lt	127e8 <__gmpf_fits_ulong_p@@Base+0x20>  // b.tstop
   127d4:	ldr	w9, [x0, #4]
   127d8:	tbnz	w9, #31, 127f0 <__gmpf_fits_ulong_p@@Base+0x28>
   127dc:	cmp	x8, #0x1
   127e0:	cset	w0, eq  // eq = none
   127e4:	ret
   127e8:	mov	w0, #0x1                   	// #1
   127ec:	ret
   127f0:	mov	w0, wzr
   127f4:	ret

00000000000127f8 <__gmpf_fits_ushort_p@@Base>:
   127f8:	ldr	x9, [x0, #8]
   127fc:	cmp	x9, #0x1
   12800:	b.lt	12834 <__gmpf_fits_ushort_p@@Base+0x3c>  // b.tstop
   12804:	mov	x8, x0
   12808:	cmp	x9, #0x1
   1280c:	mov	w0, wzr
   12810:	b.ne	12830 <__gmpf_fits_ushort_p@@Base+0x38>  // b.any
   12814:	ldr	w9, [x8, #4]
   12818:	tbnz	w9, #31, 12830 <__gmpf_fits_ushort_p@@Base+0x38>
   1281c:	ldr	x8, [x8, #16]
   12820:	add	x8, x8, x9, lsl #3
   12824:	ldur	x8, [x8, #-8]
   12828:	cmp	x8, #0x10, lsl #12
   1282c:	cset	w0, cc  // cc = lo, ul, last
   12830:	ret
   12834:	mov	w0, #0x1                   	// #1
   12838:	ret

000000000001283c <__gmpf_get_si@@Base>:
   1283c:	ldr	x9, [x0, #8]
   12840:	cmp	x9, #0x1
   12844:	b.lt	12864 <__gmpf_get_si@@Base+0x28>  // b.tstop
   12848:	ldrsw	x8, [x0, #4]
   1284c:	cmp	x8, #0x0
   12850:	cneg	x10, x8, mi  // mi = first
   12854:	subs	x9, x10, x9
   12858:	b.ge	1286c <__gmpf_get_si@@Base+0x30>  // b.tcont
   1285c:	mov	x9, xzr
   12860:	b	12874 <__gmpf_get_si@@Base+0x38>
   12864:	mov	x0, xzr
   12868:	ret
   1286c:	ldr	x10, [x0, #16]
   12870:	ldr	x9, [x10, x9, lsl #3]
   12874:	cmp	w8, #0x1
   12878:	b.lt	12884 <__gmpf_get_si@@Base+0x48>  // b.tstop
   1287c:	and	x0, x9, #0x7fffffffffffffff
   12880:	ret
   12884:	sub	x8, x9, #0x1
   12888:	orr	x8, x8, #0x8000000000000000
   1288c:	eor	x0, x8, #0x7fffffffffffffff
   12890:	ret

0000000000012894 <__gmpf_get_ui@@Base>:
   12894:	ldr	x8, [x0, #8]
   12898:	cmp	x8, #0x1
   1289c:	b.lt	128b4 <__gmpf_get_ui@@Base+0x20>  // b.tstop
   128a0:	ldrsw	x9, [x0, #4]
   128a4:	cmp	x9, #0x0
   128a8:	cneg	x9, x9, mi  // mi = first
   128ac:	subs	x8, x9, x8
   128b0:	b.ge	128bc <__gmpf_get_ui@@Base+0x28>  // b.tcont
   128b4:	mov	x0, xzr
   128b8:	ret
   128bc:	ldr	x9, [x0, #16]
   128c0:	ldr	x0, [x9, x8, lsl #3]
   128c4:	ret

00000000000128c8 <__gmpf_integer_p@@Base>:
   128c8:	ldr	x8, [x0, #8]
   128cc:	ldrsw	x9, [x0, #4]
   128d0:	cmp	x8, #0x0
   128d4:	b.le	12908 <__gmpf_integer_p@@Base+0x40>
   128d8:	ldr	x10, [x0, #16]
   128dc:	cmp	x9, #0x0
   128e0:	cneg	x9, x9, mi  // mi = first
   128e4:	ldr	x11, [x10]
   128e8:	cbnz	x11, 128fc <__gmpf_integer_p@@Base+0x34>
   128ec:	add	x10, x10, #0x8
   128f0:	ldr	x11, [x10], #8
   128f4:	sub	x9, x9, #0x1
   128f8:	cbz	x11, 128f0 <__gmpf_integer_p@@Base+0x28>
   128fc:	cmp	x9, x8
   12900:	cset	w0, le
   12904:	ret
   12908:	cmp	w9, #0x0
   1290c:	cset	w0, eq  // eq = none
   12910:	ret

0000000000012914 <__gmpz_abs@@Base>:
   12914:	stp	x29, x30, [sp, #-48]!
   12918:	stp	x20, x19, [sp, #32]
   1291c:	ldr	w8, [x1, #4]
   12920:	mov	x19, x0
   12924:	str	x21, [sp, #16]
   12928:	mov	x29, sp
   1292c:	cmp	w8, #0x0
   12930:	cneg	w20, w8, mi  // mi = first
   12934:	cmp	x1, x0
   12938:	b.eq	1295c <__gmpz_abs@@Base+0x48>  // b.none
   1293c:	ldrsw	x8, [x19]
   12940:	mov	x21, x1
   12944:	cmp	x20, x8
   12948:	b.gt	12970 <__gmpz_abs@@Base+0x5c>
   1294c:	ldr	x0, [x19, #8]
   12950:	ldr	x1, [x21, #8]
   12954:	mov	x2, x20
   12958:	bl	ca70 <__gmpn_copyi@plt>
   1295c:	str	w20, [x19, #4]
   12960:	ldp	x20, x19, [sp, #32]
   12964:	ldr	x21, [sp, #16]
   12968:	ldp	x29, x30, [sp], #48
   1296c:	ret
   12970:	mov	x0, x19
   12974:	mov	x1, x20
   12978:	bl	c090 <__gmpz_realloc@plt>
   1297c:	b	12950 <__gmpz_abs@@Base+0x3c>

0000000000012980 <__gmpz_add@@Base>:
   12980:	stp	x29, x30, [sp, #-80]!
   12984:	stp	x26, x25, [sp, #16]
   12988:	stp	x24, x23, [sp, #32]
   1298c:	stp	x22, x21, [sp, #48]
   12990:	stp	x20, x19, [sp, #64]
   12994:	ldrsw	x8, [x1, #4]
   12998:	ldrsw	x9, [x2, #4]
   1299c:	ldrsw	x10, [x0]
   129a0:	mov	x19, x0
   129a4:	cmp	x8, #0x0
   129a8:	cneg	x11, x8, mi  // mi = first
   129ac:	cmp	x9, #0x0
   129b0:	cneg	x12, x9, mi  // mi = first
   129b4:	cmp	x11, x12
   129b8:	csel	x20, x12, x11, lt  // lt = tstop
   129bc:	csel	x23, x11, x12, lt  // lt = tstop
   129c0:	csel	x25, x8, x9, lt  // lt = tstop
   129c4:	csel	x24, x9, x8, lt  // lt = tstop
   129c8:	csel	x26, x1, x2, lt  // lt = tstop
   129cc:	csel	x22, x2, x1, lt  // lt = tstop
   129d0:	cmp	x20, x10
   129d4:	mov	x29, sp
   129d8:	b.ge	12bc4 <__gmpz_add@@Base+0x244>  // b.tcont
   129dc:	ldr	x21, [x19, #8]
   129e0:	ldr	x22, [x22, #8]
   129e4:	ldr	x2, [x26, #8]
   129e8:	eor	x8, x24, x25
   129ec:	tbnz	x8, #63, 12a30 <__gmpz_add@@Base+0xb0>
   129f0:	cbz	x23, 12a8c <__gmpz_add@@Base+0x10c>
   129f4:	mov	x0, x21
   129f8:	mov	x1, x22
   129fc:	mov	x3, x23
   12a00:	bl	ca90 <__gmpn_add_n@plt>
   12a04:	cbz	x0, 12ad0 <__gmpz_add@@Base+0x150>
   12a08:	mov	w8, #0x1                   	// #1
   12a0c:	cmp	x23, x20
   12a10:	b.ge	12b04 <__gmpz_add@@Base+0x184>  // b.tcont
   12a14:	ldr	x9, [x22, x23, lsl #3]
   12a18:	adds	x10, x9, #0x1
   12a1c:	add	x9, x23, #0x1
   12a20:	str	x10, [x21, x23, lsl #3]
   12a24:	mov	x23, x9
   12a28:	b.cs	12a0c <__gmpz_add@@Base+0x8c>  // b.hs, b.nlast
   12a2c:	b	12ad4 <__gmpz_add@@Base+0x154>
   12a30:	cmp	x20, x23
   12a34:	b.ne	12a94 <__gmpz_add@@Base+0x114>  // b.any
   12a38:	sub	x8, x20, #0x1
   12a3c:	add	x9, x8, #0x1
   12a40:	cmp	x9, #0x1
   12a44:	b.lt	12a60 <__gmpz_add@@Base+0xe0>  // b.tstop
   12a48:	ldr	x9, [x22, x8, lsl #3]
   12a4c:	ldr	x10, [x2, x8, lsl #3]
   12a50:	sub	x8, x8, #0x1
   12a54:	cmp	x9, x10
   12a58:	b.eq	12a3c <__gmpz_add@@Base+0xbc>  // b.none
   12a5c:	b.ls	12b20 <__gmpz_add@@Base+0x1a0>  // b.plast
   12a60:	mov	x0, x21
   12a64:	mov	x1, x22
   12a68:	mov	x3, x20
   12a6c:	bl	c2e0 <__gmpn_sub_n@plt>
   12a70:	sub	x8, x21, #0x8
   12a74:	mov	x9, x20
   12a78:	subs	x20, x20, #0x1
   12a7c:	b.lt	12ba0 <__gmpz_add@@Base+0x220>  // b.tstop
   12a80:	ldr	x10, [x8, x9, lsl #3]
   12a84:	cbz	x10, 12a74 <__gmpz_add@@Base+0xf4>
   12a88:	b	12ba0 <__gmpz_add@@Base+0x220>
   12a8c:	mov	x9, xzr
   12a90:	b	12ad4 <__gmpz_add@@Base+0x154>
   12a94:	cbz	x23, 12b18 <__gmpz_add@@Base+0x198>
   12a98:	mov	x0, x21
   12a9c:	mov	x1, x22
   12aa0:	mov	x3, x23
   12aa4:	bl	c2e0 <__gmpn_sub_n@plt>
   12aa8:	cbz	x0, 12b58 <__gmpz_add@@Base+0x1d8>
   12aac:	cmp	x23, x20
   12ab0:	b.ge	12b88 <__gmpz_add@@Base+0x208>  // b.tcont
   12ab4:	ldr	x8, [x22, x23, lsl #3]
   12ab8:	add	x9, x23, #0x1
   12abc:	sub	x10, x8, #0x1
   12ac0:	str	x10, [x21, x23, lsl #3]
   12ac4:	mov	x23, x9
   12ac8:	cbz	x8, 12aac <__gmpz_add@@Base+0x12c>
   12acc:	b	12b5c <__gmpz_add@@Base+0x1dc>
   12ad0:	mov	x9, x23
   12ad4:	cmp	x21, x22
   12ad8:	mov	x8, xzr
   12adc:	b.eq	12b04 <__gmpz_add@@Base+0x184>  // b.none
   12ae0:	cmp	x9, x20
   12ae4:	b.ge	12b04 <__gmpz_add@@Base+0x184>  // b.tcont
   12ae8:	sub	x8, x20, x9
   12aec:	add	x10, x21, x9, lsl #3
   12af0:	add	x9, x22, x9, lsl #3
   12af4:	ldr	x11, [x9], #8
   12af8:	subs	x8, x8, #0x1
   12afc:	str	x11, [x10], #8
   12b00:	b.ne	12af4 <__gmpz_add@@Base+0x174>  // b.any
   12b04:	str	x8, [x21, x20, lsl #3]
   12b08:	add	x8, x8, x20
   12b0c:	cmp	x24, #0x0
   12b10:	cneg	x8, x8, lt  // lt = tstop
   12b14:	b	12ba8 <__gmpz_add@@Base+0x228>
   12b18:	mov	x9, xzr
   12b1c:	b	12b5c <__gmpz_add@@Base+0x1dc>
   12b20:	mov	x0, x21
   12b24:	mov	x1, x2
   12b28:	mov	x2, x22
   12b2c:	mov	x3, x20
   12b30:	bl	c2e0 <__gmpn_sub_n@plt>
   12b34:	sub	x8, x21, #0x8
   12b38:	mov	x9, x20
   12b3c:	subs	x20, x20, #0x1
   12b40:	b.lt	12b4c <__gmpz_add@@Base+0x1cc>  // b.tstop
   12b44:	ldr	x10, [x8, x9, lsl #3]
   12b48:	cbz	x10, 12b38 <__gmpz_add@@Base+0x1b8>
   12b4c:	cmp	x24, #0x0
   12b50:	cneg	x8, x9, ge  // ge = tcont
   12b54:	b	12ba8 <__gmpz_add@@Base+0x228>
   12b58:	mov	x9, x23
   12b5c:	cmp	x21, x22
   12b60:	b.eq	12b88 <__gmpz_add@@Base+0x208>  // b.none
   12b64:	cmp	x9, x20
   12b68:	b.ge	12b88 <__gmpz_add@@Base+0x208>  // b.tcont
   12b6c:	sub	x8, x20, x9
   12b70:	add	x10, x21, x9, lsl #3
   12b74:	add	x9, x22, x9, lsl #3
   12b78:	ldr	x11, [x9], #8
   12b7c:	subs	x8, x8, #0x1
   12b80:	str	x11, [x10], #8
   12b84:	b.ne	12b78 <__gmpz_add@@Base+0x1f8>  // b.any
   12b88:	sub	x8, x21, #0x8
   12b8c:	mov	x9, x20
   12b90:	subs	x20, x20, #0x1
   12b94:	b.lt	12ba0 <__gmpz_add@@Base+0x220>  // b.tstop
   12b98:	ldr	x10, [x8, x9, lsl #3]
   12b9c:	cbz	x10, 12b8c <__gmpz_add@@Base+0x20c>
   12ba0:	cmp	x24, #0x0
   12ba4:	cneg	x8, x9, lt  // lt = tstop
   12ba8:	str	w8, [x19, #4]
   12bac:	ldp	x20, x19, [sp, #64]
   12bb0:	ldp	x22, x21, [sp, #48]
   12bb4:	ldp	x24, x23, [sp, #32]
   12bb8:	ldp	x26, x25, [sp, #16]
   12bbc:	ldp	x29, x30, [sp], #80
   12bc0:	ret
   12bc4:	add	x1, x20, #0x1
   12bc8:	mov	x0, x19
   12bcc:	bl	c090 <__gmpz_realloc@plt>
   12bd0:	mov	x21, x0
   12bd4:	b	129e0 <__gmpz_add@@Base+0x60>

0000000000012bd8 <__gmpz_add_ui@@Base>:
   12bd8:	stp	x29, x30, [sp, #-64]!
   12bdc:	stp	x22, x21, [sp, #32]
   12be0:	stp	x20, x19, [sp, #48]
   12be4:	str	x23, [sp, #16]
   12be8:	ldrsw	x23, [x1, #4]
   12bec:	mov	x20, x2
   12bf0:	mov	x19, x0
   12bf4:	mov	x29, sp
   12bf8:	cbz	w23, 12c94 <__gmpz_add_ui@@Base+0xbc>
   12bfc:	ldrsw	x8, [x19]
   12c00:	cmp	w23, #0x0
   12c04:	cneg	x22, x23, lt  // lt = tstop
   12c08:	mov	x21, x1
   12c0c:	cmp	x22, x8
   12c10:	b.ge	12dd4 <__gmpz_add_ui@@Base+0x1fc>  // b.tcont
   12c14:	ldr	x0, [x19, #8]
   12c18:	ldr	x8, [x21, #8]
   12c1c:	tbnz	w23, #31, 12cb4 <__gmpz_add_ui@@Base+0xdc>
   12c20:	ldr	x9, [x8]
   12c24:	adds	x9, x9, x20
   12c28:	str	x9, [x0]
   12c2c:	b.cc	12cd8 <__gmpz_add_ui@@Base+0x100>  // b.lo, b.ul, b.last
   12c30:	mov	x11, #0xfffffffffffffff8    	// #-8
   12c34:	mov	w10, #0x1                   	// #1
   12c38:	mov	w9, #0x1                   	// #1
   12c3c:	cmp	x9, x22
   12c40:	b.ge	12d0c <__gmpz_add_ui@@Base+0x134>  // b.tcont
   12c44:	ldr	x12, [x8, x9, lsl #3]
   12c48:	sub	x11, x11, #0x8
   12c4c:	adds	x12, x12, #0x1
   12c50:	str	x12, [x0, x9, lsl #3]
   12c54:	add	x9, x9, #0x1
   12c58:	b.cs	12c3c <__gmpz_add_ui@@Base+0x64>  // b.hs, b.nlast
   12c5c:	cmp	x8, x0
   12c60:	mov	x10, xzr
   12c64:	b.eq	12d0c <__gmpz_add_ui@@Base+0x134>  // b.none
   12c68:	cmp	x9, x22
   12c6c:	b.ge	12d0c <__gmpz_add_ui@@Base+0x134>  // b.tcont
   12c70:	sub	x8, x8, x11
   12c74:	sub	x10, x0, x11
   12c78:	mov	x11, x22
   12c7c:	ldr	x12, [x8], #8
   12c80:	sub	x11, x11, #0x1
   12c84:	cmp	x9, x11
   12c88:	str	x12, [x10], #8
   12c8c:	b.ne	12c7c <__gmpz_add_ui@@Base+0xa4>  // b.any
   12c90:	b	12d08 <__gmpz_add_ui@@Base+0x130>
   12c94:	ldr	w8, [x19]
   12c98:	cmp	w8, #0x0
   12c9c:	b.le	12de4 <__gmpz_add_ui@@Base+0x20c>
   12ca0:	ldr	x0, [x19, #8]
   12ca4:	cmp	x20, #0x0
   12ca8:	str	x20, [x0]
   12cac:	cset	w8, ne  // ne = any
   12cb0:	b	12dbc <__gmpz_add_ui@@Base+0x1e4>
   12cb4:	ldr	x10, [x8]
   12cb8:	subs	x9, x22, #0x1
   12cbc:	b.ne	12d18 <__gmpz_add_ui@@Base+0x140>  // b.any
   12cc0:	cmp	x10, x20
   12cc4:	b.cs	12d18 <__gmpz_add_ui@@Base+0x140>  // b.hs, b.nlast
   12cc8:	sub	x8, x20, x10
   12ccc:	str	x8, [x0]
   12cd0:	mov	w8, #0x1                   	// #1
   12cd4:	b	12dbc <__gmpz_add_ui@@Base+0x1e4>
   12cd8:	cmp	x22, #0x2
   12cdc:	mov	x10, xzr
   12ce0:	b.lt	12d0c <__gmpz_add_ui@@Base+0x134>  // b.tstop
   12ce4:	cmp	x8, x0
   12ce8:	b.eq	12d0c <__gmpz_add_ui@@Base+0x134>  // b.none
   12cec:	sub	x9, x22, #0x1
   12cf0:	add	x10, x0, #0x8
   12cf4:	add	x8, x8, #0x8
   12cf8:	ldr	x11, [x8], #8
   12cfc:	subs	x9, x9, #0x1
   12d00:	str	x11, [x10], #8
   12d04:	b.ne	12cf8 <__gmpz_add_ui@@Base+0x120>  // b.any
   12d08:	mov	x10, xzr
   12d0c:	str	x10, [x0, x22, lsl #3]
   12d10:	add	x8, x10, x22
   12d14:	b	12dbc <__gmpz_add_ui@@Base+0x1e4>
   12d18:	subs	x10, x10, x20
   12d1c:	str	x10, [x0]
   12d20:	b.cs	12d80 <__gmpz_add_ui@@Base+0x1a8>  // b.hs, b.nlast
   12d24:	mov	x10, #0xfffffffffffffff8    	// #-8
   12d28:	mov	w9, #0x1                   	// #1
   12d2c:	cmp	x9, x22
   12d30:	b.ge	12da8 <__gmpz_add_ui@@Base+0x1d0>  // b.tcont
   12d34:	ldr	x11, [x8, x9, lsl #3]
   12d38:	sub	x10, x10, #0x8
   12d3c:	sub	x12, x11, #0x1
   12d40:	str	x12, [x0, x9, lsl #3]
   12d44:	add	x9, x9, #0x1
   12d48:	cbz	x11, 12d2c <__gmpz_add_ui@@Base+0x154>
   12d4c:	cmp	x8, x0
   12d50:	b.eq	12da8 <__gmpz_add_ui@@Base+0x1d0>  // b.none
   12d54:	cmp	x9, x22
   12d58:	b.ge	12da8 <__gmpz_add_ui@@Base+0x1d0>  // b.tcont
   12d5c:	sub	x8, x8, x10
   12d60:	sub	x10, x0, x10
   12d64:	mov	x11, x22
   12d68:	ldr	x12, [x8], #8
   12d6c:	sub	x11, x11, #0x1
   12d70:	cmp	x9, x11
   12d74:	str	x12, [x10], #8
   12d78:	b.ne	12d68 <__gmpz_add_ui@@Base+0x190>  // b.any
   12d7c:	b	12da8 <__gmpz_add_ui@@Base+0x1d0>
   12d80:	cmp	x22, #0x2
   12d84:	b.lt	12da8 <__gmpz_add_ui@@Base+0x1d0>  // b.tstop
   12d88:	cmp	x8, x0
   12d8c:	b.eq	12da8 <__gmpz_add_ui@@Base+0x1d0>  // b.none
   12d90:	add	x10, x0, #0x8
   12d94:	add	x8, x8, #0x8
   12d98:	ldr	x11, [x8], #8
   12d9c:	subs	x9, x9, #0x1
   12da0:	str	x11, [x10], #8
   12da4:	b.ne	12d98 <__gmpz_add_ui@@Base+0x1c0>  // b.any
   12da8:	add	x8, x0, x22, lsl #3
   12dac:	ldur	x8, [x8, #-8]
   12db0:	cmp	x8, #0x0
   12db4:	cset	w8, eq  // eq = none
   12db8:	sub	x8, x8, x22
   12dbc:	str	w8, [x19, #4]
   12dc0:	ldp	x20, x19, [sp, #48]
   12dc4:	ldp	x22, x21, [sp, #32]
   12dc8:	ldr	x23, [sp, #16]
   12dcc:	ldp	x29, x30, [sp], #64
   12dd0:	ret
   12dd4:	add	x1, x22, #0x1
   12dd8:	mov	x0, x19
   12ddc:	bl	c090 <__gmpz_realloc@plt>
   12de0:	b	12c18 <__gmpz_add_ui@@Base+0x40>
   12de4:	mov	w1, #0x1                   	// #1
   12de8:	mov	x0, x19
   12dec:	bl	c090 <__gmpz_realloc@plt>
   12df0:	b	12ca4 <__gmpz_add_ui@@Base+0xcc>

0000000000012df4 <__gmpz_addmul@@Base>:
   12df4:	mov	x3, xzr
   12df8:	b	12dfc <__gmpz_addmul@@Base+0x8>
   12dfc:	stp	x29, x30, [sp, #-96]!
   12e00:	stp	x28, x27, [sp, #16]
   12e04:	stp	x26, x25, [sp, #32]
   12e08:	stp	x24, x23, [sp, #48]
   12e0c:	stp	x22, x21, [sp, #64]
   12e10:	stp	x20, x19, [sp, #80]
   12e14:	mov	x29, sp
   12e18:	sub	sp, sp, #0x10
   12e1c:	ldrsw	x8, [x1, #4]
   12e20:	cbz	w8, 13114 <__gmpz_addmul@@Base+0x320>
   12e24:	ldr	w9, [x2, #4]
   12e28:	cbz	w9, 13114 <__gmpz_addmul@@Base+0x320>
   12e2c:	sxtw	x9, w9
   12e30:	cmp	x9, #0x0
   12e34:	cneg	x10, x9, mi  // mi = first
   12e38:	cmp	x8, #0x0
   12e3c:	cneg	x11, x8, mi  // mi = first
   12e40:	cmp	x10, x11
   12e44:	csel	x10, x8, x9, gt
   12e48:	csel	x8, x9, x8, gt
   12e4c:	csel	x28, x1, x2, gt
   12e50:	csel	x23, x2, x1, gt
   12e54:	cmp	x10, #0x0
   12e58:	cneg	x22, x10, mi  // mi = first
   12e5c:	mov	x19, x0
   12e60:	cmp	x22, #0x1
   12e64:	eor	x3, x10, x3
   12e68:	b.ne	12e84 <__gmpz_addmul@@Base+0x90>  // b.any
   12e6c:	ldr	x8, [x28, #8]
   12e70:	mov	x0, x19
   12e74:	mov	x1, x23
   12e78:	ldr	x2, [x8]
   12e7c:	bl	cfa0 <__gmpz_aorsmul_1@plt>
   12e80:	b	13114 <__gmpz_addmul@@Base+0x320>
   12e84:	ldpsw	x10, x11, [x19]
   12e88:	cmp	x8, #0x0
   12e8c:	cneg	x24, x8, mi  // mi = first
   12e90:	add	x27, x24, x22
   12e94:	cmp	x11, #0x0
   12e98:	cneg	x26, x11, mi  // mi = first
   12e9c:	cmp	x26, x27
   12ea0:	csel	x9, x26, x27, gt
   12ea4:	cmp	x9, x10
   12ea8:	eor	x21, x3, x8
   12eac:	b.ge	13134 <__gmpz_addmul@@Base+0x340>  // b.tcont
   12eb0:	ldr	x20, [x19, #8]
   12eb4:	eor	x25, x21, x11
   12eb8:	cbz	w11, 12f64 <__gmpz_addmul@@Base+0x170>
   12ebc:	cmp	x27, #0xfe0
   12ec0:	lsl	x1, x27, #3
   12ec4:	stp	x11, xzr, [x29, #-16]
   12ec8:	b.hi	13150 <__gmpz_addmul@@Base+0x35c>  // b.pmore
   12ecc:	add	x9, x1, #0xf
   12ed0:	mov	x8, sp
   12ed4:	and	x9, x9, #0xfffffffffffffff0
   12ed8:	sub	x21, x8, x9
   12edc:	mov	sp, x21
   12ee0:	ldr	x1, [x23, #8]
   12ee4:	ldr	x3, [x28, #8]
   12ee8:	mov	x0, x21
   12eec:	mov	x2, x24
   12ef0:	mov	x4, x22
   12ef4:	bl	ccf0 <__gmpn_mul@plt>
   12ef8:	cmp	x0, #0x0
   12efc:	cset	w8, eq  // eq = none
   12f00:	sub	x8, x27, x8
   12f04:	cmp	x26, x8
   12f08:	tbnz	x25, #63, 12f9c <__gmpz_addmul@@Base+0x1a8>
   12f0c:	csel	x23, x26, x8, lt  // lt = tstop
   12f10:	csel	x24, x8, x26, lt  // lt = tstop
   12f14:	csel	x22, x21, x20, lt  // lt = tstop
   12f18:	cbz	x23, 12fc0 <__gmpz_addmul@@Base+0x1cc>
   12f1c:	cmp	x26, x8
   12f20:	csel	x2, x20, x21, lt  // lt = tstop
   12f24:	mov	x0, x20
   12f28:	mov	x1, x22
   12f2c:	mov	x3, x23
   12f30:	bl	ca90 <__gmpn_add_n@plt>
   12f34:	cbz	x0, 13004 <__gmpz_addmul@@Base+0x210>
   12f38:	ldur	x13, [x29, #-16]
   12f3c:	mov	w8, #0x1                   	// #1
   12f40:	cmp	x23, x24
   12f44:	b.ge	1303c <__gmpz_addmul@@Base+0x248>  // b.tcont
   12f48:	ldr	x9, [x22, x23, lsl #3]
   12f4c:	adds	x10, x9, #0x1
   12f50:	add	x9, x23, #0x1
   12f54:	str	x10, [x20, x23, lsl #3]
   12f58:	mov	x23, x9
   12f5c:	b.cs	12f40 <__gmpz_addmul@@Base+0x14c>  // b.hs, b.nlast
   12f60:	b	1300c <__gmpz_addmul@@Base+0x218>
   12f64:	ldr	x1, [x23, #8]
   12f68:	ldr	x3, [x28, #8]
   12f6c:	mov	x0, x20
   12f70:	mov	x2, x24
   12f74:	mov	x4, x22
   12f78:	bl	ccf0 <__gmpn_mul@plt>
   12f7c:	cmp	x0, #0x0
   12f80:	cset	w8, eq  // eq = none
   12f84:	sub	x8, x27, x8
   12f88:	neg	w9, w8
   12f8c:	cmp	x25, #0x0
   12f90:	csel	x8, x8, x9, ge  // ge = tcont
   12f94:	str	w8, [x19, #4]
   12f98:	b	13114 <__gmpz_addmul@@Base+0x320>
   12f9c:	ldur	x13, [x29, #-16]
   12fa0:	neg	x9, x13
   12fa4:	b.ge	12fcc <__gmpz_addmul@@Base+0x1d8>  // b.tcont
   12fa8:	mov	x22, x26
   12fac:	mov	x13, x9
   12fb0:	mov	x2, x20
   12fb4:	mov	x26, x8
   12fb8:	cbnz	x22, 13058 <__gmpz_addmul@@Base+0x264>
   12fbc:	b	130b4 <__gmpz_addmul@@Base+0x2c0>
   12fc0:	ldur	x13, [x29, #-16]
   12fc4:	mov	x9, xzr
   12fc8:	b	1300c <__gmpz_addmul@@Base+0x218>
   12fcc:	b.ne	13048 <__gmpz_addmul@@Base+0x254>  // b.any
   12fd0:	sub	x8, x21, #0x8
   12fd4:	mov	x10, x26
   12fd8:	subs	x11, x10, #0x1
   12fdc:	b.lt	12ffc <__gmpz_addmul@@Base+0x208>  // b.tstop
   12fe0:	add	x12, x20, x10, lsl #3
   12fe4:	ldur	x12, [x12, #-8]
   12fe8:	ldr	x10, [x8, x10, lsl #3]
   12fec:	cmp	x12, x10
   12ff0:	mov	x10, x11
   12ff4:	b.eq	12fd8 <__gmpz_addmul@@Base+0x1e4>  // b.none
   12ff8:	b.ls	130a4 <__gmpz_addmul@@Base+0x2b0>  // b.plast
   12ffc:	mov	x22, x26
   13000:	b	1304c <__gmpz_addmul@@Base+0x258>
   13004:	ldur	x13, [x29, #-16]
   13008:	mov	x9, x23
   1300c:	cmp	x20, x22
   13010:	mov	x8, xzr
   13014:	b.eq	1303c <__gmpz_addmul@@Base+0x248>  // b.none
   13018:	cmp	x9, x24
   1301c:	b.ge	1303c <__gmpz_addmul@@Base+0x248>  // b.tcont
   13020:	sub	x8, x24, x9
   13024:	add	x10, x20, x9, lsl #3
   13028:	add	x9, x22, x9, lsl #3
   1302c:	ldr	x11, [x9], #8
   13030:	subs	x8, x8, #0x1
   13034:	str	x11, [x10], #8
   13038:	b.ne	1302c <__gmpz_addmul@@Base+0x238>  // b.any
   1303c:	str	x8, [x20, x24, lsl #3]
   13040:	add	x8, x8, x24
   13044:	b	130fc <__gmpz_addmul@@Base+0x308>
   13048:	mov	x22, x8
   1304c:	mov	x2, x21
   13050:	mov	x21, x20
   13054:	cbz	x22, 130b4 <__gmpz_addmul@@Base+0x2c0>
   13058:	mov	x0, x20
   1305c:	mov	x1, x21
   13060:	mov	x3, x22
   13064:	mov	x23, x13
   13068:	bl	c2e0 <__gmpn_sub_n@plt>
   1306c:	cbz	x0, 13098 <__gmpz_addmul@@Base+0x2a4>
   13070:	mov	x13, x23
   13074:	cmp	x22, x26
   13078:	b.ge	130e4 <__gmpz_addmul@@Base+0x2f0>  // b.tcont
   1307c:	ldr	x8, [x21, x22, lsl #3]
   13080:	add	x9, x22, #0x1
   13084:	sub	x10, x8, #0x1
   13088:	str	x10, [x20, x22, lsl #3]
   1308c:	mov	x22, x9
   13090:	cbz	x8, 13074 <__gmpz_addmul@@Base+0x280>
   13094:	b	130b8 <__gmpz_addmul@@Base+0x2c4>
   13098:	mov	x9, x22
   1309c:	mov	x13, x23
   130a0:	b	130b8 <__gmpz_addmul@@Base+0x2c4>
   130a4:	mov	x22, x26
   130a8:	mov	x13, x9
   130ac:	mov	x2, x20
   130b0:	cbnz	x22, 13058 <__gmpz_addmul@@Base+0x264>
   130b4:	mov	x9, xzr
   130b8:	cmp	x20, x21
   130bc:	b.eq	130e4 <__gmpz_addmul@@Base+0x2f0>  // b.none
   130c0:	cmp	x9, x26
   130c4:	b.ge	130e4 <__gmpz_addmul@@Base+0x2f0>  // b.tcont
   130c8:	sub	x8, x26, x9
   130cc:	add	x10, x20, x9, lsl #3
   130d0:	add	x9, x21, x9, lsl #3
   130d4:	ldr	x11, [x9], #8
   130d8:	subs	x8, x8, #0x1
   130dc:	str	x11, [x10], #8
   130e0:	b.ne	130d4 <__gmpz_addmul@@Base+0x2e0>  // b.any
   130e4:	sub	x9, x20, #0x8
   130e8:	mov	x8, x26
   130ec:	subs	x26, x26, #0x1
   130f0:	b.lt	130fc <__gmpz_addmul@@Base+0x308>  // b.tstop
   130f4:	ldr	x10, [x9, x8, lsl #3]
   130f8:	cbz	x10, 130e8 <__gmpz_addmul@@Base+0x2f4>
   130fc:	neg	w9, w8
   13100:	cmp	x13, #0x0
   13104:	csel	x8, x8, x9, ge  // ge = tcont
   13108:	str	w8, [x19, #4]
   1310c:	ldur	x0, [x29, #-8]
   13110:	cbnz	x0, 13160 <__gmpz_addmul@@Base+0x36c>
   13114:	mov	sp, x29
   13118:	ldp	x20, x19, [sp, #80]
   1311c:	ldp	x22, x21, [sp, #64]
   13120:	ldp	x24, x23, [sp, #48]
   13124:	ldp	x26, x25, [sp, #32]
   13128:	ldp	x28, x27, [sp, #16]
   1312c:	ldp	x29, x30, [sp], #96
   13130:	ret
   13134:	add	x1, x9, #0x1
   13138:	mov	x0, x19
   1313c:	mov	x20, x11
   13140:	bl	c090 <__gmpz_realloc@plt>
   13144:	mov	x11, x20
   13148:	mov	x20, x0
   1314c:	b	12eb4 <__gmpz_addmul@@Base+0xc0>
   13150:	sub	x0, x29, #0x8
   13154:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   13158:	mov	x21, x0
   1315c:	b	12ee0 <__gmpz_addmul@@Base+0xec>
   13160:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   13164:	b	13114 <__gmpz_addmul@@Base+0x320>

0000000000013168 <__gmpz_submul@@Base>:
   13168:	mov	x3, #0xffffffffffffffff    	// #-1
   1316c:	b	12dfc <__gmpz_addmul@@Base+0x8>

0000000000013170 <__gmpz_aorsmul_1@@Base>:
   13170:	sub	sp, sp, #0x70
   13174:	stp	x29, x30, [sp, #16]
   13178:	stp	x28, x27, [sp, #32]
   1317c:	stp	x26, x25, [sp, #48]
   13180:	stp	x24, x23, [sp, #64]
   13184:	stp	x22, x21, [sp, #80]
   13188:	stp	x20, x19, [sp, #96]
   1318c:	add	x29, sp, #0x10
   13190:	cbz	x2, 1342c <__gmpz_aorsmul_1@@Base+0x2bc>
   13194:	ldr	w8, [x1, #4]
   13198:	mov	x26, x1
   1319c:	cbz	w8, 1342c <__gmpz_aorsmul_1@@Base+0x2bc>
   131a0:	ldrsw	x25, [x0, #4]
   131a4:	sxtw	x8, w8
   131a8:	cmp	x8, #0x0
   131ac:	mov	x22, x2
   131b0:	mov	x27, x0
   131b4:	eor	x21, x8, x3
   131b8:	cneg	x24, x8, mi  // mi = first
   131bc:	cbz	w25, 1323c <__gmpz_aorsmul_1@@Base+0xcc>
   131c0:	cmp	x25, #0x0
   131c4:	ldrsw	x8, [x27]
   131c8:	cneg	x23, x25, mi  // mi = first
   131cc:	cmp	x24, x23
   131d0:	csel	x20, x23, x24, lt  // lt = tstop
   131d4:	eor	x19, x21, x25
   131d8:	cmp	x20, x8
   131dc:	add	x8, x20, #0x1
   131e0:	str	x27, [sp, #8]
   131e4:	b.ge	13464 <__gmpz_aorsmul_1@@Base+0x2f4>  // b.tcont
   131e8:	ldr	x21, [x27, #8]
   131ec:	ldr	x26, [x26, #8]
   131f0:	subs	x27, x24, x23
   131f4:	csel	x28, x23, x24, gt
   131f8:	tbnz	x19, #63, 13274 <__gmpz_aorsmul_1@@Base+0x104>
   131fc:	mov	x0, x21
   13200:	mov	x1, x26
   13204:	mov	x2, x28
   13208:	mov	x3, x22
   1320c:	bl	d420 <__gmpn_addmul_1@plt>
   13210:	mov	x4, x0
   13214:	cmp	x27, #0x1
   13218:	add	x21, x21, x28, lsl #3
   1321c:	b.lt	132ec <__gmpz_aorsmul_1@@Base+0x17c>  // b.tstop
   13220:	add	x1, x26, x28, lsl #3
   13224:	mov	x0, x21
   13228:	mov	x2, x27
   1322c:	mov	x3, x22
   13230:	bl	d260 <__gmpn_mul_1c@plt>
   13234:	mov	x4, x0
   13238:	b	133b4 <__gmpz_aorsmul_1@@Base+0x244>
   1323c:	ldrsw	x8, [x27]
   13240:	cmp	x24, x8
   13244:	b.ge	13480 <__gmpz_aorsmul_1@@Base+0x310>  // b.tcont
   13248:	ldr	x20, [x27, #8]
   1324c:	ldr	x1, [x26, #8]
   13250:	mov	x0, x20
   13254:	mov	x2, x24
   13258:	mov	x3, x22
   1325c:	bl	d4b0 <__gmpn_mul_1@plt>
   13260:	cmp	x0, #0x0
   13264:	str	x0, [x20, x24, lsl #3]
   13268:	cinc	x8, x24, ne  // ne = any
   1326c:	mov	x25, x21
   13270:	b	1341c <__gmpz_aorsmul_1@@Base+0x2ac>
   13274:	mov	x0, x21
   13278:	mov	x1, x26
   1327c:	mov	x2, x28
   13280:	mov	x3, x22
   13284:	str	x8, [sp]
   13288:	neg	x19, x25
   1328c:	bl	ca00 <__gmpn_submul_1@plt>
   13290:	subs	x28, x24, x23
   13294:	mov	x27, x0
   13298:	b.le	132f8 <__gmpz_aorsmul_1@@Base+0x188>
   1329c:	mov	x0, x21
   132a0:	mov	x1, x21
   132a4:	mov	x2, x23
   132a8:	bl	c2a0 <__gmpn_com@plt>
   132ac:	ldr	x8, [x21]
   132b0:	adds	x8, x8, #0x1
   132b4:	str	x8, [x21]
   132b8:	b.cc	132e0 <__gmpz_aorsmul_1@@Base+0x170>  // b.lo, b.ul, b.last
   132bc:	mov	w8, #0x1                   	// #1
   132c0:	mov	w9, #0x1                   	// #1
   132c4:	cmp	x9, x23
   132c8:	b.ge	133c8 <__gmpz_aorsmul_1@@Base+0x258>  // b.tcont
   132cc:	ldr	x10, [x21, x9, lsl #3]
   132d0:	adds	x10, x10, #0x1
   132d4:	str	x10, [x21, x9, lsl #3]
   132d8:	add	x9, x9, #0x1
   132dc:	b.cs	132c4 <__gmpz_aorsmul_1@@Base+0x154>  // b.hs, b.nlast
   132e0:	mov	x25, x19
   132e4:	mov	x8, xzr
   132e8:	b	133cc <__gmpz_aorsmul_1@@Base+0x25c>
   132ec:	tbnz	x27, #63, 13378 <__gmpz_aorsmul_1@@Base+0x208>
   132f0:	mov	x27, xzr
   132f4:	b	133b4 <__gmpz_aorsmul_1@@Base+0x244>
   132f8:	b.ne	13338 <__gmpz_aorsmul_1@@Base+0x1c8>  // b.any
   132fc:	cbz	x27, 13400 <__gmpz_aorsmul_1@@Base+0x290>
   13300:	sub	x8, x27, #0x1
   13304:	mov	x0, x21
   13308:	mov	x1, x21
   1330c:	mov	x2, x20
   13310:	str	x8, [x21, x20, lsl #3]
   13314:	bl	c2a0 <__gmpn_com@plt>
   13318:	mov	x8, x21
   1331c:	ldr	x9, [x8]
   13320:	adds	x9, x9, #0x1
   13324:	str	x9, [x8], #8
   13328:	b.cs	1331c <__gmpz_aorsmul_1@@Base+0x1ac>  // b.hs, b.nlast
   1332c:	ldr	x20, [sp]
   13330:	mov	x25, x19
   13334:	b	13400 <__gmpz_aorsmul_1@@Base+0x290>
   13338:	add	x8, x21, x24, lsl #3
   1333c:	ldr	x9, [x8]
   13340:	subs	x9, x9, x27
   13344:	str	x9, [x8]
   13348:	b.cs	13400 <__gmpz_aorsmul_1@@Base+0x290>  // b.hs, b.nlast
   1334c:	sub	x9, x23, x24
   13350:	mov	w27, #0x1                   	// #1
   13354:	mov	w10, #0x1                   	// #1
   13358:	cmp	x10, x9
   1335c:	b.ge	13300 <__gmpz_aorsmul_1@@Base+0x190>  // b.tcont
   13360:	ldr	x11, [x8, x10, lsl #3]
   13364:	sub	x12, x11, #0x1
   13368:	str	x12, [x8, x10, lsl #3]
   1336c:	add	x10, x10, #0x1
   13370:	cbz	x11, 13358 <__gmpz_aorsmul_1@@Base+0x1e8>
   13374:	b	13400 <__gmpz_aorsmul_1@@Base+0x290>
   13378:	ldr	x8, [x21]
   1337c:	neg	x27, x27
   13380:	adds	x8, x8, x4
   13384:	str	x8, [x21]
   13388:	b.cc	133b0 <__gmpz_aorsmul_1@@Base+0x240>  // b.lo, b.ul, b.last
   1338c:	mov	w4, #0x1                   	// #1
   13390:	mov	w8, #0x1                   	// #1
   13394:	cmp	x8, x27
   13398:	b.ge	133b4 <__gmpz_aorsmul_1@@Base+0x244>  // b.tcont
   1339c:	ldr	x9, [x21, x8, lsl #3]
   133a0:	adds	x9, x9, #0x1
   133a4:	str	x9, [x21, x8, lsl #3]
   133a8:	add	x8, x8, #0x1
   133ac:	b.cs	13394 <__gmpz_aorsmul_1@@Base+0x224>  // b.hs, b.nlast
   133b0:	mov	x4, xzr
   133b4:	str	x4, [x21, x27, lsl #3]
   133b8:	ldr	x27, [sp, #8]
   133bc:	cmp	x4, #0x0
   133c0:	cinc	x8, x20, ne  // ne = any
   133c4:	b	1341c <__gmpz_aorsmul_1@@Base+0x2ac>
   133c8:	mov	x25, x19
   133cc:	adds	x19, x8, x27
   133d0:	add	x24, x21, x23, lsl #3
   133d4:	cinc	x8, x19, eq  // eq = none
   133d8:	sub	x4, x8, #0x1
   133dc:	add	x1, x26, x23, lsl #3
   133e0:	mov	x0, x24
   133e4:	mov	x2, x28
   133e8:	mov	x3, x22
   133ec:	bl	d260 <__gmpn_mul_1c@plt>
   133f0:	cmp	x0, #0x0
   133f4:	str	x0, [x21, x20, lsl #3]
   133f8:	cinc	x20, x20, ne  // ne = any
   133fc:	cbz	x19, 1344c <__gmpz_aorsmul_1@@Base+0x2dc>
   13400:	ldr	x27, [sp, #8]
   13404:	sub	x9, x21, #0x8
   13408:	mov	x8, x20
   1340c:	subs	x20, x20, #0x1
   13410:	b.lt	1341c <__gmpz_aorsmul_1@@Base+0x2ac>  // b.tstop
   13414:	ldr	x10, [x9, x8, lsl #3]
   13418:	cbz	x10, 13408 <__gmpz_aorsmul_1@@Base+0x298>
   1341c:	neg	w9, w8
   13420:	cmp	x25, #0x0
   13424:	csel	x8, x8, x9, ge  // ge = tcont
   13428:	str	w8, [x27, #4]
   1342c:	ldp	x20, x19, [sp, #96]
   13430:	ldp	x22, x21, [sp, #80]
   13434:	ldp	x24, x23, [sp, #64]
   13438:	ldp	x26, x25, [sp, #48]
   1343c:	ldp	x28, x27, [sp, #32]
   13440:	ldp	x29, x30, [sp, #16]
   13444:	add	sp, sp, #0x70
   13448:	ret
   1344c:	ldr	x27, [sp, #8]
   13450:	ldr	x8, [x24]
   13454:	sub	x9, x8, #0x1
   13458:	str	x9, [x24], #8
   1345c:	cbz	x8, 13450 <__gmpz_aorsmul_1@@Base+0x2e0>
   13460:	b	13404 <__gmpz_aorsmul_1@@Base+0x294>
   13464:	mov	x0, x27
   13468:	mov	x1, x8
   1346c:	mov	x21, x8
   13470:	bl	c090 <__gmpz_realloc@plt>
   13474:	mov	x8, x21
   13478:	mov	x21, x0
   1347c:	b	131ec <__gmpz_aorsmul_1@@Base+0x7c>
   13480:	add	x1, x24, #0x1
   13484:	mov	x0, x27
   13488:	bl	c090 <__gmpz_realloc@plt>
   1348c:	mov	x20, x0
   13490:	b	1324c <__gmpz_aorsmul_1@@Base+0xdc>

0000000000013494 <__gmpz_addmul_ui@@Base>:
   13494:	mov	x3, xzr
   13498:	b	cfa0 <__gmpz_aorsmul_1@plt>

000000000001349c <__gmpz_submul_ui@@Base>:
   1349c:	mov	x3, #0xffffffffffffffff    	// #-1
   134a0:	b	cfa0 <__gmpz_aorsmul_1@plt>

00000000000134a4 <__gmpz_and@@Base>:
   134a4:	stp	x29, x30, [sp, #-96]!
   134a8:	stp	x26, x25, [sp, #32]
   134ac:	stp	x24, x23, [sp, #48]
   134b0:	stp	x22, x21, [sp, #64]
   134b4:	stp	x20, x19, [sp, #80]
   134b8:	ldr	w8, [x1, #4]
   134bc:	ldr	w9, [x2, #4]
   134c0:	str	x27, [sp, #16]
   134c4:	mov	x19, x0
   134c8:	mov	x29, sp
   134cc:	cmp	w8, w9
   134d0:	csel	x10, x1, x2, lt  // lt = tstop
   134d4:	csel	x11, x2, x1, lt  // lt = tstop
   134d8:	ldr	x22, [x11, #8]
   134dc:	ldr	x23, [x10, #8]
   134e0:	csel	w10, w8, w9, lt  // lt = tstop
   134e4:	sxtw	x27, w10
   134e8:	csel	w8, w9, w8, lt  // lt = tstop
   134ec:	tbnz	w10, #31, 13560 <__gmpz_and@@Base+0xbc>
   134f0:	sub	x9, x27, #0x1
   134f4:	add	w8, w27, #0x1
   134f8:	add	x10, x9, #0x1
   134fc:	cmp	x10, #0x1
   13500:	b.lt	135d0 <__gmpz_and@@Base+0x12c>  // b.tstop
   13504:	ldr	x10, [x22, x9, lsl #3]
   13508:	ldr	x11, [x23, x9, lsl #3]
   1350c:	sub	x9, x9, #0x1
   13510:	sub	w8, w8, #0x1
   13514:	and	x10, x11, x10
   13518:	cbz	x10, 134f8 <__gmpz_and@@Base+0x54>
   1351c:	ldrsw	x10, [x19]
   13520:	add	x20, x9, #0x2
   13524:	str	w8, [x19, #4]
   13528:	cmp	x20, x10
   1352c:	b.gt	138dc <__gmpz_and@@Base+0x438>
   13530:	ldr	x0, [x19, #8]
   13534:	mov	x1, x22
   13538:	mov	x2, x23
   1353c:	mov	x3, x20
   13540:	mov	sp, x29
   13544:	ldp	x20, x19, [sp, #80]
   13548:	ldp	x22, x21, [sp, #64]
   1354c:	ldp	x24, x23, [sp, #48]
   13550:	ldp	x26, x25, [sp, #32]
   13554:	ldr	x27, [sp, #16]
   13558:	ldp	x29, x30, [sp], #96
   1355c:	b	c280 <__gmpn_and_n@plt>
   13560:	sxtw	x20, w8
   13564:	neg	x21, x27
   13568:	str	xzr, [x29, #24]
   1356c:	tbnz	w20, #31, 135d8 <__gmpz_and@@Base+0x134>
   13570:	cmp	x21, #0xfe0
   13574:	lsl	x1, x21, #3
   13578:	b.hi	138ec <__gmpz_and@@Base+0x448>  // b.pmore
   1357c:	add	x9, x1, #0xf
   13580:	mov	x8, sp
   13584:	and	x9, x9, #0xfffffffffffffff0
   13588:	sub	x24, x8, x9
   1358c:	mov	sp, x24
   13590:	ldr	x8, [x23]
   13594:	sub	x9, x8, #0x1
   13598:	str	x9, [x24]
   1359c:	cbz	x8, 13648 <__gmpz_and@@Base+0x1a4>
   135a0:	cmn	w27, #0x2
   135a4:	b.gt	136a0 <__gmpz_and@@Base+0x1fc>
   135a8:	cmp	x23, x24
   135ac:	b.eq	136a0 <__gmpz_and@@Base+0x1fc>  // b.none
   135b0:	add	x8, x27, #0x1
   135b4:	add	x9, x24, #0x8
   135b8:	add	x10, x23, #0x8
   135bc:	ldr	x11, [x10], #8
   135c0:	adds	x8, x8, #0x1
   135c4:	str	x11, [x9], #8
   135c8:	b.cc	135bc <__gmpz_and@@Base+0x118>  // b.lo, b.ul, b.last
   135cc:	b	136a0 <__gmpz_and@@Base+0x1fc>
   135d0:	str	wzr, [x19, #4]
   135d4:	b	138bc <__gmpz_and@@Base+0x418>
   135d8:	add	x8, x20, x27
   135dc:	neg	x1, x8, lsl #3
   135e0:	mov	w8, #0x7f00                	// #32512
   135e4:	cmp	x1, x8
   135e8:	neg	x24, x20
   135ec:	b.hi	138fc <__gmpz_and@@Base+0x458>  // b.pmore
   135f0:	add	x9, x1, #0xf
   135f4:	mov	x8, sp
   135f8:	and	x9, x9, #0xfffffffffffffff0
   135fc:	sub	x25, x8, x9
   13600:	mov	sp, x25
   13604:	ldr	x8, [x22]
   13608:	add	x26, x25, x24, lsl #3
   1360c:	sub	x9, x8, #0x1
   13610:	str	x9, [x25]
   13614:	cbz	x8, 13744 <__gmpz_and@@Base+0x2a0>
   13618:	cmn	w20, #0x2
   1361c:	b.gt	1379c <__gmpz_and@@Base+0x2f8>
   13620:	cmp	x22, x25
   13624:	b.eq	1379c <__gmpz_and@@Base+0x2f8>  // b.none
   13628:	add	x8, x20, #0x1
   1362c:	add	x9, x25, #0x8
   13630:	add	x10, x22, #0x8
   13634:	ldr	x11, [x10], #8
   13638:	adds	x8, x8, #0x1
   1363c:	str	x11, [x9], #8
   13640:	b.cc	13634 <__gmpz_and@@Base+0x190>  // b.lo, b.ul, b.last
   13644:	b	1379c <__gmpz_and@@Base+0x2f8>
   13648:	mov	x9, #0xfffffffffffffff8    	// #-8
   1364c:	mov	w8, #0x1                   	// #1
   13650:	cmp	x8, x21
   13654:	b.ge	136a0 <__gmpz_and@@Base+0x1fc>  // b.tcont
   13658:	ldr	x10, [x23, x8, lsl #3]
   1365c:	sub	x9, x9, #0x8
   13660:	sub	x11, x10, #0x1
   13664:	str	x11, [x24, x8, lsl #3]
   13668:	add	x8, x8, #0x1
   1366c:	cbz	x10, 13650 <__gmpz_and@@Base+0x1ac>
   13670:	cmp	x23, x24
   13674:	b.eq	136a0 <__gmpz_and@@Base+0x1fc>  // b.none
   13678:	cmp	x8, x21
   1367c:	b.ge	136a0 <__gmpz_and@@Base+0x1fc>  // b.tcont
   13680:	sub	x10, x23, x9
   13684:	sub	x9, x24, x9
   13688:	mov	x11, x21
   1368c:	ldr	x12, [x10], #8
   13690:	sub	x11, x11, #0x1
   13694:	cmp	x8, x11
   13698:	str	x12, [x9], #8
   1369c:	b.ne	1368c <__gmpz_and@@Base+0x1e8>  // b.any
   136a0:	cmp	x20, x21
   136a4:	b.le	136e0 <__gmpz_and@@Base+0x23c>
   136a8:	ldr	w8, [x19]
   136ac:	cmp	w20, w8
   136b0:	b.gt	13924 <__gmpz_and@@Base+0x480>
   136b4:	ldr	x23, [x19, #8]
   136b8:	mov	x0, x23
   136bc:	mov	x1, x22
   136c0:	mov	x2, x24
   136c4:	mov	x3, x21
   136c8:	bl	c070 <__gmpn_andn_n@plt>
   136cc:	add	x0, x23, x21, lsl #3
   136d0:	add	x1, x22, x21, lsl #3
   136d4:	add	x2, x20, x27
   136d8:	bl	ca70 <__gmpn_copyi@plt>
   136dc:	b	13730 <__gmpz_and@@Base+0x28c>
   136e0:	sub	x8, x24, #0x8
   136e4:	subs	x9, x20, #0x1
   136e8:	b.lt	1372c <__gmpz_and@@Base+0x288>  // b.tstop
   136ec:	add	x10, x22, x20, lsl #3
   136f0:	ldur	x10, [x10, #-8]
   136f4:	ldr	x11, [x8, x20, lsl #3]
   136f8:	mov	x20, x9
   136fc:	bics	xzr, x10, x11
   13700:	b.eq	136e4 <__gmpz_and@@Base+0x240>  // b.none
   13704:	ldrsw	x8, [x19]
   13708:	add	x20, x9, #0x1
   1370c:	cmp	x20, x8
   13710:	b.gt	13938 <__gmpz_and@@Base+0x494>
   13714:	ldr	x0, [x19, #8]
   13718:	mov	x1, x22
   1371c:	mov	x2, x24
   13720:	mov	x3, x20
   13724:	bl	c070 <__gmpn_andn_n@plt>
   13728:	b	13730 <__gmpz_and@@Base+0x28c>
   1372c:	mov	x20, xzr
   13730:	str	w20, [x19, #4]
   13734:	ldr	x0, [x29, #24]
   13738:	cbz	x0, 138bc <__gmpz_and@@Base+0x418>
   1373c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   13740:	b	138bc <__gmpz_and@@Base+0x418>
   13744:	mov	x9, #0xfffffffffffffff8    	// #-8
   13748:	mov	w8, #0x1                   	// #1
   1374c:	cmp	x8, x24
   13750:	b.ge	1379c <__gmpz_and@@Base+0x2f8>  // b.tcont
   13754:	ldr	x10, [x22, x8, lsl #3]
   13758:	sub	x9, x9, #0x8
   1375c:	sub	x11, x10, #0x1
   13760:	str	x11, [x25, x8, lsl #3]
   13764:	add	x8, x8, #0x1
   13768:	cbz	x10, 1374c <__gmpz_and@@Base+0x2a8>
   1376c:	cmp	x22, x25
   13770:	b.eq	1379c <__gmpz_and@@Base+0x2f8>  // b.none
   13774:	cmp	x8, x24
   13778:	b.ge	1379c <__gmpz_and@@Base+0x2f8>  // b.tcont
   1377c:	sub	x10, x22, x9
   13780:	sub	x9, x25, x9
   13784:	mov	x11, x24
   13788:	ldr	x12, [x10], #8
   1378c:	sub	x11, x11, #0x1
   13790:	cmp	x8, x11
   13794:	str	x12, [x9], #8
   13798:	b.ne	13788 <__gmpz_and@@Base+0x2e4>  // b.any
   1379c:	ldr	x8, [x23]
   137a0:	sub	x9, x8, #0x1
   137a4:	str	x9, [x26]
   137a8:	cbz	x8, 137e0 <__gmpz_and@@Base+0x33c>
   137ac:	cmn	w27, #0x2
   137b0:	b.gt	13850 <__gmpz_and@@Base+0x3ac>
   137b4:	cmp	x23, x26
   137b8:	b.eq	13850 <__gmpz_and@@Base+0x3ac>  // b.none
   137bc:	sub	x9, x25, x20, lsl #3
   137c0:	add	x8, x27, #0x1
   137c4:	add	x9, x9, #0x8
   137c8:	add	x10, x23, #0x8
   137cc:	ldr	x11, [x10], #8
   137d0:	adds	x8, x8, #0x1
   137d4:	str	x11, [x9], #8
   137d8:	b.cc	137cc <__gmpz_and@@Base+0x328>  // b.lo, b.ul, b.last
   137dc:	b	13850 <__gmpz_and@@Base+0x3ac>
   137e0:	mov	w8, #0x10                  	// #16
   137e4:	sub	x10, x8, x20, lsl #3
   137e8:	add	x8, x10, x25
   137ec:	mov	x9, #0xfffffffffffffff8    	// #-8
   137f0:	sub	x11, x8, #0x10
   137f4:	mov	w8, #0x1                   	// #1
   137f8:	cmp	x8, x21
   137fc:	b.ge	13850 <__gmpz_and@@Base+0x3ac>  // b.tcont
   13800:	ldr	x12, [x23, x8, lsl #3]
   13804:	sub	x9, x9, #0x8
   13808:	sub	x13, x12, #0x1
   1380c:	str	x13, [x11, x8, lsl #3]
   13810:	add	x8, x8, #0x1
   13814:	cbz	x12, 137f8 <__gmpz_and@@Base+0x354>
   13818:	cmp	x23, x26
   1381c:	b.eq	13850 <__gmpz_and@@Base+0x3ac>  // b.none
   13820:	cmp	x8, x21
   13824:	b.ge	13850 <__gmpz_and@@Base+0x3ac>  // b.tcont
   13828:	add	x10, x10, x25
   1382c:	sub	x11, x23, x9
   13830:	sub	x9, x10, x9
   13834:	sub	x9, x9, #0x10
   13838:	mov	x10, x21
   1383c:	ldr	x12, [x11], #8
   13840:	sub	x10, x10, #0x1
   13844:	cmp	x8, x10
   13848:	str	x12, [x9], #8
   1384c:	b.ne	1383c <__gmpz_and@@Base+0x398>  // b.any
   13850:	ldrsw	x8, [x19]
   13854:	mov	w9, #0x1                   	// #1
   13858:	sub	x1, x9, x27
   1385c:	cmp	x1, x8
   13860:	b.gt	1390c <__gmpz_and@@Base+0x468>
   13864:	ldr	x22, [x19, #8]
   13868:	add	x0, x22, x24, lsl #3
   1386c:	add	x1, x26, x24, lsl #3
   13870:	sub	x2, x20, x27
   13874:	bl	ca70 <__gmpn_copyi@plt>
   13878:	mov	x0, x22
   1387c:	mov	x1, x25
   13880:	mov	x2, x26
   13884:	mov	x3, x24
   13888:	bl	cc20 <__gmpn_ior_n@plt>
   1388c:	ldr	x0, [x29, #24]
   13890:	cbnz	x0, 1391c <__gmpz_and@@Base+0x478>
   13894:	mov	x8, x22
   13898:	str	xzr, [x22, x21, lsl #3]
   1389c:	ldr	x9, [x8]
   138a0:	adds	x9, x9, #0x1
   138a4:	str	x9, [x8], #8
   138a8:	b.cs	1389c <__gmpz_and@@Base+0x3f8>  // b.hs, b.nlast
   138ac:	lsl	x8, x21, #3
   138b0:	ldr	w8, [x22, x8]
   138b4:	sub	w8, w27, w8
   138b8:	str	w8, [x19, #4]
   138bc:	mov	sp, x29
   138c0:	ldp	x20, x19, [sp, #80]
   138c4:	ldp	x22, x21, [sp, #64]
   138c8:	ldp	x24, x23, [sp, #48]
   138cc:	ldp	x26, x25, [sp, #32]
   138d0:	ldr	x27, [sp, #16]
   138d4:	ldp	x29, x30, [sp], #96
   138d8:	ret
   138dc:	mov	x0, x19
   138e0:	mov	x1, x20
   138e4:	bl	c090 <__gmpz_realloc@plt>
   138e8:	b	13534 <__gmpz_and@@Base+0x90>
   138ec:	add	x0, x29, #0x18
   138f0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   138f4:	mov	x24, x0
   138f8:	b	13590 <__gmpz_and@@Base+0xec>
   138fc:	add	x0, x29, #0x18
   13900:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   13904:	mov	x25, x0
   13908:	b	13604 <__gmpz_and@@Base+0x160>
   1390c:	mov	x0, x19
   13910:	bl	c090 <__gmpz_realloc@plt>
   13914:	mov	x22, x0
   13918:	b	13868 <__gmpz_and@@Base+0x3c4>
   1391c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   13920:	b	13894 <__gmpz_and@@Base+0x3f0>
   13924:	mov	x0, x19
   13928:	mov	x1, x20
   1392c:	bl	c090 <__gmpz_realloc@plt>
   13930:	mov	x23, x0
   13934:	b	136b8 <__gmpz_and@@Base+0x214>
   13938:	mov	x0, x19
   1393c:	mov	x1, x20
   13940:	bl	c090 <__gmpz_realloc@plt>
   13944:	b	13718 <__gmpz_and@@Base+0x274>

0000000000013948 <__gmpz_array_init@@Base>:
   13948:	stp	x29, x30, [sp, #-48]!
   1394c:	str	x21, [sp, #16]
   13950:	stp	x20, x19, [sp, #32]
   13954:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   13958:	ldr	x9, [x9, #3840]
   1395c:	add	x8, x2, #0x3f
   13960:	cmp	x2, #0x0
   13964:	csel	x8, x8, x2, lt  // lt = tstop
   13968:	asr	x21, x8, #6
   1396c:	ldr	x8, [x9]
   13970:	add	x9, x21, #0x1
   13974:	mul	x9, x1, x9
   13978:	mov	x20, x0
   1397c:	lsl	x0, x9, #3
   13980:	mov	x29, sp
   13984:	mov	x19, x1
   13988:	blr	x8
   1398c:	cmp	x19, #0x1
   13990:	b.lt	139bc <__gmpz_array_init@@Base+0x74>  // b.tstop
   13994:	lsl	x10, x21, #3
   13998:	add	w8, w21, #0x2
   1399c:	add	x9, x20, #0x4
   139a0:	add	x10, x10, #0x8
   139a4:	stp	w8, wzr, [x9, #-4]
   139a8:	stur	x0, [x9, #4]
   139ac:	subs	x19, x19, #0x1
   139b0:	add	x9, x9, #0x10
   139b4:	add	x0, x0, x10
   139b8:	b.ne	139a4 <__gmpz_array_init@@Base+0x5c>  // b.any
   139bc:	ldp	x20, x19, [sp, #32]
   139c0:	ldr	x21, [sp, #16]
   139c4:	ldp	x29, x30, [sp], #48
   139c8:	ret

00000000000139cc <__gmpz_bin_ui@@Base>:
   139cc:	sub	sp, sp, #0x70
   139d0:	stp	x29, x30, [sp, #48]
   139d4:	stp	x22, x21, [sp, #80]
   139d8:	stp	x20, x19, [sp, #96]
   139dc:	ldr	w8, [x1, #4]
   139e0:	mov	x20, x2
   139e4:	mov	x21, x1
   139e8:	mov	x19, x0
   139ec:	str	x23, [sp, #64]
   139f0:	add	x29, sp, #0x30
   139f4:	tbnz	w8, #31, 13a28 <__gmpz_bin_ui@@Base+0x5c>
   139f8:	mov	x0, x21
   139fc:	mov	x1, x20
   13a00:	bl	d210 <__gmpz_cmp_ui@plt>
   13a04:	tbnz	w0, #31, 13b94 <__gmpz_bin_ui@@Base+0x1c8>
   13a08:	sub	x0, x29, #0x10
   13a0c:	bl	d270 <__gmpz_init@plt>
   13a10:	sub	x0, x29, #0x10
   13a14:	mov	x1, x21
   13a18:	mov	x2, x20
   13a1c:	bl	c130 <__gmpz_sub_ui@plt>
   13a20:	mov	x23, xzr
   13a24:	b	13a50 <__gmpz_bin_ui@@Base+0x84>
   13a28:	sub	x0, x29, #0x10
   13a2c:	bl	d270 <__gmpz_init@plt>
   13a30:	sub	x0, x29, #0x10
   13a34:	mov	w2, #0x1                   	// #1
   13a38:	mov	x1, x21
   13a3c:	bl	c8d0 <__gmpz_add_ui@plt>
   13a40:	ldur	w8, [x29, #-12]
   13a44:	and	x23, x20, #0x1
   13a48:	neg	w8, w8
   13a4c:	stur	w8, [x29, #-12]
   13a50:	sub	x0, x29, #0x10
   13a54:	mov	x1, x20
   13a58:	bl	d210 <__gmpz_cmp_ui@plt>
   13a5c:	tbz	w0, #31, 13a80 <__gmpz_bin_ui@@Base+0xb4>
   13a60:	ldur	x8, [x29, #-8]
   13a64:	ldur	w22, [x29, #-12]
   13a68:	sub	x0, x29, #0x10
   13a6c:	mov	x1, x20
   13a70:	ldr	x21, [x8]
   13a74:	bl	c180 <__gmpz_set_ui@plt>
   13a78:	cbz	w22, 13b9c <__gmpz_bin_ui@@Base+0x1d0>
   13a7c:	mov	x20, x21
   13a80:	cmp	x20, #0x1
   13a84:	b.hi	13aa0 <__gmpz_bin_ui@@Base+0xd4>  // b.pmore
   13a88:	cbz	x20, 13b9c <__gmpz_bin_ui@@Base+0x1d0>
   13a8c:	sub	x1, x29, #0x10
   13a90:	mov	w2, #0x1                   	// #1
   13a94:	mov	x0, x19
   13a98:	bl	c8d0 <__gmpz_add_ui@plt>
   13a9c:	b	13cc4 <__gmpz_bin_ui@@Base+0x2f8>
   13aa0:	add	x0, sp, #0x10
   13aa4:	bl	d270 <__gmpz_init@plt>
   13aa8:	mov	x0, sp
   13aac:	bl	d270 <__gmpz_init@plt>
   13ab0:	ldp	w8, w21, [x29, #-16]
   13ab4:	sxtw	x21, w21
   13ab8:	add	x1, x21, #0x2
   13abc:	cmp	w1, w8
   13ac0:	b.gt	13cf8 <__gmpz_bin_ui@@Base+0x32c>
   13ac4:	ldur	x0, [x29, #-8]
   13ac8:	add	x8, x0, x21, lsl #3
   13acc:	stp	xzr, xzr, [x8]
   13ad0:	ldur	x8, [x29, #-8]
   13ad4:	mov	x9, x8
   13ad8:	ldr	x10, [x9]
   13adc:	adds	x10, x10, #0x1
   13ae0:	str	x10, [x9], #8
   13ae4:	b.cs	13ad8 <__gmpz_bin_ui@@Base+0x10c>  // b.hs, b.nlast
   13ae8:	ldursw	x9, [x29, #-12]
   13aec:	ldr	x8, [x8, x9, lsl #3]
   13af0:	str	wzr, [sp, #20]
   13af4:	cmp	x8, #0x0
   13af8:	cinc	w8, w9, ne  // ne = any
   13afc:	stur	w8, [x29, #-12]
   13b00:	tbz	w20, #0, 13b3c <__gmpz_bin_ui@@Base+0x170>
   13b04:	add	x0, sp, #0x10
   13b08:	sub	x1, x29, #0x10
   13b0c:	bl	c440 <__gmpz_set@plt>
   13b10:	ldur	x8, [x29, #-8]
   13b14:	mov	x9, x8
   13b18:	ldr	x10, [x9]
   13b1c:	adds	x10, x10, #0x1
   13b20:	str	x10, [x9], #8
   13b24:	b.cs	13b18 <__gmpz_bin_ui@@Base+0x14c>  // b.hs, b.nlast
   13b28:	ldursw	x9, [x29, #-12]
   13b2c:	ldr	x8, [x8, x9, lsl #3]
   13b30:	cmp	x8, #0x0
   13b34:	cinc	w8, w9, ne  // ne = any
   13b38:	stur	w8, [x29, #-12]
   13b3c:	lsr	x21, x20, #1
   13b40:	sub	x1, x29, #0x10
   13b44:	mov	x3, sp
   13b48:	mov	x0, x19
   13b4c:	mov	x2, x21
   13b50:	bl	13d60 <__gmpz_bin_ui@@Base+0x394>
   13b54:	ldp	w8, w22, [x19]
   13b58:	sxtw	x22, w22
   13b5c:	add	x1, x22, #0x2
   13b60:	cmp	w1, w8
   13b64:	b.gt	13d04 <__gmpz_bin_ui@@Base+0x338>
   13b68:	ldr	x0, [x19, #8]
   13b6c:	add	x8, x0, x22, lsl #3
   13b70:	stp	xzr, xzr, [x8]
   13b74:	tbz	w20, #1, 13bd8 <__gmpz_bin_ui@@Base+0x20c>
   13b78:	ldr	w8, [sp, #20]
   13b7c:	cbz	w8, 13bc0 <__gmpz_bin_ui@@Base+0x1f4>
   13b80:	add	x0, sp, #0x10
   13b84:	add	x1, sp, #0x10
   13b88:	mov	x2, x19
   13b8c:	bl	c4d0 <__gmpz_mul@plt>
   13b90:	b	13bcc <__gmpz_bin_ui@@Base+0x200>
   13b94:	str	wzr, [x19, #4]
   13b98:	b	13ce0 <__gmpz_bin_ui@@Base+0x314>
   13b9c:	ldr	w8, [x19]
   13ba0:	mov	w9, #0x1                   	// #1
   13ba4:	str	w9, [x19, #4]
   13ba8:	cmp	w8, #0x0
   13bac:	b.le	13d10 <__gmpz_bin_ui@@Base+0x344>
   13bb0:	ldr	x0, [x19, #8]
   13bb4:	mov	w8, #0x1                   	// #1
   13bb8:	str	x8, [x0]
   13bbc:	b	13cc4 <__gmpz_bin_ui@@Base+0x2f8>
   13bc0:	add	x0, sp, #0x10
   13bc4:	mov	x1, x19
   13bc8:	bl	c440 <__gmpz_set@plt>
   13bcc:	sub	x1, x21, #0x1
   13bd0:	mov	x0, x19
   13bd4:	bl	13d20 <__gmpz_bin_ui@@Base+0x354>
   13bd8:	lsr	x22, x20, #2
   13bdc:	cbz	x22, 13c4c <__gmpz_bin_ui@@Base+0x280>
   13be0:	mov	x0, sp
   13be4:	sub	x3, x29, #0x10
   13be8:	mov	x1, x19
   13bec:	mov	x2, x22
   13bf0:	bl	13d60 <__gmpz_bin_ui@@Base+0x394>
   13bf4:	ldr	w8, [sp, #20]
   13bf8:	cbz	w8, 13c10 <__gmpz_bin_ui@@Base+0x244>
   13bfc:	add	x0, sp, #0x10
   13c00:	add	x1, sp, #0x10
   13c04:	mov	x2, sp
   13c08:	bl	c4d0 <__gmpz_mul@plt>
   13c0c:	b	13c1c <__gmpz_bin_ui@@Base+0x250>
   13c10:	add	x0, sp, #0x10
   13c14:	mov	x1, sp
   13c18:	bl	c440 <__gmpz_set@plt>
   13c1c:	cmp	x20, #0x8
   13c20:	b.cc	13c4c <__gmpz_bin_ui@@Base+0x280>  // b.lo, b.ul, b.last
   13c24:	mov	x0, x19
   13c28:	mov	x1, x22
   13c2c:	bl	13e64 <__gmpz_bin_ui@@Base+0x498>
   13c30:	sub	x3, x22, #0x1
   13c34:	add	x0, sp, #0x10
   13c38:	mov	x2, sp
   13c3c:	sub	x5, x29, #0x10
   13c40:	mov	x1, x19
   13c44:	mov	x4, xzr
   13c48:	bl	13eac <__gmpz_bin_ui@@Base+0x4e0>
   13c4c:	and	x8, x21, #0x5555555555555555
   13c50:	sub	x8, x20, x8
   13c54:	lsr	x10, x8, #2
   13c58:	and	x8, x8, #0x3333333333333333
   13c5c:	and	x10, x10, #0x3333333333333333
   13c60:	add	x8, x10, x8
   13c64:	add	x8, x8, x8, lsr #4
   13c68:	and	x8, x8, #0xf0f0f0f0f0f0f0f
   13c6c:	add	x8, x8, x8, lsr #8
   13c70:	add	x8, x8, x8, lsr #16
   13c74:	sub	x9, x20, x21
   13c78:	lsr	x10, x8, #32
   13c7c:	add	w8, w10, w8
   13c80:	sub	x9, x9, x22
   13c84:	sub	x2, x9, w8, uxtb
   13c88:	add	x0, sp, #0x10
   13c8c:	add	x1, sp, #0x10
   13c90:	bl	cc90 <__gmpz_tdiv_q_2exp@plt>
   13c94:	mov	x0, sp
   13c98:	mov	x1, x20
   13c9c:	mov	w2, wzr
   13ca0:	bl	c3f0 <__gmpz_oddfac_1@plt>
   13ca4:	add	x1, sp, #0x10
   13ca8:	mov	x2, sp
   13cac:	mov	x0, x19
   13cb0:	bl	c410 <__gmpz_divexact@plt>
   13cb4:	add	x0, sp, #0x10
   13cb8:	bl	cb70 <__gmpz_clear@plt>
   13cbc:	mov	x0, sp
   13cc0:	bl	cb70 <__gmpz_clear@plt>
   13cc4:	sub	x0, x29, #0x10
   13cc8:	bl	cb70 <__gmpz_clear@plt>
   13ccc:	ldr	w8, [x19, #4]
   13cd0:	neg	w9, w23
   13cd4:	eor	w8, w8, w9
   13cd8:	add	w8, w8, w23
   13cdc:	str	w8, [x19, #4]
   13ce0:	ldp	x20, x19, [sp, #96]
   13ce4:	ldp	x22, x21, [sp, #80]
   13ce8:	ldr	x23, [sp, #64]
   13cec:	ldp	x29, x30, [sp, #48]
   13cf0:	add	sp, sp, #0x70
   13cf4:	ret
   13cf8:	sub	x0, x29, #0x10
   13cfc:	bl	c090 <__gmpz_realloc@plt>
   13d00:	b	13ac8 <__gmpz_bin_ui@@Base+0xfc>
   13d04:	mov	x0, x19
   13d08:	bl	c090 <__gmpz_realloc@plt>
   13d0c:	b	13b6c <__gmpz_bin_ui@@Base+0x1a0>
   13d10:	mov	w1, #0x1                   	// #1
   13d14:	mov	x0, x19
   13d18:	bl	c090 <__gmpz_realloc@plt>
   13d1c:	b	13bb4 <__gmpz_bin_ui@@Base+0x1e8>
   13d20:	ldr	x8, [x0, #8]
   13d24:	ldr	x9, [x8]
   13d28:	adds	x9, x9, x1
   13d2c:	str	x9, [x8]
   13d30:	b.cc	13d48 <__gmpz_bin_ui@@Base+0x37c>  // b.lo, b.ul, b.last
   13d34:	add	x9, x8, #0x8
   13d38:	ldr	x10, [x9]
   13d3c:	adds	x10, x10, #0x1
   13d40:	str	x10, [x9], #8
   13d44:	b.cs	13d38 <__gmpz_bin_ui@@Base+0x36c>  // b.hs, b.nlast
   13d48:	ldrsw	x9, [x0, #4]
   13d4c:	ldr	x8, [x8, x9, lsl #3]
   13d50:	cmp	x8, #0x0
   13d54:	cinc	w8, w9, ne  // ne = any
   13d58:	str	w8, [x0, #4]
   13d5c:	ret
   13d60:	sub	sp, sp, #0x40
   13d64:	stp	x20, x19, [sp, #48]
   13d68:	sub	x20, x2, #0x1
   13d6c:	mov	x19, x0
   13d70:	mov	x0, x3
   13d74:	mov	x2, x20
   13d78:	stp	x29, x30, [sp, #16]
   13d7c:	stp	x22, x21, [sp, #32]
   13d80:	add	x29, sp, #0x10
   13d84:	mov	x21, x3
   13d88:	mov	x22, x1
   13d8c:	bl	c8d0 <__gmpz_add_ui@plt>
   13d90:	mov	x0, x19
   13d94:	mov	x1, x21
   13d98:	mov	x2, x21
   13d9c:	bl	c4d0 <__gmpz_mul@plt>
   13da0:	mov	x0, x19
   13da4:	mov	x1, x19
   13da8:	mov	x2, x22
   13dac:	bl	cfb0 <__gmpz_add@plt>
   13db0:	ldrsw	x21, [x19, #4]
   13db4:	ldr	x22, [x19, #8]
   13db8:	mov	w3, #0x1                   	// #1
   13dbc:	mov	x2, x21
   13dc0:	mov	x0, x22
   13dc4:	mov	x1, x22
   13dc8:	bl	c1b0 <__gmpn_rshift@plt>
   13dcc:	add	x8, x22, x21, lsl #3
   13dd0:	ldur	x8, [x8, #-8]
   13dd4:	ldr	w9, [x19, #4]
   13dd8:	mov	x10, #0x100000000           	// #4294967296
   13ddc:	cmp	x8, #0x0
   13de0:	cset	w8, eq  // eq = none
   13de4:	sub	w8, w9, w8
   13de8:	cmp	x20, x10
   13dec:	str	w8, [x19, #4]
   13df0:	and	x8, x20, #0x1
   13df4:	b.hi	13e1c <__gmpz_bin_ui@@Base+0x450>  // b.pmore
   13df8:	add	x8, x8, x20
   13dfc:	lsr	x9, x20, #1
   13e00:	mov	x0, x19
   13e04:	ldp	x20, x19, [sp, #48]
   13e08:	ldp	x22, x21, [sp, #32]
   13e0c:	ldp	x29, x30, [sp, #16]
   13e10:	mul	x1, x8, x9
   13e14:	add	sp, sp, #0x40
   13e18:	b	13e64 <__gmpz_bin_ui@@Base+0x498>
   13e1c:	add	x1, x8, x20
   13e20:	mov	x0, sp
   13e24:	bl	ce70 <__gmpz_init_set_ui@plt>
   13e28:	lsr	x2, x20, #1
   13e2c:	mov	x0, sp
   13e30:	mov	x1, sp
   13e34:	bl	c5e0 <__gmpz_mul_ui@plt>
   13e38:	mov	x2, sp
   13e3c:	mov	x0, x19
   13e40:	mov	x1, x19
   13e44:	bl	c270 <__gmpz_sub@plt>
   13e48:	mov	x0, sp
   13e4c:	bl	cb70 <__gmpz_clear@plt>
   13e50:	ldp	x20, x19, [sp, #48]
   13e54:	ldp	x22, x21, [sp, #32]
   13e58:	ldp	x29, x30, [sp, #16]
   13e5c:	add	sp, sp, #0x40
   13e60:	ret
   13e64:	ldr	x8, [x0, #8]
   13e68:	ldr	x9, [x8]
   13e6c:	subs	x9, x9, x1
   13e70:	str	x9, [x8]
   13e74:	b.cs	13e8c <__gmpz_bin_ui@@Base+0x4c0>  // b.hs, b.nlast
   13e78:	add	x9, x8, #0x8
   13e7c:	ldr	x10, [x9]
   13e80:	sub	x11, x10, #0x1
   13e84:	str	x11, [x9], #8
   13e88:	cbz	x10, 13e7c <__gmpz_bin_ui@@Base+0x4b0>
   13e8c:	ldr	w9, [x0, #4]
   13e90:	sub	w10, w9, #0x1
   13e94:	ldr	x8, [x8, w10, sxtw #3]
   13e98:	cmp	x8, #0x0
   13e9c:	cset	w8, eq  // eq = none
   13ea0:	sub	w8, w9, w8
   13ea4:	str	w8, [x0, #4]
   13ea8:	ret
   13eac:	sub	sp, sp, #0x60
   13eb0:	sub	x8, x3, x4
   13eb4:	stp	x26, x25, [sp, #32]
   13eb8:	stp	x22, x21, [sp, #64]
   13ebc:	stp	x20, x19, [sp, #80]
   13ec0:	mov	x19, x4
   13ec4:	mov	x25, x3
   13ec8:	mov	x21, x2
   13ecc:	mov	x22, x1
   13ed0:	cmp	x8, #0x4
   13ed4:	mov	x20, x0
   13ed8:	stp	x29, x30, [sp, #16]
   13edc:	stp	x24, x23, [sp, #48]
   13ee0:	add	x29, sp, #0x10
   13ee4:	b.hi	13f38 <__gmpz_bin_ui@@Base+0x56c>  // b.pmore
   13ee8:	lsl	x23, x25, #2
   13eec:	add	x1, x23, #0x2
   13ef0:	mov	x0, x22
   13ef4:	bl	13d20 <__gmpz_bin_ui@@Base+0x354>
   13ef8:	mov	x0, x21
   13efc:	mov	x1, x22
   13f00:	mov	x2, x23
   13f04:	bl	d340 <__gmpz_addmul_ui@plt>
   13f08:	mov	x0, x21
   13f0c:	mov	x1, x25
   13f10:	bl	13e64 <__gmpz_bin_ui@@Base+0x498>
   13f14:	mov	x0, x20
   13f18:	mov	x1, x20
   13f1c:	mov	x2, x21
   13f20:	bl	c4d0 <__gmpz_mul@plt>
   13f24:	sub	x25, x25, #0x1
   13f28:	cmp	x25, x19
   13f2c:	sub	x23, x23, #0x4
   13f30:	b.hi	13eec <__gmpz_bin_ui@@Base+0x520>  // b.pmore
   13f34:	b	13fec <__gmpz_bin_ui@@Base+0x620>
   13f38:	add	x8, x19, x25
   13f3c:	lsr	x24, x8, #1
   13f40:	add	x26, x24, #0x1
   13f44:	mov	x0, x20
   13f48:	mov	x1, x22
   13f4c:	mov	x2, x21
   13f50:	mov	x3, x25
   13f54:	mov	x4, x26
   13f58:	mov	x23, x5
   13f5c:	bl	13eac <__gmpz_bin_ui@@Base+0x4e0>
   13f60:	mov	w1, #0x2                   	// #2
   13f64:	bfi	x1, x26, #2, #62
   13f68:	mov	x0, x22
   13f6c:	lsl	x25, x26, #2
   13f70:	bl	13d20 <__gmpz_bin_ui@@Base+0x354>
   13f74:	mov	x0, x21
   13f78:	mov	x1, x22
   13f7c:	mov	x2, x25
   13f80:	bl	d340 <__gmpz_addmul_ui@plt>
   13f84:	mov	x0, x21
   13f88:	mov	x1, x26
   13f8c:	bl	13e64 <__gmpz_bin_ui@@Base+0x498>
   13f90:	cbz	x23, 13fa8 <__gmpz_bin_ui@@Base+0x5dc>
   13f94:	mov	x0, x23
   13f98:	mov	x1, x21
   13f9c:	str	wzr, [sp]
   13fa0:	bl	c440 <__gmpz_set@plt>
   13fa4:	b	13fb8 <__gmpz_bin_ui@@Base+0x5ec>
   13fa8:	mov	x0, sp
   13fac:	mov	x1, x21
   13fb0:	mov	x23, sp
   13fb4:	bl	bf90 <__gmpz_init_set@plt>
   13fb8:	mov	x0, x23
   13fbc:	mov	x1, x22
   13fc0:	mov	x2, x21
   13fc4:	mov	x3, x24
   13fc8:	mov	x4, x19
   13fcc:	mov	x5, xzr
   13fd0:	bl	13eac <__gmpz_bin_ui@@Base+0x4e0>
   13fd4:	mov	x0, x20
   13fd8:	mov	x1, x20
   13fdc:	mov	x2, x23
   13fe0:	bl	c4d0 <__gmpz_mul@plt>
   13fe4:	mov	x0, sp
   13fe8:	bl	cb70 <__gmpz_clear@plt>
   13fec:	ldp	x20, x19, [sp, #80]
   13ff0:	ldp	x22, x21, [sp, #64]
   13ff4:	ldp	x24, x23, [sp, #48]
   13ff8:	ldp	x26, x25, [sp, #32]
   13ffc:	ldp	x29, x30, [sp, #16]
   14000:	add	sp, sp, #0x60
   14004:	ret

0000000000014008 <__gmpz_bin_uiui@@Base>:
   14008:	stp	x29, x30, [sp, #-32]!
   1400c:	stp	x20, x19, [sp, #16]
   14010:	subs	x8, x1, x2
   14014:	mov	x19, x0
   14018:	mov	x29, sp
   1401c:	b.cc	140f0 <__gmpz_bin_uiui@@Base+0xe8>  // b.lo, b.ul, b.last
   14020:	cmp	x8, x2
   14024:	csel	x2, x2, x8, hi  // hi = pmore
   14028:	cmp	x2, #0x1
   1402c:	b.hi	14050 <__gmpz_bin_uiui@@Base+0x48>  // b.pmore
   14030:	ldr	w8, [x19]
   14034:	cmp	x2, #0x0
   14038:	csinc	x20, x1, xzr, ne  // ne = any
   1403c:	cmp	w8, #0x0
   14040:	b.le	140f8 <__gmpz_bin_uiui@@Base+0xf0>
   14044:	ldr	x0, [x19, #8]
   14048:	str	x20, [x0]
   1404c:	b	14078 <__gmpz_bin_uiui@@Base+0x70>
   14050:	cmp	x1, #0x43
   14054:	b.hi	1408c <__gmpz_bin_uiui@@Base+0x84>  // b.pmore
   14058:	mov	w0, w1
   1405c:	mov	w1, w2
   14060:	bl	14124 <__gmpz_bin_uiui@@Base+0x11c>
   14064:	ldr	w8, [x19]
   14068:	cmp	w8, #0x0
   1406c:	b.le	14108 <__gmpz_bin_uiui@@Base+0x100>
   14070:	ldr	x8, [x19, #8]
   14074:	str	x0, [x8]
   14078:	mov	w8, #0x1                   	// #1
   1407c:	str	w8, [x19, #4]
   14080:	ldp	x20, x19, [sp, #16]
   14084:	ldp	x29, x30, [sp], #32
   14088:	ret
   1408c:	cmp	x2, #0x19
   14090:	b.hi	140a4 <__gmpz_bin_uiui@@Base+0x9c>  // b.pmore
   14094:	mov	x0, x19
   14098:	ldp	x20, x19, [sp, #16]
   1409c:	ldp	x29, x30, [sp], #32
   140a0:	b	14190 <__gmpz_bin_uiui@@Base+0x188>
   140a4:	cmp	x2, #0x46
   140a8:	b.hi	140bc <__gmpz_bin_uiui@@Base+0xb4>  // b.pmore
   140ac:	mov	x0, x19
   140b0:	ldp	x20, x19, [sp, #16]
   140b4:	ldp	x29, x30, [sp], #32
   140b8:	b	143b0 <__gmpz_bin_uiui@@Base+0x3a8>
   140bc:	cmp	x2, #0x200
   140c0:	b.cc	140e0 <__gmpz_bin_uiui@@Base+0xd8>  // b.lo, b.ul, b.last
   140c4:	lsr	x8, x1, #4
   140c8:	cmp	x2, x8
   140cc:	b.ls	140e0 <__gmpz_bin_uiui@@Base+0xd8>  // b.plast
   140d0:	mov	x0, x19
   140d4:	ldp	x20, x19, [sp, #16]
   140d8:	ldp	x29, x30, [sp], #32
   140dc:	b	1451c <__gmpz_bin_uiui@@Base+0x514>
   140e0:	mov	x0, x19
   140e4:	ldp	x20, x19, [sp, #16]
   140e8:	ldp	x29, x30, [sp], #32
   140ec:	b	149c0 <__gmpz_bin_uiui@@Base+0x9b8>
   140f0:	str	wzr, [x19, #4]
   140f4:	b	14080 <__gmpz_bin_uiui@@Base+0x78>
   140f8:	mov	w1, #0x1                   	// #1
   140fc:	mov	x0, x19
   14100:	bl	c090 <__gmpz_realloc@plt>
   14104:	b	14048 <__gmpz_bin_uiui@@Base+0x40>
   14108:	mov	w1, #0x1                   	// #1
   1410c:	mov	x20, x0
   14110:	mov	x0, x19
   14114:	bl	c090 <__gmpz_realloc@plt>
   14118:	mov	x8, x0
   1411c:	mov	x0, x20
   14120:	b	14074 <__gmpz_bin_uiui@@Base+0x6c>
   14124:	adrp	x10, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
   14128:	sub	w11, w0, w1
   1412c:	sub	w9, w1, #0x2
   14130:	add	x10, x10, #0xe28
   14134:	sub	w13, w11, #0x2
   14138:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1413c:	ldr	x9, [x10, w9, uxtw #3]
   14140:	ldr	x10, [x10, w13, uxtw #3]
   14144:	adrp	x13, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14148:	ldr	x8, [x8, #3848]
   1414c:	ldr	x13, [x13, #3992]
   14150:	lsr	w12, w0, #1
   14154:	lsr	w14, w1, #1
   14158:	sub	w12, w12, #0x1
   1415c:	sub	w14, w14, #0x1
   14160:	lsr	w11, w11, #1
   14164:	ldr	x8, [x8, w0, uxtw #3]
   14168:	ldrb	w12, [x13, w12, uxtw]
   1416c:	ldrb	w14, [x13, w14, uxtw]
   14170:	sub	w11, w11, #0x1
   14174:	ldrb	w11, [x13, w11, uxtw]
   14178:	mul	x8, x9, x8
   1417c:	sub	w9, w12, w14
   14180:	mul	x8, x8, x10
   14184:	sub	w9, w9, w11
   14188:	lsl	x0, x8, x9
   1418c:	ret
   14190:	sub	sp, sp, #0x70
   14194:	stp	x29, x30, [sp, #16]
   14198:	stp	x28, x27, [sp, #32]
   1419c:	stp	x26, x25, [sp, #48]
   141a0:	stp	x24, x23, [sp, #64]
   141a4:	stp	x22, x21, [sp, #80]
   141a8:	stp	x20, x19, [sp, #96]
   141ac:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   141b0:	ldr	x9, [x9, #3880]
   141b4:	mov	x20, x2
   141b8:	mov	x21, x0
   141bc:	mov	w8, #0x9                   	// #9
   141c0:	add	x29, sp, #0x10
   141c4:	sub	w10, w8, #0x2
   141c8:	ldr	x10, [x9, w10, uxtw #3]
   141cc:	sub	w8, w8, #0x1
   141d0:	cmp	x10, x1
   141d4:	b.cc	141c4 <__gmpz_bin_uiui@@Base+0x1bc>  // b.lo, b.ul, b.last
   141d8:	adrp	x10, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   141dc:	ldr	x10, [x10, #3992]
   141e0:	cmp	w8, #0x8
   141e4:	mov	w9, #0x8                   	// #8
   141e8:	csel	w26, w8, w9, cc  // cc = lo, ul, last
   141ec:	add	x8, x10, x20, lsr #1
   141f0:	ldurb	w24, [x8, #-1]
   141f4:	sub	x8, x1, x20
   141f8:	cmp	x26, x20
   141fc:	add	x22, x8, #0x1
   14200:	b.cs	14314 <__gmpz_bin_uiui@@Base+0x30c>  // b.hs, b.nlast
   14204:	clz	x8, x1
   14208:	mov	w9, #0x40                  	// #64
   1420c:	sub	x8, x9, x8
   14210:	ldrsw	x9, [x21]
   14214:	mul	x8, x8, x20
   14218:	lsr	x8, x8, #6
   1421c:	add	x1, x8, #0x3
   14220:	cmp	x1, x9
   14224:	str	x21, [sp, #8]
   14228:	b.gt	14390 <__gmpz_bin_uiui@@Base+0x388>
   1422c:	ldr	x21, [x21, #8]
   14230:	adrp	x27, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14234:	sub	w19, w26, #0x1
   14238:	add	x27, x27, #0x9a0
   1423c:	ldr	x8, [x27, w19, uxtw #3]
   14240:	mov	x0, x22
   14244:	blr	x8
   14248:	adrp	x28, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   1424c:	add	x28, x28, #0x1af
   14250:	ldrb	w8, [x28, w19, uxtw]
   14254:	add	x23, x22, x26
   14258:	sub	w19, w20, w26
   1425c:	mov	w2, #0x1                   	// #1
   14260:	sub	w22, w24, w8
   14264:	str	x0, [x21]
   14268:	cmp	w26, w19
   1426c:	csel	w26, w26, w19, cc  // cc = lo, ul, last
   14270:	sub	w25, w26, #0x1
   14274:	ldr	x8, [x27, w25, uxtw #3]
   14278:	mov	x0, x23
   1427c:	mov	x24, x2
   14280:	blr	x8
   14284:	ldrb	w8, [x28, w25, uxtw]
   14288:	mov	x3, x0
   1428c:	mov	x0, x21
   14290:	mov	x1, x21
   14294:	mov	x2, x24
   14298:	add	x23, x23, x26
   1429c:	sub	w22, w22, w8
   142a0:	bl	d4b0 <__gmpn_mul_1@plt>
   142a4:	cmp	x0, #0x0
   142a8:	cinc	x2, x24, ne  // ne = any
   142ac:	subs	w19, w19, w26
   142b0:	str	x0, [x21, x24, lsl #3]
   142b4:	b.ne	14268 <__gmpz_bin_uiui@@Base+0x260>  // b.any
   142b8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   142bc:	ldr	x8, [x8, #3848]
   142c0:	adrp	x9, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
   142c4:	add	x9, x9, #0xe28
   142c8:	mov	x25, x0
   142cc:	ldr	x3, [x8, x20, lsl #3]
   142d0:	add	x8, x9, x20, lsl #3
   142d4:	ldur	x4, [x8, #-16]
   142d8:	mov	x0, x21
   142dc:	mov	x1, x21
   142e0:	mov	w5, w22
   142e4:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   142e8:	cmp	x25, #0x0
   142ec:	cinc	x9, x24, ne  // ne = any
   142f0:	add	x9, x21, x9, lsl #3
   142f4:	ldr	x21, [sp, #8]
   142f8:	cinc	w8, w24, ne  // ne = any
   142fc:	add	w8, w8, #0x1
   14300:	sub	x9, x9, #0x8
   14304:	ldr	x10, [x9], #-8
   14308:	sub	w8, w8, #0x1
   1430c:	cbz	x10, 14304 <__gmpz_bin_uiui@@Base+0x2fc>
   14310:	b	1436c <__gmpz_bin_uiui@@Base+0x364>
   14314:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14318:	sub	x19, x20, #0x1
   1431c:	add	x8, x8, #0x9a0
   14320:	ldr	x8, [x8, x19, lsl #3]
   14324:	mov	x0, x22
   14328:	blr	x8
   1432c:	adrp	x8, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
   14330:	add	x8, x8, #0xe28
   14334:	adrp	x9, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   14338:	add	x9, x9, #0x1af
   1433c:	add	x8, x8, x20, lsl #3
   14340:	ldrb	w9, [x9, x19]
   14344:	ldur	x8, [x8, #-16]
   14348:	ldr	w10, [x21]
   1434c:	sub	w9, w24, w9
   14350:	mul	x8, x8, x0
   14354:	cmp	w10, #0x0
   14358:	lsr	x19, x8, x9
   1435c:	b.le	143a0 <__gmpz_bin_uiui@@Base+0x398>
   14360:	ldr	x0, [x21, #8]
   14364:	str	x19, [x0]
   14368:	mov	w8, #0x1                   	// #1
   1436c:	str	w8, [x21, #4]
   14370:	ldp	x20, x19, [sp, #96]
   14374:	ldp	x22, x21, [sp, #80]
   14378:	ldp	x24, x23, [sp, #64]
   1437c:	ldp	x26, x25, [sp, #48]
   14380:	ldp	x28, x27, [sp, #32]
   14384:	ldp	x29, x30, [sp, #16]
   14388:	add	sp, sp, #0x70
   1438c:	ret
   14390:	mov	x0, x21
   14394:	bl	c090 <__gmpz_realloc@plt>
   14398:	mov	x21, x0
   1439c:	b	14230 <__gmpz_bin_uiui@@Base+0x228>
   143a0:	mov	w1, #0x1                   	// #1
   143a4:	mov	x0, x21
   143a8:	bl	c090 <__gmpz_realloc@plt>
   143ac:	b	14364 <__gmpz_bin_uiui@@Base+0x35c>
   143b0:	sub	sp, sp, #0x190
   143b4:	stp	x20, x19, [sp, #384]
   143b8:	lsr	x20, x2, #1
   143bc:	stp	x22, x21, [sp, #368]
   143c0:	mov	x21, x2
   143c4:	mov	x22, x1
   143c8:	mov	x19, x0
   143cc:	cmp	x2, #0x33
   143d0:	mov	x2, x20
   143d4:	stp	x29, x30, [sp, #320]
   143d8:	str	x28, [sp, #336]
   143dc:	stp	x24, x23, [sp, #352]
   143e0:	add	x29, sp, #0x140
   143e4:	b.hi	143f0 <__gmpz_bin_uiui@@Base+0x3e8>  // b.pmore
   143e8:	bl	14190 <__gmpz_bin_uiui@@Base+0x188>
   143ec:	b	143f4 <__gmpz_bin_uiui@@Base+0x3ec>
   143f0:	bl	143b0 <__gmpz_bin_uiui@@Base+0x3a8>
   143f4:	sub	x23, x22, x20
   143f8:	cmp	x23, #0x43
   143fc:	sub	x21, x21, x20
   14400:	b.hi	14448 <__gmpz_bin_uiui@@Base+0x440>  // b.pmore
   14404:	ldp	w8, w24, [x19]
   14408:	sxtw	x24, w24
   1440c:	cmp	w24, w8
   14410:	b.ge	14508 <__gmpz_bin_uiui@@Base+0x500>  // b.tcont
   14414:	ldr	x22, [x19, #8]
   14418:	mov	w0, w23
   1441c:	mov	w1, w21
   14420:	bl	14124 <__gmpz_bin_uiui@@Base+0x11c>
   14424:	mov	x3, x0
   14428:	mov	x0, x22
   1442c:	mov	x1, x22
   14430:	mov	x2, x24
   14434:	bl	d4b0 <__gmpn_mul_1@plt>
   14438:	cmp	x0, #0x0
   1443c:	str	x0, [x22, x24, lsl #3]
   14440:	cinc	x23, x24, ne  // ne = any
   14444:	b	14490 <__gmpz_bin_uiui@@Base+0x488>
   14448:	mov	w8, #0x26                  	// #38
   1444c:	add	x9, sp, #0x10
   14450:	cmp	x21, #0x19
   14454:	mov	x0, sp
   14458:	mov	x1, x23
   1445c:	mov	x2, x21
   14460:	str	w8, [sp]
   14464:	str	x9, [sp, #8]
   14468:	b.hi	14474 <__gmpz_bin_uiui@@Base+0x46c>  // b.pmore
   1446c:	bl	14190 <__gmpz_bin_uiui@@Base+0x188>
   14470:	b	14478 <__gmpz_bin_uiui@@Base+0x470>
   14474:	bl	143b0 <__gmpz_bin_uiui@@Base+0x3a8>
   14478:	mov	x2, sp
   1447c:	mov	x0, x19
   14480:	mov	x1, x19
   14484:	bl	c4d0 <__gmpz_mul@plt>
   14488:	ldr	x22, [x19, #8]
   1448c:	ldrsw	x23, [x19, #4]
   14490:	adrp	x9, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   14494:	adrp	x11, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   14498:	sub	x8, x21, #0xd
   1449c:	add	x9, x9, #0x28
   144a0:	adrp	x10, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   144a4:	add	x11, x11, #0x198
   144a8:	add	x10, x10, #0xe0
   144ac:	ldr	x3, [x9, x8, lsl #3]
   144b0:	ldrb	w9, [x11, x8]
   144b4:	ldr	x4, [x10, x8, lsl #3]
   144b8:	cmp	x21, x20
   144bc:	cset	w8, ne  // ne = any
   144c0:	sub	w5, w9, w8
   144c4:	mov	x0, x22
   144c8:	mov	x1, x22
   144cc:	mov	x2, x23
   144d0:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   144d4:	sub	x8, x22, #0x8
   144d8:	ldr	x9, [x8, x23, lsl #3]
   144dc:	sub	x23, x23, #0x1
   144e0:	cbz	x9, 144d8 <__gmpz_bin_uiui@@Base+0x4d0>
   144e4:	add	w8, w23, #0x1
   144e8:	str	w8, [x19, #4]
   144ec:	ldp	x20, x19, [sp, #384]
   144f0:	ldp	x22, x21, [sp, #368]
   144f4:	ldp	x24, x23, [sp, #352]
   144f8:	ldr	x28, [sp, #336]
   144fc:	ldp	x29, x30, [sp, #320]
   14500:	add	sp, sp, #0x190
   14504:	ret
   14508:	add	x1, x24, #0x1
   1450c:	mov	x0, x19
   14510:	bl	c090 <__gmpz_realloc@plt>
   14514:	mov	x22, x0
   14518:	b	14418 <__gmpz_bin_uiui@@Base+0x410>
   1451c:	stp	x29, x30, [sp, #-64]!
   14520:	sub	x8, x1, #0x5
   14524:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   14528:	movk	x9, #0xaaab
   1452c:	orr	x8, x8, #0x1
   14530:	str	x23, [sp, #16]
   14534:	umulh	x23, x8, x9
   14538:	lsr	x9, x23, #4
   1453c:	lsr	x8, x8, #11
   14540:	and	x9, x9, #0xffffffffffffff8
   14544:	stp	x22, x21, [sp, #32]
   14548:	stp	x20, x19, [sp, #48]
   1454c:	mov	x29, sp
   14550:	mov	x21, x2
   14554:	mov	x22, x1
   14558:	mov	x19, x0
   1455c:	cmp	x8, #0x17c
   14560:	add	x1, x9, #0x8
   14564:	str	xzr, [x29, #24]
   14568:	b.hi	14960 <__gmpz_bin_uiui@@Base+0x958>  // b.pmore
   1456c:	add	x9, x1, #0xf
   14570:	mov	x8, sp
   14574:	and	x9, x9, #0x3ffffffffffffff0
   14578:	sub	x20, x8, x9
   1457c:	mov	sp, x20
   14580:	mov	x0, x20
   14584:	mov	x1, x22
   14588:	lsr	x23, x23, #1
   1458c:	bl	d220 <__gmp_primesieve@plt>
   14590:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14594:	ldr	x8, [x8, #3880]
   14598:	mov	w10, #0x9                   	// #9
   1459c:	sub	w9, w10, #0x2
   145a0:	ldr	x9, [x8, w9, uxtw #3]
   145a4:	sub	w10, w10, #0x1
   145a8:	cmp	x9, x22
   145ac:	b.cc	1459c <__gmpz_bin_uiui@@Base+0x594>  // b.lo, b.ul, b.last
   145b0:	add	x9, x0, #0x1
   145b4:	mov	w10, w10
   145b8:	udiv	x10, x9, x10
   145bc:	lsl	x10, x10, #3
   145c0:	add	x10, x10, #0x8
   145c4:	mov	w11, #0x9                   	// #9
   145c8:	sub	w12, w11, #0x2
   145cc:	ldr	x12, [x8, w12, uxtw #3]
   145d0:	sub	w11, w11, #0x1
   145d4:	cmp	x12, x22
   145d8:	b.cc	145c8 <__gmpz_bin_uiui@@Base+0x5c0>  // b.lo, b.ul, b.last
   145dc:	mov	w8, w11
   145e0:	udiv	x8, x9, x8
   145e4:	mov	w11, #0x7f00                	// #32512
   145e8:	lsl	x8, x8, #3
   145ec:	cmp	x10, x11
   145f0:	add	x1, x8, #0x8
   145f4:	b.hi	14970 <__gmpz_bin_uiui@@Base+0x968>  // b.pmore
   145f8:	add	x9, x1, #0xf
   145fc:	mov	x8, sp
   14600:	and	x9, x9, #0xfffffffffffffff0
   14604:	sub	x1, x8, x9
   14608:	mov	sp, x1
   1460c:	lsr	x9, x21, #1
   14610:	and	x9, x9, #0x5555555555555555
   14614:	lsr	x12, x22, #1
   14618:	sub	x9, x21, x9
   1461c:	mov	x8, #0xffffffffffffffff    	// #-1
   14620:	sub	x10, x22, x21
   14624:	and	x13, x12, #0x5555555555555555
   14628:	lsr	x14, x9, #2
   1462c:	udiv	x11, x8, x22
   14630:	lsr	x8, x10, #1
   14634:	sub	x13, x22, x13
   14638:	and	x9, x9, #0x3333333333333333
   1463c:	and	x14, x14, #0x3333333333333333
   14640:	and	x8, x8, #0x5555555555555555
   14644:	add	x9, x14, x9
   14648:	lsr	x14, x13, #2
   1464c:	sub	x8, x10, x8
   14650:	and	x13, x13, #0x3333333333333333
   14654:	and	x14, x14, #0x3333333333333333
   14658:	add	x13, x14, x13
   1465c:	lsr	x14, x8, #2
   14660:	and	x8, x8, #0x3333333333333333
   14664:	and	x14, x14, #0x3333333333333333
   14668:	add	x9, x9, x9, lsr #4
   1466c:	add	x8, x14, x8
   14670:	add	x13, x13, x13, lsr #4
   14674:	and	x9, x9, #0xf0f0f0f0f0f0f0f
   14678:	add	x8, x8, x8, lsr #4
   1467c:	and	x13, x13, #0xf0f0f0f0f0f0f0f
   14680:	add	x9, x9, x9, lsr #8
   14684:	and	x8, x8, #0xf0f0f0f0f0f0f0f
   14688:	add	x13, x13, x13, lsr #8
   1468c:	add	x9, x9, x9, lsr #16
   14690:	add	x8, x8, x8, lsr #8
   14694:	add	x13, x13, x13, lsr #16
   14698:	lsr	x14, x9, #32
   1469c:	add	x8, x8, x8, lsr #16
   146a0:	add	w9, w14, w9
   146a4:	lsr	x14, x13, #32
   146a8:	add	w13, w14, w13
   146ac:	lsr	x14, x8, #32
   146b0:	and	x9, x9, #0xff
   146b4:	add	w8, w14, w8
   146b8:	sub	x9, x9, w13, uxtb
   146bc:	add	x8, x9, w8, uxtb
   146c0:	mov	w9, #0x1                   	// #1
   146c4:	lsl	x8, x9, x8
   146c8:	cmp	x8, x11
   146cc:	b.ls	146e0 <__gmpz_bin_uiui@@Base+0x6d8>  // b.plast
   146d0:	str	x8, [x1]
   146d4:	mov	w9, #0x1                   	// #1
   146d8:	mov	w8, #0x1                   	// #1
   146dc:	b	146e4 <__gmpz_bin_uiui@@Base+0x6dc>
   146e0:	mov	x9, xzr
   146e4:	mov	x13, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   146e8:	mov	x14, xzr
   146ec:	movk	x13, #0xaaab
   146f0:	mov	x16, x21
   146f4:	mov	x15, x22
   146f8:	umulh	x17, x16, x13
   146fc:	umulh	x18, x15, x13
   14700:	lsr	x0, x17, #1
   14704:	lsr	x2, x18, #1
   14708:	lsl	x3, x0, #1
   1470c:	add	x17, x3, x17, lsr #1
   14710:	lsl	x3, x2, #1
   14714:	add	x18, x3, x18, lsr #1
   14718:	sub	x16, x16, x17
   1471c:	add	x14, x16, x14
   14720:	sub	x17, x15, x18
   14724:	add	x16, x8, x8, lsl #1
   14728:	cmp	x17, x14
   1472c:	cset	w14, cc  // cc = lo, ul, last
   14730:	csel	x8, x16, x8, cc  // cc = lo, ul, last
   14734:	cmp	x15, #0x8
   14738:	mov	x16, x0
   1473c:	mov	x15, x2
   14740:	b.hi	146f8 <__gmpz_bin_uiui@@Base+0x6f0>  // b.pmore
   14744:	clz	x14, x22
   14748:	mov	w15, #0x40                  	// #64
   1474c:	sub	w14, w15, w14
   14750:	mov	w17, #0x1                   	// #1
   14754:	asr	w14, w14, #1
   14758:	lsl	x15, x17, x14
   1475c:	lsr	x14, x22, x14
   14760:	add	x14, x15, x14
   14764:	lsr	x14, x14, #1
   14768:	mov	x15, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   1476c:	sub	x14, x14, #0x5
   14770:	movk	x15, #0xaaab
   14774:	orr	x14, x14, #0x1
   14778:	umulh	x14, x14, x15
   1477c:	mov	x13, xzr
   14780:	mov	x16, xzr
   14784:	lsr	x18, x14, #1
   14788:	mov	w2, #0x7                   	// #7
   1478c:	ldr	x0, [x20, x13, lsl #3]
   14790:	mov	x14, x16
   14794:	mov	x15, x2
   14798:	add	x16, x16, #0x1
   1479c:	tst	x0, x17
   147a0:	b.ne	1480c <__gmpz_bin_uiui@@Base+0x804>  // b.any
   147a4:	add	x0, x16, x16, lsl #1
   147a8:	and	x2, x16, #0x1
   147ac:	cmp	x8, x11
   147b0:	add	x2, x0, x2
   147b4:	b.ls	147c8 <__gmpz_bin_uiui@@Base+0x7c0>  // b.plast
   147b8:	add	x0, x9, #0x1
   147bc:	str	x8, [x1, x9, lsl #3]
   147c0:	mov	x9, x0
   147c4:	mov	w8, #0x1                   	// #1
   147c8:	mov	x0, xzr
   147cc:	add	x2, x2, #0x1
   147d0:	mov	x3, x22
   147d4:	mov	x4, x21
   147d8:	udiv	x5, x4, x2
   147dc:	udiv	x6, x3, x2
   147e0:	msub	x4, x5, x2, x4
   147e4:	msub	x3, x6, x2, x3
   147e8:	add	x0, x4, x0
   147ec:	cmp	x3, x0
   147f0:	csinc	x3, x2, xzr, cc  // cc = lo, ul, last
   147f4:	cset	w0, cc  // cc = lo, ul, last
   147f8:	cmp	x6, x2
   147fc:	mul	x8, x3, x8
   14800:	mov	x3, x6
   14804:	mov	x4, x5
   14808:	b.cs	147d8 <__gmpz_bin_uiui@@Base+0x7d0>  // b.hs, b.nlast
   1480c:	ror	x0, x17, #63
   14810:	add	x13, x13, x17, lsr #63
   14814:	cmp	x14, x18
   14818:	add	x2, x15, #0x3
   1481c:	mov	x17, x0
   14820:	b.cc	1478c <__gmpz_bin_uiui@@Base+0x784>  // b.lo, b.ul, b.last
   14824:	sub	x12, x12, #0x5
   14828:	mov	x17, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   1482c:	orr	x12, x12, #0x1
   14830:	movk	x17, #0xaaab
   14834:	umulh	x12, x12, x17
   14838:	lsl	x16, x11, #1
   1483c:	lsr	x12, x12, #1
   14840:	ldr	x17, [x20, x13, lsl #3]
   14844:	tst	x17, x0
   14848:	b.ne	1488c <__gmpz_bin_uiui@@Base+0x884>  // b.any
   1484c:	and	x17, x14, #0x1
   14850:	add	x17, x15, x17
   14854:	udiv	x18, x22, x17
   14858:	udiv	x2, x21, x17
   1485c:	msub	x18, x18, x17, x22
   14860:	msub	x2, x2, x17, x21
   14864:	cmp	x18, x2
   14868:	b.cs	1488c <__gmpz_bin_uiui@@Base+0x884>  // b.hs, b.nlast
   1486c:	cmp	x8, x16
   14870:	b.ls	14888 <__gmpz_bin_uiui@@Base+0x880>  // b.plast
   14874:	add	x18, x9, #0x1
   14878:	str	x8, [x1, x9, lsl #3]
   1487c:	mov	x9, x18
   14880:	mov	x8, x17
   14884:	b	1488c <__gmpz_bin_uiui@@Base+0x884>
   14888:	mul	x8, x17, x8
   1488c:	add	x14, x14, #0x1
   14890:	add	x13, x13, x0, lsr #63
   14894:	ror	x0, x0, #63
   14898:	cmp	x14, x12
   1489c:	add	x15, x15, #0x3
   148a0:	b.cc	14840 <__gmpz_bin_uiui@@Base+0x838>  // b.lo, b.ul, b.last
   148a4:	sub	x10, x10, #0x5
   148a8:	mov	x12, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   148ac:	movk	x12, #0xaaab
   148b0:	orr	x10, x10, #0x1
   148b4:	umulh	x15, x10, x12
   148b8:	lsr	x12, x15, #1
   148bc:	mov	w13, #0x1                   	// #1
   148c0:	add	x14, x12, #0x1
   148c4:	lsl	x16, x12, #1
   148c8:	add	x10, x12, #0x2
   148cc:	lsr	x12, x14, #6
   148d0:	lsl	x14, x13, x14
   148d4:	add	x13, x16, x15, lsr #1
   148d8:	and	x11, x11, #0x7fffffffffffffff
   148dc:	add	x13, x13, #0x7
   148e0:	ldr	x15, [x20, x12, lsl #3]
   148e4:	tst	x15, x14
   148e8:	b.ne	14914 <__gmpz_bin_uiui@@Base+0x90c>  // b.any
   148ec:	and	x15, x10, #0x1
   148f0:	cmp	x8, x11
   148f4:	add	x15, x13, x15
   148f8:	b.ls	14910 <__gmpz_bin_uiui@@Base+0x908>  // b.plast
   148fc:	add	x16, x9, #0x1
   14900:	str	x8, [x1, x9, lsl #3]
   14904:	mov	x9, x16
   14908:	mov	x8, x15
   1490c:	b	14914 <__gmpz_bin_uiui@@Base+0x90c>
   14910:	mul	x8, x15, x8
   14914:	add	x12, x12, x14, lsr #63
   14918:	ror	x14, x14, #63
   1491c:	cmp	x10, x23
   14920:	add	x10, x10, #0x1
   14924:	add	x13, x13, #0x3
   14928:	b.ls	148e0 <__gmpz_bin_uiui@@Base+0x8d8>  // b.plast
   1492c:	cbz	x9, 14980 <__gmpz_bin_uiui@@Base+0x978>
   14930:	add	x2, x9, #0x1
   14934:	mov	x0, x19
   14938:	str	x8, [x1, x9, lsl #3]
   1493c:	bl	cd90 <__gmpz_prodlimbs@plt>
   14940:	ldr	x0, [x29, #24]
   14944:	cbnz	x0, 149a0 <__gmpz_bin_uiui@@Base+0x998>
   14948:	mov	sp, x29
   1494c:	ldp	x20, x19, [sp, #48]
   14950:	ldp	x22, x21, [sp, #32]
   14954:	ldr	x23, [sp, #16]
   14958:	ldp	x29, x30, [sp], #64
   1495c:	ret
   14960:	add	x0, x29, #0x18
   14964:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   14968:	mov	x20, x0
   1496c:	b	14580 <__gmpz_bin_uiui@@Base+0x578>
   14970:	add	x0, x29, #0x18
   14974:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   14978:	mov	x1, x0
   1497c:	b	1460c <__gmpz_bin_uiui@@Base+0x604>
   14980:	ldr	w9, [x19]
   14984:	cmp	w9, #0x0
   14988:	b.le	149a8 <__gmpz_bin_uiui@@Base+0x9a0>
   1498c:	ldr	x0, [x19, #8]
   14990:	str	x8, [x0]
   14994:	mov	w8, #0x1                   	// #1
   14998:	str	w8, [x19, #4]
   1499c:	b	14940 <__gmpz_bin_uiui@@Base+0x938>
   149a0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   149a4:	b	14948 <__gmpz_bin_uiui@@Base+0x940>
   149a8:	mov	w1, #0x1                   	// #1
   149ac:	mov	x0, x19
   149b0:	mov	x20, x8
   149b4:	bl	c090 <__gmpz_realloc@plt>
   149b8:	mov	x8, x20
   149bc:	b	14990 <__gmpz_bin_uiui@@Base+0x988>
   149c0:	stp	x29, x30, [sp, #-96]!
   149c4:	stp	x28, x27, [sp, #16]
   149c8:	stp	x26, x25, [sp, #32]
   149cc:	stp	x24, x23, [sp, #48]
   149d0:	stp	x22, x21, [sp, #64]
   149d4:	stp	x20, x19, [sp, #80]
   149d8:	mov	x29, sp
   149dc:	sub	sp, sp, #0x40
   149e0:	lsr	x8, x1, #6
   149e4:	lsl	x8, x8, #1
   149e8:	add	x8, x8, x1, lsr #6
   149ec:	add	x10, x8, #0x3
   149f0:	cmp	x8, #0x27
   149f4:	lsr	x8, x10, #1
   149f8:	mov	w9, #0x27                  	// #39
   149fc:	add	x8, x8, #0x13
   14a00:	csel	x8, x9, x8, cc  // cc = lo, ul, last
   14a04:	cmp	x8, x2
   14a08:	csel	x19, x8, x2, lt  // lt = tstop
   14a0c:	lsl	x8, x19, #3
   14a10:	mov	x21, x1
   14a14:	add	x1, x8, #0xb0
   14a18:	mov	w8, #0x7f00                	// #32512
   14a1c:	cmp	x1, x8
   14a20:	stur	x0, [x29, #-40]
   14a24:	stur	x2, [x29, #-24]
   14a28:	stur	xzr, [x29, #-8]
   14a2c:	b.hi	14df4 <__gmpz_bin_uiui@@Base+0xdec>  // b.pmore
   14a30:	add	x9, x1, #0xf
   14a34:	mov	x8, sp
   14a38:	and	x9, x9, #0xfffffffffffffff0
   14a3c:	sub	x20, x8, x9
   14a40:	mov	sp, x20
   14a44:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14a48:	ldr	x8, [x8, #3880]
   14a4c:	add	x9, x19, #0x1
   14a50:	mov	w11, #0x9                   	// #9
   14a54:	sub	w10, w11, #0x2
   14a58:	ldr	x10, [x8, w10, uxtw #3]
   14a5c:	sub	w11, w11, #0x1
   14a60:	cmp	x10, x21
   14a64:	b.cc	14a54 <__gmpz_bin_uiui@@Base+0xa4c>  // b.lo, b.ul, b.last
   14a68:	ldur	x10, [x29, #-24]
   14a6c:	add	x24, x20, x9, lsl #3
   14a70:	mov	w27, #0x9                   	// #9
   14a74:	stur	w11, [x29, #-28]
   14a78:	sub	w9, w27, #0x2
   14a7c:	ldr	x9, [x8, w9, uxtw #3]
   14a80:	sub	w27, w27, #0x1
   14a84:	cmp	x9, x10
   14a88:	b.cc	14a78 <__gmpz_bin_uiui@@Base+0xa70>  // b.lo, b.ul, b.last
   14a8c:	mov	x9, #0x41ef                	// #16879
   14a90:	movk	x9, #0x7ec2, lsl #16
   14a94:	sub	x11, x21, x10
   14a98:	movk	x9, #0x8186, lsl #32
   14a9c:	adrp	x22, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14aa0:	mov	w23, #0x1                   	// #1
   14aa4:	movk	x9, #0x3352, lsl #48
   14aa8:	mov	w8, #0x1a                  	// #26
   14aac:	add	x22, x22, #0x9a0
   14ab0:	stp	x11, x21, [x29, #-56]
   14ab4:	add	x25, x11, #0x1
   14ab8:	mov	w28, #0x1                   	// #1
   14abc:	mov	x21, x10
   14ac0:	str	x23, [x20]
   14ac4:	sub	x10, x21, x8
   14ac8:	add	x11, x10, #0x1
   14acc:	mov	w12, w27
   14ad0:	cmp	x11, w27, uxtw
   14ad4:	csinc	x19, x12, x10, hi  // hi = pmore
   14ad8:	str	x9, [x24]
   14adc:	cbz	x19, 14b58 <__gmpz_bin_uiui@@Base+0xb50>
   14ae0:	mov	w27, #0x1                   	// #1
   14ae4:	mov	x26, x8
   14ae8:	sub	w8, w19, #0x1
   14aec:	ldr	x8, [x22, w8, uxtw #3]
   14af0:	mov	x0, x26
   14af4:	blr	x8
   14af8:	rbit	x8, x0
   14afc:	clz	x8, x8
   14b00:	lsr	x3, x0, x8
   14b04:	mov	x0, x24
   14b08:	mov	x1, x24
   14b0c:	mov	x2, x27
   14b10:	and	x22, x19, #0xffffffff
   14b14:	add	x26, x26, w19, uxtw
   14b18:	bl	d4b0 <__gmpn_mul_1@plt>
   14b1c:	sub	x8, x21, x26
   14b20:	cmp	x0, #0x0
   14b24:	add	x9, x8, #0x1
   14b28:	str	x0, [x24, x27, lsl #3]
   14b2c:	cinc	x27, x27, ne  // ne = any
   14b30:	cmp	x22, x9
   14b34:	csinc	x19, x22, x8, cc  // cc = lo, ul, last
   14b38:	adrp	x22, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14b3c:	add	x22, x22, #0x9a0
   14b40:	cmp	x27, #0x13
   14b44:	b.hi	14b4c <__gmpz_bin_uiui@@Base+0xb44>  // b.pmore
   14b48:	cbnz	x19, 14ae8 <__gmpz_bin_uiui@@Base+0xae0>
   14b4c:	mov	w8, w19
   14b50:	stur	w19, [x29, #-12]
   14b54:	b	14b64 <__gmpz_bin_uiui@@Base+0xb5c>
   14b58:	stur	wzr, [x29, #-12]
   14b5c:	mov	x26, x8
   14b60:	mov	w27, #0x1                   	// #1
   14b64:	subs	w22, w26, w28
   14b68:	b.eq	14bc4 <__gmpz_bin_uiui@@Base+0xbbc>  // b.none
   14b6c:	ldur	w28, [x29, #-28]
   14b70:	cmp	w28, w22
   14b74:	csel	w21, w28, w22, cc  // cc = lo, ul, last
   14b78:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14b7c:	sub	w8, w21, #0x1
   14b80:	add	x9, x9, #0x9a0
   14b84:	ldr	x8, [x9, w8, uxtw #3]
   14b88:	mov	x0, x25
   14b8c:	blr	x8
   14b90:	rbit	x8, x0
   14b94:	clz	x8, x8
   14b98:	lsr	x3, x0, x8
   14b9c:	mov	x0, x20
   14ba0:	mov	x1, x20
   14ba4:	mov	x2, x23
   14ba8:	add	x25, x25, x21
   14bac:	bl	d4b0 <__gmpn_mul_1@plt>
   14bb0:	cmp	x0, #0x0
   14bb4:	str	x0, [x20, x23, lsl #3]
   14bb8:	cinc	x23, x23, ne  // ne = any
   14bbc:	subs	w22, w22, w21
   14bc0:	b.ne	14b70 <__gmpz_bin_uiui@@Base+0xb68>  // b.any
   14bc4:	ldr	x8, [x24]
   14bc8:	add	x9, x20, x23, lsl #3
   14bcc:	add	x10, x24, x27, lsl #3
   14bd0:	adrp	x13, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14bd4:	ldur	x9, [x9, #-8]
   14bd8:	ldur	x10, [x10, #-8]
   14bdc:	ldr	x13, [x13, #3952]
   14be0:	ubfx	x12, x8, #1, #7
   14be4:	sub	x11, x23, x27
   14be8:	cmp	x9, x10
   14bec:	ldrb	w12, [x13, x12]
   14bf0:	mov	w10, #0x2                   	// #2
   14bf4:	cinc	x23, x11, cs  // cs = hs, nlast
   14bf8:	cmp	x27, x23
   14bfc:	msub	x9, x8, x12, x10
   14c00:	mul	x9, x9, x12
   14c04:	msub	x10, x9, x8, x10
   14c08:	mul	x9, x9, x10
   14c0c:	orr	x10, xzr, #0xfffffffffffffffe
   14c10:	madd	x8, x9, x8, x10
   14c14:	csel	x4, x27, x23, lt  // lt = tstop
   14c18:	mul	x5, x8, x9
   14c1c:	mov	x0, x20
   14c20:	mov	x1, x20
   14c24:	mov	x2, x23
   14c28:	mov	x3, x24
   14c2c:	bl	c530 <__gmpn_sbpi1_bdiv_q@plt>
   14c30:	ldr	x10, [x20]
   14c34:	cbz	x10, 14c54 <__gmpz_bin_uiui@@Base+0xc4c>
   14c38:	ldur	x21, [x29, #-24]
   14c3c:	ldur	w27, [x29, #-12]
   14c40:	adrp	x22, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14c44:	mov	x8, x20
   14c48:	mov	x9, x23
   14c4c:	add	x22, x22, #0x9a0
   14c50:	b	14c80 <__gmpz_bin_uiui@@Base+0xc78>
   14c54:	ldur	x21, [x29, #-24]
   14c58:	ldur	w27, [x29, #-12]
   14c5c:	adrp	x22, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   14c60:	mov	x9, x23
   14c64:	mov	x8, x20
   14c68:	add	x22, x22, #0x9a0
   14c6c:	subs	x9, x9, #0x1
   14c70:	str	xzr, [x8]
   14c74:	b.eq	14c9c <__gmpz_bin_uiui@@Base+0xc94>  // b.none
   14c78:	ldr	x10, [x8, #8]!
   14c7c:	cbz	x10, 14c6c <__gmpz_bin_uiui@@Base+0xc64>
   14c80:	neg	x10, x10
   14c84:	subs	x2, x9, #0x1
   14c88:	str	x10, [x8]
   14c8c:	b.eq	14c9c <__gmpz_bin_uiui@@Base+0xc94>  // b.none
   14c90:	add	x0, x8, #0x8
   14c94:	mov	x1, x0
   14c98:	bl	c2a0 <__gmpn_com@plt>
   14c9c:	cbz	w27, 14cc8 <__gmpz_bin_uiui@@Base+0xcc0>
   14ca0:	sub	w8, w19, #0x1
   14ca4:	ldr	x8, [x22, w8, uxtw #3]
   14ca8:	mov	x0, x26
   14cac:	blr	x8
   14cb0:	rbit	x9, x0
   14cb4:	clz	x9, x9
   14cb8:	add	x8, x26, w19, uxtw
   14cbc:	lsr	x9, x0, x9
   14cc0:	mov	x28, x26
   14cc4:	b	14ac4 <__gmpz_bin_uiui@@Base+0xabc>
   14cc8:	ldp	x9, x11, [x29, #-56]
   14ccc:	lsr	x8, x9, #1
   14cd0:	and	x8, x8, #0x5555555555555555
   14cd4:	lsr	x10, x11, #1
   14cd8:	sub	x8, x9, x8
   14cdc:	lsr	x9, x21, #1
   14ce0:	and	x10, x10, #0x5555555555555555
   14ce4:	and	x9, x9, #0x5555555555555555
   14ce8:	sub	x10, x11, x10
   14cec:	lsr	x11, x8, #2
   14cf0:	sub	x9, x21, x9
   14cf4:	and	x8, x8, #0x3333333333333333
   14cf8:	and	x11, x11, #0x3333333333333333
   14cfc:	add	x8, x11, x8
   14d00:	lsr	x11, x9, #2
   14d04:	and	x9, x9, #0x3333333333333333
   14d08:	and	x11, x11, #0x3333333333333333
   14d0c:	add	x9, x11, x9
   14d10:	lsr	x11, x10, #2
   14d14:	and	x10, x10, #0x3333333333333333
   14d18:	and	x11, x11, #0x3333333333333333
   14d1c:	add	x8, x8, x8, lsr #4
   14d20:	add	x10, x11, x10
   14d24:	add	x9, x9, x9, lsr #4
   14d28:	and	x8, x8, #0xf0f0f0f0f0f0f0f
   14d2c:	add	x10, x10, x10, lsr #4
   14d30:	and	x9, x9, #0xf0f0f0f0f0f0f0f
   14d34:	add	x8, x8, x8, lsr #8
   14d38:	and	x10, x10, #0xf0f0f0f0f0f0f0f
   14d3c:	add	x9, x9, x9, lsr #8
   14d40:	add	x8, x8, x8, lsr #16
   14d44:	add	x10, x10, x10, lsr #8
   14d48:	add	x9, x9, x9, lsr #16
   14d4c:	lsr	x11, x8, #32
   14d50:	add	x10, x10, x10, lsr #16
   14d54:	add	w8, w11, w8
   14d58:	lsr	x11, x9, #32
   14d5c:	add	w9, w11, w9
   14d60:	lsr	x11, x10, #32
   14d64:	and	w9, w9, #0xff
   14d68:	add	w10, w11, w10
   14d6c:	sub	w9, w9, w10, uxtb
   14d70:	adds	w3, w9, w8, uxtb
   14d74:	b.eq	14d94 <__gmpz_bin_uiui@@Base+0xd8c>  // b.none
   14d78:	mov	x0, x20
   14d7c:	mov	x1, x20
   14d80:	mov	x2, x23
   14d84:	bl	c190 <__gmpn_lshift@plt>
   14d88:	cmp	x0, #0x0
   14d8c:	str	x0, [x20, x23, lsl #3]
   14d90:	cinc	x23, x23, ne  // ne = any
   14d94:	ldur	x19, [x29, #-40]
   14d98:	add	x8, x20, x23, lsl #3
   14d9c:	ldur	x8, [x8, #-8]
   14da0:	ldrsw	x9, [x19]
   14da4:	cmp	x8, #0x0
   14da8:	cset	w8, eq  // eq = none
   14dac:	sub	x21, x23, x8
   14db0:	cmp	x21, x9
   14db4:	b.gt	14e04 <__gmpz_bin_uiui@@Base+0xdfc>
   14db8:	ldr	x0, [x19, #8]
   14dbc:	mov	x1, x20
   14dc0:	mov	x2, x21
   14dc4:	str	w21, [x19, #4]
   14dc8:	bl	ca70 <__gmpn_copyi@plt>
   14dcc:	ldur	x0, [x29, #-8]
   14dd0:	cbnz	x0, 14e14 <__gmpz_bin_uiui@@Base+0xe0c>
   14dd4:	mov	sp, x29
   14dd8:	ldp	x20, x19, [sp, #80]
   14ddc:	ldp	x22, x21, [sp, #64]
   14de0:	ldp	x24, x23, [sp, #48]
   14de4:	ldp	x26, x25, [sp, #32]
   14de8:	ldp	x28, x27, [sp, #16]
   14dec:	ldp	x29, x30, [sp], #96
   14df0:	ret
   14df4:	sub	x0, x29, #0x8
   14df8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   14dfc:	mov	x20, x0
   14e00:	b	14a44 <__gmpz_bin_uiui@@Base+0xa3c>
   14e04:	mov	x0, x19
   14e08:	mov	x1, x21
   14e0c:	bl	c090 <__gmpz_realloc@plt>
   14e10:	b	14dbc <__gmpz_bin_uiui@@Base+0xdb4>
   14e14:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   14e18:	b	14dd4 <__gmpz_bin_uiui@@Base+0xdcc>
   14e1c:	ret
   14e20:	add	x9, x0, #0x1
   14e24:	orr	x8, x0, #0x1
   14e28:	lsr	x9, x9, #1
   14e2c:	mul	x0, x9, x8
   14e30:	ret
   14e34:	add	x8, x0, #0x1
   14e38:	mul	x8, x8, x0
   14e3c:	lsr	x8, x8, #1
   14e40:	add	x9, x0, #0x2
   14e44:	mul	x0, x8, x9
   14e48:	ret
   14e4c:	add	x8, x0, #0x3
   14e50:	mul	x8, x8, x0
   14e54:	lsr	x8, x8, #1
   14e58:	add	x9, x8, #0x1
   14e5c:	mul	x0, x9, x8
   14e60:	ret
   14e64:	add	x8, x0, #0x3
   14e68:	mul	x8, x8, x0
   14e6c:	add	x9, x0, #0x4
   14e70:	lsr	x8, x8, #1
   14e74:	mul	x9, x8, x9
   14e78:	add	x8, x8, #0x1
   14e7c:	mul	x0, x9, x8
   14e80:	ret
   14e84:	add	x8, x0, #0x5
   14e88:	mul	x8, x8, x0
   14e8c:	add	x9, x8, #0x5
   14e90:	mul	x9, x9, x9
   14e94:	lsr	x9, x9, #3
   14e98:	lsr	x8, x8, #1
   14e9c:	mul	x0, x9, x8
   14ea0:	ret
   14ea4:	add	x8, x0, #0x5
   14ea8:	mul	x8, x8, x0
   14eac:	add	x9, x0, #0x6
   14eb0:	add	x10, x8, #0x5
   14eb4:	mul	x8, x8, x9
   14eb8:	mul	x9, x10, x10
   14ebc:	lsr	x9, x9, #3
   14ec0:	lsr	x8, x8, #1
   14ec4:	mul	x0, x9, x8
   14ec8:	ret
   14ecc:	add	x8, x0, #0x7
   14ed0:	mul	x8, x8, x0
   14ed4:	add	x9, x8, #0xa
   14ed8:	mul	x9, x9, x8
   14edc:	add	x8, x8, x9, lsr #3
   14ee0:	lsr	x10, x9, #3
   14ee4:	add	x8, x8, #0x9
   14ee8:	mul	x0, x8, x10
   14eec:	ret

0000000000014ef0 <__gmpz_cdiv_q@@Base>:
   14ef0:	stp	x29, x30, [sp, #-64]!
   14ef4:	str	x23, [sp, #16]
   14ef8:	stp	x22, x21, [sp, #32]
   14efc:	stp	x20, x19, [sp, #48]
   14f00:	mov	x29, sp
   14f04:	sub	sp, sp, #0x10
   14f08:	ldrsw	x22, [x2, #4]
   14f0c:	ldr	w23, [x1, #4]
   14f10:	mov	x20, x2
   14f14:	mov	x21, x1
   14f18:	cmp	x22, #0x0
   14f1c:	cneg	x8, x22, mi  // mi = first
   14f20:	mov	x19, x0
   14f24:	cmp	x8, #0xfe0
   14f28:	lsl	x1, x8, #3
   14f2c:	str	xzr, [x29, #24]
   14f30:	stur	w8, [x29, #-16]
   14f34:	b.hi	14fa4 <__gmpz_cdiv_q@@Base+0xb4>  // b.pmore
   14f38:	add	x9, x1, #0xf
   14f3c:	mov	x8, sp
   14f40:	and	x9, x9, #0xfffffffffffffff0
   14f44:	sub	x0, x8, x9
   14f48:	mov	sp, x0
   14f4c:	stur	x0, [x29, #-8]
   14f50:	sub	x1, x29, #0x10
   14f54:	mov	x0, x19
   14f58:	mov	x2, x21
   14f5c:	mov	x3, x20
   14f60:	bl	c000 <__gmpz_tdiv_qr@plt>
   14f64:	eor	w8, w22, w23
   14f68:	tbnz	w8, #31, 14f84 <__gmpz_cdiv_q@@Base+0x94>
   14f6c:	ldur	w8, [x29, #-12]
   14f70:	cbz	w8, 14f84 <__gmpz_cdiv_q@@Base+0x94>
   14f74:	mov	w2, #0x1                   	// #1
   14f78:	mov	x0, x19
   14f7c:	mov	x1, x19
   14f80:	bl	c8d0 <__gmpz_add_ui@plt>
   14f84:	ldr	x0, [x29, #24]
   14f88:	cbnz	x0, 14fb0 <__gmpz_cdiv_q@@Base+0xc0>
   14f8c:	mov	sp, x29
   14f90:	ldp	x20, x19, [sp, #48]
   14f94:	ldp	x22, x21, [sp, #32]
   14f98:	ldr	x23, [sp, #16]
   14f9c:	ldp	x29, x30, [sp], #64
   14fa0:	ret
   14fa4:	add	x0, x29, #0x18
   14fa8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   14fac:	b	14f4c <__gmpz_cdiv_q@@Base+0x5c>
   14fb0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   14fb4:	b	14f8c <__gmpz_cdiv_q@@Base+0x9c>

0000000000014fb8 <__gmpz_cdiv_q_ui@@Base>:
   14fb8:	stp	x29, x30, [sp, #-64]!
   14fbc:	stp	x24, x23, [sp, #16]
   14fc0:	stp	x22, x21, [sp, #32]
   14fc4:	stp	x20, x19, [sp, #48]
   14fc8:	mov	x29, sp
   14fcc:	cbz	x2, 15088 <__gmpz_cdiv_q_ui@@Base+0xd0>
   14fd0:	ldrsw	x24, [x1, #4]
   14fd4:	mov	x23, x1
   14fd8:	mov	x19, x0
   14fdc:	cbz	w24, 15054 <__gmpz_cdiv_q_ui@@Base+0x9c>
   14fe0:	ldrsw	x8, [x19]
   14fe4:	cmp	w24, #0x0
   14fe8:	cneg	x21, x24, lt  // lt = tstop
   14fec:	mov	x20, x2
   14ff0:	cmp	x21, x8
   14ff4:	b.gt	15074 <__gmpz_cdiv_q_ui@@Base+0xbc>
   14ff8:	ldr	x22, [x19, #8]
   14ffc:	ldr	x2, [x23, #8]
   15000:	mov	x0, x22
   15004:	mov	x1, xzr
   15008:	mov	x3, x21
   1500c:	mov	x4, x20
   15010:	bl	cd20 <__gmpn_divrem_1@plt>
   15014:	tbnz	w24, #31, 15034 <__gmpz_cdiv_q_ui@@Base+0x7c>
   15018:	cbz	x0, 15034 <__gmpz_cdiv_q_ui@@Base+0x7c>
   1501c:	mov	x8, x22
   15020:	ldr	x9, [x8]
   15024:	adds	x9, x9, #0x1
   15028:	str	x9, [x8], #8
   1502c:	b.cs	15020 <__gmpz_cdiv_q_ui@@Base+0x68>  // b.hs, b.nlast
   15030:	sub	x0, x20, x0
   15034:	add	x8, x22, x21, lsl #3
   15038:	ldur	x8, [x8, #-8]
   1503c:	cmp	x8, #0x0
   15040:	cset	w8, eq  // eq = none
   15044:	sub	w8, w21, w8
   15048:	cmp	w24, #0x0
   1504c:	cneg	w8, w8, lt  // lt = tstop
   15050:	b	1505c <__gmpz_cdiv_q_ui@@Base+0xa4>
   15054:	mov	w8, wzr
   15058:	mov	x0, xzr
   1505c:	str	w8, [x19, #4]
   15060:	ldp	x20, x19, [sp, #48]
   15064:	ldp	x22, x21, [sp, #32]
   15068:	ldp	x24, x23, [sp, #16]
   1506c:	ldp	x29, x30, [sp], #64
   15070:	ret
   15074:	mov	x0, x19
   15078:	mov	x1, x21
   1507c:	bl	c090 <__gmpz_realloc@plt>
   15080:	mov	x22, x0
   15084:	b	14ffc <__gmpz_cdiv_q_ui@@Base+0x44>
   15088:	bl	bfe0 <__gmp_divide_by_zero@plt>

000000000001508c <__gmpz_cdiv_qr@@Base>:
   1508c:	stp	x29, x30, [sp, #-64]!
   15090:	str	x23, [sp, #16]
   15094:	stp	x22, x21, [sp, #32]
   15098:	stp	x20, x19, [sp, #48]
   1509c:	mov	x29, sp
   150a0:	sub	sp, sp, #0x10
   150a4:	ldrsw	x23, [x3, #4]
   150a8:	mov	x20, x3
   150ac:	mov	x22, x2
   150b0:	mov	x19, x1
   150b4:	mov	x21, x0
   150b8:	cmp	x0, x3
   150bc:	str	xzr, [x29, #24]
   150c0:	b.eq	150cc <__gmpz_cdiv_qr@@Base+0x40>  // b.none
   150c4:	cmp	x19, x20
   150c8:	b.ne	1510c <__gmpz_cdiv_qr@@Base+0x80>  // b.any
   150cc:	cmp	x23, #0x0
   150d0:	cneg	x8, x23, mi  // mi = first
   150d4:	cmp	x8, #0xfe0
   150d8:	lsl	x1, x8, #3
   150dc:	stur	w8, [x29, #-16]
   150e0:	b.hi	1517c <__gmpz_cdiv_qr@@Base+0xf0>  // b.pmore
   150e4:	add	x9, x1, #0xf
   150e8:	mov	x8, sp
   150ec:	and	x9, x9, #0xfffffffffffffff0
   150f0:	sub	x0, x8, x9
   150f4:	mov	sp, x0
   150f8:	stur	x0, [x29, #-8]
   150fc:	sub	x0, x29, #0x10
   15100:	mov	x1, x20
   15104:	bl	c440 <__gmpz_set@plt>
   15108:	sub	x20, x29, #0x10
   1510c:	ldr	w8, [x22, #4]
   15110:	mov	x0, x21
   15114:	mov	x1, x19
   15118:	mov	x2, x22
   1511c:	mov	x3, x20
   15120:	eor	w23, w8, w23
   15124:	bl	c000 <__gmpz_tdiv_qr@plt>
   15128:	tbnz	w23, #31, 15154 <__gmpz_cdiv_qr@@Base+0xc8>
   1512c:	ldr	w8, [x19, #4]
   15130:	cbz	w8, 15154 <__gmpz_cdiv_qr@@Base+0xc8>
   15134:	mov	w2, #0x1                   	// #1
   15138:	mov	x0, x21
   1513c:	mov	x1, x21
   15140:	bl	c8d0 <__gmpz_add_ui@plt>
   15144:	mov	x0, x19
   15148:	mov	x1, x19
   1514c:	mov	x2, x20
   15150:	bl	c270 <__gmpz_sub@plt>
   15154:	ldr	x0, [x29, #24]
   15158:	cbnz	x0, 15174 <__gmpz_cdiv_qr@@Base+0xe8>
   1515c:	mov	sp, x29
   15160:	ldp	x20, x19, [sp, #48]
   15164:	ldp	x22, x21, [sp, #32]
   15168:	ldr	x23, [sp, #16]
   1516c:	ldp	x29, x30, [sp], #64
   15170:	ret
   15174:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   15178:	b	1515c <__gmpz_cdiv_qr@@Base+0xd0>
   1517c:	add	x0, x29, #0x18
   15180:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   15184:	b	150f8 <__gmpz_cdiv_qr@@Base+0x6c>

0000000000015188 <__gmpz_cdiv_qr_ui@@Base>:
   15188:	stp	x29, x30, [sp, #-80]!
   1518c:	str	x25, [sp, #16]
   15190:	stp	x24, x23, [sp, #32]
   15194:	stp	x22, x21, [sp, #48]
   15198:	stp	x20, x19, [sp, #64]
   1519c:	mov	x29, sp
   151a0:	cbz	x3, 152ac <__gmpz_cdiv_qr_ui@@Base+0x124>
   151a4:	ldrsw	x25, [x2, #4]
   151a8:	mov	x22, x2
   151ac:	mov	x20, x1
   151b0:	mov	x19, x0
   151b4:	cbz	w25, 15230 <__gmpz_cdiv_qr_ui@@Base+0xa8>
   151b8:	ldrsw	x8, [x19]
   151bc:	cmp	w25, #0x0
   151c0:	cneg	x21, x25, lt  // lt = tstop
   151c4:	mov	x24, x3
   151c8:	cmp	x21, x8
   151cc:	b.gt	15288 <__gmpz_cdiv_qr_ui@@Base+0x100>
   151d0:	ldr	x23, [x19, #8]
   151d4:	ldr	x2, [x22, #8]
   151d8:	mov	x0, x23
   151dc:	mov	x1, xzr
   151e0:	mov	x3, x21
   151e4:	mov	x4, x24
   151e8:	bl	cd20 <__gmpn_divrem_1@plt>
   151ec:	mov	x22, x0
   151f0:	cbz	x0, 15244 <__gmpz_cdiv_qr_ui@@Base+0xbc>
   151f4:	tbnz	w25, #31, 15210 <__gmpz_cdiv_qr_ui@@Base+0x88>
   151f8:	mov	x8, x23
   151fc:	ldr	x9, [x8]
   15200:	adds	x9, x9, #0x1
   15204:	str	x9, [x8], #8
   15208:	b.cs	151fc <__gmpz_cdiv_qr_ui@@Base+0x74>  // b.hs, b.nlast
   1520c:	sub	x22, x24, x22
   15210:	ldr	w8, [x20]
   15214:	cmp	w8, #0x0
   15218:	b.le	1529c <__gmpz_cdiv_qr_ui@@Base+0x114>
   1521c:	ldr	x0, [x20, #8]
   15220:	cmp	x22, #0x0
   15224:	csetm	w8, ne  // ne = any
   15228:	str	x22, [x0]
   1522c:	b	15248 <__gmpz_cdiv_qr_ui@@Base+0xc0>
   15230:	mov	w8, wzr
   15234:	mov	x22, xzr
   15238:	str	wzr, [x19, #4]
   1523c:	mov	x19, x20
   15240:	b	15268 <__gmpz_cdiv_qr_ui@@Base+0xe0>
   15244:	mov	w8, wzr
   15248:	str	w8, [x20, #4]
   1524c:	add	x8, x23, x21, lsl #3
   15250:	ldur	x8, [x8, #-8]
   15254:	cmp	x8, #0x0
   15258:	cset	w8, eq  // eq = none
   1525c:	sub	w8, w21, w8
   15260:	cmp	w25, #0x0
   15264:	cneg	w8, w8, lt  // lt = tstop
   15268:	str	w8, [x19, #4]
   1526c:	mov	x0, x22
   15270:	ldp	x20, x19, [sp, #64]
   15274:	ldp	x22, x21, [sp, #48]
   15278:	ldp	x24, x23, [sp, #32]
   1527c:	ldr	x25, [sp, #16]
   15280:	ldp	x29, x30, [sp], #80
   15284:	ret
   15288:	mov	x0, x19
   1528c:	mov	x1, x21
   15290:	bl	c090 <__gmpz_realloc@plt>
   15294:	mov	x23, x0
   15298:	b	151d4 <__gmpz_cdiv_qr_ui@@Base+0x4c>
   1529c:	mov	w1, #0x1                   	// #1
   152a0:	mov	x0, x20
   152a4:	bl	c090 <__gmpz_realloc@plt>
   152a8:	b	15220 <__gmpz_cdiv_qr_ui@@Base+0x98>
   152ac:	bl	bfe0 <__gmp_divide_by_zero@plt>

00000000000152b0 <__gmpz_cdiv_r@@Base>:
   152b0:	stp	x29, x30, [sp, #-48]!
   152b4:	stp	x22, x21, [sp, #16]
   152b8:	stp	x20, x19, [sp, #32]
   152bc:	mov	x29, sp
   152c0:	sub	sp, sp, #0x20
   152c4:	ldrsw	x22, [x2, #4]
   152c8:	mov	x19, x2
   152cc:	mov	x21, x1
   152d0:	mov	x20, x0
   152d4:	cmp	x0, x2
   152d8:	stur	xzr, [x29, #-24]
   152dc:	b.ne	15320 <__gmpz_cdiv_r@@Base+0x70>  // b.any
   152e0:	cmp	x22, #0x0
   152e4:	cneg	x8, x22, mi  // mi = first
   152e8:	cmp	x8, #0xfe0
   152ec:	lsl	x1, x8, #3
   152f0:	stur	w8, [x29, #-16]
   152f4:	b.hi	15378 <__gmpz_cdiv_r@@Base+0xc8>  // b.pmore
   152f8:	add	x9, x1, #0xf
   152fc:	mov	x8, sp
   15300:	and	x9, x9, #0xfffffffffffffff0
   15304:	sub	x0, x8, x9
   15308:	mov	sp, x0
   1530c:	stur	x0, [x29, #-8]
   15310:	sub	x0, x29, #0x10
   15314:	mov	x1, x19
   15318:	bl	c440 <__gmpz_set@plt>
   1531c:	sub	x19, x29, #0x10
   15320:	mov	x0, x20
   15324:	mov	x1, x21
   15328:	mov	x2, x19
   1532c:	bl	caa0 <__gmpz_tdiv_r@plt>
   15330:	ldr	w8, [x21, #4]
   15334:	eor	w8, w8, w22
   15338:	tbnz	w8, #31, 15354 <__gmpz_cdiv_r@@Base+0xa4>
   1533c:	ldr	w8, [x20, #4]
   15340:	cbz	w8, 15354 <__gmpz_cdiv_r@@Base+0xa4>
   15344:	mov	x0, x20
   15348:	mov	x1, x20
   1534c:	mov	x2, x19
   15350:	bl	c270 <__gmpz_sub@plt>
   15354:	ldur	x0, [x29, #-24]
   15358:	cbnz	x0, 15370 <__gmpz_cdiv_r@@Base+0xc0>
   1535c:	mov	sp, x29
   15360:	ldp	x20, x19, [sp, #32]
   15364:	ldp	x22, x21, [sp, #16]
   15368:	ldp	x29, x30, [sp], #48
   1536c:	ret
   15370:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   15374:	b	1535c <__gmpz_cdiv_r@@Base+0xac>
   15378:	sub	x0, x29, #0x18
   1537c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   15380:	b	1530c <__gmpz_cdiv_r@@Base+0x5c>

0000000000015384 <__gmpz_cdiv_r_ui@@Base>:
   15384:	stp	x29, x30, [sp, #-48]!
   15388:	str	x21, [sp, #16]
   1538c:	stp	x20, x19, [sp, #32]
   15390:	mov	x29, sp
   15394:	cbz	x2, 15414 <__gmpz_cdiv_r_ui@@Base+0x90>
   15398:	ldrsw	x21, [x1, #4]
   1539c:	mov	x19, x0
   153a0:	cbz	w21, 153e4 <__gmpz_cdiv_r_ui@@Base+0x60>
   153a4:	ldr	x0, [x1, #8]
   153a8:	cmp	w21, #0x0
   153ac:	cneg	x1, x21, lt  // lt = tstop
   153b0:	mov	x20, x2
   153b4:	bl	c400 <__gmpn_mod_1@plt>
   153b8:	cbz	x0, 153e4 <__gmpz_cdiv_r_ui@@Base+0x60>
   153bc:	ldr	w8, [x19]
   153c0:	sub	x9, x20, x0
   153c4:	cmp	w21, #0x0
   153c8:	csel	x20, x9, x0, ge  // ge = tcont
   153cc:	cmp	w8, #0x0
   153d0:	b.le	15404 <__gmpz_cdiv_r_ui@@Base+0x80>
   153d4:	ldr	x0, [x19, #8]
   153d8:	mov	w8, #0xffffffff            	// #-1
   153dc:	str	x20, [x0]
   153e0:	b	153ec <__gmpz_cdiv_r_ui@@Base+0x68>
   153e4:	mov	w8, wzr
   153e8:	mov	x20, xzr
   153ec:	str	w8, [x19, #4]
   153f0:	mov	x0, x20
   153f4:	ldp	x20, x19, [sp, #32]
   153f8:	ldr	x21, [sp, #16]
   153fc:	ldp	x29, x30, [sp], #48
   15400:	ret
   15404:	mov	w1, #0x1                   	// #1
   15408:	mov	x0, x19
   1540c:	bl	c090 <__gmpz_realloc@plt>
   15410:	b	153d8 <__gmpz_cdiv_r_ui@@Base+0x54>
   15414:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000015418 <__gmpz_cdiv_ui@@Base>:
   15418:	stp	x29, x30, [sp, #-32]!
   1541c:	stp	x20, x19, [sp, #16]
   15420:	mov	x29, sp
   15424:	cbz	x1, 15470 <__gmpz_cdiv_ui@@Base+0x58>
   15428:	ldrsw	x20, [x0, #4]
   1542c:	cbz	w20, 15460 <__gmpz_cdiv_ui@@Base+0x48>
   15430:	ldr	x0, [x0, #8]
   15434:	mov	x19, x1
   15438:	cmp	w20, #0x0
   1543c:	cneg	x1, x20, lt  // lt = tstop
   15440:	mov	x2, x19
   15444:	bl	c400 <__gmpn_mod_1@plt>
   15448:	cmp	x0, #0x0
   1544c:	mov	w9, #0xffffffff            	// #-1
   15450:	sub	x8, x19, x0
   15454:	ccmp	w20, w9, #0x4, ne  // ne = any
   15458:	csel	x0, x8, x0, gt
   1545c:	b	15464 <__gmpz_cdiv_ui@@Base+0x4c>
   15460:	mov	x0, xzr
   15464:	ldp	x20, x19, [sp, #16]
   15468:	ldp	x29, x30, [sp], #32
   1546c:	ret
   15470:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000015474 <__gmpz_cdiv_q_2exp@@Base>:
   15474:	mov	w3, #0x1                   	// #1
   15478:	b	1547c <__gmpz_cdiv_q_2exp@@Base+0x8>
   1547c:	stp	x29, x30, [sp, #-80]!
   15480:	stp	x26, x25, [sp, #16]
   15484:	stp	x24, x23, [sp, #32]
   15488:	stp	x22, x21, [sp, #48]
   1548c:	stp	x20, x19, [sp, #64]
   15490:	ldrsw	x25, [x1, #4]
   15494:	ldrsw	x8, [x0]
   15498:	mov	x19, x0
   1549c:	mov	w23, w3
   154a0:	cmp	x25, #0x0
   154a4:	cneg	x9, x25, mi  // mi = first
   154a8:	sub	x20, x9, x2, lsr #6
   154ac:	cmp	x20, #0x0
   154b0:	mov	x29, sp
   154b4:	b.le	15544 <__gmpz_cdiv_q_2exp@@Base+0xd0>
   154b8:	mov	x22, x2
   154bc:	mov	x24, x1
   154c0:	cmp	x20, x8
   154c4:	b.ge	155f0 <__gmpz_cdiv_q_2exp@@Base+0x17c>  // b.tcont
   154c8:	ldr	x21, [x19, #8]
   154cc:	ldr	x9, [x24, #8]
   154d0:	mov	x26, xzr
   154d4:	eor	w8, w25, w23
   154d8:	lsr	x10, x22, #6
   154dc:	tbnz	w8, #31, 154fc <__gmpz_cdiv_q_2exp@@Base+0x88>
   154e0:	cbz	x10, 154fc <__gmpz_cdiv_q_2exp@@Base+0x88>
   154e4:	mov	x11, xzr
   154e8:	ldr	x26, [x9, x11, lsl #3]
   154ec:	add	x11, x11, #0x1
   154f0:	cmp	x11, x10
   154f4:	b.cs	154fc <__gmpz_cdiv_q_2exp@@Base+0x88>  // b.hs, b.nlast
   154f8:	cbz	x26, 154e8 <__gmpz_cdiv_q_2exp@@Base+0x74>
   154fc:	ands	x3, x22, #0x3f
   15500:	add	x1, x9, x10, lsl #3
   15504:	b.eq	1556c <__gmpz_cdiv_q_2exp@@Base+0xf8>  // b.none
   15508:	mov	w9, #0xffffffff            	// #-1
   1550c:	eor	w8, w9, w8, asr #31
   15510:	mov	x0, x21
   15514:	mov	x2, x20
   15518:	sxtw	x22, w8
   1551c:	bl	c1b0 <__gmpn_rshift@plt>
   15520:	add	x8, x21, x20, lsl #3
   15524:	ldur	x8, [x8, #-8]
   15528:	and	x9, x0, x22
   1552c:	orr	x26, x9, x26
   15530:	cmp	x8, #0x0
   15534:	cset	w8, eq  // eq = none
   15538:	sub	x20, x20, x8
   1553c:	cbnz	x26, 1557c <__gmpz_cdiv_q_2exp@@Base+0x108>
   15540:	b	155cc <__gmpz_cdiv_q_2exp@@Base+0x158>
   15544:	cmp	w8, #0x0
   15548:	b.le	15604 <__gmpz_cdiv_q_2exp@@Base+0x190>
   1554c:	ldr	x0, [x19, #8]
   15550:	eor	w9, w25, w23
   15554:	cmp	w9, #0x0
   15558:	mov	w8, #0x1                   	// #1
   1555c:	ccmp	w25, #0x0, #0x4, ge  // ge = tcont
   15560:	str	x8, [x0]
   15564:	csel	w8, wzr, w23, eq  // eq = none
   15568:	b	155d4 <__gmpz_cdiv_q_2exp@@Base+0x160>
   1556c:	mov	x0, x21
   15570:	mov	x2, x20
   15574:	bl	ca70 <__gmpn_copyi@plt>
   15578:	cbz	x26, 155cc <__gmpz_cdiv_q_2exp@@Base+0x158>
   1557c:	cbz	x20, 155c4 <__gmpz_cdiv_q_2exp@@Base+0x150>
   15580:	ldr	x8, [x21]
   15584:	adds	x8, x8, #0x1
   15588:	str	x8, [x21]
   1558c:	b.cc	155b4 <__gmpz_cdiv_q_2exp@@Base+0x140>  // b.lo, b.ul, b.last
   15590:	mov	w8, #0x1                   	// #1
   15594:	mov	w9, #0x1                   	// #1
   15598:	cmp	x9, x20
   1559c:	b.ge	155b8 <__gmpz_cdiv_q_2exp@@Base+0x144>  // b.tcont
   155a0:	ldr	x10, [x21, x9, lsl #3]
   155a4:	adds	x10, x10, #0x1
   155a8:	str	x10, [x21, x9, lsl #3]
   155ac:	add	x9, x9, #0x1
   155b0:	b.cs	15598 <__gmpz_cdiv_q_2exp@@Base+0x124>  // b.hs, b.nlast
   155b4:	mov	x8, xzr
   155b8:	str	x8, [x21, x20, lsl #3]
   155bc:	add	x20, x8, x20
   155c0:	b	155cc <__gmpz_cdiv_q_2exp@@Base+0x158>
   155c4:	mov	w20, #0x1                   	// #1
   155c8:	str	x20, [x21]
   155cc:	cmp	w25, #0x0
   155d0:	cneg	w8, w20, lt  // lt = tstop
   155d4:	str	w8, [x19, #4]
   155d8:	ldp	x20, x19, [sp, #64]
   155dc:	ldp	x22, x21, [sp, #48]
   155e0:	ldp	x24, x23, [sp, #32]
   155e4:	ldp	x26, x25, [sp, #16]
   155e8:	ldp	x29, x30, [sp], #80
   155ec:	ret
   155f0:	add	x1, x20, #0x1
   155f4:	mov	x0, x19
   155f8:	bl	c090 <__gmpz_realloc@plt>
   155fc:	mov	x21, x0
   15600:	b	154cc <__gmpz_cdiv_q_2exp@@Base+0x58>
   15604:	mov	w1, #0x1                   	// #1
   15608:	mov	x0, x19
   1560c:	bl	c090 <__gmpz_realloc@plt>
   15610:	b	15550 <__gmpz_cdiv_q_2exp@@Base+0xdc>

0000000000015614 <__gmpz_fdiv_q_2exp@@Base>:
   15614:	mov	w3, #0xffffffff            	// #-1
   15618:	b	1547c <__gmpz_cdiv_q_2exp@@Base+0x8>

000000000001561c <__gmpz_cdiv_r_2exp@@Base>:
   1561c:	mov	w3, #0x1                   	// #1
   15620:	b	15624 <__gmpz_cdiv_r_2exp@@Base+0x8>
   15624:	stp	x29, x30, [sp, #-80]!
   15628:	stp	x26, x25, [sp, #16]
   1562c:	stp	x24, x23, [sp, #32]
   15630:	stp	x22, x21, [sp, #48]
   15634:	stp	x20, x19, [sp, #64]
   15638:	ldr	w26, [x1, #4]
   1563c:	mov	x19, x0
   15640:	mov	x29, sp
   15644:	cbz	w26, 157c0 <__gmpz_cdiv_r_2exp@@Base+0x1a4>
   15648:	mov	x21, x1
   1564c:	ldr	x1, [x1, #8]
   15650:	sxtw	x22, w26
   15654:	cmp	x22, #0x0
   15658:	lsr	x23, x2, #6
   1565c:	and	x24, x2, #0x3f
   15660:	eor	w8, w26, w3
   15664:	cneg	x25, x22, mi  // mi = first
   15668:	tbnz	w8, #31, 156dc <__gmpz_cdiv_r_2exp@@Base+0xc0>
   1566c:	cmp	x25, x23
   15670:	b.le	156a8 <__gmpz_cdiv_r_2exp@@Base+0x8c>
   15674:	cbz	x23, 15694 <__gmpz_cdiv_r_2exp@@Base+0x78>
   15678:	mov	x8, x1
   1567c:	mov	x9, x23
   15680:	ldr	x10, [x8]
   15684:	cbnz	x10, 156a8 <__gmpz_cdiv_r_2exp@@Base+0x8c>
   15688:	subs	x9, x9, #0x1
   1568c:	add	x8, x8, #0x8
   15690:	b.ne	15680 <__gmpz_cdiv_r_2exp@@Base+0x64>  // b.any
   15694:	ldr	x8, [x1, x23, lsl #3]
   15698:	mov	x9, #0xffffffffffffffff    	// #-1
   1569c:	lsl	x9, x9, x24
   156a0:	bics	xzr, x8, x9
   156a4:	b.eq	157bc <__gmpz_cdiv_r_2exp@@Base+0x1a0>  // b.none
   156a8:	ldrsw	x8, [x19]
   156ac:	add	x20, x23, #0x1
   156b0:	cmp	x23, x8
   156b4:	b.ge	157e8 <__gmpz_cdiv_r_2exp@@Base+0x1cc>  // b.tcont
   156b8:	ldr	x21, [x19, #8]
   156bc:	ldr	x10, [x1]
   156c0:	cmp	x25, x23
   156c4:	neg	x22, x22
   156c8:	csel	x25, x20, x25, gt
   156cc:	cbz	x10, 15718 <__gmpz_cdiv_r_2exp@@Base+0xfc>
   156d0:	mov	x8, x21
   156d4:	mov	x9, x25
   156d8:	b	15738 <__gmpz_cdiv_r_2exp@@Base+0x11c>
   156dc:	cmp	x19, x21
   156e0:	b.eq	157dc <__gmpz_cdiv_r_2exp@@Base+0x1c0>  // b.none
   156e4:	ldrsw	x8, [x19]
   156e8:	cmp	x25, x23
   156ec:	csinc	x20, x25, x23, le
   156f0:	cmp	x20, x8
   156f4:	b.gt	15800 <__gmpz_cdiv_r_2exp@@Base+0x1e4>
   156f8:	ldr	x21, [x19, #8]
   156fc:	mov	x0, x21
   15700:	mov	x2, x20
   15704:	bl	ca70 <__gmpn_copyi@plt>
   15708:	cmp	x25, x23
   1570c:	mov	x1, x21
   15710:	b.gt	15774 <__gmpz_cdiv_r_2exp@@Base+0x158>
   15714:	b	157c0 <__gmpz_cdiv_r_2exp@@Base+0x1a4>
   15718:	mov	x9, x25
   1571c:	mov	x8, x21
   15720:	subs	x9, x9, #0x1
   15724:	str	xzr, [x8]
   15728:	b.eq	15754 <__gmpz_cdiv_r_2exp@@Base+0x138>  // b.none
   1572c:	ldr	x10, [x1, #8]!
   15730:	add	x8, x8, #0x8
   15734:	cbz	x10, 15720 <__gmpz_cdiv_r_2exp@@Base+0x104>
   15738:	neg	x10, x10
   1573c:	subs	x2, x9, #0x1
   15740:	str	x10, [x8]
   15744:	b.eq	15754 <__gmpz_cdiv_r_2exp@@Base+0x138>  // b.none
   15748:	add	x0, x8, #0x8
   1574c:	add	x1, x1, #0x8
   15750:	bl	c2a0 <__gmpn_com@plt>
   15754:	cmp	x25, x23
   15758:	b.hi	15770 <__gmpz_cdiv_r_2exp@@Base+0x154>  // b.pmore
   1575c:	sub	x8, x20, x25
   15760:	add	x0, x21, x25, lsl #3
   15764:	lsl	x2, x8, #3
   15768:	mov	w1, #0xff                  	// #255
   1576c:	bl	c610 <memset@plt>
   15770:	mov	x1, x21
   15774:	ldr	x8, [x1, x23, lsl #3]
   15778:	mov	x9, #0xffffffffffffffff    	// #-1
   1577c:	lsl	x9, x9, x24
   15780:	bics	x8, x8, x9
   15784:	str	x8, [x1, x23, lsl #3]
   15788:	b.eq	15794 <__gmpz_cdiv_r_2exp@@Base+0x178>  // b.none
   1578c:	mov	x8, x23
   15790:	b	157ac <__gmpz_cdiv_r_2exp@@Base+0x190>
   15794:	sub	x9, x1, #0x8
   15798:	subs	x8, x23, #0x1
   1579c:	b.lt	157bc <__gmpz_cdiv_r_2exp@@Base+0x1a0>  // b.tstop
   157a0:	ldr	x10, [x9, x23, lsl #3]
   157a4:	mov	x23, x8
   157a8:	cbz	x10, 15798 <__gmpz_cdiv_r_2exp@@Base+0x17c>
   157ac:	mvn	w9, w8
   157b0:	cmp	x22, #0x0
   157b4:	csinc	w26, w9, w8, lt  // lt = tstop
   157b8:	b	157c0 <__gmpz_cdiv_r_2exp@@Base+0x1a4>
   157bc:	mov	w26, wzr
   157c0:	str	w26, [x19, #4]
   157c4:	ldp	x20, x19, [sp, #64]
   157c8:	ldp	x22, x21, [sp, #48]
   157cc:	ldp	x24, x23, [sp, #32]
   157d0:	ldp	x26, x25, [sp, #16]
   157d4:	ldp	x29, x30, [sp], #80
   157d8:	ret
   157dc:	cmp	x25, x23
   157e0:	b.gt	15774 <__gmpz_cdiv_r_2exp@@Base+0x158>
   157e4:	b	157c4 <__gmpz_cdiv_r_2exp@@Base+0x1a8>
   157e8:	mov	x0, x19
   157ec:	mov	x1, x20
   157f0:	bl	c090 <__gmpz_realloc@plt>
   157f4:	ldr	x1, [x21, #8]
   157f8:	mov	x21, x0
   157fc:	b	156bc <__gmpz_cdiv_r_2exp@@Base+0xa0>
   15800:	mov	x0, x19
   15804:	mov	x21, x1
   15808:	mov	x1, x20
   1580c:	bl	c090 <__gmpz_realloc@plt>
   15810:	mov	x1, x21
   15814:	mov	x21, x0
   15818:	b	156fc <__gmpz_cdiv_r_2exp@@Base+0xe0>

000000000001581c <__gmpz_fdiv_r_2exp@@Base>:
   1581c:	mov	w3, #0xffffffff            	// #-1
   15820:	b	15624 <__gmpz_cdiv_r_2exp@@Base+0x8>

0000000000015824 <__gmpz_clear@@Base>:
   15824:	ldrsw	x8, [x0]
   15828:	cbz	w8, 15844 <__gmpz_clear@@Base+0x20>
   1582c:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   15830:	ldr	x9, [x9, #4016]
   15834:	ldr	x0, [x0, #8]
   15838:	lsl	x1, x8, #3
   1583c:	ldr	x2, [x9]
   15840:	br	x2
   15844:	ret

0000000000015848 <__gmpz_clears@@Base>:
   15848:	sub	sp, sp, #0x100
   1584c:	stp	x29, x30, [sp, #224]
   15850:	add	x29, sp, #0xe0
   15854:	mov	x8, #0xffffffffffffffc8    	// #-56
   15858:	mov	x9, sp
   1585c:	sub	x10, x29, #0x58
   15860:	movk	x8, #0xff80, lsl #32
   15864:	add	x11, x29, #0x20
   15868:	add	x9, x9, #0x80
   1586c:	add	x10, x10, #0x38
   15870:	str	x19, [sp, #240]
   15874:	stp	x1, x2, [x29, #-88]
   15878:	stp	x3, x4, [x29, #-72]
   1587c:	stp	x5, x6, [x29, #-56]
   15880:	stur	x7, [x29, #-40]
   15884:	stp	q0, q1, [sp]
   15888:	stp	q2, q3, [sp, #32]
   1588c:	stp	q4, q5, [sp, #64]
   15890:	stp	q6, q7, [sp, #96]
   15894:	stp	x9, x8, [x29, #-16]
   15898:	stp	x11, x10, [x29, #-32]
   1589c:	adrp	x19, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   158a0:	ldr	x19, [x19, #4016]
   158a4:	ldrsw	x8, [x0]
   158a8:	cbz	w8, 158bc <__gmpz_clears@@Base+0x74>
   158ac:	ldr	x9, [x19]
   158b0:	ldr	x0, [x0, #8]
   158b4:	lsl	x1, x8, #3
   158b8:	blr	x9
   158bc:	ldursw	x8, [x29, #-8]
   158c0:	tbz	w8, #31, 158e0 <__gmpz_clears@@Base+0x98>
   158c4:	add	w9, w8, #0x8
   158c8:	cmn	w8, #0x8
   158cc:	stur	w9, [x29, #-8]
   158d0:	b.gt	158e0 <__gmpz_clears@@Base+0x98>
   158d4:	ldur	x9, [x29, #-24]
   158d8:	add	x8, x9, x8
   158dc:	b	158ec <__gmpz_clears@@Base+0xa4>
   158e0:	ldur	x8, [x29, #-32]
   158e4:	add	x9, x8, #0x8
   158e8:	stur	x9, [x29, #-32]
   158ec:	ldr	x0, [x8]
   158f0:	cbnz	x0, 158a4 <__gmpz_clears@@Base+0x5c>
   158f4:	ldr	x19, [sp, #240]
   158f8:	ldp	x29, x30, [sp, #224]
   158fc:	add	sp, sp, #0x100
   15900:	ret

0000000000015904 <__gmpz_clrbit@@Base>:
   15904:	sub	sp, sp, #0x40
   15908:	stp	x29, x30, [sp, #16]
   1590c:	stp	x20, x19, [sp, #48]
   15910:	ldrsw	x8, [x0, #4]
   15914:	ldr	x19, [x0, #8]
   15918:	mov	w9, #0x1                   	// #1
   1591c:	str	x21, [sp, #32]
   15920:	lsr	x20, x1, #6
   15924:	lsl	x21, x9, x1
   15928:	add	x29, sp, #0x10
   1592c:	tbnz	w8, #31, 15974 <__gmpz_clrbit@@Base+0x70>
   15930:	cmp	x20, x8
   15934:	b.ge	15a44 <__gmpz_clrbit@@Base+0x140>  // b.tcont
   15938:	ldr	x9, [x19, x20, lsl #3]
   1593c:	bics	xzr, x9, x21
   15940:	bic	x10, x9, x21
   15944:	cinc	x9, x20, eq  // eq = none
   15948:	cmp	x9, x8
   1594c:	str	x10, [x19, x20, lsl #3]
   15950:	b.ne	15a44 <__gmpz_clrbit@@Base+0x140>  // b.any
   15954:	sub	x8, x19, #0x8
   15958:	subs	x9, x20, #0x1
   1595c:	b.lt	15a80 <__gmpz_clrbit@@Base+0x17c>  // b.tstop
   15960:	ldr	x10, [x8, x20, lsl #3]
   15964:	mov	x20, x9
   15968:	cbz	x10, 15958 <__gmpz_clrbit@@Base+0x54>
   1596c:	add	x8, x9, #0x1
   15970:	b	15a84 <__gmpz_clrbit@@Base+0x180>
   15974:	neg	x9, x8
   15978:	cmp	x20, x9
   1597c:	b.ge	159ac <__gmpz_clrbit@@Base+0xa8>  // b.tcont
   15980:	mov	x10, xzr
   15984:	ldr	x11, [x19, x10, lsl #3]
   15988:	add	x10, x10, #0x1
   1598c:	cbz	x11, 15984 <__gmpz_clrbit@@Base+0x80>
   15990:	sub	x11, x10, #0x1
   15994:	cmp	x20, x11
   15998:	b.ls	159e0 <__gmpz_clrbit@@Base+0xdc>  // b.plast
   1599c:	ldr	x8, [x19, x20, lsl #3]
   159a0:	orr	x8, x8, x21
   159a4:	str	x8, [x19, x20, lsl #3]
   159a8:	b	15a44 <__gmpz_clrbit@@Base+0x140>
   159ac:	ldrsw	x10, [x0]
   159b0:	cmp	x20, x10
   159b4:	b.ge	15a58 <__gmpz_clrbit@@Base+0x154>  // b.tcont
   159b8:	mvn	w10, w20
   159bc:	adds	x8, x20, x8
   159c0:	str	w10, [x0, #4]
   159c4:	b.eq	159d8 <__gmpz_clrbit@@Base+0xd4>  // b.none
   159c8:	add	x0, x19, x9, lsl #3
   159cc:	lsl	x2, x8, #3
   159d0:	mov	w1, wzr
   159d4:	bl	c610 <memset@plt>
   159d8:	str	x21, [x19, x20, lsl #3]
   159dc:	b	15a44 <__gmpz_clrbit@@Base+0x140>
   159e0:	add	x11, x20, #0x1
   159e4:	cmp	x11, x10
   159e8:	b.ne	15a44 <__gmpz_clrbit@@Base+0x140>  // b.any
   159ec:	ldr	x10, [x19, x20, lsl #3]
   159f0:	sub	x10, x10, #0x1
   159f4:	orr	x10, x10, x21
   159f8:	adds	x10, x10, #0x1
   159fc:	str	x10, [x19, x20, lsl #3]
   15a00:	b.cc	15a44 <__gmpz_clrbit@@Base+0x140>  // b.lo, b.ul, b.last
   15a04:	ldrsw	x10, [x0]
   15a08:	mov	w11, #0x1                   	// #1
   15a0c:	sub	x1, x11, x8
   15a10:	cmp	x1, x10
   15a14:	b.gt	15a8c <__gmpz_clrbit@@Base+0x188>
   15a18:	add	x10, x19, x20, lsl #3
   15a1c:	add	x10, x10, #0x8
   15a20:	str	xzr, [x19, x9, lsl #3]
   15a24:	ldr	x11, [x10]
   15a28:	adds	x11, x11, #0x1
   15a2c:	str	x11, [x10], #8
   15a30:	b.cs	15a24 <__gmpz_clrbit@@Base+0x120>  // b.hs, b.nlast
   15a34:	lsl	x9, x9, #3
   15a38:	ldr	w9, [x19, x9]
   15a3c:	sub	w8, w8, w9
   15a40:	str	w8, [x0, #4]
   15a44:	ldp	x20, x19, [sp, #48]
   15a48:	ldr	x21, [sp, #32]
   15a4c:	ldp	x29, x30, [sp, #16]
   15a50:	add	sp, sp, #0x40
   15a54:	ret
   15a58:	add	x1, x20, #0x1
   15a5c:	str	x0, [x29, #24]
   15a60:	str	x8, [sp, #8]
   15a64:	mov	x19, x9
   15a68:	bl	c090 <__gmpz_realloc@plt>
   15a6c:	mov	x9, x19
   15a70:	ldr	x8, [sp, #8]
   15a74:	mov	x19, x0
   15a78:	ldr	x0, [x29, #24]
   15a7c:	b	159b8 <__gmpz_clrbit@@Base+0xb4>
   15a80:	mov	x8, xzr
   15a84:	str	w8, [x0, #4]
   15a88:	b	15a44 <__gmpz_clrbit@@Base+0x140>
   15a8c:	str	x0, [x29, #24]
   15a90:	mov	x19, x8
   15a94:	mov	x21, x9
   15a98:	bl	c090 <__gmpz_realloc@plt>
   15a9c:	mov	x8, x19
   15aa0:	mov	x19, x0
   15aa4:	ldr	x0, [x29, #24]
   15aa8:	mov	x9, x21
   15aac:	b	15a18 <__gmpz_clrbit@@Base+0x114>

0000000000015ab0 <__gmpz_cmp@@Base>:
   15ab0:	ldrsw	x9, [x0, #4]
   15ab4:	ldrsw	x10, [x1, #4]
   15ab8:	mov	x8, x0
   15abc:	subs	x0, x9, x10
   15ac0:	b.eq	15ac8 <__gmpz_cmp@@Base+0x18>  // b.none
   15ac4:	ret
   15ac8:	ldr	x8, [x8, #8]
   15acc:	ldr	x11, [x1, #8]
   15ad0:	cmp	w9, #0x0
   15ad4:	cneg	x10, x9, lt  // lt = tstop
   15ad8:	sub	x8, x8, #0x8
   15adc:	sub	x11, x11, #0x8
   15ae0:	subs	x12, x10, #0x1
   15ae4:	b.lt	15b08 <__gmpz_cmp@@Base+0x58>  // b.tstop
   15ae8:	ldr	x13, [x8, x10, lsl #3]
   15aec:	ldr	x10, [x11, x10, lsl #3]
   15af0:	cmp	x13, x10
   15af4:	mov	x10, x12
   15af8:	b.eq	15ae0 <__gmpz_cmp@@Base+0x30>  // b.none
   15afc:	mov	w8, #0x1                   	// #1
   15b00:	cneg	w8, w8, ls  // ls = plast
   15b04:	b	15b0c <__gmpz_cmp@@Base+0x5c>
   15b08:	mov	w8, wzr
   15b0c:	cmp	w9, #0x0
   15b10:	cneg	w0, w8, lt  // lt = tstop
   15b14:	ret

0000000000015b18 <__gmpz_cmp_d@@Base>:
   15b18:	sub	sp, sp, #0x40
   15b1c:	fmov	x8, d0
   15b20:	mvn	x9, x8
   15b24:	tst	x9, #0x7ff0000000000000
   15b28:	stp	x29, x30, [sp, #16]
   15b2c:	str	x21, [sp, #32]
   15b30:	stp	x20, x19, [sp, #48]
   15b34:	add	x29, sp, #0x10
   15b38:	b.eq	15c50 <__gmpz_cmp_d@@Base+0x138>  // b.none
   15b3c:	mov	x19, x0
   15b40:	ldr	w0, [x0, #4]
   15b44:	fcmp	d0, #0.0
   15b48:	b.ne	15b60 <__gmpz_cmp_d@@Base+0x48>  // b.any
   15b4c:	ldp	x20, x19, [sp, #48]
   15b50:	ldr	x21, [sp, #32]
   15b54:	ldp	x29, x30, [sp, #16]
   15b58:	add	sp, sp, #0x40
   15b5c:	ret
   15b60:	cbz	w0, 15c58 <__gmpz_cmp_d@@Base+0x140>
   15b64:	sxtw	x21, w0
   15b68:	tbnz	w0, #31, 15b80 <__gmpz_cmp_d@@Base+0x68>
   15b6c:	mov	w20, #0x1                   	// #1
   15b70:	fcmp	d0, #0.0
   15b74:	mov	w0, #0x1                   	// #1
   15b78:	b.mi	15b4c <__gmpz_cmp_d@@Base+0x34>  // b.first
   15b7c:	b	15b94 <__gmpz_cmp_d@@Base+0x7c>
   15b80:	fcmp	d0, #0.0
   15b84:	b.ge	15be8 <__gmpz_cmp_d@@Base+0xd0>  // b.tcont
   15b88:	fneg	d0, d0
   15b8c:	neg	x21, x21
   15b90:	mov	w20, #0xffffffff            	// #-1
   15b94:	fmov	d1, #1.000000000000000000e+00
   15b98:	fcmp	d0, d1
   15b9c:	b.pl	15ba8 <__gmpz_cmp_d@@Base+0x90>  // b.nfrst
   15ba0:	mov	w0, w20
   15ba4:	b	15b4c <__gmpz_cmp_d@@Base+0x34>
   15ba8:	mov	x0, sp
   15bac:	bl	d2a0 <__gmp_extract_double@plt>
   15bb0:	cmp	x21, w0, sxtw
   15bb4:	b.ne	15bf0 <__gmpz_cmp_d@@Base+0xd8>  // b.any
   15bb8:	ldr	x8, [x19, #8]
   15bbc:	ldr	x10, [sp, #8]
   15bc0:	add	x9, x8, x21, lsl #3
   15bc4:	ldur	x9, [x9, #-8]
   15bc8:	cmp	x9, x10
   15bcc:	b.ne	15c40 <__gmpz_cmp_d@@Base+0x128>  // b.any
   15bd0:	cmp	x21, #0x1
   15bd4:	b.ne	15c00 <__gmpz_cmp_d@@Base+0xe8>  // b.any
   15bd8:	ldr	x8, [sp]
   15bdc:	cmp	x8, #0x0
   15be0:	csneg	w0, wzr, w20, eq  // eq = none
   15be4:	b	15b4c <__gmpz_cmp_d@@Base+0x34>
   15be8:	mov	w0, #0xffffffff            	// #-1
   15bec:	b	15b4c <__gmpz_cmp_d@@Base+0x34>
   15bf0:	sxtw	x8, w0
   15bf4:	cmp	x21, x8
   15bf8:	cneg	w0, w20, lt  // lt = tstop
   15bfc:	b	15b4c <__gmpz_cmp_d@@Base+0x34>
   15c00:	add	x9, x8, x21, lsl #3
   15c04:	ldur	x9, [x9, #-16]
   15c08:	ldr	x10, [sp]
   15c0c:	cmp	x9, x10
   15c10:	b.ne	15c40 <__gmpz_cmp_d@@Base+0x128>  // b.any
   15c14:	cmp	x21, #0x3
   15c18:	b.lt	15c48 <__gmpz_cmp_d@@Base+0x130>  // b.tstop
   15c1c:	sub	x8, x8, #0x18
   15c20:	ldr	x9, [x8, x21, lsl #3]
   15c24:	cbnz	x9, 15ba0 <__gmpz_cmp_d@@Base+0x88>
   15c28:	sub	x9, x21, #0x3
   15c2c:	mov	w0, wzr
   15c30:	sub	x21, x21, #0x1
   15c34:	cmp	x9, #0x1
   15c38:	b.ge	15c20 <__gmpz_cmp_d@@Base+0x108>  // b.tcont
   15c3c:	b	15b4c <__gmpz_cmp_d@@Base+0x34>
   15c40:	cneg	w0, w20, cc  // cc = lo, ul, last
   15c44:	b	15b4c <__gmpz_cmp_d@@Base+0x34>
   15c48:	mov	w0, wzr
   15c4c:	b	15b4c <__gmpz_cmp_d@@Base+0x34>
   15c50:	tst	x8, #0xfffffffffffff
   15c54:	b.ne	15c68 <__gmpz_cmp_d@@Base+0x150>  // b.any
   15c58:	fcmp	d0, #0.0
   15c5c:	mov	w8, #0xffffffff            	// #-1
   15c60:	csinc	w0, w8, wzr, pl  // pl = nfrst
   15c64:	b	15b4c <__gmpz_cmp_d@@Base+0x34>
   15c68:	bl	c1c0 <__gmp_invalid_operation@plt>

0000000000015c6c <__gmpz_cmp_si@@Base>:
   15c6c:	ldr	w8, [x0, #4]
   15c70:	cmp	x1, #0x0
   15c74:	asr	x9, x1, #63
   15c78:	cinc	x9, x9, gt
   15c7c:	cbz	w8, 15cac <__gmpz_cmp_si@@Base+0x40>
   15c80:	sxtw	x10, w8
   15c84:	cmp	x9, x10
   15c88:	b.ne	15cac <__gmpz_cmp_si@@Base+0x40>  // b.any
   15c8c:	ldr	x9, [x0, #8]
   15c90:	cmp	x1, #0x0
   15c94:	cneg	x10, x1, mi  // mi = first
   15c98:	ldr	x9, [x9]
   15c9c:	cmp	x9, x10
   15ca0:	b.ne	15cb4 <__gmpz_cmp_si@@Base+0x48>  // b.any
   15ca4:	mov	w0, wzr
   15ca8:	ret
   15cac:	sub	w0, w8, w9
   15cb0:	ret
   15cb4:	cneg	w0, w8, ls  // ls = plast
   15cb8:	ret

0000000000015cbc <__gmpz_cmp_ui@@Base>:
   15cbc:	ldr	w8, [x0, #4]
   15cc0:	cmp	w8, #0x1
   15cc4:	b.eq	15cd8 <__gmpz_cmp_ui@@Base+0x1c>  // b.none
   15cc8:	cbnz	w8, 15cf0 <__gmpz_cmp_ui@@Base+0x34>
   15ccc:	cmp	x1, #0x0
   15cd0:	csetm	w0, ne  // ne = any
   15cd4:	ret
   15cd8:	ldr	x8, [x0, #8]
   15cdc:	ldr	x8, [x8]
   15ce0:	cmp	x8, x1
   15ce4:	b.ls	15d00 <__gmpz_cmp_ui@@Base+0x44>  // b.plast
   15ce8:	mov	w0, #0x1                   	// #1
   15cec:	ret
   15cf0:	cmp	w8, #0x1
   15cf4:	mov	w8, #0xffffffff            	// #-1
   15cf8:	cneg	w0, w8, ge  // ge = tcont
   15cfc:	ret
   15d00:	csetm	w0, cc  // cc = lo, ul, last
   15d04:	ret

0000000000015d08 <__gmpz_cmpabs@@Base>:
   15d08:	ldr	w9, [x0, #4]
   15d0c:	ldr	w10, [x1, #4]
   15d10:	mov	x8, x0
   15d14:	cmp	w9, #0x0
   15d18:	cneg	w9, w9, mi  // mi = first
   15d1c:	cmp	w10, #0x0
   15d20:	cneg	w10, w10, mi  // mi = first
   15d24:	subs	x0, x9, x10
   15d28:	b.eq	15d30 <__gmpz_cmpabs@@Base+0x28>  // b.none
   15d2c:	ret
   15d30:	ldr	x8, [x8, #8]
   15d34:	ldr	x10, [x1, #8]
   15d38:	sub	x8, x8, #0x8
   15d3c:	sub	x10, x10, #0x8
   15d40:	subs	x11, x9, #0x1
   15d44:	b.lt	15d68 <__gmpz_cmpabs@@Base+0x60>  // b.tstop
   15d48:	ldr	x12, [x8, x9, lsl #3]
   15d4c:	ldr	x9, [x10, x9, lsl #3]
   15d50:	cmp	x12, x9
   15d54:	mov	x9, x11
   15d58:	b.eq	15d40 <__gmpz_cmpabs@@Base+0x38>  // b.none
   15d5c:	mov	w8, #0x1                   	// #1
   15d60:	cneg	w0, w8, ls  // ls = plast
   15d64:	ret
   15d68:	mov	w0, wzr
   15d6c:	ret

0000000000015d70 <__gmpz_cmpabs_d@@Base>:
   15d70:	sub	sp, sp, #0x30
   15d74:	fmov	x8, d0
   15d78:	mvn	x9, x8
   15d7c:	tst	x9, #0x7ff0000000000000
   15d80:	stp	x29, x30, [sp, #16]
   15d84:	stp	x20, x19, [sp, #32]
   15d88:	add	x29, sp, #0x10
   15d8c:	b.eq	15e8c <__gmpz_cmpabs_d@@Base+0x11c>  // b.none
   15d90:	ldrsw	x8, [x0, #4]
   15d94:	mov	x19, x0
   15d98:	fcmp	d0, #0.0
   15d9c:	b.ne	15db8 <__gmpz_cmpabs_d@@Base+0x48>  // b.any
   15da0:	cmp	w8, #0x0
   15da4:	cset	w0, ne  // ne = any
   15da8:	ldp	x20, x19, [sp, #32]
   15dac:	ldp	x29, x30, [sp, #16]
   15db0:	add	sp, sp, #0x30
   15db4:	ret
   15db8:	cbz	w8, 15e94 <__gmpz_cmpabs_d@@Base+0x124>
   15dbc:	cmp	x8, #0x0
   15dc0:	fneg	d1, d0
   15dc4:	cneg	x20, x8, mi  // mi = first
   15dc8:	fcmp	d0, #0.0
   15dcc:	fcsel	d0, d0, d1, ge  // ge = tcont
   15dd0:	fmov	d1, #1.000000000000000000e+00
   15dd4:	fcmp	d0, d1
   15dd8:	b.pl	15de4 <__gmpz_cmpabs_d@@Base+0x74>  // b.nfrst
   15ddc:	mov	w0, #0x1                   	// #1
   15de0:	b	15da8 <__gmpz_cmpabs_d@@Base+0x38>
   15de4:	mov	x0, sp
   15de8:	bl	d2a0 <__gmp_extract_double@plt>
   15dec:	cmp	x20, w0, sxtw
   15df0:	b.ne	15e24 <__gmpz_cmpabs_d@@Base+0xb4>  // b.any
   15df4:	ldr	x8, [x19, #8]
   15df8:	ldr	x10, [sp, #8]
   15dfc:	add	x9, x8, x20, lsl #3
   15e00:	ldur	x9, [x9, #-8]
   15e04:	cmp	x9, x10
   15e08:	b.ne	15e78 <__gmpz_cmpabs_d@@Base+0x108>  // b.any
   15e0c:	cmp	x20, #0x1
   15e10:	b.ne	15e38 <__gmpz_cmpabs_d@@Base+0xc8>  // b.any
   15e14:	ldr	x8, [sp]
   15e18:	cmp	x8, #0x0
   15e1c:	csetm	w0, ne  // ne = any
   15e20:	b	15da8 <__gmpz_cmpabs_d@@Base+0x38>
   15e24:	sxtw	x8, w0
   15e28:	cmp	x20, x8
   15e2c:	mov	w8, #0xffffffff            	// #-1
   15e30:	cneg	w0, w8, ge  // ge = tcont
   15e34:	b	15da8 <__gmpz_cmpabs_d@@Base+0x38>
   15e38:	add	x9, x8, x20, lsl #3
   15e3c:	ldur	x9, [x9, #-16]
   15e40:	ldr	x10, [sp]
   15e44:	cmp	x9, x10
   15e48:	b.ne	15e78 <__gmpz_cmpabs_d@@Base+0x108>  // b.any
   15e4c:	cmp	x20, #0x3
   15e50:	b.lt	15e84 <__gmpz_cmpabs_d@@Base+0x114>  // b.tstop
   15e54:	sub	x8, x8, #0x18
   15e58:	ldr	x9, [x8, x20, lsl #3]
   15e5c:	cbnz	x9, 15ddc <__gmpz_cmpabs_d@@Base+0x6c>
   15e60:	sub	x9, x20, #0x3
   15e64:	mov	w0, wzr
   15e68:	sub	x20, x20, #0x1
   15e6c:	cmp	x9, #0x1
   15e70:	b.ge	15e58 <__gmpz_cmpabs_d@@Base+0xe8>  // b.tcont
   15e74:	b	15da8 <__gmpz_cmpabs_d@@Base+0x38>
   15e78:	mov	w8, #0xffffffff            	// #-1
   15e7c:	cneg	w0, w8, cs  // cs = hs, nlast
   15e80:	b	15da8 <__gmpz_cmpabs_d@@Base+0x38>
   15e84:	mov	w0, wzr
   15e88:	b	15da8 <__gmpz_cmpabs_d@@Base+0x38>
   15e8c:	tst	x8, #0xfffffffffffff
   15e90:	b.ne	15e9c <__gmpz_cmpabs_d@@Base+0x12c>  // b.any
   15e94:	mov	w0, #0xffffffff            	// #-1
   15e98:	b	15da8 <__gmpz_cmpabs_d@@Base+0x38>
   15e9c:	bl	c1c0 <__gmp_invalid_operation@plt>

0000000000015ea0 <__gmpz_cmpabs_ui@@Base>:
   15ea0:	ldrsw	x8, [x0, #4]
   15ea4:	cbz	w8, 15ed0 <__gmpz_cmpabs_ui@@Base+0x30>
   15ea8:	cmp	x8, #0x0
   15eac:	cneg	x8, x8, mi  // mi = first
   15eb0:	cmp	x8, #0x1
   15eb4:	b.ne	15ec8 <__gmpz_cmpabs_ui@@Base+0x28>  // b.any
   15eb8:	ldr	x8, [x0, #8]
   15ebc:	ldr	x8, [x8]
   15ec0:	cmp	x8, x1
   15ec4:	b.ls	15edc <__gmpz_cmpabs_ui@@Base+0x3c>  // b.plast
   15ec8:	mov	w0, #0x1                   	// #1
   15ecc:	ret
   15ed0:	cmp	x1, #0x0
   15ed4:	csetm	w0, ne  // ne = any
   15ed8:	ret
   15edc:	csetm	w0, cc  // cc = lo, ul, last
   15ee0:	ret

0000000000015ee4 <__gmpz_com@@Base>:
   15ee4:	stp	x29, x30, [sp, #-48]!
   15ee8:	stp	x22, x21, [sp, #16]
   15eec:	stp	x20, x19, [sp, #32]
   15ef0:	ldrsw	x22, [x1, #4]
   15ef4:	mov	x21, x1
   15ef8:	mov	x19, x0
   15efc:	mov	x29, sp
   15f00:	tbnz	w22, #31, 15f90 <__gmpz_com@@Base+0xac>
   15f04:	ldr	w8, [x19]
   15f08:	cbz	w22, 160a8 <__gmpz_com@@Base+0x1c4>
   15f0c:	cmp	w22, w8
   15f10:	b.ge	160c4 <__gmpz_com@@Base+0x1e0>  // b.tcont
   15f14:	ldr	x0, [x19, #8]
   15f18:	ldr	x8, [x21, #8]
   15f1c:	ldr	x9, [x8]
   15f20:	adds	x9, x9, #0x1
   15f24:	str	x9, [x0]
   15f28:	b.cc	15fe8 <__gmpz_com@@Base+0x104>  // b.lo, b.ul, b.last
   15f2c:	mov	x11, #0xfffffffffffffff8    	// #-8
   15f30:	mov	w10, #0x1                   	// #1
   15f34:	mov	w9, #0x1                   	// #1
   15f38:	cmp	x9, x22
   15f3c:	b.ge	1601c <__gmpz_com@@Base+0x138>  // b.tcont
   15f40:	ldr	x12, [x8, x9, lsl #3]
   15f44:	sub	x11, x11, #0x8
   15f48:	adds	x12, x12, #0x1
   15f4c:	str	x12, [x0, x9, lsl #3]
   15f50:	add	x9, x9, #0x1
   15f54:	b.cs	15f38 <__gmpz_com@@Base+0x54>  // b.hs, b.nlast
   15f58:	cmp	x8, x0
   15f5c:	mov	x10, xzr
   15f60:	b.eq	1601c <__gmpz_com@@Base+0x138>  // b.none
   15f64:	cmp	x9, x22
   15f68:	b.ge	1601c <__gmpz_com@@Base+0x138>  // b.tcont
   15f6c:	sub	x8, x8, x11
   15f70:	sub	x10, x0, x11
   15f74:	mov	x11, x22
   15f78:	ldr	x12, [x8], #8
   15f7c:	sub	x11, x11, #0x1
   15f80:	cmp	x9, x11
   15f84:	str	x12, [x10], #8
   15f88:	b.ne	15f78 <__gmpz_com@@Base+0x94>  // b.any
   15f8c:	b	16018 <__gmpz_com@@Base+0x134>
   15f90:	ldrsw	x8, [x19]
   15f94:	neg	x20, x22
   15f98:	cmp	x20, x8
   15f9c:	b.gt	160d4 <__gmpz_com@@Base+0x1f0>
   15fa0:	ldr	x0, [x19, #8]
   15fa4:	ldr	x9, [x21, #8]
   15fa8:	ldr	x8, [x9]
   15fac:	sub	x10, x8, #0x1
   15fb0:	str	x10, [x0]
   15fb4:	cbz	x8, 1602c <__gmpz_com@@Base+0x148>
   15fb8:	cmn	w22, #0x2
   15fbc:	b.gt	16080 <__gmpz_com@@Base+0x19c>
   15fc0:	cmp	x9, x0
   15fc4:	b.eq	16080 <__gmpz_com@@Base+0x19c>  // b.none
   15fc8:	add	x8, x22, #0x1
   15fcc:	add	x10, x0, #0x8
   15fd0:	add	x9, x9, #0x8
   15fd4:	ldr	x11, [x9], #8
   15fd8:	adds	x8, x8, #0x1
   15fdc:	str	x11, [x10], #8
   15fe0:	b.cc	15fd4 <__gmpz_com@@Base+0xf0>  // b.lo, b.ul, b.last
   15fe4:	b	16080 <__gmpz_com@@Base+0x19c>
   15fe8:	cmp	w22, #0x2
   15fec:	mov	x10, xzr
   15ff0:	b.lt	1601c <__gmpz_com@@Base+0x138>  // b.tstop
   15ff4:	cmp	x8, x0
   15ff8:	b.eq	1601c <__gmpz_com@@Base+0x138>  // b.none
   15ffc:	sub	x9, x22, #0x1
   16000:	add	x10, x0, #0x8
   16004:	add	x8, x8, #0x8
   16008:	ldr	x11, [x8], #8
   1600c:	subs	x9, x9, #0x1
   16010:	str	x11, [x10], #8
   16014:	b.ne	16008 <__gmpz_com@@Base+0x124>  // b.any
   16018:	mov	x10, xzr
   1601c:	add	w8, w22, w10
   16020:	str	x10, [x0, x22, lsl #3]
   16024:	neg	w8, w8
   16028:	b	16094 <__gmpz_com@@Base+0x1b0>
   1602c:	mov	x10, #0xfffffffffffffff8    	// #-8
   16030:	mov	w8, #0x1                   	// #1
   16034:	cmp	x8, x20
   16038:	b.ge	16080 <__gmpz_com@@Base+0x19c>  // b.tcont
   1603c:	ldr	x11, [x9, x8, lsl #3]
   16040:	sub	x10, x10, #0x8
   16044:	sub	x12, x11, #0x1
   16048:	str	x12, [x0, x8, lsl #3]
   1604c:	add	x8, x8, #0x1
   16050:	cbz	x11, 16034 <__gmpz_com@@Base+0x150>
   16054:	cmp	x9, x0
   16058:	b.eq	16080 <__gmpz_com@@Base+0x19c>  // b.none
   1605c:	cmp	x8, x20
   16060:	b.ge	16080 <__gmpz_com@@Base+0x19c>  // b.tcont
   16064:	sub	x9, x9, x10
   16068:	sub	x10, x0, x10
   1606c:	ldr	x11, [x9], #8
   16070:	sub	x20, x20, #0x1
   16074:	cmp	x8, x20
   16078:	str	x11, [x10], #8
   1607c:	b.ne	1606c <__gmpz_com@@Base+0x188>  // b.any
   16080:	mvn	x8, x22
   16084:	ldr	x8, [x0, x8, lsl #3]
   16088:	cmp	x8, #0x0
   1608c:	csetm	w8, eq  // eq = none
   16090:	sub	w8, w8, w22
   16094:	str	w8, [x19, #4]
   16098:	ldp	x20, x19, [sp, #32]
   1609c:	ldp	x22, x21, [sp, #16]
   160a0:	ldp	x29, x30, [sp], #48
   160a4:	ret
   160a8:	cmp	w8, #0x0
   160ac:	b.le	160e4 <__gmpz_com@@Base+0x200>
   160b0:	ldr	x0, [x19, #8]
   160b4:	mov	w8, #0x1                   	// #1
   160b8:	str	x8, [x0]
   160bc:	mov	w8, #0xffffffff            	// #-1
   160c0:	b	16094 <__gmpz_com@@Base+0x1b0>
   160c4:	add	x1, x22, #0x1
   160c8:	mov	x0, x19
   160cc:	bl	c090 <__gmpz_realloc@plt>
   160d0:	b	15f18 <__gmpz_com@@Base+0x34>
   160d4:	mov	x0, x19
   160d8:	mov	x1, x20
   160dc:	bl	c090 <__gmpz_realloc@plt>
   160e0:	b	15fa4 <__gmpz_com@@Base+0xc0>
   160e4:	mov	w1, #0x1                   	// #1
   160e8:	mov	x0, x19
   160ec:	bl	c090 <__gmpz_realloc@plt>
   160f0:	b	160b4 <__gmpz_com@@Base+0x1d0>

00000000000160f4 <__gmpz_combit@@Base>:
   160f4:	stp	x29, x30, [sp, #-64]!
   160f8:	stp	x22, x21, [sp, #32]
   160fc:	stp	x20, x19, [sp, #48]
   16100:	ldrsw	x8, [x0, #4]
   16104:	ldr	x20, [x0, #8]
   16108:	lsr	x22, x1, #6
   1610c:	mov	w9, #0x1                   	// #1
   16110:	add	x21, x22, #0x1
   16114:	str	x23, [sp, #16]
   16118:	cmp	x21, x8
   1611c:	lsl	x23, x9, x1
   16120:	mov	x29, sp
   16124:	b.ge	16138 <__gmpz_combit@@Base+0x44>  // b.tcont
   16128:	ldr	x8, [x20, x22, lsl #3]
   1612c:	eor	x8, x8, x23
   16130:	str	x8, [x20, x22, lsl #3]
   16134:	b	16290 <__gmpz_combit@@Base+0x19c>
   16138:	neg	x9, x8
   1613c:	mov	x19, x0
   16140:	cmp	x22, x9
   16144:	b.ge	16174 <__gmpz_combit@@Base+0x80>  // b.tcont
   16148:	cbz	x22, 16164 <__gmpz_combit@@Base+0x70>
   1614c:	lsl	x10, x22, #3
   16150:	sub	x11, x20, #0x8
   16154:	ldr	x12, [x11, x10]
   16158:	cbnz	x12, 16174 <__gmpz_combit@@Base+0x80>
   1615c:	subs	x10, x10, #0x8
   16160:	b.ne	16154 <__gmpz_combit@@Base+0x60>  // b.any
   16164:	ldr	x10, [x20, x22, lsl #3]
   16168:	sub	x11, x23, #0x1
   1616c:	tst	x10, x11
   16170:	b.eq	16200 <__gmpz_combit@@Base+0x10c>  // b.none
   16174:	cmp	x8, #0x0
   16178:	cneg	x9, x8, mi  // mi = first
   1617c:	cmp	x22, x9
   16180:	b.ge	161c0 <__gmpz_combit@@Base+0xcc>  // b.tcont
   16184:	ldr	x10, [x20, x22, lsl #3]
   16188:	eor	x10, x10, x23
   1618c:	cmp	x10, #0x0
   16190:	cinc	x11, x22, eq  // eq = none
   16194:	cmp	x11, x9
   16198:	str	x10, [x20, x22, lsl #3]
   1619c:	b.ne	16290 <__gmpz_combit@@Base+0x19c>  // b.any
   161a0:	sub	x9, x20, #0x8
   161a4:	subs	x10, x22, #0x1
   161a8:	b.lt	162c0 <__gmpz_combit@@Base+0x1cc>  // b.tstop
   161ac:	ldr	x11, [x9, x22, lsl #3]
   161b0:	mov	x22, x10
   161b4:	cbz	x11, 161a4 <__gmpz_combit@@Base+0xb0>
   161b8:	add	x9, x10, #0x1
   161bc:	b	162c4 <__gmpz_combit@@Base+0x1d0>
   161c0:	ldrsw	x8, [x19]
   161c4:	cmp	x22, x8
   161c8:	b.ge	162a4 <__gmpz_combit@@Base+0x1b0>  // b.tcont
   161cc:	subs	x8, x22, x9
   161d0:	b.eq	161e4 <__gmpz_combit@@Base+0xf0>  // b.none
   161d4:	add	x0, x20, x9, lsl #3
   161d8:	lsl	x2, x8, #3
   161dc:	mov	w1, wzr
   161e0:	bl	c610 <memset@plt>
   161e4:	str	x23, [x20, x22, lsl #3]
   161e8:	ldr	w8, [x19, #4]
   161ec:	mvn	w9, w22
   161f0:	cmp	w8, #0x0
   161f4:	csel	x8, x21, x9, ge  // ge = tcont
   161f8:	str	w8, [x19, #4]
   161fc:	b	16290 <__gmpz_combit@@Base+0x19c>
   16200:	tst	x10, x23
   16204:	b.eq	16258 <__gmpz_combit@@Base+0x164>  // b.none
   16208:	ldrsw	x10, [x19]
   1620c:	mov	w11, #0x1                   	// #1
   16210:	sub	x1, x11, x8
   16214:	cmp	x1, x10
   16218:	b.gt	162d4 <__gmpz_combit@@Base+0x1e0>
   1621c:	str	xzr, [x20, x9, lsl #3]
   16220:	ldr	x10, [x20, x22, lsl #3]
   16224:	adds	x10, x10, x23
   16228:	str	x10, [x20, x22, lsl #3]
   1622c:	b.cc	16248 <__gmpz_combit@@Base+0x154>  // b.lo, b.ul, b.last
   16230:	add	x10, x20, x22, lsl #3
   16234:	add	x10, x10, #0x8
   16238:	ldr	x11, [x10]
   1623c:	adds	x11, x11, #0x1
   16240:	str	x11, [x10], #8
   16244:	b.cs	16238 <__gmpz_combit@@Base+0x144>  // b.hs, b.nlast
   16248:	lsl	x9, x9, #3
   1624c:	ldr	w9, [x20, x9]
   16250:	sub	w8, w8, w9
   16254:	b	1628c <__gmpz_combit@@Base+0x198>
   16258:	subs	x9, x10, x23
   1625c:	str	x9, [x20, x22, lsl #3]
   16260:	b.cs	1627c <__gmpz_combit@@Base+0x188>  // b.hs, b.nlast
   16264:	add	x9, x20, x22, lsl #3
   16268:	add	x9, x9, #0x8
   1626c:	ldr	x10, [x9]
   16270:	sub	x11, x10, #0x1
   16274:	str	x11, [x9], #8
   16278:	cbz	x10, 1626c <__gmpz_combit@@Base+0x178>
   1627c:	mvn	x9, x8
   16280:	ldr	x9, [x20, x9, lsl #3]
   16284:	cmp	x9, #0x0
   16288:	cinc	w8, w8, eq  // eq = none
   1628c:	str	w8, [x19, #4]
   16290:	ldp	x20, x19, [sp, #48]
   16294:	ldp	x22, x21, [sp, #32]
   16298:	ldr	x23, [sp, #16]
   1629c:	ldp	x29, x30, [sp], #64
   162a0:	ret
   162a4:	mov	x0, x19
   162a8:	mov	x1, x21
   162ac:	mov	x20, x9
   162b0:	bl	c090 <__gmpz_realloc@plt>
   162b4:	mov	x9, x20
   162b8:	mov	x20, x0
   162bc:	b	161cc <__gmpz_combit@@Base+0xd8>
   162c0:	mov	x9, xzr
   162c4:	neg	w10, w9
   162c8:	cmp	w8, #0x0
   162cc:	csel	x8, x9, x10, ge  // ge = tcont
   162d0:	b	161f8 <__gmpz_combit@@Base+0x104>
   162d4:	mov	x0, x19
   162d8:	mov	x20, x8
   162dc:	mov	x21, x9
   162e0:	bl	c090 <__gmpz_realloc@plt>
   162e4:	mov	x9, x21
   162e8:	mov	x8, x20
   162ec:	mov	x20, x0
   162f0:	b	1621c <__gmpz_combit@@Base+0x128>

00000000000162f4 <__gmpz_congruent_p@@Base>:
   162f4:	stp	x29, x30, [sp, #-80]!
   162f8:	stp	x24, x23, [sp, #32]
   162fc:	stp	x22, x21, [sp, #48]
   16300:	stp	x20, x19, [sp, #64]
   16304:	ldrsw	x8, [x2, #4]
   16308:	str	x25, [sp, #16]
   1630c:	mov	x29, sp
   16310:	cbz	w8, 165b0 <__gmpz_congruent_p@@Base+0x2bc>
   16314:	ldr	w9, [x0, #4]
   16318:	ldr	w10, [x1, #4]
   1631c:	cmp	x8, #0x0
   16320:	cneg	x21, x8, mi  // mi = first
   16324:	cmp	w9, #0x0
   16328:	cneg	w8, w9, mi  // mi = first
   1632c:	cmp	w10, #0x0
   16330:	cneg	w9, w10, mi  // mi = first
   16334:	cmp	w8, w9
   16338:	csel	x11, x1, x0, lt  // lt = tstop
   1633c:	ldrsw	x8, [x11, #4]
   16340:	csel	x10, x0, x1, lt  // lt = tstop
   16344:	ldr	x20, [x2, #8]
   16348:	ldrsw	x9, [x10, #4]
   1634c:	ldr	x22, [x11, #8]
   16350:	cmp	x8, #0x0
   16354:	cneg	x19, x8, mi  // mi = first
   16358:	cbz	w9, 163a0 <__gmpz_congruent_p@@Base+0xac>
   1635c:	ldr	x2, [x10, #8]
   16360:	ldr	x25, [x20]
   16364:	ldr	x10, [x22]
   16368:	eor	w8, w9, w8
   1636c:	ldr	x23, [x2]
   16370:	cmp	x9, #0x0
   16374:	cneg	x24, x9, mi  // mi = first
   16378:	neg	x9, x25
   1637c:	cmp	w8, #0x0
   16380:	and	x9, x25, x9
   16384:	cneg	x10, x10, lt  // lt = tstop
   16388:	sub	x9, x9, #0x1
   1638c:	sub	x10, x10, x23
   16390:	tst	x9, x10
   16394:	b.eq	163bc <__gmpz_congruent_p@@Base+0xc8>  // b.none
   16398:	mov	w19, wzr
   1639c:	b	1667c <__gmpz_congruent_p@@Base+0x388>
   163a0:	mov	x0, x22
   163a4:	mov	x1, x19
   163a8:	mov	x2, x20
   163ac:	mov	x3, x21
   163b0:	bl	d380 <__gmpn_divisible_p@plt>
   163b4:	mov	w19, w0
   163b8:	b	1667c <__gmpz_congruent_p@@Base+0x388>
   163bc:	cmp	x24, #0x1
   163c0:	b.ne	1640c <__gmpz_congruent_p@@Base+0x118>  // b.any
   163c4:	cmp	x21, #0x1
   163c8:	b.ne	163f4 <__gmpz_congruent_p@@Base+0x100>  // b.any
   163cc:	tbz	w8, #31, 16534 <__gmpz_congruent_p@@Base+0x240>
   163d0:	subs	x8, x25, x23
   163d4:	b.cs	16530 <__gmpz_congruent_p@@Base+0x23c>  // b.hs, b.nlast
   163d8:	clz	x8, x25
   163dc:	lsl	x8, x25, x8
   163e0:	cmp	x23, x8
   163e4:	cset	w9, hi  // hi = pmore
   163e8:	lsl	x8, x8, x9
   163ec:	sub	x23, x8, x23
   163f0:	b	16534 <__gmpz_congruent_p@@Base+0x240>
   163f4:	cmp	x21, #0x2
   163f8:	b.ne	1640c <__gmpz_congruent_p@@Base+0x118>  // b.any
   163fc:	cbz	x25, 1640c <__gmpz_congruent_p@@Base+0x118>
   16400:	ldr	x10, [x20, #8]
   16404:	cmp	x10, x9
   16408:	b.ls	16510 <__gmpz_congruent_p@@Base+0x21c>  // b.plast
   1640c:	lsl	x9, x19, #3
   16410:	cmp	x19, #0xfdf
   16414:	add	x1, x9, #0x8
   16418:	str	xzr, [x29, #24]
   1641c:	b.hi	165bc <__gmpz_congruent_p@@Base+0x2c8>  // b.pmore
   16420:	add	x10, x1, #0xf
   16424:	mov	x9, sp
   16428:	and	x10, x10, #0xfffffffffffffff0
   1642c:	sub	x23, x9, x10
   16430:	mov	sp, x23
   16434:	tbnz	w8, #31, 165dc <__gmpz_congruent_p@@Base+0x2e8>
   16438:	cmp	x19, x24
   1643c:	b.le	1647c <__gmpz_congruent_p@@Base+0x188>
   16440:	cbz	x24, 164bc <__gmpz_congruent_p@@Base+0x1c8>
   16444:	mov	x0, x23
   16448:	mov	x1, x22
   1644c:	mov	x3, x24
   16450:	bl	c2e0 <__gmpn_sub_n@plt>
   16454:	cbz	x0, 164c4 <__gmpz_congruent_p@@Base+0x1d0>
   16458:	cmp	x24, x19
   1645c:	b.ge	164f4 <__gmpz_congruent_p@@Base+0x200>  // b.tcont
   16460:	ldr	x8, [x22, x24, lsl #3]
   16464:	add	x9, x24, #0x1
   16468:	sub	x10, x8, #0x1
   1646c:	str	x10, [x23, x24, lsl #3]
   16470:	mov	x24, x9
   16474:	cbz	x8, 16458 <__gmpz_congruent_p@@Base+0x164>
   16478:	b	164c8 <__gmpz_congruent_p@@Base+0x1d4>
   1647c:	sub	x8, x19, #0x1
   16480:	add	x9, x8, #0x1
   16484:	cmp	x9, #0x1
   16488:	b.lt	16440 <__gmpz_congruent_p@@Base+0x14c>  // b.tstop
   1648c:	ldr	x9, [x22, x8, lsl #3]
   16490:	ldr	x10, [x2, x8, lsl #3]
   16494:	sub	x8, x8, #0x1
   16498:	cmp	x9, x10
   1649c:	b.eq	16480 <__gmpz_congruent_p@@Base+0x18c>  // b.none
   164a0:	b.hi	16440 <__gmpz_congruent_p@@Base+0x14c>  // b.pmore
   164a4:	mov	x0, x23
   164a8:	mov	x1, x2
   164ac:	mov	x2, x22
   164b0:	mov	x3, x19
   164b4:	bl	c2e0 <__gmpn_sub_n@plt>
   164b8:	b	164f4 <__gmpz_congruent_p@@Base+0x200>
   164bc:	mov	x9, xzr
   164c0:	b	164c8 <__gmpz_congruent_p@@Base+0x1d4>
   164c4:	mov	x9, x24
   164c8:	cmp	x22, x23
   164cc:	b.eq	164f4 <__gmpz_congruent_p@@Base+0x200>  // b.none
   164d0:	cmp	x9, x19
   164d4:	b.ge	164f4 <__gmpz_congruent_p@@Base+0x200>  // b.tcont
   164d8:	sub	x8, x19, x9
   164dc:	add	x10, x23, x9, lsl #3
   164e0:	add	x9, x22, x9, lsl #3
   164e4:	ldr	x11, [x9], #8
   164e8:	subs	x8, x8, #0x1
   164ec:	str	x11, [x10], #8
   164f0:	b.ne	164e4 <__gmpz_congruent_p@@Base+0x1f0>  // b.any
   164f4:	sub	x8, x23, #0x8
   164f8:	mov	x1, x19
   164fc:	subs	x19, x19, #0x1
   16500:	b.lt	16660 <__gmpz_congruent_p@@Base+0x36c>  // b.tstop
   16504:	ldr	x9, [x8, x1, lsl #3]
   16508:	cbz	x9, 164f8 <__gmpz_congruent_p@@Base+0x204>
   1650c:	b	16660 <__gmpz_congruent_p@@Base+0x36c>
   16510:	rbit	x9, x25
   16514:	clz	x9, x9
   16518:	lsr	x11, x25, x9
   1651c:	neg	x9, x9
   16520:	lsl	x9, x10, x9
   16524:	orr	x25, x9, x11
   16528:	tbz	w8, #31, 16534 <__gmpz_congruent_p@@Base+0x240>
   1652c:	b	163d0 <__gmpz_congruent_p@@Base+0xdc>
   16530:	mov	x23, x8
   16534:	cmp	x19, #0x28
   16538:	b.lt	1655c <__gmpz_congruent_p@@Base+0x268>  // b.tstop
   1653c:	mov	x0, x22
   16540:	mov	x1, x19
   16544:	mov	x2, x25
   16548:	bl	c400 <__gmpn_mod_1@plt>
   1654c:	cmp	x23, x25
   16550:	b.cs	1659c <__gmpz_congruent_p@@Base+0x2a8>  // b.hs, b.nlast
   16554:	cmp	x0, x23
   16558:	b	165a8 <__gmpz_congruent_p@@Base+0x2b4>
   1655c:	rbit	x8, x25
   16560:	clz	x8, x8
   16564:	tst	x25, #0x1
   16568:	csel	x8, x8, xzr, eq  // eq = none
   1656c:	lsr	x20, x25, x8
   16570:	mov	x0, x22
   16574:	mov	x1, x19
   16578:	mov	x2, x20
   1657c:	mov	x3, x23
   16580:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   16584:	cmp	x0, #0x0
   16588:	cset	w8, eq  // eq = none
   1658c:	cmp	x0, x20
   16590:	cset	w9, eq  // eq = none
   16594:	orr	w19, w8, w9
   16598:	b	1667c <__gmpz_congruent_p@@Base+0x388>
   1659c:	udiv	x8, x23, x25
   165a0:	msub	x8, x8, x25, x23
   165a4:	cmp	x0, x8
   165a8:	cset	w19, eq  // eq = none
   165ac:	b	1667c <__gmpz_congruent_p@@Base+0x388>
   165b0:	bl	ce90 <__gmpz_cmp@plt>
   165b4:	cmp	w0, #0x0
   165b8:	b	165a8 <__gmpz_congruent_p@@Base+0x2b4>
   165bc:	add	x0, x29, #0x18
   165c0:	mov	x23, x2
   165c4:	mov	w25, w8
   165c8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   165cc:	mov	w8, w25
   165d0:	mov	x2, x23
   165d4:	mov	x23, x0
   165d8:	tbz	w8, #31, 16438 <__gmpz_congruent_p@@Base+0x144>
   165dc:	cbz	x24, 1661c <__gmpz_congruent_p@@Base+0x328>
   165e0:	mov	x0, x23
   165e4:	mov	x1, x22
   165e8:	mov	x3, x24
   165ec:	bl	ca90 <__gmpn_add_n@plt>
   165f0:	cbz	x0, 16624 <__gmpz_congruent_p@@Base+0x330>
   165f4:	mov	w8, #0x1                   	// #1
   165f8:	cmp	x24, x19
   165fc:	b.ge	16658 <__gmpz_congruent_p@@Base+0x364>  // b.tcont
   16600:	ldr	x9, [x22, x24, lsl #3]
   16604:	adds	x10, x9, #0x1
   16608:	add	x9, x24, #0x1
   1660c:	str	x10, [x23, x24, lsl #3]
   16610:	mov	x24, x9
   16614:	b.cs	165f8 <__gmpz_congruent_p@@Base+0x304>  // b.hs, b.nlast
   16618:	b	16628 <__gmpz_congruent_p@@Base+0x334>
   1661c:	mov	x9, xzr
   16620:	b	16628 <__gmpz_congruent_p@@Base+0x334>
   16624:	mov	x9, x24
   16628:	cmp	x22, x23
   1662c:	mov	x8, xzr
   16630:	b.eq	16658 <__gmpz_congruent_p@@Base+0x364>  // b.none
   16634:	cmp	x9, x19
   16638:	b.ge	16658 <__gmpz_congruent_p@@Base+0x364>  // b.tcont
   1663c:	sub	x8, x19, x9
   16640:	add	x10, x23, x9, lsl #3
   16644:	add	x9, x22, x9, lsl #3
   16648:	ldr	x11, [x9], #8
   1664c:	subs	x8, x8, #0x1
   16650:	str	x11, [x10], #8
   16654:	b.ne	16648 <__gmpz_congruent_p@@Base+0x354>  // b.any
   16658:	add	x1, x8, x19
   1665c:	str	x8, [x23, x19, lsl #3]
   16660:	mov	x0, x23
   16664:	mov	x2, x20
   16668:	mov	x3, x21
   1666c:	bl	d380 <__gmpn_divisible_p@plt>
   16670:	ldr	x8, [x29, #24]
   16674:	mov	w19, w0
   16678:	cbnz	x8, 1669c <__gmpz_congruent_p@@Base+0x3a8>
   1667c:	mov	w0, w19
   16680:	mov	sp, x29
   16684:	ldp	x20, x19, [sp, #64]
   16688:	ldp	x22, x21, [sp, #48]
   1668c:	ldp	x24, x23, [sp, #32]
   16690:	ldr	x25, [sp, #16]
   16694:	ldp	x29, x30, [sp], #80
   16698:	ret
   1669c:	mov	x0, x8
   166a0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   166a4:	b	1667c <__gmpz_congruent_p@@Base+0x388>

00000000000166a8 <__gmpz_congruent_2exp_p@@Base>:
   166a8:	ldrsw	x13, [x0, #4]
   166ac:	ldrsw	x15, [x1, #4]
   166b0:	cmp	x13, #0x0
   166b4:	cneg	x8, x13, mi  // mi = first
   166b8:	cmp	x15, #0x0
   166bc:	cneg	x9, x15, mi  // mi = first
   166c0:	cmp	x8, x9
   166c4:	csel	x11, x9, x8, lt  // lt = tstop
   166c8:	csel	x12, x8, x9, lt  // lt = tstop
   166cc:	csel	x9, x1, x0, lt  // lt = tstop
   166d0:	ldr	x10, [x9, #8]
   166d4:	mov	x9, #0xffffffffffffffff    	// #-1
   166d8:	lsl	x9, x9, x2
   166dc:	csel	x14, x0, x1, lt  // lt = tstop
   166e0:	lsr	x8, x2, #6
   166e4:	mvn	x9, x9
   166e8:	cbz	x12, 167e8 <__gmpz_congruent_2exp_p@@Base+0x140>
   166ec:	ldr	x14, [x14, #8]
   166f0:	eor	w13, w15, w13
   166f4:	tbnz	w13, #31, 1672c <__gmpz_congruent_2exp_p@@Base+0x84>
   166f8:	cmp	x12, x8
   166fc:	sub	x13, x14, #0x8
   16700:	csel	x16, x12, x8, cc  // cc = lo, ul, last
   16704:	sub	x15, x10, #0x8
   16708:	subs	x17, x16, #0x1
   1670c:	b.lt	167d0 <__gmpz_congruent_2exp_p@@Base+0x128>  // b.tstop
   16710:	ldr	x18, [x15, x16, lsl #3]
   16714:	ldr	x16, [x13, x16, lsl #3]
   16718:	cmp	x18, x16
   1671c:	mov	x16, x17
   16720:	b.eq	16708 <__gmpz_congruent_2exp_p@@Base+0x60>  // b.none
   16724:	mov	w0, wzr
   16728:	ret
   1672c:	mov	x15, xzr
   16730:	and	w13, w2, #0x3f
   16734:	ldr	x16, [x10, x15, lsl #3]
   16738:	ldr	x17, [x14, x15, lsl #3]
   1673c:	cmp	x8, x15
   16740:	add	x17, x17, x16
   16744:	b.eq	1681c <__gmpz_congruent_2exp_p@@Base+0x174>  // b.none
   16748:	cbnz	x17, 16724 <__gmpz_congruent_2exp_p@@Base+0x7c>
   1674c:	add	x15, x15, #0x1
   16750:	cbz	x16, 16734 <__gmpz_congruent_2exp_p@@Base+0x8c>
   16754:	cmp	x15, x12
   16758:	b.cs	16788 <__gmpz_congruent_2exp_p@@Base+0xe0>  // b.hs, b.nlast
   1675c:	ldr	x16, [x10, x15, lsl #3]
   16760:	ldr	x17, [x14, x15, lsl #3]
   16764:	cmp	x15, x8
   16768:	eor	x16, x17, x16
   1676c:	b.cs	16828 <__gmpz_congruent_2exp_p@@Base+0x180>  // b.hs, b.nlast
   16770:	cmn	x16, #0x1
   16774:	b.ne	16724 <__gmpz_congruent_2exp_p@@Base+0x7c>  // b.any
   16778:	add	x15, x15, #0x1
   1677c:	cmp	x15, x12
   16780:	b.cc	1675c <__gmpz_congruent_2exp_p@@Base+0xb4>  // b.lo, b.ul, b.last
   16784:	mov	x15, x12
   16788:	cmp	x11, x8
   1678c:	b.cc	16724 <__gmpz_congruent_2exp_p@@Base+0x7c>  // b.lo, b.ul, b.last
   16790:	cmp	x15, x8
   16794:	b.cs	167b8 <__gmpz_congruent_2exp_p@@Base+0x110>  // b.hs, b.nlast
   16798:	sub	x12, x8, x15
   1679c:	add	x14, x10, x15, lsl #3
   167a0:	ldr	x15, [x14]
   167a4:	cmn	x15, #0x1
   167a8:	b.ne	16724 <__gmpz_congruent_2exp_p@@Base+0x7c>  // b.any
   167ac:	subs	x12, x12, #0x1
   167b0:	add	x14, x14, #0x8
   167b4:	b.ne	167a0 <__gmpz_congruent_2exp_p@@Base+0xf8>  // b.any
   167b8:	cbz	w13, 16830 <__gmpz_congruent_2exp_p@@Base+0x188>
   167bc:	cmp	x11, x8
   167c0:	b.eq	16724 <__gmpz_congruent_2exp_p@@Base+0x7c>  // b.none
   167c4:	ldr	x8, [x10, x8, lsl #3]
   167c8:	add	x8, x8, #0x1
   167cc:	b	16814 <__gmpz_congruent_2exp_p@@Base+0x16c>
   167d0:	cmp	x12, x8
   167d4:	b.ls	167e8 <__gmpz_congruent_2exp_p@@Base+0x140>  // b.plast
   167d8:	ldr	x10, [x10, x8, lsl #3]
   167dc:	ldr	x8, [x14, x8, lsl #3]
   167e0:	sub	x8, x10, x8
   167e4:	b	16814 <__gmpz_congruent_2exp_p@@Base+0x16c>
   167e8:	cmp	x11, x8
   167ec:	b.ls	16808 <__gmpz_congruent_2exp_p@@Base+0x160>  // b.plast
   167f0:	cmp	x12, x8
   167f4:	b.cs	16810 <__gmpz_congruent_2exp_p@@Base+0x168>  // b.hs, b.nlast
   167f8:	ldr	x11, [x10, x12, lsl #3]
   167fc:	cbnz	x11, 16724 <__gmpz_congruent_2exp_p@@Base+0x7c>
   16800:	add	x12, x12, #0x1
   16804:	b	167f0 <__gmpz_congruent_2exp_p@@Base+0x148>
   16808:	cmp	x11, x12
   1680c:	b	16820 <__gmpz_congruent_2exp_p@@Base+0x178>
   16810:	ldr	x8, [x10, x8, lsl #3]
   16814:	tst	x8, x9
   16818:	b	16820 <__gmpz_congruent_2exp_p@@Base+0x178>
   1681c:	tst	x17, x9
   16820:	cset	w0, eq  // eq = none
   16824:	ret
   16828:	bics	xzr, x9, x16
   1682c:	b	16820 <__gmpz_congruent_2exp_p@@Base+0x178>
   16830:	mov	w0, #0x1                   	// #1
   16834:	ret

0000000000016838 <__gmpz_congruent_ui_p@@Base>:
   16838:	stp	x29, x30, [sp, #-32]!
   1683c:	stp	x20, x19, [sp, #16]
   16840:	mov	x20, x1
   16844:	mov	x29, sp
   16848:	cbz	x2, 16940 <__gmpz_congruent_ui_p@@Base+0x108>
   1684c:	ldrsw	x1, [x0, #4]
   16850:	mov	x19, x2
   16854:	cbz	w1, 16884 <__gmpz_congruent_ui_p@@Base+0x4c>
   16858:	tbz	w1, #31, 168a8 <__gmpz_congruent_ui_p@@Base+0x70>
   1685c:	subs	x8, x19, x20
   16860:	neg	x1, x1
   16864:	b.cs	168a4 <__gmpz_congruent_ui_p@@Base+0x6c>  // b.hs, b.nlast
   16868:	clz	x8, x19
   1686c:	lsl	x8, x19, x8
   16870:	cmp	x8, x20
   16874:	cset	w9, cc  // cc = lo, ul, last
   16878:	lsl	x8, x8, x9
   1687c:	sub	x20, x8, x20
   16880:	b	168a8 <__gmpz_congruent_ui_p@@Base+0x70>
   16884:	cmp	x19, x20
   16888:	b.ls	16894 <__gmpz_congruent_ui_p@@Base+0x5c>  // b.plast
   1688c:	cmp	x20, #0x0
   16890:	b	16900 <__gmpz_congruent_ui_p@@Base+0xc8>
   16894:	udiv	x8, x20, x19
   16898:	msub	x8, x8, x19, x20
   1689c:	cmp	x8, #0x0
   168a0:	b	16900 <__gmpz_congruent_ui_p@@Base+0xc8>
   168a4:	mov	x20, x8
   168a8:	ldr	x0, [x0, #8]
   168ac:	cmp	x1, #0x28
   168b0:	b.lt	168cc <__gmpz_congruent_ui_p@@Base+0x94>  // b.tstop
   168b4:	mov	x2, x19
   168b8:	bl	c400 <__gmpn_mod_1@plt>
   168bc:	cmp	x20, x19
   168c0:	b.cs	168f4 <__gmpz_congruent_ui_p@@Base+0xbc>  // b.hs, b.nlast
   168c4:	cmp	x0, x20
   168c8:	b	16900 <__gmpz_congruent_ui_p@@Base+0xc8>
   168cc:	tbnz	w19, #0, 16914 <__gmpz_congruent_ui_p@@Base+0xdc>
   168d0:	ldr	x8, [x0]
   168d4:	neg	x9, x19
   168d8:	and	x9, x9, x19
   168dc:	sub	x9, x9, #0x1
   168e0:	sub	x8, x8, x20
   168e4:	tst	x8, x9
   168e8:	b.eq	16908 <__gmpz_congruent_ui_p@@Base+0xd0>  // b.none
   168ec:	mov	w0, wzr
   168f0:	b	16934 <__gmpz_congruent_ui_p@@Base+0xfc>
   168f4:	udiv	x8, x20, x19
   168f8:	msub	x8, x8, x19, x20
   168fc:	cmp	x0, x8
   16900:	cset	w0, eq  // eq = none
   16904:	b	16934 <__gmpz_congruent_ui_p@@Base+0xfc>
   16908:	rbit	x8, x19
   1690c:	clz	x8, x8
   16910:	lsr	x19, x19, x8
   16914:	mov	x2, x19
   16918:	mov	x3, x20
   1691c:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   16920:	cmp	x0, #0x0
   16924:	cset	w8, eq  // eq = none
   16928:	cmp	x0, x19
   1692c:	cset	w9, eq  // eq = none
   16930:	orr	w0, w8, w9
   16934:	ldp	x20, x19, [sp, #16]
   16938:	ldp	x29, x30, [sp], #32
   1693c:	ret
   16940:	mov	x1, x20
   16944:	bl	d210 <__gmpz_cmp_ui@plt>
   16948:	cmp	w0, #0x0
   1694c:	b	16900 <__gmpz_congruent_ui_p@@Base+0xc8>

0000000000016950 <__gmpz_divexact@@Base>:
   16950:	stp	x29, x30, [sp, #-80]!
   16954:	stp	x24, x23, [sp, #32]
   16958:	stp	x22, x21, [sp, #48]
   1695c:	stp	x20, x19, [sp, #64]
   16960:	ldr	w8, [x1, #4]
   16964:	ldr	w9, [x2, #4]
   16968:	mov	x19, x0
   1696c:	str	x25, [sp, #16]
   16970:	cmp	w8, #0x0
   16974:	cneg	w23, w8, mi  // mi = first
   16978:	cmp	w9, #0x0
   1697c:	cneg	w22, w9, mi  // mi = first
   16980:	cmp	w23, w22
   16984:	mov	x29, sp
   16988:	b.cs	16994 <__gmpz_divexact@@Base+0x44>  // b.hs, b.nlast
   1698c:	str	wzr, [x19, #4]
   16990:	b	16a6c <__gmpz_divexact@@Base+0x11c>
   16994:	sub	x25, x23, x22
   16998:	mov	x20, x1
   1699c:	mov	x21, x2
   169a0:	cmp	x19, x1
   169a4:	add	x1, x25, #0x1
   169a8:	str	xzr, [x29, #24]
   169ac:	b.eq	169cc <__gmpz_divexact@@Base+0x7c>  // b.none
   169b0:	cmp	x19, x21
   169b4:	b.eq	169cc <__gmpz_divexact@@Base+0x7c>  // b.none
   169b8:	ldrsw	x8, [x19]
   169bc:	cmp	x25, x8
   169c0:	b.ge	16aa0 <__gmpz_divexact@@Base+0x150>  // b.tcont
   169c4:	ldr	x24, [x19, #8]
   169c8:	b	169f0 <__gmpz_divexact@@Base+0xa0>
   169cc:	lsl	x1, x1, #3
   169d0:	mov	w8, #0x7f00                	// #32512
   169d4:	cmp	x1, x8
   169d8:	b.hi	16aac <__gmpz_divexact@@Base+0x15c>  // b.pmore
   169dc:	add	x9, x1, #0xf
   169e0:	mov	x8, sp
   169e4:	and	x9, x9, #0xfffffffffffffff0
   169e8:	sub	x24, x8, x9
   169ec:	mov	sp, x24
   169f0:	ldr	x1, [x20, #8]
   169f4:	ldr	x3, [x21, #8]
   169f8:	mov	x0, x24
   169fc:	mov	x2, x23
   16a00:	mov	x4, x22
   16a04:	bl	c450 <__gmpn_divexact@plt>
   16a08:	add	x22, x25, #0x1
   16a0c:	mov	x23, x25
   16a10:	cmp	x22, #0x1
   16a14:	b.lt	16a24 <__gmpz_divexact@@Base+0xd4>  // b.tstop
   16a18:	ldr	x8, [x24, x23, lsl #3]
   16a1c:	sub	x25, x23, #0x1
   16a20:	cbz	x8, 16a08 <__gmpz_divexact@@Base+0xb8>
   16a24:	ldr	x0, [x19, #8]
   16a28:	cmp	x24, x0
   16a2c:	b.eq	16a48 <__gmpz_divexact@@Base+0xf8>  // b.none
   16a30:	ldrsw	x8, [x19]
   16a34:	cmp	x22, x8
   16a38:	b.gt	16a90 <__gmpz_divexact@@Base+0x140>
   16a3c:	mov	x1, x24
   16a40:	mov	x2, x22
   16a44:	bl	ca70 <__gmpn_copyi@plt>
   16a48:	ldr	w8, [x20, #4]
   16a4c:	ldr	w9, [x21, #4]
   16a50:	eor	w8, w9, w8
   16a54:	mvn	w9, w23
   16a58:	cmp	w8, #0x0
   16a5c:	csel	x8, x22, x9, ge  // ge = tcont
   16a60:	str	w8, [x19, #4]
   16a64:	ldr	x0, [x29, #24]
   16a68:	cbnz	x0, 16a88 <__gmpz_divexact@@Base+0x138>
   16a6c:	mov	sp, x29
   16a70:	ldp	x20, x19, [sp, #64]
   16a74:	ldp	x22, x21, [sp, #48]
   16a78:	ldp	x24, x23, [sp, #32]
   16a7c:	ldr	x25, [sp, #16]
   16a80:	ldp	x29, x30, [sp], #80
   16a84:	ret
   16a88:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   16a8c:	b	16a6c <__gmpz_divexact@@Base+0x11c>
   16a90:	mov	x0, x19
   16a94:	mov	x1, x22
   16a98:	bl	c090 <__gmpz_realloc@plt>
   16a9c:	b	16a3c <__gmpz_divexact@@Base+0xec>
   16aa0:	mov	x0, x19
   16aa4:	bl	c090 <__gmpz_realloc@plt>
   16aa8:	b	16ab4 <__gmpz_divexact@@Base+0x164>
   16aac:	add	x0, x29, #0x18
   16ab0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   16ab4:	mov	x24, x0
   16ab8:	b	169f0 <__gmpz_divexact@@Base+0xa0>

0000000000016abc <__gmpz_divexact_gcd@@Base>:
   16abc:	stp	x29, x30, [sp, #-64]!
   16ac0:	stp	x22, x21, [sp, #32]
   16ac4:	stp	x20, x19, [sp, #48]
   16ac8:	ldr	w8, [x1, #4]
   16acc:	mov	x19, x0
   16ad0:	str	x23, [sp, #16]
   16ad4:	mov	x29, sp
   16ad8:	cbz	w8, 16b44 <__gmpz_divexact_gcd@@Base+0x88>
   16adc:	ldr	w8, [x2, #4]
   16ae0:	cmp	w8, #0x1
   16ae4:	b.ne	16b4c <__gmpz_divexact_gcd@@Base+0x90>  // b.any
   16ae8:	ldr	x8, [x2, #8]
   16aec:	ldr	x20, [x8]
   16af0:	tbnz	w20, #0, 16b0c <__gmpz_divexact_gcd@@Base+0x50>
   16af4:	rbit	x8, x20
   16af8:	clz	x2, x8
   16afc:	mov	x0, x19
   16b00:	lsr	x20, x20, x2
   16b04:	bl	cc90 <__gmpz_tdiv_q_2exp@plt>
   16b08:	mov	x1, x19
   16b0c:	cmp	x20, #0x5
   16b10:	b.eq	16b64 <__gmpz_divexact_gcd@@Base+0xa8>  // b.none
   16b14:	cmp	x20, #0x3
   16b18:	b.eq	16b8c <__gmpz_divexact_gcd@@Base+0xd0>  // b.none
   16b1c:	cmp	x20, #0x1
   16b20:	b.ne	16be0 <__gmpz_divexact_gcd@@Base+0x124>  // b.any
   16b24:	cmp	x1, x19
   16b28:	b.eq	16c34 <__gmpz_divexact_gcd@@Base+0x178>  // b.none
   16b2c:	mov	x0, x19
   16b30:	ldp	x20, x19, [sp, #48]
   16b34:	ldp	x22, x21, [sp, #32]
   16b38:	ldr	x23, [sp, #16]
   16b3c:	ldp	x29, x30, [sp], #64
   16b40:	b	c440 <__gmpz_set@plt>
   16b44:	str	wzr, [x19, #4]
   16b48:	b	16c34 <__gmpz_divexact_gcd@@Base+0x178>
   16b4c:	mov	x0, x19
   16b50:	ldp	x20, x19, [sp, #48]
   16b54:	ldp	x22, x21, [sp, #32]
   16b58:	ldr	x23, [sp, #16]
   16b5c:	ldp	x29, x30, [sp], #64
   16b60:	b	c410 <__gmpz_divexact@plt>
   16b64:	ldrsw	x22, [x1, #4]
   16b68:	ldrsw	x8, [x19]
   16b6c:	cmp	x22, #0x0
   16b70:	cneg	x20, x22, mi  // mi = first
   16b74:	cmp	x20, x8
   16b78:	b.gt	16c48 <__gmpz_divexact_gcd@@Base+0x18c>
   16b7c:	ldr	x21, [x19, #8]
   16b80:	ldr	x1, [x1, #8]
   16b84:	mov	x3, #0x3333333333333333    	// #3689348814741910323
   16b88:	b	16bb0 <__gmpz_divexact_gcd@@Base+0xf4>
   16b8c:	ldrsw	x22, [x1, #4]
   16b90:	ldrsw	x8, [x19]
   16b94:	cmp	x22, #0x0
   16b98:	cneg	x20, x22, mi  // mi = first
   16b9c:	cmp	x20, x8
   16ba0:	b.gt	16c64 <__gmpz_divexact_gcd@@Base+0x1a8>
   16ba4:	ldr	x21, [x19, #8]
   16ba8:	ldr	x1, [x1, #8]
   16bac:	mov	x3, #0x5555555555555555    	// #6148914691236517205
   16bb0:	mov	x0, x21
   16bb4:	mov	x2, x20
   16bb8:	mov	x4, xzr
   16bbc:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
   16bc0:	add	x8, x21, x20, lsl #3
   16bc4:	ldur	x8, [x8, #-8]
   16bc8:	cmp	x8, #0x0
   16bcc:	cset	w8, eq  // eq = none
   16bd0:	sub	x8, x20, x8
   16bd4:	neg	w9, w8
   16bd8:	cmp	w22, #0x0
   16bdc:	b	16c2c <__gmpz_divexact_gcd@@Base+0x170>
   16be0:	ldrsw	x23, [x1, #4]
   16be4:	ldrsw	x8, [x19]
   16be8:	cmp	x23, #0x0
   16bec:	cneg	x21, x23, mi  // mi = first
   16bf0:	cmp	x21, x8
   16bf4:	b.gt	16c80 <__gmpz_divexact_gcd@@Base+0x1c4>
   16bf8:	ldr	x22, [x19, #8]
   16bfc:	ldr	x1, [x1, #8]
   16c00:	mov	x0, x22
   16c04:	mov	x2, x21
   16c08:	mov	x3, x20
   16c0c:	bl	c790 <__gmpn_divexact_1@plt>
   16c10:	add	x8, x22, x21, lsl #3
   16c14:	ldur	x8, [x8, #-8]
   16c18:	cmp	x8, #0x0
   16c1c:	cset	w8, eq  // eq = none
   16c20:	sub	x8, x21, x8
   16c24:	neg	w9, w8
   16c28:	cmp	w23, #0x0
   16c2c:	csel	x8, x8, x9, gt
   16c30:	str	w8, [x19, #4]
   16c34:	ldp	x20, x19, [sp, #48]
   16c38:	ldp	x22, x21, [sp, #32]
   16c3c:	ldr	x23, [sp, #16]
   16c40:	ldp	x29, x30, [sp], #64
   16c44:	ret
   16c48:	mov	x0, x19
   16c4c:	mov	x21, x1
   16c50:	mov	x1, x20
   16c54:	bl	c090 <__gmpz_realloc@plt>
   16c58:	mov	x1, x21
   16c5c:	mov	x21, x0
   16c60:	b	16b80 <__gmpz_divexact_gcd@@Base+0xc4>
   16c64:	mov	x0, x19
   16c68:	mov	x21, x1
   16c6c:	mov	x1, x20
   16c70:	bl	c090 <__gmpz_realloc@plt>
   16c74:	mov	x1, x21
   16c78:	mov	x21, x0
   16c7c:	b	16ba8 <__gmpz_divexact_gcd@@Base+0xec>
   16c80:	mov	x0, x19
   16c84:	mov	x22, x1
   16c88:	mov	x1, x21
   16c8c:	bl	c090 <__gmpz_realloc@plt>
   16c90:	mov	x1, x22
   16c94:	mov	x22, x0
   16c98:	b	16bfc <__gmpz_divexact_gcd@@Base+0x140>

0000000000016c9c <__gmpz_divexact_ui@@Base>:
   16c9c:	stp	x29, x30, [sp, #-64]!
   16ca0:	stp	x24, x23, [sp, #16]
   16ca4:	stp	x22, x21, [sp, #32]
   16ca8:	stp	x20, x19, [sp, #48]
   16cac:	mov	x29, sp
   16cb0:	cbz	x2, 16d44 <__gmpz_divexact_ui@@Base+0xa8>
   16cb4:	ldrsw	x24, [x1, #4]
   16cb8:	mov	x21, x1
   16cbc:	mov	x19, x0
   16cc0:	cbz	w24, 16d14 <__gmpz_divexact_ui@@Base+0x78>
   16cc4:	ldrsw	x8, [x19]
   16cc8:	cmp	w24, #0x0
   16ccc:	cneg	x22, x24, lt  // lt = tstop
   16cd0:	mov	x20, x2
   16cd4:	cmp	x22, x8
   16cd8:	b.gt	16d30 <__gmpz_divexact_ui@@Base+0x94>
   16cdc:	ldr	x23, [x19, #8]
   16ce0:	ldr	x1, [x21, #8]
   16ce4:	mov	x0, x23
   16ce8:	mov	x2, x22
   16cec:	mov	x3, x20
   16cf0:	bl	c790 <__gmpn_divexact_1@plt>
   16cf4:	add	x8, x23, x22, lsl #3
   16cf8:	ldur	x8, [x8, #-8]
   16cfc:	cmp	x8, #0x0
   16d00:	cset	w8, eq  // eq = none
   16d04:	sub	w8, w22, w8
   16d08:	cmp	w24, #0x0
   16d0c:	cneg	w8, w8, lt  // lt = tstop
   16d10:	b	16d18 <__gmpz_divexact_ui@@Base+0x7c>
   16d14:	mov	w8, wzr
   16d18:	str	w8, [x19, #4]
   16d1c:	ldp	x20, x19, [sp, #48]
   16d20:	ldp	x22, x21, [sp, #32]
   16d24:	ldp	x24, x23, [sp, #16]
   16d28:	ldp	x29, x30, [sp], #64
   16d2c:	ret
   16d30:	mov	x0, x19
   16d34:	mov	x1, x22
   16d38:	bl	c090 <__gmpz_realloc@plt>
   16d3c:	mov	x23, x0
   16d40:	b	16ce0 <__gmpz_divexact_ui@@Base+0x44>
   16d44:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000016d48 <__gmpz_divisible_p@@Base>:
   16d48:	ldrsw	x8, [x1, #4]
   16d4c:	ldrsw	x9, [x0, #4]
   16d50:	cbz	w8, 16d70 <__gmpz_divisible_p@@Base+0x28>
   16d54:	ldr	x0, [x0, #8]
   16d58:	ldr	x2, [x1, #8]
   16d5c:	cmp	x9, #0x0
   16d60:	cneg	x1, x9, mi  // mi = first
   16d64:	cmp	x8, #0x0
   16d68:	cneg	x3, x8, mi  // mi = first
   16d6c:	b	d380 <__gmpn_divisible_p@plt>
   16d70:	cmp	w9, #0x0
   16d74:	cset	w0, eq  // eq = none
   16d78:	ret

0000000000016d7c <__gmpz_divisible_ui_p@@Base>:
   16d7c:	stp	x29, x30, [sp, #-16]!
   16d80:	ldrsw	x9, [x0, #4]
   16d84:	mov	x8, x0
   16d88:	mov	x29, sp
   16d8c:	cmp	x9, #0x0
   16d90:	cset	w10, eq  // eq = none
   16d94:	cmp	x1, #0x0
   16d98:	cset	w11, ne  // ne = any
   16d9c:	orr	w0, w10, w11
   16da0:	cbz	x1, 16e08 <__gmpz_divisible_ui_p@@Base+0x8c>
   16da4:	cbz	w9, 16e08 <__gmpz_divisible_ui_p@@Base+0x8c>
   16da8:	ldr	x0, [x8, #8]
   16dac:	cmp	x9, #0x0
   16db0:	mov	x2, x1
   16db4:	cneg	x1, x9, mi  // mi = first
   16db8:	cmp	x1, #0x28
   16dbc:	b.lt	16dc8 <__gmpz_divisible_ui_p@@Base+0x4c>  // b.tstop
   16dc0:	bl	c400 <__gmpn_mod_1@plt>
   16dc4:	b	16e00 <__gmpz_divisible_ui_p@@Base+0x84>
   16dc8:	tbnz	w2, #0, 16df8 <__gmpz_divisible_ui_p@@Base+0x7c>
   16dcc:	ldr	x8, [x0]
   16dd0:	neg	x9, x2
   16dd4:	and	x9, x9, x2
   16dd8:	sub	x9, x9, #0x1
   16ddc:	tst	x8, x9
   16de0:	b.eq	16dec <__gmpz_divisible_ui_p@@Base+0x70>  // b.none
   16de4:	mov	w0, wzr
   16de8:	b	16e08 <__gmpz_divisible_ui_p@@Base+0x8c>
   16dec:	rbit	x8, x2
   16df0:	clz	x8, x8
   16df4:	lsr	x2, x2, x8
   16df8:	mov	x3, xzr
   16dfc:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   16e00:	cmp	x0, #0x0
   16e04:	cset	w0, eq  // eq = none
   16e08:	ldp	x29, x30, [sp], #16
   16e0c:	ret

0000000000016e10 <__gmpz_divisible_2exp_p@@Base>:
   16e10:	ldr	w8, [x0, #4]
   16e14:	cmp	w8, #0x0
   16e18:	cneg	w9, w8, mi  // mi = first
   16e1c:	lsr	x8, x1, #6
   16e20:	cmp	x8, x9
   16e24:	b.cs	16e60 <__gmpz_divisible_2exp_p@@Base+0x50>  // b.hs, b.nlast
   16e28:	ldr	x9, [x0, #8]
   16e2c:	cbz	x8, 16e4c <__gmpz_divisible_2exp_p@@Base+0x3c>
   16e30:	mov	x10, x9
   16e34:	mov	x11, x8
   16e38:	ldr	x12, [x10]
   16e3c:	cbnz	x12, 16e6c <__gmpz_divisible_2exp_p@@Base+0x5c>
   16e40:	subs	x11, x11, #0x1
   16e44:	add	x10, x10, #0x8
   16e48:	b.ne	16e38 <__gmpz_divisible_2exp_p@@Base+0x28>  // b.any
   16e4c:	ldr	x8, [x9, x8, lsl #3]
   16e50:	mov	x9, #0xffffffffffffffff    	// #-1
   16e54:	lsl	x9, x9, x1
   16e58:	bics	xzr, x8, x9
   16e5c:	b	16e64 <__gmpz_divisible_2exp_p@@Base+0x54>
   16e60:	cmp	w9, #0x0
   16e64:	cset	w0, eq  // eq = none
   16e68:	ret
   16e6c:	mov	w0, wzr
   16e70:	ret

0000000000016e74 <__gmpz_dump@@Base>:
   16e74:	stp	x29, x30, [sp, #-32]!
   16e78:	mov	x2, x0
   16e7c:	mov	w1, #0xa                   	// #10
   16e80:	mov	x0, xzr
   16e84:	str	x19, [sp, #16]
   16e88:	mov	x29, sp
   16e8c:	bl	c3c0 <__gmpz_get_str@plt>
   16e90:	mov	x19, x0
   16e94:	bl	c9d0 <puts@plt>
   16e98:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   16e9c:	ldr	x8, [x8, #4016]
   16ea0:	ldr	x0, [x8]
   16ea4:	str	x0, [x29, #24]
   16ea8:	mov	x0, x19
   16eac:	bl	bf70 <strlen@plt>
   16eb0:	add	x1, x0, #0x1
   16eb4:	mov	x0, x19
   16eb8:	ldr	x2, [x29, #24]
   16ebc:	ldr	x19, [sp, #16]
   16ec0:	ldp	x29, x30, [sp], #32
   16ec4:	br	x2

0000000000016ec8 <__gmpz_export@@Base>:
   16ec8:	sub	sp, sp, #0x70
   16ecc:	stp	x29, x30, [sp, #16]
   16ed0:	stp	x28, x27, [sp, #32]
   16ed4:	stp	x26, x25, [sp, #48]
   16ed8:	stp	x24, x23, [sp, #64]
   16edc:	stp	x22, x21, [sp, #80]
   16ee0:	stp	x20, x19, [sp, #96]
   16ee4:	ldrsw	x9, [x6, #4]
   16ee8:	cmp	x1, #0x0
   16eec:	add	x8, sp, #0x8
   16ef0:	mov	x19, x0
   16ef4:	csel	x8, x8, x1, eq  // eq = none
   16ef8:	add	x29, sp, #0x10
   16efc:	cbz	w9, 170d8 <__gmpz_export@@Base+0x210>
   16f00:	ldr	x21, [x6, #8]
   16f04:	cmp	x9, #0x0
   16f08:	cneg	x26, x9, mi  // mi = first
   16f0c:	lsl	x10, x3, #3
   16f10:	add	x9, x21, x26, lsl #3
   16f14:	ldur	x9, [x9, #-8]
   16f18:	sub	x27, x10, x5
   16f1c:	add	x10, x27, x26, lsl #6
   16f20:	mov	x24, x5
   16f24:	clz	x9, x9
   16f28:	mvn	x9, x9
   16f2c:	add	x28, x9, x10
   16f30:	mov	w25, w4
   16f34:	mov	x22, x3
   16f38:	mov	w23, w2
   16f3c:	udiv	x20, x28, x27
   16f40:	str	x20, [x8]
   16f44:	cbnz	x19, 16f60 <__gmpz_export@@Base+0x98>
   16f48:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   16f4c:	ldr	x8, [x8, #3840]
   16f50:	mul	x0, x20, x22
   16f54:	ldr	x8, [x8]
   16f58:	blr	x8
   16f5c:	mov	x19, x0
   16f60:	cmp	w25, #0x0
   16f64:	csinv	w18, w25, wzr, ne  // ne = any
   16f68:	cbz	x24, 17100 <__gmpz_export@@Base+0x238>
   16f6c:	cmp	w18, #0x0
   16f70:	cneg	x12, x22, lt  // lt = tstop
   16f74:	cmp	w23, #0x0
   16f78:	cneg	x13, x22, ge  // ge = tcont
   16f7c:	cmp	x27, x28
   16f80:	b.hi	170dc <__gmpz_export@@Base+0x214>  // b.pmore
   16f84:	and	w11, w27, #0x7
   16f88:	mov	x15, #0xffffffffffffffff    	// #-1
   16f8c:	sub	x16, x20, #0x1
   16f90:	mov	x8, xzr
   16f94:	cmp	w23, #0x0
   16f98:	mov	w17, #0x40                  	// #64
   16f9c:	lsl	x1, x15, x11
   16fa0:	mul	x2, x16, x22
   16fa4:	sub	x0, x22, #0x1
   16fa8:	sub	w15, w17, w11
   16fac:	mvn	x17, x1
   16fb0:	csel	x1, x2, x8, ge  // ge = tcont
   16fb4:	cmp	w18, #0x0
   16fb8:	lsr	x10, x27, #3
   16fbc:	sub	x14, x8, w18, sxtw
   16fc0:	add	x18, x19, x1
   16fc4:	csel	x0, x0, x8, ge  // ge = tcont
   16fc8:	mov	w9, wzr
   16fcc:	add	x12, x12, x13
   16fd0:	add	x13, x21, x26, lsl #3
   16fd4:	add	x16, x10, #0x1
   16fd8:	add	x18, x18, x0
   16fdc:	mov	w0, #0x8                   	// #8
   16fe0:	mov	x1, x8
   16fe4:	cbz	x10, 17044 <__gmpz_export@@Base+0x17c>
   16fe8:	mov	x2, x10
   16fec:	cmp	w9, #0x8
   16ff0:	b.lt	17004 <__gmpz_export@@Base+0x13c>  // b.tstop
   16ff4:	strb	w1, [x18]
   16ff8:	lsr	x1, x1, #8
   16ffc:	mov	w3, #0xfffffff8            	// #-8
   17000:	b	17034 <__gmpz_export@@Base+0x16c>
   17004:	cmp	x21, x13
   17008:	b.eq	17014 <__gmpz_export@@Base+0x14c>  // b.none
   1700c:	ldr	x3, [x21], #8
   17010:	b	1701c <__gmpz_export@@Base+0x154>
   17014:	mov	x3, xzr
   17018:	mov	x21, x13
   1701c:	lsl	x4, x3, x9
   17020:	sub	w5, w0, w9
   17024:	orr	w4, w4, w1
   17028:	lsr	x1, x3, x5
   1702c:	mov	w3, #0x38                  	// #56
   17030:	strb	w4, [x18]
   17034:	add	w9, w9, w3
   17038:	subs	x2, x2, #0x1
   1703c:	add	x18, x18, x14
   17040:	b.ne	16fec <__gmpz_export@@Base+0x124>  // b.any
   17044:	cbz	w11, 17060 <__gmpz_export@@Base+0x198>
   17048:	cmp	w9, w11
   1704c:	b.ge	17068 <__gmpz_export@@Base+0x1a0>  // b.tcont
   17050:	cmp	x21, x13
   17054:	b.eq	1707c <__gmpz_export@@Base+0x1b4>  // b.none
   17058:	ldr	x2, [x21], #8
   1705c:	b	17084 <__gmpz_export@@Base+0x1bc>
   17060:	mov	x2, x10
   17064:	b	170a8 <__gmpz_export@@Base+0x1e0>
   17068:	and	w2, w1, w17
   1706c:	lsr	x1, x1, x11
   17070:	strb	w2, [x18]
   17074:	sub	w9, w9, w11
   17078:	b	170a0 <__gmpz_export@@Base+0x1d8>
   1707c:	mov	x2, xzr
   17080:	mov	x21, x13
   17084:	lsl	x3, x2, x9
   17088:	sub	w4, w11, w9
   1708c:	orr	w3, w3, w1
   17090:	lsr	x1, x2, x4
   17094:	and	w2, w3, w17
   17098:	add	w9, w15, w9
   1709c:	strb	w2, [x18]
   170a0:	add	x18, x18, x14
   170a4:	mov	x2, x16
   170a8:	cmp	x2, x22
   170ac:	b.cs	170c4 <__gmpz_export@@Base+0x1fc>  // b.hs, b.nlast
   170b0:	sub	x2, x22, x2
   170b4:	strb	wzr, [x18]
   170b8:	subs	x2, x2, #0x1
   170bc:	add	x18, x18, x14
   170c0:	b.ne	170b4 <__gmpz_export@@Base+0x1ec>  // b.any
   170c4:	add	x8, x8, #0x1
   170c8:	cmp	x8, x20
   170cc:	add	x18, x18, x12
   170d0:	b.cc	16fe4 <__gmpz_export@@Base+0x11c>  // b.lo, b.ul, b.last
   170d4:	b	170dc <__gmpz_export@@Base+0x214>
   170d8:	str	xzr, [x8]
   170dc:	mov	x0, x19
   170e0:	ldp	x20, x19, [sp, #96]
   170e4:	ldp	x22, x21, [sp, #80]
   170e8:	ldp	x24, x23, [sp, #64]
   170ec:	ldp	x26, x25, [sp, #48]
   170f0:	ldp	x28, x27, [sp, #32]
   170f4:	ldp	x29, x30, [sp, #16]
   170f8:	add	sp, sp, #0x70
   170fc:	ret
   17100:	cmp	x22, #0x8
   17104:	b.ne	16f6c <__gmpz_export@@Base+0xa4>  // b.any
   17108:	and	x8, x19, #0x7
   1710c:	cbnz	x8, 16f6c <__gmpz_export@@Base+0xa4>
   17110:	and	w8, w18, w23
   17114:	cmn	w8, #0x1
   17118:	b.eq	17154 <__gmpz_export@@Base+0x28c>  // b.none
   1711c:	cmp	w23, #0x1
   17120:	b.ne	17168 <__gmpz_export@@Base+0x2a0>  // b.any
   17124:	cmn	w18, #0x1
   17128:	b.ne	17168 <__gmpz_export@@Base+0x2a0>  // b.any
   1712c:	cmp	x20, #0x1
   17130:	b.lt	170dc <__gmpz_export@@Base+0x214>  // b.tstop
   17134:	mov	x8, xzr
   17138:	add	x9, x21, x20, lsl #3
   1713c:	ldr	x10, [x9, #-8]!
   17140:	str	x10, [x19, x8, lsl #3]
   17144:	add	x8, x8, #0x1
   17148:	cmp	x8, x20
   1714c:	b.lt	1713c <__gmpz_export@@Base+0x274>  // b.tstop
   17150:	b	170dc <__gmpz_export@@Base+0x214>
   17154:	mov	x0, x19
   17158:	mov	x1, x21
   1715c:	mov	x2, x20
   17160:	bl	ca70 <__gmpn_copyi@plt>
   17164:	b	170dc <__gmpz_export@@Base+0x214>
   17168:	cmn	w23, #0x1
   1716c:	b.ne	171dc <__gmpz_export@@Base+0x314>  // b.any
   17170:	cmp	w18, #0x1
   17174:	b.ne	171dc <__gmpz_export@@Base+0x314>  // b.any
   17178:	cmp	x20, #0x1
   1717c:	b.lt	170dc <__gmpz_export@@Base+0x214>  // b.tstop
   17180:	mov	x8, xzr
   17184:	ldr	x9, [x21, x8, lsl #3]
   17188:	lsl	x12, x9, #40
   1718c:	and	x12, x12, #0xff000000000000
   17190:	lsr	x11, x9, #16
   17194:	bfi	x12, x9, #56, #8
   17198:	lsr	x10, x9, #24
   1719c:	bfi	x12, x11, #40, #8
   171a0:	lsr	x11, x9, #8
   171a4:	and	x11, x11, #0xff000000
   171a8:	bfi	x12, x10, #32, #8
   171ac:	orr	x11, x12, x11
   171b0:	lsr	x12, x9, #40
   171b4:	and	x10, x10, #0xff0000
   171b8:	and	x12, x12, #0xff00
   171bc:	orr	x10, x11, x10
   171c0:	orr	x10, x10, x12
   171c4:	add	x9, x10, x9, lsr #56
   171c8:	str	x9, [x19, x8, lsl #3]
   171cc:	add	x8, x8, #0x1
   171d0:	cmp	x8, x20
   171d4:	b.lt	17184 <__gmpz_export@@Base+0x2bc>  // b.tstop
   171d8:	b	170dc <__gmpz_export@@Base+0x214>
   171dc:	cmp	w23, #0x1
   171e0:	b.ne	16f6c <__gmpz_export@@Base+0xa4>  // b.any
   171e4:	cmp	w18, #0x1
   171e8:	b.ne	16f6c <__gmpz_export@@Base+0xa4>  // b.any
   171ec:	cmp	x20, #0x1
   171f0:	b.lt	170dc <__gmpz_export@@Base+0x214>  // b.tstop
   171f4:	mov	x8, xzr
   171f8:	add	x9, x21, x20, lsl #3
   171fc:	ldr	x10, [x9, #-8]!
   17200:	lsl	x13, x10, #40
   17204:	and	x13, x13, #0xff000000000000
   17208:	lsr	x12, x10, #16
   1720c:	bfi	x13, x10, #56, #8
   17210:	lsr	x11, x10, #24
   17214:	bfi	x13, x12, #40, #8
   17218:	lsr	x12, x10, #8
   1721c:	and	x12, x12, #0xff000000
   17220:	bfi	x13, x11, #32, #8
   17224:	orr	x12, x13, x12
   17228:	lsr	x13, x10, #40
   1722c:	and	x11, x11, #0xff0000
   17230:	and	x13, x13, #0xff00
   17234:	orr	x11, x12, x11
   17238:	orr	x11, x11, x13
   1723c:	add	x10, x11, x10, lsr #56
   17240:	str	x10, [x19, x8, lsl #3]
   17244:	add	x8, x8, #0x1
   17248:	cmp	x8, x20
   1724c:	b.lt	171fc <__gmpz_export@@Base+0x334>  // b.tstop
   17250:	b	170dc <__gmpz_export@@Base+0x214>

0000000000017254 <__gmpz_mfac_uiui@@Base>:
   17254:	stp	x29, x30, [sp, #-64]!
   17258:	str	x23, [sp, #16]
   1725c:	stp	x22, x21, [sp, #32]
   17260:	stp	x20, x19, [sp, #48]
   17264:	mov	x29, sp
   17268:	sub	sp, sp, #0x20
   1726c:	mov	x20, x1
   17270:	subs	x8, x1, #0x3
   17274:	mov	x19, x0
   17278:	b.cc	172e8 <__gmpz_mfac_uiui@@Base+0x94>  // b.lo, b.ul, b.last
   1727c:	sub	x9, x2, #0x1
   17280:	mov	x22, x2
   17284:	cmp	x8, x9
   17288:	b.cc	172e8 <__gmpz_mfac_uiui@@Base+0x94>  // b.lo, b.ul, b.last
   1728c:	add	x0, x29, #0x18
   17290:	mov	w1, #0x1                   	// #1
   17294:	mov	x2, x22
   17298:	str	x20, [x29, #24]
   1729c:	bl	bfa0 <__gmpn_gcd_1@plt>
   172a0:	mov	x21, x0
   172a4:	cmp	x0, #0x2
   172a8:	b.cc	172b4 <__gmpz_mfac_uiui@@Base+0x60>  // b.lo, b.ul, b.last
   172ac:	udiv	x20, x20, x21
   172b0:	udiv	x22, x22, x21
   172b4:	cmp	x22, #0x2
   172b8:	b.hi	17310 <__gmpz_mfac_uiui@@Base+0xbc>  // b.pmore
   172bc:	cmp	x22, #0x1
   172c0:	b.ne	17368 <__gmpz_mfac_uiui@@Base+0x114>  // b.any
   172c4:	cmp	x21, #0x3
   172c8:	b.cc	174e0 <__gmpz_mfac_uiui@@Base+0x28c>  // b.lo, b.ul, b.last
   172cc:	sub	x0, x29, #0x10
   172d0:	bl	d270 <__gmpz_init@plt>
   172d4:	sub	x0, x29, #0x10
   172d8:	mov	x1, x20
   172dc:	bl	c470 <__gmpz_fac_ui@plt>
   172e0:	str	x20, [x29, #24]
   172e4:	b	17484 <__gmpz_mfac_uiui@@Base+0x230>
   172e8:	ldr	w8, [x19]
   172ec:	cmp	x20, #0x0
   172f0:	cinc	x20, x20, eq  // eq = none
   172f4:	cmp	w8, #0x0
   172f8:	b.le	17528 <__gmpz_mfac_uiui@@Base+0x2d4>
   172fc:	ldr	x0, [x19, #8]
   17300:	mov	w8, #0x1                   	// #1
   17304:	str	x20, [x0]
   17308:	str	w8, [x19, #4]
   1730c:	b	17510 <__gmpz_mfac_uiui@@Base+0x2bc>
   17310:	udiv	x8, x20, x22
   17314:	cmp	x21, #0x2
   17318:	add	x9, x8, #0x1
   1731c:	sub	x8, x20, x22
   17320:	str	x9, [x29, #24]
   17324:	b.cc	17394 <__gmpz_mfac_uiui@@Base+0x140>  // b.lo, b.ul, b.last
   17328:	adrp	x10, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1732c:	ldr	x10, [x10, #3880]
   17330:	mov	w11, #0x9                   	// #9
   17334:	sub	w12, w11, #0x2
   17338:	ldr	x12, [x10, w12, uxtw #3]
   1733c:	sub	w11, w11, #0x1
   17340:	cmp	x12, x8
   17344:	b.cc	17334 <__gmpz_mfac_uiui@@Base+0xe0>  // b.lo, b.ul, b.last
   17348:	ldrsw	x12, [x19]
   1734c:	mov	w11, w11
   17350:	udiv	x11, x9, x11
   17354:	add	x11, x11, #0x2
   17358:	cmp	x11, x12
   1735c:	b.hi	17538 <__gmpz_mfac_uiui@@Base+0x2e4>  // b.pmore
   17360:	ldr	x23, [x19, #8]
   17364:	b	17410 <__gmpz_mfac_uiui@@Base+0x1bc>
   17368:	cmp	x21, #0x2
   1736c:	b.cc	174f4 <__gmpz_mfac_uiui@@Base+0x2a0>  // b.lo, b.ul, b.last
   17370:	sub	x0, x29, #0x10
   17374:	bl	d270 <__gmpz_init@plt>
   17378:	sub	x0, x29, #0x10
   1737c:	mov	x1, x20
   17380:	bl	c620 <__gmpz_2fac_ui@plt>
   17384:	lsr	x8, x20, #1
   17388:	add	x8, x8, #0x1
   1738c:	str	x8, [x29, #24]
   17390:	b	17484 <__gmpz_mfac_uiui@@Base+0x230>
   17394:	stur	xzr, [x29, #-32]
   17398:	adrp	x10, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1739c:	ldr	x10, [x10, #3880]
   173a0:	mov	w11, #0x9                   	// #9
   173a4:	sub	w12, w11, #0x2
   173a8:	ldr	x12, [x10, w12, uxtw #3]
   173ac:	sub	w11, w11, #0x1
   173b0:	cmp	x12, x8
   173b4:	b.cc	173a4 <__gmpz_mfac_uiui@@Base+0x150>  // b.lo, b.ul, b.last
   173b8:	mov	w11, w11
   173bc:	udiv	x11, x9, x11
   173c0:	lsl	x11, x11, #3
   173c4:	add	x11, x11, #0x10
   173c8:	mov	w12, #0x9                   	// #9
   173cc:	sub	w13, w12, #0x2
   173d0:	ldr	x13, [x10, w13, uxtw #3]
   173d4:	sub	w12, w12, #0x1
   173d8:	cmp	x13, x8
   173dc:	b.cc	173cc <__gmpz_mfac_uiui@@Base+0x178>  // b.lo, b.ul, b.last
   173e0:	mov	w10, w12
   173e4:	udiv	x9, x9, x10
   173e8:	mov	w12, #0x7f00                	// #32512
   173ec:	lsl	x9, x9, #3
   173f0:	cmp	x11, x12
   173f4:	add	x1, x9, #0x10
   173f8:	b.hi	1756c <__gmpz_mfac_uiui@@Base+0x318>  // b.pmore
   173fc:	add	x10, x1, #0xf
   17400:	mov	x9, sp
   17404:	and	x10, x10, #0xfffffffffffffff0
   17408:	sub	x23, x9, x10
   1740c:	mov	sp, x23
   17410:	cmp	x8, x22
   17414:	b.ls	17450 <__gmpz_mfac_uiui@@Base+0x1fc>  // b.plast
   17418:	mov	x10, xzr
   1741c:	mov	x9, x8
   17420:	umulh	x11, x8, x20
   17424:	cbz	x11, 1743c <__gmpz_mfac_uiui@@Base+0x1e8>
   17428:	add	x11, x10, #0x1
   1742c:	str	x20, [x23, x10, lsl #3]
   17430:	mov	x20, x9
   17434:	mov	x10, x11
   17438:	b	17440 <__gmpz_mfac_uiui@@Base+0x1ec>
   1743c:	mul	x20, x9, x20
   17440:	sub	x9, x9, x22
   17444:	cmp	x9, x22
   17448:	b.hi	17420 <__gmpz_mfac_uiui@@Base+0x1cc>  // b.pmore
   1744c:	b	17458 <__gmpz_mfac_uiui@@Base+0x204>
   17450:	mov	x10, xzr
   17454:	mov	x9, x8
   17458:	add	x8, x23, x10, lsl #3
   1745c:	add	x22, x10, #0x2
   17460:	cmp	x21, #0x2
   17464:	stp	x9, x20, [x8]
   17468:	b.cc	174c0 <__gmpz_mfac_uiui@@Base+0x26c>  // b.lo, b.ul, b.last
   1746c:	sub	x0, x29, #0x10
   17470:	bl	d270 <__gmpz_init@plt>
   17474:	sub	x0, x29, #0x10
   17478:	mov	x1, x23
   1747c:	mov	x2, x22
   17480:	bl	cd90 <__gmpz_prodlimbs@plt>
   17484:	sub	x0, x29, #0x20
   17488:	bl	d270 <__gmpz_init@plt>
   1748c:	ldr	x2, [x29, #24]
   17490:	sub	x0, x29, #0x20
   17494:	mov	x1, x21
   17498:	bl	ca30 <__gmpz_ui_pow_ui@plt>
   1749c:	sub	x1, x29, #0x20
   174a0:	sub	x2, x29, #0x10
   174a4:	mov	x0, x19
   174a8:	bl	c4d0 <__gmpz_mul@plt>
   174ac:	sub	x0, x29, #0x20
   174b0:	bl	cb70 <__gmpz_clear@plt>
   174b4:	sub	x0, x29, #0x10
   174b8:	bl	cb70 <__gmpz_clear@plt>
   174bc:	b	17510 <__gmpz_mfac_uiui@@Base+0x2bc>
   174c0:	mov	x0, x19
   174c4:	mov	x1, x23
   174c8:	mov	x2, x22
   174cc:	bl	cd90 <__gmpz_prodlimbs@plt>
   174d0:	ldur	x0, [x29, #-32]
   174d4:	cbz	x0, 17510 <__gmpz_mfac_uiui@@Base+0x2bc>
   174d8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   174dc:	b	17510 <__gmpz_mfac_uiui@@Base+0x2bc>
   174e0:	cmp	x21, #0x2
   174e4:	b.ne	17504 <__gmpz_mfac_uiui@@Base+0x2b0>  // b.any
   174e8:	lsl	x1, x20, #1
   174ec:	mov	x0, x19
   174f0:	b	174fc <__gmpz_mfac_uiui@@Base+0x2a8>
   174f4:	mov	x0, x19
   174f8:	mov	x1, x20
   174fc:	bl	c620 <__gmpz_2fac_ui@plt>
   17500:	b	17510 <__gmpz_mfac_uiui@@Base+0x2bc>
   17504:	mov	x0, x19
   17508:	mov	x1, x20
   1750c:	bl	c470 <__gmpz_fac_ui@plt>
   17510:	mov	sp, x29
   17514:	ldp	x20, x19, [sp, #48]
   17518:	ldp	x22, x21, [sp, #32]
   1751c:	ldr	x23, [sp, #16]
   17520:	ldp	x29, x30, [sp], #64
   17524:	ret
   17528:	mov	w1, #0x1                   	// #1
   1752c:	mov	x0, x19
   17530:	bl	c090 <__gmpz_realloc@plt>
   17534:	b	17300 <__gmpz_mfac_uiui@@Base+0xac>
   17538:	mov	w11, #0x9                   	// #9
   1753c:	sub	w12, w11, #0x2
   17540:	ldr	x12, [x10, w12, uxtw #3]
   17544:	sub	w11, w11, #0x1
   17548:	cmp	x12, x8
   1754c:	b.cc	1753c <__gmpz_mfac_uiui@@Base+0x2e8>  // b.lo, b.ul, b.last
   17550:	mov	w10, w11
   17554:	udiv	x9, x9, x10
   17558:	add	x1, x9, #0x2
   1755c:	mov	x0, x19
   17560:	mov	x23, x8
   17564:	bl	c090 <__gmpz_realloc@plt>
   17568:	b	17578 <__gmpz_mfac_uiui@@Base+0x324>
   1756c:	sub	x0, x29, #0x20
   17570:	mov	x23, x8
   17574:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   17578:	mov	x8, x23
   1757c:	mov	x23, x0
   17580:	b	17410 <__gmpz_mfac_uiui@@Base+0x1bc>

0000000000017584 <__gmpz_2fac_ui@@Base>:
   17584:	stp	x29, x30, [sp, #-32]!
   17588:	stp	x20, x19, [sp, #16]
   1758c:	mov	x19, x0
   17590:	mov	x29, sp
   17594:	tbnz	w1, #0, 175bc <__gmpz_2fac_ui@@Base+0x38>
   17598:	sub	x8, x1, #0x1
   1759c:	cmp	x8, #0x50
   175a0:	lsr	x8, x1, #1
   175a4:	b.hi	175f8 <__gmpz_2fac_ui@@Base+0x74>  // b.pmore
   175a8:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   175ac:	ldr	x9, [x9, #3992]
   175b0:	add	x9, x8, x9
   175b4:	ldurb	w20, [x9, #-1]
   175b8:	b	1762c <__gmpz_2fac_ui@@Base+0xa8>
   175bc:	cmp	x1, #0x21
   175c0:	b.hi	17658 <__gmpz_2fac_ui@@Base+0xd4>  // b.pmore
   175c4:	adrp	x10, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   175c8:	ldr	w9, [x19]
   175cc:	ldr	x10, [x10, #3928]
   175d0:	lsl	x8, x1, #2
   175d4:	and	x8, x8, #0xfffffffffffffff8
   175d8:	cmp	w9, #0x0
   175dc:	ldr	x20, [x10, x8]
   175e0:	b.le	17730 <__gmpz_2fac_ui@@Base+0x1ac>
   175e4:	ldr	x0, [x19, #8]
   175e8:	mov	w8, #0x1                   	// #1
   175ec:	str	x20, [x0]
   175f0:	str	w8, [x19, #4]
   175f4:	b	17720 <__gmpz_2fac_ui@@Base+0x19c>
   175f8:	and	x9, x8, #0x5555555555555555
   175fc:	sub	x9, x1, x9
   17600:	lsr	x10, x9, #2
   17604:	and	x10, x10, #0x3333333333333333
   17608:	and	x9, x9, #0x3333333333333333
   1760c:	add	x9, x10, x9
   17610:	add	x9, x9, x9, lsr #4
   17614:	and	x9, x9, #0xf0f0f0f0f0f0f0f
   17618:	add	x9, x9, x9, lsr #8
   1761c:	add	x9, x9, x9, lsr #16
   17620:	lsr	x10, x9, #32
   17624:	add	w9, w10, w9
   17628:	sub	x20, x1, w9, uxtb
   1762c:	mov	x0, x19
   17630:	mov	x1, x8
   17634:	mov	w2, wzr
   17638:	bl	c3f0 <__gmpz_oddfac_1@plt>
   1763c:	mov	x0, x19
   17640:	mov	x1, x19
   17644:	mov	x2, x20
   17648:	mov	sp, x29
   1764c:	ldp	x20, x19, [sp, #16]
   17650:	ldp	x29, x30, [sp], #32
   17654:	b	c700 <__gmpz_mul_2exp@plt>
   17658:	cmp	x1, #0x1d7
   1765c:	b.ls	17678 <__gmpz_2fac_ui@@Base+0xf4>  // b.plast
   17660:	mov	w2, #0x1                   	// #1
   17664:	mov	x0, x19
   17668:	mov	sp, x29
   1766c:	ldp	x20, x19, [sp, #16]
   17670:	ldp	x29, x30, [sp], #32
   17674:	b	c3f0 <__gmpz_oddfac_1@plt>
   17678:	mov	w9, #0xaaab                	// #43691
   1767c:	and	w8, w1, #0xffff
   17680:	movk	w9, #0xaaaa, lsl #16
   17684:	umull	x8, w8, w9
   17688:	lsr	x8, x8, #32
   1768c:	and	w8, w8, #0xfff8
   17690:	add	w8, w8, #0x8
   17694:	and	w8, w8, #0xfff8
   17698:	add	w8, w8, #0xf
   1769c:	and	x8, x8, #0x1fff0
   176a0:	mov	x9, sp
   176a4:	sub	x8, x9, x8
   176a8:	mov	sp, x8
   176ac:	mov	x9, #0xd941                	// #55617
   176b0:	movk	x9, #0xc030, lsl #16
   176b4:	movk	x9, #0x2099, lsl #32
   176b8:	movk	x9, #0x57e2, lsl #48
   176bc:	sub	x10, x1, #0x2
   176c0:	cmp	x10, #0x22
   176c4:	str	x9, [x8]
   176c8:	mov	w9, #0x1                   	// #1
   176cc:	b.cc	1770c <__gmpz_2fac_ui@@Base+0x188>  // b.lo, b.ul, b.last
   176d0:	mov	x11, #0x3869                	// #14441
   176d4:	movk	x11, #0xfba9, lsl #16
   176d8:	movk	x11, #0xd8f2, lsl #32
   176dc:	movk	x11, #0x8a, lsl #48
   176e0:	cmp	x1, x11
   176e4:	b.cc	176fc <__gmpz_2fac_ui@@Base+0x178>  // b.lo, b.ul, b.last
   176e8:	add	x12, x9, #0x1
   176ec:	str	x1, [x8, x9, lsl #3]
   176f0:	mov	x1, x10
   176f4:	mov	x9, x12
   176f8:	b	17700 <__gmpz_2fac_ui@@Base+0x17c>
   176fc:	mul	x1, x10, x1
   17700:	sub	x10, x10, #0x2
   17704:	cmp	x10, #0x21
   17708:	b.hi	176e0 <__gmpz_2fac_ui@@Base+0x15c>  // b.pmore
   1770c:	add	x2, x9, #0x1
   17710:	str	x1, [x8, x9, lsl #3]
   17714:	mov	x0, x19
   17718:	mov	x1, x8
   1771c:	bl	cd90 <__gmpz_prodlimbs@plt>
   17720:	mov	sp, x29
   17724:	ldp	x20, x19, [sp, #16]
   17728:	ldp	x29, x30, [sp], #32
   1772c:	ret
   17730:	mov	w1, #0x1                   	// #1
   17734:	mov	x0, x19
   17738:	bl	c090 <__gmpz_realloc@plt>
   1773c:	b	175e8 <__gmpz_2fac_ui@@Base+0x64>

0000000000017740 <__gmpz_fac_ui@@Base>:
   17740:	stp	x29, x30, [sp, #-32]!
   17744:	stp	x20, x19, [sp, #16]
   17748:	mov	x20, x1
   1774c:	cmp	x1, #0x14
   17750:	mov	x19, x0
   17754:	mov	x29, sp
   17758:	b.hi	17788 <__gmpz_fac_ui@@Base+0x48>  // b.pmore
   1775c:	adrp	x9, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   17760:	ldr	w8, [x19]
   17764:	add	x9, x9, #0x1b8
   17768:	ldr	x20, [x9, x20, lsl #3]
   1776c:	cmp	w8, #0x0
   17770:	b.le	178cc <__gmpz_fac_ui@@Base+0x18c>
   17774:	ldr	x0, [x19, #8]
   17778:	mov	w8, #0x1                   	// #1
   1777c:	str	x20, [x0]
   17780:	str	w8, [x19, #4]
   17784:	b	178bc <__gmpz_fac_ui@@Base+0x17c>
   17788:	cmp	x20, #0x17
   1778c:	b.ls	177c0 <__gmpz_fac_ui@@Base+0x80>  // b.plast
   17790:	mov	x0, x19
   17794:	mov	x1, x20
   17798:	mov	w2, wzr
   1779c:	bl	c3f0 <__gmpz_oddfac_1@plt>
   177a0:	cmp	x20, #0x51
   177a4:	lsr	x8, x20, #1
   177a8:	b.hi	17858 <__gmpz_fac_ui@@Base+0x118>  // b.pmore
   177ac:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   177b0:	ldr	x9, [x9, #3992]
   177b4:	add	x8, x8, x9
   177b8:	ldurb	w2, [x8, #-1]
   177bc:	b	1788c <__gmpz_fac_ui@@Base+0x14c>
   177c0:	sub	w8, w20, #0x15
   177c4:	mov	w9, #0xcccd                	// #52429
   177c8:	and	w8, w8, #0xff
   177cc:	movk	w9, #0xcccc, lsl #16
   177d0:	umull	x8, w8, w9
   177d4:	lsr	x8, x8, #32
   177d8:	and	w8, w8, #0xf8
   177dc:	add	w8, w8, #0x10
   177e0:	and	w8, w8, #0xf8
   177e4:	add	w8, w8, #0xf
   177e8:	and	x8, x8, #0x1f0
   177ec:	mov	x9, sp
   177f0:	sub	x1, x9, x8
   177f4:	mov	sp, x1
   177f8:	mov	x8, #0x82b40000            	// #2192834560
   177fc:	movk	x8, #0x677c, lsl #32
   17800:	sub	x9, x20, #0x1
   17804:	movk	x8, #0x21c3, lsl #48
   17808:	cmp	x9, #0x15
   1780c:	str	x8, [x1]
   17810:	b.cc	178a4 <__gmpz_fac_ui@@Base+0x164>  // b.lo, b.ul, b.last
   17814:	mov	x10, #0x3d71                	// #15729
   17818:	movk	x10, #0xd70a, lsl #16
   1781c:	movk	x10, #0x70a3, lsl #32
   17820:	mov	w8, #0x1                   	// #1
   17824:	movk	x10, #0xa3d, lsl #48
   17828:	cmp	x20, x10
   1782c:	b.cc	17844 <__gmpz_fac_ui@@Base+0x104>  // b.lo, b.ul, b.last
   17830:	add	x11, x8, #0x1
   17834:	str	x20, [x1, x8, lsl #3]
   17838:	mov	x8, x11
   1783c:	mov	x20, x9
   17840:	b	17848 <__gmpz_fac_ui@@Base+0x108>
   17844:	mul	x20, x9, x20
   17848:	sub	x9, x9, #0x1
   1784c:	cmp	x9, #0x14
   17850:	b.hi	17828 <__gmpz_fac_ui@@Base+0xe8>  // b.pmore
   17854:	b	178ac <__gmpz_fac_ui@@Base+0x16c>
   17858:	and	x8, x8, #0x5555555555555555
   1785c:	sub	x8, x20, x8
   17860:	lsr	x9, x8, #2
   17864:	and	x9, x9, #0x3333333333333333
   17868:	and	x8, x8, #0x3333333333333333
   1786c:	add	x8, x9, x8
   17870:	add	x8, x8, x8, lsr #4
   17874:	and	x8, x8, #0xf0f0f0f0f0f0f0f
   17878:	add	x8, x8, x8, lsr #8
   1787c:	add	x8, x8, x8, lsr #16
   17880:	lsr	x9, x8, #32
   17884:	add	w8, w9, w8
   17888:	sub	x2, x20, w8, uxtb
   1788c:	mov	x0, x19
   17890:	mov	x1, x19
   17894:	mov	sp, x29
   17898:	ldp	x20, x19, [sp, #16]
   1789c:	ldp	x29, x30, [sp], #32
   178a0:	b	c700 <__gmpz_mul_2exp@plt>
   178a4:	mov	w20, #0x15                  	// #21
   178a8:	mov	w8, #0x1                   	// #1
   178ac:	add	x2, x8, #0x1
   178b0:	mov	x0, x19
   178b4:	str	x20, [x1, x8, lsl #3]
   178b8:	bl	cd90 <__gmpz_prodlimbs@plt>
   178bc:	mov	sp, x29
   178c0:	ldp	x20, x19, [sp, #16]
   178c4:	ldp	x29, x30, [sp], #32
   178c8:	ret
   178cc:	mov	w1, #0x1                   	// #1
   178d0:	mov	x0, x19
   178d4:	bl	c090 <__gmpz_realloc@plt>
   178d8:	b	17778 <__gmpz_fac_ui@@Base+0x38>

00000000000178dc <__gmpz_oddfac_1@@Base>:
   178dc:	stp	x29, x30, [sp, #-96]!
   178e0:	stp	x28, x27, [sp, #16]
   178e4:	stp	x26, x25, [sp, #32]
   178e8:	stp	x24, x23, [sp, #48]
   178ec:	stp	x22, x21, [sp, #64]
   178f0:	stp	x20, x19, [sp, #80]
   178f4:	mov	x29, sp
   178f8:	sub	sp, sp, #0x30
   178fc:	mov	x19, x1
   17900:	cmp	x1, #0x19
   17904:	mov	x26, x0
   17908:	stur	w2, [x29, #-44]
   1790c:	b.hi	1793c <__gmpz_oddfac_1@@Base+0x60>  // b.pmore
   17910:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   17914:	ldr	w8, [x26]
   17918:	ldr	x9, [x9, #3848]
   1791c:	cmp	w8, #0x0
   17920:	ldr	x20, [x9, x19, lsl #3]
   17924:	b.le	17ef8 <__gmpz_oddfac_1@@Base+0x61c>
   17928:	ldr	x0, [x26, #8]
   1792c:	mov	w8, #0x1                   	// #1
   17930:	str	x20, [x0]
   17934:	str	w8, [x26, #4]
   17938:	b	17ed8 <__gmpz_oddfac_1@@Base+0x5fc>
   1793c:	cmp	x19, #0x23
   17940:	b.cs	17994 <__gmpz_oddfac_1@@Base+0xb8>  // b.hs, b.nlast
   17944:	ldr	w8, [x26]
   17948:	cmp	w8, #0x1
   1794c:	b.le	17f08 <__gmpz_oddfac_1@@Base+0x62c>
   17950:	ldr	x0, [x26, #8]
   17954:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   17958:	adrp	x10, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1795c:	ldr	x9, [x9, #3928]
   17960:	ldr	x10, [x10, #3848]
   17964:	lsl	x8, x19, #2
   17968:	sub	x11, x8, #0x4
   1796c:	and	x8, x8, #0xfffffffffffffff8
   17970:	and	x11, x11, #0xfffffffffffffff8
   17974:	ldr	x8, [x10, x8]
   17978:	ldr	x9, [x9, x11]
   1797c:	mov	w10, #0x2                   	// #2
   17980:	umulh	x11, x9, x8
   17984:	mul	x8, x8, x9
   17988:	stp	x8, x11, [x0]
   1798c:	str	w10, [x26, #4]
   17990:	b	17ed8 <__gmpz_oddfac_1@@Base+0x5fc>
   17994:	cmp	x19, #0xec
   17998:	b.cc	179bc <__gmpz_oddfac_1@@Base+0xe0>  // b.lo, b.ul, b.last
   1799c:	mov	w25, wzr
   179a0:	mov	x8, x19
   179a4:	lsr	x13, x8, #1
   179a8:	cmp	x8, #0x1d7
   179ac:	add	w25, w25, #0x1
   179b0:	mov	x8, x13
   179b4:	b.hi	179a4 <__gmpz_oddfac_1@@Base+0xc8>  // b.pmore
   179b8:	b	179c4 <__gmpz_oddfac_1@@Base+0xe8>
   179bc:	mov	w25, wzr
   179c0:	mov	x13, x19
   179c4:	mov	w9, #0x4925                	// #18725
   179c8:	and	w8, w13, #0xff
   179cc:	movk	w9, #0x2492, lsl #16
   179d0:	umull	x9, w8, w9
   179d4:	lsr	x9, x9, #32
   179d8:	sub	w8, w8, w9
   179dc:	add	w8, w9, w8, lsr #1
   179e0:	lsl	w8, w8, #1
   179e4:	and	w8, w8, #0x7f8
   179e8:	add	w8, w8, #0x17
   179ec:	and	x8, x8, #0x7f0
   179f0:	mov	x9, sp
   179f4:	sub	x1, x9, x8
   179f8:	mov	sp, x1
   179fc:	mov	x10, #0x70d0                	// #28880
   17a00:	mov	x12, #0xd941                	// #55617
   17a04:	movk	x10, #0xf752, lsl #16
   17a08:	movk	x12, #0xc030, lsl #16
   17a0c:	movk	x10, #0xb1e5, lsl #32
   17a10:	movk	x12, #0x2099, lsl #32
   17a14:	mov	x8, xzr
   17a18:	movk	x10, #0x115, lsl #48
   17a1c:	mov	w9, #0x1                   	// #1
   17a20:	movk	x12, #0x57e2, lsl #48
   17a24:	mov	x11, x13
   17a28:	str	x12, [x1, x8, lsl #3]
   17a2c:	add	x8, x8, #0x1
   17a30:	mov	w13, #0x23                  	// #35
   17a34:	cmp	x9, x10
   17a38:	b.ls	17a50 <__gmpz_oddfac_1@@Base+0x174>  // b.plast
   17a3c:	add	x14, x8, #0x1
   17a40:	str	x9, [x1, x8, lsl #3]
   17a44:	mov	x8, x14
   17a48:	mov	x9, x13
   17a4c:	b	17a54 <__gmpz_oddfac_1@@Base+0x178>
   17a50:	mul	x9, x9, x13
   17a54:	add	x13, x13, #0x2
   17a58:	cmp	x13, x11
   17a5c:	b.ls	17a34 <__gmpz_oddfac_1@@Base+0x158>  // b.plast
   17a60:	lsl	x10, x10, #1
   17a64:	cmp	x11, #0x45
   17a68:	lsr	x13, x11, #1
   17a6c:	b.hi	17a24 <__gmpz_oddfac_1@@Base+0x148>  // b.pmore
   17a70:	lsl	x12, x13, #2
   17a74:	adrp	x13, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   17a78:	adrp	x14, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   17a7c:	ldr	x13, [x13, #3928]
   17a80:	ldr	x14, [x14, #3848]
   17a84:	lsl	x11, x11, #1
   17a88:	sub	x12, x12, #0x4
   17a8c:	and	x11, x11, #0xfffffffffffffff8
   17a90:	and	x12, x12, #0xfffffffffffffff8
   17a94:	ldr	x12, [x13, x12]
   17a98:	ldr	x11, [x14, x11]
   17a9c:	add	x10, x1, x8, lsl #3
   17aa0:	add	x2, x8, #0x3
   17aa4:	mov	x0, x26
   17aa8:	stp	x9, x12, [x10]
   17aac:	str	x11, [x10, #16]
   17ab0:	bl	cd90 <__gmpz_prodlimbs@plt>
   17ab4:	cbz	w25, 17ed8 <__gmpz_oddfac_1@@Base+0x5fc>
   17ab8:	lsr	x8, x19, #6
   17abc:	add	x20, x8, #0x4
   17ac0:	cmp	x8, #0xfdc
   17ac4:	lsl	x1, x20, #3
   17ac8:	stur	xzr, [x29, #-24]
   17acc:	stur	w20, [x29, #-16]
   17ad0:	b.hi	17f18 <__gmpz_oddfac_1@@Base+0x63c>  // b.pmore
   17ad4:	add	x9, x1, #0xf
   17ad8:	mov	x8, sp
   17adc:	and	x9, x9, #0x7ffffffffffffff0
   17ae0:	sub	x0, x8, x9
   17ae4:	mov	sp, x0
   17ae8:	lsl	x8, x20, #2
   17aec:	and	x8, x8, #0x1ffffffffffffff8
   17af0:	add	x8, x0, x8
   17af4:	add	x22, x8, #0x8
   17af8:	stur	x0, [x29, #-8]
   17afc:	sub	x1, x19, #0x1
   17b00:	mov	x0, x22
   17b04:	bl	d220 <__gmp_primesieve@plt>
   17b08:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   17b0c:	ldr	x9, [x9, #3880]
   17b10:	mov	w8, #0x9                   	// #9
   17b14:	sub	w10, w8, #0x2
   17b18:	ldr	x10, [x9, w10, uxtw #3]
   17b1c:	sub	w8, w8, #0x1
   17b20:	cmp	x10, x19
   17b24:	b.cc	17b14 <__gmpz_oddfac_1@@Base+0x238>  // b.lo, b.ul, b.last
   17b28:	add	x9, x0, #0x1
   17b2c:	mov	w8, w8
   17b30:	udiv	x8, x9, x8
   17b34:	lsl	x8, x8, #3
   17b38:	add	x1, x8, #0x8
   17b3c:	mov	w8, #0x7f00                	// #32512
   17b40:	cmp	x1, x8
   17b44:	b.hi	17f24 <__gmpz_oddfac_1@@Base+0x648>  // b.pmore
   17b48:	add	x9, x1, #0xf
   17b4c:	mov	x8, sp
   17b50:	and	x9, x9, #0xfffffffffffffff0
   17b54:	sub	x23, x8, x9
   17b58:	mov	sp, x23
   17b5c:	mov	x21, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   17b60:	mov	w28, #0x1                   	// #1
   17b64:	movk	x21, #0xaaab
   17b68:	sub	w8, w25, #0x1
   17b6c:	lsr	x12, x19, x8
   17b70:	stur	x8, [x29, #-40]
   17b74:	and	x8, x12, #0x1
   17b78:	neg	x8, x8
   17b7c:	and	x11, x12, #0xfffffffffffffffe
   17b80:	and	x8, x12, x8
   17b84:	sub	x10, x11, #0x1
   17b88:	orr	x9, x8, #0x1
   17b8c:	mov	x8, #0xffffffffffffffff    	// #-1
   17b90:	udiv	x8, x8, x10
   17b94:	cmp	x9, x8
   17b98:	b.ls	17bac <__gmpz_oddfac_1@@Base+0x2d0>  // b.plast
   17b9c:	str	x9, [x23]
   17ba0:	mov	w10, #0x1                   	// #1
   17ba4:	mov	w9, #0x1                   	// #1
   17ba8:	b	17bb0 <__gmpz_oddfac_1@@Base+0x2d4>
   17bac:	mov	x10, xzr
   17bb0:	mov	x13, x11
   17bb4:	umulh	x14, x13, x21
   17bb8:	add	x15, x9, x9, lsl #1
   17bbc:	tst	x28, x14, lsr #1
   17bc0:	csel	x9, x9, x15, eq  // eq = none
   17bc4:	cmp	x13, #0x8
   17bc8:	lsr	x13, x14, #1
   17bcc:	b.hi	17bb4 <__gmpz_oddfac_1@@Base+0x2d8>  // b.pmore
   17bd0:	clz	x14, x11
   17bd4:	mov	w15, #0x40                  	// #64
   17bd8:	sub	w14, w15, w14
   17bdc:	asr	w14, w14, #1
   17be0:	lsl	x15, x28, x14
   17be4:	lsr	x14, x11, x14
   17be8:	add	x14, x15, x14
   17bec:	lsr	x14, x14, #1
   17bf0:	sub	x14, x14, #0x5
   17bf4:	orr	x14, x14, #0x1
   17bf8:	umulh	x14, x14, x21
   17bfc:	mov	x16, xzr
   17c00:	mov	x13, xzr
   17c04:	mov	w1, #0x7                   	// #7
   17c08:	lsr	x18, x14, #1
   17c0c:	mov	w0, #0x1                   	// #1
   17c10:	ldr	x17, [x22, x13, lsl #3]
   17c14:	mov	x14, x16
   17c18:	mov	x15, x1
   17c1c:	add	x16, x16, #0x1
   17c20:	tst	x17, x0
   17c24:	b.ne	17c6c <__gmpz_oddfac_1@@Base+0x390>  // b.any
   17c28:	add	x17, x16, x16, lsl #1
   17c2c:	and	x1, x16, #0x1
   17c30:	cmp	x9, x8
   17c34:	add	x17, x17, x1
   17c38:	b.ls	17c4c <__gmpz_oddfac_1@@Base+0x370>  // b.plast
   17c3c:	add	x1, x10, #0x1
   17c40:	str	x9, [x23, x10, lsl #3]
   17c44:	mov	x10, x1
   17c48:	mov	w9, #0x1                   	// #1
   17c4c:	add	x17, x17, #0x1
   17c50:	mov	x1, x11
   17c54:	udiv	x1, x1, x17
   17c58:	tst	x1, #0x1
   17c5c:	csinc	x2, x17, xzr, ne  // ne = any
   17c60:	cmp	x1, x17
   17c64:	mul	x9, x2, x9
   17c68:	b.cs	17c54 <__gmpz_oddfac_1@@Base+0x378>  // b.hs, b.nlast
   17c6c:	ror	x17, x0, #63
   17c70:	add	x13, x13, x0, lsr #63
   17c74:	cmp	x14, x18
   17c78:	add	x1, x15, #0x3
   17c7c:	mov	x0, x17
   17c80:	b.cc	17c10 <__gmpz_oddfac_1@@Base+0x334>  // b.lo, b.ul, b.last
   17c84:	umulh	x18, x11, x21
   17c88:	lsr	x18, x18, #1
   17c8c:	sub	x18, x18, #0x5
   17c90:	orr	x18, x18, #0x1
   17c94:	umulh	x18, x18, x21
   17c98:	add	x16, x8, x8, lsl #1
   17c9c:	lsr	x18, x18, #1
   17ca0:	ldr	x0, [x22, x13, lsl #3]
   17ca4:	tst	x0, x17
   17ca8:	b.ne	17cdc <__gmpz_oddfac_1@@Base+0x400>  // b.any
   17cac:	and	x0, x14, #0x1
   17cb0:	add	x0, x15, x0
   17cb4:	udiv	x1, x11, x0
   17cb8:	tbz	w1, #0, 17cdc <__gmpz_oddfac_1@@Base+0x400>
   17cbc:	cmp	x9, x16
   17cc0:	b.ls	17cd8 <__gmpz_oddfac_1@@Base+0x3fc>  // b.plast
   17cc4:	add	x1, x10, #0x1
   17cc8:	str	x9, [x23, x10, lsl #3]
   17ccc:	mov	x10, x1
   17cd0:	mov	x9, x0
   17cd4:	b	17cdc <__gmpz_oddfac_1@@Base+0x400>
   17cd8:	mul	x9, x9, x0
   17cdc:	add	x14, x14, #0x1
   17ce0:	add	x13, x13, x17, lsr #63
   17ce4:	ror	x17, x17, #63
   17ce8:	cmp	x14, x18
   17cec:	add	x15, x15, #0x3
   17cf0:	b.cc	17ca0 <__gmpz_oddfac_1@@Base+0x3c4>  // b.lo, b.ul, b.last
   17cf4:	lsr	x12, x12, #1
   17cf8:	sub	x12, x12, #0x5
   17cfc:	orr	x12, x12, #0x1
   17d00:	umulh	x14, x12, x21
   17d04:	lsr	x12, x14, #1
   17d08:	sub	x11, x11, #0x5
   17d0c:	lsl	x16, x12, #1
   17d10:	umulh	x11, x11, x21
   17d14:	add	x15, x12, #0x1
   17d18:	add	x14, x16, x14, lsr #1
   17d1c:	lsr	x11, x11, #1
   17d20:	add	x13, x12, #0x2
   17d24:	lsr	x12, x15, #6
   17d28:	lsl	x15, x28, x15
   17d2c:	add	x14, x14, #0x7
   17d30:	ldr	x16, [x22, x12, lsl #3]
   17d34:	tst	x16, x15
   17d38:	b.ne	17d64 <__gmpz_oddfac_1@@Base+0x488>  // b.any
   17d3c:	and	x16, x13, #0x1
   17d40:	cmp	x9, x8
   17d44:	add	x16, x14, x16
   17d48:	b.ls	17d60 <__gmpz_oddfac_1@@Base+0x484>  // b.plast
   17d4c:	add	x17, x10, #0x1
   17d50:	str	x9, [x23, x10, lsl #3]
   17d54:	mov	x10, x17
   17d58:	mov	x9, x16
   17d5c:	b	17d64 <__gmpz_oddfac_1@@Base+0x488>
   17d60:	mul	x9, x16, x9
   17d64:	add	x12, x12, x15, lsr #63
   17d68:	ror	x15, x15, #63
   17d6c:	cmp	x13, x11
   17d70:	add	x13, x13, #0x1
   17d74:	add	x14, x14, #0x3
   17d78:	b.ls	17d30 <__gmpz_oddfac_1@@Base+0x454>  // b.plast
   17d7c:	cbz	x10, 17e88 <__gmpz_oddfac_1@@Base+0x5ac>
   17d80:	add	x2, x10, #0x1
   17d84:	sub	x0, x29, #0x10
   17d88:	mov	x1, x23
   17d8c:	str	x9, [x23, x10, lsl #3]
   17d90:	bl	cd90 <__gmpz_prodlimbs@plt>
   17d94:	stur	xzr, [x29, #-32]
   17d98:	ldur	w8, [x29, #-44]
   17d9c:	ldrsw	x24, [x26, #4]
   17da0:	cmp	w25, w8
   17da4:	b.ne	17de0 <__gmpz_oddfac_1@@Base+0x504>  // b.any
   17da8:	lsl	x1, x24, #3
   17dac:	mov	w8, #0x7f00                	// #32512
   17db0:	cmp	x1, x8
   17db4:	b.hi	17eb0 <__gmpz_oddfac_1@@Base+0x5d4>  // b.pmore
   17db8:	add	x9, x1, #0xf
   17dbc:	mov	x8, sp
   17dc0:	and	x9, x9, #0xfffffffffffffff0
   17dc4:	sub	x25, x8, x9
   17dc8:	mov	sp, x25
   17dcc:	ldr	x1, [x26, #8]
   17dd0:	mov	x0, x25
   17dd4:	mov	x2, x24
   17dd8:	bl	ca70 <__gmpn_copyi@plt>
   17ddc:	b	17e34 <__gmpz_oddfac_1@@Base+0x558>
   17de0:	lsl	x1, x24, #4
   17de4:	mov	w8, #0x7f00                	// #32512
   17de8:	mov	x20, x26
   17dec:	cmp	x1, x8
   17df0:	lsl	x26, x24, #1
   17df4:	b.hi	17ec0 <__gmpz_oddfac_1@@Base+0x5e4>  // b.pmore
   17df8:	add	x9, x1, #0xf
   17dfc:	mov	x8, sp
   17e00:	and	x9, x9, #0xfffffffffffffff0
   17e04:	sub	x25, x8, x9
   17e08:	mov	sp, x25
   17e0c:	ldr	x1, [x20, #8]
   17e10:	mov	x0, x25
   17e14:	mov	x2, x24
   17e18:	bl	c900 <__gmpn_sqr@plt>
   17e1c:	add	x8, x25, x26, lsl #3
   17e20:	ldur	x8, [x8, #-8]
   17e24:	cmp	x8, #0x0
   17e28:	cset	w8, eq  // eq = none
   17e2c:	sub	x24, x26, x8
   17e30:	mov	x26, x20
   17e34:	ldursw	x27, [x29, #-12]
   17e38:	ldrsw	x8, [x26]
   17e3c:	add	x20, x24, x27
   17e40:	cmp	x20, x8
   17e44:	b.gt	17e98 <__gmpz_oddfac_1@@Base+0x5bc>
   17e48:	ldr	x0, [x26, #8]
   17e4c:	ldur	x3, [x29, #-8]
   17e50:	mov	x1, x25
   17e54:	mov	x2, x24
   17e58:	mov	x4, x27
   17e5c:	bl	ccf0 <__gmpn_mul@plt>
   17e60:	cmp	x0, #0x0
   17e64:	cset	w8, eq  // eq = none
   17e68:	sub	w8, w20, w8
   17e6c:	str	w8, [x26, #4]
   17e70:	ldur	x0, [x29, #-32]
   17e74:	cbnz	x0, 17ea8 <__gmpz_oddfac_1@@Base+0x5cc>
   17e78:	ldur	x8, [x29, #-40]
   17e7c:	mov	w25, w8
   17e80:	cbnz	w8, 17b68 <__gmpz_oddfac_1@@Base+0x28c>
   17e84:	b	17ed0 <__gmpz_oddfac_1@@Base+0x5f4>
   17e88:	ldur	x8, [x29, #-8]
   17e8c:	str	x9, [x8]
   17e90:	stur	w28, [x29, #-12]
   17e94:	b	17d94 <__gmpz_oddfac_1@@Base+0x4b8>
   17e98:	mov	x0, x26
   17e9c:	mov	x1, x20
   17ea0:	bl	c090 <__gmpz_realloc@plt>
   17ea4:	b	17e4c <__gmpz_oddfac_1@@Base+0x570>
   17ea8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   17eac:	b	17e78 <__gmpz_oddfac_1@@Base+0x59c>
   17eb0:	sub	x0, x29, #0x20
   17eb4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   17eb8:	mov	x25, x0
   17ebc:	b	17dcc <__gmpz_oddfac_1@@Base+0x4f0>
   17ec0:	sub	x0, x29, #0x20
   17ec4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   17ec8:	mov	x25, x0
   17ecc:	b	17e0c <__gmpz_oddfac_1@@Base+0x530>
   17ed0:	ldur	x0, [x29, #-24]
   17ed4:	cbnz	x0, 17f34 <__gmpz_oddfac_1@@Base+0x658>
   17ed8:	mov	sp, x29
   17edc:	ldp	x20, x19, [sp, #80]
   17ee0:	ldp	x22, x21, [sp, #64]
   17ee4:	ldp	x24, x23, [sp, #48]
   17ee8:	ldp	x26, x25, [sp, #32]
   17eec:	ldp	x28, x27, [sp, #16]
   17ef0:	ldp	x29, x30, [sp], #96
   17ef4:	ret
   17ef8:	mov	w1, #0x1                   	// #1
   17efc:	mov	x0, x26
   17f00:	bl	c090 <__gmpz_realloc@plt>
   17f04:	b	1792c <__gmpz_oddfac_1@@Base+0x50>
   17f08:	mov	w1, #0x2                   	// #2
   17f0c:	mov	x0, x26
   17f10:	bl	c090 <__gmpz_realloc@plt>
   17f14:	b	17954 <__gmpz_oddfac_1@@Base+0x78>
   17f18:	sub	x0, x29, #0x18
   17f1c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   17f20:	b	17ae8 <__gmpz_oddfac_1@@Base+0x20c>
   17f24:	sub	x0, x29, #0x18
   17f28:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   17f2c:	mov	x23, x0
   17f30:	b	17b5c <__gmpz_oddfac_1@@Base+0x280>
   17f34:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   17f38:	b	17ed8 <__gmpz_oddfac_1@@Base+0x5fc>

0000000000017f3c <__gmpz_prodlimbs@@Base>:
   17f3c:	stp	x29, x30, [sp, #-64]!
   17f40:	stp	x24, x23, [sp, #16]
   17f44:	stp	x22, x21, [sp, #32]
   17f48:	stp	x20, x19, [sp, #48]
   17f4c:	mov	x29, sp
   17f50:	sub	sp, sp, #0x30
   17f54:	mov	x20, x1
   17f58:	cmp	x2, #0xd
   17f5c:	mov	x19, x0
   17f60:	b.le	17ffc <__gmpz_prodlimbs@@Base+0xc0>
   17f64:	sub	x22, x2, x2, lsr #1
   17f68:	lsl	x1, x22, #3
   17f6c:	mov	w8, #0x7f00                	// #32512
   17f70:	lsr	x21, x2, #1
   17f74:	cmp	x1, x8
   17f78:	stur	xzr, [x29, #-40]
   17f7c:	stur	w22, [x29, #-32]
   17f80:	b.hi	180d0 <__gmpz_prodlimbs@@Base+0x194>  // b.pmore
   17f84:	add	x9, x1, #0xf
   17f88:	mov	x8, sp
   17f8c:	and	x9, x9, #0xfffffffffffffff0
   17f90:	sub	x0, x8, x9
   17f94:	mov	sp, x0
   17f98:	stur	x0, [x29, #-24]
   17f9c:	add	x1, x20, x21, lsl #3
   17fa0:	sub	x0, x29, #0x20
   17fa4:	mov	x2, x22
   17fa8:	stur	x1, [x29, #-8]
   17fac:	stur	w22, [x29, #-16]
   17fb0:	bl	cd90 <__gmpz_prodlimbs@plt>
   17fb4:	mov	x22, x0
   17fb8:	sub	x0, x29, #0x10
   17fbc:	mov	x1, x20
   17fc0:	mov	x2, x21
   17fc4:	bl	cd90 <__gmpz_prodlimbs@plt>
   17fc8:	ldrsw	x8, [x19]
   17fcc:	add	x20, x0, x22
   17fd0:	mov	x21, x0
   17fd4:	cmp	x20, x8
   17fd8:	b.gt	180dc <__gmpz_prodlimbs@@Base+0x1a0>
   17fdc:	ldr	x0, [x19, #8]
   17fe0:	cmp	x21, x22
   17fe4:	b.ge	18048 <__gmpz_prodlimbs@@Base+0x10c>  // b.tcont
   17fe8:	ldur	x1, [x29, #-24]
   17fec:	ldur	x3, [x29, #-8]
   17ff0:	mov	x2, x22
   17ff4:	mov	x4, x21
   17ff8:	b	18058 <__gmpz_prodlimbs@@Base+0x11c>
   17ffc:	cmp	x2, #0x3
   18000:	b.lt	18078 <__gmpz_prodlimbs@@Base+0x13c>  // b.tstop
   18004:	mov	x22, xzr
   18008:	sub	x23, x2, #0x1
   1800c:	sub	x24, x2, #0x2
   18010:	mov	w21, #0x1                   	// #1
   18014:	add	x8, x20, x22, lsl #3
   18018:	ldr	x3, [x8, #8]
   1801c:	mov	x0, x20
   18020:	mov	x1, x20
   18024:	mov	x2, x21
   18028:	bl	d4b0 <__gmpn_mul_1@plt>
   1802c:	cmp	x0, #0x0
   18030:	add	x22, x22, #0x1
   18034:	str	x0, [x20, x21, lsl #3]
   18038:	cinc	x21, x21, ne  // ne = any
   1803c:	cmp	x24, x22
   18040:	b.ne	18014 <__gmpz_prodlimbs@@Base+0xd8>  // b.any
   18044:	b	18080 <__gmpz_prodlimbs@@Base+0x144>
   18048:	ldur	x1, [x29, #-8]
   1804c:	ldur	x3, [x29, #-24]
   18050:	mov	x2, x21
   18054:	mov	x4, x22
   18058:	bl	ccf0 <__gmpn_mul@plt>
   1805c:	mov	x21, x0
   18060:	ldur	x0, [x29, #-40]
   18064:	cbnz	x0, 180ec <__gmpz_prodlimbs@@Base+0x1b0>
   18068:	cmp	x21, #0x0
   1806c:	cset	w8, eq  // eq = none
   18070:	sub	x8, x20, x8
   18074:	b	180b0 <__gmpz_prodlimbs@@Base+0x174>
   18078:	mov	w21, #0x1                   	// #1
   1807c:	mov	w23, #0x1                   	// #1
   18080:	ldrsw	x8, [x19]
   18084:	cmp	x21, x8
   18088:	b.ge	180f4 <__gmpz_prodlimbs@@Base+0x1b8>  // b.tcont
   1808c:	ldr	x22, [x19, #8]
   18090:	ldr	x3, [x20, x23, lsl #3]
   18094:	mov	x0, x22
   18098:	mov	x1, x20
   1809c:	mov	x2, x21
   180a0:	bl	d4b0 <__gmpn_mul_1@plt>
   180a4:	cmp	x0, #0x0
   180a8:	str	x0, [x22, x21, lsl #3]
   180ac:	cinc	x8, x21, ne  // ne = any
   180b0:	str	w8, [x19, #4]
   180b4:	sxtw	x0, w8
   180b8:	mov	sp, x29
   180bc:	ldp	x20, x19, [sp, #48]
   180c0:	ldp	x22, x21, [sp, #32]
   180c4:	ldp	x24, x23, [sp, #16]
   180c8:	ldp	x29, x30, [sp], #64
   180cc:	ret
   180d0:	sub	x0, x29, #0x28
   180d4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   180d8:	b	17f98 <__gmpz_prodlimbs@@Base+0x5c>
   180dc:	mov	x0, x19
   180e0:	mov	x1, x20
   180e4:	bl	c090 <__gmpz_realloc@plt>
   180e8:	b	17fe0 <__gmpz_prodlimbs@@Base+0xa4>
   180ec:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   180f0:	b	18068 <__gmpz_prodlimbs@@Base+0x12c>
   180f4:	add	x1, x21, #0x1
   180f8:	mov	x0, x19
   180fc:	bl	c090 <__gmpz_realloc@plt>
   18100:	mov	x22, x0
   18104:	b	18090 <__gmpz_prodlimbs@@Base+0x154>

0000000000018108 <__gmpz_fdiv_q_ui@@Base>:
   18108:	stp	x29, x30, [sp, #-64]!
   1810c:	stp	x24, x23, [sp, #16]
   18110:	stp	x22, x21, [sp, #32]
   18114:	stp	x20, x19, [sp, #48]
   18118:	mov	x29, sp
   1811c:	cbz	x2, 181d8 <__gmpz_fdiv_q_ui@@Base+0xd0>
   18120:	ldrsw	x24, [x1, #4]
   18124:	mov	x23, x1
   18128:	mov	x19, x0
   1812c:	cbz	w24, 181a4 <__gmpz_fdiv_q_ui@@Base+0x9c>
   18130:	ldrsw	x8, [x19]
   18134:	cmp	w24, #0x0
   18138:	cneg	x21, x24, lt  // lt = tstop
   1813c:	mov	x20, x2
   18140:	cmp	x21, x8
   18144:	b.gt	181c4 <__gmpz_fdiv_q_ui@@Base+0xbc>
   18148:	ldr	x22, [x19, #8]
   1814c:	ldr	x2, [x23, #8]
   18150:	mov	x0, x22
   18154:	mov	x1, xzr
   18158:	mov	x3, x21
   1815c:	mov	x4, x20
   18160:	bl	cd20 <__gmpn_divrem_1@plt>
   18164:	tbz	w24, #31, 18184 <__gmpz_fdiv_q_ui@@Base+0x7c>
   18168:	cbz	x0, 18184 <__gmpz_fdiv_q_ui@@Base+0x7c>
   1816c:	mov	x8, x22
   18170:	ldr	x9, [x8]
   18174:	adds	x9, x9, #0x1
   18178:	str	x9, [x8], #8
   1817c:	b.cs	18170 <__gmpz_fdiv_q_ui@@Base+0x68>  // b.hs, b.nlast
   18180:	sub	x0, x20, x0
   18184:	add	x8, x22, x21, lsl #3
   18188:	ldur	x8, [x8, #-8]
   1818c:	cmp	x8, #0x0
   18190:	cset	w8, eq  // eq = none
   18194:	sub	w8, w21, w8
   18198:	cmp	w24, #0x0
   1819c:	cneg	w8, w8, lt  // lt = tstop
   181a0:	b	181ac <__gmpz_fdiv_q_ui@@Base+0xa4>
   181a4:	mov	w8, wzr
   181a8:	mov	x0, xzr
   181ac:	str	w8, [x19, #4]
   181b0:	ldp	x20, x19, [sp, #48]
   181b4:	ldp	x22, x21, [sp, #32]
   181b8:	ldp	x24, x23, [sp, #16]
   181bc:	ldp	x29, x30, [sp], #64
   181c0:	ret
   181c4:	mov	x0, x19
   181c8:	mov	x1, x21
   181cc:	bl	c090 <__gmpz_realloc@plt>
   181d0:	mov	x22, x0
   181d4:	b	1814c <__gmpz_fdiv_q_ui@@Base+0x44>
   181d8:	bl	bfe0 <__gmp_divide_by_zero@plt>

00000000000181dc <__gmpz_fdiv_qr@@Base>:
   181dc:	stp	x29, x30, [sp, #-64]!
   181e0:	str	x23, [sp, #16]
   181e4:	stp	x22, x21, [sp, #32]
   181e8:	stp	x20, x19, [sp, #48]
   181ec:	mov	x29, sp
   181f0:	sub	sp, sp, #0x10
   181f4:	ldrsw	x23, [x3, #4]
   181f8:	mov	x20, x3
   181fc:	mov	x22, x2
   18200:	mov	x19, x1
   18204:	mov	x21, x0
   18208:	cmp	x0, x3
   1820c:	str	xzr, [x29, #24]
   18210:	b.eq	1821c <__gmpz_fdiv_qr@@Base+0x40>  // b.none
   18214:	cmp	x19, x20
   18218:	b.ne	1825c <__gmpz_fdiv_qr@@Base+0x80>  // b.any
   1821c:	cmp	x23, #0x0
   18220:	cneg	x8, x23, mi  // mi = first
   18224:	cmp	x8, #0xfe0
   18228:	lsl	x1, x8, #3
   1822c:	stur	w8, [x29, #-16]
   18230:	b.hi	182cc <__gmpz_fdiv_qr@@Base+0xf0>  // b.pmore
   18234:	add	x9, x1, #0xf
   18238:	mov	x8, sp
   1823c:	and	x9, x9, #0xfffffffffffffff0
   18240:	sub	x0, x8, x9
   18244:	mov	sp, x0
   18248:	stur	x0, [x29, #-8]
   1824c:	sub	x0, x29, #0x10
   18250:	mov	x1, x20
   18254:	bl	c440 <__gmpz_set@plt>
   18258:	sub	x20, x29, #0x10
   1825c:	ldr	w8, [x22, #4]
   18260:	mov	x0, x21
   18264:	mov	x1, x19
   18268:	mov	x2, x22
   1826c:	mov	x3, x20
   18270:	eor	w23, w8, w23
   18274:	bl	c000 <__gmpz_tdiv_qr@plt>
   18278:	tbz	w23, #31, 182a4 <__gmpz_fdiv_qr@@Base+0xc8>
   1827c:	ldr	w8, [x19, #4]
   18280:	cbz	w8, 182a4 <__gmpz_fdiv_qr@@Base+0xc8>
   18284:	mov	w2, #0x1                   	// #1
   18288:	mov	x0, x21
   1828c:	mov	x1, x21
   18290:	bl	c130 <__gmpz_sub_ui@plt>
   18294:	mov	x0, x19
   18298:	mov	x1, x19
   1829c:	mov	x2, x20
   182a0:	bl	cfb0 <__gmpz_add@plt>
   182a4:	ldr	x0, [x29, #24]
   182a8:	cbnz	x0, 182c4 <__gmpz_fdiv_qr@@Base+0xe8>
   182ac:	mov	sp, x29
   182b0:	ldp	x20, x19, [sp, #48]
   182b4:	ldp	x22, x21, [sp, #32]
   182b8:	ldr	x23, [sp, #16]
   182bc:	ldp	x29, x30, [sp], #64
   182c0:	ret
   182c4:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   182c8:	b	182ac <__gmpz_fdiv_qr@@Base+0xd0>
   182cc:	add	x0, x29, #0x18
   182d0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   182d4:	b	18248 <__gmpz_fdiv_qr@@Base+0x6c>

00000000000182d8 <__gmpz_fdiv_qr_ui@@Base>:
   182d8:	stp	x29, x30, [sp, #-80]!
   182dc:	str	x25, [sp, #16]
   182e0:	stp	x24, x23, [sp, #32]
   182e4:	stp	x22, x21, [sp, #48]
   182e8:	stp	x20, x19, [sp, #64]
   182ec:	mov	x29, sp
   182f0:	cbz	x3, 183fc <__gmpz_fdiv_qr_ui@@Base+0x124>
   182f4:	ldrsw	x25, [x2, #4]
   182f8:	mov	x22, x2
   182fc:	mov	x20, x1
   18300:	mov	x19, x0
   18304:	cbz	w25, 18380 <__gmpz_fdiv_qr_ui@@Base+0xa8>
   18308:	ldrsw	x8, [x19]
   1830c:	cmp	w25, #0x0
   18310:	cneg	x21, x25, lt  // lt = tstop
   18314:	mov	x24, x3
   18318:	cmp	x21, x8
   1831c:	b.gt	183d8 <__gmpz_fdiv_qr_ui@@Base+0x100>
   18320:	ldr	x23, [x19, #8]
   18324:	ldr	x2, [x22, #8]
   18328:	mov	x0, x23
   1832c:	mov	x1, xzr
   18330:	mov	x3, x21
   18334:	mov	x4, x24
   18338:	bl	cd20 <__gmpn_divrem_1@plt>
   1833c:	mov	x22, x0
   18340:	cbz	x0, 18394 <__gmpz_fdiv_qr_ui@@Base+0xbc>
   18344:	tbz	w25, #31, 18360 <__gmpz_fdiv_qr_ui@@Base+0x88>
   18348:	mov	x8, x23
   1834c:	ldr	x9, [x8]
   18350:	adds	x9, x9, #0x1
   18354:	str	x9, [x8], #8
   18358:	b.cs	1834c <__gmpz_fdiv_qr_ui@@Base+0x74>  // b.hs, b.nlast
   1835c:	sub	x22, x24, x22
   18360:	ldr	w8, [x20]
   18364:	cmp	w8, #0x0
   18368:	b.le	183ec <__gmpz_fdiv_qr_ui@@Base+0x114>
   1836c:	ldr	x0, [x20, #8]
   18370:	cmp	x22, #0x0
   18374:	cset	w8, ne  // ne = any
   18378:	str	x22, [x0]
   1837c:	b	18398 <__gmpz_fdiv_qr_ui@@Base+0xc0>
   18380:	mov	w8, wzr
   18384:	mov	x22, xzr
   18388:	str	wzr, [x19, #4]
   1838c:	mov	x19, x20
   18390:	b	183b8 <__gmpz_fdiv_qr_ui@@Base+0xe0>
   18394:	mov	w8, wzr
   18398:	str	w8, [x20, #4]
   1839c:	add	x8, x23, x21, lsl #3
   183a0:	ldur	x8, [x8, #-8]
   183a4:	cmp	x8, #0x0
   183a8:	cset	w8, eq  // eq = none
   183ac:	sub	w8, w21, w8
   183b0:	cmp	w25, #0x0
   183b4:	cneg	w8, w8, lt  // lt = tstop
   183b8:	str	w8, [x19, #4]
   183bc:	mov	x0, x22
   183c0:	ldp	x20, x19, [sp, #64]
   183c4:	ldp	x22, x21, [sp, #48]
   183c8:	ldp	x24, x23, [sp, #32]
   183cc:	ldr	x25, [sp, #16]
   183d0:	ldp	x29, x30, [sp], #80
   183d4:	ret
   183d8:	mov	x0, x19
   183dc:	mov	x1, x21
   183e0:	bl	c090 <__gmpz_realloc@plt>
   183e4:	mov	x23, x0
   183e8:	b	18324 <__gmpz_fdiv_qr_ui@@Base+0x4c>
   183ec:	mov	w1, #0x1                   	// #1
   183f0:	mov	x0, x20
   183f4:	bl	c090 <__gmpz_realloc@plt>
   183f8:	b	18370 <__gmpz_fdiv_qr_ui@@Base+0x98>
   183fc:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000018400 <__gmpz_fdiv_r@@Base>:
   18400:	stp	x29, x30, [sp, #-48]!
   18404:	stp	x22, x21, [sp, #16]
   18408:	stp	x20, x19, [sp, #32]
   1840c:	mov	x29, sp
   18410:	sub	sp, sp, #0x20
   18414:	ldrsw	x22, [x2, #4]
   18418:	mov	x19, x2
   1841c:	mov	x21, x1
   18420:	mov	x20, x0
   18424:	cmp	x0, x2
   18428:	stur	xzr, [x29, #-24]
   1842c:	b.ne	18470 <__gmpz_fdiv_r@@Base+0x70>  // b.any
   18430:	cmp	x22, #0x0
   18434:	cneg	x8, x22, mi  // mi = first
   18438:	cmp	x8, #0xfe0
   1843c:	lsl	x1, x8, #3
   18440:	stur	w8, [x29, #-16]
   18444:	b.hi	184c8 <__gmpz_fdiv_r@@Base+0xc8>  // b.pmore
   18448:	add	x9, x1, #0xf
   1844c:	mov	x8, sp
   18450:	and	x9, x9, #0xfffffffffffffff0
   18454:	sub	x0, x8, x9
   18458:	mov	sp, x0
   1845c:	stur	x0, [x29, #-8]
   18460:	sub	x0, x29, #0x10
   18464:	mov	x1, x19
   18468:	bl	c440 <__gmpz_set@plt>
   1846c:	sub	x19, x29, #0x10
   18470:	mov	x0, x20
   18474:	mov	x1, x21
   18478:	mov	x2, x19
   1847c:	bl	caa0 <__gmpz_tdiv_r@plt>
   18480:	ldr	w8, [x21, #4]
   18484:	eor	w8, w8, w22
   18488:	tbz	w8, #31, 184a4 <__gmpz_fdiv_r@@Base+0xa4>
   1848c:	ldr	w8, [x20, #4]
   18490:	cbz	w8, 184a4 <__gmpz_fdiv_r@@Base+0xa4>
   18494:	mov	x0, x20
   18498:	mov	x1, x20
   1849c:	mov	x2, x19
   184a0:	bl	cfb0 <__gmpz_add@plt>
   184a4:	ldur	x0, [x29, #-24]
   184a8:	cbnz	x0, 184c0 <__gmpz_fdiv_r@@Base+0xc0>
   184ac:	mov	sp, x29
   184b0:	ldp	x20, x19, [sp, #32]
   184b4:	ldp	x22, x21, [sp, #16]
   184b8:	ldp	x29, x30, [sp], #48
   184bc:	ret
   184c0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   184c4:	b	184ac <__gmpz_fdiv_r@@Base+0xac>
   184c8:	sub	x0, x29, #0x18
   184cc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   184d0:	b	1845c <__gmpz_fdiv_r@@Base+0x5c>

00000000000184d4 <__gmpz_fdiv_r_ui@@Base>:
   184d4:	stp	x29, x30, [sp, #-48]!
   184d8:	str	x21, [sp, #16]
   184dc:	stp	x20, x19, [sp, #32]
   184e0:	mov	x29, sp
   184e4:	cbz	x2, 18564 <__gmpz_fdiv_r_ui@@Base+0x90>
   184e8:	ldrsw	x21, [x1, #4]
   184ec:	mov	x19, x0
   184f0:	cbz	w21, 18534 <__gmpz_fdiv_r_ui@@Base+0x60>
   184f4:	ldr	x0, [x1, #8]
   184f8:	cmp	x21, #0x0
   184fc:	cneg	x1, x21, mi  // mi = first
   18500:	mov	x20, x2
   18504:	bl	c400 <__gmpn_mod_1@plt>
   18508:	cbz	x0, 18534 <__gmpz_fdiv_r_ui@@Base+0x60>
   1850c:	ldr	w8, [x19]
   18510:	sub	x9, x20, x0
   18514:	cmp	w21, #0x0
   18518:	csel	x20, x9, x0, lt  // lt = tstop
   1851c:	cmp	w8, #0x0
   18520:	b.le	18554 <__gmpz_fdiv_r_ui@@Base+0x80>
   18524:	ldr	x0, [x19, #8]
   18528:	mov	w8, #0x1                   	// #1
   1852c:	str	x20, [x0]
   18530:	b	1853c <__gmpz_fdiv_r_ui@@Base+0x68>
   18534:	mov	w8, wzr
   18538:	mov	x20, xzr
   1853c:	str	w8, [x19, #4]
   18540:	mov	x0, x20
   18544:	ldp	x20, x19, [sp, #32]
   18548:	ldr	x21, [sp, #16]
   1854c:	ldp	x29, x30, [sp], #48
   18550:	ret
   18554:	mov	w1, #0x1                   	// #1
   18558:	mov	x0, x19
   1855c:	bl	c090 <__gmpz_realloc@plt>
   18560:	b	18528 <__gmpz_fdiv_r_ui@@Base+0x54>
   18564:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000018568 <__gmpz_fdiv_q@@Base>:
   18568:	stp	x29, x30, [sp, #-64]!
   1856c:	str	x23, [sp, #16]
   18570:	stp	x22, x21, [sp, #32]
   18574:	stp	x20, x19, [sp, #48]
   18578:	mov	x29, sp
   1857c:	sub	sp, sp, #0x10
   18580:	ldrsw	x22, [x2, #4]
   18584:	ldr	w23, [x1, #4]
   18588:	mov	x20, x2
   1858c:	mov	x21, x1
   18590:	cmp	x22, #0x0
   18594:	cneg	x8, x22, mi  // mi = first
   18598:	mov	x19, x0
   1859c:	cmp	x8, #0xfe0
   185a0:	lsl	x1, x8, #3
   185a4:	str	xzr, [x29, #24]
   185a8:	stur	w8, [x29, #-16]
   185ac:	b.hi	1861c <__gmpz_fdiv_q@@Base+0xb4>  // b.pmore
   185b0:	add	x9, x1, #0xf
   185b4:	mov	x8, sp
   185b8:	and	x9, x9, #0xfffffffffffffff0
   185bc:	sub	x0, x8, x9
   185c0:	mov	sp, x0
   185c4:	stur	x0, [x29, #-8]
   185c8:	sub	x1, x29, #0x10
   185cc:	mov	x0, x19
   185d0:	mov	x2, x21
   185d4:	mov	x3, x20
   185d8:	bl	c000 <__gmpz_tdiv_qr@plt>
   185dc:	eor	w8, w22, w23
   185e0:	tbz	w8, #31, 185fc <__gmpz_fdiv_q@@Base+0x94>
   185e4:	ldur	w8, [x29, #-12]
   185e8:	cbz	w8, 185fc <__gmpz_fdiv_q@@Base+0x94>
   185ec:	mov	w2, #0x1                   	// #1
   185f0:	mov	x0, x19
   185f4:	mov	x1, x19
   185f8:	bl	c130 <__gmpz_sub_ui@plt>
   185fc:	ldr	x0, [x29, #24]
   18600:	cbnz	x0, 18628 <__gmpz_fdiv_q@@Base+0xc0>
   18604:	mov	sp, x29
   18608:	ldp	x20, x19, [sp, #48]
   1860c:	ldp	x22, x21, [sp, #32]
   18610:	ldr	x23, [sp, #16]
   18614:	ldp	x29, x30, [sp], #64
   18618:	ret
   1861c:	add	x0, x29, #0x18
   18620:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   18624:	b	185c4 <__gmpz_fdiv_q@@Base+0x5c>
   18628:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1862c:	b	18604 <__gmpz_fdiv_q@@Base+0x9c>

0000000000018630 <__gmpz_fdiv_ui@@Base>:
   18630:	stp	x29, x30, [sp, #-32]!
   18634:	stp	x20, x19, [sp, #16]
   18638:	mov	x29, sp
   1863c:	cbz	x1, 18684 <__gmpz_fdiv_ui@@Base+0x54>
   18640:	ldrsw	x20, [x0, #4]
   18644:	cbz	w20, 18674 <__gmpz_fdiv_ui@@Base+0x44>
   18648:	ldr	x0, [x0, #8]
   1864c:	mov	x19, x1
   18650:	cmp	x20, #0x0
   18654:	cneg	x1, x20, mi  // mi = first
   18658:	mov	x2, x19
   1865c:	bl	c400 <__gmpn_mod_1@plt>
   18660:	cmp	x0, #0x0
   18664:	sub	x8, x19, x0
   18668:	ccmp	w20, #0x0, #0x0, ne  // ne = any
   1866c:	csel	x0, x8, x0, lt  // lt = tstop
   18670:	b	18678 <__gmpz_fdiv_ui@@Base+0x48>
   18674:	mov	x0, xzr
   18678:	ldp	x20, x19, [sp, #16]
   1867c:	ldp	x29, x30, [sp], #32
   18680:	ret
   18684:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000018688 <__gmpz_fib_ui@@Base>:
   18688:	stp	x29, x30, [sp, #-80]!
   1868c:	stp	x26, x25, [sp, #16]
   18690:	stp	x24, x23, [sp, #32]
   18694:	stp	x22, x21, [sp, #48]
   18698:	stp	x20, x19, [sp, #64]
   1869c:	mov	x29, sp
   186a0:	sub	sp, sp, #0x10
   186a4:	mov	x20, x1
   186a8:	cmp	x1, #0x5d
   186ac:	mov	x19, x0
   186b0:	b.hi	186e8 <__gmpz_fib_ui@@Base+0x60>  // b.pmore
   186b4:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   186b8:	ldr	x8, [x8, #3808]
   186bc:	ldr	w9, [x19]
   186c0:	add	x8, x8, x20, lsl #3
   186c4:	ldr	x21, [x8, #8]
   186c8:	cmp	w9, #0x0
   186cc:	b.le	18864 <__gmpz_fib_ui@@Base+0x1dc>
   186d0:	ldr	x0, [x19, #8]
   186d4:	cmp	x20, #0x0
   186d8:	cset	w8, ne  // ne = any
   186dc:	str	x21, [x0]
   186e0:	str	w8, [x19, #4]
   186e4:	b	18848 <__gmpz_fib_ui@@Base+0x1c0>
   186e8:	lsr	x8, x20, #6
   186ec:	mov	w9, #0x17                  	// #23
   186f0:	mul	x22, x8, x9
   186f4:	ldrsw	x8, [x19]
   186f8:	lsr	x9, x22, #6
   186fc:	add	x23, x9, #0x5
   18700:	lsl	x1, x23, #1
   18704:	cmp	x1, x8
   18708:	lsr	x24, x20, #1
   1870c:	b.gt	18874 <__gmpz_fib_ui@@Base+0x1ec>
   18710:	ldr	x21, [x19, #8]
   18714:	lsr	x8, x22, #8
   18718:	cmp	x8, #0x1fa
   1871c:	lsl	x1, x23, #4
   18720:	stur	xzr, [x29, #-8]
   18724:	b.hi	18884 <__gmpz_fib_ui@@Base+0x1fc>  // b.pmore
   18728:	add	x9, x1, #0xf
   1872c:	mov	x8, sp
   18730:	and	x9, x9, #0x7ffffffffffffff0
   18734:	sub	x22, x8, x9
   18738:	mov	sp, x22
   1873c:	add	x23, x22, x23, lsl #3
   18740:	mov	x0, x22
   18744:	mov	x1, x23
   18748:	mov	x2, x24
   1874c:	bl	d090 <__gmpn_fib2_ui@plt>
   18750:	mov	x24, x0
   18754:	tbnz	w20, #0, 18794 <__gmpz_fib_ui@@Base+0x10c>
   18758:	mov	x0, x23
   1875c:	mov	x1, x22
   18760:	mov	x2, x23
   18764:	mov	x3, x24
   18768:	bl	cc60 <__gmpn_addlsh1_n@plt>
   1876c:	cmp	x0, #0x0
   18770:	str	x0, [x23, x24, lsl #3]
   18774:	cinc	x2, x24, ne  // ne = any
   18778:	mov	x0, x21
   1877c:	mov	x1, x23
   18780:	mov	x3, x22
   18784:	mov	x4, x24
   18788:	add	x25, x2, x24
   1878c:	bl	ccf0 <__gmpn_mul@plt>
   18790:	b	1881c <__gmpz_fib_ui@@Base+0x194>
   18794:	mov	w3, #0x1                   	// #1
   18798:	mov	x0, x21
   1879c:	mov	x1, x22
   187a0:	mov	x2, x24
   187a4:	bl	c190 <__gmpn_lshift@plt>
   187a8:	mov	x25, x0
   187ac:	mov	x0, x22
   187b0:	mov	x1, x21
   187b4:	mov	x2, x23
   187b8:	mov	x3, x24
   187bc:	bl	ca90 <__gmpn_add_n@plt>
   187c0:	adds	x8, x0, x25
   187c4:	mov	x0, x23
   187c8:	mov	x1, x21
   187cc:	mov	x2, x23
   187d0:	mov	x3, x24
   187d4:	str	x8, [x22, x24, lsl #3]
   187d8:	cinc	x26, x24, ne  // ne = any
   187dc:	bl	c2e0 <__gmpn_sub_n@plt>
   187e0:	sub	x8, x25, x0
   187e4:	add	x4, x8, x24
   187e8:	mov	x0, x21
   187ec:	mov	x1, x22
   187f0:	mov	x2, x26
   187f4:	mov	x3, x23
   187f8:	str	x8, [x23, x24, lsl #3]
   187fc:	add	x25, x26, x4
   18800:	bl	ccf0 <__gmpn_mul@plt>
   18804:	ldr	x8, [x21]
   18808:	tst	x20, #0x2
   1880c:	mov	w9, #0x2                   	// #2
   18810:	cneg	x9, x9, ne  // ne = any
   18814:	add	x8, x8, x9
   18818:	str	x8, [x21]
   1881c:	cmp	x0, #0x0
   18820:	cset	w8, eq  // eq = none
   18824:	sub	x8, x25, x8
   18828:	add	x9, x21, x8, lsl #3
   1882c:	ldur	x9, [x9, #-8]
   18830:	cmp	x9, #0x0
   18834:	cset	w9, eq  // eq = none
   18838:	sub	w8, w8, w9
   1883c:	str	w8, [x19, #4]
   18840:	ldur	x0, [x29, #-8]
   18844:	cbnz	x0, 18894 <__gmpz_fib_ui@@Base+0x20c>
   18848:	mov	sp, x29
   1884c:	ldp	x20, x19, [sp, #64]
   18850:	ldp	x22, x21, [sp, #48]
   18854:	ldp	x24, x23, [sp, #32]
   18858:	ldp	x26, x25, [sp, #16]
   1885c:	ldp	x29, x30, [sp], #80
   18860:	ret
   18864:	mov	w1, #0x1                   	// #1
   18868:	mov	x0, x19
   1886c:	bl	c090 <__gmpz_realloc@plt>
   18870:	b	186d4 <__gmpz_fib_ui@@Base+0x4c>
   18874:	mov	x0, x19
   18878:	bl	c090 <__gmpz_realloc@plt>
   1887c:	mov	x21, x0
   18880:	b	18714 <__gmpz_fib_ui@@Base+0x8c>
   18884:	sub	x0, x29, #0x8
   18888:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1888c:	mov	x22, x0
   18890:	b	1873c <__gmpz_fib_ui@@Base+0xb4>
   18894:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   18898:	b	18848 <__gmpz_fib_ui@@Base+0x1c0>

000000000001889c <__gmpz_fib2_ui@@Base>:
   1889c:	stp	x29, x30, [sp, #-64]!
   188a0:	stp	x22, x21, [sp, #32]
   188a4:	stp	x20, x19, [sp, #48]
   188a8:	mov	x20, x2
   188ac:	mov	x19, x1
   188b0:	cmp	x2, #0x5d
   188b4:	mov	x21, x0
   188b8:	str	x23, [sp, #16]
   188bc:	mov	x29, sp
   188c0:	b.hi	18918 <__gmpz_fib2_ui@@Base+0x7c>  // b.pmore
   188c4:	adrp	x22, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   188c8:	ldr	x22, [x22, #3808]
   188cc:	ldr	w8, [x21]
   188d0:	add	x9, x22, x20, lsl #3
   188d4:	ldr	x23, [x9, #8]
   188d8:	cmp	w8, #0x0
   188dc:	b.le	1898c <__gmpz_fib2_ui@@Base+0xf0>
   188e0:	ldr	x0, [x21, #8]
   188e4:	cmp	x20, #0x0
   188e8:	cset	w8, ne  // ne = any
   188ec:	str	x23, [x0]
   188f0:	str	w8, [x21, #4]
   188f4:	ldr	w8, [x19]
   188f8:	ldr	x21, [x22, x20, lsl #3]
   188fc:	cmp	w8, #0x0
   18900:	b.le	1899c <__gmpz_fib2_ui@@Base+0x100>
   18904:	ldr	x0, [x19, #8]
   18908:	cmp	x20, #0x1
   1890c:	str	x21, [x0]
   18910:	cset	w8, ne  // ne = any
   18914:	b	18974 <__gmpz_fib2_ui@@Base+0xd8>
   18918:	lsr	x8, x20, #5
   1891c:	mov	w9, #0x17                  	// #23
   18920:	ldrsw	x10, [x21]
   18924:	mul	x8, x8, x9
   18928:	lsr	x8, x8, #6
   1892c:	add	x23, x8, #0x4
   18930:	cmp	x23, x10
   18934:	b.gt	189ac <__gmpz_fib2_ui@@Base+0x110>
   18938:	ldr	x22, [x21, #8]
   1893c:	ldrsw	x8, [x19]
   18940:	cmp	x23, x8
   18944:	b.gt	189c0 <__gmpz_fib2_ui@@Base+0x124>
   18948:	ldr	x23, [x19, #8]
   1894c:	mov	x0, x22
   18950:	mov	x1, x23
   18954:	mov	x2, x20
   18958:	bl	d090 <__gmpn_fib2_ui@plt>
   1895c:	str	w0, [x21, #4]
   18960:	add	x8, x23, x0, lsl #3
   18964:	ldur	x8, [x8, #-8]
   18968:	cmp	x8, #0x0
   1896c:	cset	w8, eq  // eq = none
   18970:	sub	w8, w0, w8
   18974:	str	w8, [x19, #4]
   18978:	ldp	x20, x19, [sp, #48]
   1897c:	ldp	x22, x21, [sp, #32]
   18980:	ldr	x23, [sp, #16]
   18984:	ldp	x29, x30, [sp], #64
   18988:	ret
   1898c:	mov	w1, #0x1                   	// #1
   18990:	mov	x0, x21
   18994:	bl	c090 <__gmpz_realloc@plt>
   18998:	b	188e4 <__gmpz_fib2_ui@@Base+0x48>
   1899c:	mov	w1, #0x1                   	// #1
   189a0:	mov	x0, x19
   189a4:	bl	c090 <__gmpz_realloc@plt>
   189a8:	b	18908 <__gmpz_fib2_ui@@Base+0x6c>
   189ac:	mov	x0, x21
   189b0:	mov	x1, x23
   189b4:	bl	c090 <__gmpz_realloc@plt>
   189b8:	mov	x22, x0
   189bc:	b	1893c <__gmpz_fib2_ui@@Base+0xa0>
   189c0:	mov	x0, x19
   189c4:	mov	x1, x23
   189c8:	bl	c090 <__gmpz_realloc@plt>
   189cc:	mov	x23, x0
   189d0:	b	1894c <__gmpz_fib2_ui@@Base+0xb0>

00000000000189d4 <__gmpz_fits_sint_p@@Base>:
   189d4:	ldr	x8, [x0, #8]
   189d8:	ldr	w9, [x0, #4]
   189dc:	ldr	x8, [x8]
   189e0:	cmn	w9, #0x1
   189e4:	b.eq	18a04 <__gmpz_fits_sint_p@@Base+0x30>  // b.none
   189e8:	cbz	w9, 18a14 <__gmpz_fits_sint_p@@Base+0x40>
   189ec:	cmp	w9, #0x1
   189f0:	b.ne	18a1c <__gmpz_fits_sint_p@@Base+0x48>  // b.any
   189f4:	lsr	x8, x8, #31
   189f8:	cmp	x8, #0x0
   189fc:	cset	w0, eq  // eq = none
   18a00:	ret
   18a04:	mov	w9, #0x80000001            	// #-2147483647
   18a08:	cmp	x8, x9
   18a0c:	cset	w0, cc  // cc = lo, ul, last
   18a10:	ret
   18a14:	mov	w0, #0x1                   	// #1
   18a18:	ret
   18a1c:	mov	w0, wzr
   18a20:	ret

0000000000018a24 <__gmpz_fits_slong_p@@Base>:
   18a24:	ldr	x8, [x0, #8]
   18a28:	ldr	w9, [x0, #4]
   18a2c:	ldr	x8, [x8]
   18a30:	cmn	w9, #0x1
   18a34:	b.eq	18a50 <__gmpz_fits_slong_p@@Base+0x2c>  // b.none
   18a38:	cbz	w9, 18a60 <__gmpz_fits_slong_p@@Base+0x3c>
   18a3c:	cmp	w9, #0x1
   18a40:	b.ne	18a68 <__gmpz_fits_slong_p@@Base+0x44>  // b.any
   18a44:	lsr	x8, x8, #63
   18a48:	eor	w0, w8, #0x1
   18a4c:	ret
   18a50:	mov	x9, #0x8000000000000001    	// #-9223372036854775807
   18a54:	cmp	x8, x9
   18a58:	cset	w0, cc  // cc = lo, ul, last
   18a5c:	ret
   18a60:	mov	w0, #0x1                   	// #1
   18a64:	ret
   18a68:	mov	w0, wzr
   18a6c:	ret

0000000000018a70 <__gmpz_fits_sshort_p@@Base>:
   18a70:	ldr	x8, [x0, #8]
   18a74:	ldr	w9, [x0, #4]
   18a78:	ldr	x8, [x8]
   18a7c:	cmn	w9, #0x1
   18a80:	b.eq	18a9c <__gmpz_fits_sshort_p@@Base+0x2c>  // b.none
   18a84:	cbz	w9, 18aa8 <__gmpz_fits_sshort_p@@Base+0x38>
   18a88:	cmp	w9, #0x1
   18a8c:	b.ne	18ab0 <__gmpz_fits_sshort_p@@Base+0x40>  // b.any
   18a90:	cmp	x8, #0x8, lsl #12
   18a94:	cset	w0, cc  // cc = lo, ul, last
   18a98:	ret
   18a9c:	cmp	x8, #0x8, lsl #12
   18aa0:	cset	w0, ls  // ls = plast
   18aa4:	ret
   18aa8:	mov	w0, #0x1                   	// #1
   18aac:	ret
   18ab0:	mov	w0, wzr
   18ab4:	ret

0000000000018ab8 <__gmpz_fits_uint_p@@Base>:
   18ab8:	ldr	w8, [x0, #4]
   18abc:	cbz	w8, 18adc <__gmpz_fits_uint_p@@Base+0x24>
   18ac0:	cmp	w8, #0x1
   18ac4:	b.ne	18ae4 <__gmpz_fits_uint_p@@Base+0x2c>  // b.any
   18ac8:	ldr	x8, [x0, #8]
   18acc:	ldr	w8, [x8, #4]
   18ad0:	cmp	w8, #0x0
   18ad4:	cset	w0, eq  // eq = none
   18ad8:	ret
   18adc:	mov	w0, #0x1                   	// #1
   18ae0:	ret
   18ae4:	mov	w0, wzr
   18ae8:	ret

0000000000018aec <__gmpz_fits_ulong_p@@Base>:
   18aec:	ldr	w8, [x0, #4]
   18af0:	cmp	w8, #0x2
   18af4:	cset	w0, cc  // cc = lo, ul, last
   18af8:	ret

0000000000018afc <__gmpz_fits_ushort_p@@Base>:
   18afc:	ldr	w8, [x0, #4]
   18b00:	cbz	w8, 18b20 <__gmpz_fits_ushort_p@@Base+0x24>
   18b04:	cmp	w8, #0x1
   18b08:	b.ne	18b28 <__gmpz_fits_ushort_p@@Base+0x2c>  // b.any
   18b0c:	ldr	x8, [x0, #8]
   18b10:	ldr	x8, [x8]
   18b14:	cmp	x8, #0x10, lsl #12
   18b18:	cset	w0, cc  // cc = lo, ul, last
   18b1c:	ret
   18b20:	mov	w0, #0x1                   	// #1
   18b24:	ret
   18b28:	mov	w0, wzr
   18b2c:	ret

0000000000018b30 <__gmpz_gcd@@Base>:
   18b30:	stp	x29, x30, [sp, #-96]!
   18b34:	stp	x26, x25, [sp, #32]
   18b38:	stp	x24, x23, [sp, #48]
   18b3c:	stp	x22, x21, [sp, #64]
   18b40:	stp	x20, x19, [sp, #80]
   18b44:	ldr	w8, [x1, #4]
   18b48:	ldr	w9, [x2, #4]
   18b4c:	ldr	x20, [x2, #8]
   18b50:	mov	x19, x0
   18b54:	cmp	w8, #0x0
   18b58:	cneg	w21, w8, mi  // mi = first
   18b5c:	cmp	w9, #0x0
   18b60:	cneg	w22, w9, mi  // mi = first
   18b64:	str	x27, [sp, #16]
   18b68:	mov	x29, sp
   18b6c:	cbz	w21, 18b98 <__gmpz_gcd@@Base+0x68>
   18b70:	ldr	x23, [x1, #8]
   18b74:	cbz	w22, 18bc0 <__gmpz_gcd@@Base+0x90>
   18b78:	cmp	w21, #0x1
   18b7c:	b.ne	18bec <__gmpz_gcd@@Base+0xbc>  // b.any
   18b80:	mov	w8, #0x1                   	// #1
   18b84:	str	w8, [x19, #4]
   18b88:	ldr	x2, [x23]
   18b8c:	mov	x0, x20
   18b90:	mov	x1, x22
   18b94:	b	18c08 <__gmpz_gcd@@Base+0xd8>
   18b98:	cmp	x19, x2
   18b9c:	str	w22, [x19, #4]
   18ba0:	b.eq	18e3c <__gmpz_gcd@@Base+0x30c>  // b.none
   18ba4:	ldrsw	x8, [x19]
   18ba8:	cmp	x22, x8
   18bac:	b.gt	18e6c <__gmpz_gcd@@Base+0x33c>
   18bb0:	ldr	x0, [x19, #8]
   18bb4:	mov	x1, x20
   18bb8:	mov	x2, x22
   18bbc:	b	18be4 <__gmpz_gcd@@Base+0xb4>
   18bc0:	cmp	x19, x1
   18bc4:	str	w21, [x19, #4]
   18bc8:	b.eq	18e3c <__gmpz_gcd@@Base+0x30c>  // b.none
   18bcc:	ldrsw	x8, [x19]
   18bd0:	cmp	x21, x8
   18bd4:	b.gt	18e7c <__gmpz_gcd@@Base+0x34c>
   18bd8:	ldr	x0, [x19, #8]
   18bdc:	mov	x1, x23
   18be0:	mov	x2, x21
   18be4:	bl	ca70 <__gmpn_copyi@plt>
   18be8:	b	18e3c <__gmpz_gcd@@Base+0x30c>
   18bec:	cmp	w22, #0x1
   18bf0:	b.ne	18c28 <__gmpz_gcd@@Base+0xf8>  // b.any
   18bf4:	mov	w8, #0x1                   	// #1
   18bf8:	str	w8, [x19, #4]
   18bfc:	ldr	x2, [x20]
   18c00:	mov	x0, x23
   18c04:	mov	x1, x21
   18c08:	bl	bfa0 <__gmpn_gcd_1@plt>
   18c0c:	ldr	w8, [x19]
   18c10:	mov	x20, x0
   18c14:	cmp	w8, #0x0
   18c18:	b.le	18e5c <__gmpz_gcd@@Base+0x32c>
   18c1c:	ldr	x0, [x19, #8]
   18c20:	str	x20, [x0]
   18c24:	b	18e3c <__gmpz_gcd@@Base+0x30c>
   18c28:	sub	x25, x23, #0x8
   18c2c:	str	xzr, [x29, #24]
   18c30:	ldr	x8, [x25, #8]!
   18c34:	cbz	x8, 18c30 <__gmpz_gcd@@Base+0x100>
   18c38:	sub	x26, x25, x23
   18c3c:	sub	x21, x21, x26, asr #3
   18c40:	rbit	x8, x8
   18c44:	lsl	x1, x21, #3
   18c48:	mov	w9, #0x7f00                	// #32512
   18c4c:	cmp	x1, x9
   18c50:	clz	x24, x8
   18c54:	b.hi	18e8c <__gmpz_gcd@@Base+0x35c>  // b.pmore
   18c58:	add	x9, x1, #0xf
   18c5c:	mov	x8, sp
   18c60:	and	x9, x9, #0xfffffffffffffff0
   18c64:	sub	x23, x8, x9
   18c68:	mov	sp, x23
   18c6c:	asr	x27, x26, #3
   18c70:	mov	x0, x23
   18c74:	mov	x1, x25
   18c78:	mov	x2, x21
   18c7c:	cbz	x24, 18ca0 <__gmpz_gcd@@Base+0x170>
   18c80:	mov	w3, w24
   18c84:	bl	c1b0 <__gmpn_rshift@plt>
   18c88:	add	x8, x23, x21, lsl #3
   18c8c:	ldur	x8, [x8, #-8]
   18c90:	cmp	x8, #0x0
   18c94:	cset	w8, eq  // eq = none
   18c98:	sub	x21, x21, x8
   18c9c:	b	18ca4 <__gmpz_gcd@@Base+0x174>
   18ca0:	bl	ca70 <__gmpn_copyi@plt>
   18ca4:	sub	x1, x20, #0x8
   18ca8:	ldr	x8, [x1, #8]!
   18cac:	cbz	x8, 18ca8 <__gmpz_gcd@@Base+0x178>
   18cb0:	sub	x26, x1, x20
   18cb4:	sub	x25, x22, x26, asr #3
   18cb8:	rbit	x9, x8
   18cbc:	lsl	x8, x25, #3
   18cc0:	mov	w10, #0x7f00                	// #32512
   18cc4:	cmp	x8, x10
   18cc8:	clz	x22, x9
   18ccc:	b.hi	18e9c <__gmpz_gcd@@Base+0x36c>  // b.pmore
   18cd0:	add	x8, x8, #0xf
   18cd4:	mov	x9, sp
   18cd8:	and	x8, x8, #0xfffffffffffffff0
   18cdc:	sub	x20, x9, x8
   18ce0:	mov	sp, x20
   18ce4:	asr	x26, x26, #3
   18ce8:	mov	x0, x20
   18cec:	mov	x2, x25
   18cf0:	cbz	x22, 18d14 <__gmpz_gcd@@Base+0x1e4>
   18cf4:	mov	w3, w22
   18cf8:	bl	c1b0 <__gmpn_rshift@plt>
   18cfc:	add	x8, x20, x25, lsl #3
   18d00:	ldur	x8, [x8, #-8]
   18d04:	cmp	x8, #0x0
   18d08:	cset	w8, eq  // eq = none
   18d0c:	sub	x25, x25, x8
   18d10:	b	18d18 <__gmpz_gcd@@Base+0x1e8>
   18d14:	bl	ca70 <__gmpn_copyi@plt>
   18d18:	cmp	x27, x26
   18d1c:	b.gt	18d3c <__gmpz_gcd@@Base+0x20c>
   18d20:	b.ge	18d30 <__gmpz_gcd@@Base+0x200>  // b.tcont
   18d24:	mov	x26, x27
   18d28:	mov	x22, x24
   18d2c:	b	18d3c <__gmpz_gcd@@Base+0x20c>
   18d30:	cmp	x24, x22
   18d34:	csel	x22, x24, x22, cc  // cc = lo, ul, last
   18d38:	mov	x26, x27
   18d3c:	cmp	x21, x25
   18d40:	b.lt	18d60 <__gmpz_gcd@@Base+0x230>  // b.tstop
   18d44:	b.ne	18d78 <__gmpz_gcd@@Base+0x248>  // b.any
   18d48:	lsl	x8, x21, #3
   18d4c:	sub	x8, x8, #0x8
   18d50:	ldr	x9, [x23, x8]
   18d54:	ldr	x8, [x20, x8]
   18d58:	cmp	x9, x8
   18d5c:	b.cs	18d78 <__gmpz_gcd@@Base+0x248>  // b.hs, b.nlast
   18d60:	mov	x0, x20
   18d64:	mov	x1, x20
   18d68:	mov	x2, x25
   18d6c:	mov	x3, x23
   18d70:	mov	x4, x21
   18d74:	b	18d8c <__gmpz_gcd@@Base+0x25c>
   18d78:	mov	x0, x20
   18d7c:	mov	x1, x23
   18d80:	mov	x2, x21
   18d84:	mov	x3, x20
   18d88:	mov	x4, x25
   18d8c:	bl	cc30 <__gmpn_gcd@plt>
   18d90:	mov	x23, x0
   18d94:	add	x21, x0, x26
   18d98:	cbz	x22, 18dfc <__gmpz_gcd@@Base+0x2cc>
   18d9c:	add	x8, x20, x23, lsl #3
   18da0:	ldur	x8, [x8, #-8]
   18da4:	neg	x9, x22
   18da8:	ldrsw	x10, [x19]
   18dac:	lsr	x8, x8, x9
   18db0:	cmp	x8, #0x0
   18db4:	cinc	x21, x21, ne  // ne = any
   18db8:	cmp	x21, x10
   18dbc:	b.gt	18ec0 <__gmpz_gcd@@Base+0x390>
   18dc0:	ldr	x24, [x19, #8]
   18dc4:	cbz	x26, 18dd8 <__gmpz_gcd@@Base+0x2a8>
   18dc8:	lsl	x2, x26, #3
   18dcc:	mov	x0, x24
   18dd0:	mov	w1, wzr
   18dd4:	bl	c610 <memset@plt>
   18dd8:	add	x24, x24, x26, lsl #3
   18ddc:	mov	x0, x24
   18de0:	mov	x1, x20
   18de4:	mov	x2, x23
   18de8:	mov	w3, w22
   18dec:	bl	c190 <__gmpn_lshift@plt>
   18df0:	cbz	x0, 18e30 <__gmpz_gcd@@Base+0x300>
   18df4:	str	x0, [x24, x23, lsl #3]
   18df8:	b	18e30 <__gmpz_gcd@@Base+0x300>
   18dfc:	ldrsw	x8, [x19]
   18e00:	cmp	x21, x8
   18e04:	b.gt	18ed8 <__gmpz_gcd@@Base+0x3a8>
   18e08:	ldr	x22, [x19, #8]
   18e0c:	cbz	x26, 18e20 <__gmpz_gcd@@Base+0x2f0>
   18e10:	lsl	x2, x26, #3
   18e14:	mov	x0, x22
   18e18:	mov	w1, wzr
   18e1c:	bl	c610 <memset@plt>
   18e20:	add	x0, x22, x26, lsl #3
   18e24:	mov	x1, x20
   18e28:	mov	x2, x23
   18e2c:	bl	ca70 <__gmpn_copyi@plt>
   18e30:	str	w21, [x19, #4]
   18e34:	ldr	x0, [x29, #24]
   18e38:	cbnz	x0, 18eb8 <__gmpz_gcd@@Base+0x388>
   18e3c:	mov	sp, x29
   18e40:	ldp	x20, x19, [sp, #80]
   18e44:	ldp	x22, x21, [sp, #64]
   18e48:	ldp	x24, x23, [sp, #48]
   18e4c:	ldp	x26, x25, [sp, #32]
   18e50:	ldr	x27, [sp, #16]
   18e54:	ldp	x29, x30, [sp], #96
   18e58:	ret
   18e5c:	mov	w1, #0x1                   	// #1
   18e60:	mov	x0, x19
   18e64:	bl	c090 <__gmpz_realloc@plt>
   18e68:	b	18c20 <__gmpz_gcd@@Base+0xf0>
   18e6c:	mov	x0, x19
   18e70:	mov	x1, x22
   18e74:	bl	c090 <__gmpz_realloc@plt>
   18e78:	b	18bb4 <__gmpz_gcd@@Base+0x84>
   18e7c:	mov	x0, x19
   18e80:	mov	x1, x21
   18e84:	bl	c090 <__gmpz_realloc@plt>
   18e88:	b	18bdc <__gmpz_gcd@@Base+0xac>
   18e8c:	add	x0, x29, #0x18
   18e90:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   18e94:	mov	x23, x0
   18e98:	b	18c6c <__gmpz_gcd@@Base+0x13c>
   18e9c:	add	x0, x29, #0x18
   18ea0:	mov	x20, x1
   18ea4:	mov	x1, x8
   18ea8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   18eac:	mov	x1, x20
   18eb0:	mov	x20, x0
   18eb4:	b	18ce4 <__gmpz_gcd@@Base+0x1b4>
   18eb8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   18ebc:	b	18e3c <__gmpz_gcd@@Base+0x30c>
   18ec0:	mov	x0, x19
   18ec4:	mov	x1, x21
   18ec8:	bl	c090 <__gmpz_realloc@plt>
   18ecc:	mov	x24, x0
   18ed0:	cbnz	x26, 18dc8 <__gmpz_gcd@@Base+0x298>
   18ed4:	b	18dd8 <__gmpz_gcd@@Base+0x2a8>
   18ed8:	mov	x0, x19
   18edc:	mov	x1, x21
   18ee0:	bl	c090 <__gmpz_realloc@plt>
   18ee4:	mov	x22, x0
   18ee8:	cbnz	x26, 18e10 <__gmpz_gcd@@Base+0x2e0>
   18eec:	b	18e20 <__gmpz_gcd@@Base+0x2f0>

0000000000018ef0 <__gmpz_gcd_ui@@Base>:
   18ef0:	stp	x29, x30, [sp, #-48]!
   18ef4:	stp	x22, x21, [sp, #16]
   18ef8:	stp	x20, x19, [sp, #32]
   18efc:	ldr	w8, [x1, #4]
   18f00:	mov	x20, x2
   18f04:	mov	x19, x0
   18f08:	mov	x29, sp
   18f0c:	cmp	w8, #0x0
   18f10:	cneg	w21, w8, mi  // mi = first
   18f14:	cbz	w21, 18f34 <__gmpz_gcd_ui@@Base+0x44>
   18f18:	mov	x22, x1
   18f1c:	cbz	x20, 18f5c <__gmpz_gcd_ui@@Base+0x6c>
   18f20:	ldr	x0, [x22, #8]
   18f24:	mov	x1, x21
   18f28:	mov	x2, x20
   18f2c:	bl	bfa0 <__gmpn_gcd_1@plt>
   18f30:	mov	x20, x0
   18f34:	cbz	x19, 18f98 <__gmpz_gcd_ui@@Base+0xa8>
   18f38:	ldr	w8, [x19]
   18f3c:	cmp	w8, #0x0
   18f40:	b.le	18fac <__gmpz_gcd_ui@@Base+0xbc>
   18f44:	ldr	x0, [x19, #8]
   18f48:	cmp	x20, #0x0
   18f4c:	cset	w8, ne  // ne = any
   18f50:	str	x20, [x0]
   18f54:	str	w8, [x19, #4]
   18f58:	b	18f98 <__gmpz_gcd_ui@@Base+0xa8>
   18f5c:	cbz	x19, 18f88 <__gmpz_gcd_ui@@Base+0x98>
   18f60:	cmp	x22, x19
   18f64:	b.eq	18f84 <__gmpz_gcd_ui@@Base+0x94>  // b.none
   18f68:	ldrsw	x8, [x19]
   18f6c:	cmp	x21, x8
   18f70:	b.gt	18fbc <__gmpz_gcd_ui@@Base+0xcc>
   18f74:	ldr	x0, [x19, #8]
   18f78:	ldr	x1, [x22, #8]
   18f7c:	mov	x2, x21
   18f80:	bl	ca70 <__gmpn_copyi@plt>
   18f84:	str	w21, [x19, #4]
   18f88:	ldr	x8, [x22, #8]
   18f8c:	cmp	w21, #0x1
   18f90:	ldr	x8, [x8]
   18f94:	csel	x20, x8, xzr, eq  // eq = none
   18f98:	mov	x0, x20
   18f9c:	ldp	x20, x19, [sp, #32]
   18fa0:	ldp	x22, x21, [sp, #16]
   18fa4:	ldp	x29, x30, [sp], #48
   18fa8:	ret
   18fac:	mov	w1, #0x1                   	// #1
   18fb0:	mov	x0, x19
   18fb4:	bl	c090 <__gmpz_realloc@plt>
   18fb8:	b	18f48 <__gmpz_gcd_ui@@Base+0x58>
   18fbc:	mov	x0, x19
   18fc0:	mov	x1, x21
   18fc4:	bl	c090 <__gmpz_realloc@plt>
   18fc8:	b	18f74 <__gmpz_gcd_ui@@Base+0x84>

0000000000018fcc <__gmpz_gcdext@@Base>:
   18fcc:	stp	x29, x30, [sp, #-96]!
   18fd0:	stp	x28, x27, [sp, #16]
   18fd4:	stp	x26, x25, [sp, #32]
   18fd8:	stp	x24, x23, [sp, #48]
   18fdc:	stp	x22, x21, [sp, #64]
   18fe0:	stp	x20, x19, [sp, #80]
   18fe4:	mov	x29, sp
   18fe8:	sub	sp, sp, #0x50
   18fec:	ldr	w8, [x3, #4]
   18ff0:	ldr	w9, [x4, #4]
   18ff4:	mov	x19, x0
   18ff8:	cmp	w8, #0x0
   18ffc:	cneg	w8, w8, mi  // mi = first
   19000:	cmp	w9, #0x0
   19004:	cneg	w9, w9, mi  // mi = first
   19008:	cmp	w8, w9
   1900c:	csel	w26, w8, w9, cc  // cc = lo, ul, last
   19010:	csel	w23, w9, w8, cc  // cc = lo, ul, last
   19014:	csel	x21, x3, x4, cc  // cc = lo, ul, last
   19018:	csel	x24, x4, x3, cc  // cc = lo, ul, last
   1901c:	csel	x25, x1, x2, cc  // cc = lo, ul, last
   19020:	csel	x20, x2, x1, cc  // cc = lo, ul, last
   19024:	cbz	w26, 19184 <__gmpz_gcdext@@Base+0x1b8>
   19028:	add	x8, x26, x26, lsl #1
   1902c:	add	x8, x23, x8
   19030:	add	x8, x8, #0x1
   19034:	cmp	x8, #0xfe0
   19038:	lsl	x1, x8, #3
   1903c:	stur	xzr, [x29, #-16]
   19040:	stur	x25, [x29, #-72]
   19044:	b.hi	19204 <__gmpz_gcdext@@Base+0x238>  // b.pmore
   19048:	add	x9, x1, #0xf
   1904c:	mov	x8, sp
   19050:	and	x9, x9, #0xfffffffff0
   19054:	sub	x22, x8, x9
   19058:	mov	sp, x22
   1905c:	add	x27, x22, x26, lsl #3
   19060:	ldr	x1, [x24, #8]
   19064:	add	x8, x27, x26, lsl #3
   19068:	add	x28, x8, #0x8
   1906c:	add	x25, x28, x26, lsl #3
   19070:	mov	x0, x25
   19074:	mov	x2, x23
   19078:	bl	ca70 <__gmpn_copyi@plt>
   1907c:	ldr	x1, [x21, #8]
   19080:	mov	x0, x28
   19084:	mov	x2, x26
   19088:	bl	ca70 <__gmpn_copyi@plt>
   1908c:	sub	x2, x29, #0x8
   19090:	mov	x0, x22
   19094:	mov	x1, x27
   19098:	mov	x3, x25
   1909c:	mov	x4, x23
   190a0:	mov	x5, x28
   190a4:	mov	x6, x26
   190a8:	bl	c580 <__gmpn_gcdext@plt>
   190ac:	ldur	x8, [x29, #-8]
   190b0:	ldr	w9, [x24, #4]
   190b4:	ldur	x25, [x29, #-72]
   190b8:	mov	x26, x0
   190bc:	cmp	x8, #0x0
   190c0:	cneg	x28, x8, mi  // mi = first
   190c4:	cmp	w9, #0x0
   190c8:	cneg	x8, x8, lt  // lt = tstop
   190cc:	stur	x8, [x29, #-8]
   190d0:	cbz	x25, 19128 <__gmpz_gcdext@@Base+0x15c>
   190d4:	stur	w8, [x29, #-60]
   190d8:	add	x8, x27, x28, lsl #3
   190dc:	add	w9, w23, w28
   190e0:	stur	x8, [x29, #-24]
   190e4:	add	w8, w9, #0x1
   190e8:	sub	x0, x29, #0x20
   190ec:	sub	x1, x29, #0x40
   190f0:	mov	x2, x24
   190f4:	stur	x22, [x29, #-40]
   190f8:	stur	w26, [x29, #-44]
   190fc:	stur	x27, [x29, #-56]
   19100:	stur	w8, [x29, #-32]
   19104:	bl	c4d0 <__gmpz_mul@plt>
   19108:	sub	x0, x29, #0x20
   1910c:	sub	x1, x29, #0x30
   19110:	sub	x2, x29, #0x20
   19114:	bl	c270 <__gmpz_sub@plt>
   19118:	sub	x1, x29, #0x20
   1911c:	mov	x0, x25
   19120:	mov	x2, x21
   19124:	bl	c410 <__gmpz_divexact@plt>
   19128:	cbz	x20, 19150 <__gmpz_gcdext@@Base+0x184>
   1912c:	ldrsw	x8, [x20]
   19130:	cmp	x28, x8
   19134:	b.gt	19214 <__gmpz_gcdext@@Base+0x248>
   19138:	ldr	x0, [x20, #8]
   1913c:	mov	x1, x27
   19140:	mov	x2, x28
   19144:	bl	ca70 <__gmpn_copyi@plt>
   19148:	ldur	x8, [x29, #-8]
   1914c:	str	w8, [x20, #4]
   19150:	cbz	x19, 19174 <__gmpz_gcdext@@Base+0x1a8>
   19154:	ldrsw	x8, [x19]
   19158:	cmp	x26, x8
   1915c:	b.gt	19224 <__gmpz_gcdext@@Base+0x258>
   19160:	ldr	x0, [x19, #8]
   19164:	mov	x1, x22
   19168:	mov	x2, x26
   1916c:	bl	ca70 <__gmpn_copyi@plt>
   19170:	str	w26, [x19, #4]
   19174:	ldur	x0, [x29, #-16]
   19178:	cbz	x0, 191e4 <__gmpz_gcdext@@Base+0x218>
   1917c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   19180:	b	191e4 <__gmpz_gcdext@@Base+0x218>
   19184:	ldr	w8, [x24, #4]
   19188:	cmp	w23, #0x0
   1918c:	cset	w9, ne  // ne = any
   19190:	cmp	w8, #0x0
   19194:	csinv	w22, w9, wzr, ge  // ge = tcont
   19198:	cbz	x19, 191bc <__gmpz_gcdext@@Base+0x1f0>
   1919c:	ldrsw	x8, [x19]
   191a0:	cmp	x23, x8
   191a4:	b.gt	19234 <__gmpz_gcdext@@Base+0x268>
   191a8:	ldr	x0, [x19, #8]
   191ac:	ldr	x1, [x24, #8]
   191b0:	mov	x2, x23
   191b4:	bl	ca70 <__gmpn_copyi@plt>
   191b8:	str	w23, [x19, #4]
   191bc:	cbz	x25, 191c4 <__gmpz_gcdext@@Base+0x1f8>
   191c0:	str	wzr, [x25, #4]
   191c4:	cbz	x20, 191e4 <__gmpz_gcdext@@Base+0x218>
   191c8:	ldr	w8, [x20]
   191cc:	str	w22, [x20, #4]
   191d0:	cmp	w8, #0x0
   191d4:	b.le	19244 <__gmpz_gcdext@@Base+0x278>
   191d8:	ldr	x0, [x20, #8]
   191dc:	mov	w8, #0x1                   	// #1
   191e0:	str	x8, [x0]
   191e4:	mov	sp, x29
   191e8:	ldp	x20, x19, [sp, #80]
   191ec:	ldp	x22, x21, [sp, #64]
   191f0:	ldp	x24, x23, [sp, #48]
   191f4:	ldp	x26, x25, [sp, #32]
   191f8:	ldp	x28, x27, [sp, #16]
   191fc:	ldp	x29, x30, [sp], #96
   19200:	ret
   19204:	sub	x0, x29, #0x10
   19208:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1920c:	mov	x22, x0
   19210:	b	1905c <__gmpz_gcdext@@Base+0x90>
   19214:	mov	x0, x20
   19218:	mov	x1, x28
   1921c:	bl	c090 <__gmpz_realloc@plt>
   19220:	b	1913c <__gmpz_gcdext@@Base+0x170>
   19224:	mov	x0, x19
   19228:	mov	x1, x26
   1922c:	bl	c090 <__gmpz_realloc@plt>
   19230:	b	19164 <__gmpz_gcdext@@Base+0x198>
   19234:	mov	x0, x19
   19238:	mov	x1, x23
   1923c:	bl	c090 <__gmpz_realloc@plt>
   19240:	b	191ac <__gmpz_gcdext@@Base+0x1e0>
   19244:	mov	w1, #0x1                   	// #1
   19248:	mov	x0, x20
   1924c:	bl	c090 <__gmpz_realloc@plt>
   19250:	b	191dc <__gmpz_gcdext@@Base+0x210>

0000000000019254 <__gmpz_get_d@@Base>:
   19254:	ldrsw	x2, [x0, #4]
   19258:	cbz	w2, 19270 <__gmpz_get_d@@Base+0x1c>
   1925c:	ldr	x0, [x0, #8]
   19260:	cmp	x2, #0x0
   19264:	cneg	x1, x2, mi  // mi = first
   19268:	mov	x3, xzr
   1926c:	b	bf50 <__gmpn_get_d@plt>
   19270:	fmov	d0, xzr
   19274:	ret

0000000000019278 <__gmpz_get_d_2exp@@Base>:
   19278:	ldrsw	x2, [x1, #4]
   1927c:	cbz	w2, 192b0 <__gmpz_get_d_2exp@@Base+0x38>
   19280:	ldr	x8, [x1, #8]
   19284:	cmp	x2, #0x0
   19288:	cneg	x1, x2, mi  // mi = first
   1928c:	lsl	x10, x1, #6
   19290:	add	x9, x8, x1, lsl #3
   19294:	ldur	x9, [x9, #-8]
   19298:	clz	x9, x9
   1929c:	sub	x9, x10, x9
   192a0:	neg	x3, x9
   192a4:	str	x9, [x0]
   192a8:	mov	x0, x8
   192ac:	b	bf50 <__gmpn_get_d@plt>
   192b0:	fmov	d0, xzr
   192b4:	str	xzr, [x0]
   192b8:	ret

00000000000192bc <__gmpz_get_si@@Base>:
   192bc:	ldr	x8, [x0, #8]
   192c0:	ldr	w9, [x0, #4]
   192c4:	ldr	x8, [x8]
   192c8:	cmp	w9, #0x1
   192cc:	b.lt	192d8 <__gmpz_get_si@@Base+0x1c>  // b.tstop
   192d0:	and	x0, x8, #0x7fffffffffffffff
   192d4:	ret
   192d8:	tbnz	w9, #31, 192e4 <__gmpz_get_si@@Base+0x28>
   192dc:	mov	x0, xzr
   192e0:	ret
   192e4:	sub	x8, x8, #0x1
   192e8:	orr	x8, x8, #0x8000000000000000
   192ec:	eor	x0, x8, #0x7fffffffffffffff
   192f0:	ret

00000000000192f4 <__gmpz_get_str@@Base>:
   192f4:	stp	x29, x30, [sp, #-80]!
   192f8:	stp	x24, x23, [sp, #32]
   192fc:	stp	x22, x21, [sp, #48]
   19300:	stp	x20, x19, [sp, #64]
   19304:	ldrsw	x20, [x2, #4]
   19308:	mov	x22, x2
   1930c:	mov	w21, w1
   19310:	cmp	w1, #0x2
   19314:	mov	x19, x0
   19318:	str	x25, [sp, #16]
   1931c:	mov	x29, sp
   19320:	b.lt	19390 <__gmpz_get_str@@Base+0x9c>  // b.tstop
   19324:	cmp	w21, #0x25
   19328:	b.ge	193a0 <__gmpz_get_str@@Base+0xac>  // b.tcont
   1932c:	adrp	x25, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
   19330:	add	x25, x25, #0xded
   19334:	cbnz	x19, 193c4 <__gmpz_get_str@@Base+0xd0>
   19338:	cmp	x20, #0x0
   1933c:	cneg	x8, x20, mi  // mi = first
   19340:	cbz	x8, 193cc <__gmpz_get_str@@Base+0xd8>
   19344:	ldr	x9, [x22, #8]
   19348:	adrp	x11, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1934c:	sub	w10, w21, #0x1
   19350:	tst	w21, w10
   19354:	add	x9, x9, x8, lsl #3
   19358:	ldur	x9, [x9, #-8]
   1935c:	ldr	x11, [x11, #3936]
   19360:	lsl	x8, x8, #6
   19364:	mov	w10, #0x28                  	// #40
   19368:	clz	x9, x9
   1936c:	sub	x8, x8, x9
   19370:	mov	w9, w21
   19374:	madd	x9, x9, x10, x11
   19378:	b.ne	193d4 <__gmpz_get_str@@Base+0xe0>  // b.any
   1937c:	ldrsw	x9, [x9, #24]
   19380:	add	x8, x8, x9
   19384:	sub	x8, x8, #0x1
   19388:	udiv	x8, x8, x9
   1938c:	b	193e4 <__gmpz_get_str@@Base+0xf0>
   19390:	cmn	w21, #0x2
   19394:	b.le	193ac <__gmpz_get_str@@Base+0xb8>
   19398:	mov	w21, #0xa                   	// #10
   1939c:	b	193b8 <__gmpz_get_str@@Base+0xc4>
   193a0:	cmp	w21, #0x3e
   193a4:	b.le	193b8 <__gmpz_get_str@@Base+0xc4>
   193a8:	b	19510 <__gmpz_get_str@@Base+0x21c>
   193ac:	cmn	w21, #0x24
   193b0:	b.lt	19510 <__gmpz_get_str@@Base+0x21c>  // b.tstop
   193b4:	neg	w21, w21
   193b8:	adrp	x25, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
   193bc:	add	x25, x25, #0xdae
   193c0:	cbz	x19, 19338 <__gmpz_get_str@@Base+0x44>
   193c4:	mov	x23, xzr
   193c8:	b	19408 <__gmpz_get_str@@Base+0x114>
   193cc:	mov	w8, #0x1                   	// #1
   193d0:	b	193e4 <__gmpz_get_str@@Base+0xf0>
   193d4:	ldr	x9, [x9, #8]
   193d8:	add	x9, x9, #0x1
   193dc:	umulh	x8, x9, x8
   193e0:	add	x8, x8, #0x1
   193e4:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   193e8:	ldr	x9, [x9, #3840]
   193ec:	ubfx	x10, x20, #31, #1
   193f0:	add	w10, w10, #0x1
   193f4:	add	x23, x8, x10
   193f8:	ldr	x9, [x9]
   193fc:	mov	x0, x23
   19400:	blr	x9
   19404:	mov	x19, x0
   19408:	mov	x24, x19
   1940c:	tbz	w20, #31, 19420 <__gmpz_get_str@@Base+0x12c>
   19410:	mov	w8, #0x2d                  	// #45
   19414:	mov	x24, x19
   19418:	strb	w8, [x24], #1
   1941c:	neg	x20, x20
   19420:	str	xzr, [x29, #24]
   19424:	ldr	x2, [x22, #8]
   19428:	sub	w8, w21, #0x1
   1942c:	tst	w21, w8
   19430:	b.eq	19470 <__gmpz_get_str@@Base+0x17c>  // b.none
   19434:	lsl	x8, x20, #3
   19438:	orr	x1, x8, #0x8
   1943c:	mov	w8, #0x7f00                	// #32512
   19440:	cmp	x1, x8
   19444:	b.hi	19518 <__gmpz_get_str@@Base+0x224>  // b.pmore
   19448:	add	x9, x1, #0xf
   1944c:	mov	x8, sp
   19450:	and	x9, x9, #0xfffffffffffffff0
   19454:	sub	x22, x8, x9
   19458:	mov	sp, x22
   1945c:	mov	x0, x22
   19460:	mov	x1, x2
   19464:	mov	x2, x20
   19468:	bl	ca70 <__gmpn_copyi@plt>
   1946c:	mov	x2, x22
   19470:	mov	x0, x24
   19474:	mov	w1, w21
   19478:	mov	x3, x20
   1947c:	bl	cab0 <__gmpn_get_str@plt>
   19480:	mov	x20, x0
   19484:	cbz	x0, 194a4 <__gmpz_get_str@@Base+0x1b0>
   19488:	mov	x8, x20
   1948c:	mov	x9, x24
   19490:	ldrb	w10, [x9]
   19494:	subs	x8, x8, #0x1
   19498:	ldrb	w10, [x25, x10]
   1949c:	strb	w10, [x9], #1
   194a0:	b.ne	19490 <__gmpz_get_str@@Base+0x19c>  // b.any
   194a4:	strb	wzr, [x24, x20]
   194a8:	ldr	x0, [x29, #24]
   194ac:	cbnz	x0, 19504 <__gmpz_get_str@@Base+0x210>
   194b0:	cbz	x23, 194e4 <__gmpz_get_str@@Base+0x1f0>
   194b4:	sub	x8, x24, x19
   194b8:	add	x8, x8, x20
   194bc:	add	x2, x8, #0x1
   194c0:	cmp	x23, x2
   194c4:	b.eq	194e4 <__gmpz_get_str@@Base+0x1f0>  // b.none
   194c8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   194cc:	ldr	x8, [x8, #3792]
   194d0:	mov	x0, x19
   194d4:	mov	x1, x23
   194d8:	ldr	x8, [x8]
   194dc:	blr	x8
   194e0:	mov	x19, x0
   194e4:	mov	x0, x19
   194e8:	mov	sp, x29
   194ec:	ldp	x20, x19, [sp, #64]
   194f0:	ldp	x22, x21, [sp, #48]
   194f4:	ldp	x24, x23, [sp, #32]
   194f8:	ldr	x25, [sp, #16]
   194fc:	ldp	x29, x30, [sp], #80
   19500:	ret
   19504:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   19508:	cbnz	x23, 194b4 <__gmpz_get_str@@Base+0x1c0>
   1950c:	b	194e4 <__gmpz_get_str@@Base+0x1f0>
   19510:	mov	x19, xzr
   19514:	b	194e4 <__gmpz_get_str@@Base+0x1f0>
   19518:	add	x0, x29, #0x18
   1951c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   19520:	ldr	x2, [x22, #8]
   19524:	mov	x22, x0
   19528:	b	1945c <__gmpz_get_str@@Base+0x168>

000000000001952c <__gmpz_get_ui@@Base>:
   1952c:	ldr	x8, [x0, #8]
   19530:	ldr	w9, [x0, #4]
   19534:	ldr	x8, [x8]
   19538:	cmp	w9, #0x0
   1953c:	csel	x0, xzr, x8, eq  // eq = none
   19540:	ret

0000000000019544 <__gmpz_getlimbn@@Base>:
   19544:	tbnz	x1, #63, 19568 <__gmpz_getlimbn@@Base+0x24>
   19548:	ldr	w8, [x0, #4]
   1954c:	cmp	w8, #0x0
   19550:	cneg	w8, w8, mi  // mi = first
   19554:	cmp	x8, x1
   19558:	b.le	19568 <__gmpz_getlimbn@@Base+0x24>
   1955c:	ldr	x8, [x0, #8]
   19560:	ldr	x0, [x8, x1, lsl #3]
   19564:	ret
   19568:	mov	x0, xzr
   1956c:	ret

0000000000019570 <__gmpz_hamdist@@Base>:
   19570:	stp	x29, x30, [sp, #-80]!
   19574:	stp	x24, x23, [sp, #32]
   19578:	stp	x22, x21, [sp, #48]
   1957c:	stp	x20, x19, [sp, #64]
   19580:	ldrsw	x12, [x0, #4]
   19584:	ldrsw	x9, [x1, #4]
   19588:	ldr	x8, [x0, #8]
   1958c:	ldr	x10, [x1, #8]
   19590:	str	x25, [sp, #16]
   19594:	mov	x29, sp
   19598:	tbnz	w12, #31, 195d8 <__gmpz_hamdist@@Base+0x68>
   1959c:	tbnz	w9, #31, 195dc <__gmpz_hamdist@@Base+0x6c>
   195a0:	cmp	w12, w9
   195a4:	csel	w11, w12, w9, lt  // lt = tstop
   195a8:	csel	w13, w12, w9, gt
   195ac:	sxtw	x19, w11
   195b0:	sxtw	x21, w13
   195b4:	csel	x20, x10, x8, lt  // lt = tstop
   195b8:	cbz	w11, 195e4 <__gmpz_hamdist@@Base+0x74>
   195bc:	cmp	w12, w9
   195c0:	csel	x1, x8, x10, lt  // lt = tstop
   195c4:	mov	x0, x20
   195c8:	mov	x2, x19
   195cc:	bl	ce60 <__gmpn_hamdist@plt>
   195d0:	mov	x22, x0
   195d4:	b	195e8 <__gmpz_hamdist@@Base+0x78>
   195d8:	tbnz	w9, #31, 195f8 <__gmpz_hamdist@@Base+0x88>
   195dc:	mov	x22, #0xffffffffffffffff    	// #-1
   195e0:	b	1978c <__gmpz_hamdist@@Base+0x21c>
   195e4:	mov	x22, xzr
   195e8:	subs	x1, x21, x19
   195ec:	b.eq	1978c <__gmpz_hamdist@@Base+0x21c>  // b.none
   195f0:	add	x0, x20, x19, lsl #3
   195f4:	b	19784 <__gmpz_hamdist@@Base+0x214>
   195f8:	mov	x11, xzr
   195fc:	neg	x24, x12
   19600:	neg	x19, x9
   19604:	ldr	x12, [x8, x11]
   19608:	ldr	x9, [x10, x11]
   1960c:	sub	x24, x24, #0x1
   19610:	sub	x19, x19, #0x1
   19614:	cbnz	x12, 19634 <__gmpz_hamdist@@Base+0xc4>
   19618:	add	x11, x11, #0x8
   1961c:	cbz	x9, 19604 <__gmpz_hamdist@@Base+0x94>
   19620:	add	x20, x10, x11
   19624:	add	x21, x8, x11
   19628:	mov	x12, x9
   1962c:	mov	x9, xzr
   19630:	b	19650 <__gmpz_hamdist@@Base+0xe0>
   19634:	mov	x0, x24
   19638:	add	x10, x10, x11
   1963c:	add	x8, x8, x11
   19640:	add	x21, x10, #0x8
   19644:	add	x20, x8, #0x8
   19648:	mov	x24, x19
   1964c:	mov	x19, x0
   19650:	neg	x8, x12
   19654:	neg	x10, x9
   19658:	eor	x8, x10, x8
   1965c:	lsr	x10, x8, #1
   19660:	and	x10, x10, #0x5555555555555555
   19664:	sub	x8, x8, x10
   19668:	lsr	x10, x8, #2
   1966c:	and	x10, x10, #0x3333333333333333
   19670:	and	x8, x8, #0x3333333333333333
   19674:	add	x8, x10, x8
   19678:	add	x8, x8, x8, lsr #4
   1967c:	and	x8, x8, #0xf0f0f0f0f0f0f0f
   19680:	add	x8, x8, x8, lsr #8
   19684:	add	x8, x8, x8, lsr #16
   19688:	lsr	x10, x8, #32
   1968c:	add	w8, w10, w8
   19690:	and	x22, x8, #0xff
   19694:	cbnz	x9, 1973c <__gmpz_hamdist@@Base+0x1cc>
   19698:	mov	w8, #0x40                  	// #64
   1969c:	sub	x25, x8, x22
   196a0:	mov	w8, #0x1                   	// #1
   196a4:	ldr	x23, [x21], #8
   196a8:	sub	x25, x25, #0x40
   196ac:	sub	x8, x8, #0x1
   196b0:	cbz	x23, 196a4 <__gmpz_hamdist@@Base+0x134>
   196b4:	neg	x9, x8
   196b8:	cmp	x9, x19
   196bc:	csneg	x22, x19, x8, ge  // ge = tcont
   196c0:	add	x24, x24, x8
   196c4:	cbz	x22, 196e8 <__gmpz_hamdist@@Base+0x178>
   196c8:	mov	x0, x20
   196cc:	mov	x1, x22
   196d0:	bl	cda0 <__gmpn_popcount@plt>
   196d4:	add	x8, x0, x25
   196d8:	sub	x19, x19, x22
   196dc:	neg	x8, x8
   196e0:	add	x20, x20, x22, lsl #3
   196e4:	b	196ec <__gmpz_hamdist@@Base+0x17c>
   196e8:	neg	x8, x25
   196ec:	sub	x24, x24, #0x1
   196f0:	sub	x9, x23, #0x1
   196f4:	cbz	x19, 19704 <__gmpz_hamdist@@Base+0x194>
   196f8:	ldr	x10, [x20], #8
   196fc:	sub	x19, x19, #0x1
   19700:	eor	x9, x10, x9
   19704:	lsr	x10, x9, #1
   19708:	and	x10, x10, #0x5555555555555555
   1970c:	sub	x9, x9, x10
   19710:	lsr	x10, x9, #2
   19714:	and	x10, x10, #0x3333333333333333
   19718:	and	x9, x9, #0x3333333333333333
   1971c:	add	x9, x10, x9
   19720:	add	x9, x9, x9, lsr #4
   19724:	and	x9, x9, #0xf0f0f0f0f0f0f0f
   19728:	add	x9, x9, x9, lsr #8
   1972c:	add	x9, x9, x9, lsr #16
   19730:	lsr	x10, x9, #32
   19734:	add	w9, w10, w9
   19738:	add	x22, x8, w9, uxtb
   1973c:	cmp	x19, x24
   19740:	csel	x23, x19, x24, lt  // lt = tstop
   19744:	cbz	x23, 1976c <__gmpz_hamdist@@Base+0x1fc>
   19748:	mov	x0, x20
   1974c:	mov	x1, x21
   19750:	mov	x2, x23
   19754:	bl	ce60 <__gmpn_hamdist@plt>
   19758:	add	x22, x0, x22
   1975c:	sub	x19, x19, x23
   19760:	sub	x24, x24, x23
   19764:	add	x20, x20, x23, lsl #3
   19768:	add	x21, x21, x23, lsl #3
   1976c:	cbnz	x19, 1977c <__gmpz_hamdist@@Base+0x20c>
   19770:	mov	x19, x24
   19774:	mov	x20, x21
   19778:	cbz	x24, 1978c <__gmpz_hamdist@@Base+0x21c>
   1977c:	mov	x0, x20
   19780:	mov	x1, x19
   19784:	bl	cda0 <__gmpn_popcount@plt>
   19788:	add	x22, x0, x22
   1978c:	mov	x0, x22
   19790:	ldp	x20, x19, [sp, #64]
   19794:	ldp	x22, x21, [sp, #48]
   19798:	ldp	x24, x23, [sp, #32]
   1979c:	ldr	x25, [sp, #16]
   197a0:	ldp	x29, x30, [sp], #80
   197a4:	ret

00000000000197a8 <__gmpz_import@@Base>:
   197a8:	stp	x29, x30, [sp, #-96]!
   197ac:	stp	x26, x25, [sp, #32]
   197b0:	stp	x24, x23, [sp, #48]
   197b4:	stp	x22, x21, [sp, #64]
   197b8:	stp	x20, x19, [sp, #80]
   197bc:	lsl	x8, x3, #3
   197c0:	ldrsw	x9, [x0]
   197c4:	str	x27, [sp, #16]
   197c8:	sub	x27, x8, x5
   197cc:	orr	x8, xzr, #0x3f
   197d0:	madd	x8, x27, x1, x8
   197d4:	lsr	x20, x8, #6
   197d8:	mov	x22, x6
   197dc:	mov	x25, x5
   197e0:	mov	w26, w4
   197e4:	mov	x23, x3
   197e8:	mov	x21, x1
   197ec:	mov	x19, x0
   197f0:	cmp	x20, x9
   197f4:	mov	w24, w2
   197f8:	mov	x29, sp
   197fc:	b.gt	19a38 <__gmpz_import@@Base+0x290>
   19800:	ldr	x0, [x19, #8]
   19804:	cmp	w26, #0x0
   19808:	csinv	w15, w26, wzr, ne  // ne = any
   1980c:	cbz	x25, 19908 <__gmpz_import@@Base+0x160>
   19810:	add	x8, x27, #0x7
   19814:	cmp	w15, #0x0
   19818:	lsr	x8, x8, #3
   1981c:	cneg	x9, x8, lt  // lt = tstop
   19820:	cmp	w24, #0x0
   19824:	cneg	x10, x23, ge  // ge = tcont
   19828:	cbz	x21, 199f0 <__gmpz_import@@Base+0x248>
   1982c:	sub	x12, x21, #0x1
   19830:	mov	x8, xzr
   19834:	cmp	w24, #0x0
   19838:	mul	x12, x12, x23
   1983c:	csel	x12, x12, x8, ge  // ge = tcont
   19840:	and	w11, w27, #0x7
   19844:	add	x14, x22, x12
   19848:	mov	x12, #0xffffffffffffffff    	// #-1
   1984c:	sub	x16, x23, #0x1
   19850:	cmp	w15, #0x0
   19854:	lsl	x12, x12, x11
   19858:	csel	x16, x16, x8, ge  // ge = tcont
   1985c:	mov	w13, wzr
   19860:	add	x9, x9, x10
   19864:	lsr	x10, x27, #3
   19868:	mvn	x12, x12
   1986c:	add	x14, x14, x16
   19870:	sub	x15, x8, w15, sxtw
   19874:	mov	x16, x8
   19878:	cbz	x10, 198b8 <__gmpz_import@@Base+0x110>
   1987c:	mov	x17, x10
   19880:	ldrb	w18, [x14]
   19884:	add	x14, x14, x15
   19888:	subs	w1, w13, #0x38
   1988c:	lsl	x2, x18, x13
   19890:	orr	x16, x2, x16
   19894:	b.lt	198ac <__gmpz_import@@Base+0x104>  // b.tstop
   19898:	neg	w13, w13
   1989c:	str	x16, [x0], #8
   198a0:	lsr	x16, x18, x13
   198a4:	mov	w13, w1
   198a8:	b	198b0 <__gmpz_import@@Base+0x108>
   198ac:	add	w13, w13, #0x8
   198b0:	subs	x17, x17, #0x1
   198b4:	b.ne	19880 <__gmpz_import@@Base+0xd8>  // b.any
   198b8:	cbz	w11, 198ec <__gmpz_import@@Base+0x144>
   198bc:	ldrb	w17, [x14]
   198c0:	add	x14, x14, x15
   198c4:	and	x17, x17, x12
   198c8:	lsl	x1, x17, x13
   198cc:	add	w13, w13, w11
   198d0:	subs	w18, w13, #0x40
   198d4:	orr	x16, x1, x16
   198d8:	b.lt	198ec <__gmpz_import@@Base+0x144>  // b.tstop
   198dc:	sub	w13, w11, w18
   198e0:	str	x16, [x0], #8
   198e4:	lsr	x16, x17, x13
   198e8:	mov	w13, w18
   198ec:	add	x8, x8, #0x1
   198f0:	cmp	x8, x21
   198f4:	add	x14, x14, x9
   198f8:	b.ne	19878 <__gmpz_import@@Base+0xd0>  // b.any
   198fc:	cbz	w13, 199f0 <__gmpz_import@@Base+0x248>
   19900:	str	x16, [x0]
   19904:	b	199f0 <__gmpz_import@@Base+0x248>
   19908:	cmn	w24, #0x1
   1990c:	cset	w8, eq  // eq = none
   19910:	cmp	x23, #0x8
   19914:	cset	w9, eq  // eq = none
   19918:	and	w9, w8, w9
   1991c:	cmp	w9, #0x1
   19920:	and	x8, x22, #0x7
   19924:	b.ne	19944 <__gmpz_import@@Base+0x19c>  // b.any
   19928:	cmn	w15, #0x1
   1992c:	b.ne	19944 <__gmpz_import@@Base+0x19c>  // b.any
   19930:	cbnz	x8, 19944 <__gmpz_import@@Base+0x19c>
   19934:	mov	x1, x22
   19938:	mov	x2, x21
   1993c:	bl	ca70 <__gmpn_copyi@plt>
   19940:	b	199f0 <__gmpz_import@@Base+0x248>
   19944:	cmp	w15, #0x1
   19948:	cset	w10, ne  // ne = any
   1994c:	eor	w9, w9, #0x1
   19950:	orr	w9, w9, w10
   19954:	tbnz	w9, #0, 199b8 <__gmpz_import@@Base+0x210>
   19958:	cbnz	x8, 199b8 <__gmpz_import@@Base+0x210>
   1995c:	cmp	x21, #0x1
   19960:	b.lt	199f0 <__gmpz_import@@Base+0x248>  // b.tstop
   19964:	ldr	x8, [x22], #8
   19968:	subs	x21, x21, #0x1
   1996c:	lsl	x11, x8, #40
   19970:	and	x11, x11, #0xff000000000000
   19974:	lsr	x10, x8, #16
   19978:	bfi	x11, x8, #56, #8
   1997c:	lsr	x9, x8, #24
   19980:	bfi	x11, x10, #40, #8
   19984:	lsr	x10, x8, #8
   19988:	and	x10, x10, #0xff000000
   1998c:	bfi	x11, x9, #32, #8
   19990:	orr	x10, x11, x10
   19994:	lsr	x11, x8, #40
   19998:	and	x9, x9, #0xff0000
   1999c:	and	x11, x11, #0xff00
   199a0:	orr	x9, x10, x9
   199a4:	orr	x9, x9, x11
   199a8:	add	x8, x9, x8, lsr #56
   199ac:	str	x8, [x0], #8
   199b0:	b.ne	19964 <__gmpz_import@@Base+0x1bc>  // b.any
   199b4:	b	199f0 <__gmpz_import@@Base+0x248>
   199b8:	cmp	w24, #0x1
   199bc:	b.ne	19810 <__gmpz_import@@Base+0x68>  // b.any
   199c0:	cmp	x23, #0x8
   199c4:	b.ne	19810 <__gmpz_import@@Base+0x68>  // b.any
   199c8:	cmn	w15, #0x1
   199cc:	b.ne	19810 <__gmpz_import@@Base+0x68>  // b.any
   199d0:	cbnz	x8, 19810 <__gmpz_import@@Base+0x68>
   199d4:	cmp	x21, #0x1
   199d8:	b.lt	199f0 <__gmpz_import@@Base+0x248>  // b.tstop
   199dc:	sub	x8, x22, #0x8
   199e0:	ldr	x9, [x8, x21, lsl #3]
   199e4:	subs	x21, x21, #0x1
   199e8:	str	x9, [x0], #8
   199ec:	b.ne	199e0 <__gmpz_import@@Base+0x238>  // b.any
   199f0:	ldr	x8, [x19, #8]
   199f4:	sub	x8, x8, #0x8
   199f8:	subs	x9, x20, #0x1
   199fc:	b.lt	19a14 <__gmpz_import@@Base+0x26c>  // b.tstop
   19a00:	ldr	x10, [x8, x20, lsl #3]
   19a04:	mov	x20, x9
   19a08:	cbz	x10, 199f8 <__gmpz_import@@Base+0x250>
   19a0c:	add	x8, x9, #0x1
   19a10:	b	19a18 <__gmpz_import@@Base+0x270>
   19a14:	mov	x8, xzr
   19a18:	str	w8, [x19, #4]
   19a1c:	ldp	x20, x19, [sp, #80]
   19a20:	ldp	x22, x21, [sp, #64]
   19a24:	ldp	x24, x23, [sp, #48]
   19a28:	ldp	x26, x25, [sp, #32]
   19a2c:	ldr	x27, [sp, #16]
   19a30:	ldp	x29, x30, [sp], #96
   19a34:	ret
   19a38:	mov	x0, x19
   19a3c:	mov	x1, x20
   19a40:	bl	c090 <__gmpz_realloc@plt>
   19a44:	b	19804 <__gmpz_import@@Base+0x5c>

0000000000019a48 <__gmpz_init@@Base>:
   19a48:	adrp	x8, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   19a4c:	add	x8, x8, #0x260
   19a50:	stp	xzr, x8, [x0]
   19a54:	ret

0000000000019a58 <__gmpz_init2@@Base>:
   19a58:	stp	x29, x30, [sp, #-32]!
   19a5c:	cmp	x1, #0x0
   19a60:	cset	w8, ne  // ne = any
   19a64:	sub	x8, x1, x8
   19a68:	mov	x9, #0x1fffffffc0          	// #137438953408
   19a6c:	cmp	x8, x9
   19a70:	stp	x20, x19, [sp, #16]
   19a74:	mov	x29, sp
   19a78:	b.cs	19ab0 <__gmpz_init2@@Base+0x58>  // b.hs, b.nlast
   19a7c:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   19a80:	ldr	x9, [x9, #3840]
   19a84:	lsr	x8, x8, #6
   19a88:	add	x20, x8, #0x1
   19a8c:	mov	x19, x0
   19a90:	ldr	x9, [x9]
   19a94:	lsl	x0, x20, #3
   19a98:	blr	x9
   19a9c:	str	x0, [x19, #8]
   19aa0:	stp	w20, wzr, [x19]
   19aa4:	ldp	x20, x19, [sp, #16]
   19aa8:	ldp	x29, x30, [sp], #32
   19aac:	ret
   19ab0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   19ab4:	ldr	x8, [x8, #3824]
   19ab8:	adrp	x0, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   19abc:	add	x0, x0, #0x268
   19ac0:	mov	w1, #0x1a                  	// #26
   19ac4:	ldr	x3, [x8]
   19ac8:	mov	w2, #0x1                   	// #1
   19acc:	bl	ce50 <fwrite@plt>
   19ad0:	bl	c920 <abort@plt>

0000000000019ad4 <__gmpz_inits@@Base>:
   19ad4:	sub	sp, sp, #0xe0
   19ad8:	mov	x8, #0xffffffffffffffc8    	// #-56
   19adc:	mov	x9, sp
   19ae0:	movk	x8, #0xff80, lsl #32
   19ae4:	add	x9, x9, #0x80
   19ae8:	add	x10, sp, #0x88
   19aec:	stp	x9, x8, [sp, #208]
   19af0:	adrp	x8, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   19af4:	add	x11, sp, #0xe0
   19af8:	add	x10, x10, #0x38
   19afc:	add	x8, x8, #0x288
   19b00:	stp	x1, x2, [sp, #136]
   19b04:	stp	x3, x4, [sp, #152]
   19b08:	stp	x5, x6, [sp, #168]
   19b0c:	stp	q0, q1, [sp]
   19b10:	stp	q2, q3, [sp, #32]
   19b14:	stp	q4, q5, [sp, #64]
   19b18:	stp	q6, q7, [sp, #96]
   19b1c:	str	x10, [sp, #200]
   19b20:	stp	x7, x11, [sp, #184]
   19b24:	stp	xzr, x8, [x0]
   19b28:	ldrsw	x9, [sp, #216]
   19b2c:	tbz	w9, #31, 19b4c <__gmpz_inits@@Base+0x78>
   19b30:	add	w10, w9, #0x8
   19b34:	cmn	w9, #0x8
   19b38:	str	w10, [sp, #216]
   19b3c:	b.gt	19b4c <__gmpz_inits@@Base+0x78>
   19b40:	ldr	x10, [sp, #200]
   19b44:	add	x9, x10, x9
   19b48:	b	19b58 <__gmpz_inits@@Base+0x84>
   19b4c:	ldr	x9, [sp, #192]
   19b50:	add	x10, x9, #0x8
   19b54:	str	x10, [sp, #192]
   19b58:	ldr	x0, [x9]
   19b5c:	cbnz	x0, 19b24 <__gmpz_inits@@Base+0x50>
   19b60:	add	sp, sp, #0xe0
   19b64:	ret

0000000000019b68 <__gmpz_inp_raw@@Base>:
   19b68:	sub	sp, sp, #0x50
   19b6c:	stp	x29, x30, [sp, #16]
   19b70:	stp	x24, x23, [sp, #32]
   19b74:	stp	x22, x21, [sp, #48]
   19b78:	stp	x20, x19, [sp, #64]
   19b7c:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   19b80:	ldr	x8, [x8, #3888]
   19b84:	cmp	x1, #0x0
   19b88:	add	x29, sp, #0x10
   19b8c:	mov	x19, x0
   19b90:	ldr	x8, [x8]
   19b94:	sub	x0, x29, #0x4
   19b98:	mov	w2, #0x1                   	// #1
   19b9c:	csel	x23, x8, x1, eq  // eq = none
   19ba0:	mov	w1, #0x4                   	// #4
   19ba4:	mov	x3, x23
   19ba8:	bl	cbb0 <fread@plt>
   19bac:	cmp	x0, #0x1
   19bb0:	b.ne	19cf0 <__gmpz_inp_raw@@Base+0x188>  // b.any
   19bb4:	ldur	w8, [x29, #-4]
   19bb8:	lsl	x8, x8, #32
   19bbc:	rev	x8, x8
   19bc0:	lsr	x10, x8, #31
   19bc4:	orr	x9, x8, #0xffffffff00000000
   19bc8:	cmp	x10, #0x0
   19bcc:	csel	x24, x8, x9, eq  // eq = none
   19bd0:	cmp	x24, #0x0
   19bd4:	cneg	x20, x24, mi  // mi = first
   19bd8:	lsl	x8, x20, #3
   19bdc:	add	x8, x8, #0x3f
   19be0:	lsr	x21, x8, #6
   19be4:	cbz	x21, 19cf8 <__gmpz_inp_raw@@Base+0x190>
   19be8:	ldrsw	x8, [x19]
   19bec:	cmp	x21, x8
   19bf0:	b.gt	19d28 <__gmpz_inp_raw@@Base+0x1c0>
   19bf4:	ldr	x22, [x19, #8]
   19bf8:	add	x8, x22, x21, lsl #3
   19bfc:	sub	x0, x8, x20
   19c00:	mov	w2, #0x1                   	// #1
   19c04:	mov	x1, x20
   19c08:	mov	x3, x23
   19c0c:	str	xzr, [x22]
   19c10:	bl	cbb0 <fread@plt>
   19c14:	cmp	x0, #0x1
   19c18:	mov	x0, xzr
   19c1c:	b.ne	19d10 <__gmpz_inp_raw@@Base+0x1a8>  // b.any
   19c20:	add	x8, x21, #0x1
   19c24:	lsr	x8, x8, #1
   19c28:	cbz	x8, 19cd0 <__gmpz_inp_raw@@Base+0x168>
   19c2c:	add	x9, x22, x21, lsl #3
   19c30:	sub	x9, x9, #0x8
   19c34:	mov	x10, x22
   19c38:	ldr	x11, [x9]
   19c3c:	ldr	x12, [x10]
   19c40:	subs	x8, x8, #0x1
   19c44:	lsl	x15, x11, #40
   19c48:	and	x15, x15, #0xff000000000000
   19c4c:	lsr	x14, x11, #16
   19c50:	bfi	x15, x11, #56, #8
   19c54:	bfi	x15, x14, #40, #8
   19c58:	lsl	x14, x12, #40
   19c5c:	lsr	x13, x11, #24
   19c60:	lsr	x16, x11, #8
   19c64:	and	x14, x14, #0xff000000000000
   19c68:	lsr	x17, x12, #16
   19c6c:	bfi	x14, x12, #56, #8
   19c70:	and	x16, x16, #0xff000000
   19c74:	bfi	x15, x13, #32, #8
   19c78:	bfi	x14, x17, #40, #8
   19c7c:	lsr	x17, x12, #24
   19c80:	orr	x15, x15, x16
   19c84:	lsr	x16, x12, #8
   19c88:	and	x16, x16, #0xff000000
   19c8c:	bfi	x14, x17, #32, #8
   19c90:	and	x13, x13, #0xff0000
   19c94:	orr	x14, x14, x16
   19c98:	orr	x13, x15, x13
   19c9c:	and	x15, x17, #0xff0000
   19ca0:	orr	x14, x14, x15
   19ca4:	lsr	x15, x11, #40
   19ca8:	and	x15, x15, #0xff00
   19cac:	orr	x13, x13, x15
   19cb0:	lsr	x15, x12, #40
   19cb4:	and	x15, x15, #0xff00
   19cb8:	orr	x14, x14, x15
   19cbc:	add	x11, x13, x11, lsr #56
   19cc0:	add	x12, x14, x12, lsr #56
   19cc4:	str	x11, [x10], #8
   19cc8:	str	x12, [x9], #-8
   19ccc:	b.ne	19c38 <__gmpz_inp_raw@@Base+0xd0>  // b.any
   19cd0:	sub	x8, x22, #0x8
   19cd4:	subs	x9, x21, #0x1
   19cd8:	b.lt	19cf8 <__gmpz_inp_raw@@Base+0x190>  // b.tstop
   19cdc:	ldr	x10, [x8, x21, lsl #3]
   19ce0:	mov	x21, x9
   19ce4:	cbz	x10, 19cd4 <__gmpz_inp_raw@@Base+0x16c>
   19ce8:	add	x8, x9, #0x1
   19cec:	b	19cfc <__gmpz_inp_raw@@Base+0x194>
   19cf0:	mov	x0, xzr
   19cf4:	b	19d10 <__gmpz_inp_raw@@Base+0x1a8>
   19cf8:	mov	x8, xzr
   19cfc:	neg	w9, w8
   19d00:	cmp	x24, #0x0
   19d04:	csel	x8, x8, x9, ge  // ge = tcont
   19d08:	add	x0, x20, #0x4
   19d0c:	str	w8, [x19, #4]
   19d10:	ldp	x20, x19, [sp, #64]
   19d14:	ldp	x22, x21, [sp, #48]
   19d18:	ldp	x24, x23, [sp, #32]
   19d1c:	ldp	x29, x30, [sp, #16]
   19d20:	add	sp, sp, #0x50
   19d24:	ret
   19d28:	mov	x0, x19
   19d2c:	mov	x1, x21
   19d30:	bl	c090 <__gmpz_realloc@plt>
   19d34:	mov	x22, x0
   19d38:	b	19bf8 <__gmpz_inp_raw@@Base+0x90>

0000000000019d3c <__gmpz_inp_str@@Base>:
   19d3c:	stp	x29, x30, [sp, #-64]!
   19d40:	str	x23, [sp, #16]
   19d44:	stp	x22, x21, [sp, #32]
   19d48:	stp	x20, x19, [sp, #48]
   19d4c:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   19d50:	ldr	x8, [x8, #3888]
   19d54:	cmp	x1, #0x0
   19d58:	mov	w19, w2
   19d5c:	mov	x21, x0
   19d60:	ldr	x8, [x8]
   19d64:	mov	x20, xzr
   19d68:	mov	x29, sp
   19d6c:	csel	x22, x8, x1, eq  // eq = none
   19d70:	mov	x0, x22
   19d74:	bl	c810 <getc@plt>
   19d78:	mov	w23, w0
   19d7c:	add	x20, x20, #0x1
   19d80:	bl	cb00 <__ctype_b_loc@plt>
   19d84:	ldr	x8, [x0]
   19d88:	ldrh	w8, [x8, w23, sxtw #1]
   19d8c:	tbnz	w8, #13, 19d70 <__gmpz_inp_str@@Base+0x34>
   19d90:	mov	x0, x21
   19d94:	mov	x1, x22
   19d98:	mov	w2, w19
   19d9c:	mov	w3, w23
   19da0:	mov	x4, x20
   19da4:	ldp	x20, x19, [sp, #48]
   19da8:	ldp	x22, x21, [sp, #32]
   19dac:	ldr	x23, [sp, #16]
   19db0:	ldp	x29, x30, [sp], #64
   19db4:	b	c9f0 <__gmpz_inp_str_nowhite@plt>

0000000000019db8 <__gmpz_inp_str_nowhite@@Base>:
   19db8:	sub	sp, sp, #0x70
   19dbc:	stp	x29, x30, [sp, #16]
   19dc0:	stp	x28, x27, [sp, #32]
   19dc4:	stp	x26, x25, [sp, #48]
   19dc8:	stp	x24, x23, [sp, #64]
   19dcc:	stp	x22, x21, [sp, #80]
   19dd0:	stp	x20, x19, [sp, #96]
   19dd4:	adrp	x28, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   19dd8:	ldr	x28, [x28, #3920]
   19ddc:	mov	x20, x4
   19de0:	mov	w23, w3
   19de4:	mov	w22, w2
   19de8:	mov	x21, x1
   19dec:	mov	x26, x0
   19df0:	cmp	w2, #0x25
   19df4:	add	x29, sp, #0x10
   19df8:	b.lt	19e08 <__gmpz_inp_str_nowhite@@Base+0x50>  // b.tstop
   19dfc:	cmp	w22, #0x3e
   19e00:	b.gt	19e84 <__gmpz_inp_str_nowhite@@Base+0xcc>
   19e04:	add	x28, x28, #0xd0
   19e08:	cmp	w23, #0x2d
   19e0c:	b.ne	19e28 <__gmpz_inp_str_nowhite@@Base+0x70>  // b.any
   19e10:	mov	x0, x21
   19e14:	bl	c810 <getc@plt>
   19e18:	mov	w23, w0
   19e1c:	add	x20, x20, #0x1
   19e20:	mov	w27, #0x1                   	// #1
   19e24:	b	19e2c <__gmpz_inp_str_nowhite@@Base+0x74>
   19e28:	mov	w27, wzr
   19e2c:	cmn	w23, #0x1
   19e30:	b.eq	19e84 <__gmpz_inp_str_nowhite@@Base+0xcc>  // b.none
   19e34:	ldrb	w8, [x28, w23, sxtw]
   19e38:	cmp	w22, #0x0
   19e3c:	mov	w9, #0xa                   	// #10
   19e40:	csel	w9, w9, w22, eq  // eq = none
   19e44:	cmp	w9, w8
   19e48:	b.le	19e84 <__gmpz_inp_str_nowhite@@Base+0xcc>
   19e4c:	cbnz	w22, 19e90 <__gmpz_inp_str_nowhite@@Base+0xd8>
   19e50:	cmp	w23, #0x30
   19e54:	b.ne	19e8c <__gmpz_inp_str_nowhite@@Base+0xd4>  // b.any
   19e58:	mov	x0, x21
   19e5c:	bl	c810 <getc@plt>
   19e60:	orr	w8, w0, #0x20
   19e64:	cmp	w8, #0x78
   19e68:	b.ne	1a004 <__gmpz_inp_str_nowhite@@Base+0x24c>  // b.any
   19e6c:	mov	x0, x21
   19e70:	bl	c810 <getc@plt>
   19e74:	mov	w23, w0
   19e78:	add	x20, x20, #0x2
   19e7c:	mov	w22, #0x10                  	// #16
   19e80:	b	19e90 <__gmpz_inp_str_nowhite@@Base+0xd8>
   19e84:	mov	x20, xzr
   19e88:	b	19fe0 <__gmpz_inp_str_nowhite@@Base+0x228>
   19e8c:	mov	w22, #0xa                   	// #10
   19e90:	cmp	w23, #0x30
   19e94:	b.ne	19eb0 <__gmpz_inp_str_nowhite@@Base+0xf8>  // b.any
   19e98:	mov	x0, x21
   19e9c:	bl	c810 <getc@plt>
   19ea0:	cmp	w0, #0x30
   19ea4:	add	x20, x20, #0x1
   19ea8:	b.eq	19e98 <__gmpz_inp_str_nowhite@@Base+0xe0>  // b.none
   19eac:	mov	w23, w0
   19eb0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   19eb4:	ldr	x8, [x8, #3840]
   19eb8:	mov	w0, #0x64                  	// #100
   19ebc:	mov	w24, #0x64                  	// #100
   19ec0:	ldr	x8, [x8]
   19ec4:	blr	x8
   19ec8:	cmn	w23, #0x1
   19ecc:	mov	x25, x0
   19ed0:	b.eq	19f48 <__gmpz_inp_str_nowhite@@Base+0x190>  // b.none
   19ed4:	str	x26, [sp, #8]
   19ed8:	mov	x26, xzr
   19edc:	mov	w24, #0x64                  	// #100
   19ee0:	str	w27, [sp, #4]
   19ee4:	ldrb	w27, [x28, w23, sxtw]
   19ee8:	cmp	w22, w27
   19eec:	b.le	19f50 <__gmpz_inp_str_nowhite@@Base+0x198>
   19ef0:	cmp	x26, x24
   19ef4:	b.cc	19f24 <__gmpz_inp_str_nowhite@@Base+0x16c>  // b.lo, b.ul, b.last
   19ef8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   19efc:	ldr	x8, [x8, #3792]
   19f00:	add	x9, x24, x24, lsl #1
   19f04:	lsr	x23, x9, #1
   19f08:	mov	x0, x25
   19f0c:	ldr	x8, [x8]
   19f10:	mov	x1, x24
   19f14:	mov	x2, x23
   19f18:	blr	x8
   19f1c:	mov	x25, x0
   19f20:	mov	x24, x23
   19f24:	mov	x0, x21
   19f28:	add	x19, x26, #0x1
   19f2c:	strb	w27, [x25, x26]
   19f30:	bl	c810 <getc@plt>
   19f34:	mov	w23, w0
   19f38:	cmn	w0, #0x1
   19f3c:	mov	x26, x19
   19f40:	b.ne	19ee4 <__gmpz_inp_str_nowhite@@Base+0x12c>  // b.any
   19f44:	b	19f54 <__gmpz_inp_str_nowhite@@Base+0x19c>
   19f48:	mov	x19, xzr
   19f4c:	b	19f5c <__gmpz_inp_str_nowhite@@Base+0x1a4>
   19f50:	mov	x19, x26
   19f54:	ldr	x26, [sp, #8]
   19f58:	ldr	w27, [sp, #4]
   19f5c:	mov	w0, w23
   19f60:	mov	x1, x21
   19f64:	bl	cc70 <ungetc@plt>
   19f68:	add	x8, x20, x19
   19f6c:	sub	x20, x8, #0x1
   19f70:	cbz	x19, 19fc0 <__gmpz_inp_str_nowhite@@Base+0x208>
   19f74:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   19f78:	ldr	x8, [x8, #3936]
   19f7c:	mov	w9, #0x28                  	// #40
   19f80:	smaddl	x8, w22, w9, x8
   19f84:	ldr	x8, [x8, #16]
   19f88:	ldrsw	x9, [x26]
   19f8c:	umulh	x8, x8, x19
   19f90:	ubfx	x8, x8, #3, #58
   19f94:	add	x1, x8, #0x2
   19f98:	cmp	x1, x9
   19f9c:	b.gt	1a034 <__gmpz_inp_str_nowhite@@Base+0x27c>
   19fa0:	ldr	x0, [x26, #8]
   19fa4:	mov	x1, x25
   19fa8:	mov	x2, x19
   19fac:	mov	w3, w22
   19fb0:	bl	c0a0 <__gmpn_set_str@plt>
   19fb4:	cmp	w27, #0x0
   19fb8:	cneg	w8, w0, ne  // ne = any
   19fbc:	b	19fc4 <__gmpz_inp_str_nowhite@@Base+0x20c>
   19fc0:	mov	w8, wzr
   19fc4:	str	w8, [x26, #4]
   19fc8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   19fcc:	ldr	x8, [x8, #4016]
   19fd0:	mov	x0, x25
   19fd4:	mov	x1, x24
   19fd8:	ldr	x8, [x8]
   19fdc:	blr	x8
   19fe0:	mov	x0, x20
   19fe4:	ldp	x20, x19, [sp, #96]
   19fe8:	ldp	x22, x21, [sp, #80]
   19fec:	ldp	x24, x23, [sp, #64]
   19ff0:	ldp	x26, x25, [sp, #48]
   19ff4:	ldp	x28, x27, [sp, #32]
   19ff8:	ldp	x29, x30, [sp, #16]
   19ffc:	add	sp, sp, #0x70
   1a000:	ret
   1a004:	cmp	w8, #0x62
   1a008:	b.ne	1a024 <__gmpz_inp_str_nowhite@@Base+0x26c>  // b.any
   1a00c:	mov	x0, x21
   1a010:	bl	c810 <getc@plt>
   1a014:	mov	w23, w0
   1a018:	add	x20, x20, #0x2
   1a01c:	mov	w22, #0x2                   	// #2
   1a020:	b	19e90 <__gmpz_inp_str_nowhite@@Base+0xd8>
   1a024:	mov	w23, w0
   1a028:	add	x20, x20, #0x1
   1a02c:	mov	w22, #0x8                   	// #8
   1a030:	b	19e90 <__gmpz_inp_str_nowhite@@Base+0xd8>
   1a034:	mov	x0, x26
   1a038:	bl	c090 <__gmpz_realloc@plt>
   1a03c:	b	19fa0 <__gmpz_inp_str_nowhite@@Base+0x1e8>

000000000001a040 <__gmpz_invert@@Base>:
   1a040:	stp	x29, x30, [sp, #-64]!
   1a044:	stp	x24, x23, [sp, #16]
   1a048:	stp	x22, x21, [sp, #32]
   1a04c:	stp	x20, x19, [sp, #48]
   1a050:	mov	x29, sp
   1a054:	sub	sp, sp, #0x30
   1a058:	ldr	w8, [x1, #4]
   1a05c:	ldr	w9, [x2, #4]
   1a060:	mov	x19, x2
   1a064:	mov	x21, x1
   1a068:	cmp	w8, #0x0
   1a06c:	cneg	w8, w8, mi  // mi = first
   1a070:	cmp	w9, #0x0
   1a074:	cneg	w9, w9, mi  // mi = first
   1a078:	cmp	x8, x9
   1a07c:	csel	x8, x8, x9, hi  // hi = pmore
   1a080:	add	x24, x8, #0x1
   1a084:	mov	x20, x0
   1a088:	cmp	x8, #0xfdf
   1a08c:	lsl	x23, x24, #3
   1a090:	stur	xzr, [x29, #-40]
   1a094:	stur	w24, [x29, #-16]
   1a098:	b.hi	1a17c <__gmpz_invert@@Base+0x13c>  // b.pmore
   1a09c:	add	x9, x23, #0xf
   1a0a0:	mov	x8, sp
   1a0a4:	and	x9, x9, #0x1ffffffff0
   1a0a8:	sub	x8, x8, x9
   1a0ac:	mov	sp, x8
   1a0b0:	stur	x8, [x29, #-8]
   1a0b4:	mov	x8, sp
   1a0b8:	sub	x22, x29, #0x20
   1a0bc:	sub	x0, x8, x9
   1a0c0:	stur	w24, [x29, #-32]
   1a0c4:	mov	sp, x0
   1a0c8:	stur	x0, [x29, #-24]
   1a0cc:	sub	x0, x29, #0x10
   1a0d0:	mov	x1, x22
   1a0d4:	mov	x2, xzr
   1a0d8:	mov	x3, x21
   1a0dc:	mov	x4, x19
   1a0e0:	bl	c0d0 <__gmpz_gcdext@plt>
   1a0e4:	ldur	w8, [x29, #-12]
   1a0e8:	cmp	w8, #0x1
   1a0ec:	b.ne	1a118 <__gmpz_invert@@Base+0xd8>  // b.any
   1a0f0:	ldur	x8, [x29, #-8]
   1a0f4:	ldr	x8, [x8]
   1a0f8:	cmp	x8, #0x1
   1a0fc:	b.ne	1a118 <__gmpz_invert@@Base+0xd8>  // b.any
   1a100:	ldur	w8, [x29, #-28]
   1a104:	tbnz	w8, #31, 1a12c <__gmpz_invert@@Base+0xec>
   1a108:	mov	x0, x20
   1a10c:	mov	x1, x22
   1a110:	bl	c440 <__gmpz_set@plt>
   1a114:	b	1a158 <__gmpz_invert@@Base+0x118>
   1a118:	ldur	x0, [x29, #-40]
   1a11c:	cbz	x0, 1a164 <__gmpz_invert@@Base+0x124>
   1a120:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1a124:	mov	w0, wzr
   1a128:	b	1a164 <__gmpz_invert@@Base+0x124>
   1a12c:	ldr	w8, [x19, #4]
   1a130:	tbnz	w8, #31, 1a148 <__gmpz_invert@@Base+0x108>
   1a134:	mov	x0, x20
   1a138:	mov	x1, x22
   1a13c:	mov	x2, x19
   1a140:	bl	cfb0 <__gmpz_add@plt>
   1a144:	b	1a158 <__gmpz_invert@@Base+0x118>
   1a148:	mov	x0, x20
   1a14c:	mov	x1, x22
   1a150:	mov	x2, x19
   1a154:	bl	c270 <__gmpz_sub@plt>
   1a158:	ldur	x0, [x29, #-40]
   1a15c:	cbnz	x0, 1a1a4 <__gmpz_invert@@Base+0x164>
   1a160:	mov	w0, #0x1                   	// #1
   1a164:	mov	sp, x29
   1a168:	ldp	x20, x19, [sp, #48]
   1a16c:	ldp	x22, x21, [sp, #32]
   1a170:	ldp	x24, x23, [sp, #16]
   1a174:	ldp	x29, x30, [sp], #64
   1a178:	ret
   1a17c:	sub	x0, x29, #0x28
   1a180:	mov	x1, x23
   1a184:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1a188:	stur	x0, [x29, #-8]
   1a18c:	sub	x0, x29, #0x28
   1a190:	mov	x1, x23
   1a194:	sub	x22, x29, #0x20
   1a198:	stur	w24, [x29, #-32]
   1a19c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1a1a0:	b	1a0c8 <__gmpz_invert@@Base+0x88>
   1a1a4:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1a1a8:	b	1a160 <__gmpz_invert@@Base+0x120>

000000000001a1ac <__gmpz_ior@@Base>:
   1a1ac:	stp	x29, x30, [sp, #-80]!
   1a1b0:	stp	x26, x25, [sp, #16]
   1a1b4:	stp	x24, x23, [sp, #32]
   1a1b8:	stp	x22, x21, [sp, #48]
   1a1bc:	stp	x20, x19, [sp, #64]
   1a1c0:	mov	x29, sp
   1a1c4:	sub	sp, sp, #0x10
   1a1c8:	ldr	w9, [x1, #4]
   1a1cc:	ldr	w10, [x2, #4]
   1a1d0:	ldr	x22, [x0, #8]
   1a1d4:	mov	x19, x0
   1a1d8:	cmp	w9, w10
   1a1dc:	csel	x8, x2, x1, lt  // lt = tstop
   1a1e0:	ldr	x21, [x8, #8]
   1a1e4:	csel	w11, w9, w10, lt  // lt = tstop
   1a1e8:	csel	w24, w10, w9, lt  // lt = tstop
   1a1ec:	sxtw	x23, w11
   1a1f0:	sxtw	x20, w24
   1a1f4:	csel	x26, x1, x2, lt  // lt = tstop
   1a1f8:	tbnz	w11, #31, 1a244 <__gmpz_ior@@Base+0x98>
   1a1fc:	cmp	x22, x21
   1a200:	mov	x0, x21
   1a204:	b.eq	1a228 <__gmpz_ior@@Base+0x7c>  // b.none
   1a208:	ldr	w8, [x19]
   1a20c:	cmp	w24, w8
   1a210:	b.gt	1a61c <__gmpz_ior@@Base+0x470>
   1a214:	add	x0, x22, x23, lsl #3
   1a218:	add	x1, x21, x23, lsl #3
   1a21c:	sub	x2, x20, x23
   1a220:	bl	ca70 <__gmpn_copyi@plt>
   1a224:	mov	x0, x22
   1a228:	cbz	w23, 1a23c <__gmpz_ior@@Base+0x90>
   1a22c:	ldr	x2, [x26, #8]
   1a230:	mov	x1, x21
   1a234:	mov	x3, x23
   1a238:	bl	cc20 <__gmpn_ior_n@plt>
   1a23c:	str	w24, [x19, #4]
   1a240:	b	1a600 <__gmpz_ior@@Base+0x454>
   1a244:	stur	xzr, [x29, #-8]
   1a248:	tbnz	w24, #31, 1a2c0 <__gmpz_ior@@Base+0x114>
   1a24c:	ldrsw	x9, [x19]
   1a250:	neg	x25, x23
   1a254:	cmp	x25, x9
   1a258:	b.gt	1a638 <__gmpz_ior@@Base+0x48c>
   1a25c:	cmp	x25, #0xfe0
   1a260:	lsl	x1, x25, #3
   1a264:	b.hi	1a654 <__gmpz_ior@@Base+0x4a8>  // b.pmore
   1a268:	add	x9, x1, #0xf
   1a26c:	mov	x8, sp
   1a270:	and	x9, x9, #0xfffffffffffffff0
   1a274:	sub	x24, x8, x9
   1a278:	mov	sp, x24
   1a27c:	ldr	x9, [x26, #8]
   1a280:	ldr	x8, [x9]
   1a284:	sub	x10, x8, #0x1
   1a288:	str	x10, [x24]
   1a28c:	cbz	x8, 1a328 <__gmpz_ior@@Base+0x17c>
   1a290:	cmn	w23, #0x2
   1a294:	b.gt	1a37c <__gmpz_ior@@Base+0x1d0>
   1a298:	cmp	x9, x24
   1a29c:	b.eq	1a37c <__gmpz_ior@@Base+0x1d0>  // b.none
   1a2a0:	add	x8, x23, #0x1
   1a2a4:	add	x10, x24, #0x8
   1a2a8:	add	x9, x9, #0x8
   1a2ac:	ldr	x11, [x9], #8
   1a2b0:	adds	x8, x8, #0x1
   1a2b4:	str	x11, [x10], #8
   1a2b8:	b.cc	1a2ac <__gmpz_ior@@Base+0x100>  // b.lo, b.ul, b.last
   1a2bc:	b	1a37c <__gmpz_ior@@Base+0x1d0>
   1a2c0:	neg	x23, x20
   1a2c4:	cmp	x23, #0x7f0
   1a2c8:	lsl	x1, x23, #4
   1a2cc:	b.hi	1a664 <__gmpz_ior@@Base+0x4b8>  // b.pmore
   1a2d0:	add	x9, x1, #0xf
   1a2d4:	mov	x8, sp
   1a2d8:	and	x9, x9, #0xfffffffffffffff0
   1a2dc:	sub	x1, x8, x9
   1a2e0:	mov	sp, x1
   1a2e4:	ldr	x8, [x21]
   1a2e8:	add	x22, x1, x23, lsl #3
   1a2ec:	sub	x9, x8, #0x1
   1a2f0:	str	x9, [x1]
   1a2f4:	cbz	x8, 1a438 <__gmpz_ior@@Base+0x28c>
   1a2f8:	cmn	w24, #0x2
   1a2fc:	b.gt	1a490 <__gmpz_ior@@Base+0x2e4>
   1a300:	cmp	x21, x1
   1a304:	b.eq	1a490 <__gmpz_ior@@Base+0x2e4>  // b.none
   1a308:	add	x8, x20, #0x1
   1a30c:	add	x9, x1, #0x8
   1a310:	add	x10, x21, #0x8
   1a314:	ldr	x11, [x10], #8
   1a318:	adds	x8, x8, #0x1
   1a31c:	str	x11, [x9], #8
   1a320:	b.cc	1a314 <__gmpz_ior@@Base+0x168>  // b.lo, b.ul, b.last
   1a324:	b	1a490 <__gmpz_ior@@Base+0x2e4>
   1a328:	mov	x10, #0xfffffffffffffff8    	// #-8
   1a32c:	mov	w8, #0x1                   	// #1
   1a330:	cmp	x8, x25
   1a334:	b.ge	1a37c <__gmpz_ior@@Base+0x1d0>  // b.tcont
   1a338:	ldr	x11, [x9, x8, lsl #3]
   1a33c:	sub	x10, x10, #0x8
   1a340:	sub	x12, x11, #0x1
   1a344:	str	x12, [x24, x8, lsl #3]
   1a348:	add	x8, x8, #0x1
   1a34c:	cbz	x11, 1a330 <__gmpz_ior@@Base+0x184>
   1a350:	cmp	x9, x24
   1a354:	b.eq	1a37c <__gmpz_ior@@Base+0x1d0>  // b.none
   1a358:	cmp	x8, x25
   1a35c:	b.ge	1a37c <__gmpz_ior@@Base+0x1d0>  // b.tcont
   1a360:	sub	x9, x9, x10
   1a364:	sub	x10, x24, x10
   1a368:	ldr	x11, [x9], #8
   1a36c:	sub	x25, x25, #0x1
   1a370:	cmp	x8, x25
   1a374:	str	x11, [x10], #8
   1a378:	b.ne	1a368 <__gmpz_ior@@Base+0x1bc>  // b.any
   1a37c:	mvn	x8, x23
   1a380:	ldr	x8, [x24, x8, lsl #3]
   1a384:	cmp	x8, #0x0
   1a388:	csetm	x8, eq  // eq = none
   1a38c:	sub	x23, x8, x23
   1a390:	subs	x2, x23, x20
   1a394:	b.le	1a3b0 <__gmpz_ior@@Base+0x204>
   1a398:	add	x0, x22, x20, lsl #3
   1a39c:	add	x1, x24, x20, lsl #3
   1a3a0:	bl	ca70 <__gmpn_copyi@plt>
   1a3a4:	cbz	x23, 1a42c <__gmpz_ior@@Base+0x280>
   1a3a8:	cbnz	x20, 1a3dc <__gmpz_ior@@Base+0x230>
   1a3ac:	b	1a3f0 <__gmpz_ior@@Base+0x244>
   1a3b0:	sub	x8, x21, #0x8
   1a3b4:	sub	x9, x24, #0x8
   1a3b8:	subs	x10, x23, #0x1
   1a3bc:	b.lt	1a424 <__gmpz_ior@@Base+0x278>  // b.tstop
   1a3c0:	ldr	x11, [x8, x23, lsl #3]
   1a3c4:	ldr	x12, [x9, x23, lsl #3]
   1a3c8:	mov	x23, x10
   1a3cc:	bics	xzr, x12, x11
   1a3d0:	b.eq	1a3b8 <__gmpz_ior@@Base+0x20c>  // b.none
   1a3d4:	add	x23, x10, #0x1
   1a3d8:	mov	x20, x23
   1a3dc:	mov	x0, x22
   1a3e0:	mov	x1, x24
   1a3e4:	mov	x2, x21
   1a3e8:	mov	x3, x20
   1a3ec:	bl	c070 <__gmpn_andn_n@plt>
   1a3f0:	ldr	x8, [x22]
   1a3f4:	adds	x8, x8, #0x1
   1a3f8:	str	x8, [x22]
   1a3fc:	b.cc	1a5f0 <__gmpz_ior@@Base+0x444>  // b.lo, b.ul, b.last
   1a400:	mov	w8, #0x1                   	// #1
   1a404:	cmp	x8, x23
   1a408:	b.ge	1a5e4 <__gmpz_ior@@Base+0x438>  // b.tcont
   1a40c:	ldr	x9, [x22, x8, lsl #3]
   1a410:	adds	x9, x9, #0x1
   1a414:	str	x9, [x22, x8, lsl #3]
   1a418:	add	x8, x8, #0x1
   1a41c:	b.cs	1a404 <__gmpz_ior@@Base+0x258>  // b.hs, b.nlast
   1a420:	b	1a5f0 <__gmpz_ior@@Base+0x444>
   1a424:	mov	x20, x23
   1a428:	cbnz	x23, 1a3a8 <__gmpz_ior@@Base+0x1fc>
   1a42c:	mov	w23, #0x1                   	// #1
   1a430:	str	x23, [x22]
   1a434:	b	1a5f0 <__gmpz_ior@@Base+0x444>
   1a438:	mov	x9, #0xfffffffffffffff8    	// #-8
   1a43c:	mov	w8, #0x1                   	// #1
   1a440:	cmp	x8, x23
   1a444:	b.ge	1a490 <__gmpz_ior@@Base+0x2e4>  // b.tcont
   1a448:	ldr	x10, [x21, x8, lsl #3]
   1a44c:	sub	x9, x9, #0x8
   1a450:	sub	x11, x10, #0x1
   1a454:	str	x11, [x1, x8, lsl #3]
   1a458:	add	x8, x8, #0x1
   1a45c:	cbz	x10, 1a440 <__gmpz_ior@@Base+0x294>
   1a460:	cmp	x21, x1
   1a464:	b.eq	1a490 <__gmpz_ior@@Base+0x2e4>  // b.none
   1a468:	cmp	x8, x23
   1a46c:	b.ge	1a490 <__gmpz_ior@@Base+0x2e4>  // b.tcont
   1a470:	sub	x10, x21, x9
   1a474:	sub	x9, x1, x9
   1a478:	mov	x11, x23
   1a47c:	ldr	x12, [x10], #8
   1a480:	sub	x11, x11, #0x1
   1a484:	cmp	x8, x11
   1a488:	str	x12, [x9], #8
   1a48c:	b.ne	1a47c <__gmpz_ior@@Base+0x2d0>  // b.any
   1a490:	ldr	x8, [x26, #8]
   1a494:	ldr	x9, [x8]
   1a498:	sub	x10, x9, #0x1
   1a49c:	str	x10, [x22]
   1a4a0:	cbz	x9, 1a4d8 <__gmpz_ior@@Base+0x32c>
   1a4a4:	cmn	w24, #0x2
   1a4a8:	b.gt	1a548 <__gmpz_ior@@Base+0x39c>
   1a4ac:	cmp	x8, x22
   1a4b0:	b.eq	1a548 <__gmpz_ior@@Base+0x39c>  // b.none
   1a4b4:	sub	x10, x1, x20, lsl #3
   1a4b8:	add	x9, x20, #0x1
   1a4bc:	add	x10, x10, #0x8
   1a4c0:	add	x8, x8, #0x8
   1a4c4:	ldr	x11, [x8], #8
   1a4c8:	adds	x9, x9, #0x1
   1a4cc:	str	x11, [x10], #8
   1a4d0:	b.cc	1a4c4 <__gmpz_ior@@Base+0x318>  // b.lo, b.ul, b.last
   1a4d4:	b	1a548 <__gmpz_ior@@Base+0x39c>
   1a4d8:	mov	w9, #0x10                  	// #16
   1a4dc:	sub	x11, x9, x20, lsl #3
   1a4e0:	add	x9, x11, x1
   1a4e4:	mov	x10, #0xfffffffffffffff8    	// #-8
   1a4e8:	sub	x12, x9, #0x10
   1a4ec:	mov	w9, #0x1                   	// #1
   1a4f0:	cmp	x9, x23
   1a4f4:	b.ge	1a548 <__gmpz_ior@@Base+0x39c>  // b.tcont
   1a4f8:	ldr	x13, [x8, x9, lsl #3]
   1a4fc:	sub	x10, x10, #0x8
   1a500:	sub	x14, x13, #0x1
   1a504:	str	x14, [x12, x9, lsl #3]
   1a508:	add	x9, x9, #0x1
   1a50c:	cbz	x13, 1a4f0 <__gmpz_ior@@Base+0x344>
   1a510:	cmp	x8, x22
   1a514:	b.eq	1a548 <__gmpz_ior@@Base+0x39c>  // b.none
   1a518:	cmp	x9, x23
   1a51c:	b.ge	1a548 <__gmpz_ior@@Base+0x39c>  // b.tcont
   1a520:	add	x11, x11, x1
   1a524:	sub	x8, x8, x10
   1a528:	sub	x10, x11, x10
   1a52c:	sub	x10, x10, #0x10
   1a530:	mov	x11, x23
   1a534:	ldr	x12, [x8], #8
   1a538:	sub	x11, x11, #0x1
   1a53c:	cmp	x9, x11
   1a540:	str	x12, [x10], #8
   1a544:	b.ne	1a534 <__gmpz_ior@@Base+0x388>  // b.any
   1a548:	sub	x8, x1, x20, lsl #3
   1a54c:	sub	x9, x1, x20, lsl #4
   1a550:	mov	x10, xzr
   1a554:	sub	x8, x8, #0x8
   1a558:	sub	x9, x9, #0x8
   1a55c:	add	x21, x23, x10
   1a560:	mov	x24, x10
   1a564:	cmp	x21, #0x1
   1a568:	b.lt	1a580 <__gmpz_ior@@Base+0x3d4>  // b.tstop
   1a56c:	ldr	x10, [x8, x24, lsl #3]
   1a570:	ldr	x11, [x9, x24, lsl #3]
   1a574:	and	x11, x11, x10
   1a578:	sub	x10, x24, #0x1
   1a57c:	cbz	x11, 1a55c <__gmpz_ior@@Base+0x3b0>
   1a580:	ldrsw	x8, [x19]
   1a584:	cmp	x21, x8
   1a588:	b.ge	1a674 <__gmpz_ior@@Base+0x4c8>  // b.tcont
   1a58c:	ldr	x23, [x19, #8]
   1a590:	cmp	x20, x24
   1a594:	b.ne	1a5a8 <__gmpz_ior@@Base+0x3fc>  // b.any
   1a598:	mov	w8, #0x1                   	// #1
   1a59c:	str	x8, [x23]
   1a5a0:	mov	w8, #0xffffffff            	// #-1
   1a5a4:	b	1a5f4 <__gmpz_ior@@Base+0x448>
   1a5a8:	mov	x0, x23
   1a5ac:	mov	x2, x22
   1a5b0:	mov	x3, x21
   1a5b4:	bl	c280 <__gmpn_and_n@plt>
   1a5b8:	sub	x8, x23, x20, lsl #3
   1a5bc:	str	xzr, [x8, x24, lsl #3]
   1a5c0:	ldr	x9, [x23]
   1a5c4:	adds	x9, x9, #0x1
   1a5c8:	str	x9, [x23], #8
   1a5cc:	b.cs	1a5c0 <__gmpz_ior@@Base+0x414>  // b.hs, b.nlast
   1a5d0:	lsl	x9, x24, #3
   1a5d4:	ldr	w8, [x8, x9]
   1a5d8:	sub	w8, w20, w8
   1a5dc:	sub	w8, w8, w24
   1a5e0:	b	1a5f4 <__gmpz_ior@@Base+0x448>
   1a5e4:	mov	w8, #0x1                   	// #1
   1a5e8:	str	x8, [x22, x23, lsl #3]
   1a5ec:	add	x23, x23, #0x1
   1a5f0:	neg	w8, w23
   1a5f4:	str	w8, [x19, #4]
   1a5f8:	ldur	x0, [x29, #-8]
   1a5fc:	cbnz	x0, 1a630 <__gmpz_ior@@Base+0x484>
   1a600:	mov	sp, x29
   1a604:	ldp	x20, x19, [sp, #64]
   1a608:	ldp	x22, x21, [sp, #48]
   1a60c:	ldp	x24, x23, [sp, #32]
   1a610:	ldp	x26, x25, [sp, #16]
   1a614:	ldp	x29, x30, [sp], #80
   1a618:	ret
   1a61c:	mov	x0, x19
   1a620:	mov	x1, x20
   1a624:	bl	c090 <__gmpz_realloc@plt>
   1a628:	mov	x22, x0
   1a62c:	b	1a214 <__gmpz_ior@@Base+0x68>
   1a630:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1a634:	b	1a600 <__gmpz_ior@@Base+0x454>
   1a638:	mov	x0, x19
   1a63c:	mov	x1, x25
   1a640:	mov	x21, x8
   1a644:	bl	c090 <__gmpz_realloc@plt>
   1a648:	ldr	x21, [x21, #8]
   1a64c:	mov	x22, x0
   1a650:	b	1a25c <__gmpz_ior@@Base+0xb0>
   1a654:	sub	x0, x29, #0x8
   1a658:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1a65c:	mov	x24, x0
   1a660:	b	1a27c <__gmpz_ior@@Base+0xd0>
   1a664:	sub	x0, x29, #0x8
   1a668:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1a66c:	mov	x1, x0
   1a670:	b	1a2e4 <__gmpz_ior@@Base+0x138>
   1a674:	add	x8, x23, x24
   1a678:	add	x8, x8, #0x1
   1a67c:	mov	x0, x19
   1a680:	mov	x23, x1
   1a684:	mov	x1, x8
   1a688:	bl	c090 <__gmpz_realloc@plt>
   1a68c:	mov	x1, x23
   1a690:	mov	x23, x0
   1a694:	b	1a590 <__gmpz_ior@@Base+0x3e4>

000000000001a698 <__gmpz_init_set@@Base>:
   1a698:	stp	x29, x30, [sp, #-48]!
   1a69c:	stp	x22, x21, [sp, #16]
   1a6a0:	stp	x20, x19, [sp, #32]
   1a6a4:	ldrsw	x22, [x1, #4]
   1a6a8:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1a6ac:	mov	x20, x0
   1a6b0:	mov	x29, sp
   1a6b4:	cmp	x22, #0x0
   1a6b8:	cneg	x21, x22, mi  // mi = first
   1a6bc:	cmp	x21, #0x1
   1a6c0:	csinc	x8, x21, xzr, gt
   1a6c4:	str	w8, [x0]
   1a6c8:	ldr	x9, [x9, #3840]
   1a6cc:	sbfiz	x0, x8, #3, #32
   1a6d0:	mov	x19, x1
   1a6d4:	ldr	x9, [x9]
   1a6d8:	blr	x9
   1a6dc:	str	x0, [x20, #8]
   1a6e0:	ldr	x1, [x19, #8]
   1a6e4:	mov	x2, x21
   1a6e8:	bl	ca70 <__gmpn_copyi@plt>
   1a6ec:	str	w22, [x20, #4]
   1a6f0:	ldp	x20, x19, [sp, #32]
   1a6f4:	ldp	x22, x21, [sp, #16]
   1a6f8:	ldp	x29, x30, [sp], #48
   1a6fc:	ret

000000000001a700 <__gmpz_init_set_d@@Base>:
   1a700:	adrp	x8, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   1a704:	add	x8, x8, #0x290
   1a708:	stp	xzr, x8, [x0]
   1a70c:	b	c8b0 <__gmpz_set_d@plt>

000000000001a710 <__gmpz_init_set_si@@Base>:
   1a710:	stp	x29, x30, [sp, #-32]!
   1a714:	mov	w8, #0x1                   	// #1
   1a718:	stp	x20, x19, [sp, #16]
   1a71c:	str	w8, [x0]
   1a720:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1a724:	ldr	x8, [x8, #3840]
   1a728:	mov	x19, x0
   1a72c:	mov	w0, #0x8                   	// #8
   1a730:	mov	x29, sp
   1a734:	ldr	x8, [x8]
   1a738:	mov	x20, x1
   1a73c:	blr	x8
   1a740:	cmp	x20, #0x0
   1a744:	cneg	x8, x20, mi  // mi = first
   1a748:	cset	w9, ne  // ne = any
   1a74c:	csetm	w10, ne  // ne = any
   1a750:	str	x0, [x19, #8]
   1a754:	str	x8, [x0]
   1a758:	csel	w8, w9, w10, ge  // ge = tcont
   1a75c:	str	w8, [x19, #4]
   1a760:	ldp	x20, x19, [sp, #16]
   1a764:	ldp	x29, x30, [sp], #32
   1a768:	ret

000000000001a76c <__gmpz_init_set_str@@Base>:
   1a76c:	adrp	x8, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   1a770:	add	x8, x8, #0x298
   1a774:	stp	xzr, x8, [x0]
   1a778:	b	c0e0 <__gmpz_set_str@plt>

000000000001a77c <__gmpz_init_set_ui@@Base>:
   1a77c:	stp	x29, x30, [sp, #-32]!
   1a780:	mov	w8, #0x1                   	// #1
   1a784:	stp	x20, x19, [sp, #16]
   1a788:	str	w8, [x0]
   1a78c:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1a790:	ldr	x8, [x8, #3840]
   1a794:	mov	x19, x0
   1a798:	mov	w0, #0x8                   	// #8
   1a79c:	mov	x29, sp
   1a7a0:	ldr	x8, [x8]
   1a7a4:	mov	x20, x1
   1a7a8:	blr	x8
   1a7ac:	cmp	x20, #0x0
   1a7b0:	cset	w8, ne  // ne = any
   1a7b4:	str	x0, [x19, #8]
   1a7b8:	str	x20, [x0]
   1a7bc:	str	w8, [x19, #4]
   1a7c0:	ldp	x20, x19, [sp, #16]
   1a7c4:	ldp	x29, x30, [sp], #32
   1a7c8:	ret

000000000001a7cc <__gmpz_jacobi@@Base>:
   1a7cc:	stp	x29, x30, [sp, #-80]!
   1a7d0:	stp	x26, x25, [sp, #16]
   1a7d4:	stp	x24, x23, [sp, #32]
   1a7d8:	stp	x22, x21, [sp, #48]
   1a7dc:	stp	x20, x19, [sp, #64]
   1a7e0:	mov	x29, sp
   1a7e4:	sub	sp, sp, #0x10
   1a7e8:	ldr	x8, [x0, #8]
   1a7ec:	ldrsw	x10, [x0, #4]
   1a7f0:	ldrsw	x13, [x1, #4]
   1a7f4:	ldr	x9, [x8]
   1a7f8:	cbz	w13, 1a8d8 <__gmpz_jacobi@@Base+0x10c>
   1a7fc:	ldr	x3, [x1, #8]
   1a800:	ldr	x11, [x3]
   1a804:	cbz	w10, 1a8f0 <__gmpz_jacobi@@Base+0x124>
   1a808:	orr	w12, w11, w9
   1a80c:	tbz	w12, #0, 1a90c <__gmpz_jacobi@@Base+0x140>
   1a810:	and	w12, w10, w13
   1a814:	cmp	w13, #0x0
   1a818:	lsr	w12, w12, #30
   1a81c:	cneg	x4, x13, lt  // lt = tstop
   1a820:	cbz	x11, 1aad8 <__gmpz_jacobi@@Base+0x30c>
   1a824:	rbit	x13, x11
   1a828:	clz	x20, x13
   1a82c:	and	w12, w12, #0x2
   1a830:	cmp	x4, #0x2
   1a834:	lsr	x19, x11, x20
   1a838:	b.lt	1a868 <__gmpz_jacobi@@Base+0x9c>  // b.tstop
   1a83c:	cbz	w20, 1a868 <__gmpz_jacobi@@Base+0x9c>
   1a840:	ldr	x11, [x3, #8]
   1a844:	neg	x13, x20
   1a848:	cmp	x4, #0x2
   1a84c:	lsl	x13, x11, x13
   1a850:	orr	x19, x13, x19
   1a854:	b.ne	1a868 <__gmpz_jacobi@@Base+0x9c>  // b.any
   1a858:	lsr	x11, x11, x20
   1a85c:	cmp	x11, #0x0
   1a860:	mov	w11, #0x1                   	// #1
   1a864:	cinc	x4, x11, ne  // ne = any
   1a868:	and	w11, w19, w10, asr #31
   1a86c:	cmp	w10, #0x0
   1a870:	eor	w26, w11, w12
   1a874:	cneg	x10, x10, lt  // lt = tstop
   1a878:	cbz	x9, 1aae8 <__gmpz_jacobi@@Base+0x31c>
   1a87c:	cmp	x10, x4
   1a880:	b.ge	1a930 <__gmpz_jacobi@@Base+0x164>  // b.tcont
   1a884:	rbit	x11, x9
   1a888:	clz	x20, x11
   1a88c:	cmp	x10, #0x2
   1a890:	lsr	x21, x9, x20
   1a894:	b.lt	1a8c4 <__gmpz_jacobi@@Base+0xf8>  // b.tstop
   1a898:	cbz	w20, 1a8c4 <__gmpz_jacobi@@Base+0xf8>
   1a89c:	ldr	x9, [x8, #8]
   1a8a0:	neg	x11, x20
   1a8a4:	cmp	x10, #0x2
   1a8a8:	lsl	x11, x9, x11
   1a8ac:	orr	x21, x11, x21
   1a8b0:	b.ne	1a8c4 <__gmpz_jacobi@@Base+0xf8>  // b.any
   1a8b4:	lsr	x9, x9, x20
   1a8b8:	cmp	x9, #0x0
   1a8bc:	mov	w9, #0x1                   	// #1
   1a8c0:	cinc	x10, x9, ne  // ne = any
   1a8c4:	and	w9, w21, w19
   1a8c8:	eor	w26, w26, w9
   1a8cc:	mov	x22, x10
   1a8d0:	mov	x23, x8
   1a8d4:	b	1a948 <__gmpz_jacobi@@Base+0x17c>
   1a8d8:	cmp	w10, #0x1
   1a8dc:	b.eq	1a8e8 <__gmpz_jacobi@@Base+0x11c>  // b.none
   1a8e0:	cmn	w10, #0x1
   1a8e4:	b.ne	1a90c <__gmpz_jacobi@@Base+0x140>  // b.any
   1a8e8:	cmp	x9, #0x1
   1a8ec:	b	1a904 <__gmpz_jacobi@@Base+0x138>
   1a8f0:	cmp	w13, #0x1
   1a8f4:	b.eq	1a900 <__gmpz_jacobi@@Base+0x134>  // b.none
   1a8f8:	cmn	w13, #0x1
   1a8fc:	b.ne	1a90c <__gmpz_jacobi@@Base+0x140>  // b.any
   1a900:	cmp	x11, #0x1
   1a904:	cset	w19, eq  // eq = none
   1a908:	b	1a910 <__gmpz_jacobi@@Base+0x144>
   1a90c:	mov	w19, wzr
   1a910:	mov	w0, w19
   1a914:	mov	sp, x29
   1a918:	ldp	x20, x19, [sp, #64]
   1a91c:	ldp	x22, x21, [sp, #48]
   1a920:	ldp	x24, x23, [sp, #32]
   1a924:	ldp	x26, x25, [sp, #16]
   1a928:	ldp	x29, x30, [sp], #80
   1a92c:	ret
   1a930:	mov	x21, x19
   1a934:	mov	x19, x9
   1a938:	mov	x22, x4
   1a93c:	mov	x4, x10
   1a940:	mov	x23, x3
   1a944:	mov	x3, x8
   1a948:	cmp	x22, #0x1
   1a94c:	b.ne	1a978 <__gmpz_jacobi@@Base+0x1ac>  // b.any
   1a950:	lsr	x8, x19, #1
   1a954:	eor	w8, w8, w19
   1a958:	and	w8, w8, w20, lsl #1
   1a95c:	cmp	x21, #0x1
   1a960:	eor	w20, w8, w26
   1a964:	b.ne	1a98c <__gmpz_jacobi@@Base+0x1c0>  // b.any
   1a968:	and	w8, w20, #0x2
   1a96c:	mov	w9, #0x1                   	// #1
   1a970:	sub	w19, w9, w8
   1a974:	b	1a910 <__gmpz_jacobi@@Base+0x144>
   1a978:	cmp	x4, x22, lsl #1
   1a97c:	stur	xzr, [x29, #-8]
   1a980:	b.ge	1a9b0 <__gmpz_jacobi@@Base+0x1e4>  // b.tcont
   1a984:	lsl	x1, x22, #4
   1a988:	b	1a9b8 <__gmpz_jacobi@@Base+0x1ec>
   1a98c:	cmp	x4, #0x2
   1a990:	b.lt	1aac0 <__gmpz_jacobi@@Base+0x2f4>  // b.tstop
   1a994:	cmp	x4, #0x28
   1a998:	b.lt	1aaa4 <__gmpz_jacobi@@Base+0x2d8>  // b.tstop
   1a99c:	mov	x0, x3
   1a9a0:	mov	x1, x4
   1a9a4:	mov	x2, x21
   1a9a8:	bl	c400 <__gmpn_mod_1@plt>
   1a9ac:	b	1aabc <__gmpz_jacobi@@Base+0x2f0>
   1a9b0:	lsl	x8, x4, #3
   1a9b4:	add	x1, x8, #0x8
   1a9b8:	mov	w8, #0x7f00                	// #32512
   1a9bc:	cmp	x1, x8
   1a9c0:	b.hi	1aaf8 <__gmpz_jacobi@@Base+0x32c>  // b.pmore
   1a9c4:	add	x9, x1, #0xf
   1a9c8:	mov	x8, sp
   1a9cc:	and	x9, x9, #0xfffffffffffffff0
   1a9d0:	sub	x24, x8, x9
   1a9d4:	mov	sp, x24
   1a9d8:	cmp	x4, x22
   1a9dc:	add	x25, x24, x22, lsl #3
   1a9e0:	b.le	1aa48 <__gmpz_jacobi@@Base+0x27c>
   1a9e4:	mov	x0, x25
   1a9e8:	mov	x1, x24
   1a9ec:	mov	x2, xzr
   1a9f0:	mov	x5, x23
   1a9f4:	mov	x6, x22
   1a9f8:	bl	bf10 <__gmpn_tdiv_qr@plt>
   1a9fc:	cbz	w20, 1aa5c <__gmpz_jacobi@@Base+0x290>
   1aa00:	lsr	x8, x19, #1
   1aa04:	eor	w8, w8, w19
   1aa08:	and	w8, w8, w20, lsl #1
   1aa0c:	mov	x0, x25
   1aa10:	mov	x1, x23
   1aa14:	mov	x2, x22
   1aa18:	mov	w3, w20
   1aa1c:	eor	w26, w8, w26
   1aa20:	bl	c1b0 <__gmpn_rshift@plt>
   1aa24:	lsl	x8, x22, #3
   1aa28:	sub	x8, x8, #0x8
   1aa2c:	ldr	x9, [x24, x8]
   1aa30:	ldr	x8, [x25, x8]
   1aa34:	orr	x8, x8, x9
   1aa38:	cmp	x8, #0x0
   1aa3c:	cset	w8, eq  // eq = none
   1aa40:	sub	x22, x22, x8
   1aa44:	b	1aa6c <__gmpz_jacobi@@Base+0x2a0>
   1aa48:	mov	x0, x24
   1aa4c:	mov	x1, x3
   1aa50:	mov	x2, x22
   1aa54:	bl	ca70 <__gmpn_copyi@plt>
   1aa58:	cbnz	w20, 1aa00 <__gmpz_jacobi@@Base+0x234>
   1aa5c:	mov	x0, x25
   1aa60:	mov	x1, x23
   1aa64:	mov	x2, x22
   1aa68:	bl	ca70 <__gmpn_copyi@plt>
   1aa6c:	ldr	w8, [x24]
   1aa70:	and	w3, w21, #0x2
   1aa74:	bfxil	w3, w26, #1, #1
   1aa78:	mov	x0, x24
   1aa7c:	bfi	w3, w8, #2, #2
   1aa80:	mov	x1, x25
   1aa84:	mov	x2, x22
   1aa88:	bl	cec0 <__gmpn_jacobi_n@plt>
   1aa8c:	ldur	x8, [x29, #-8]
   1aa90:	mov	w19, w0
   1aa94:	cbz	x8, 1a910 <__gmpz_jacobi@@Base+0x144>
   1aa98:	mov	x0, x8
   1aa9c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1aaa0:	b	1a910 <__gmpz_jacobi@@Base+0x144>
   1aaa4:	mov	x0, x3
   1aaa8:	mov	x1, x4
   1aaac:	mov	x2, x21
   1aab0:	mov	x3, xzr
   1aab4:	eor	w20, w20, w21
   1aab8:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   1aabc:	mov	x19, x0
   1aac0:	mov	x0, x19
   1aac4:	mov	x1, x21
   1aac8:	mov	w2, w20
   1aacc:	bl	c750 <__gmpn_jacobi_base@plt>
   1aad0:	mov	w19, w0
   1aad4:	b	1a910 <__gmpz_jacobi@@Base+0x144>
   1aad8:	ldr	x11, [x3, #8]!
   1aadc:	sub	x4, x4, #0x1
   1aae0:	cbnz	x11, 1a824 <__gmpz_jacobi@@Base+0x58>
   1aae4:	b	1aad8 <__gmpz_jacobi@@Base+0x30c>
   1aae8:	ldr	x9, [x8, #8]!
   1aaec:	sub	x10, x10, #0x1
   1aaf0:	cbnz	x9, 1a87c <__gmpz_jacobi@@Base+0xb0>
   1aaf4:	b	1aae8 <__gmpz_jacobi@@Base+0x31c>
   1aaf8:	sub	x0, x29, #0x8
   1aafc:	mov	x24, x3
   1ab00:	mov	x25, x4
   1ab04:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1ab08:	mov	x4, x25
   1ab0c:	mov	x3, x24
   1ab10:	mov	x24, x0
   1ab14:	b	1a9d8 <__gmpz_jacobi@@Base+0x20c>

000000000001ab18 <__gmpz_si_kronecker@@Base>:
   1ab18:	stp	x29, x30, [sp, #-48]!
   1ab1c:	stp	x20, x19, [sp, #32]
   1ab20:	ldrsw	x11, [x1, #4]
   1ab24:	mov	x8, x0
   1ab28:	str	x21, [sp, #16]
   1ab2c:	mov	x29, sp
   1ab30:	cbz	w11, 1ab60 <__gmpz_si_kronecker@@Base+0x48>
   1ab34:	ldr	x0, [x1, #8]
   1ab38:	lsr	x10, x8, #63
   1ab3c:	and	w9, w10, w11, lsr #31
   1ab40:	cmp	x11, #0x0
   1ab44:	ldr	x20, [x0]
   1ab48:	lsl	w9, w9, #1
   1ab4c:	cneg	x1, x11, mi  // mi = first
   1ab50:	tbnz	w20, #0, 1ab78 <__gmpz_si_kronecker@@Base+0x60>
   1ab54:	tbnz	w8, #0, 1abb0 <__gmpz_si_kronecker@@Base+0x98>
   1ab58:	mov	w0, wzr
   1ab5c:	b	1ac4c <__gmpz_si_kronecker@@Base+0x134>
   1ab60:	cmp	x8, #0x1
   1ab64:	cset	w9, eq  // eq = none
   1ab68:	cmn	x8, #0x1
   1ab6c:	cset	w8, eq  // eq = none
   1ab70:	orr	w0, w9, w8
   1ab74:	b	1ac4c <__gmpz_si_kronecker@@Base+0x134>
   1ab78:	and	w10, w20, w10, lsl #1
   1ab7c:	cmp	x8, #0x0
   1ab80:	cneg	x19, x8, mi  // mi = first
   1ab84:	eor	w21, w9, w10
   1ab88:	tbnz	w19, #0, 1abe0 <__gmpz_si_kronecker@@Base+0xc8>
   1ab8c:	cbz	x19, 1ac38 <__gmpz_si_kronecker@@Base+0x120>
   1ab90:	rbit	x8, x8
   1ab94:	lsr	x9, x20, #1
   1ab98:	clz	x8, x8
   1ab9c:	eor	w9, w9, w20
   1aba0:	lsr	x19, x19, x8
   1aba4:	and	w8, w9, w8, lsl #1
   1aba8:	eor	w21, w8, w21
   1abac:	b	1abe0 <__gmpz_si_kronecker@@Base+0xc8>
   1abb0:	cbz	x20, 1ac5c <__gmpz_si_kronecker@@Base+0x144>
   1abb4:	tbnz	w20, #0, 1abd0 <__gmpz_si_kronecker@@Base+0xb8>
   1abb8:	mov	x11, #0x8000000000000000    	// #-9223372036854775808
   1abbc:	cmp	x20, x11
   1abc0:	b.eq	1ac6c <__gmpz_si_kronecker@@Base+0x154>  // b.none
   1abc4:	rbit	x11, x20
   1abc8:	clz	x11, x11
   1abcc:	lsr	x20, x20, x11
   1abd0:	and	w10, w20, w10, lsl #1
   1abd4:	cmp	x8, #0x0
   1abd8:	eor	w21, w9, w10
   1abdc:	cneg	x19, x8, mi  // mi = first
   1abe0:	cmp	x19, #0x1
   1abe4:	b.ne	1abf8 <__gmpz_si_kronecker@@Base+0xe0>  // b.any
   1abe8:	and	w8, w21, #0x2
   1abec:	mov	w9, #0x1                   	// #1
   1abf0:	sub	w0, w9, w8
   1abf4:	b	1ac4c <__gmpz_si_kronecker@@Base+0x134>
   1abf8:	cmp	x1, #0x28
   1abfc:	b.lt	1ac0c <__gmpz_si_kronecker@@Base+0xf4>  // b.tstop
   1ac00:	mov	x2, x19
   1ac04:	bl	c400 <__gmpn_mod_1@plt>
   1ac08:	b	1ac1c <__gmpz_si_kronecker@@Base+0x104>
   1ac0c:	mov	x2, x19
   1ac10:	mov	x3, xzr
   1ac14:	eor	w21, w21, w19
   1ac18:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   1ac1c:	and	w8, w20, w19
   1ac20:	eor	w2, w21, w8
   1ac24:	mov	x1, x19
   1ac28:	ldp	x20, x19, [sp, #32]
   1ac2c:	ldr	x21, [sp, #16]
   1ac30:	ldp	x29, x30, [sp], #48
   1ac34:	b	c750 <__gmpn_jacobi_base@plt>
   1ac38:	cmp	x1, #0x1
   1ac3c:	cset	w8, eq  // eq = none
   1ac40:	cmp	x20, #0x1
   1ac44:	cset	w9, eq  // eq = none
   1ac48:	and	w0, w8, w9
   1ac4c:	ldp	x20, x19, [sp, #32]
   1ac50:	ldr	x21, [sp, #16]
   1ac54:	ldp	x29, x30, [sp], #48
   1ac58:	ret
   1ac5c:	ldr	x20, [x0, #8]!
   1ac60:	sub	x1, x1, #0x1
   1ac64:	cbnz	x20, 1abb4 <__gmpz_si_kronecker@@Base+0x9c>
   1ac68:	b	1ac5c <__gmpz_si_kronecker@@Base+0x144>
   1ac6c:	cmp	x1, #0x1
   1ac70:	b.ne	1ac84 <__gmpz_si_kronecker@@Base+0x16c>  // b.any
   1ac74:	eor	w8, w8, w8, lsr #1
   1ac78:	and	w8, w8, #0x2
   1ac7c:	eor	w8, w9, w8
   1ac80:	b	1abec <__gmpz_si_kronecker@@Base+0xd4>
   1ac84:	ldr	x11, [x0, #8]
   1ac88:	lsl	x20, x11, #1
   1ac8c:	b	1abd0 <__gmpz_si_kronecker@@Base+0xb8>

000000000001ac90 <__gmpz_ui_kronecker@@Base>:
   1ac90:	stp	x29, x30, [sp, #-48]!
   1ac94:	stp	x20, x19, [sp, #32]
   1ac98:	ldr	w8, [x1, #4]
   1ac9c:	mov	x19, x0
   1aca0:	str	x21, [sp, #16]
   1aca4:	mov	x29, sp
   1aca8:	cmp	w8, #0x0
   1acac:	cneg	w8, w8, mi  // mi = first
   1acb0:	cbz	w8, 1accc <__gmpz_ui_kronecker@@Base+0x3c>
   1acb4:	ldr	x0, [x1, #8]
   1acb8:	ldr	x20, [x0]
   1acbc:	tbnz	w20, #0, 1acd8 <__gmpz_ui_kronecker@@Base+0x48>
   1acc0:	tbnz	w19, #0, 1acfc <__gmpz_ui_kronecker@@Base+0x6c>
   1acc4:	mov	w0, wzr
   1acc8:	b	1ad6c <__gmpz_ui_kronecker@@Base+0xdc>
   1accc:	cmp	x19, #0x1
   1acd0:	cset	w0, eq  // eq = none
   1acd4:	b	1ad6c <__gmpz_ui_kronecker@@Base+0xdc>
   1acd8:	cbz	x19, 1ad58 <__gmpz_ui_kronecker@@Base+0xc8>
   1acdc:	tbnz	w19, #0, 1ad24 <__gmpz_ui_kronecker@@Base+0x94>
   1ace0:	rbit	x9, x19
   1ace4:	lsr	x10, x20, #1
   1ace8:	clz	x9, x9
   1acec:	eor	w10, w10, w20
   1acf0:	lsr	x19, x19, x9
   1acf4:	and	w21, w10, w9, lsl #1
   1acf8:	b	1ad28 <__gmpz_ui_kronecker@@Base+0x98>
   1acfc:	cbz	x20, 1ada8 <__gmpz_ui_kronecker@@Base+0x118>
   1ad00:	tbnz	w20, #0, 1ad24 <__gmpz_ui_kronecker@@Base+0x94>
   1ad04:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
   1ad08:	cmp	x20, x9
   1ad0c:	b.eq	1adb8 <__gmpz_ui_kronecker@@Base+0x128>  // b.none
   1ad10:	rbit	x9, x20
   1ad14:	clz	x9, x9
   1ad18:	mov	w21, wzr
   1ad1c:	lsr	x20, x20, x9
   1ad20:	b	1ad28 <__gmpz_ui_kronecker@@Base+0x98>
   1ad24:	mov	w21, wzr
   1ad28:	cmp	x19, #0x1
   1ad2c:	b.ne	1ad40 <__gmpz_ui_kronecker@@Base+0xb0>  // b.any
   1ad30:	and	w8, w21, #0x2
   1ad34:	mov	w9, #0x1                   	// #1
   1ad38:	sub	w0, w9, w8
   1ad3c:	b	1ad6c <__gmpz_ui_kronecker@@Base+0xdc>
   1ad40:	cmp	w8, #0x28
   1ad44:	sxtw	x1, w8
   1ad48:	b.lt	1ad7c <__gmpz_ui_kronecker@@Base+0xec>  // b.tstop
   1ad4c:	mov	x2, x19
   1ad50:	bl	c400 <__gmpn_mod_1@plt>
   1ad54:	b	1ad8c <__gmpz_ui_kronecker@@Base+0xfc>
   1ad58:	cmp	w8, #0x1
   1ad5c:	cset	w8, eq  // eq = none
   1ad60:	cmp	x20, #0x1
   1ad64:	cset	w9, eq  // eq = none
   1ad68:	and	w0, w8, w9
   1ad6c:	ldp	x20, x19, [sp, #32]
   1ad70:	ldr	x21, [sp, #16]
   1ad74:	ldp	x29, x30, [sp], #48
   1ad78:	ret
   1ad7c:	mov	x2, x19
   1ad80:	mov	x3, xzr
   1ad84:	eor	w21, w21, w19
   1ad88:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   1ad8c:	and	w8, w19, w20
   1ad90:	eor	w2, w21, w8
   1ad94:	mov	x1, x19
   1ad98:	ldp	x20, x19, [sp, #32]
   1ad9c:	ldr	x21, [sp, #16]
   1ada0:	ldp	x29, x30, [sp], #48
   1ada4:	b	c750 <__gmpn_jacobi_base@plt>
   1ada8:	ldr	x20, [x0, #8]!
   1adac:	sub	w8, w8, #0x1
   1adb0:	cbnz	x20, 1ad00 <__gmpz_ui_kronecker@@Base+0x70>
   1adb4:	b	1ada8 <__gmpz_ui_kronecker@@Base+0x118>
   1adb8:	cmp	w8, #0x1
   1adbc:	b.ne	1adcc <__gmpz_ui_kronecker@@Base+0x13c>  // b.any
   1adc0:	eor	w8, w19, w19, lsr #1
   1adc4:	and	w8, w8, #0x2
   1adc8:	b	1ad34 <__gmpz_ui_kronecker@@Base+0xa4>
   1adcc:	ldr	x9, [x0, #8]
   1add0:	mov	w21, wzr
   1add4:	lsl	x20, x9, #1
   1add8:	b	1ad28 <__gmpz_ui_kronecker@@Base+0x98>

000000000001addc <__gmpz_kronecker_si@@Base>:
   1addc:	stp	x29, x30, [sp, #-32]!
   1ade0:	stp	x20, x19, [sp, #16]
   1ade4:	ldrsw	x8, [x0, #4]
   1ade8:	mov	x29, sp
   1adec:	cbz	w8, 1ae4c <__gmpz_kronecker_si@@Base+0x70>
   1adf0:	ldr	x0, [x0, #8]
   1adf4:	lsr	x9, x1, #63
   1adf8:	and	w9, w9, w8, lsr #31
   1adfc:	cmp	x1, #0x0
   1ae00:	cneg	x19, x1, mi  // mi = first
   1ae04:	lsl	w9, w9, #1
   1ae08:	tbnz	w19, #0, 1ae34 <__gmpz_kronecker_si@@Base+0x58>
   1ae0c:	ldr	x10, [x0]
   1ae10:	cbz	x19, 1ae8c <__gmpz_kronecker_si@@Base+0xb0>
   1ae14:	tbz	w10, #0, 1aea8 <__gmpz_kronecker_si@@Base+0xcc>
   1ae18:	rbit	x11, x1
   1ae1c:	lsr	x12, x10, #1
   1ae20:	clz	x11, x11
   1ae24:	eor	w10, w12, w10
   1ae28:	and	w10, w10, w11, lsl #1
   1ae2c:	lsr	x19, x19, x11
   1ae30:	eor	w9, w10, w9
   1ae34:	cmp	x19, #0x1
   1ae38:	b.ne	1ae64 <__gmpz_kronecker_si@@Base+0x88>  // b.any
   1ae3c:	and	w8, w9, #0x2
   1ae40:	mov	w9, #0x1                   	// #1
   1ae44:	sub	w0, w9, w8
   1ae48:	b	1aeac <__gmpz_kronecker_si@@Base+0xd0>
   1ae4c:	cmp	x1, #0x1
   1ae50:	cset	w8, eq  // eq = none
   1ae54:	cmn	x1, #0x1
   1ae58:	cset	w9, eq  // eq = none
   1ae5c:	orr	w0, w8, w9
   1ae60:	b	1aeac <__gmpz_kronecker_si@@Base+0xd0>
   1ae64:	ubfx	x10, x8, #31, #1
   1ae68:	cmp	x8, #0x0
   1ae6c:	and	w10, w19, w10, lsl #1
   1ae70:	cneg	x1, x8, mi  // mi = first
   1ae74:	cmp	x1, #0x28
   1ae78:	eor	w20, w10, w9
   1ae7c:	b.lt	1aeb8 <__gmpz_kronecker_si@@Base+0xdc>  // b.tstop
   1ae80:	mov	x2, x19
   1ae84:	bl	c400 <__gmpn_mod_1@plt>
   1ae88:	b	1aec8 <__gmpz_kronecker_si@@Base+0xec>
   1ae8c:	cmp	w8, #0x1
   1ae90:	b.eq	1ae9c <__gmpz_kronecker_si@@Base+0xc0>  // b.none
   1ae94:	cmn	w8, #0x1
   1ae98:	b.ne	1aea8 <__gmpz_kronecker_si@@Base+0xcc>  // b.any
   1ae9c:	cmp	x10, #0x1
   1aea0:	cset	w0, eq  // eq = none
   1aea4:	b	1aeac <__gmpz_kronecker_si@@Base+0xd0>
   1aea8:	mov	w0, wzr
   1aeac:	ldp	x20, x19, [sp, #16]
   1aeb0:	ldp	x29, x30, [sp], #32
   1aeb4:	ret
   1aeb8:	mov	x2, x19
   1aebc:	mov	x3, xzr
   1aec0:	eor	w20, w20, w19
   1aec4:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   1aec8:	mov	x1, x19
   1aecc:	mov	w2, w20
   1aed0:	ldp	x20, x19, [sp, #16]
   1aed4:	ldp	x29, x30, [sp], #32
   1aed8:	b	c750 <__gmpn_jacobi_base@plt>

000000000001aedc <__gmpz_kronecker_ui@@Base>:
   1aedc:	stp	x29, x30, [sp, #-32]!
   1aee0:	stp	x20, x19, [sp, #16]
   1aee4:	ldrsw	x8, [x0, #4]
   1aee8:	mov	x19, x1
   1aeec:	mov	x29, sp
   1aef0:	cbz	w8, 1af30 <__gmpz_kronecker_ui@@Base+0x54>
   1aef4:	ldr	x0, [x0, #8]
   1aef8:	tbnz	w19, #0, 1af3c <__gmpz_kronecker_ui@@Base+0x60>
   1aefc:	ldr	x9, [x0]
   1af00:	cbz	x19, 1af78 <__gmpz_kronecker_ui@@Base+0x9c>
   1af04:	tbz	w9, #0, 1af90 <__gmpz_kronecker_ui@@Base+0xb4>
   1af08:	rbit	x10, x19
   1af0c:	lsr	x11, x9, #1
   1af10:	clz	x10, x10
   1af14:	eor	w9, w11, w9
   1af18:	lsr	x19, x19, x10
   1af1c:	and	w9, w9, w10, lsl #1
   1af20:	and	w10, w19, w8, lsr #30
   1af24:	and	w10, w10, #0x2
   1af28:	eor	w20, w9, w10
   1af2c:	b	1af44 <__gmpz_kronecker_ui@@Base+0x68>
   1af30:	cmp	x19, #0x1
   1af34:	cset	w0, eq  // eq = none
   1af38:	b	1af94 <__gmpz_kronecker_ui@@Base+0xb8>
   1af3c:	and	w9, w19, w8, lsr #30
   1af40:	and	w20, w9, #0x2
   1af44:	cmp	x19, #0x1
   1af48:	b.ne	1af5c <__gmpz_kronecker_ui@@Base+0x80>  // b.any
   1af4c:	and	w8, w20, #0x2
   1af50:	mov	w9, #0x1                   	// #1
   1af54:	sub	w0, w9, w8
   1af58:	b	1af94 <__gmpz_kronecker_ui@@Base+0xb8>
   1af5c:	cmp	x8, #0x0
   1af60:	cneg	x1, x8, mi  // mi = first
   1af64:	cmp	x1, #0x28
   1af68:	b.lt	1afa0 <__gmpz_kronecker_ui@@Base+0xc4>  // b.tstop
   1af6c:	mov	x2, x19
   1af70:	bl	c400 <__gmpn_mod_1@plt>
   1af74:	b	1afb0 <__gmpz_kronecker_ui@@Base+0xd4>
   1af78:	cmp	w8, #0x1
   1af7c:	b.eq	1af88 <__gmpz_kronecker_ui@@Base+0xac>  // b.none
   1af80:	cmn	w8, #0x1
   1af84:	b.ne	1af90 <__gmpz_kronecker_ui@@Base+0xb4>  // b.any
   1af88:	cmp	x9, #0x1
   1af8c:	b	1af34 <__gmpz_kronecker_ui@@Base+0x58>
   1af90:	mov	w0, wzr
   1af94:	ldp	x20, x19, [sp, #16]
   1af98:	ldp	x29, x30, [sp], #32
   1af9c:	ret
   1afa0:	mov	x2, x19
   1afa4:	mov	x3, xzr
   1afa8:	eor	w20, w20, w19
   1afac:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   1afb0:	mov	x1, x19
   1afb4:	mov	w2, w20
   1afb8:	ldp	x20, x19, [sp, #16]
   1afbc:	ldp	x29, x30, [sp], #32
   1afc0:	b	c750 <__gmpn_jacobi_base@plt>

000000000001afc4 <__gmpz_lcm@@Base>:
   1afc4:	stp	x29, x30, [sp, #-64]!
   1afc8:	str	x23, [sp, #16]
   1afcc:	stp	x22, x21, [sp, #32]
   1afd0:	stp	x20, x19, [sp, #48]
   1afd4:	mov	x29, sp
   1afd8:	sub	sp, sp, #0x10
   1afdc:	ldrsw	x8, [x1, #4]
   1afe0:	mov	x19, x0
   1afe4:	cbz	w8, 1b098 <__gmpz_lcm@@Base+0xd4>
   1afe8:	ldr	w9, [x2, #4]
   1afec:	mov	x20, x2
   1aff0:	cbz	w9, 1b098 <__gmpz_lcm@@Base+0xd4>
   1aff4:	sxtw	x9, w9
   1aff8:	cmp	x8, #0x0
   1affc:	cneg	x8, x8, mi  // mi = first
   1b000:	cmp	x9, #0x0
   1b004:	mov	x21, x1
   1b008:	cneg	x9, x9, mi  // mi = first
   1b00c:	cmp	x8, #0x1
   1b010:	b.eq	1b0a0 <__gmpz_lcm@@Base+0xdc>  // b.none
   1b014:	cmp	x9, #0x1
   1b018:	b.eq	1b0a0 <__gmpz_lcm@@Base+0xdc>  // b.none
   1b01c:	cmp	x8, #0xfe0
   1b020:	lsl	x1, x8, #3
   1b024:	str	xzr, [x29, #24]
   1b028:	stur	w8, [x29, #-16]
   1b02c:	b.hi	1b118 <__gmpz_lcm@@Base+0x154>  // b.pmore
   1b030:	add	x9, x1, #0xf
   1b034:	mov	x8, sp
   1b038:	and	x9, x9, #0xfffffffffffffff0
   1b03c:	sub	x0, x8, x9
   1b040:	mov	sp, x0
   1b044:	stur	x0, [x29, #-8]
   1b048:	sub	x0, x29, #0x10
   1b04c:	mov	x1, x21
   1b050:	mov	x2, x20
   1b054:	bl	cf90 <__gmpz_gcd@plt>
   1b058:	sub	x0, x29, #0x10
   1b05c:	sub	x2, x29, #0x10
   1b060:	mov	x1, x21
   1b064:	bl	c410 <__gmpz_divexact@plt>
   1b068:	sub	x1, x29, #0x10
   1b06c:	mov	x0, x19
   1b070:	mov	x2, x20
   1b074:	bl	c4d0 <__gmpz_mul@plt>
   1b078:	ldr	w8, [x19, #4]
   1b07c:	cmp	w8, #0x0
   1b080:	cneg	w8, w8, mi  // mi = first
   1b084:	str	w8, [x19, #4]
   1b088:	ldr	x0, [x29, #24]
   1b08c:	cbz	x0, 1b100 <__gmpz_lcm@@Base+0x13c>
   1b090:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1b094:	b	1b100 <__gmpz_lcm@@Base+0x13c>
   1b098:	str	wzr, [x19, #4]
   1b09c:	b	1b100 <__gmpz_lcm@@Base+0x13c>
   1b0a0:	ldrsw	x10, [x19]
   1b0a4:	cmp	x8, #0x1
   1b0a8:	csel	x22, x9, x8, eq  // eq = none
   1b0ac:	csel	x23, x21, x20, eq  // eq = none
   1b0b0:	csel	x20, x20, x21, eq  // eq = none
   1b0b4:	cmp	x22, x10
   1b0b8:	b.ge	1b124 <__gmpz_lcm@@Base+0x160>  // b.tcont
   1b0bc:	ldr	x8, [x23, #8]
   1b0c0:	ldr	x20, [x20, #8]
   1b0c4:	mov	x1, x22
   1b0c8:	ldr	x21, [x8]
   1b0cc:	mov	x0, x20
   1b0d0:	mov	x2, x21
   1b0d4:	bl	bfa0 <__gmpn_gcd_1@plt>
   1b0d8:	ldr	x23, [x19, #8]
   1b0dc:	udiv	x3, x21, x0
   1b0e0:	mov	x1, x20
   1b0e4:	mov	x2, x22
   1b0e8:	mov	x0, x23
   1b0ec:	bl	d4b0 <__gmpn_mul_1@plt>
   1b0f0:	cmp	x0, #0x0
   1b0f4:	cinc	w8, w22, ne  // ne = any
   1b0f8:	str	x0, [x23, x22, lsl #3]
   1b0fc:	str	w8, [x19, #4]
   1b100:	mov	sp, x29
   1b104:	ldp	x20, x19, [sp, #48]
   1b108:	ldp	x22, x21, [sp, #32]
   1b10c:	ldr	x23, [sp, #16]
   1b110:	ldp	x29, x30, [sp], #64
   1b114:	ret
   1b118:	add	x0, x29, #0x18
   1b11c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1b120:	b	1b044 <__gmpz_lcm@@Base+0x80>
   1b124:	add	x1, x22, #0x1
   1b128:	mov	x0, x19
   1b12c:	bl	c090 <__gmpz_realloc@plt>
   1b130:	b	1b0bc <__gmpz_lcm@@Base+0xf8>

000000000001b134 <__gmpz_lcm_ui@@Base>:
   1b134:	stp	x29, x30, [sp, #-64]!
   1b138:	stp	x20, x19, [sp, #48]
   1b13c:	mov	x19, x0
   1b140:	mov	w8, wzr
   1b144:	str	x23, [sp, #16]
   1b148:	stp	x22, x21, [sp, #32]
   1b14c:	mov	x29, sp
   1b150:	cbz	x2, 1b1b4 <__gmpz_lcm_ui@@Base+0x80>
   1b154:	ldr	w9, [x1, #4]
   1b158:	mov	x22, x1
   1b15c:	cbz	w9, 1b1b4 <__gmpz_lcm_ui@@Base+0x80>
   1b160:	ldrsw	x8, [x19]
   1b164:	sxtw	x9, w9
   1b168:	cmp	x9, #0x0
   1b16c:	cneg	x21, x9, mi  // mi = first
   1b170:	mov	x20, x2
   1b174:	cmp	x21, x8
   1b178:	b.ge	1b1cc <__gmpz_lcm_ui@@Base+0x98>  // b.tcont
   1b17c:	ldr	x22, [x22, #8]
   1b180:	mov	x1, x21
   1b184:	mov	x2, x20
   1b188:	mov	x0, x22
   1b18c:	bl	bfa0 <__gmpn_gcd_1@plt>
   1b190:	ldr	x23, [x19, #8]
   1b194:	udiv	x3, x20, x0
   1b198:	mov	x1, x22
   1b19c:	mov	x2, x21
   1b1a0:	mov	x0, x23
   1b1a4:	bl	d4b0 <__gmpn_mul_1@plt>
   1b1a8:	cmp	x0, #0x0
   1b1ac:	cinc	w8, w21, ne  // ne = any
   1b1b0:	str	x0, [x23, x21, lsl #3]
   1b1b4:	str	w8, [x19, #4]
   1b1b8:	ldp	x20, x19, [sp, #48]
   1b1bc:	ldp	x22, x21, [sp, #32]
   1b1c0:	ldr	x23, [sp, #16]
   1b1c4:	ldp	x29, x30, [sp], #64
   1b1c8:	ret
   1b1cc:	add	x1, x21, #0x1
   1b1d0:	mov	x0, x19
   1b1d4:	bl	c090 <__gmpz_realloc@plt>
   1b1d8:	b	1b17c <__gmpz_lcm_ui@@Base+0x48>

000000000001b1dc <__gmpz_limbs_finish@@Base>:
   1b1dc:	cmp	x1, #0x0
   1b1e0:	cneg	x9, x1, mi  // mi = first
   1b1e4:	mov	x8, x9
   1b1e8:	subs	x9, x9, #0x1
   1b1ec:	b.lt	1b200 <__gmpz_limbs_finish@@Base+0x24>  // b.tstop
   1b1f0:	ldr	x10, [x0, #8]
   1b1f4:	add	x10, x10, x8, lsl #3
   1b1f8:	ldur	x10, [x10, #-8]
   1b1fc:	cbz	x10, 1b1e4 <__gmpz_limbs_finish@@Base+0x8>
   1b200:	neg	w9, w8
   1b204:	cmp	x1, #0x0
   1b208:	csel	x8, x9, x8, lt  // lt = tstop
   1b20c:	str	w8, [x0, #4]
   1b210:	ret

000000000001b214 <__gmpz_limbs_modify@@Base>:
   1b214:	ldrsw	x8, [x0]
   1b218:	cmp	x8, x1
   1b21c:	b.lt	1b228 <__gmpz_limbs_modify@@Base+0x14>  // b.tstop
   1b220:	ldr	x0, [x0, #8]
   1b224:	ret
   1b228:	b	c090 <__gmpz_realloc@plt>

000000000001b22c <__gmpz_limbs_read@@Base>:
   1b22c:	ldr	x0, [x0, #8]
   1b230:	ret

000000000001b234 <__gmpz_limbs_write@@Base>:
   1b234:	ldrsw	x8, [x0]
   1b238:	cmp	x8, x1
   1b23c:	b.lt	1b248 <__gmpz_limbs_write@@Base+0x14>  // b.tstop
   1b240:	ldr	x0, [x0, #8]
   1b244:	ret
   1b248:	b	c090 <__gmpz_realloc@plt>

000000000001b24c <__gmpz_lucas_mod@@Base>:
   1b24c:	stp	x29, x30, [sp, #-96]!
   1b250:	stp	x22, x21, [sp, #64]
   1b254:	mov	x21, x1
   1b258:	mov	w1, #0x1                   	// #1
   1b25c:	str	x27, [sp, #16]
   1b260:	stp	x26, x25, [sp, #32]
   1b264:	stp	x24, x23, [sp, #48]
   1b268:	stp	x20, x19, [sp, #80]
   1b26c:	mov	x29, sp
   1b270:	mov	x19, x6
   1b274:	mov	x22, x5
   1b278:	mov	x20, x4
   1b27c:	mov	x25, x3
   1b280:	mov	x23, x2
   1b284:	mov	x26, x0
   1b288:	bl	c180 <__gmpz_set_ui@plt>
   1b28c:	mov	w1, #0x2                   	// #2
   1b290:	mov	x0, x20
   1b294:	bl	d280 <__gmpz_sizeinbase@plt>
   1b298:	sub	x27, x0, #0x2
   1b29c:	cmp	x27, x25
   1b2a0:	b.cc	1b47c <__gmpz_lucas_mod@@Base+0x230>  // b.lo, b.ul, b.last
   1b2a4:	mov	w1, #0x1                   	// #1
   1b2a8:	mov	x0, x21
   1b2ac:	bl	c180 <__gmpz_set_ui@plt>
   1b2b0:	neg	x24, x23
   1b2b4:	mov	x0, x22
   1b2b8:	mov	x1, x21
   1b2bc:	mov	x2, x21
   1b2c0:	bl	c4d0 <__gmpz_mul@plt>
   1b2c4:	mov	x0, x21
   1b2c8:	mov	x1, x26
   1b2cc:	mov	x2, x21
   1b2d0:	bl	c270 <__gmpz_sub@plt>
   1b2d4:	mov	x0, x19
   1b2d8:	mov	x1, x21
   1b2dc:	mov	x2, x21
   1b2e0:	bl	c4d0 <__gmpz_mul@plt>
   1b2e4:	mov	x0, x21
   1b2e8:	mov	x1, x26
   1b2ec:	mov	x2, x26
   1b2f0:	bl	c4d0 <__gmpz_mul@plt>
   1b2f4:	mov	x0, x19
   1b2f8:	mov	x1, x22
   1b2fc:	mov	x2, x19
   1b300:	bl	c270 <__gmpz_sub@plt>
   1b304:	mov	x0, x22
   1b308:	mov	x1, x21
   1b30c:	cmp	x23, #0x1
   1b310:	b.lt	1b320 <__gmpz_lucas_mod@@Base+0xd4>  // b.tstop
   1b314:	mov	x2, x23
   1b318:	bl	c890 <__gmpz_submul_ui@plt>
   1b31c:	b	1b328 <__gmpz_lucas_mod@@Base+0xdc>
   1b320:	mov	x2, x24
   1b324:	bl	d340 <__gmpz_addmul_ui@plt>
   1b328:	mov	x0, x20
   1b32c:	mov	x1, x27
   1b330:	bl	c4a0 <__gmpz_tstbit@plt>
   1b334:	cbz	w0, 1b364 <__gmpz_lucas_mod@@Base+0x118>
   1b338:	mov	x0, x19
   1b33c:	mov	x1, x19
   1b340:	mov	x2, x23
   1b344:	bl	cbd0 <__gmpz_mul_si@plt>
   1b348:	mov	x0, x19
   1b34c:	mov	x1, x22
   1b350:	mov	x2, x19
   1b354:	bl	c270 <__gmpz_sub@plt>
   1b358:	mov	x0, x22
   1b35c:	mov	x1, x19
   1b360:	bl	c5a0 <__gmpz_swap@plt>
   1b364:	mov	x0, x21
   1b368:	mov	x1, x22
   1b36c:	mov	x2, x20
   1b370:	bl	caa0 <__gmpz_tdiv_r@plt>
   1b374:	mov	x0, x26
   1b378:	mov	x1, x19
   1b37c:	mov	x2, x20
   1b380:	bl	caa0 <__gmpz_tdiv_r@plt>
   1b384:	sub	x27, x27, #0x1
   1b388:	cmp	x27, x25
   1b38c:	b.cs	1b2b4 <__gmpz_lucas_mod@@Base+0x68>  // b.hs, b.nlast
   1b390:	ldr	w8, [x21, #4]
   1b394:	cbz	w8, 1b43c <__gmpz_lucas_mod@@Base+0x1f0>
   1b398:	neg	x2, x23, lsl #1
   1b39c:	mov	x0, x22
   1b3a0:	mov	x1, x26
   1b3a4:	bl	cbd0 <__gmpz_mul_si@plt>
   1b3a8:	mov	x0, x22
   1b3ac:	mov	x1, x21
   1b3b0:	mov	x2, x22
   1b3b4:	bl	cfb0 <__gmpz_add@plt>
   1b3b8:	mov	x0, x26
   1b3bc:	mov	x1, x22
   1b3c0:	mov	x2, x20
   1b3c4:	bl	caa0 <__gmpz_tdiv_r@plt>
   1b3c8:	ldr	w8, [x26, #4]
   1b3cc:	cmp	w8, #0x0
   1b3d0:	cset	w0, eq  // eq = none
   1b3d4:	cmp	x25, #0x2
   1b3d8:	b.cc	1b460 <__gmpz_lucas_mod@@Base+0x214>  // b.lo, b.ul, b.last
   1b3dc:	cbz	w8, 1b460 <__gmpz_lucas_mod@@Base+0x214>
   1b3e0:	mov	x0, x19
   1b3e4:	mov	x1, x22
   1b3e8:	mov	x2, x22
   1b3ec:	bl	c4d0 <__gmpz_mul@plt>
   1b3f0:	mov	x0, x22
   1b3f4:	mov	x1, x21
   1b3f8:	mov	x2, x21
   1b3fc:	bl	c4d0 <__gmpz_mul@plt>
   1b400:	mov	x0, x19
   1b404:	mov	x1, x19
   1b408:	mov	x2, x22
   1b40c:	bl	c270 <__gmpz_sub@plt>
   1b410:	mov	w2, #0x2                   	// #2
   1b414:	mov	x0, x19
   1b418:	mov	x1, x19
   1b41c:	bl	cc90 <__gmpz_tdiv_q_2exp@plt>
   1b420:	mov	x0, x19
   1b424:	mov	x1, x22
   1b428:	cmp	x23, #0x1
   1b42c:	b.lt	1b444 <__gmpz_lucas_mod@@Base+0x1f8>  // b.tstop
   1b430:	mov	x2, x23
   1b434:	bl	d340 <__gmpz_addmul_ui@plt>
   1b438:	b	1b44c <__gmpz_lucas_mod@@Base+0x200>
   1b43c:	mov	w0, #0x1                   	// #1
   1b440:	b	1b460 <__gmpz_lucas_mod@@Base+0x214>
   1b444:	mov	x2, x24
   1b448:	bl	c890 <__gmpz_submul_ui@plt>
   1b44c:	mov	x0, x21
   1b450:	mov	x1, x19
   1b454:	mov	x2, x20
   1b458:	bl	caa0 <__gmpz_tdiv_r@plt>
   1b45c:	mov	w0, wzr
   1b460:	ldp	x20, x19, [sp, #80]
   1b464:	ldp	x22, x21, [sp, #64]
   1b468:	ldp	x24, x23, [sp, #48]
   1b46c:	ldp	x26, x25, [sp, #32]
   1b470:	ldr	x27, [sp, #16]
   1b474:	ldp	x29, x30, [sp], #96
   1b478:	ret
   1b47c:	mov	x0, x21
   1b480:	mov	x1, x23
   1b484:	bl	d290 <__gmpz_set_si@plt>
   1b488:	b	1b45c <__gmpz_lucas_mod@@Base+0x210>

000000000001b48c <__gmpz_lucnum_ui@@Base>:
   1b48c:	stp	x29, x30, [sp, #-80]!
   1b490:	stp	x26, x25, [sp, #16]
   1b494:	stp	x24, x23, [sp, #32]
   1b498:	stp	x22, x21, [sp, #48]
   1b49c:	stp	x20, x19, [sp, #64]
   1b4a0:	mov	x29, sp
   1b4a4:	sub	sp, sp, #0x10
   1b4a8:	mov	x20, x1
   1b4ac:	cmp	x1, #0x5c
   1b4b0:	mov	x19, x0
   1b4b4:	b.hi	1b4ec <__gmpz_lucnum_ui@@Base+0x60>  // b.pmore
   1b4b8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1b4bc:	ldr	x8, [x8, #3808]
   1b4c0:	ldr	w9, [x19]
   1b4c4:	add	x8, x8, x20, lsl #3
   1b4c8:	ldp	x8, x10, [x8]
   1b4cc:	cmp	w9, #0x0
   1b4d0:	add	x20, x10, x8, lsl #1
   1b4d4:	b.le	1b73c <__gmpz_lucnum_ui@@Base+0x2b0>
   1b4d8:	ldr	x0, [x19, #8]
   1b4dc:	mov	w8, #0x1                   	// #1
   1b4e0:	str	x20, [x0]
   1b4e4:	str	w8, [x19, #4]
   1b4e8:	b	1b720 <__gmpz_lucnum_ui@@Base+0x294>
   1b4ec:	lsr	x8, x20, #5
   1b4f0:	mov	w9, #0x17                  	// #23
   1b4f4:	ldrsw	x10, [x19]
   1b4f8:	mul	x8, x8, x9
   1b4fc:	lsr	x24, x8, #6
   1b500:	add	x22, x24, #0x6
   1b504:	cmp	x22, x10
   1b508:	b.gt	1b74c <__gmpz_lucnum_ui@@Base+0x2c0>
   1b50c:	ldr	x21, [x19, #8]
   1b510:	mov	w23, #0xf6c0                	// #63168
   1b514:	movk	w23, #0x3, lsl #16
   1b518:	cmp	x24, #0xfda
   1b51c:	lsl	x1, x22, #3
   1b520:	stur	xzr, [x29, #-8]
   1b524:	b.hi	1b760 <__gmpz_lucnum_ui@@Base+0x2d4>  // b.pmore
   1b528:	add	x9, x1, #0xf
   1b52c:	mov	x8, sp
   1b530:	and	x9, x9, #0x7ffffffffffffff0
   1b534:	sub	x0, x8, x9
   1b538:	mov	sp, x0
   1b53c:	mov	w26, wzr
   1b540:	mov	x22, x21
   1b544:	mov	x21, x0
   1b548:	lsr	x2, x20, #1
   1b54c:	tbnz	w20, #0, 1b598 <__gmpz_lucnum_ui@@Base+0x10c>
   1b550:	cmp	x20, #0xb9
   1b554:	add	w26, w26, #0x1
   1b558:	mov	x0, x22
   1b55c:	mov	x20, x2
   1b560:	b.hi	1b540 <__gmpz_lucnum_ui@@Base+0xb4>  // b.pmore
   1b564:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1b568:	ldr	x8, [x8, #3808]
   1b56c:	sbfiz	x9, x2, #3, #32
   1b570:	mov	w23, #0x1                   	// #1
   1b574:	mov	x20, x2
   1b578:	add	x10, x8, x2, lsl #3
   1b57c:	ldr	x8, [x8, x9]
   1b580:	ldr	x9, [x10, #8]
   1b584:	mov	x0, x21
   1b588:	add	x8, x9, x8, lsl #1
   1b58c:	str	x8, [x21]
   1b590:	mov	x21, x22
   1b594:	b	1b69c <__gmpz_lucnum_ui@@Base+0x210>
   1b598:	lsr	x8, x20, #6
   1b59c:	mov	w9, #0x17                  	// #23
   1b5a0:	mul	x8, x8, x9
   1b5a4:	lsr	x9, x8, #3
   1b5a8:	add	x10, x23, #0x80
   1b5ac:	and	x9, x9, #0xffffffffffffff8
   1b5b0:	cmp	x8, x10
   1b5b4:	add	x1, x9, #0x20
   1b5b8:	b.cs	1b774 <__gmpz_lucnum_ui@@Base+0x2e8>  // b.hs, b.nlast
   1b5bc:	add	x9, x1, #0xf
   1b5c0:	mov	x8, sp
   1b5c4:	and	x9, x9, #0x3ffffffffffffff0
   1b5c8:	sub	x23, x8, x9
   1b5cc:	mov	sp, x23
   1b5d0:	mov	x0, x21
   1b5d4:	mov	x1, x23
   1b5d8:	bl	d090 <__gmpn_fib2_ui@plt>
   1b5dc:	add	x8, x23, x0, lsl #3
   1b5e0:	ldur	x8, [x8, #-8]
   1b5e4:	mov	x24, x0
   1b5e8:	mov	x1, x23
   1b5ec:	mov	x2, x21
   1b5f0:	cmp	x8, #0x0
   1b5f4:	cset	w8, eq  // eq = none
   1b5f8:	sub	x25, x0, x8
   1b5fc:	mov	x0, x21
   1b600:	mov	x3, x24
   1b604:	bl	cc60 <__gmpn_addlsh1_n@plt>
   1b608:	cmp	x0, #0x0
   1b60c:	str	x0, [x21, x24, lsl #3]
   1b610:	cinc	x24, x24, ne  // ne = any
   1b614:	mov	x0, x22
   1b618:	mov	x1, x21
   1b61c:	mov	x2, x24
   1b620:	mov	x3, x23
   1b624:	mov	x4, x25
   1b628:	bl	ccf0 <__gmpn_mul@plt>
   1b62c:	cmp	x0, #0x0
   1b630:	add	x8, x24, x25
   1b634:	cset	w9, eq  // eq = none
   1b638:	sub	x23, x8, x9
   1b63c:	mov	x0, x22
   1b640:	mov	x1, x22
   1b644:	mov	x2, x22
   1b648:	mov	x3, x23
   1b64c:	bl	cbc0 <__gmpn_addlsh2_n@plt>
   1b650:	str	x0, [x22, x23, lsl #3]
   1b654:	ldr	x8, [x22]
   1b658:	cmp	x0, #0x0
   1b65c:	cinc	x23, x23, ne  // ne = any
   1b660:	tbnz	w20, #1, 1b68c <__gmpz_lucnum_ui@@Base+0x200>
   1b664:	sub	x9, x8, #0x4
   1b668:	cmp	x8, #0x3
   1b66c:	str	x9, [x22]
   1b670:	b.hi	1b694 <__gmpz_lucnum_ui@@Base+0x208>  // b.pmore
   1b674:	add	x8, x22, #0x8
   1b678:	ldr	x9, [x8]
   1b67c:	sub	x10, x9, #0x1
   1b680:	str	x10, [x8], #8
   1b684:	cbz	x9, 1b678 <__gmpz_lucnum_ui@@Base+0x1ec>
   1b688:	b	1b694 <__gmpz_lucnum_ui@@Base+0x208>
   1b68c:	add	x8, x8, #0x4
   1b690:	str	x8, [x22]
   1b694:	mov	x0, x22
   1b698:	cbz	w26, 1b714 <__gmpz_lucnum_ui@@Base+0x288>
   1b69c:	mov	x22, x21
   1b6a0:	mov	x21, x0
   1b6a4:	mov	x0, x22
   1b6a8:	mov	x1, x21
   1b6ac:	mov	x2, x23
   1b6b0:	bl	c900 <__gmpn_sqr@plt>
   1b6b4:	add	x8, x22, x23, lsl #4
   1b6b8:	ldur	x9, [x8, #-8]
   1b6bc:	ldr	x8, [x22]
   1b6c0:	lsl	x10, x23, #1
   1b6c4:	cmp	x9, #0x0
   1b6c8:	cset	w9, eq  // eq = none
   1b6cc:	sub	x23, x10, x9
   1b6d0:	tbnz	w20, #0, 1b6fc <__gmpz_lucnum_ui@@Base+0x270>
   1b6d4:	sub	x9, x8, #0x2
   1b6d8:	cmp	x8, #0x1
   1b6dc:	str	x9, [x22]
   1b6e0:	b.hi	1b708 <__gmpz_lucnum_ui@@Base+0x27c>  // b.pmore
   1b6e4:	add	x8, x22, #0x8
   1b6e8:	ldr	x9, [x8]
   1b6ec:	sub	x10, x9, #0x1
   1b6f0:	str	x10, [x8], #8
   1b6f4:	cbz	x9, 1b6e8 <__gmpz_lucnum_ui@@Base+0x25c>
   1b6f8:	b	1b708 <__gmpz_lucnum_ui@@Base+0x27c>
   1b6fc:	add	x8, x8, #0x2
   1b700:	mov	x20, xzr
   1b704:	str	x8, [x22]
   1b708:	subs	w26, w26, #0x1
   1b70c:	mov	x0, x22
   1b710:	b.ne	1b69c <__gmpz_lucnum_ui@@Base+0x210>  // b.any
   1b714:	str	w23, [x19, #4]
   1b718:	ldur	x0, [x29, #-8]
   1b71c:	cbnz	x0, 1b76c <__gmpz_lucnum_ui@@Base+0x2e0>
   1b720:	mov	sp, x29
   1b724:	ldp	x20, x19, [sp, #64]
   1b728:	ldp	x22, x21, [sp, #48]
   1b72c:	ldp	x24, x23, [sp, #32]
   1b730:	ldp	x26, x25, [sp, #16]
   1b734:	ldp	x29, x30, [sp], #80
   1b738:	ret
   1b73c:	mov	w1, #0x1                   	// #1
   1b740:	mov	x0, x19
   1b744:	bl	c090 <__gmpz_realloc@plt>
   1b748:	b	1b4dc <__gmpz_lucnum_ui@@Base+0x50>
   1b74c:	mov	x0, x19
   1b750:	mov	x1, x22
   1b754:	bl	c090 <__gmpz_realloc@plt>
   1b758:	mov	x21, x0
   1b75c:	b	1b510 <__gmpz_lucnum_ui@@Base+0x84>
   1b760:	sub	x0, x29, #0x8
   1b764:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1b768:	b	1b53c <__gmpz_lucnum_ui@@Base+0xb0>
   1b76c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1b770:	b	1b720 <__gmpz_lucnum_ui@@Base+0x294>
   1b774:	sub	x0, x29, #0x8
   1b778:	mov	x23, x2
   1b77c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1b780:	mov	x2, x23
   1b784:	mov	x23, x0
   1b788:	b	1b5d0 <__gmpz_lucnum_ui@@Base+0x144>

000000000001b78c <__gmpz_lucnum2_ui@@Base>:
   1b78c:	stp	x29, x30, [sp, #-64]!
   1b790:	stp	x24, x23, [sp, #16]
   1b794:	stp	x22, x21, [sp, #32]
   1b798:	stp	x20, x19, [sp, #48]
   1b79c:	mov	x29, sp
   1b7a0:	sub	sp, sp, #0x10
   1b7a4:	mov	x20, x2
   1b7a8:	mov	x19, x1
   1b7ac:	cmp	x2, #0x5c
   1b7b0:	mov	x21, x0
   1b7b4:	b.hi	1b820 <__gmpz_lucnum2_ui@@Base+0x94>  // b.pmore
   1b7b8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1b7bc:	ldr	x8, [x8, #3808]
   1b7c0:	ldr	w9, [x21]
   1b7c4:	add	x8, x8, x20, lsl #3
   1b7c8:	ldp	x22, x23, [x8]
   1b7cc:	cmp	w9, #0x0
   1b7d0:	add	x24, x23, x22, lsl #1
   1b7d4:	b.le	1b8f8 <__gmpz_lucnum2_ui@@Base+0x16c>
   1b7d8:	ldr	x0, [x21, #8]
   1b7dc:	mov	w8, #0x1                   	// #1
   1b7e0:	str	x24, [x0]
   1b7e4:	str	w8, [x21, #4]
   1b7e8:	ldr	w9, [x19]
   1b7ec:	lsl	x8, x23, #1
   1b7f0:	sub	x8, x8, x22
   1b7f4:	cmp	x20, #0x0
   1b7f8:	csinc	x21, x8, xzr, ne  // ne = any
   1b7fc:	cmp	w9, #0x0
   1b800:	b.le	1b908 <__gmpz_lucnum2_ui@@Base+0x17c>
   1b804:	ldr	x0, [x19, #8]
   1b808:	cmp	x20, #0x0
   1b80c:	mov	w8, #0xffffffff            	// #-1
   1b810:	cneg	w8, w8, ne  // ne = any
   1b814:	str	x21, [x0]
   1b818:	str	w8, [x19, #4]
   1b81c:	b	1b8e0 <__gmpz_lucnum2_ui@@Base+0x154>
   1b820:	lsr	x8, x20, #5
   1b824:	mov	w9, #0x17                  	// #23
   1b828:	mul	x8, x8, x9
   1b82c:	lsr	x23, x8, #6
   1b830:	lsl	x8, x23, #3
   1b834:	cmp	x23, #0xfdc
   1b838:	add	x1, x8, #0x20
   1b83c:	stur	xzr, [x29, #-8]
   1b840:	b.hi	1b918 <__gmpz_lucnum2_ui@@Base+0x18c>  // b.pmore
   1b844:	add	x9, x1, #0xf
   1b848:	mov	x8, sp
   1b84c:	and	x9, x9, #0x7ffffffffffffff0
   1b850:	sub	x22, x8, x9
   1b854:	mov	sp, x22
   1b858:	ldrsw	x8, [x21]
   1b85c:	add	x24, x23, #0x5
   1b860:	cmp	x24, x8
   1b864:	b.gt	1b928 <__gmpz_lucnum2_ui@@Base+0x19c>
   1b868:	ldr	x23, [x21, #8]
   1b86c:	ldrsw	x8, [x19]
   1b870:	cmp	x24, x8
   1b874:	b.gt	1b93c <__gmpz_lucnum2_ui@@Base+0x1b0>
   1b878:	ldr	x24, [x19, #8]
   1b87c:	mov	x0, x24
   1b880:	mov	x1, x22
   1b884:	mov	x2, x20
   1b888:	bl	d090 <__gmpn_fib2_ui@plt>
   1b88c:	mov	x20, x0
   1b890:	mov	x0, x23
   1b894:	mov	x1, x24
   1b898:	mov	x2, x22
   1b89c:	mov	x3, x20
   1b8a0:	bl	cc60 <__gmpn_addlsh1_n@plt>
   1b8a4:	cmp	x0, #0x0
   1b8a8:	str	x0, [x23, x20, lsl #3]
   1b8ac:	cinc	w8, w20, ne  // ne = any
   1b8b0:	mov	x0, x24
   1b8b4:	mov	x1, x22
   1b8b8:	mov	x2, x24
   1b8bc:	mov	x3, x20
   1b8c0:	str	w8, [x21, #4]
   1b8c4:	bl	d0b0 <__gmpn_rsblsh1_n@plt>
   1b8c8:	cmp	x0, #0x0
   1b8cc:	cinc	w8, w20, ne  // ne = any
   1b8d0:	str	x0, [x24, x20, lsl #3]
   1b8d4:	str	w8, [x19, #4]
   1b8d8:	ldur	x0, [x29, #-8]
   1b8dc:	cbnz	x0, 1b950 <__gmpz_lucnum2_ui@@Base+0x1c4>
   1b8e0:	mov	sp, x29
   1b8e4:	ldp	x20, x19, [sp, #48]
   1b8e8:	ldp	x22, x21, [sp, #32]
   1b8ec:	ldp	x24, x23, [sp, #16]
   1b8f0:	ldp	x29, x30, [sp], #64
   1b8f4:	ret
   1b8f8:	mov	w1, #0x1                   	// #1
   1b8fc:	mov	x0, x21
   1b900:	bl	c090 <__gmpz_realloc@plt>
   1b904:	b	1b7dc <__gmpz_lucnum2_ui@@Base+0x50>
   1b908:	mov	w1, #0x1                   	// #1
   1b90c:	mov	x0, x19
   1b910:	bl	c090 <__gmpz_realloc@plt>
   1b914:	b	1b808 <__gmpz_lucnum2_ui@@Base+0x7c>
   1b918:	sub	x0, x29, #0x8
   1b91c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1b920:	mov	x22, x0
   1b924:	b	1b858 <__gmpz_lucnum2_ui@@Base+0xcc>
   1b928:	mov	x0, x21
   1b92c:	mov	x1, x24
   1b930:	bl	c090 <__gmpz_realloc@plt>
   1b934:	mov	x23, x0
   1b938:	b	1b86c <__gmpz_lucnum2_ui@@Base+0xe0>
   1b93c:	mov	x0, x19
   1b940:	mov	x1, x24
   1b944:	bl	c090 <__gmpz_realloc@plt>
   1b948:	mov	x24, x0
   1b94c:	b	1b87c <__gmpz_lucnum2_ui@@Base+0xf0>
   1b950:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1b954:	b	1b8e0 <__gmpz_lucnum2_ui@@Base+0x154>

000000000001b958 <__gmpz_millerrabin@@Base>:
   1b958:	stp	x29, x30, [sp, #-48]!
   1b95c:	stp	x22, x21, [sp, #16]
   1b960:	stp	x20, x19, [sp, #32]
   1b964:	mov	x29, sp
   1b968:	sub	sp, sp, #0x70
   1b96c:	stur	xzr, [x29, #-104]
   1b970:	ldrsw	x8, [x0, #4]
   1b974:	mov	w20, w1
   1b978:	mov	w9, #0x7f00                	// #32512
   1b97c:	mov	x19, x0
   1b980:	add	x8, x8, #0x1
   1b984:	lsl	x1, x8, #3
   1b988:	cmp	x1, x9
   1b98c:	stur	w8, [x29, #-16]
   1b990:	b.hi	1bb7c <__gmpz_millerrabin@@Base+0x224>  // b.pmore
   1b994:	add	x9, x1, #0xf
   1b998:	mov	x8, sp
   1b99c:	and	x9, x9, #0xfffffffffffffff0
   1b9a0:	sub	x0, x8, x9
   1b9a4:	mov	sp, x0
   1b9a8:	stur	x0, [x29, #-8]
   1b9ac:	sub	x0, x29, #0x10
   1b9b0:	mov	w2, #0x1                   	// #1
   1b9b4:	mov	x1, x19
   1b9b8:	bl	cc90 <__gmpz_tdiv_q_2exp@plt>
   1b9bc:	ldr	w8, [x19, #4]
   1b9c0:	mov	w10, #0x7f00                	// #32512
   1b9c4:	add	w9, w8, #0x1
   1b9c8:	sbfiz	x1, x9, #3, #32
   1b9cc:	cmp	x1, x10
   1b9d0:	stur	w9, [x29, #-32]
   1b9d4:	b.hi	1bb88 <__gmpz_millerrabin@@Base+0x230>  // b.pmore
   1b9d8:	add	x10, x1, #0xf
   1b9dc:	mov	x9, sp
   1b9e0:	and	x10, x10, #0xfffffffffffffff0
   1b9e4:	sub	x0, x9, x10
   1b9e8:	mov	sp, x0
   1b9ec:	lsl	w9, w8, #1
   1b9f0:	sbfiz	x1, x9, #3, #32
   1b9f4:	mov	w10, #0x7f00                	// #32512
   1b9f8:	cmp	x1, x10
   1b9fc:	stur	x0, [x29, #-24]
   1ba00:	stur	w9, [x29, #-48]
   1ba04:	b.hi	1bb98 <__gmpz_millerrabin@@Base+0x240>  // b.pmore
   1ba08:	add	x10, x1, #0xf
   1ba0c:	mov	x9, sp
   1ba10:	and	x10, x10, #0xfffffffffffffff0
   1ba14:	sub	x0, x9, x10
   1ba18:	mov	sp, x0
   1ba1c:	sbfiz	x1, x8, #3, #32
   1ba20:	mov	w9, #0x7f00                	// #32512
   1ba24:	cmp	x1, x9
   1ba28:	stur	x0, [x29, #-40]
   1ba2c:	stur	w8, [x29, #-64]
   1ba30:	b.hi	1bba8 <__gmpz_millerrabin@@Base+0x250>  // b.pmore
   1ba34:	add	x9, x1, #0xf
   1ba38:	mov	x8, sp
   1ba3c:	and	x9, x9, #0xfffffffffffffff0
   1ba40:	sub	x0, x8, x9
   1ba44:	mov	sp, x0
   1ba48:	stur	x0, [x29, #-56]
   1ba4c:	sub	x0, x29, #0x10
   1ba50:	mov	x1, xzr
   1ba54:	bl	bf30 <__gmpz_scan1@plt>
   1ba58:	mov	x21, x0
   1ba5c:	sub	x0, x29, #0x40
   1ba60:	sub	x1, x29, #0x10
   1ba64:	mov	x2, x21
   1ba68:	bl	cc90 <__gmpz_tdiv_q_2exp@plt>
   1ba6c:	sub	x0, x29, #0x20
   1ba70:	mov	w1, #0x2                   	// #2
   1ba74:	add	x21, x21, #0x1
   1ba78:	bl	c180 <__gmpz_set_ui@plt>
   1ba7c:	sub	x1, x29, #0x20
   1ba80:	sub	x2, x29, #0x30
   1ba84:	sub	x3, x29, #0x40
   1ba88:	mov	x0, x19
   1ba8c:	mov	x4, x21
   1ba90:	bl	1bbbc <__gmpz_millerrabin@@Base+0x264>
   1ba94:	cbz	w0, 1bad4 <__gmpz_millerrabin@@Base+0x17c>
   1ba98:	sub	x1, x29, #0x20
   1ba9c:	sub	x2, x29, #0x30
   1baa0:	mov	x0, x19
   1baa4:	bl	c9e0 <__gmpz_stronglucas@plt>
   1baa8:	cbz	w0, 1bad4 <__gmpz_millerrabin@@Base+0x17c>
   1baac:	ldr	x8, [x19, #8]
   1bab0:	ldr	w9, [x19, #4]
   1bab4:	ldr	x8, [x8]
   1bab8:	lsr	x8, x8, #46
   1babc:	cmp	x8, #0x13
   1bac0:	cset	w8, cc  // cc = lo, ul, last
   1bac4:	cmp	w9, w8
   1bac8:	b.ne	1baf8 <__gmpz_millerrabin@@Base+0x1a0>  // b.any
   1bacc:	mov	w20, #0x2                   	// #2
   1bad0:	b	1bad8 <__gmpz_millerrabin@@Base+0x180>
   1bad4:	mov	w20, wzr
   1bad8:	ldur	x0, [x29, #-104]
   1badc:	cbnz	x0, 1bbb4 <__gmpz_millerrabin@@Base+0x25c>
   1bae0:	mov	w0, w20
   1bae4:	mov	sp, x29
   1bae8:	ldp	x20, x19, [sp, #32]
   1baec:	ldp	x22, x21, [sp, #16]
   1baf0:	ldp	x29, x30, [sp], #48
   1baf4:	ret
   1baf8:	cmp	w20, #0x19
   1bafc:	b.lt	1bb74 <__gmpz_millerrabin@@Base+0x21c>  // b.tstop
   1bb00:	sub	x0, x29, #0x10
   1bb04:	sub	x1, x29, #0x10
   1bb08:	mov	w2, #0x2                   	// #2
   1bb0c:	sub	w22, w20, #0x18
   1bb10:	bl	c130 <__gmpz_sub_ui@plt>
   1bb14:	sub	x0, x29, #0x60
   1bb18:	bl	c7c0 <__gmp_randinit_default@plt>
   1bb1c:	sub	x0, x29, #0x20
   1bb20:	sub	x1, x29, #0x60
   1bb24:	sub	x2, x29, #0x10
   1bb28:	bl	c910 <__gmpz_urandomm@plt>
   1bb2c:	sub	x0, x29, #0x20
   1bb30:	sub	x1, x29, #0x20
   1bb34:	mov	w2, #0x3                   	// #3
   1bb38:	bl	c8d0 <__gmpz_add_ui@plt>
   1bb3c:	sub	x1, x29, #0x20
   1bb40:	sub	x2, x29, #0x30
   1bb44:	sub	x3, x29, #0x40
   1bb48:	mov	x0, x19
   1bb4c:	mov	x4, x21
   1bb50:	bl	1bbbc <__gmpz_millerrabin@@Base+0x264>
   1bb54:	cmp	w22, #0x2
   1bb58:	mov	w20, w0
   1bb5c:	b.lt	1bb68 <__gmpz_millerrabin@@Base+0x210>  // b.tstop
   1bb60:	sub	w22, w22, #0x1
   1bb64:	cbnz	w20, 1bb1c <__gmpz_millerrabin@@Base+0x1c4>
   1bb68:	sub	x0, x29, #0x60
   1bb6c:	bl	c4b0 <__gmp_randclear@plt>
   1bb70:	b	1bad8 <__gmpz_millerrabin@@Base+0x180>
   1bb74:	mov	w20, #0x1                   	// #1
   1bb78:	b	1bad8 <__gmpz_millerrabin@@Base+0x180>
   1bb7c:	sub	x0, x29, #0x68
   1bb80:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1bb84:	b	1b9a8 <__gmpz_millerrabin@@Base+0x50>
   1bb88:	sub	x0, x29, #0x68
   1bb8c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1bb90:	ldr	w8, [x19, #4]
   1bb94:	b	1b9ec <__gmpz_millerrabin@@Base+0x94>
   1bb98:	sub	x0, x29, #0x68
   1bb9c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1bba0:	ldr	w8, [x19, #4]
   1bba4:	b	1ba1c <__gmpz_millerrabin@@Base+0xc4>
   1bba8:	sub	x0, x29, #0x68
   1bbac:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1bbb0:	b	1ba48 <__gmpz_millerrabin@@Base+0xf0>
   1bbb4:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1bbb8:	b	1bae0 <__gmpz_millerrabin@@Base+0x188>
   1bbbc:	stp	x29, x30, [sp, #-64]!
   1bbc0:	stp	x22, x21, [sp, #32]
   1bbc4:	mov	x21, x0
   1bbc8:	stp	x20, x19, [sp, #48]
   1bbcc:	mov	x20, x2
   1bbd0:	mov	x0, x2
   1bbd4:	mov	x2, x3
   1bbd8:	mov	x3, x21
   1bbdc:	str	x23, [sp, #16]
   1bbe0:	mov	x29, sp
   1bbe4:	mov	x19, x4
   1bbe8:	bl	c390 <__gmpz_powm@plt>
   1bbec:	mov	w1, #0x1                   	// #1
   1bbf0:	mov	x0, x20
   1bbf4:	mov	w22, #0x1                   	// #1
   1bbf8:	bl	d210 <__gmpz_cmp_ui@plt>
   1bbfc:	cbz	w0, 1bc74 <__gmpz_millerrabin@@Base+0x31c>
   1bc00:	mov	x0, x20
   1bc04:	mov	x1, x21
   1bc08:	bl	1bc8c <__gmpz_millerrabin@@Base+0x334>
   1bc0c:	cbz	w0, 1bc18 <__gmpz_millerrabin@@Base+0x2c0>
   1bc10:	mov	w22, #0x1                   	// #1
   1bc14:	b	1bc74 <__gmpz_millerrabin@@Base+0x31c>
   1bc18:	cmp	x19, #0x2
   1bc1c:	b.cc	1bc70 <__gmpz_millerrabin@@Base+0x318>  // b.lo, b.ul, b.last
   1bc20:	mov	w23, #0x2                   	// #2
   1bc24:	mov	w2, #0x2                   	// #2
   1bc28:	mov	x0, x20
   1bc2c:	mov	x1, x20
   1bc30:	mov	x3, x21
   1bc34:	bl	d2e0 <__gmpz_powm_ui@plt>
   1bc38:	mov	x0, x20
   1bc3c:	mov	x1, x21
   1bc40:	bl	1bc8c <__gmpz_millerrabin@@Base+0x334>
   1bc44:	cbnz	w0, 1bc10 <__gmpz_millerrabin@@Base+0x2b8>
   1bc48:	mov	w1, #0x1                   	// #1
   1bc4c:	mov	x0, x20
   1bc50:	bl	d210 <__gmpz_cmp_ui@plt>
   1bc54:	cmp	w0, #0x1
   1bc58:	mov	w22, wzr
   1bc5c:	b.lt	1bc74 <__gmpz_millerrabin@@Base+0x31c>  // b.tstop
   1bc60:	cmp	x23, x19
   1bc64:	add	x23, x23, #0x1
   1bc68:	b.cc	1bc24 <__gmpz_millerrabin@@Base+0x2cc>  // b.lo, b.ul, b.last
   1bc6c:	b	1bc74 <__gmpz_millerrabin@@Base+0x31c>
   1bc70:	mov	w22, wzr
   1bc74:	mov	w0, w22
   1bc78:	ldp	x20, x19, [sp, #48]
   1bc7c:	ldp	x22, x21, [sp, #32]
   1bc80:	ldr	x23, [sp, #16]
   1bc84:	ldp	x29, x30, [sp], #64
   1bc88:	ret
   1bc8c:	ldrsw	x8, [x1, #4]
   1bc90:	ldr	w9, [x0, #4]
   1bc94:	cmp	w9, w8
   1bc98:	b.ne	1bcdc <__gmpz_millerrabin@@Base+0x384>  // b.any
   1bc9c:	ldr	x9, [x0, #8]
   1bca0:	ldr	x10, [x1, #8]
   1bca4:	ldr	x11, [x9]
   1bca8:	ldr	x12, [x10]
   1bcac:	eor	x11, x11, #0x1
   1bcb0:	cmp	x11, x12
   1bcb4:	b.ne	1bcdc <__gmpz_millerrabin@@Base+0x384>  // b.any
   1bcb8:	sub	x9, x9, #0x8
   1bcbc:	sub	x10, x10, #0x8
   1bcc0:	cmp	x8, #0x2
   1bcc4:	b.lt	1bce4 <__gmpz_millerrabin@@Base+0x38c>  // b.tstop
   1bcc8:	ldr	x11, [x9, x8, lsl #3]
   1bccc:	ldr	x12, [x10, x8, lsl #3]
   1bcd0:	sub	x8, x8, #0x1
   1bcd4:	cmp	x11, x12
   1bcd8:	b.eq	1bcc0 <__gmpz_millerrabin@@Base+0x368>  // b.none
   1bcdc:	mov	w0, wzr
   1bce0:	ret
   1bce4:	mov	w0, #0x1                   	// #1
   1bce8:	ret

000000000001bcec <__gmpz_mod@@Base>:
   1bcec:	stp	x29, x30, [sp, #-48]!
   1bcf0:	stp	x22, x21, [sp, #16]
   1bcf4:	stp	x20, x19, [sp, #32]
   1bcf8:	mov	x29, sp
   1bcfc:	sub	sp, sp, #0x20
   1bd00:	stur	xzr, [x29, #-24]
   1bd04:	ldr	w8, [x2, #4]
   1bd08:	mov	x22, x2
   1bd0c:	mov	x19, x0
   1bd10:	mov	x20, x1
   1bd14:	cmp	w8, #0x0
   1bd18:	cneg	w21, w8, mi  // mi = first
   1bd1c:	cmp	x0, x2
   1bd20:	b.eq	1bd30 <__gmpz_mod@@Base+0x44>  // b.none
   1bd24:	ldr	x8, [x22, #8]
   1bd28:	stur	x8, [x29, #-8]
   1bd2c:	b	1bd60 <__gmpz_mod@@Base+0x74>
   1bd30:	cmp	w21, #0xfe0
   1bd34:	lsl	x1, x21, #3
   1bd38:	b.hi	1bdb0 <__gmpz_mod@@Base+0xc4>  // b.pmore
   1bd3c:	add	x9, x1, #0xf
   1bd40:	mov	x8, sp
   1bd44:	and	x9, x9, #0xffffffff0
   1bd48:	sub	x0, x8, x9
   1bd4c:	mov	sp, x0
   1bd50:	stur	x0, [x29, #-8]
   1bd54:	ldr	x1, [x22, #8]
   1bd58:	mov	x2, x21
   1bd5c:	bl	ca70 <__gmpn_copyi@plt>
   1bd60:	sub	x2, x29, #0x10
   1bd64:	mov	x0, x19
   1bd68:	mov	x1, x20
   1bd6c:	stur	w21, [x29, #-12]
   1bd70:	bl	caa0 <__gmpz_tdiv_r@plt>
   1bd74:	ldr	w8, [x19, #4]
   1bd78:	tbz	w8, #31, 1bd8c <__gmpz_mod@@Base+0xa0>
   1bd7c:	sub	x2, x29, #0x10
   1bd80:	mov	x0, x19
   1bd84:	mov	x1, x19
   1bd88:	bl	cfb0 <__gmpz_add@plt>
   1bd8c:	ldur	x0, [x29, #-24]
   1bd90:	cbnz	x0, 1bda8 <__gmpz_mod@@Base+0xbc>
   1bd94:	mov	sp, x29
   1bd98:	ldp	x20, x19, [sp, #32]
   1bd9c:	ldp	x22, x21, [sp, #16]
   1bda0:	ldp	x29, x30, [sp], #48
   1bda4:	ret
   1bda8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1bdac:	b	1bd94 <__gmpz_mod@@Base+0xa8>
   1bdb0:	sub	x0, x29, #0x18
   1bdb4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1bdb8:	b	1bd50 <__gmpz_mod@@Base+0x64>

000000000001bdbc <__gmpz_mul@@Base>:
   1bdbc:	stp	x29, x30, [sp, #-96]!
   1bdc0:	stp	x28, x27, [sp, #16]
   1bdc4:	stp	x26, x25, [sp, #32]
   1bdc8:	stp	x24, x23, [sp, #48]
   1bdcc:	stp	x22, x21, [sp, #64]
   1bdd0:	stp	x20, x19, [sp, #80]
   1bdd4:	mov	x29, sp
   1bdd8:	sub	sp, sp, #0x10
   1bddc:	ldrsw	x8, [x1, #4]
   1bde0:	ldrsw	x9, [x2, #4]
   1bde4:	mov	x19, x0
   1bde8:	cmp	x8, #0x0
   1bdec:	cneg	x10, x8, mi  // mi = first
   1bdf0:	cmp	x9, #0x0
   1bdf4:	cneg	x11, x9, mi  // mi = first
   1bdf8:	cmp	x10, x11
   1bdfc:	csel	x21, x10, x11, lt  // lt = tstop
   1be00:	csel	x20, x11, x10, lt  // lt = tstop
   1be04:	csel	x23, x1, x2, lt  // lt = tstop
   1be08:	csel	x22, x2, x1, lt  // lt = tstop
   1be0c:	cmp	x21, #0x1
   1be10:	eor	w27, w9, w8
   1be14:	b.eq	1be24 <__gmpz_mul@@Base+0x68>  // b.none
   1be18:	cbnz	x21, 1be6c <__gmpz_mul@@Base+0xb0>
   1be1c:	str	wzr, [x19, #4]
   1be20:	b	1c004 <__gmpz_mul@@Base+0x248>
   1be24:	ldrsw	x8, [x19]
   1be28:	cmp	x20, x8
   1be2c:	b.ge	1c024 <__gmpz_mul@@Base+0x268>  // b.tcont
   1be30:	ldr	x21, [x19, #8]
   1be34:	ldr	x8, [x23, #8]
   1be38:	ldr	x1, [x22, #8]
   1be3c:	mov	x0, x21
   1be40:	mov	x2, x20
   1be44:	ldr	x3, [x8]
   1be48:	bl	d4b0 <__gmpn_mul_1@plt>
   1be4c:	cmp	x0, #0x0
   1be50:	cinc	x8, x20, ne  // ne = any
   1be54:	neg	w9, w8
   1be58:	cmp	w27, #0x0
   1be5c:	csel	x8, x8, x9, ge  // ge = tcont
   1be60:	str	x0, [x21, x20, lsl #3]
   1be64:	str	w8, [x19, #4]
   1be68:	b	1c004 <__gmpz_mul@@Base+0x248>
   1be6c:	ldrsw	x9, [x19]
   1be70:	ldr	x22, [x22, #8]
   1be74:	ldr	x23, [x23, #8]
   1be78:	ldr	x24, [x19, #8]
   1be7c:	add	x28, x20, x21
   1be80:	cmp	x28, x9
   1be84:	stp	x9, xzr, [x29, #-16]
   1be88:	b.le	1bee8 <__gmpz_mul@@Base+0x12c>
   1be8c:	cbz	w9, 1beb8 <__gmpz_mul@@Base+0xfc>
   1be90:	cmp	x24, x22
   1be94:	b.eq	1bebc <__gmpz_mul@@Base+0x100>  // b.none
   1be98:	cmp	x24, x23
   1be9c:	b.eq	1bebc <__gmpz_mul@@Base+0x100>  // b.none
   1bea0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1bea4:	ldr	x8, [x8, #4016]
   1bea8:	lsl	x1, x9, #3
   1beac:	mov	x0, x24
   1beb0:	ldr	x8, [x8]
   1beb4:	blr	x8
   1beb8:	mov	x24, xzr
   1bebc:	str	w28, [x19]
   1bec0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1bec4:	ldr	x8, [x8, #3840]
   1bec8:	lsl	x0, x28, #3
   1becc:	ldr	x8, [x8]
   1bed0:	blr	x8
   1bed4:	mov	x26, x22
   1bed8:	str	x0, [x19, #8]
   1bedc:	mov	x25, x23
   1bee0:	mov	x22, x0
   1bee4:	b	1bf84 <__gmpz_mul@@Base+0x1c8>
   1bee8:	cmp	x24, x22
   1beec:	b.eq	1bf08 <__gmpz_mul@@Base+0x14c>  // b.none
   1bef0:	cmp	x24, x23
   1bef4:	b.eq	1bf48 <__gmpz_mul@@Base+0x18c>  // b.none
   1bef8:	mov	x26, x22
   1befc:	mov	x25, x23
   1bf00:	mov	x22, x24
   1bf04:	b	1bf40 <__gmpz_mul@@Base+0x184>
   1bf08:	cmp	x20, #0xfe0
   1bf0c:	lsl	x1, x20, #3
   1bf10:	b.hi	1c040 <__gmpz_mul@@Base+0x284>  // b.pmore
   1bf14:	add	x9, x1, #0xf
   1bf18:	mov	x8, sp
   1bf1c:	and	x9, x9, #0xfffffffffffffff0
   1bf20:	sub	x26, x8, x9
   1bf24:	mov	sp, x26
   1bf28:	cmp	x22, x23
   1bf2c:	mov	x0, x26
   1bf30:	mov	x1, x22
   1bf34:	mov	x2, x20
   1bf38:	csel	x25, x26, x23, eq  // eq = none
   1bf3c:	bl	ca70 <__gmpn_copyi@plt>
   1bf40:	mov	x24, xzr
   1bf44:	b	1bf84 <__gmpz_mul@@Base+0x1c8>
   1bf48:	cmp	x21, #0xfe0
   1bf4c:	lsl	x1, x21, #3
   1bf50:	b.hi	1c050 <__gmpz_mul@@Base+0x294>  // b.pmore
   1bf54:	add	x9, x1, #0xf
   1bf58:	mov	x8, sp
   1bf5c:	and	x9, x9, #0xfffffffffffffff0
   1bf60:	sub	x25, x8, x9
   1bf64:	mov	sp, x25
   1bf68:	mov	x0, x25
   1bf6c:	mov	x1, x23
   1bf70:	mov	x2, x21
   1bf74:	bl	ca70 <__gmpn_copyi@plt>
   1bf78:	mov	x24, xzr
   1bf7c:	mov	x26, x22
   1bf80:	mov	x22, x23
   1bf84:	cmp	x26, x25
   1bf88:	b.eq	1bfa8 <__gmpz_mul@@Base+0x1ec>  // b.none
   1bf8c:	mov	x0, x22
   1bf90:	mov	x1, x26
   1bf94:	mov	x2, x20
   1bf98:	mov	x3, x25
   1bf9c:	mov	x4, x21
   1bfa0:	bl	ccf0 <__gmpn_mul@plt>
   1bfa4:	b	1bfc0 <__gmpz_mul@@Base+0x204>
   1bfa8:	mov	x0, x22
   1bfac:	mov	x1, x26
   1bfb0:	mov	x2, x20
   1bfb4:	bl	c900 <__gmpn_sqr@plt>
   1bfb8:	add	x8, x22, x28, lsl #3
   1bfbc:	ldur	x0, [x8, #-8]
   1bfc0:	cmp	x0, #0x0
   1bfc4:	cset	w8, eq  // eq = none
   1bfc8:	sub	x8, x28, x8
   1bfcc:	neg	w9, w8
   1bfd0:	cmp	w27, #0x0
   1bfd4:	csel	x8, x9, x8, lt  // lt = tstop
   1bfd8:	str	w8, [x19, #4]
   1bfdc:	cbz	x24, 1bffc <__gmpz_mul@@Base+0x240>
   1bfe0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1bfe4:	ldr	x8, [x8, #4016]
   1bfe8:	ldur	x9, [x29, #-16]
   1bfec:	mov	x0, x24
   1bff0:	ldr	x8, [x8]
   1bff4:	lsl	x1, x9, #3
   1bff8:	blr	x8
   1bffc:	ldur	x0, [x29, #-8]
   1c000:	cbnz	x0, 1c038 <__gmpz_mul@@Base+0x27c>
   1c004:	mov	sp, x29
   1c008:	ldp	x20, x19, [sp, #80]
   1c00c:	ldp	x22, x21, [sp, #64]
   1c010:	ldp	x24, x23, [sp, #48]
   1c014:	ldp	x26, x25, [sp, #32]
   1c018:	ldp	x28, x27, [sp, #16]
   1c01c:	ldp	x29, x30, [sp], #96
   1c020:	ret
   1c024:	add	x1, x20, #0x1
   1c028:	mov	x0, x19
   1c02c:	bl	c090 <__gmpz_realloc@plt>
   1c030:	mov	x21, x0
   1c034:	b	1be34 <__gmpz_mul@@Base+0x78>
   1c038:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1c03c:	b	1c004 <__gmpz_mul@@Base+0x248>
   1c040:	sub	x0, x29, #0x8
   1c044:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1c048:	mov	x26, x0
   1c04c:	b	1bf28 <__gmpz_mul@@Base+0x16c>
   1c050:	sub	x0, x29, #0x8
   1c054:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1c058:	mov	x25, x0
   1c05c:	b	1bf68 <__gmpz_mul@@Base+0x1ac>

000000000001c060 <__gmpz_mul_2exp@@Base>:
   1c060:	stp	x29, x30, [sp, #-80]!
   1c064:	stp	x24, x23, [sp, #32]
   1c068:	stp	x22, x21, [sp, #48]
   1c06c:	stp	x20, x19, [sp, #64]
   1c070:	ldr	w8, [x1, #4]
   1c074:	mov	x20, x1
   1c078:	mov	x19, x0
   1c07c:	str	x25, [sp, #16]
   1c080:	cmp	w8, #0x0
   1c084:	cneg	w22, w8, mi  // mi = first
   1c088:	mov	x29, sp
   1c08c:	cbz	w22, 1c0d8 <__gmpz_mul_2exp@@Base+0x78>
   1c090:	ldrsw	x8, [x19]
   1c094:	add	x24, x22, x2, lsr #6
   1c098:	mov	x23, x2
   1c09c:	lsr	x25, x2, #6
   1c0a0:	cmp	x24, x8
   1c0a4:	b.ge	1c124 <__gmpz_mul_2exp@@Base+0xc4>  // b.tcont
   1c0a8:	ldr	x21, [x19, #8]
   1c0ac:	ldr	x1, [x20, #8]
   1c0b0:	ands	x3, x23, #0x3f
   1c0b4:	add	x0, x21, x25, lsl #3
   1c0b8:	mov	x2, x22
   1c0bc:	b.eq	1c0e0 <__gmpz_mul_2exp@@Base+0x80>  // b.none
   1c0c0:	bl	c190 <__gmpn_lshift@plt>
   1c0c4:	cmp	x0, #0x0
   1c0c8:	str	x0, [x21, x24, lsl #3]
   1c0cc:	cinc	x24, x24, ne  // ne = any
   1c0d0:	cbnz	x25, 1c0e8 <__gmpz_mul_2exp@@Base+0x88>
   1c0d4:	b	1c0f8 <__gmpz_mul_2exp@@Base+0x98>
   1c0d8:	mov	x24, xzr
   1c0dc:	b	1c0f8 <__gmpz_mul_2exp@@Base+0x98>
   1c0e0:	bl	c010 <__gmpn_copyd@plt>
   1c0e4:	cbz	x25, 1c0f8 <__gmpz_mul_2exp@@Base+0x98>
   1c0e8:	lsl	x2, x25, #3
   1c0ec:	mov	x0, x21
   1c0f0:	mov	w1, wzr
   1c0f4:	bl	c610 <memset@plt>
   1c0f8:	ldr	w8, [x20, #4]
   1c0fc:	neg	w9, w24
   1c100:	ldr	x25, [sp, #16]
   1c104:	cmp	w8, #0x0
   1c108:	csel	x8, x24, x9, ge  // ge = tcont
   1c10c:	str	w8, [x19, #4]
   1c110:	ldp	x20, x19, [sp, #64]
   1c114:	ldp	x22, x21, [sp, #48]
   1c118:	ldp	x24, x23, [sp, #32]
   1c11c:	ldp	x29, x30, [sp], #80
   1c120:	ret
   1c124:	add	x1, x24, #0x1
   1c128:	mov	x0, x19
   1c12c:	bl	c090 <__gmpz_realloc@plt>
   1c130:	mov	x21, x0
   1c134:	b	1c0ac <__gmpz_mul_2exp@@Base+0x4c>

000000000001c138 <__gmpz_mul_si@@Base>:
   1c138:	stp	x29, x30, [sp, #-80]!
   1c13c:	stp	x20, x19, [sp, #64]
   1c140:	mov	x19, x0
   1c144:	mov	w8, wzr
   1c148:	str	x25, [sp, #16]
   1c14c:	stp	x24, x23, [sp, #32]
   1c150:	stp	x22, x21, [sp, #48]
   1c154:	mov	x29, sp
   1c158:	cbz	x2, 1c1bc <__gmpz_mul_si@@Base+0x84>
   1c15c:	ldr	w9, [x1, #4]
   1c160:	mov	x21, x1
   1c164:	cbz	w9, 1c1bc <__gmpz_mul_si@@Base+0x84>
   1c168:	ldrsw	x8, [x19]
   1c16c:	sxtw	x25, w9
   1c170:	cmp	x25, #0x0
   1c174:	cneg	x22, x25, mi  // mi = first
   1c178:	cmp	x2, #0x0
   1c17c:	mov	x20, x2
   1c180:	cneg	x23, x2, mi  // mi = first
   1c184:	cmp	x22, x8
   1c188:	b.ge	1c1d8 <__gmpz_mul_si@@Base+0xa0>  // b.tcont
   1c18c:	ldr	x24, [x19, #8]
   1c190:	ldr	x1, [x21, #8]
   1c194:	mov	x0, x24
   1c198:	mov	x2, x22
   1c19c:	mov	x3, x23
   1c1a0:	bl	d4b0 <__gmpn_mul_1@plt>
   1c1a4:	cmp	x0, #0x0
   1c1a8:	lsr	x8, x20, #63
   1c1ac:	cinc	w9, w22, ne  // ne = any
   1c1b0:	cmp	w8, w25, lsr #31
   1c1b4:	cneg	w8, w9, ne  // ne = any
   1c1b8:	str	x0, [x24, x22, lsl #3]
   1c1bc:	str	w8, [x19, #4]
   1c1c0:	ldp	x20, x19, [sp, #64]
   1c1c4:	ldp	x22, x21, [sp, #48]
   1c1c8:	ldp	x24, x23, [sp, #32]
   1c1cc:	ldr	x25, [sp, #16]
   1c1d0:	ldp	x29, x30, [sp], #80
   1c1d4:	ret
   1c1d8:	add	x1, x22, #0x1
   1c1dc:	mov	x0, x19
   1c1e0:	bl	c090 <__gmpz_realloc@plt>
   1c1e4:	mov	x24, x0
   1c1e8:	b	1c190 <__gmpz_mul_si@@Base+0x58>

000000000001c1ec <__gmpz_mul_ui@@Base>:
   1c1ec:	stp	x29, x30, [sp, #-64]!
   1c1f0:	stp	x20, x19, [sp, #48]
   1c1f4:	mov	x19, x0
   1c1f8:	mov	w8, wzr
   1c1fc:	stp	x24, x23, [sp, #16]
   1c200:	stp	x22, x21, [sp, #32]
   1c204:	mov	x29, sp
   1c208:	cbz	x2, 1c260 <__gmpz_mul_ui@@Base+0x74>
   1c20c:	ldr	w9, [x1, #4]
   1c210:	mov	x21, x1
   1c214:	cbz	w9, 1c260 <__gmpz_mul_ui@@Base+0x74>
   1c218:	ldrsw	x8, [x19]
   1c21c:	sxtw	x24, w9
   1c220:	cmp	x24, #0x0
   1c224:	cneg	x22, x24, mi  // mi = first
   1c228:	mov	x20, x2
   1c22c:	cmp	x22, x8
   1c230:	b.ge	1c278 <__gmpz_mul_ui@@Base+0x8c>  // b.tcont
   1c234:	ldr	x23, [x19, #8]
   1c238:	ldr	x1, [x21, #8]
   1c23c:	mov	x0, x23
   1c240:	mov	x2, x22
   1c244:	mov	x3, x20
   1c248:	bl	d4b0 <__gmpn_mul_1@plt>
   1c24c:	cmp	x0, #0x0
   1c250:	cinc	w8, w22, ne  // ne = any
   1c254:	cmp	w24, #0x0
   1c258:	cneg	w8, w8, lt  // lt = tstop
   1c25c:	str	x0, [x23, x22, lsl #3]
   1c260:	str	w8, [x19, #4]
   1c264:	ldp	x20, x19, [sp, #48]
   1c268:	ldp	x22, x21, [sp, #32]
   1c26c:	ldp	x24, x23, [sp, #16]
   1c270:	ldp	x29, x30, [sp], #64
   1c274:	ret
   1c278:	add	x1, x22, #0x1
   1c27c:	mov	x0, x19
   1c280:	bl	c090 <__gmpz_realloc@plt>
   1c284:	mov	x23, x0
   1c288:	b	1c238 <__gmpz_mul_ui@@Base+0x4c>

000000000001c28c <__gmpz_n_pow_ui@@Base>:
   1c28c:	stp	x29, x30, [sp, #-96]!
   1c290:	stp	x28, x27, [sp, #16]
   1c294:	stp	x26, x25, [sp, #32]
   1c298:	stp	x24, x23, [sp, #48]
   1c29c:	stp	x22, x21, [sp, #64]
   1c2a0:	stp	x20, x19, [sp, #80]
   1c2a4:	mov	x29, sp
   1c2a8:	sub	sp, sp, #0x40
   1c2ac:	mov	x26, x0
   1c2b0:	cbz	x3, 1c37c <__gmpz_n_pow_ui@@Base+0xf0>
   1c2b4:	cbz	x2, 1c398 <__gmpz_n_pow_ui@@Base+0x10c>
   1c2b8:	ldr	x10, [x1]
   1c2bc:	ldr	x8, [x26, #8]
   1c2c0:	cmp	x2, #0x0
   1c2c4:	mov	x21, x3
   1c2c8:	cset	w11, lt  // lt = tstop
   1c2cc:	cneg	x23, x2, mi  // mi = first
   1c2d0:	mov	x9, xzr
   1c2d4:	mov	x22, x1
   1c2d8:	stur	w11, [x29, #-52]
   1c2dc:	cbnz	x10, 1c2f0 <__gmpz_n_pow_ui@@Base+0x64>
   1c2e0:	ldr	x10, [x22, #8]!
   1c2e4:	add	x9, x9, x21
   1c2e8:	sub	x23, x23, #0x1
   1c2ec:	cbz	x10, 1c2e0 <__gmpz_n_pow_ui@@Base+0x54>
   1c2f0:	rbit	x11, x10
   1c2f4:	clz	x25, x11
   1c2f8:	lsr	x24, x10, x25
   1c2fc:	mul	x10, x25, x21
   1c300:	cmp	x23, #0x2
   1c304:	add	x27, x9, x10, lsr #6
   1c308:	and	x28, x10, #0x3f
   1c30c:	stur	xzr, [x29, #-24]
   1c310:	b.eq	1c3a0 <__gmpz_n_pow_ui@@Base+0x114>  // b.none
   1c314:	cmp	x23, #0x1
   1c318:	b.eq	1c3d8 <__gmpz_n_pow_ui@@Base+0x14c>  // b.none
   1c31c:	cmp	x8, x1
   1c320:	b.eq	1c328 <__gmpz_n_pow_ui@@Base+0x9c>  // b.none
   1c324:	cbz	w25, 1c440 <__gmpz_n_pow_ui@@Base+0x1b4>
   1c328:	lsl	x1, x23, #3
   1c32c:	mov	w8, #0x7f00                	// #32512
   1c330:	cmp	x1, x8
   1c334:	b.hi	1c760 <__gmpz_n_pow_ui@@Base+0x4d4>  // b.pmore
   1c338:	add	x9, x1, #0xf
   1c33c:	mov	x8, sp
   1c340:	and	x9, x9, #0xfffffffffffffff0
   1c344:	sub	x24, x8, x9
   1c348:	mov	sp, x24
   1c34c:	mov	x0, x24
   1c350:	mov	x1, x22
   1c354:	mov	x2, x23
   1c358:	cbz	w25, 1c438 <__gmpz_n_pow_ui@@Base+0x1ac>
   1c35c:	mov	w3, w25
   1c360:	bl	c1b0 <__gmpn_rshift@plt>
   1c364:	add	x8, x24, x23, lsl #3
   1c368:	ldur	x8, [x8, #-8]
   1c36c:	cmp	x8, #0x0
   1c370:	cset	w8, eq  // eq = none
   1c374:	sub	x23, x23, x8
   1c378:	b	1c43c <__gmpz_n_pow_ui@@Base+0x1b0>
   1c37c:	ldr	w8, [x26]
   1c380:	cmp	w8, #0x0
   1c384:	b.le	1c738 <__gmpz_n_pow_ui@@Base+0x4ac>
   1c388:	ldr	x0, [x26, #8]
   1c38c:	mov	w8, #0x1                   	// #1
   1c390:	str	x8, [x0]
   1c394:	b	1c664 <__gmpz_n_pow_ui@@Base+0x3d8>
   1c398:	mov	w8, wzr
   1c39c:	b	1c664 <__gmpz_n_pow_ui@@Base+0x3d8>
   1c3a0:	ldr	x8, [x22, #8]
   1c3a4:	neg	x9, x25
   1c3a8:	cmp	w25, #0x0
   1c3ac:	lsl	x9, x8, x9
   1c3b0:	csel	x9, xzr, x9, eq  // eq = none
   1c3b4:	lsr	x8, x8, x25
   1c3b8:	orr	x24, x9, x24
   1c3bc:	cbz	x8, 1c3d8 <__gmpz_n_pow_ui@@Base+0x14c>
   1c3c0:	sub	x22, x29, #0x10
   1c3c4:	stp	x24, x8, [x29, #-16]
   1c3c8:	mov	w23, #0x2                   	// #2
   1c3cc:	mov	w25, #0x1                   	// #1
   1c3d0:	mov	x24, x8
   1c3d4:	b	1c44c <__gmpz_n_pow_ui@@Base+0x1c0>
   1c3d8:	mov	w25, #0x1                   	// #1
   1c3dc:	mov	x20, x21
   1c3e0:	lsr	x8, x24, #32
   1c3e4:	cbnz	x8, 1c430 <__gmpz_n_pow_ui@@Base+0x1a4>
   1c3e8:	tst	x20, #0x1
   1c3ec:	csinc	x8, x24, xzr, ne  // ne = any
   1c3f0:	lsr	x20, x20, #1
   1c3f4:	mul	x25, x8, x25
   1c3f8:	cbz	x20, 1c408 <__gmpz_n_pow_ui@@Base+0x17c>
   1c3fc:	mul	x24, x24, x24
   1c400:	lsr	x8, x24, #32
   1c404:	cbz	x8, 1c3e8 <__gmpz_n_pow_ui@@Base+0x15c>
   1c408:	mov	w23, #0x1                   	// #1
   1c40c:	cbz	x28, 1c450 <__gmpz_n_pow_ui@@Base+0x1c4>
   1c410:	cmp	x25, #0x1
   1c414:	b.eq	1c450 <__gmpz_n_pow_ui@@Base+0x1c4>  // b.none
   1c418:	neg	x8, x28
   1c41c:	lsr	x8, x25, x8
   1c420:	cmp	x8, #0x0
   1c424:	csel	x8, x28, xzr, eq  // eq = none
   1c428:	csel	x28, xzr, x28, eq  // eq = none
   1c42c:	lsl	x25, x25, x8
   1c430:	mov	w23, #0x1                   	// #1
   1c434:	b	1c450 <__gmpz_n_pow_ui@@Base+0x1c4>
   1c438:	bl	ca70 <__gmpn_copyi@plt>
   1c43c:	mov	x22, x24
   1c440:	add	x8, x22, x23, lsl #3
   1c444:	ldur	x24, [x8, #-8]
   1c448:	mov	w25, #0x1                   	// #1
   1c44c:	mov	x20, x21
   1c450:	clz	x8, x24
   1c454:	lsl	x9, x23, #6
   1c458:	sub	x8, x9, x8
   1c45c:	mul	x8, x8, x20
   1c460:	ldrsw	x9, [x26]
   1c464:	lsr	x8, x8, #6
   1c468:	add	x19, x8, #0x5
   1c46c:	add	x1, x19, x27
   1c470:	cmp	x1, x9
   1c474:	stur	x26, [x29, #-32]
   1c478:	b.gt	1c71c <__gmpz_n_pow_ui@@Base+0x490>
   1c47c:	ldr	x26, [x26, #8]
   1c480:	cbz	x27, 1c494 <__gmpz_n_pow_ui@@Base+0x208>
   1c484:	lsl	x2, x27, #3
   1c488:	mov	x0, x26
   1c48c:	mov	w1, wzr
   1c490:	bl	c610 <memset@plt>
   1c494:	add	x12, x26, x27, lsl #3
   1c498:	stp	x28, x27, [x29, #-48]
   1c49c:	cbz	x20, 1c508 <__gmpz_n_pow_ui@@Base+0x27c>
   1c4a0:	cmp	x23, #0x2
   1c4a4:	mvn	w8, w20
   1c4a8:	cset	w9, lt  // lt = tstop
   1c4ac:	and	x8, x8, #0x1
   1c4b0:	orr	x8, x8, x9
   1c4b4:	lsr	x8, x19, x8
   1c4b8:	cmp	x8, #0xfe0
   1c4bc:	lsl	x1, x8, #3
   1c4c0:	b.hi	1c748 <__gmpz_n_pow_ui@@Base+0x4bc>  // b.pmore
   1c4c4:	add	x9, x1, #0xf
   1c4c8:	mov	x8, sp
   1c4cc:	and	x9, x9, #0x7ffffffffffffff0
   1c4d0:	sub	x27, x8, x9
   1c4d4:	mov	sp, x27
   1c4d8:	clz	x19, x20
   1c4dc:	mov	w8, #0x3e                  	// #62
   1c4e0:	cmp	x23, #0x1
   1c4e4:	sub	w28, w8, w19
   1c4e8:	b.ne	1c518 <__gmpz_n_pow_ui@@Base+0x28c>  // b.any
   1c4ec:	tst	w28, #0x1
   1c4f0:	csel	x26, x27, x12, eq  // eq = none
   1c4f4:	cmp	w19, #0x3f
   1c4f8:	str	x24, [x26]
   1c4fc:	b.ne	1c574 <__gmpz_n_pow_ui@@Base+0x2e8>  // b.any
   1c500:	mov	w27, #0x1                   	// #1
   1c504:	b	1c5f8 <__gmpz_n_pow_ui@@Base+0x36c>
   1c508:	str	x25, [x12]
   1c50c:	mov	w27, #0x1                   	// #1
   1c510:	mov	x26, x12
   1c514:	b	1c620 <__gmpz_n_pow_ui@@Base+0x394>
   1c518:	mov	w9, #0x6996                	// #27030
   1c51c:	mov	x8, xzr
   1c520:	movk	w9, #0x9669, lsl #16
   1c524:	mov	x10, x20
   1c528:	and	x11, x10, #0x1f
   1c52c:	sxtw	x8, w8
   1c530:	lsr	x11, x9, x11
   1c534:	lsr	x10, x10, #5
   1c538:	eor	x8, x8, x11
   1c53c:	cbnz	x10, 1c528 <__gmpz_n_pow_ui@@Base+0x29c>
   1c540:	eor	w24, w28, w8
   1c544:	tst	w24, #0x1
   1c548:	csel	x26, x12, x27, eq  // eq = none
   1c54c:	mov	x0, x26
   1c550:	mov	x1, x22
   1c554:	mov	x2, x23
   1c558:	stur	x12, [x29, #-64]
   1c55c:	bl	ca70 <__gmpn_copyi@plt>
   1c560:	ldur	w25, [x29, #-52]
   1c564:	cmp	w19, #0x3f
   1c568:	b.ne	1c688 <__gmpz_n_pow_ui@@Base+0x3fc>  // b.any
   1c56c:	mov	x27, x23
   1c570:	b	1c624 <__gmpz_n_pow_ui@@Base+0x398>
   1c574:	tst	w28, #0x1
   1c578:	mov	w8, #0x3f                  	// #63
   1c57c:	csel	x22, x12, x27, eq  // eq = none
   1c580:	sub	w19, w8, w19
   1c584:	mov	w27, #0x1                   	// #1
   1c588:	mov	x0, x26
   1c58c:	mov	x26, x22
   1c590:	mov	x22, x0
   1c594:	mov	x0, x26
   1c598:	mov	x1, x22
   1c59c:	mov	x2, x27
   1c5a0:	bl	c900 <__gmpn_sqr@plt>
   1c5a4:	add	x8, x26, x27, lsl #4
   1c5a8:	ldur	x8, [x8, #-8]
   1c5ac:	lsl	x9, x27, #1
   1c5b0:	lsr	x10, x20, x28
   1c5b4:	cmp	x8, #0x0
   1c5b8:	cset	w8, eq  // eq = none
   1c5bc:	sub	x27, x9, x8
   1c5c0:	tbz	w10, #0, 1c5e4 <__gmpz_n_pow_ui@@Base+0x358>
   1c5c4:	mov	x0, x26
   1c5c8:	mov	x1, x26
   1c5cc:	mov	x2, x27
   1c5d0:	mov	x3, x24
   1c5d4:	bl	d4b0 <__gmpn_mul_1@plt>
   1c5d8:	cmp	x0, #0x0
   1c5dc:	str	x0, [x26, x27, lsl #3]
   1c5e0:	cinc	x27, x27, ne  // ne = any
   1c5e4:	sub	w19, w19, #0x1
   1c5e8:	cmp	w19, #0x0
   1c5ec:	sub	x28, x28, #0x1
   1c5f0:	mov	x0, x26
   1c5f4:	b.gt	1c58c <__gmpz_n_pow_ui@@Base+0x300>
   1c5f8:	cmp	x25, #0x1
   1c5fc:	b.eq	1c620 <__gmpz_n_pow_ui@@Base+0x394>  // b.none
   1c600:	mov	x0, x26
   1c604:	mov	x1, x26
   1c608:	mov	x2, x27
   1c60c:	mov	x3, x25
   1c610:	bl	d4b0 <__gmpn_mul_1@plt>
   1c614:	cmp	x0, #0x0
   1c618:	str	x0, [x26, x27, lsl #3]
   1c61c:	cinc	x27, x27, ne  // ne = any
   1c620:	ldur	w25, [x29, #-52]
   1c624:	ldur	x0, [x29, #-24]
   1c628:	cbnz	x0, 1c730 <__gmpz_n_pow_ui@@Base+0x4a4>
   1c62c:	ldur	x3, [x29, #-48]
   1c630:	and	w19, w21, w25
   1c634:	cbz	x3, 1c654 <__gmpz_n_pow_ui@@Base+0x3c8>
   1c638:	mov	x0, x26
   1c63c:	mov	x1, x26
   1c640:	mov	x2, x27
   1c644:	bl	c190 <__gmpn_lshift@plt>
   1c648:	cmp	x0, #0x0
   1c64c:	str	x0, [x26, x27, lsl #3]
   1c650:	cinc	x27, x27, ne  // ne = any
   1c654:	ldp	x8, x26, [x29, #-40]
   1c658:	cmp	w19, #0x0
   1c65c:	add	w8, w27, w8
   1c660:	cneg	w8, w8, ne  // ne = any
   1c664:	str	w8, [x26, #4]
   1c668:	mov	sp, x29
   1c66c:	ldp	x20, x19, [sp, #80]
   1c670:	ldp	x22, x21, [sp, #64]
   1c674:	ldp	x24, x23, [sp, #48]
   1c678:	ldp	x26, x25, [sp, #32]
   1c67c:	ldp	x28, x27, [sp, #16]
   1c680:	ldp	x29, x30, [sp], #96
   1c684:	ret
   1c688:	ldur	x9, [x29, #-64]
   1c68c:	tst	w24, #0x1
   1c690:	mov	w8, #0x3f                  	// #63
   1c694:	sub	w19, w8, w19
   1c698:	csel	x24, x27, x9, eq  // eq = none
   1c69c:	mov	x27, x23
   1c6a0:	mov	x0, x24
   1c6a4:	mov	x1, x26
   1c6a8:	mov	x2, x27
   1c6ac:	bl	c900 <__gmpn_sqr@plt>
   1c6b0:	add	x8, x24, x27, lsl #4
   1c6b4:	ldur	x8, [x8, #-8]
   1c6b8:	lsl	x9, x27, #1
   1c6bc:	lsr	x10, x20, x28
   1c6c0:	cmp	x8, #0x0
   1c6c4:	cset	w8, eq  // eq = none
   1c6c8:	sub	x27, x9, x8
   1c6cc:	tbz	w10, #0, 1c6fc <__gmpz_n_pow_ui@@Base+0x470>
   1c6d0:	mov	x0, x26
   1c6d4:	mov	x1, x24
   1c6d8:	mov	x2, x27
   1c6dc:	mov	x3, x22
   1c6e0:	mov	x4, x23
   1c6e4:	bl	ccf0 <__gmpn_mul@plt>
   1c6e8:	cmp	x0, #0x0
   1c6ec:	cset	w8, eq  // eq = none
   1c6f0:	add	x9, x27, x23
   1c6f4:	sub	x27, x9, x8
   1c6f8:	b	1c708 <__gmpz_n_pow_ui@@Base+0x47c>
   1c6fc:	mov	x0, x26
   1c700:	mov	x26, x24
   1c704:	mov	x24, x0
   1c708:	sub	w19, w19, #0x1
   1c70c:	cmp	w19, #0x0
   1c710:	sub	x28, x28, #0x1
   1c714:	b.gt	1c6a0 <__gmpz_n_pow_ui@@Base+0x414>
   1c718:	b	1c624 <__gmpz_n_pow_ui@@Base+0x398>
   1c71c:	mov	x0, x26
   1c720:	bl	c090 <__gmpz_realloc@plt>
   1c724:	mov	x26, x0
   1c728:	cbnz	x27, 1c484 <__gmpz_n_pow_ui@@Base+0x1f8>
   1c72c:	b	1c494 <__gmpz_n_pow_ui@@Base+0x208>
   1c730:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1c734:	b	1c62c <__gmpz_n_pow_ui@@Base+0x3a0>
   1c738:	mov	w1, #0x1                   	// #1
   1c73c:	mov	x0, x26
   1c740:	bl	c090 <__gmpz_realloc@plt>
   1c744:	b	1c38c <__gmpz_n_pow_ui@@Base+0x100>
   1c748:	sub	x0, x29, #0x18
   1c74c:	mov	x19, x12
   1c750:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1c754:	mov	x12, x19
   1c758:	mov	x27, x0
   1c75c:	b	1c4d8 <__gmpz_n_pow_ui@@Base+0x24c>
   1c760:	sub	x0, x29, #0x18
   1c764:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1c768:	mov	x24, x0
   1c76c:	b	1c34c <__gmpz_n_pow_ui@@Base+0xc0>

000000000001c770 <__gmpz_neg@@Base>:
   1c770:	stp	x29, x30, [sp, #-48]!
   1c774:	stp	x22, x21, [sp, #16]
   1c778:	stp	x20, x19, [sp, #32]
   1c77c:	ldrsw	x22, [x1, #4]
   1c780:	mov	x19, x0
   1c784:	cmp	x1, x0
   1c788:	mov	x29, sp
   1c78c:	b.eq	1c7b8 <__gmpz_neg@@Base+0x48>  // b.none
   1c790:	ldrsw	x8, [x19]
   1c794:	cmp	x22, #0x0
   1c798:	cneg	x21, x22, mi  // mi = first
   1c79c:	mov	x20, x1
   1c7a0:	cmp	x21, x8
   1c7a4:	b.gt	1c7d0 <__gmpz_neg@@Base+0x60>
   1c7a8:	ldr	x0, [x19, #8]
   1c7ac:	ldr	x1, [x20, #8]
   1c7b0:	mov	x2, x21
   1c7b4:	bl	ca70 <__gmpn_copyi@plt>
   1c7b8:	neg	w8, w22
   1c7bc:	str	w8, [x19, #4]
   1c7c0:	ldp	x20, x19, [sp, #32]
   1c7c4:	ldp	x22, x21, [sp, #16]
   1c7c8:	ldp	x29, x30, [sp], #48
   1c7cc:	ret
   1c7d0:	mov	x0, x19
   1c7d4:	mov	x1, x21
   1c7d8:	bl	c090 <__gmpz_realloc@plt>
   1c7dc:	b	1c7ac <__gmpz_neg@@Base+0x3c>

000000000001c7e0 <__gmpz_nextprime@@Base>:
   1c7e0:	stp	x29, x30, [sp, #-96]!
   1c7e4:	stp	x20, x19, [sp, #80]
   1c7e8:	mov	x20, x1
   1c7ec:	mov	x19, x0
   1c7f0:	mov	w1, #0x2                   	// #2
   1c7f4:	mov	x0, x20
   1c7f8:	str	x27, [sp, #16]
   1c7fc:	stp	x26, x25, [sp, #32]
   1c800:	stp	x24, x23, [sp, #48]
   1c804:	stp	x22, x21, [sp, #64]
   1c808:	mov	x29, sp
   1c80c:	bl	d210 <__gmpz_cmp_ui@plt>
   1c810:	tbnz	w0, #31, 1c970 <__gmpz_nextprime@@Base+0x190>
   1c814:	mov	w2, #0x1                   	// #1
   1c818:	mov	x0, x19
   1c81c:	mov	x1, x20
   1c820:	bl	c8d0 <__gmpz_add_ui@plt>
   1c824:	mov	x0, x19
   1c828:	mov	x1, xzr
   1c82c:	bl	c330 <__gmpz_setbit@plt>
   1c830:	mov	w1, #0x7                   	// #7
   1c834:	mov	x0, x19
   1c838:	bl	d210 <__gmpz_cmp_ui@plt>
   1c83c:	cmp	w0, #0x1
   1c840:	b.lt	1c950 <__gmpz_nextprime@@Base+0x170>  // b.tstop
   1c844:	ldrsw	x8, [x19, #4]
   1c848:	ldr	x9, [x19, #8]
   1c84c:	add	x9, x9, x8, lsl #3
   1c850:	ldur	x9, [x9, #-8]
   1c854:	lsl	x8, x8, #6
   1c858:	clz	x9, x9
   1c85c:	sub	x8, x8, x9
   1c860:	lsr	x9, x8, #1
   1c864:	cmp	x8, #0x14d
   1c868:	mov	w8, #0xa6                  	// #166
   1c86c:	csel	w21, w8, w9, hi  // hi = pmore
   1c870:	lsl	x8, x21, #1
   1c874:	add	x8, x8, #0xf
   1c878:	and	x8, x8, #0x3fffffff0
   1c87c:	mov	x9, sp
   1c880:	sub	x22, x9, x8
   1c884:	mov	sp, x22
   1c888:	adrp	x24, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   1c88c:	mov	w23, #0xfffe                	// #65534
   1c890:	add	x24, x24, #0x2a0
   1c894:	cbz	w21, 1c8c8 <__gmpz_nextprime@@Base+0xe8>
   1c898:	mov	x25, x21
   1c89c:	mov	x26, x22
   1c8a0:	mov	x27, x24
   1c8a4:	mov	w20, #0x3                   	// #3
   1c8a8:	mov	x0, x19
   1c8ac:	mov	x1, x20
   1c8b0:	bl	bfb0 <__gmpz_tdiv_ui@plt>
   1c8b4:	strh	w0, [x26], #2
   1c8b8:	ldrb	w8, [x27], #1
   1c8bc:	subs	x25, x25, #0x1
   1c8c0:	add	x20, x20, x8
   1c8c4:	b.ne	1c8a8 <__gmpz_nextprime@@Base+0xc8>  // b.any
   1c8c8:	mov	x2, xzr
   1c8cc:	mov	w20, wzr
   1c8d0:	cbz	w21, 1c90c <__gmpz_nextprime@@Base+0x12c>
   1c8d4:	mov	x8, x21
   1c8d8:	mov	x9, x22
   1c8dc:	mov	x10, x24
   1c8e0:	mov	w11, #0x3                   	// #3
   1c8e4:	ldrh	w12, [x9]
   1c8e8:	add	x12, x12, w20, uxtw
   1c8ec:	udiv	x13, x12, x11
   1c8f0:	msub	x12, x13, x11, x12
   1c8f4:	cbz	x12, 1c92c <__gmpz_nextprime@@Base+0x14c>
   1c8f8:	ldrb	w12, [x10], #1
   1c8fc:	subs	x8, x8, #0x1
   1c900:	add	x9, x9, #0x2
   1c904:	add	x11, x11, x12
   1c908:	b.ne	1c8e4 <__gmpz_nextprime@@Base+0x104>  // b.any
   1c90c:	mov	x0, x19
   1c910:	mov	x1, x19
   1c914:	bl	c8d0 <__gmpz_add_ui@plt>
   1c918:	mov	w1, #0x19                  	// #25
   1c91c:	mov	x0, x19
   1c920:	bl	cba0 <__gmpz_millerrabin@plt>
   1c924:	cbnz	w0, 1c950 <__gmpz_nextprime@@Base+0x170>
   1c928:	mov	x2, xzr
   1c92c:	cmp	w20, w23
   1c930:	add	w20, w20, #0x2
   1c934:	add	x2, x2, #0x2
   1c938:	b.cc	1c8d0 <__gmpz_nextprime@@Base+0xf0>  // b.lo, b.ul, b.last
   1c93c:	mov	x0, x19
   1c940:	mov	x1, x19
   1c944:	bl	c8d0 <__gmpz_add_ui@plt>
   1c948:	cbnz	w21, 1c898 <__gmpz_nextprime@@Base+0xb8>
   1c94c:	b	1c8c8 <__gmpz_nextprime@@Base+0xe8>
   1c950:	mov	sp, x29
   1c954:	ldp	x20, x19, [sp, #80]
   1c958:	ldp	x22, x21, [sp, #64]
   1c95c:	ldp	x24, x23, [sp, #48]
   1c960:	ldp	x26, x25, [sp, #32]
   1c964:	ldr	x27, [sp, #16]
   1c968:	ldp	x29, x30, [sp], #96
   1c96c:	ret
   1c970:	mov	w1, #0x2                   	// #2
   1c974:	mov	x0, x19
   1c978:	mov	sp, x29
   1c97c:	ldp	x20, x19, [sp, #80]
   1c980:	ldp	x22, x21, [sp, #64]
   1c984:	ldp	x24, x23, [sp, #48]
   1c988:	ldp	x26, x25, [sp, #32]
   1c98c:	ldr	x27, [sp, #16]
   1c990:	ldp	x29, x30, [sp], #96
   1c994:	b	c180 <__gmpz_set_ui@plt>

000000000001c998 <__gmpz_out_raw@@Base>:
   1c998:	stp	x29, x30, [sp, #-80]!
   1c99c:	stp	x24, x23, [sp, #32]
   1c9a0:	stp	x22, x21, [sp, #48]
   1c9a4:	stp	x20, x19, [sp, #64]
   1c9a8:	str	x25, [sp, #16]
   1c9ac:	ldrsw	x23, [x1, #4]
   1c9b0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1c9b4:	ldr	x8, [x8, #3840]
   1c9b8:	mov	x21, x0
   1c9bc:	cmp	x23, #0x0
   1c9c0:	cneg	x25, x23, mi  // mi = first
   1c9c4:	ldr	x8, [x8]
   1c9c8:	ubfiz	x24, x25, #3, #58
   1c9cc:	add	x19, x24, #0x8
   1c9d0:	mov	x0, x19
   1c9d4:	mov	x29, sp
   1c9d8:	mov	x22, x1
   1c9dc:	blr	x8
   1c9e0:	mov	x20, x0
   1c9e4:	add	x0, x0, #0x8
   1c9e8:	cbz	x24, 1ca5c <__gmpz_out_raw@@Base+0xc4>
   1c9ec:	ldr	x9, [x22, #8]
   1c9f0:	add	x8, x0, x24
   1c9f4:	add	x10, x25, #0x1
   1c9f8:	ldr	x11, [x9], #8
   1c9fc:	sub	x10, x10, #0x1
   1ca00:	cmp	x10, #0x1
   1ca04:	lsl	x14, x11, #40
   1ca08:	and	x14, x14, #0xff000000000000
   1ca0c:	lsr	x13, x11, #16
   1ca10:	bfi	x14, x11, #56, #8
   1ca14:	lsr	x12, x11, #24
   1ca18:	bfi	x14, x13, #40, #8
   1ca1c:	lsr	x13, x11, #8
   1ca20:	and	x13, x13, #0xff000000
   1ca24:	bfi	x14, x12, #32, #8
   1ca28:	orr	x13, x14, x13
   1ca2c:	lsr	x14, x11, #40
   1ca30:	and	x12, x12, #0xff0000
   1ca34:	and	x14, x14, #0xff00
   1ca38:	orr	x12, x13, x12
   1ca3c:	orr	x12, x12, x14
   1ca40:	add	x12, x12, x11, lsr #56
   1ca44:	str	x12, [x8, #-8]!
   1ca48:	b.gt	1c9f8 <__gmpz_out_raw@@Base+0x60>
   1ca4c:	clz	x9, x11
   1ca50:	add	x0, x8, x9, lsr #3
   1ca54:	sub	x8, x24, x9, lsr #3
   1ca58:	b	1ca60 <__gmpz_out_raw@@Base+0xc8>
   1ca5c:	mov	x8, xzr
   1ca60:	cmp	w23, #0x0
   1ca64:	cneg	w9, w8, lt  // lt = tstop
   1ca68:	rev	w9, w9
   1ca6c:	str	w9, [x0, #-4]!
   1ca70:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1ca74:	ldr	x9, [x9, #3856]
   1ca78:	add	x22, x8, #0x4
   1ca7c:	cmp	x21, #0x0
   1ca80:	mov	w2, #0x1                   	// #1
   1ca84:	ldr	x9, [x9]
   1ca88:	mov	x1, x22
   1ca8c:	csel	x3, x9, x21, eq  // eq = none
   1ca90:	bl	ce50 <fwrite@plt>
   1ca94:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1ca98:	ldr	x8, [x8, #4016]
   1ca9c:	cmp	x0, #0x1
   1caa0:	mov	x0, x20
   1caa4:	mov	x1, x19
   1caa8:	ldr	x8, [x8]
   1caac:	csel	x21, x22, xzr, eq  // eq = none
   1cab0:	blr	x8
   1cab4:	mov	x0, x21
   1cab8:	ldp	x20, x19, [sp, #64]
   1cabc:	ldp	x22, x21, [sp, #48]
   1cac0:	ldp	x24, x23, [sp, #32]
   1cac4:	ldr	x25, [sp, #16]
   1cac8:	ldp	x29, x30, [sp], #80
   1cacc:	ret

000000000001cad0 <__gmpz_out_str@@Base>:
   1cad0:	stp	x29, x30, [sp, #-80]!
   1cad4:	str	x25, [sp, #16]
   1cad8:	stp	x24, x23, [sp, #32]
   1cadc:	stp	x22, x21, [sp, #48]
   1cae0:	stp	x20, x19, [sp, #64]
   1cae4:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1cae8:	ldr	x8, [x8, #3856]
   1caec:	ldrsw	x21, [x2, #4]
   1caf0:	cmp	x0, #0x0
   1caf4:	mov	x22, x2
   1caf8:	ldr	x8, [x8]
   1cafc:	mov	w20, w1
   1cb00:	mov	x29, sp
   1cb04:	csel	x19, x8, x0, eq  // eq = none
   1cb08:	cmp	w1, #0x2
   1cb0c:	b.lt	1cb3c <__gmpz_out_str@@Base+0x6c>  // b.tstop
   1cb10:	cmp	w20, #0x25
   1cb14:	b.ge	1cb4c <__gmpz_out_str@@Base+0x7c>  // b.tcont
   1cb18:	adrp	x24, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
   1cb1c:	add	x24, x24, #0xded
   1cb20:	tbz	w21, #31, 1cb70 <__gmpz_out_str@@Base+0xa0>
   1cb24:	mov	w0, #0x2d                  	// #45
   1cb28:	mov	x1, x19
   1cb2c:	bl	c220 <fputc@plt>
   1cb30:	neg	x21, x21
   1cb34:	mov	w25, #0x1                   	// #1
   1cb38:	b	1cb74 <__gmpz_out_str@@Base+0xa4>
   1cb3c:	cmn	w20, #0x2
   1cb40:	b.le	1cb58 <__gmpz_out_str@@Base+0x88>
   1cb44:	mov	w20, #0xa                   	// #10
   1cb48:	b	1cb64 <__gmpz_out_str@@Base+0x94>
   1cb4c:	cmp	w20, #0x3e
   1cb50:	b.le	1cb64 <__gmpz_out_str@@Base+0x94>
   1cb54:	b	1cca0 <__gmpz_out_str@@Base+0x1d0>
   1cb58:	cmn	w20, #0x24
   1cb5c:	b.lt	1cca0 <__gmpz_out_str@@Base+0x1d0>  // b.tstop
   1cb60:	neg	w20, w20
   1cb64:	adrp	x24, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
   1cb68:	add	x24, x24, #0xdae
   1cb6c:	tbnz	w21, #31, 1cb24 <__gmpz_out_str@@Base+0x54>
   1cb70:	mov	x25, xzr
   1cb74:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1cb78:	ldr	x8, [x8, #3936]
   1cb7c:	mov	w9, #0x28                  	// #40
   1cb80:	str	xzr, [x29, #24]
   1cb84:	umaddl	x8, w20, w9, x8
   1cb88:	ldr	x8, [x8, #8]
   1cb8c:	lsl	x9, x21, #6
   1cb90:	umulh	x8, x8, x9
   1cb94:	add	x1, x8, #0x3
   1cb98:	mov	w8, #0x7f00                	// #32512
   1cb9c:	cmp	x1, x8
   1cba0:	b.hi	1cc84 <__gmpz_out_str@@Base+0x1b4>  // b.pmore
   1cba4:	add	x9, x1, #0xf
   1cba8:	mov	x8, sp
   1cbac:	and	x9, x9, #0xfffffffffffffff0
   1cbb0:	sub	x23, x8, x9
   1cbb4:	mov	sp, x23
   1cbb8:	ldr	x2, [x22, #8]
   1cbbc:	sub	w8, w20, #0x1
   1cbc0:	tst	w20, w8
   1cbc4:	b.eq	1cc04 <__gmpz_out_str@@Base+0x134>  // b.none
   1cbc8:	lsl	x8, x21, #3
   1cbcc:	orr	x1, x8, #0x8
   1cbd0:	mov	w8, #0x7f00                	// #32512
   1cbd4:	cmp	x1, x8
   1cbd8:	b.hi	1cca8 <__gmpz_out_str@@Base+0x1d8>  // b.pmore
   1cbdc:	add	x9, x1, #0xf
   1cbe0:	mov	x8, sp
   1cbe4:	and	x9, x9, #0xfffffffffffffff0
   1cbe8:	sub	x22, x8, x9
   1cbec:	mov	sp, x22
   1cbf0:	mov	x0, x22
   1cbf4:	mov	x1, x2
   1cbf8:	mov	x2, x21
   1cbfc:	bl	ca70 <__gmpn_copyi@plt>
   1cc00:	mov	x2, x22
   1cc04:	mov	x0, x23
   1cc08:	mov	w1, w20
   1cc0c:	mov	x3, x21
   1cc10:	bl	cab0 <__gmpn_get_str@plt>
   1cc14:	mov	x2, x0
   1cc18:	cbz	x0, 1cc38 <__gmpz_out_str@@Base+0x168>
   1cc1c:	mov	x8, x23
   1cc20:	mov	x9, x2
   1cc24:	ldrb	w10, [x8]
   1cc28:	subs	x9, x9, #0x1
   1cc2c:	ldrb	w10, [x24, x10]
   1cc30:	strb	w10, [x8], #1
   1cc34:	b.ne	1cc24 <__gmpz_out_str@@Base+0x154>  // b.any
   1cc38:	mov	w1, #0x1                   	// #1
   1cc3c:	mov	x0, x23
   1cc40:	mov	x3, x19
   1cc44:	strb	wzr, [x23, x2]
   1cc48:	bl	ce50 <fwrite@plt>
   1cc4c:	ldr	x8, [x29, #24]
   1cc50:	add	x20, x0, x25
   1cc54:	cbnz	x8, 1cc94 <__gmpz_out_str@@Base+0x1c4>
   1cc58:	mov	x0, x19
   1cc5c:	bl	d4c0 <ferror@plt>
   1cc60:	cmp	w0, #0x0
   1cc64:	csel	x0, x20, xzr, eq  // eq = none
   1cc68:	mov	sp, x29
   1cc6c:	ldp	x20, x19, [sp, #64]
   1cc70:	ldp	x22, x21, [sp, #48]
   1cc74:	ldp	x24, x23, [sp, #32]
   1cc78:	ldr	x25, [sp, #16]
   1cc7c:	ldp	x29, x30, [sp], #80
   1cc80:	ret
   1cc84:	add	x0, x29, #0x18
   1cc88:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1cc8c:	mov	x23, x0
   1cc90:	b	1cbb8 <__gmpz_out_str@@Base+0xe8>
   1cc94:	mov	x0, x8
   1cc98:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1cc9c:	b	1cc58 <__gmpz_out_str@@Base+0x188>
   1cca0:	mov	x0, xzr
   1cca4:	b	1cc68 <__gmpz_out_str@@Base+0x198>
   1cca8:	add	x0, x29, #0x18
   1ccac:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1ccb0:	ldr	x2, [x22, #8]
   1ccb4:	mov	x22, x0
   1ccb8:	b	1cbf0 <__gmpz_out_str@@Base+0x120>

000000000001ccbc <__gmpz_perfect_power_p@@Base>:
   1ccbc:	ldr	x8, [x0, #8]
   1ccc0:	ldrsw	x1, [x0, #4]
   1ccc4:	mov	x0, x8
   1ccc8:	b	c250 <__gmpn_perfect_power_p@plt>

000000000001cccc <__gmpz_perfect_square_p@@Base>:
   1cccc:	ldr	w1, [x0, #4]
   1ccd0:	cmp	w1, #0x1
   1ccd4:	b.lt	1cce0 <__gmpz_perfect_square_p@@Base+0x14>  // b.tstop
   1ccd8:	ldr	x0, [x0, #8]
   1ccdc:	b	d0d0 <__gmpn_perfect_square_p@plt>
   1cce0:	mvn	w8, w1
   1cce4:	lsr	w0, w8, #31
   1cce8:	ret

000000000001ccec <__gmpz_popcount@@Base>:
   1ccec:	ldr	w1, [x0, #4]
   1ccf0:	cmp	w1, #0x1
   1ccf4:	b.lt	1cd00 <__gmpz_popcount@@Base+0x14>  // b.tstop
   1ccf8:	ldr	x0, [x0, #8]
   1ccfc:	b	cda0 <__gmpn_popcount@plt>
   1cd00:	sbfx	x0, x1, #31, #1
   1cd04:	ret

000000000001cd08 <__gmpz_pow_ui@@Base>:
   1cd08:	cmp	x2, #0x2
   1cd0c:	b.eq	1cd28 <__gmpz_pow_ui@@Base+0x20>  // b.none
   1cd10:	mov	x3, x2
   1cd14:	cmp	x2, #0x1
   1cd18:	b.eq	1cd30 <__gmpz_pow_ui@@Base+0x28>  // b.none
   1cd1c:	cbnz	x3, 1cd34 <__gmpz_pow_ui@@Base+0x2c>
   1cd20:	mov	w1, #0x1                   	// #1
   1cd24:	b	c180 <__gmpz_set_ui@plt>
   1cd28:	mov	x2, x1
   1cd2c:	b	c4d0 <__gmpz_mul@plt>
   1cd30:	b	c440 <__gmpz_set@plt>
   1cd34:	ldr	x8, [x1, #8]
   1cd38:	ldrsw	x2, [x1, #4]
   1cd3c:	mov	x1, x8
   1cd40:	b	c360 <__gmpz_n_pow_ui@plt>

000000000001cd44 <__gmpz_powm@@Base>:
   1cd44:	stp	x29, x30, [sp, #-96]!
   1cd48:	stp	x28, x27, [sp, #16]
   1cd4c:	stp	x26, x25, [sp, #32]
   1cd50:	stp	x24, x23, [sp, #48]
   1cd54:	stp	x22, x21, [sp, #64]
   1cd58:	stp	x20, x19, [sp, #80]
   1cd5c:	mov	x29, sp
   1cd60:	sub	sp, sp, #0x50
   1cd64:	ldr	w8, [x3, #4]
   1cd68:	cmp	w8, #0x0
   1cd6c:	cneg	w20, w8, mi  // mi = first
   1cd70:	cbz	w20, 1d5bc <__gmpz_powm@@Base+0x878>
   1cd74:	ldr	x11, [x3, #8]
   1cd78:	stur	xzr, [x29, #-24]
   1cd7c:	ldrsw	x19, [x2, #4]
   1cd80:	mov	x25, x3
   1cd84:	mov	x21, x2
   1cd88:	mov	x24, x1
   1cd8c:	mov	x23, x0
   1cd90:	cmp	w19, #0x0
   1cd94:	stur	x3, [x29, #-64]
   1cd98:	b.le	1d240 <__gmpz_powm@@Base+0x4fc>
   1cd9c:	ldr	w8, [x24, #4]
   1cda0:	cmp	w8, #0x0
   1cda4:	cneg	w26, w8, mi  // mi = first
   1cda8:	cbz	w26, 1d298 <__gmpz_powm@@Base+0x554>
   1cdac:	ldr	x9, [x21, #8]
   1cdb0:	cmp	x19, #0x1
   1cdb4:	b.ne	1cdc4 <__gmpz_powm@@Base+0x80>  // b.any
   1cdb8:	ldr	x8, [x9]
   1cdbc:	cmp	x8, #0x1
   1cdc0:	b.eq	1d2c0 <__gmpz_powm@@Base+0x57c>  // b.none
   1cdc4:	ldr	x8, [x11]
   1cdc8:	mov	x28, xzr
   1cdcc:	stur	x9, [x29, #-32]
   1cdd0:	cbz	x8, 1d2a0 <__gmpz_powm@@Base+0x55c>
   1cdd4:	sub	x27, x20, x28
   1cdd8:	tbnz	w8, #0, 1ce3c <__gmpz_powm@@Base+0xf8>
   1cddc:	lsl	x1, x27, #3
   1cde0:	mov	w9, #0x7f00                	// #32512
   1cde4:	cmp	x1, x9
   1cde8:	b.hi	1d308 <__gmpz_powm@@Base+0x5c4>  // b.pmore
   1cdec:	add	x10, x1, #0xf
   1cdf0:	mov	x9, sp
   1cdf4:	and	x10, x10, #0xfffffffffffffff0
   1cdf8:	sub	x21, x9, x10
   1cdfc:	mov	sp, x21
   1ce00:	rbit	x8, x8
   1ce04:	clz	x3, x8
   1ce08:	mov	x0, x21
   1ce0c:	mov	x1, x11
   1ce10:	mov	x2, x27
   1ce14:	stur	x3, [x29, #-56]
   1ce18:	bl	c1b0 <__gmpn_rshift@plt>
   1ce1c:	add	x8, x21, x27, lsl #3
   1ce20:	ldur	x8, [x8, #-8]
   1ce24:	add	x28, x28, #0x1
   1ce28:	stur	x21, [x29, #-40]
   1ce2c:	cmp	x8, #0x0
   1ce30:	cset	w8, eq  // eq = none
   1ce34:	sub	x27, x27, x8
   1ce38:	b	1ce48 <__gmpz_powm@@Base+0x104>
   1ce3c:	stur	x11, [x29, #-40]
   1ce40:	cbz	x28, 1cf88 <__gmpz_powm@@Base+0x244>
   1ce44:	stur	xzr, [x29, #-56]
   1ce48:	cmp	x28, x27
   1ce4c:	csel	x0, x28, x27, gt
   1ce50:	bl	d200 <__gmpn_binvert_itch@plt>
   1ce54:	lsl	x8, x20, #1
   1ce58:	cmp	x0, x20, lsl #1
   1ce5c:	add	x9, x20, x20, lsl #1
   1ce60:	csel	x8, x0, x8, gt
   1ce64:	mov	w22, #0x1                   	// #1
   1ce68:	add	x8, x8, x9
   1ce6c:	lsl	x1, x8, #3
   1ce70:	mov	w8, #0x7f00                	// #32512
   1ce74:	cmp	x1, x8
   1ce78:	b.hi	1d2b0 <__gmpz_powm@@Base+0x56c>  // b.pmore
   1ce7c:	add	x9, x1, #0xf
   1ce80:	mov	x8, sp
   1ce84:	and	x9, x9, #0xfffffffffffffff0
   1ce88:	sub	x21, x8, x9
   1ce8c:	mov	sp, x21
   1ce90:	ldr	x25, [x24, #8]
   1ce94:	ldp	x5, x3, [x29, #-40]
   1ce98:	stur	x24, [x29, #-48]
   1ce9c:	add	x24, x21, x20, lsl #3
   1cea0:	mov	x0, x21
   1cea4:	mov	x1, x25
   1cea8:	mov	x2, x26
   1ceac:	mov	x4, x19
   1ceb0:	mov	x6, x27
   1ceb4:	mov	x7, x24
   1ceb8:	bl	d020 <__gmpn_powm@plt>
   1cebc:	cbz	w22, 1d168 <__gmpz_powm@@Base+0x424>
   1cec0:	cmp	x28, x26
   1cec4:	stur	x23, [x29, #-72]
   1cec8:	b.le	1cf20 <__gmpz_powm@@Base+0x1dc>
   1cecc:	lsl	x22, x28, #3
   1ced0:	mov	w8, #0x7f00                	// #32512
   1ced4:	cmp	x22, x8
   1ced8:	b.hi	1d3ec <__gmpz_powm@@Base+0x6a8>  // b.pmore
   1cedc:	add	x9, x22, #0xf
   1cee0:	mov	x8, sp
   1cee4:	and	x9, x9, #0xfffffffffffffff0
   1cee8:	sub	x23, x8, x9
   1ceec:	mov	sp, x23
   1cef0:	mov	x0, x23
   1cef4:	mov	x1, x25
   1cef8:	mov	x2, x26
   1cefc:	bl	ca70 <__gmpn_copyi@plt>
   1cf00:	cmp	x28, x26
   1cf04:	mov	x25, x23
   1cf08:	b.eq	1cf20 <__gmpz_powm@@Base+0x1dc>  // b.none
   1cf0c:	add	x0, x23, x26, lsl #3
   1cf10:	sub	x2, x22, x26, lsl #3
   1cf14:	mov	w1, wzr
   1cf18:	bl	c610 <memset@plt>
   1cf1c:	mov	x25, x23
   1cf20:	ldr	x8, [x25]
   1cf24:	tbnz	w8, #0, 1cf68 <__gmpz_powm@@Base+0x224>
   1cf28:	cmp	x19, #0x2
   1cf2c:	b.ge	1cfac <__gmpz_powm@@Base+0x268>  // b.tcont
   1cf30:	ldur	x10, [x29, #-32]
   1cf34:	ldur	x12, [x29, #-56]
   1cf38:	ubfiz	w8, w8, #1, #3
   1cf3c:	mov	w9, #0x1213                	// #4627
   1cf40:	ldr	x10, [x10]
   1cf44:	cmp	w12, #0x0
   1cf48:	cset	w11, ne  // ne = any
   1cf4c:	lsr	w8, w9, w8
   1cf50:	sub	x9, x28, x11
   1cf54:	and	w8, w8, #0x3
   1cf58:	add	x9, x12, x9, lsl #6
   1cf5c:	mul	x8, x10, x8
   1cf60:	cmp	x8, x9
   1cf64:	b.cs	1cfac <__gmpz_powm@@Base+0x268>  // b.hs, b.nlast
   1cf68:	ldur	x2, [x29, #-32]
   1cf6c:	add	x5, x24, x28, lsl #3
   1cf70:	mov	x0, x24
   1cf74:	mov	x1, x25
   1cf78:	mov	x3, x19
   1cf7c:	mov	x4, x28
   1cf80:	bl	c3e0 <__gmpn_powlo@plt>
   1cf84:	b	1cfbc <__gmpz_powm@@Base+0x278>
   1cf88:	mov	x0, x27
   1cf8c:	bl	d200 <__gmpn_binvert_itch@plt>
   1cf90:	lsl	x8, x20, #1
   1cf94:	cmp	x0, x20, lsl #1
   1cf98:	mov	w22, wzr
   1cf9c:	csel	x8, x0, x8, gt
   1cfa0:	mov	x9, x20
   1cfa4:	stur	xzr, [x29, #-56]
   1cfa8:	b	1ce68 <__gmpz_powm@@Base+0x124>
   1cfac:	add	x0, x21, x20, lsl #3
   1cfb0:	lsl	x2, x28, #3
   1cfb4:	mov	w1, wzr
   1cfb8:	bl	c610 <memset@plt>
   1cfbc:	ldur	x1, [x29, #-40]
   1cfc0:	cmp	x28, x27
   1cfc4:	b.le	1d020 <__gmpz_powm@@Base+0x2dc>
   1cfc8:	ldur	x23, [x29, #-72]
   1cfcc:	lsl	x19, x28, #3
   1cfd0:	mov	w8, #0x7f00                	// #32512
   1cfd4:	cmp	x19, x8
   1cfd8:	b.hi	1d400 <__gmpz_powm@@Base+0x6bc>  // b.pmore
   1cfdc:	add	x9, x19, #0xf
   1cfe0:	mov	x8, sp
   1cfe4:	and	x9, x9, #0xfffffffffffffff0
   1cfe8:	sub	x22, x8, x9
   1cfec:	mov	sp, x22
   1cff0:	mov	x0, x22
   1cff4:	mov	x2, x27
   1cff8:	bl	ca70 <__gmpn_copyi@plt>
   1cffc:	cmp	x28, x27
   1d000:	mov	x1, x22
   1d004:	b.eq	1d024 <__gmpz_powm@@Base+0x2e0>  // b.none
   1d008:	add	x0, x22, x27, lsl #3
   1d00c:	sub	x2, x19, x27, lsl #3
   1d010:	mov	w1, wzr
   1d014:	bl	c610 <memset@plt>
   1d018:	mov	x1, x22
   1d01c:	b	1d024 <__gmpz_powm@@Base+0x2e0>
   1d020:	ldur	x23, [x29, #-72]
   1d024:	add	x25, x24, x20, lsl #3
   1d028:	add	x19, x24, x20, lsl #4
   1d02c:	mov	x0, x25
   1d030:	mov	x2, x28
   1d034:	mov	x3, x19
   1d038:	mov	x26, x1
   1d03c:	bl	cd40 <__gmpn_binvert@plt>
   1d040:	cmp	x28, x27
   1d044:	csel	x22, x28, x27, lt  // lt = tstop
   1d048:	cbz	x22, 1d088 <__gmpz_powm@@Base+0x344>
   1d04c:	mov	x0, x24
   1d050:	mov	x1, x24
   1d054:	mov	x2, x21
   1d058:	mov	x3, x22
   1d05c:	bl	c2e0 <__gmpn_sub_n@plt>
   1d060:	cbz	x0, 1d088 <__gmpz_powm@@Base+0x344>
   1d064:	add	x8, x21, x20, lsl #3
   1d068:	cmp	x22, x28
   1d06c:	b.ge	1d088 <__gmpz_powm@@Base+0x344>  // b.tcont
   1d070:	ldr	x9, [x8, x22, lsl #3]
   1d074:	add	x11, x22, #0x1
   1d078:	sub	x10, x9, #0x1
   1d07c:	str	x10, [x8, x22, lsl #3]
   1d080:	mov	x22, x11
   1d084:	cbz	x9, 1d068 <__gmpz_powm@@Base+0x324>
   1d088:	mov	x0, x19
   1d08c:	mov	x1, x25
   1d090:	mov	x2, x24
   1d094:	mov	x3, x28
   1d098:	bl	cee0 <__gmpn_mullo_n@plt>
   1d09c:	ldur	x11, [x29, #-56]
   1d0a0:	cbz	w11, 1d0bc <__gmpz_powm@@Base+0x378>
   1d0a4:	add	x8, x19, x28, lsl #3
   1d0a8:	ldur	x9, [x8, #-8]
   1d0ac:	mov	x10, #0xffffffffffffffff    	// #-1
   1d0b0:	lsl	x10, x10, x11
   1d0b4:	bic	x9, x9, x10
   1d0b8:	stur	x9, [x8, #-8]
   1d0bc:	cmp	x28, x27
   1d0c0:	mov	x3, x26
   1d0c4:	mov	x0, x24
   1d0c8:	b.le	1d0dc <__gmpz_powm@@Base+0x398>
   1d0cc:	mov	x1, x19
   1d0d0:	mov	x2, x28
   1d0d4:	mov	x4, x27
   1d0d8:	b	1d0ec <__gmpz_powm@@Base+0x3a8>
   1d0dc:	mov	x1, x3
   1d0e0:	mov	x2, x27
   1d0e4:	mov	x3, x19
   1d0e8:	mov	x4, x28
   1d0ec:	bl	ccf0 <__gmpn_mul@plt>
   1d0f0:	cbz	x27, 1d134 <__gmpz_powm@@Base+0x3f0>
   1d0f4:	mov	x0, x21
   1d0f8:	mov	x1, x24
   1d0fc:	mov	x2, x21
   1d100:	mov	x3, x27
   1d104:	bl	ca90 <__gmpn_add_n@plt>
   1d108:	cbz	x0, 1d13c <__gmpz_powm@@Base+0x3f8>
   1d10c:	add	x9, x21, x20, lsl #3
   1d110:	cmp	x27, x20
   1d114:	b.ge	1d168 <__gmpz_powm@@Base+0x424>  // b.tcont
   1d118:	ldr	x8, [x9, x27, lsl #3]
   1d11c:	adds	x10, x8, #0x1
   1d120:	add	x8, x27, #0x1
   1d124:	str	x10, [x21, x27, lsl #3]
   1d128:	mov	x27, x8
   1d12c:	b.cs	1d110 <__gmpz_powm@@Base+0x3cc>  // b.hs, b.nlast
   1d130:	b	1d140 <__gmpz_powm@@Base+0x3fc>
   1d134:	mov	x8, xzr
   1d138:	b	1d140 <__gmpz_powm@@Base+0x3fc>
   1d13c:	mov	x8, x27
   1d140:	cmp	x24, x21
   1d144:	b.eq	1d168 <__gmpz_powm@@Base+0x424>  // b.none
   1d148:	cmp	x8, x20
   1d14c:	b.ge	1d168 <__gmpz_powm@@Base+0x424>  // b.tcont
   1d150:	sub	x9, x20, x8
   1d154:	add	x8, x21, x8, lsl #3
   1d158:	ldr	x10, [x8, x20, lsl #3]
   1d15c:	subs	x9, x9, #0x1
   1d160:	str	x10, [x8], #8
   1d164:	b.ne	1d158 <__gmpz_powm@@Base+0x414>  // b.any
   1d168:	ldur	x11, [x29, #-48]
   1d16c:	ldur	x12, [x29, #-32]
   1d170:	sub	x22, x21, #0x8
   1d174:	mov	x8, x20
   1d178:	subs	x9, x8, #0x1
   1d17c:	b.lt	1d194 <__gmpz_powm@@Base+0x450>  // b.tstop
   1d180:	ldr	x10, [x22, x8, lsl #3]
   1d184:	mov	x8, x9
   1d188:	cbz	x10, 1d178 <__gmpz_powm@@Base+0x434>
   1d18c:	add	x26, x9, #0x1
   1d190:	b	1d198 <__gmpz_powm@@Base+0x454>
   1d194:	mov	x26, xzr
   1d198:	ldrb	w8, [x12]
   1d19c:	tbz	w8, #0, 1d514 <__gmpz_powm@@Base+0x7d0>
   1d1a0:	cbz	x26, 1d514 <__gmpz_powm@@Base+0x7d0>
   1d1a4:	ldr	w8, [x11, #4]
   1d1a8:	tbz	w8, #31, 1d514 <__gmpz_powm@@Base+0x7d0>
   1d1ac:	ldur	x8, [x29, #-64]
   1d1b0:	mov	x0, x21
   1d1b4:	mov	x2, x21
   1d1b8:	mov	x3, x26
   1d1bc:	ldr	x19, [x8, #8]
   1d1c0:	mov	x1, x19
   1d1c4:	bl	c2e0 <__gmpn_sub_n@plt>
   1d1c8:	cbz	x0, 1d1f0 <__gmpz_powm@@Base+0x4ac>
   1d1cc:	cmp	x26, x20
   1d1d0:	b.ge	1d230 <__gmpz_powm@@Base+0x4ec>  // b.tcont
   1d1d4:	ldr	x8, [x19, x26, lsl #3]
   1d1d8:	add	x10, x26, #0x1
   1d1dc:	sub	x9, x8, #0x1
   1d1e0:	str	x9, [x21, x26, lsl #3]
   1d1e4:	mov	x26, x10
   1d1e8:	cbz	x8, 1d1cc <__gmpz_powm@@Base+0x488>
   1d1ec:	b	1d1f4 <__gmpz_powm@@Base+0x4b0>
   1d1f0:	mov	x10, x26
   1d1f4:	cmp	x19, x21
   1d1f8:	b.eq	1d230 <__gmpz_powm@@Base+0x4ec>  // b.none
   1d1fc:	cmp	x10, x20
   1d200:	b.ge	1d230 <__gmpz_powm@@Base+0x4ec>  // b.tcont
   1d204:	sub	x8, x20, x10
   1d208:	add	x9, x21, x10, lsl #3
   1d20c:	add	x10, x19, x10, lsl #3
   1d210:	ldr	x11, [x10], #8
   1d214:	subs	x8, x8, #0x1
   1d218:	str	x11, [x9], #8
   1d21c:	b.ne	1d210 <__gmpz_powm@@Base+0x4cc>  // b.any
   1d220:	b	1d230 <__gmpz_powm@@Base+0x4ec>
   1d224:	ldr	x9, [x22, x20, lsl #3]
   1d228:	mov	x20, x8
   1d22c:	cbnz	x9, 1d510 <__gmpz_powm@@Base+0x7cc>
   1d230:	subs	x8, x20, #0x1
   1d234:	b.ge	1d224 <__gmpz_powm@@Base+0x4e0>  // b.tcont
   1d238:	mov	x26, xzr
   1d23c:	b	1d514 <__gmpz_powm@@Base+0x7d0>
   1d240:	cbz	w19, 1d324 <__gmpz_powm@@Base+0x5e0>
   1d244:	add	x8, x20, #0x1
   1d248:	cmp	w20, #0xfdf
   1d24c:	lsl	x1, x8, #3
   1d250:	mov	x22, x11
   1d254:	stur	w8, [x29, #-16]
   1d258:	b.hi	1d574 <__gmpz_powm@@Base+0x830>  // b.pmore
   1d25c:	add	x9, x1, #0xf
   1d260:	mov	x8, sp
   1d264:	and	x9, x9, #0x1ffffffff0
   1d268:	sub	x0, x8, x9
   1d26c:	mov	sp, x0
   1d270:	stur	x0, [x29, #-8]
   1d274:	sub	x0, x29, #0x10
   1d278:	mov	x1, x24
   1d27c:	mov	x2, x25
   1d280:	bl	cbf0 <__gmpz_invert@plt>
   1d284:	cbz	w0, 1d5bc <__gmpz_powm@@Base+0x878>
   1d288:	sub	x24, x29, #0x10
   1d28c:	neg	x19, x19
   1d290:	mov	x11, x22
   1d294:	b	1cd9c <__gmpz_powm@@Base+0x58>
   1d298:	str	wzr, [x23, #4]
   1d29c:	b	1d534 <__gmpz_powm@@Base+0x7f0>
   1d2a0:	ldr	x8, [x11, #8]!
   1d2a4:	add	x28, x28, #0x1
   1d2a8:	cbnz	x8, 1cdd4 <__gmpz_powm@@Base+0x90>
   1d2ac:	b	1d2a0 <__gmpz_powm@@Base+0x55c>
   1d2b0:	sub	x0, x29, #0x18
   1d2b4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1d2b8:	mov	x21, x0
   1d2bc:	b	1ce90 <__gmpz_powm@@Base+0x14c>
   1d2c0:	cmp	w20, #0xfe0
   1d2c4:	lsl	x1, x20, #3
   1d2c8:	b.hi	1d580 <__gmpz_powm@@Base+0x83c>  // b.pmore
   1d2cc:	add	x9, x1, #0xf
   1d2d0:	mov	x8, sp
   1d2d4:	and	x9, x9, #0xffffffff0
   1d2d8:	sub	x21, x8, x9
   1d2dc:	mov	sp, x21
   1d2e0:	ldr	x19, [x24, #8]
   1d2e4:	cmp	w26, w20
   1d2e8:	b.cs	1d33c <__gmpz_powm@@Base+0x5f8>  // b.hs, b.nlast
   1d2ec:	ldr	w8, [x24, #4]
   1d2f0:	tbnz	w8, #31, 1d43c <__gmpz_powm@@Base+0x6f8>
   1d2f4:	mov	x0, x21
   1d2f8:	mov	x1, x19
   1d2fc:	mov	x2, x26
   1d300:	bl	ca70 <__gmpn_copyi@plt>
   1d304:	b	1d514 <__gmpz_powm@@Base+0x7d0>
   1d308:	sub	x0, x29, #0x18
   1d30c:	mov	x21, x11
   1d310:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1d314:	ldr	x8, [x21]
   1d318:	mov	x11, x21
   1d31c:	mov	x21, x0
   1d320:	b	1ce00 <__gmpz_powm@@Base+0xbc>
   1d324:	cmp	w20, #0x1
   1d328:	b.ne	1d418 <__gmpz_powm@@Base+0x6d4>  // b.any
   1d32c:	ldr	x8, [x11]
   1d330:	cmp	x8, #0x1
   1d334:	cset	w8, ne  // ne = any
   1d338:	b	1d41c <__gmpz_powm@@Base+0x6d8>
   1d33c:	sub	x8, x26, x20
   1d340:	lsl	x8, x8, #3
   1d344:	add	x1, x8, #0x8
   1d348:	mov	w8, #0x7f00                	// #32512
   1d34c:	cmp	x1, x8
   1d350:	b.hi	1d5a8 <__gmpz_powm@@Base+0x864>  // b.pmore
   1d354:	add	x9, x1, #0xf
   1d358:	mov	x8, sp
   1d35c:	and	x9, x9, #0xfffffffffffffff0
   1d360:	sub	x0, x8, x9
   1d364:	mov	sp, x0
   1d368:	mov	x1, x21
   1d36c:	mov	x2, xzr
   1d370:	mov	x3, x19
   1d374:	mov	x4, x26
   1d378:	mov	x5, x11
   1d37c:	mov	x6, x20
   1d380:	mov	x22, x11
   1d384:	bl	bf10 <__gmpn_tdiv_qr@plt>
   1d388:	sub	x19, x21, #0x8
   1d38c:	mov	x9, x20
   1d390:	subs	x8, x9, #0x1
   1d394:	b.lt	1d238 <__gmpz_powm@@Base+0x4f4>  // b.tstop
   1d398:	ldr	x10, [x19, x9, lsl #3]
   1d39c:	mov	x9, x8
   1d3a0:	cbz	x10, 1d390 <__gmpz_powm@@Base+0x64c>
   1d3a4:	ldr	w9, [x24, #4]
   1d3a8:	add	x26, x8, #0x1
   1d3ac:	tbz	w9, #31, 1d514 <__gmpz_powm@@Base+0x7d0>
   1d3b0:	mov	x0, x21
   1d3b4:	mov	x1, x22
   1d3b8:	mov	x2, x21
   1d3bc:	mov	x3, x26
   1d3c0:	bl	c2e0 <__gmpn_sub_n@plt>
   1d3c4:	cbz	x0, 1d4d0 <__gmpz_powm@@Base+0x78c>
   1d3c8:	cmp	x26, x20
   1d3cc:	b.ge	1d500 <__gmpz_powm@@Base+0x7bc>  // b.tcont
   1d3d0:	ldr	x8, [x22, x26, lsl #3]
   1d3d4:	add	x10, x26, #0x1
   1d3d8:	sub	x9, x8, #0x1
   1d3dc:	str	x9, [x21, x26, lsl #3]
   1d3e0:	mov	x26, x10
   1d3e4:	cbz	x8, 1d3c8 <__gmpz_powm@@Base+0x684>
   1d3e8:	b	1d4d4 <__gmpz_powm@@Base+0x790>
   1d3ec:	sub	x0, x29, #0x18
   1d3f0:	mov	x1, x22
   1d3f4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1d3f8:	mov	x23, x0
   1d3fc:	b	1cef0 <__gmpz_powm@@Base+0x1ac>
   1d400:	sub	x0, x29, #0x18
   1d404:	mov	x1, x19
   1d408:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1d40c:	ldur	x1, [x29, #-40]
   1d410:	mov	x22, x0
   1d414:	b	1cff0 <__gmpz_powm@@Base+0x2ac>
   1d418:	mov	w8, #0x1                   	// #1
   1d41c:	ldr	w9, [x23]
   1d420:	str	w8, [x23, #4]
   1d424:	cmp	w9, #0x0
   1d428:	b.le	1d598 <__gmpz_powm@@Base+0x854>
   1d42c:	ldr	x0, [x23, #8]
   1d430:	mov	w8, #0x1                   	// #1
   1d434:	str	x8, [x0]
   1d438:	b	1d53c <__gmpz_powm@@Base+0x7f8>
   1d43c:	mov	x0, x21
   1d440:	mov	x1, x11
   1d444:	mov	x2, x19
   1d448:	mov	x3, x26
   1d44c:	mov	x22, x11
   1d450:	bl	c2e0 <__gmpn_sub_n@plt>
   1d454:	cbz	x0, 1d480 <__gmpz_powm@@Base+0x73c>
   1d458:	mov	x11, x22
   1d45c:	cmp	x26, x20
   1d460:	b.cs	1d4b4 <__gmpz_powm@@Base+0x770>  // b.hs, b.nlast
   1d464:	ldr	x8, [x11, x26, lsl #3]
   1d468:	add	x10, x26, #0x1
   1d46c:	sub	x9, x8, #0x1
   1d470:	str	x9, [x21, x26, lsl #3]
   1d474:	mov	x26, x10
   1d478:	cbz	x8, 1d45c <__gmpz_powm@@Base+0x718>
   1d47c:	b	1d488 <__gmpz_powm@@Base+0x744>
   1d480:	mov	x10, x26
   1d484:	mov	x11, x22
   1d488:	cmp	x11, x21
   1d48c:	b.eq	1d4b4 <__gmpz_powm@@Base+0x770>  // b.none
   1d490:	cmp	x10, x20
   1d494:	b.ge	1d4b4 <__gmpz_powm@@Base+0x770>  // b.tcont
   1d498:	sub	x8, x20, x10
   1d49c:	add	x9, x21, x10, lsl #3
   1d4a0:	add	x10, x11, x10, lsl #3
   1d4a4:	ldr	x11, [x10], #8
   1d4a8:	subs	x8, x8, #0x1
   1d4ac:	str	x11, [x9], #8
   1d4b0:	b.ne	1d4a4 <__gmpz_powm@@Base+0x760>  // b.any
   1d4b4:	sub	x8, x21, #0x8
   1d4b8:	ldr	x10, [x8, x20, lsl #3]
   1d4bc:	sub	x9, x20, #0x1
   1d4c0:	mov	x20, x9
   1d4c4:	cbz	x10, 1d4b8 <__gmpz_powm@@Base+0x774>
   1d4c8:	add	x26, x9, #0x1
   1d4cc:	b	1d514 <__gmpz_powm@@Base+0x7d0>
   1d4d0:	mov	x10, x26
   1d4d4:	cmp	x22, x21
   1d4d8:	b.eq	1d500 <__gmpz_powm@@Base+0x7bc>  // b.none
   1d4dc:	cmp	x10, x20
   1d4e0:	b.ge	1d500 <__gmpz_powm@@Base+0x7bc>  // b.tcont
   1d4e4:	sub	x8, x20, x10
   1d4e8:	add	x9, x21, x10, lsl #3
   1d4ec:	add	x10, x22, x10, lsl #3
   1d4f0:	ldr	x11, [x10], #8
   1d4f4:	subs	x8, x8, #0x1
   1d4f8:	str	x11, [x9], #8
   1d4fc:	b.ne	1d4f0 <__gmpz_powm@@Base+0x7ac>  // b.any
   1d500:	ldr	x9, [x19, x20, lsl #3]
   1d504:	sub	x8, x20, #0x1
   1d508:	mov	x20, x8
   1d50c:	cbz	x9, 1d500 <__gmpz_powm@@Base+0x7bc>
   1d510:	add	x26, x8, #0x1
   1d514:	ldrsw	x8, [x23]
   1d518:	cmp	x26, x8
   1d51c:	b.gt	1d564 <__gmpz_powm@@Base+0x820>
   1d520:	ldr	x0, [x23, #8]
   1d524:	mov	x1, x21
   1d528:	mov	x2, x26
   1d52c:	str	w26, [x23, #4]
   1d530:	bl	ca70 <__gmpn_copyi@plt>
   1d534:	ldur	x0, [x29, #-24]
   1d538:	cbnz	x0, 1d55c <__gmpz_powm@@Base+0x818>
   1d53c:	mov	sp, x29
   1d540:	ldp	x20, x19, [sp, #80]
   1d544:	ldp	x22, x21, [sp, #64]
   1d548:	ldp	x24, x23, [sp, #48]
   1d54c:	ldp	x26, x25, [sp, #32]
   1d550:	ldp	x28, x27, [sp, #16]
   1d554:	ldp	x29, x30, [sp], #96
   1d558:	ret
   1d55c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1d560:	b	1d53c <__gmpz_powm@@Base+0x7f8>
   1d564:	mov	x0, x23
   1d568:	mov	x1, x26
   1d56c:	bl	c090 <__gmpz_realloc@plt>
   1d570:	b	1d520 <__gmpz_powm@@Base+0x7dc>
   1d574:	sub	x0, x29, #0x18
   1d578:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1d57c:	b	1d270 <__gmpz_powm@@Base+0x52c>
   1d580:	sub	x0, x29, #0x18
   1d584:	mov	x19, x11
   1d588:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1d58c:	mov	x11, x19
   1d590:	mov	x21, x0
   1d594:	b	1d2e0 <__gmpz_powm@@Base+0x59c>
   1d598:	mov	w1, #0x1                   	// #1
   1d59c:	mov	x0, x23
   1d5a0:	bl	c090 <__gmpz_realloc@plt>
   1d5a4:	b	1d430 <__gmpz_powm@@Base+0x6ec>
   1d5a8:	sub	x0, x29, #0x18
   1d5ac:	mov	x22, x11
   1d5b0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1d5b4:	mov	x11, x22
   1d5b8:	b	1d368 <__gmpz_powm@@Base+0x624>
   1d5bc:	bl	bfe0 <__gmp_divide_by_zero@plt>

000000000001d5c0 <__gmpz_powm_sec@@Base>:
   1d5c0:	stp	x29, x30, [sp, #-96]!
   1d5c4:	stp	x28, x27, [sp, #16]
   1d5c8:	stp	x26, x25, [sp, #32]
   1d5cc:	stp	x24, x23, [sp, #48]
   1d5d0:	stp	x22, x21, [sp, #64]
   1d5d4:	stp	x20, x19, [sp, #80]
   1d5d8:	mov	x29, sp
   1d5dc:	sub	sp, sp, #0x10
   1d5e0:	ldr	w8, [x3, #4]
   1d5e4:	cmp	w8, #0x0
   1d5e8:	cneg	w20, w8, mi  // mi = first
   1d5ec:	cbz	w20, 1d820 <__gmpz_powm_sec@@Base+0x260>
   1d5f0:	ldr	x25, [x3, #8]
   1d5f4:	mov	x22, x3
   1d5f8:	ldr	x8, [x25]
   1d5fc:	tbz	w8, #0, 1d820 <__gmpz_powm_sec@@Base+0x260>
   1d600:	ldrsw	x9, [x2, #4]
   1d604:	mov	x24, x2
   1d608:	mov	x19, x0
   1d60c:	cmp	w9, #0x0
   1d610:	b.le	1d7a8 <__gmpz_powm_sec@@Base+0x1e8>
   1d614:	ldr	w8, [x1, #4]
   1d618:	mov	x23, x1
   1d61c:	cmp	w8, #0x0
   1d620:	cneg	w26, w8, mi  // mi = first
   1d624:	cbz	w26, 1d7e0 <__gmpz_powm_sec@@Base+0x220>
   1d628:	lsl	x27, x9, #6
   1d62c:	mov	x0, x26
   1d630:	mov	x1, x27
   1d634:	mov	x2, x20
   1d638:	stur	xzr, [x29, #-8]
   1d63c:	bl	c240 <__gmpn_sec_powm_itch@plt>
   1d640:	add	x8, x0, x20
   1d644:	lsl	x1, x8, #3
   1d648:	mov	w8, #0x7f00                	// #32512
   1d64c:	cmp	x1, x8
   1d650:	b.hi	1d7e8 <__gmpz_powm_sec@@Base+0x228>  // b.pmore
   1d654:	add	x9, x1, #0xf
   1d658:	mov	x8, sp
   1d65c:	and	x9, x9, #0xfffffffffffffff0
   1d660:	sub	x21, x8, x9
   1d664:	mov	sp, x21
   1d668:	ldr	x28, [x24, #8]
   1d66c:	ldr	x1, [x23, #8]
   1d670:	add	x7, x21, x20, lsl #3
   1d674:	mov	x0, x21
   1d678:	mov	x2, x26
   1d67c:	mov	x3, x28
   1d680:	mov	x4, x27
   1d684:	mov	x5, x25
   1d688:	mov	x6, x20
   1d68c:	bl	cc80 <__gmpn_sec_powm@plt>
   1d690:	sub	x25, x21, #0x8
   1d694:	mov	x8, x20
   1d698:	subs	x9, x8, #0x1
   1d69c:	b.lt	1d6b4 <__gmpz_powm_sec@@Base+0xf4>  // b.tstop
   1d6a0:	ldr	x10, [x25, x8, lsl #3]
   1d6a4:	mov	x8, x9
   1d6a8:	cbz	x10, 1d698 <__gmpz_powm_sec@@Base+0xd8>
   1d6ac:	add	x24, x9, #0x1
   1d6b0:	b	1d6b8 <__gmpz_powm_sec@@Base+0xf8>
   1d6b4:	mov	x24, xzr
   1d6b8:	ldrb	w8, [x28]
   1d6bc:	tbz	w8, #0, 1d760 <__gmpz_powm_sec@@Base+0x1a0>
   1d6c0:	cbz	x24, 1d760 <__gmpz_powm_sec@@Base+0x1a0>
   1d6c4:	ldr	w8, [x23, #4]
   1d6c8:	tbz	w8, #31, 1d760 <__gmpz_powm_sec@@Base+0x1a0>
   1d6cc:	ldr	x22, [x22, #8]
   1d6d0:	mov	x0, x21
   1d6d4:	mov	x2, x21
   1d6d8:	mov	x3, x24
   1d6dc:	mov	x1, x22
   1d6e0:	bl	c2e0 <__gmpn_sub_n@plt>
   1d6e4:	cbz	x0, 1d70c <__gmpz_powm_sec@@Base+0x14c>
   1d6e8:	cmp	x24, x20
   1d6ec:	b.ge	1d74c <__gmpz_powm_sec@@Base+0x18c>  // b.tcont
   1d6f0:	ldr	x8, [x22, x24, lsl #3]
   1d6f4:	add	x10, x24, #0x1
   1d6f8:	sub	x9, x8, #0x1
   1d6fc:	str	x9, [x21, x24, lsl #3]
   1d700:	mov	x24, x10
   1d704:	cbz	x8, 1d6e8 <__gmpz_powm_sec@@Base+0x128>
   1d708:	b	1d710 <__gmpz_powm_sec@@Base+0x150>
   1d70c:	mov	x10, x24
   1d710:	cmp	x22, x21
   1d714:	b.eq	1d74c <__gmpz_powm_sec@@Base+0x18c>  // b.none
   1d718:	cmp	x10, x20
   1d71c:	b.ge	1d74c <__gmpz_powm_sec@@Base+0x18c>  // b.tcont
   1d720:	sub	x8, x20, x10
   1d724:	add	x9, x21, x10, lsl #3
   1d728:	add	x10, x22, x10, lsl #3
   1d72c:	ldr	x11, [x10], #8
   1d730:	subs	x8, x8, #0x1
   1d734:	str	x11, [x9], #8
   1d738:	b.ne	1d72c <__gmpz_powm_sec@@Base+0x16c>  // b.any
   1d73c:	b	1d74c <__gmpz_powm_sec@@Base+0x18c>
   1d740:	ldr	x9, [x25, x20, lsl #3]
   1d744:	mov	x20, x8
   1d748:	cbnz	x9, 1d75c <__gmpz_powm_sec@@Base+0x19c>
   1d74c:	subs	x8, x20, #0x1
   1d750:	b.ge	1d740 <__gmpz_powm_sec@@Base+0x180>  // b.tcont
   1d754:	mov	x24, xzr
   1d758:	b	1d760 <__gmpz_powm_sec@@Base+0x1a0>
   1d75c:	add	x24, x8, #0x1
   1d760:	ldrsw	x8, [x19]
   1d764:	cmp	x24, x8
   1d768:	b.gt	1d7f8 <__gmpz_powm_sec@@Base+0x238>
   1d76c:	ldr	x0, [x19, #8]
   1d770:	mov	x1, x21
   1d774:	mov	x2, x24
   1d778:	str	w24, [x19, #4]
   1d77c:	bl	ca70 <__gmpn_copyi@plt>
   1d780:	ldur	x0, [x29, #-8]
   1d784:	cbnz	x0, 1d808 <__gmpz_powm_sec@@Base+0x248>
   1d788:	mov	sp, x29
   1d78c:	ldp	x20, x19, [sp, #80]
   1d790:	ldp	x22, x21, [sp, #64]
   1d794:	ldp	x24, x23, [sp, #48]
   1d798:	ldp	x26, x25, [sp, #32]
   1d79c:	ldp	x28, x27, [sp, #16]
   1d7a0:	ldp	x29, x30, [sp], #96
   1d7a4:	ret
   1d7a8:	cbnz	w9, 1d820 <__gmpz_powm_sec@@Base+0x260>
   1d7ac:	ldr	w9, [x19]
   1d7b0:	cmp	w20, #0x1
   1d7b4:	cset	w10, ne  // ne = any
   1d7b8:	cmp	x8, #0x1
   1d7bc:	cset	w8, ne  // ne = any
   1d7c0:	orr	w8, w10, w8
   1d7c4:	cmp	w9, #0x0
   1d7c8:	str	w8, [x19, #4]
   1d7cc:	b.le	1d810 <__gmpz_powm_sec@@Base+0x250>
   1d7d0:	ldr	x0, [x19, #8]
   1d7d4:	mov	w8, #0x1                   	// #1
   1d7d8:	str	x8, [x0]
   1d7dc:	b	1d788 <__gmpz_powm_sec@@Base+0x1c8>
   1d7e0:	str	wzr, [x19, #4]
   1d7e4:	b	1d788 <__gmpz_powm_sec@@Base+0x1c8>
   1d7e8:	sub	x0, x29, #0x8
   1d7ec:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1d7f0:	mov	x21, x0
   1d7f4:	b	1d668 <__gmpz_powm_sec@@Base+0xa8>
   1d7f8:	mov	x0, x19
   1d7fc:	mov	x1, x24
   1d800:	bl	c090 <__gmpz_realloc@plt>
   1d804:	b	1d76c <__gmpz_powm_sec@@Base+0x1ac>
   1d808:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1d80c:	b	1d788 <__gmpz_powm_sec@@Base+0x1c8>
   1d810:	mov	w1, #0x1                   	// #1
   1d814:	mov	x0, x19
   1d818:	bl	c090 <__gmpz_realloc@plt>
   1d81c:	b	1d7d4 <__gmpz_powm_sec@@Base+0x214>
   1d820:	bl	bfe0 <__gmp_divide_by_zero@plt>

000000000001d824 <__gmpz_powm_ui@@Base>:
   1d824:	stp	x29, x30, [sp, #-96]!
   1d828:	stp	x28, x27, [sp, #16]
   1d82c:	stp	x26, x25, [sp, #32]
   1d830:	stp	x24, x23, [sp, #48]
   1d834:	stp	x22, x21, [sp, #64]
   1d838:	stp	x20, x19, [sp, #80]
   1d83c:	mov	x29, sp
   1d840:	sub	sp, sp, #0x40
   1d844:	mov	x26, x3
   1d848:	mov	x28, x2
   1d84c:	mov	x27, x1
   1d850:	cmp	x2, #0x13
   1d854:	mov	x25, x0
   1d858:	b.hi	1d890 <__gmpz_powm_ui@@Base+0x6c>  // b.pmore
   1d85c:	ldr	w8, [x26, #4]
   1d860:	cmp	w8, #0x0
   1d864:	cneg	w22, w8, mi  // mi = first
   1d868:	cbz	w22, 1dd68 <__gmpz_powm_ui@@Base+0x544>
   1d86c:	ldr	x24, [x26, #8]
   1d870:	cmp	x28, #0x1
   1d874:	b.hi	1d8b8 <__gmpz_powm_ui@@Base+0x94>  // b.pmore
   1d878:	b.ne	1d918 <__gmpz_powm_ui@@Base+0xf4>  // b.any
   1d87c:	mov	x0, x25
   1d880:	mov	x1, x27
   1d884:	mov	x2, x26
   1d888:	bl	ce10 <__gmpz_mod@plt>
   1d88c:	b	1dce8 <__gmpz_powm_ui@@Base+0x4c4>
   1d890:	sub	x8, x29, #0x8
   1d894:	mov	w9, #0x1                   	// #1
   1d898:	sub	x2, x29, #0x18
   1d89c:	mov	x0, x25
   1d8a0:	mov	x1, x27
   1d8a4:	mov	x3, x26
   1d8a8:	stp	x8, x28, [x29, #-16]
   1d8ac:	stur	w9, [x29, #-20]
   1d8b0:	bl	c390 <__gmpz_powm@plt>
   1d8b4:	b	1dce8 <__gmpz_powm_ui@@Base+0x4c4>
   1d8b8:	stur	xzr, [x29, #-8]
   1d8bc:	sub	x21, x22, #0x1
   1d8c0:	ldr	x8, [x24, x21, lsl #3]
   1d8c4:	lsl	x19, x22, #3
   1d8c8:	clz	x23, x8
   1d8cc:	cbz	w23, 1d904 <__gmpz_powm_ui@@Base+0xe0>
   1d8d0:	cmp	w22, #0xfe0
   1d8d4:	b.hi	1dd10 <__gmpz_powm_ui@@Base+0x4ec>  // b.pmore
   1d8d8:	add	x9, x19, #0xf
   1d8dc:	mov	x8, sp
   1d8e0:	and	x9, x9, #0xffffffff0
   1d8e4:	sub	x20, x8, x9
   1d8e8:	mov	sp, x20
   1d8ec:	mov	x0, x20
   1d8f0:	mov	x1, x24
   1d8f4:	mov	x2, x22
   1d8f8:	mov	w3, w23
   1d8fc:	bl	c190 <__gmpn_lshift@plt>
   1d900:	mov	x24, x20
   1d904:	cmp	w22, #0x1
   1d908:	stur	x23, [x29, #-48]
   1d90c:	b.ne	1d930 <__gmpz_powm_ui@@Base+0x10c>  // b.any
   1d910:	mov	x23, xzr
   1d914:	b	1d938 <__gmpz_powm_ui@@Base+0x114>
   1d918:	cmp	w22, #0x1
   1d91c:	b.ne	1dbd4 <__gmpz_powm_ui@@Base+0x3b0>  // b.any
   1d920:	ldr	x8, [x24]
   1d924:	cmp	x8, #0x1
   1d928:	cset	w8, ne  // ne = any
   1d92c:	b	1dbd8 <__gmpz_powm_ui@@Base+0x3b4>
   1d930:	add	x8, x24, x22, lsl #3
   1d934:	ldur	x23, [x8, #-16]
   1d938:	ldr	x20, [x24, x21, lsl #3]
   1d93c:	mov	x0, x20
   1d940:	bl	d410 <__gmpn_invert_limb@plt>
   1d944:	mul	x8, x0, x20
   1d948:	adds	x8, x8, x23
   1d94c:	b.cc	1d968 <__gmpz_powm_ui@@Base+0x144>  // b.lo, b.ul, b.last
   1d950:	subs	x8, x8, x20
   1d954:	cset	w9, cs  // cs = hs, nlast
   1d958:	csel	x10, x20, xzr, cs  // cs = hs, nlast
   1d95c:	mvn	x9, x9
   1d960:	add	x0, x9, x0
   1d964:	sub	x8, x8, x10
   1d968:	umulh	x9, x23, x0
   1d96c:	adds	x9, x9, x8
   1d970:	stur	x28, [x29, #-32]
   1d974:	b.cc	1d99c <__gmpz_powm_ui@@Base+0x178>  // b.lo, b.ul, b.last
   1d978:	cmp	x9, x20
   1d97c:	sub	x8, x0, #0x1
   1d980:	b.cc	1d9a0 <__gmpz_powm_ui@@Base+0x17c>  // b.lo, b.ul, b.last
   1d984:	mul	x10, x0, x23
   1d988:	cmp	x9, x20
   1d98c:	sub	x11, x0, #0x2
   1d990:	ccmp	x10, x23, #0x2, ls  // ls = plast
   1d994:	csel	x8, x8, x11, cc  // cc = lo, ul, last
   1d998:	b	1d9a0 <__gmpz_powm_ui@@Base+0x17c>
   1d99c:	mov	x8, x0
   1d9a0:	stur	x8, [x29, #-24]
   1d9a4:	ldr	w8, [x27, #4]
   1d9a8:	ldr	x28, [x27, #8]
   1d9ac:	stur	x27, [x29, #-40]
   1d9b0:	cmp	w8, #0x0
   1d9b4:	cneg	w27, w8, mi  // mi = first
   1d9b8:	cmp	w27, w22
   1d9bc:	b.ls	1da20 <__gmpz_powm_ui@@Base+0x1fc>  // b.plast
   1d9c0:	cmp	w22, #0xfe0
   1d9c4:	b.hi	1dd44 <__gmpz_powm_ui@@Base+0x520>  // b.pmore
   1d9c8:	add	x9, x19, #0xf
   1d9cc:	mov	x8, sp
   1d9d0:	and	x9, x9, #0xffffffff0
   1d9d4:	sub	x19, x8, x9
   1d9d8:	mov	sp, x19
   1d9dc:	sub	x5, x29, #0x18
   1d9e0:	mov	x0, x19
   1d9e4:	mov	x1, x28
   1d9e8:	mov	x2, x27
   1d9ec:	mov	x3, x24
   1d9f0:	mov	x4, x22
   1d9f4:	bl	1dd6c <__gmpz_powm_ui@@Base+0x548>
   1d9f8:	sub	x8, x19, #0x8
   1d9fc:	mov	x10, x22
   1da00:	subs	x9, x10, #0x1
   1da04:	b.lt	1dbcc <__gmpz_powm_ui@@Base+0x3a8>  // b.tstop
   1da08:	ldr	x11, [x8, x10, lsl #3]
   1da0c:	mov	x10, x9
   1da10:	cbz	x11, 1da00 <__gmpz_powm_ui@@Base+0x1dc>
   1da14:	add	x27, x9, #0x1
   1da18:	mov	x28, x19
   1da1c:	b	1da24 <__gmpz_powm_ui@@Base+0x200>
   1da20:	cbz	w27, 1dbcc <__gmpz_powm_ui@@Base+0x3a8>
   1da24:	add	x20, x22, #0x1
   1da28:	mov	w8, #0x1                   	// #1
   1da2c:	add	x9, x20, x22
   1da30:	bfi	x8, x22, #1, #32
   1da34:	add	x8, x9, x8
   1da38:	cmp	x8, #0xfe0
   1da3c:	lsl	x1, x8, #3
   1da40:	stp	x26, x25, [x29, #-64]
   1da44:	b.hi	1dd24 <__gmpz_powm_ui@@Base+0x500>  // b.pmore
   1da48:	add	x9, x1, #0xf
   1da4c:	mov	x8, sp
   1da50:	and	x9, x9, #0x7ffffffff0
   1da54:	sub	x26, x8, x9
   1da58:	mov	sp, x26
   1da5c:	add	x19, x26, x22, lsl #3
   1da60:	mov	x0, x26
   1da64:	mov	x1, x28
   1da68:	mov	x2, x27
   1da6c:	add	x25, x19, x20, lsl #3
   1da70:	bl	ca70 <__gmpn_copyi@plt>
   1da74:	ldur	x9, [x29, #-32]
   1da78:	mov	x20, x27
   1da7c:	clz	x8, x9
   1da80:	lsl	x21, x9, x8
   1da84:	sub	w23, w8, #0x3f
   1da88:	mov	x0, x25
   1da8c:	mov	x1, x26
   1da90:	mov	x2, x20
   1da94:	lsl	x21, x21, #1
   1da98:	bl	c900 <__gmpn_sqr@plt>
   1da9c:	add	x8, x25, x20, lsl #4
   1daa0:	ldur	x8, [x8, #-8]
   1daa4:	lsl	x9, x20, #1
   1daa8:	cmp	x8, #0x0
   1daac:	cset	w8, eq  // eq = none
   1dab0:	sub	x20, x9, x8
   1dab4:	cmp	x20, x22
   1dab8:	b.lt	1dadc <__gmpz_powm_ui@@Base+0x2b8>  // b.tstop
   1dabc:	sub	x4, x29, #0x18
   1dac0:	mov	x0, x25
   1dac4:	mov	x1, x20
   1dac8:	mov	x2, x24
   1dacc:	mov	x3, x22
   1dad0:	mov	x5, x19
   1dad4:	bl	1de50 <__gmpz_powm_ui@@Base+0x62c>
   1dad8:	mov	x20, x22
   1dadc:	mov	x0, x26
   1dae0:	mov	x1, x25
   1dae4:	mov	x2, x20
   1dae8:	bl	ca70 <__gmpn_copyi@plt>
   1daec:	tbz	x21, #63, 1db58 <__gmpz_powm_ui@@Base+0x334>
   1daf0:	mov	x0, x25
   1daf4:	mov	x1, x26
   1daf8:	mov	x2, x20
   1dafc:	mov	x3, x28
   1db00:	mov	x4, x27
   1db04:	bl	ccf0 <__gmpn_mul@plt>
   1db08:	add	x8, x20, x27
   1db0c:	add	x9, x25, x8, lsl #3
   1db10:	ldur	x9, [x9, #-8]
   1db14:	cmp	x9, #0x0
   1db18:	cset	w9, eq  // eq = none
   1db1c:	sub	x20, x8, x9
   1db20:	cmp	x20, x22
   1db24:	b.lt	1db48 <__gmpz_powm_ui@@Base+0x324>  // b.tstop
   1db28:	sub	x4, x29, #0x18
   1db2c:	mov	x0, x25
   1db30:	mov	x1, x20
   1db34:	mov	x2, x24
   1db38:	mov	x3, x22
   1db3c:	mov	x5, x19
   1db40:	bl	1de50 <__gmpz_powm_ui@@Base+0x62c>
   1db44:	mov	x20, x22
   1db48:	mov	x0, x26
   1db4c:	mov	x1, x25
   1db50:	mov	x2, x20
   1db54:	bl	ca70 <__gmpn_copyi@plt>
   1db58:	adds	w23, w23, #0x1
   1db5c:	b.cc	1da88 <__gmpz_powm_ui@@Base+0x264>  // b.lo, b.ul, b.last
   1db60:	ldur	x21, [x29, #-48]
   1db64:	cbz	w21, 1dbf8 <__gmpz_powm_ui@@Base+0x3d4>
   1db68:	mov	x0, x25
   1db6c:	mov	x1, x26
   1db70:	mov	x2, x20
   1db74:	mov	w3, w21
   1db78:	bl	c190 <__gmpn_lshift@plt>
   1db7c:	ldp	x27, x28, [x29, #-40]
   1db80:	cmp	x0, #0x0
   1db84:	str	x0, [x25, x20, lsl #3]
   1db88:	cinc	x20, x20, ne  // ne = any
   1db8c:	cmp	x20, x22
   1db90:	b.lt	1dbb4 <__gmpz_powm_ui@@Base+0x390>  // b.tstop
   1db94:	sub	x4, x29, #0x18
   1db98:	mov	x0, x25
   1db9c:	mov	x1, x20
   1dba0:	mov	x2, x24
   1dba4:	mov	x3, x22
   1dba8:	mov	x5, x19
   1dbac:	bl	1de50 <__gmpz_powm_ui@@Base+0x62c>
   1dbb0:	mov	x20, x22
   1dbb4:	mov	x0, x26
   1dbb8:	mov	x1, x25
   1dbbc:	mov	x2, x20
   1dbc0:	mov	w3, w21
   1dbc4:	bl	c1b0 <__gmpn_rshift@plt>
   1dbc8:	b	1dbfc <__gmpz_powm_ui@@Base+0x3d8>
   1dbcc:	str	wzr, [x25, #4]
   1dbd0:	b	1dce0 <__gmpz_powm_ui@@Base+0x4bc>
   1dbd4:	mov	w8, #0x1                   	// #1
   1dbd8:	ldr	w9, [x25]
   1dbdc:	str	w8, [x25, #4]
   1dbe0:	cmp	w9, #0x0
   1dbe4:	b.le	1dd58 <__gmpz_powm_ui@@Base+0x534>
   1dbe8:	ldr	x0, [x25, #8]
   1dbec:	mov	w8, #0x1                   	// #1
   1dbf0:	str	x8, [x0]
   1dbf4:	b	1dce8 <__gmpz_powm_ui@@Base+0x4c4>
   1dbf8:	ldp	x27, x28, [x29, #-40]
   1dbfc:	ldur	x23, [x29, #-56]
   1dc00:	sub	x21, x26, #0x8
   1dc04:	mov	x19, x20
   1dc08:	subs	x20, x20, #0x1
   1dc0c:	b.lt	1dc18 <__gmpz_powm_ui@@Base+0x3f4>  // b.tstop
   1dc10:	ldr	x8, [x21, x19, lsl #3]
   1dc14:	cbz	x8, 1dc04 <__gmpz_powm_ui@@Base+0x3e0>
   1dc18:	tbz	w28, #0, 1dcc0 <__gmpz_powm_ui@@Base+0x49c>
   1dc1c:	cbz	x19, 1dcc0 <__gmpz_powm_ui@@Base+0x49c>
   1dc20:	ldr	w8, [x27, #4]
   1dc24:	tbz	w8, #31, 1dcc0 <__gmpz_powm_ui@@Base+0x49c>
   1dc28:	ldur	x8, [x29, #-64]
   1dc2c:	mov	x0, x26
   1dc30:	mov	x2, x26
   1dc34:	mov	x3, x19
   1dc38:	ldr	x20, [x8, #8]
   1dc3c:	mov	x1, x20
   1dc40:	bl	c2e0 <__gmpn_sub_n@plt>
   1dc44:	cbz	x0, 1dc6c <__gmpz_powm_ui@@Base+0x448>
   1dc48:	cmp	x19, x22
   1dc4c:	b.ge	1dcac <__gmpz_powm_ui@@Base+0x488>  // b.tcont
   1dc50:	ldr	x8, [x20, x19, lsl #3]
   1dc54:	add	x10, x19, #0x1
   1dc58:	sub	x9, x8, #0x1
   1dc5c:	str	x9, [x26, x19, lsl #3]
   1dc60:	mov	x19, x10
   1dc64:	cbz	x8, 1dc48 <__gmpz_powm_ui@@Base+0x424>
   1dc68:	b	1dc70 <__gmpz_powm_ui@@Base+0x44c>
   1dc6c:	mov	x10, x19
   1dc70:	cmp	x20, x26
   1dc74:	b.eq	1dcac <__gmpz_powm_ui@@Base+0x488>  // b.none
   1dc78:	cmp	x10, x22
   1dc7c:	b.ge	1dcac <__gmpz_powm_ui@@Base+0x488>  // b.tcont
   1dc80:	sub	x8, x22, x10
   1dc84:	add	x9, x26, x10, lsl #3
   1dc88:	add	x10, x20, x10, lsl #3
   1dc8c:	ldr	x11, [x10], #8
   1dc90:	subs	x8, x8, #0x1
   1dc94:	str	x11, [x9], #8
   1dc98:	b.ne	1dc8c <__gmpz_powm_ui@@Base+0x468>  // b.any
   1dc9c:	b	1dcac <__gmpz_powm_ui@@Base+0x488>
   1dca0:	ldr	x9, [x21, x22, lsl #3]
   1dca4:	mov	x22, x8
   1dca8:	cbnz	x9, 1dcbc <__gmpz_powm_ui@@Base+0x498>
   1dcac:	subs	x8, x22, #0x1
   1dcb0:	b.ge	1dca0 <__gmpz_powm_ui@@Base+0x47c>  // b.tcont
   1dcb4:	mov	x19, xzr
   1dcb8:	b	1dcc0 <__gmpz_powm_ui@@Base+0x49c>
   1dcbc:	add	x19, x8, #0x1
   1dcc0:	ldrsw	x8, [x23]
   1dcc4:	cmp	x19, x8
   1dcc8:	b.gt	1dd34 <__gmpz_powm_ui@@Base+0x510>
   1dccc:	ldr	x0, [x23, #8]
   1dcd0:	mov	x1, x26
   1dcd4:	mov	x2, x19
   1dcd8:	str	w19, [x23, #4]
   1dcdc:	bl	ca70 <__gmpn_copyi@plt>
   1dce0:	ldur	x0, [x29, #-8]
   1dce4:	cbnz	x0, 1dd08 <__gmpz_powm_ui@@Base+0x4e4>
   1dce8:	mov	sp, x29
   1dcec:	ldp	x20, x19, [sp, #80]
   1dcf0:	ldp	x22, x21, [sp, #64]
   1dcf4:	ldp	x24, x23, [sp, #48]
   1dcf8:	ldp	x26, x25, [sp, #32]
   1dcfc:	ldp	x28, x27, [sp, #16]
   1dd00:	ldp	x29, x30, [sp], #96
   1dd04:	ret
   1dd08:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1dd0c:	b	1dce8 <__gmpz_powm_ui@@Base+0x4c4>
   1dd10:	sub	x0, x29, #0x8
   1dd14:	mov	x1, x19
   1dd18:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1dd1c:	mov	x20, x0
   1dd20:	b	1d8ec <__gmpz_powm_ui@@Base+0xc8>
   1dd24:	sub	x0, x29, #0x8
   1dd28:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1dd2c:	mov	x26, x0
   1dd30:	b	1da5c <__gmpz_powm_ui@@Base+0x238>
   1dd34:	mov	x0, x23
   1dd38:	mov	x1, x19
   1dd3c:	bl	c090 <__gmpz_realloc@plt>
   1dd40:	b	1dccc <__gmpz_powm_ui@@Base+0x4a8>
   1dd44:	sub	x0, x29, #0x8
   1dd48:	mov	x1, x19
   1dd4c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1dd50:	mov	x19, x0
   1dd54:	b	1d9dc <__gmpz_powm_ui@@Base+0x1b8>
   1dd58:	mov	w1, #0x1                   	// #1
   1dd5c:	mov	x0, x25
   1dd60:	bl	c090 <__gmpz_realloc@plt>
   1dd64:	b	1dbec <__gmpz_powm_ui@@Base+0x3c8>
   1dd68:	bl	bfe0 <__gmp_divide_by_zero@plt>
   1dd6c:	stp	x29, x30, [sp, #-80]!
   1dd70:	stp	x26, x25, [sp, #16]
   1dd74:	stp	x24, x23, [sp, #32]
   1dd78:	stp	x22, x21, [sp, #48]
   1dd7c:	stp	x20, x19, [sp, #64]
   1dd80:	mov	x29, sp
   1dd84:	sub	sp, sp, #0x10
   1dd88:	mov	w8, #0x1                   	// #1
   1dd8c:	bfi	x8, x2, #1, #63
   1dd90:	sub	x8, x8, x4
   1dd94:	mov	x24, x1
   1dd98:	lsl	x1, x8, #3
   1dd9c:	mov	w8, #0x7f00                	// #32512
   1dda0:	mov	x21, x5
   1dda4:	mov	x19, x4
   1dda8:	mov	x22, x3
   1ddac:	mov	x23, x2
   1ddb0:	mov	x20, x0
   1ddb4:	cmp	x1, x8
   1ddb8:	stur	xzr, [x29, #-8]
   1ddbc:	b.hi	1de38 <__gmpz_powm_ui@@Base+0x614>  // b.pmore
   1ddc0:	add	x9, x1, #0xf
   1ddc4:	mov	x8, sp
   1ddc8:	and	x9, x9, #0xfffffffffffffff0
   1ddcc:	sub	x25, x8, x9
   1ddd0:	mov	sp, x25
   1ddd4:	mov	x0, x25
   1ddd8:	mov	x1, x24
   1dddc:	mov	x2, x23
   1dde0:	add	x26, x25, x23, lsl #3
   1dde4:	bl	ca70 <__gmpn_copyi@plt>
   1dde8:	mov	x0, x25
   1ddec:	mov	x1, x23
   1ddf0:	mov	x2, x22
   1ddf4:	mov	x3, x19
   1ddf8:	mov	x4, x21
   1ddfc:	mov	x5, x26
   1de00:	bl	1de50 <__gmpz_powm_ui@@Base+0x62c>
   1de04:	mov	x0, x20
   1de08:	mov	x1, x25
   1de0c:	mov	x2, x19
   1de10:	bl	ca70 <__gmpn_copyi@plt>
   1de14:	ldur	x0, [x29, #-8]
   1de18:	cbnz	x0, 1de48 <__gmpz_powm_ui@@Base+0x624>
   1de1c:	mov	sp, x29
   1de20:	ldp	x20, x19, [sp, #64]
   1de24:	ldp	x22, x21, [sp, #48]
   1de28:	ldp	x24, x23, [sp, #32]
   1de2c:	ldp	x26, x25, [sp, #16]
   1de30:	ldp	x29, x30, [sp], #80
   1de34:	ret
   1de38:	sub	x0, x29, #0x8
   1de3c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1de40:	mov	x25, x0
   1de44:	b	1ddd4 <__gmpz_powm_ui@@Base+0x5b0>
   1de48:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1de4c:	b	1de1c <__gmpz_powm_ui@@Base+0x5f8>
   1de50:	stp	x29, x30, [sp, #-80]!
   1de54:	stp	x24, x23, [sp, #32]
   1de58:	stp	x22, x21, [sp, #48]
   1de5c:	stp	x20, x19, [sp, #64]
   1de60:	mov	x23, x5
   1de64:	mov	x8, x4
   1de68:	mov	x22, x2
   1de6c:	mov	x21, x1
   1de70:	cmp	x3, #0x2
   1de74:	mov	x19, x0
   1de78:	str	x25, [sp, #16]
   1de7c:	mov	x29, sp
   1de80:	b.eq	1dec4 <__gmpz_powm_ui@@Base+0x6a0>  // b.none
   1de84:	mov	x20, x3
   1de88:	cmp	x3, #0x1
   1de8c:	b.ne	1def4 <__gmpz_powm_ui@@Base+0x6d0>  // b.any
   1de90:	ldr	x4, [x22]
   1de94:	mov	x0, x23
   1de98:	mov	x1, xzr
   1de9c:	mov	x2, x19
   1dea0:	mov	x3, x21
   1dea4:	bl	cd20 <__gmpn_divrem_1@plt>
   1dea8:	str	x0, [x19]
   1deac:	ldp	x20, x19, [sp, #64]
   1deb0:	ldp	x22, x21, [sp, #48]
   1deb4:	ldp	x24, x23, [sp, #32]
   1deb8:	ldr	x25, [sp, #16]
   1debc:	ldp	x29, x30, [sp], #80
   1dec0:	ret
   1dec4:	ldp	x5, x4, [x22]
   1dec8:	ldr	x6, [x8]
   1decc:	mov	x0, x23
   1ded0:	mov	x1, x19
   1ded4:	mov	x2, x19
   1ded8:	mov	x3, x21
   1dedc:	ldp	x20, x19, [sp, #64]
   1dee0:	ldp	x22, x21, [sp, #48]
   1dee4:	ldp	x24, x23, [sp, #32]
   1dee8:	ldr	x25, [sp, #16]
   1deec:	ldp	x29, x30, [sp], #80
   1def0:	b	c940 <__gmpn_div_qr_2n_pi1@plt>
   1def4:	cmp	x20, #0x2a
   1def8:	b.lt	1df78 <__gmpz_powm_ui@@Base+0x754>  // b.tstop
   1defc:	sub	x9, x21, x20
   1df00:	cmp	x9, #0x29
   1df04:	b.le	1df78 <__gmpz_powm_ui@@Base+0x754>
   1df08:	cmp	x21, #0x7cc
   1df0c:	b.lt	1df48 <__gmpz_powm_ui@@Base+0x724>  // b.tstop
   1df10:	cmp	x20, #0x62
   1df14:	b.lt	1df48 <__gmpz_powm_ui@@Base+0x724>  // b.tstop
   1df18:	adrp	x9, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   1df1c:	adrp	x10, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   1df20:	ldr	d0, [x9, #840]
   1df24:	ldr	d1, [x10, #848]
   1df28:	scvtf	d2, x20
   1df2c:	scvtf	d3, x21
   1df30:	fmul	d0, d2, d0
   1df34:	fmul	d1, d3, d1
   1df38:	fadd	d0, d1, d0
   1df3c:	fmul	d1, d3, d2
   1df40:	fcmp	d0, d1
   1df44:	b.le	1dfa8 <__gmpz_powm_ui@@Base+0x784>
   1df48:	mov	x0, x23
   1df4c:	mov	x1, x19
   1df50:	mov	x2, x21
   1df54:	mov	x3, x22
   1df58:	mov	x4, x20
   1df5c:	ldp	x20, x19, [sp, #64]
   1df60:	ldp	x22, x21, [sp, #48]
   1df64:	ldp	x24, x23, [sp, #32]
   1df68:	ldr	x25, [sp, #16]
   1df6c:	mov	x5, x8
   1df70:	ldp	x29, x30, [sp], #80
   1df74:	b	c3d0 <__gmpn_dcpi1_div_qr@plt>
   1df78:	ldr	x5, [x8]
   1df7c:	mov	x0, x23
   1df80:	mov	x1, x19
   1df84:	mov	x2, x21
   1df88:	mov	x3, x22
   1df8c:	mov	x4, x20
   1df90:	ldp	x20, x19, [sp, #64]
   1df94:	ldp	x22, x21, [sp, #48]
   1df98:	ldp	x24, x23, [sp, #32]
   1df9c:	ldr	x25, [sp, #16]
   1dfa0:	ldp	x29, x30, [sp], #80
   1dfa4:	b	c660 <__gmpn_sbpi1_div_qr@plt>
   1dfa8:	mov	x0, x21
   1dfac:	mov	x1, x20
   1dfb0:	mov	w2, wzr
   1dfb4:	str	xzr, [x29, #24]
   1dfb8:	bl	d030 <__gmpn_mu_div_qr_itch@plt>
   1dfbc:	mov	x24, x0
   1dfc0:	lsl	x1, x20, #3
   1dfc4:	add	x0, x29, #0x18
   1dfc8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1dfcc:	mov	x25, x0
   1dfd0:	lsl	x1, x24, #3
   1dfd4:	add	x0, x29, #0x18
   1dfd8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1dfdc:	mov	x6, x0
   1dfe0:	mov	x0, x23
   1dfe4:	mov	x1, x25
   1dfe8:	mov	x2, x19
   1dfec:	mov	x3, x21
   1dff0:	mov	x4, x22
   1dff4:	mov	x5, x20
   1dff8:	bl	c980 <__gmpn_mu_div_qr@plt>
   1dffc:	mov	x0, x19
   1e000:	mov	x1, x25
   1e004:	mov	x2, x20
   1e008:	bl	ca70 <__gmpn_copyi@plt>
   1e00c:	ldr	x0, [x29, #24]
   1e010:	cbz	x0, 1deac <__gmpz_powm_ui@@Base+0x688>
   1e014:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1e018:	b	1deac <__gmpz_powm_ui@@Base+0x688>

000000000001e01c <__gmpz_primorial_ui@@Base>:
   1e01c:	stp	x29, x30, [sp, #-48]!
   1e020:	stp	x20, x19, [sp, #32]
   1e024:	mov	x20, x1
   1e028:	cmp	x1, #0x4
   1e02c:	mov	x19, x0
   1e030:	str	x21, [sp, #16]
   1e034:	mov	x29, sp
   1e038:	b.hi	1e06c <__gmpz_primorial_ui@@Base+0x50>  // b.pmore
   1e03c:	ldr	w8, [x19]
   1e040:	add	w9, w20, w20, lsl #1
   1e044:	mov	w10, #0x6c89                	// #27785
   1e048:	lsr	w9, w10, w9
   1e04c:	cmp	w8, #0x0
   1e050:	and	w20, w9, #0x7
   1e054:	b.le	1e1a8 <__gmpz_primorial_ui@@Base+0x18c>
   1e058:	ldr	x0, [x19, #8]
   1e05c:	mov	w8, #0x1                   	// #1
   1e060:	str	x20, [x0]
   1e064:	str	w8, [x19, #4]
   1e068:	b	1e194 <__gmpz_primorial_ui@@Base+0x178>
   1e06c:	ldrsw	x9, [x19]
   1e070:	lsr	x8, x20, #6
   1e074:	add	x8, x8, x20, lsr #7
   1e078:	cmp	x8, x9
   1e07c:	b.ge	1e1b8 <__gmpz_primorial_ui@@Base+0x19c>  // b.tcont
   1e080:	ldr	x21, [x19, #8]
   1e084:	mov	x0, x21
   1e088:	mov	x1, x20
   1e08c:	bl	d220 <__gmp_primesieve@plt>
   1e090:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1e094:	ldr	x9, [x9, #3880]
   1e098:	mov	w8, #0x9                   	// #9
   1e09c:	sub	w10, w8, #0x2
   1e0a0:	ldr	x10, [x9, w10, uxtw #3]
   1e0a4:	sub	w8, w8, #0x1
   1e0a8:	cmp	x10, x20
   1e0ac:	b.cc	1e09c <__gmpz_primorial_ui@@Base+0x80>  // b.lo, b.ul, b.last
   1e0b0:	add	x9, x0, #0x1
   1e0b4:	mov	w8, w8
   1e0b8:	udiv	x8, x9, x8
   1e0bc:	lsl	x8, x8, #3
   1e0c0:	add	x1, x8, #0x8
   1e0c4:	mov	w8, #0x7f00                	// #32512
   1e0c8:	cmp	x1, x8
   1e0cc:	str	xzr, [x29, #24]
   1e0d0:	b.hi	1e1cc <__gmpz_primorial_ui@@Base+0x1b0>  // b.pmore
   1e0d4:	add	x9, x1, #0xf
   1e0d8:	mov	x8, sp
   1e0dc:	and	x9, x9, #0xfffffffffffffff0
   1e0e0:	sub	x1, x8, x9
   1e0e4:	mov	sp, x1
   1e0e8:	sub	x12, x20, #0x5
   1e0ec:	mov	x13, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   1e0f0:	movk	x13, #0xaaab
   1e0f4:	orr	x12, x12, #0x1
   1e0f8:	umulh	x12, x12, x13
   1e0fc:	mov	x9, xzr
   1e100:	mov	x8, xzr
   1e104:	mov	x11, #0xffffffffffffffff    	// #-1
   1e108:	mov	w14, #0x1                   	// #1
   1e10c:	mov	w10, #0x6                   	// #6
   1e110:	lsr	x12, x12, #1
   1e114:	mov	w13, #0x4                   	// #4
   1e118:	ldr	x15, [x21, x9, lsl #3]
   1e11c:	tst	x15, x14
   1e120:	b.ne	1e14c <__gmpz_primorial_ui@@Base+0x130>  // b.any
   1e124:	and	x15, x11, #0x1
   1e128:	umulh	x16, x20, x10
   1e12c:	add	x15, x13, x15
   1e130:	cbz	x16, 1e148 <__gmpz_primorial_ui@@Base+0x12c>
   1e134:	add	x16, x8, #0x1
   1e138:	str	x10, [x1, x8, lsl #3]
   1e13c:	mov	x10, x15
   1e140:	mov	x8, x16
   1e144:	b	1e14c <__gmpz_primorial_ui@@Base+0x130>
   1e148:	mul	x10, x15, x10
   1e14c:	add	x11, x11, #0x1
   1e150:	add	x9, x9, x14, lsr #63
   1e154:	ror	x14, x14, #63
   1e158:	cmp	x11, x12
   1e15c:	add	x13, x13, #0x3
   1e160:	b.cc	1e118 <__gmpz_primorial_ui@@Base+0xfc>  // b.lo, b.ul, b.last
   1e164:	cbz	x8, 1e17c <__gmpz_primorial_ui@@Base+0x160>
   1e168:	add	x2, x8, #0x1
   1e16c:	mov	x0, x19
   1e170:	str	x10, [x1, x8, lsl #3]
   1e174:	bl	cd90 <__gmpz_prodlimbs@plt>
   1e178:	b	1e18c <__gmpz_primorial_ui@@Base+0x170>
   1e17c:	ldr	x8, [x19, #8]
   1e180:	mov	w9, #0x1                   	// #1
   1e184:	str	x10, [x8]
   1e188:	str	w9, [x19, #4]
   1e18c:	ldr	x0, [x29, #24]
   1e190:	cbnz	x0, 1e1dc <__gmpz_primorial_ui@@Base+0x1c0>
   1e194:	mov	sp, x29
   1e198:	ldp	x20, x19, [sp, #32]
   1e19c:	ldr	x21, [sp, #16]
   1e1a0:	ldp	x29, x30, [sp], #48
   1e1a4:	ret
   1e1a8:	mov	w1, #0x1                   	// #1
   1e1ac:	mov	x0, x19
   1e1b0:	bl	c090 <__gmpz_realloc@plt>
   1e1b4:	b	1e05c <__gmpz_primorial_ui@@Base+0x40>
   1e1b8:	add	x1, x8, #0x1
   1e1bc:	mov	x0, x19
   1e1c0:	bl	c090 <__gmpz_realloc@plt>
   1e1c4:	mov	x21, x0
   1e1c8:	b	1e084 <__gmpz_primorial_ui@@Base+0x68>
   1e1cc:	add	x0, x29, #0x18
   1e1d0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1e1d4:	mov	x1, x0
   1e1d8:	b	1e0e8 <__gmpz_primorial_ui@@Base+0xcc>
   1e1dc:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1e1e0:	b	1e194 <__gmpz_primorial_ui@@Base+0x178>

000000000001e1e4 <__gmpz_probab_prime_p@@Base>:
   1e1e4:	sub	sp, sp, #0xb0
   1e1e8:	stp	x20, x19, [sp, #160]
   1e1ec:	mov	w19, w1
   1e1f0:	mov	w1, #0x4240                	// #16960
   1e1f4:	movk	w1, #0xf, lsl #16
   1e1f8:	stp	x29, x30, [sp, #80]
   1e1fc:	str	x27, [sp, #96]
   1e200:	stp	x26, x25, [sp, #112]
   1e204:	stp	x24, x23, [sp, #128]
   1e208:	stp	x22, x21, [sp, #144]
   1e20c:	add	x29, sp, #0x50
   1e210:	mov	x20, x0
   1e214:	bl	d210 <__gmpz_cmp_ui@plt>
   1e218:	cmp	w0, #0x0
   1e21c:	b.gt	1e250 <__gmpz_probab_prime_p@@Base+0x6c>
   1e220:	mov	w1, #0x4240                	// #16960
   1e224:	movk	w1, #0xf, lsl #16
   1e228:	mov	x0, x20
   1e22c:	bl	c110 <__gmpz_cmpabs_ui@plt>
   1e230:	cmp	w0, #0x0
   1e234:	b.le	1e5cc <__gmpz_probab_prime_p@@Base+0x3e8>
   1e238:	ldr	x8, [x20, #8]
   1e23c:	stur	x8, [x29, #-8]
   1e240:	ldr	w8, [x20, #4]
   1e244:	sub	x20, x29, #0x10
   1e248:	neg	w8, w8
   1e24c:	stur	w8, [x29, #-12]
   1e250:	ldr	x22, [x20, #8]
   1e254:	ldrsw	x21, [x20, #4]
   1e258:	ldr	w8, [x22]
   1e25c:	cmp	x21, #0x0
   1e260:	cset	w9, ne  // ne = any
   1e264:	tst	w8, w9
   1e268:	b.eq	1e64c <__gmpz_probab_prime_p@@Base+0x468>  // b.none
   1e26c:	mov	x2, #0x4e1d                	// #19997
   1e270:	movk	x2, #0x30e9, lsl #16
   1e274:	movk	x2, #0xf97c, lsl #32
   1e278:	movk	x2, #0xe221, lsl #48
   1e27c:	cmp	w21, #0x14
   1e280:	b.le	1e294 <__gmpz_probab_prime_p@@Base+0xb0>
   1e284:	mov	x0, x22
   1e288:	mov	x1, x21
   1e28c:	bl	c400 <__gmpn_mod_1@plt>
   1e290:	b	1e2b0 <__gmpz_probab_prime_p@@Base+0xcc>
   1e294:	mov	x3, #0xb36b                	// #45931
   1e298:	movk	x3, #0xc938, lsl #16
   1e29c:	movk	x3, #0xe6cf, lsl #32
   1e2a0:	movk	x3, #0x21cf, lsl #48
   1e2a4:	mov	x0, x22
   1e2a8:	mov	x1, x21
   1e2ac:	bl	c6f0 <__gmpn_preinv_mod_1@plt>
   1e2b0:	mov	x9, #0x521d                	// #21021
   1e2b4:	movk	x9, #0x8c13, lsl #16
   1e2b8:	mov	x10, #0x304e                	// #12366
   1e2bc:	movk	x9, #0xb2b7, lsl #32
   1e2c0:	movk	x10, #0xcade, lsl #16
   1e2c4:	movk	x9, #0x21cf, lsl #48
   1e2c8:	movk	x10, #0x873e, lsl #32
   1e2cc:	mul	x9, x0, x9
   1e2d0:	movk	x10, #0x4d4, lsl #48
   1e2d4:	mov	x8, x0
   1e2d8:	cmp	x9, x10
   1e2dc:	mov	w0, wzr
   1e2e0:	b.cc	1e650 <__gmpz_probab_prime_p@@Base+0x46c>  // b.lo, b.ul, b.last
   1e2e4:	mov	x9, #0x7263                	// #29283
   1e2e8:	movk	x9, #0x3105, lsl #16
   1e2ec:	movk	x9, #0x82b9, lsl #32
   1e2f0:	movk	x9, #0x5c98, lsl #48
   1e2f4:	umulh	x9, x8, x9
   1e2f8:	sub	x10, x8, x9
   1e2fc:	add	x9, x9, x10, lsr #1
   1e300:	lsr	x9, x9, #5
   1e304:	mov	w10, #0x2f                  	// #47
   1e308:	msub	x9, x9, x10, x8
   1e30c:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e310:	mov	x9, #0xa0bf                	// #41151
   1e314:	movk	x9, #0xe82f, lsl #16
   1e318:	movk	x9, #0xfa0b, lsl #32
   1e31c:	movk	x9, #0xbe82, lsl #48
   1e320:	umulh	x9, x8, x9
   1e324:	lsr	x9, x9, #5
   1e328:	mov	w10, #0x2b                  	// #43
   1e32c:	msub	x9, x9, x10, x8
   1e330:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e334:	mov	x9, #0xce0d                	// #52749
   1e338:	movk	x9, #0xe0c7, lsl #16
   1e33c:	movk	x9, #0xc7c, lsl #32
   1e340:	movk	x9, #0xc7ce, lsl #48
   1e344:	umulh	x9, x8, x9
   1e348:	lsr	x9, x9, #5
   1e34c:	mov	w10, #0x29                  	// #41
   1e350:	msub	x9, x9, x10, x8
   1e354:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e358:	mov	x9, #0x7c8b                	// #31883
   1e35c:	movk	x9, #0xdd6, lsl #16
   1e360:	movk	x9, #0xc8a6, lsl #32
   1e364:	movk	x9, #0xdd67, lsl #48
   1e368:	umulh	x9, x8, x9
   1e36c:	lsr	x9, x9, #5
   1e370:	mov	w10, #0x25                  	// #37
   1e374:	msub	x9, x9, x10, x8
   1e378:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e37c:	mov	x9, #0x4211                	// #16913
   1e380:	movk	x9, #0x2108, lsl #16
   1e384:	movk	x9, #0x1084, lsl #32
   1e388:	movk	x9, #0x842, lsl #48
   1e38c:	umulh	x9, x8, x9
   1e390:	sub	x10, x8, x9
   1e394:	add	x9, x9, x10, lsr #1
   1e398:	lsr	x9, x9, #4
   1e39c:	sub	x9, x9, x9, lsl #5
   1e3a0:	add	x9, x8, x9
   1e3a4:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e3a8:	mov	x9, #0x611b                	// #24859
   1e3ac:	movk	x9, #0xa7b9, lsl #16
   1e3b0:	movk	x9, #0x9611, lsl #32
   1e3b4:	movk	x9, #0x1a7b, lsl #48
   1e3b8:	umulh	x9, x8, x9
   1e3bc:	sub	x10, x8, x9
   1e3c0:	add	x9, x9, x10, lsr #1
   1e3c4:	lsr	x9, x9, #4
   1e3c8:	mov	w10, #0x1d                  	// #29
   1e3cc:	msub	x9, x9, x10, x8
   1e3d0:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e3d4:	mov	x9, #0x42c9                	// #17097
   1e3d8:	movk	x9, #0xb216, lsl #16
   1e3dc:	movk	x9, #0x8590, lsl #32
   1e3e0:	movk	x9, #0x642c, lsl #48
   1e3e4:	umulh	x9, x8, x9
   1e3e8:	sub	x10, x8, x9
   1e3ec:	add	x9, x9, x10, lsr #1
   1e3f0:	lsr	x9, x9, #4
   1e3f4:	mov	w10, #0x17                  	// #23
   1e3f8:	msub	x9, x9, x10, x8
   1e3fc:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e400:	mov	x9, #0x435f                	// #17247
   1e404:	movk	x9, #0xd79, lsl #16
   1e408:	movk	x9, #0x35e5, lsl #32
   1e40c:	movk	x9, #0xd794, lsl #48
   1e410:	umulh	x9, x8, x9
   1e414:	lsr	x9, x9, #4
   1e418:	mov	w10, #0x13                  	// #19
   1e41c:	msub	x9, x9, x10, x8
   1e420:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e424:	mov	x9, #0xf0f0f0f0f0f0f0f0    	// #-1085102592571150096
   1e428:	movk	x9, #0xf0f1
   1e42c:	umulh	x9, x8, x9
   1e430:	lsr	x10, x9, #4
   1e434:	lsl	x10, x10, #4
   1e438:	add	x9, x10, x9, lsr #4
   1e43c:	sub	x9, x8, x9
   1e440:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e444:	mov	x9, #0x4ec5                	// #20165
   1e448:	movk	x9, #0xc4ec, lsl #16
   1e44c:	movk	x9, #0xec4e, lsl #32
   1e450:	movk	x9, #0x4ec4, lsl #48
   1e454:	umulh	x9, x8, x9
   1e458:	lsr	x9, x9, #2
   1e45c:	mov	w10, #0xd                   	// #13
   1e460:	msub	x9, x9, x10, x8
   1e464:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e468:	mov	x9, #0x8ba3                	// #35747
   1e46c:	movk	x9, #0xba2e, lsl #16
   1e470:	movk	x9, #0xa2e8, lsl #32
   1e474:	movk	x9, #0x2e8b, lsl #48
   1e478:	umulh	x9, x8, x9
   1e47c:	lsr	x9, x9, #1
   1e480:	mov	w10, #0xb                   	// #11
   1e484:	msub	x9, x9, x10, x8
   1e488:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e48c:	mov	x9, #0x2493                	// #9363
   1e490:	movk	x9, #0x9249, lsl #16
   1e494:	movk	x9, #0x4924, lsl #32
   1e498:	movk	x9, #0x2492, lsl #48
   1e49c:	umulh	x9, x8, x9
   1e4a0:	sub	x10, x8, x9
   1e4a4:	add	x9, x9, x10, lsr #1
   1e4a8:	lsr	x9, x9, #2
   1e4ac:	sub	x9, x9, x9, lsl #3
   1e4b0:	add	x9, x8, x9
   1e4b4:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e4b8:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   1e4bc:	movk	x9, #0xaaab
   1e4c0:	umulh	x9, x8, x9
   1e4c4:	lsr	x10, x9, #1
   1e4c8:	lsl	x10, x10, #1
   1e4cc:	add	x9, x10, x9, lsr #1
   1e4d0:	sub	x9, x8, x9
   1e4d4:	cbz	x9, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e4d8:	mov	x9, #0xcccccccccccccccc    	// #-3689348814741910324
   1e4dc:	movk	x9, #0xcccd
   1e4e0:	umulh	x9, x8, x9
   1e4e4:	lsr	x10, x9, #2
   1e4e8:	lsl	x10, x10, #2
   1e4ec:	add	x9, x10, x9, lsr #2
   1e4f0:	sub	x8, x8, x9
   1e4f4:	cbz	x8, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e4f8:	mov	w1, #0x2                   	// #2
   1e4fc:	mov	x0, x20
   1e500:	bl	d280 <__gmpz_sizeinbase@plt>
   1e504:	cmp	x0, #0x3c
   1e508:	b.cc	1e5bc <__gmpz_probab_prime_p@@Base+0x3d8>  // b.lo, b.ul, b.last
   1e50c:	add	x24, sp, #0x4
   1e510:	mov	x23, x0
   1e514:	mov	w27, wzr
   1e518:	mov	w25, #0x3b                  	// #59
   1e51c:	sub	x26, x24, #0x4
   1e520:	mov	w2, #0x1                   	// #1
   1e524:	mov	w8, #0x3                   	// #3
   1e528:	udiv	x9, x25, x8
   1e52c:	cmp	x9, x8
   1e530:	b.cc	1e548 <__gmpz_probab_prime_p@@Base+0x364>  // b.lo, b.ul, b.last
   1e534:	mul	x9, x9, x8
   1e538:	cmp	x9, x25
   1e53c:	add	x8, x8, #0x2
   1e540:	b.ne	1e528 <__gmpz_probab_prime_p@@Base+0x344>  // b.any
   1e544:	b	1e5b0 <__gmpz_probab_prime_p@@Base+0x3cc>
   1e548:	umulh	x8, x2, x25
   1e54c:	cbz	x8, 1e568 <__gmpz_probab_prime_p@@Base+0x384>
   1e550:	mov	x0, x22
   1e554:	mov	x1, x21
   1e558:	cmp	w21, #0x27
   1e55c:	b.le	1e570 <__gmpz_probab_prime_p@@Base+0x38c>
   1e560:	bl	c400 <__gmpn_mod_1@plt>
   1e564:	b	1e578 <__gmpz_probab_prime_p@@Base+0x394>
   1e568:	mul	x2, x2, x25
   1e56c:	b	1e5a4 <__gmpz_probab_prime_p@@Base+0x3c0>
   1e570:	mov	x3, xzr
   1e574:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   1e578:	sxtw	x8, w27
   1e57c:	subs	x9, x8, #0x1
   1e580:	b.lt	1e59c <__gmpz_probab_prime_p@@Base+0x3b8>  // b.tstop
   1e584:	ldr	w2, [x26, x8, lsl #2]
   1e588:	udiv	x8, x0, x2
   1e58c:	msub	x10, x8, x2, x0
   1e590:	mov	x8, x9
   1e594:	cbnz	x10, 1e57c <__gmpz_probab_prime_p@@Base+0x398>
   1e598:	b	1e614 <__gmpz_probab_prime_p@@Base+0x430>
   1e59c:	mov	w27, wzr
   1e5a0:	mov	x2, x25
   1e5a4:	add	w8, w27, #0x1
   1e5a8:	str	w25, [x24, w27, sxtw #2]
   1e5ac:	mov	w27, w8
   1e5b0:	add	x25, x25, #0x2
   1e5b4:	cmp	x25, x23
   1e5b8:	b.cc	1e524 <__gmpz_probab_prime_p@@Base+0x340>  // b.lo, b.ul, b.last
   1e5bc:	mov	x0, x20
   1e5c0:	mov	w1, w19
   1e5c4:	bl	cba0 <__gmpz_millerrabin@plt>
   1e5c8:	b	1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e5cc:	ldr	x8, [x20, #8]
   1e5d0:	ldr	w9, [x20, #4]
   1e5d4:	ldr	x8, [x8]
   1e5d8:	cmp	w9, #0x0
   1e5dc:	csel	x8, xzr, x8, eq  // eq = none
   1e5e0:	cmp	x8, #0x1
   1e5e4:	cset	w9, hi  // hi = pmore
   1e5e8:	tst	x8, x9
   1e5ec:	b.eq	1e63c <__gmpz_probab_prime_p@@Base+0x458>  // b.none
   1e5f0:	mov	w9, #0x3                   	// #3
   1e5f4:	udiv	x10, x8, x9
   1e5f8:	cmp	x10, x9
   1e5fc:	b.cc	1e644 <__gmpz_probab_prime_p@@Base+0x460>  // b.lo, b.ul, b.last
   1e600:	mul	x10, x10, x9
   1e604:	cmp	x10, x8
   1e608:	add	x9, x9, #0x2
   1e60c:	b.ne	1e5f4 <__gmpz_probab_prime_p@@Base+0x410>  // b.any
   1e610:	b	1e64c <__gmpz_probab_prime_p@@Base+0x468>
   1e614:	mov	x0, x22
   1e618:	mov	x1, x21
   1e61c:	bl	c400 <__gmpn_mod_1@plt>
   1e620:	cbz	x0, 1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e624:	adrp	x0, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   1e628:	adrp	x2, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   1e62c:	add	x0, x0, #0x358
   1e630:	add	x2, x2, #0x363
   1e634:	mov	w1, #0x83                  	// #131
   1e638:	bl	c6e0 <__gmp_assert_fail@plt>
   1e63c:	cmp	x8, #0x2
   1e640:	b.ne	1e64c <__gmpz_probab_prime_p@@Base+0x468>  // b.any
   1e644:	mov	w0, #0x2                   	// #2
   1e648:	b	1e650 <__gmpz_probab_prime_p@@Base+0x46c>
   1e64c:	mov	w0, wzr
   1e650:	ldp	x20, x19, [sp, #160]
   1e654:	ldp	x22, x21, [sp, #144]
   1e658:	ldp	x24, x23, [sp, #128]
   1e65c:	ldp	x26, x25, [sp, #112]
   1e660:	ldr	x27, [sp, #96]
   1e664:	ldp	x29, x30, [sp, #80]
   1e668:	add	sp, sp, #0xb0
   1e66c:	ret

000000000001e670 <__gmpz_random@@Base>:
   1e670:	stp	x29, x30, [sp, #-32]!
   1e674:	stp	x20, x19, [sp, #16]
   1e678:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1e67c:	ldr	x8, [x8, #4040]
   1e680:	mov	x20, x1
   1e684:	mov	x19, x0
   1e688:	mov	x29, sp
   1e68c:	ldrb	w9, [x8]
   1e690:	cbnz	w9, 1e6a8 <__gmpz_random@@Base+0x38>
   1e694:	mov	w9, #0x1                   	// #1
   1e698:	strb	w9, [x8]
   1e69c:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1e6a0:	ldr	x0, [x0, #3976]
   1e6a4:	bl	bf40 <__gmp_randinit_mt_noseed@plt>
   1e6a8:	adrp	x1, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1e6ac:	ldr	x1, [x1, #3976]
   1e6b0:	cmp	x20, #0x0
   1e6b4:	cneg	x8, x20, mi  // mi = first
   1e6b8:	lsl	x2, x8, #6
   1e6bc:	mov	x0, x19
   1e6c0:	bl	d450 <__gmpz_urandomb@plt>
   1e6c4:	tbz	x20, #63, 1e6d4 <__gmpz_random@@Base+0x64>
   1e6c8:	ldr	w8, [x19, #4]
   1e6cc:	neg	w8, w8
   1e6d0:	str	w8, [x19, #4]
   1e6d4:	ldp	x20, x19, [sp, #16]
   1e6d8:	ldp	x29, x30, [sp], #32
   1e6dc:	ret

000000000001e6e0 <__gmpz_random2@@Base>:
   1e6e0:	stp	x29, x30, [sp, #-48]!
   1e6e4:	cmp	x1, #0x0
   1e6e8:	str	x21, [sp, #16]
   1e6ec:	stp	x20, x19, [sp, #32]
   1e6f0:	mov	x19, x1
   1e6f4:	mov	x20, x0
   1e6f8:	cneg	x21, x1, mi  // mi = first
   1e6fc:	mov	x29, sp
   1e700:	cbz	x1, 1e71c <__gmpz_random2@@Base+0x3c>
   1e704:	ldrsw	x8, [x20]
   1e708:	cmp	x21, x8
   1e70c:	b.gt	1e730 <__gmpz_random2@@Base+0x50>
   1e710:	ldr	x0, [x20, #8]
   1e714:	mov	x1, x21
   1e718:	bl	d1e0 <__gmpn_random2@plt>
   1e71c:	str	w19, [x20, #4]
   1e720:	ldp	x20, x19, [sp, #32]
   1e724:	ldr	x21, [sp, #16]
   1e728:	ldp	x29, x30, [sp], #48
   1e72c:	ret
   1e730:	mov	x0, x20
   1e734:	mov	x1, x21
   1e738:	bl	c090 <__gmpz_realloc@plt>
   1e73c:	b	1e714 <__gmpz_random2@@Base+0x34>

000000000001e740 <__gmpz_realloc@@Base>:
   1e740:	stp	x29, x30, [sp, #-32]!
   1e744:	cmp	x1, #0x1
   1e748:	stp	x20, x19, [sp, #16]
   1e74c:	csinc	x20, x1, xzr, gt
   1e750:	mov	w8, #0x80000000            	// #-2147483648
   1e754:	cmp	x20, x8
   1e758:	mov	x29, sp
   1e75c:	b.ge	1e7cc <__gmpz_realloc@@Base+0x8c>  // b.tcont
   1e760:	ldrsw	x8, [x0]
   1e764:	mov	x19, x0
   1e768:	cbz	w8, 1e7a4 <__gmpz_realloc@@Base+0x64>
   1e76c:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1e770:	ldr	x9, [x9, #3792]
   1e774:	ldr	x0, [x19, #8]
   1e778:	lsl	x1, x8, #3
   1e77c:	lsl	x2, x20, #3
   1e780:	ldr	x9, [x9]
   1e784:	blr	x9
   1e788:	ldr	w8, [x19, #4]
   1e78c:	cmp	w8, #0x0
   1e790:	cneg	w8, w8, mi  // mi = first
   1e794:	cmp	x20, x8
   1e798:	b.ge	1e7b8 <__gmpz_realloc@@Base+0x78>  // b.tcont
   1e79c:	str	wzr, [x19, #4]
   1e7a0:	b	1e7b8 <__gmpz_realloc@@Base+0x78>
   1e7a4:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1e7a8:	ldr	x8, [x8, #3840]
   1e7ac:	lsl	x0, x20, #3
   1e7b0:	ldr	x8, [x8]
   1e7b4:	blr	x8
   1e7b8:	str	x0, [x19, #8]
   1e7bc:	str	w20, [x19]
   1e7c0:	ldp	x20, x19, [sp, #16]
   1e7c4:	ldp	x29, x30, [sp], #32
   1e7c8:	ret
   1e7cc:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1e7d0:	ldr	x8, [x8, #3824]
   1e7d4:	adrp	x0, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   1e7d8:	add	x0, x0, #0x268
   1e7dc:	mov	w1, #0x1a                  	// #26
   1e7e0:	ldr	x3, [x8]
   1e7e4:	mov	w2, #0x1                   	// #1
   1e7e8:	bl	ce50 <fwrite@plt>
   1e7ec:	bl	c920 <abort@plt>

000000000001e7f0 <__gmpz_realloc2@@Base>:
   1e7f0:	stp	x29, x30, [sp, #-32]!
   1e7f4:	cmp	x1, #0x0
   1e7f8:	cset	w8, ne  // ne = any
   1e7fc:	sub	x8, x1, x8
   1e800:	mov	x9, #0x1fffffffc0          	// #137438953408
   1e804:	cmp	x8, x9
   1e808:	stp	x20, x19, [sp, #16]
   1e80c:	mov	x29, sp
   1e810:	b.cs	1e88c <__gmpz_realloc2@@Base+0x9c>  // b.hs, b.nlast
   1e814:	ldrsw	x9, [x0]
   1e818:	lsr	x8, x8, #6
   1e81c:	mov	x19, x0
   1e820:	add	x20, x8, #0x1
   1e824:	cbz	w9, 1e864 <__gmpz_realloc2@@Base+0x74>
   1e828:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1e82c:	ldr	x8, [x8, #3792]
   1e830:	ldr	x0, [x19, #8]
   1e834:	lsl	x1, x9, #3
   1e838:	lsl	x2, x20, #3
   1e83c:	ldr	x8, [x8]
   1e840:	blr	x8
   1e844:	ldr	w8, [x19, #4]
   1e848:	str	x0, [x19, #8]
   1e84c:	cmp	w8, #0x0
   1e850:	cneg	w8, w8, mi  // mi = first
   1e854:	cmp	x20, x8
   1e858:	b.cs	1e87c <__gmpz_realloc2@@Base+0x8c>  // b.hs, b.nlast
   1e85c:	str	wzr, [x19, #4]
   1e860:	b	1e87c <__gmpz_realloc2@@Base+0x8c>
   1e864:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1e868:	ldr	x8, [x8, #3840]
   1e86c:	lsl	x0, x20, #3
   1e870:	ldr	x8, [x8]
   1e874:	blr	x8
   1e878:	str	x0, [x19, #8]
   1e87c:	str	w20, [x19]
   1e880:	ldp	x20, x19, [sp, #16]
   1e884:	ldp	x29, x30, [sp], #32
   1e888:	ret
   1e88c:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1e890:	ldr	x8, [x8, #3824]
   1e894:	adrp	x0, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   1e898:	add	x0, x0, #0x268
   1e89c:	mov	w1, #0x1a                  	// #26
   1e8a0:	ldr	x3, [x8]
   1e8a4:	mov	w2, #0x1                   	// #1
   1e8a8:	bl	ce50 <fwrite@plt>
   1e8ac:	bl	c920 <abort@plt>

000000000001e8b0 <__gmpz_remove@@Base>:
   1e8b0:	stp	x29, x30, [sp, #-80]!
   1e8b4:	stp	x28, x25, [sp, #16]
   1e8b8:	stp	x24, x23, [sp, #32]
   1e8bc:	stp	x22, x21, [sp, #48]
   1e8c0:	stp	x20, x19, [sp, #64]
   1e8c4:	mov	x29, sp
   1e8c8:	sub	sp, sp, #0x420
   1e8cc:	ldr	x4, [x2, #8]
   1e8d0:	ldrsw	x9, [x2, #4]
   1e8d4:	ldrsw	x25, [x1, #4]
   1e8d8:	mov	x21, x1
   1e8dc:	ldr	x8, [x4]
   1e8e0:	cmp	x9, #0x0
   1e8e4:	cneg	x22, x9, mi  // mi = first
   1e8e8:	mov	x19, x0
   1e8ec:	cmp	x8, #0x1
   1e8f0:	cset	w10, eq  // eq = none
   1e8f4:	cbz	w25, 1eb5c <__gmpz_remove@@Base+0x2ac>
   1e8f8:	cmp	x22, x10
   1e8fc:	b.le	1eb5c <__gmpz_remove@@Base+0x2ac>
   1e900:	mov	x20, x2
   1e904:	and	x24, x9, #0xffffffff
   1e908:	tbnz	w8, #0, 1e958 <__gmpz_remove@@Base+0xa8>
   1e90c:	cmp	x8, #0x2
   1e910:	cset	w8, eq  // eq = none
   1e914:	cmp	x22, x8
   1e918:	b.ne	1e9b0 <__gmpz_remove@@Base+0x100>  // b.any
   1e91c:	mov	x0, x21
   1e920:	mov	x1, xzr
   1e924:	bl	bf30 <__gmpz_scan1@plt>
   1e928:	mov	x20, x0
   1e92c:	mov	x0, x19
   1e930:	mov	x1, x21
   1e934:	mov	x2, x20
   1e938:	bl	c670 <__gmpz_fdiv_q_2exp@plt>
   1e93c:	ubfx	x8, x24, #31, #1
   1e940:	tst	x20, x8
   1e944:	b.eq	1eb3c <__gmpz_remove@@Base+0x28c>  // b.none
   1e948:	ldr	w8, [x19, #4]
   1e94c:	neg	w8, w8
   1e950:	str	w8, [x19, #4]
   1e954:	b	1eb3c <__gmpz_remove@@Base+0x28c>
   1e958:	cmp	x25, #0x0
   1e95c:	cneg	x23, x25, mi  // mi = first
   1e960:	str	x23, [sp]
   1e964:	ldrsw	x8, [x19]
   1e968:	cmp	x23, x8
   1e96c:	b.gt	1eb74 <__gmpz_remove@@Base+0x2c4>
   1e970:	ldr	x0, [x19, #8]
   1e974:	ldr	x2, [x21, #8]
   1e978:	mov	x1, sp
   1e97c:	mov	x6, #0xffffffffffffffff    	// #-1
   1e980:	mov	x3, x23
   1e984:	mov	x5, x22
   1e988:	bl	cd60 <__gmpn_remove@plt>
   1e98c:	ldr	x8, [sp]
   1e990:	and	x9, x0, x24, lsr #31
   1e994:	ubfx	x10, x25, #31, #1
   1e998:	cmp	x9, x10
   1e99c:	neg	w11, w8
   1e9a0:	csel	x8, x8, x11, eq  // eq = none
   1e9a4:	mov	x20, x0
   1e9a8:	str	w8, [x19, #4]
   1e9ac:	b	1eb3c <__gmpz_remove@@Base+0x28c>
   1e9b0:	sub	x0, x29, #0x20
   1e9b4:	bl	d270 <__gmpz_init@plt>
   1e9b8:	sub	x0, x29, #0x10
   1e9bc:	bl	d270 <__gmpz_init@plt>
   1e9c0:	sub	x0, x29, #0x10
   1e9c4:	sub	x1, x29, #0x20
   1e9c8:	mov	x2, x21
   1e9cc:	mov	x3, x20
   1e9d0:	bl	c000 <__gmpz_tdiv_qr@plt>
   1e9d4:	ldur	w8, [x29, #-28]
   1e9d8:	cbz	w8, 1e9f0 <__gmpz_remove@@Base+0x140>
   1e9dc:	mov	x0, x19
   1e9e0:	mov	x1, x21
   1e9e4:	bl	c440 <__gmpz_set@plt>
   1e9e8:	mov	x20, xzr
   1e9ec:	b	1eb2c <__gmpz_remove@@Base+0x27c>
   1e9f0:	mov	x0, sp
   1e9f4:	mov	x1, x20
   1e9f8:	mov	x22, sp
   1e9fc:	bl	bf90 <__gmpz_init_set@plt>
   1ea00:	sub	x1, x29, #0x10
   1ea04:	mov	x0, x19
   1ea08:	bl	c5a0 <__gmpz_swap@plt>
   1ea0c:	ldr	w8, [x19, #4]
   1ea10:	ldr	w9, [sp, #4]
   1ea14:	cmp	w8, #0x0
   1ea18:	cneg	w8, w8, mi  // mi = first
   1ea1c:	cmp	w9, #0x0
   1ea20:	cneg	w9, w9, mi  // mi = first
   1ea24:	lsl	w9, w9, #1
   1ea28:	sub	w9, w9, #0x1
   1ea2c:	cmp	w8, w9
   1ea30:	b.ge	1ea3c <__gmpz_remove@@Base+0x18c>  // b.tcont
   1ea34:	mov	w23, #0x1                   	// #1
   1ea38:	b	1eac4 <__gmpz_remove@@Base+0x214>
   1ea3c:	add	x20, x22, #0x10
   1ea40:	mov	w23, #0x1                   	// #1
   1ea44:	mov	x0, x20
   1ea48:	sub	x21, x20, #0x10
   1ea4c:	bl	d270 <__gmpz_init@plt>
   1ea50:	mov	x0, x20
   1ea54:	mov	x1, x21
   1ea58:	mov	x2, x21
   1ea5c:	bl	c4d0 <__gmpz_mul@plt>
   1ea60:	sub	x0, x29, #0x10
   1ea64:	sub	x1, x29, #0x20
   1ea68:	mov	x2, x19
   1ea6c:	mov	x3, x20
   1ea70:	bl	c000 <__gmpz_tdiv_qr@plt>
   1ea74:	ldur	w8, [x29, #-28]
   1ea78:	cbnz	w8, 1eabc <__gmpz_remove@@Base+0x20c>
   1ea7c:	sub	x1, x29, #0x10
   1ea80:	mov	x0, x19
   1ea84:	bl	c5a0 <__gmpz_swap@plt>
   1ea88:	ldr	w8, [x19, #4]
   1ea8c:	ldr	w9, [x20, #4]
   1ea90:	add	w23, w23, #0x1
   1ea94:	add	x20, x20, #0x10
   1ea98:	cmp	w8, #0x0
   1ea9c:	cneg	w8, w8, mi  // mi = first
   1eaa0:	cmp	w9, #0x0
   1eaa4:	cneg	w9, w9, mi  // mi = first
   1eaa8:	lsl	w9, w9, #1
   1eaac:	sub	w9, w9, #0x1
   1eab0:	cmp	w8, w9
   1eab4:	b.ge	1ea44 <__gmpz_remove@@Base+0x194>  // b.tcont
   1eab8:	b	1eac4 <__gmpz_remove@@Base+0x214>
   1eabc:	mov	x0, x20
   1eac0:	bl	cb70 <__gmpz_clear@plt>
   1eac4:	mov	x8, #0xffffffffffffffff    	// #-1
   1eac8:	sub	w25, w23, #0x1
   1eacc:	lsl	x8, x8, x23
   1ead0:	add	w24, w23, #0x1
   1ead4:	add	x21, x22, w25, sxtw #4
   1ead8:	mvn	x20, x8
   1eadc:	mov	w22, #0x1                   	// #1
   1eae0:	sub	x0, x29, #0x10
   1eae4:	sub	x1, x29, #0x20
   1eae8:	mov	x2, x19
   1eaec:	mov	x3, x21
   1eaf0:	bl	c000 <__gmpz_tdiv_qr@plt>
   1eaf4:	ldur	w8, [x29, #-28]
   1eaf8:	cbnz	w8, 1eb10 <__gmpz_remove@@Base+0x260>
   1eafc:	lsl	x8, x22, x25
   1eb00:	sub	x1, x29, #0x10
   1eb04:	mov	x0, x19
   1eb08:	add	x20, x8, x20
   1eb0c:	bl	c5a0 <__gmpz_swap@plt>
   1eb10:	mov	x0, x21
   1eb14:	bl	cb70 <__gmpz_clear@plt>
   1eb18:	sub	w24, w24, #0x1
   1eb1c:	sub	x21, x21, #0x10
   1eb20:	cmp	w24, #0x1
   1eb24:	sub	x25, x25, #0x1
   1eb28:	b.gt	1eae0 <__gmpz_remove@@Base+0x230>
   1eb2c:	sub	x0, x29, #0x10
   1eb30:	bl	cb70 <__gmpz_clear@plt>
   1eb34:	sub	x0, x29, #0x20
   1eb38:	bl	cb70 <__gmpz_clear@plt>
   1eb3c:	mov	x0, x20
   1eb40:	add	sp, sp, #0x420
   1eb44:	ldp	x20, x19, [sp, #64]
   1eb48:	ldp	x22, x21, [sp, #48]
   1eb4c:	ldp	x24, x23, [sp, #32]
   1eb50:	ldp	x28, x25, [sp, #16]
   1eb54:	ldp	x29, x30, [sp], #80
   1eb58:	ret
   1eb5c:	cbz	x22, 1eb88 <__gmpz_remove@@Base+0x2d8>
   1eb60:	mov	x0, x19
   1eb64:	mov	x1, x21
   1eb68:	bl	c440 <__gmpz_set@plt>
   1eb6c:	mov	x20, xzr
   1eb70:	b	1eb3c <__gmpz_remove@@Base+0x28c>
   1eb74:	mov	x0, x19
   1eb78:	mov	x1, x23
   1eb7c:	bl	c090 <__gmpz_realloc@plt>
   1eb80:	ldr	x4, [x20, #8]
   1eb84:	b	1e974 <__gmpz_remove@@Base+0xc4>
   1eb88:	bl	bfe0 <__gmp_divide_by_zero@plt>

000000000001eb8c <__gmpz_roinit_n@@Base>:
   1eb8c:	cmp	x2, #0x0
   1eb90:	cneg	x9, x2, mi  // mi = first
   1eb94:	mov	x8, x9
   1eb98:	subs	x9, x9, #0x1
   1eb9c:	b.lt	1ebac <__gmpz_roinit_n@@Base+0x20>  // b.tstop
   1eba0:	add	x10, x1, x8, lsl #3
   1eba4:	ldur	x10, [x10, #-8]
   1eba8:	cbz	x10, 1eb94 <__gmpz_roinit_n@@Base+0x8>
   1ebac:	neg	w9, w8
   1ebb0:	cmp	x2, #0x0
   1ebb4:	csel	x8, x9, x8, lt  // lt = tstop
   1ebb8:	stp	wzr, w8, [x0]
   1ebbc:	str	x1, [x0, #8]
   1ebc0:	ret

000000000001ebc4 <__gmpz_root@@Base>:
   1ebc4:	stp	x29, x30, [sp, #-96]!
   1ebc8:	stp	x26, x25, [sp, #32]
   1ebcc:	stp	x24, x23, [sp, #48]
   1ebd0:	stp	x22, x21, [sp, #64]
   1ebd4:	stp	x20, x19, [sp, #80]
   1ebd8:	ldr	w8, [x1, #4]
   1ebdc:	mov	x22, x2
   1ebe0:	mov	x20, x1
   1ebe4:	mov	x19, x0
   1ebe8:	str	x27, [sp, #16]
   1ebec:	mov	x29, sp
   1ebf0:	tbnz	w22, #0, 1ebf8 <__gmpz_root@@Base+0x34>
   1ebf4:	tbnz	w8, #31, 1ed34 <__gmpz_root@@Base+0x170>
   1ebf8:	cbz	x22, 1ed38 <__gmpz_root@@Base+0x174>
   1ebfc:	sxtw	x26, w8
   1ec00:	cbz	w26, 1ec3c <__gmpz_root@@Base+0x78>
   1ec04:	cmp	w26, #0x0
   1ec08:	cneg	x23, x26, lt  // lt = tstop
   1ec0c:	sub	x8, x23, #0x1
   1ec10:	udiv	x27, x8, x22
   1ec14:	cmp	x20, x19
   1ec18:	add	x21, x27, #0x1
   1ec1c:	str	xzr, [x29, #24]
   1ec20:	b.eq	1ec4c <__gmpz_root@@Base+0x88>  // b.none
   1ec24:	cbz	x19, 1ec4c <__gmpz_root@@Base+0x88>
   1ec28:	ldrsw	x8, [x19]
   1ec2c:	cmp	x21, x8
   1ec30:	b.gt	1ed14 <__gmpz_root@@Base+0x150>
   1ec34:	ldr	x24, [x19, #8]
   1ec38:	b	1ec70 <__gmpz_root@@Base+0xac>
   1ec3c:	cbz	x19, 1ec44 <__gmpz_root@@Base+0x80>
   1ec40:	str	wzr, [x19, #4]
   1ec44:	mov	w0, #0x1                   	// #1
   1ec48:	b	1ecec <__gmpz_root@@Base+0x128>
   1ec4c:	lsl	x1, x21, #3
   1ec50:	mov	w8, #0x7f00                	// #32512
   1ec54:	cmp	x1, x8
   1ec58:	b.hi	1ed24 <__gmpz_root@@Base+0x160>  // b.pmore
   1ec5c:	add	x9, x1, #0xf
   1ec60:	mov	x8, sp
   1ec64:	and	x9, x9, #0xfffffffffffffff0
   1ec68:	sub	x24, x8, x9
   1ec6c:	mov	sp, x24
   1ec70:	ldr	x25, [x20, #8]
   1ec74:	mov	x0, x24
   1ec78:	cmp	x22, #0x1
   1ec7c:	b.ne	1ec98 <__gmpz_root@@Base+0xd4>  // b.any
   1ec80:	mov	x1, x25
   1ec84:	mov	x2, x23
   1ec88:	bl	ca70 <__gmpn_copyi@plt>
   1ec8c:	mov	x22, xzr
   1ec90:	cbnz	x19, 1ecb4 <__gmpz_root@@Base+0xf0>
   1ec94:	b	1ecdc <__gmpz_root@@Base+0x118>
   1ec98:	mov	x1, xzr
   1ec9c:	mov	x2, x25
   1eca0:	mov	x3, x23
   1eca4:	mov	x4, x22
   1eca8:	bl	c2b0 <__gmpn_rootrem@plt>
   1ecac:	mov	x22, x0
   1ecb0:	cbz	x19, 1ecdc <__gmpz_root@@Base+0x118>
   1ecb4:	mvn	w8, w27
   1ecb8:	cmp	w26, #0x0
   1ecbc:	csel	x8, x21, x8, ge  // ge = tcont
   1ecc0:	cmp	x20, x19
   1ecc4:	str	w8, [x19, #4]
   1ecc8:	b.ne	1ecdc <__gmpz_root@@Base+0x118>  // b.any
   1eccc:	mov	x0, x25
   1ecd0:	mov	x1, x24
   1ecd4:	mov	x2, x21
   1ecd8:	bl	ca70 <__gmpn_copyi@plt>
   1ecdc:	ldr	x0, [x29, #24]
   1ece0:	cbnz	x0, 1ed0c <__gmpz_root@@Base+0x148>
   1ece4:	cmp	x22, #0x0
   1ece8:	cset	w0, eq  // eq = none
   1ecec:	mov	sp, x29
   1ecf0:	ldp	x20, x19, [sp, #80]
   1ecf4:	ldp	x22, x21, [sp, #64]
   1ecf8:	ldp	x24, x23, [sp, #48]
   1ecfc:	ldp	x26, x25, [sp, #32]
   1ed00:	ldr	x27, [sp, #16]
   1ed04:	ldp	x29, x30, [sp], #96
   1ed08:	ret
   1ed0c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1ed10:	b	1ece4 <__gmpz_root@@Base+0x120>
   1ed14:	mov	x0, x19
   1ed18:	mov	x1, x21
   1ed1c:	bl	c090 <__gmpz_realloc@plt>
   1ed20:	b	1ed2c <__gmpz_root@@Base+0x168>
   1ed24:	add	x0, x29, #0x18
   1ed28:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1ed2c:	mov	x24, x0
   1ed30:	b	1ec70 <__gmpz_root@@Base+0xac>
   1ed34:	bl	d010 <__gmp_sqrt_of_negative@plt>
   1ed38:	bl	bfe0 <__gmp_divide_by_zero@plt>

000000000001ed3c <__gmpz_rootrem@@Base>:
   1ed3c:	stp	x29, x30, [sp, #-96]!
   1ed40:	stp	x28, x27, [sp, #16]
   1ed44:	stp	x26, x25, [sp, #32]
   1ed48:	stp	x24, x23, [sp, #48]
   1ed4c:	stp	x22, x21, [sp, #64]
   1ed50:	stp	x20, x19, [sp, #80]
   1ed54:	mov	x29, sp
   1ed58:	sub	sp, sp, #0x10
   1ed5c:	ldr	w8, [x2, #4]
   1ed60:	mov	x23, x3
   1ed64:	mov	x20, x2
   1ed68:	mov	x19, x1
   1ed6c:	mov	x21, x0
   1ed70:	tbnz	w23, #0, 1ed78 <__gmpz_rootrem@@Base+0x3c>
   1ed74:	tbnz	w8, #31, 1ef28 <__gmpz_rootrem@@Base+0x1ec>
   1ed78:	cbz	x23, 1ef2c <__gmpz_rootrem@@Base+0x1f0>
   1ed7c:	sxtw	x28, w8
   1ed80:	cbz	w28, 1edbc <__gmpz_rootrem@@Base+0x80>
   1ed84:	cmp	w28, #0x0
   1ed88:	cneg	x24, x28, lt  // lt = tstop
   1ed8c:	sub	x8, x24, #0x1
   1ed90:	udiv	x22, x8, x23
   1ed94:	cmp	x20, x21
   1ed98:	add	x1, x22, #0x1
   1ed9c:	stp	x1, xzr, [x29, #-16]
   1eda0:	b.eq	1edcc <__gmpz_rootrem@@Base+0x90>  // b.none
   1eda4:	cbz	x21, 1edcc <__gmpz_rootrem@@Base+0x90>
   1eda8:	ldrsw	x8, [x21]
   1edac:	cmp	x1, x8
   1edb0:	b.gt	1eefc <__gmpz_rootrem@@Base+0x1c0>
   1edb4:	ldr	x25, [x21, #8]
   1edb8:	b	1edf0 <__gmpz_rootrem@@Base+0xb4>
   1edbc:	cbz	x21, 1edc4 <__gmpz_rootrem@@Base+0x88>
   1edc0:	str	wzr, [x21, #4]
   1edc4:	str	wzr, [x19, #4]
   1edc8:	b	1eec4 <__gmpz_rootrem@@Base+0x188>
   1edcc:	lsl	x1, x1, #3
   1edd0:	mov	w8, #0x7f00                	// #32512
   1edd4:	cmp	x1, x8
   1edd8:	b.hi	1ef08 <__gmpz_rootrem@@Base+0x1cc>  // b.pmore
   1eddc:	add	x9, x1, #0xf
   1ede0:	mov	x8, sp
   1ede4:	and	x9, x9, #0xfffffffffffffff0
   1ede8:	sub	x25, x8, x9
   1edec:	mov	sp, x25
   1edf0:	cmp	x20, x19
   1edf4:	b.eq	1ee0c <__gmpz_rootrem@@Base+0xd0>  // b.none
   1edf8:	ldrsw	x8, [x19]
   1edfc:	cmp	x24, x8
   1ee00:	b.gt	1eeec <__gmpz_rootrem@@Base+0x1b0>
   1ee04:	ldr	x26, [x19, #8]
   1ee08:	b	1ee2c <__gmpz_rootrem@@Base+0xf0>
   1ee0c:	cmp	x24, #0xfe0
   1ee10:	lsl	x1, x24, #3
   1ee14:	b.hi	1ef18 <__gmpz_rootrem@@Base+0x1dc>  // b.pmore
   1ee18:	add	x9, x1, #0xf
   1ee1c:	mov	x8, sp
   1ee20:	and	x9, x9, #0xfffffffffffffff0
   1ee24:	sub	x26, x8, x9
   1ee28:	mov	sp, x26
   1ee2c:	ldr	x27, [x20, #8]
   1ee30:	mov	x0, x25
   1ee34:	cmp	x23, #0x1
   1ee38:	b.ne	1ee50 <__gmpz_rootrem@@Base+0x114>  // b.any
   1ee3c:	mov	x1, x27
   1ee40:	mov	x2, x24
   1ee44:	bl	ca70 <__gmpn_copyi@plt>
   1ee48:	mov	x23, xzr
   1ee4c:	b	1ee68 <__gmpz_rootrem@@Base+0x12c>
   1ee50:	mov	x1, x26
   1ee54:	mov	x2, x27
   1ee58:	mov	x3, x24
   1ee5c:	mov	x4, x23
   1ee60:	bl	c2b0 <__gmpn_rootrem@plt>
   1ee64:	mov	x23, x0
   1ee68:	ldur	x2, [x29, #-16]
   1ee6c:	cbz	x21, 1ee94 <__gmpz_rootrem@@Base+0x158>
   1ee70:	mvn	w8, w22
   1ee74:	cmp	w28, #0x0
   1ee78:	csel	x8, x2, x8, ge  // ge = tcont
   1ee7c:	cmp	x20, x21
   1ee80:	str	w8, [x21, #4]
   1ee84:	b.ne	1ee94 <__gmpz_rootrem@@Base+0x158>  // b.any
   1ee88:	mov	x0, x27
   1ee8c:	mov	x1, x25
   1ee90:	bl	ca70 <__gmpn_copyi@plt>
   1ee94:	cmp	x20, x19
   1ee98:	b.ne	1eeac <__gmpz_rootrem@@Base+0x170>  // b.any
   1ee9c:	mov	x0, x27
   1eea0:	mov	x1, x26
   1eea4:	mov	x2, x23
   1eea8:	bl	ca70 <__gmpn_copyi@plt>
   1eeac:	neg	w8, w23
   1eeb0:	cmp	w28, #0x0
   1eeb4:	csel	x8, x23, x8, ge  // ge = tcont
   1eeb8:	str	w8, [x19, #4]
   1eebc:	ldur	x0, [x29, #-8]
   1eec0:	cbnz	x0, 1eee4 <__gmpz_rootrem@@Base+0x1a8>
   1eec4:	mov	sp, x29
   1eec8:	ldp	x20, x19, [sp, #80]
   1eecc:	ldp	x22, x21, [sp, #64]
   1eed0:	ldp	x24, x23, [sp, #48]
   1eed4:	ldp	x26, x25, [sp, #32]
   1eed8:	ldp	x28, x27, [sp, #16]
   1eedc:	ldp	x29, x30, [sp], #96
   1eee0:	ret
   1eee4:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1eee8:	b	1eec4 <__gmpz_rootrem@@Base+0x188>
   1eeec:	mov	x0, x19
   1eef0:	mov	x1, x24
   1eef4:	bl	c090 <__gmpz_realloc@plt>
   1eef8:	b	1ef20 <__gmpz_rootrem@@Base+0x1e4>
   1eefc:	mov	x0, x21
   1ef00:	bl	c090 <__gmpz_realloc@plt>
   1ef04:	b	1ef10 <__gmpz_rootrem@@Base+0x1d4>
   1ef08:	sub	x0, x29, #0x8
   1ef0c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1ef10:	mov	x25, x0
   1ef14:	b	1edf0 <__gmpz_rootrem@@Base+0xb4>
   1ef18:	sub	x0, x29, #0x8
   1ef1c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1ef20:	mov	x26, x0
   1ef24:	b	1ee2c <__gmpz_rootrem@@Base+0xf0>
   1ef28:	bl	d010 <__gmp_sqrt_of_negative@plt>
   1ef2c:	bl	bfe0 <__gmp_divide_by_zero@plt>

000000000001ef30 <__gmpz_rrandomb@@Base>:
   1ef30:	stp	x29, x30, [sp, #-96]!
   1ef34:	stp	x24, x23, [sp, #48]
   1ef38:	add	x24, x2, #0x3f
   1ef3c:	stp	x20, x19, [sp, #80]
   1ef40:	mov	x19, x0
   1ef44:	lsr	x20, x24, #6
   1ef48:	str	x27, [sp, #16]
   1ef4c:	stp	x26, x25, [sp, #32]
   1ef50:	stp	x22, x21, [sp, #64]
   1ef54:	mov	x29, sp
   1ef58:	cbz	x2, 1f09c <__gmpz_rrandomb@@Base+0x16c>
   1ef5c:	ldrsw	x8, [x19]
   1ef60:	mov	x23, x2
   1ef64:	mov	x21, x1
   1ef68:	cmp	x20, x8
   1ef6c:	b.gt	1f0bc <__gmpz_rrandomb@@Base+0x18c>
   1ef70:	ldr	x22, [x19, #8]
   1ef74:	neg	w9, w23
   1ef78:	mov	x10, #0xffffffffffffffff    	// #-1
   1ef7c:	sub	x8, x20, #0x1
   1ef80:	lsr	x9, x10, x9
   1ef84:	cmp	x24, #0x80
   1ef88:	str	x9, [x22, x8, lsl #3]
   1ef8c:	b.cc	1efb4 <__gmpz_rrandomb@@Base+0x84>  // b.lo, b.ul, b.last
   1ef90:	cmp	x20, #0x2
   1ef94:	mov	w9, #0x2                   	// #2
   1ef98:	csel	x9, x20, x9, cc  // cc = lo, ul, last
   1ef9c:	sub	x9, x9, #0x2
   1efa0:	sub	x8, x8, x9
   1efa4:	add	x0, x22, x9, lsl #3
   1efa8:	lsl	x2, x8, #3
   1efac:	mov	w1, #0xff                  	// #255
   1efb0:	bl	c610 <memset@plt>
   1efb4:	ldr	x8, [x21, #24]
   1efb8:	add	x1, x29, #0x18
   1efbc:	mov	w2, #0x20                  	// #32
   1efc0:	mov	x0, x21
   1efc4:	ldr	x8, [x8, #8]
   1efc8:	blr	x8
   1efcc:	ldr	x8, [x29, #24]
   1efd0:	add	x24, x22, #0x8
   1efd4:	mov	w26, #0x1                   	// #1
   1efd8:	and	x8, x8, #0x3
   1efdc:	add	x8, x8, #0x1
   1efe0:	udiv	x8, x23, x8
   1efe4:	cmp	w8, #0x0
   1efe8:	cinc	w25, w8, eq  // eq = none
   1efec:	ldr	x8, [x21, #24]
   1eff0:	add	x1, x29, #0x18
   1eff4:	mov	w2, #0x20                  	// #32
   1eff8:	mov	x0, x21
   1effc:	ldr	x8, [x8, #8]
   1f000:	blr	x8
   1f004:	ldr	x8, [x29, #24]
   1f008:	udiv	x9, x8, x25
   1f00c:	msub	x8, x9, x25, x8
   1f010:	add	x8, x8, #0x1
   1f014:	subs	x8, x23, x8
   1f018:	csel	x27, xzr, x8, cc  // cc = lo, ul, last
   1f01c:	b.ls	1f09c <__gmpz_rrandomb@@Base+0x16c>  // b.plast
   1f020:	lsr	x8, x27, #3
   1f024:	and	x8, x8, #0x1ffffffffffffff8
   1f028:	ldr	x9, [x22, x8]
   1f02c:	lsl	x10, x26, x27
   1f030:	add	x1, x29, #0x18
   1f034:	mov	w2, #0x20                  	// #32
   1f038:	eor	x9, x9, x10
   1f03c:	str	x9, [x22, x8]
   1f040:	ldr	x8, [x21, #24]
   1f044:	mov	x0, x21
   1f048:	ldr	x8, [x8, #8]
   1f04c:	blr	x8
   1f050:	ldr	x8, [x29, #24]
   1f054:	udiv	x9, x8, x25
   1f058:	msub	x8, x9, x25, x8
   1f05c:	add	x8, x8, #0x1
   1f060:	subs	x9, x27, x8
   1f064:	csel	x23, xzr, x9, cc  // cc = lo, ul, last
   1f068:	lsr	x9, x23, #6
   1f06c:	ldr	x10, [x22, x9, lsl #3]
   1f070:	lsl	x11, x26, x23
   1f074:	adds	x10, x10, x11
   1f078:	str	x10, [x22, x9, lsl #3]
   1f07c:	b.cc	1f094 <__gmpz_rrandomb@@Base+0x164>  // b.lo, b.ul, b.last
   1f080:	add	x9, x24, x9, lsl #3
   1f084:	ldr	x10, [x9]
   1f088:	adds	x10, x10, #0x1
   1f08c:	str	x10, [x9], #8
   1f090:	b.cs	1f084 <__gmpz_rrandomb@@Base+0x154>  // b.hs, b.nlast
   1f094:	cmp	x27, x8
   1f098:	b.hi	1efec <__gmpz_rrandomb@@Base+0xbc>  // b.pmore
   1f09c:	str	w20, [x19, #4]
   1f0a0:	ldp	x20, x19, [sp, #80]
   1f0a4:	ldp	x22, x21, [sp, #64]
   1f0a8:	ldp	x24, x23, [sp, #48]
   1f0ac:	ldp	x26, x25, [sp, #32]
   1f0b0:	ldr	x27, [sp, #16]
   1f0b4:	ldp	x29, x30, [sp], #96
   1f0b8:	ret
   1f0bc:	mov	x0, x19
   1f0c0:	mov	x1, x20
   1f0c4:	bl	c090 <__gmpz_realloc@plt>
   1f0c8:	mov	x22, x0
   1f0cc:	b	1ef74 <__gmpz_rrandomb@@Base+0x44>

000000000001f0d0 <__gmpz_scan0@@Base>:
   1f0d0:	ldrsw	x13, [x0, #4]
   1f0d4:	lsr	x12, x1, #6
   1f0d8:	cmp	x13, #0x0
   1f0dc:	cneg	x10, x13, mi  // mi = first
   1f0e0:	cmp	x12, x10
   1f0e4:	b.ge	1f140 <__gmpz_scan0@@Base+0x70>  // b.tcont
   1f0e8:	ldr	x8, [x0, #8]
   1f0ec:	add	x9, x8, x12, lsl #3
   1f0f0:	ldr	x11, [x9]
   1f0f4:	tbnz	w13, #31, 1f14c <__gmpz_scan0@@Base+0x7c>
   1f0f8:	mov	x13, #0xffffffffffffffff    	// #-1
   1f0fc:	lsl	x13, x13, x1
   1f100:	orn	x11, x11, x13
   1f104:	cmn	x11, #0x1
   1f108:	b.ne	1f138 <__gmpz_scan0@@Base+0x68>  // b.any
   1f10c:	lsl	x11, x10, #3
   1f110:	sub	x11, x11, x12, lsl #3
   1f114:	sub	x12, x11, #0x8
   1f118:	cbz	x12, 1f1a8 <__gmpz_scan0@@Base+0xd8>
   1f11c:	ldr	x11, [x9, #8]
   1f120:	add	x13, x9, #0x8
   1f124:	sub	x12, x12, #0x8
   1f128:	mov	x9, x13
   1f12c:	cmn	x11, #0x1
   1f130:	b.eq	1f118 <__gmpz_scan0@@Base+0x48>  // b.none
   1f134:	mov	x9, x13
   1f138:	mvn	x11, x11
   1f13c:	b	1f194 <__gmpz_scan0@@Base+0xc4>
   1f140:	cmp	w13, #0x0
   1f144:	csinv	x0, x1, xzr, ge  // ge = tcont
   1f148:	ret
   1f14c:	add	x10, x8, x10, lsl #3
   1f150:	sub	x13, x8, #0x8
   1f154:	lsl	x12, x12, #3
   1f158:	cbz	x12, 1f16c <__gmpz_scan0@@Base+0x9c>
   1f15c:	ldr	x14, [x13, x12]
   1f160:	sub	x12, x12, #0x8
   1f164:	cbz	x14, 1f158 <__gmpz_scan0@@Base+0x88>
   1f168:	b	1f170 <__gmpz_scan0@@Base+0xa0>
   1f16c:	sub	x11, x11, #0x1
   1f170:	mov	x12, #0xffffffffffffffff    	// #-1
   1f174:	lsl	x12, x12, x1
   1f178:	ands	x11, x11, x12
   1f17c:	b.ne	1f194 <__gmpz_scan0@@Base+0xc4>  // b.any
   1f180:	add	x11, x9, #0x8
   1f184:	cmp	x11, x10
   1f188:	b.eq	1f1b0 <__gmpz_scan0@@Base+0xe0>  // b.none
   1f18c:	ldr	x11, [x9, #8]!
   1f190:	cbz	x11, 1f18c <__gmpz_scan0@@Base+0xbc>
   1f194:	rbit	x10, x11
   1f198:	clz	x10, x10
   1f19c:	sub	x8, x9, x8
   1f1a0:	add	x0, x10, x8, lsl #3
   1f1a4:	ret
   1f1a8:	lsl	x0, x10, #6
   1f1ac:	ret
   1f1b0:	mov	x0, #0xffffffffffffffff    	// #-1
   1f1b4:	ret

000000000001f1b8 <__gmpz_scan1@@Base>:
   1f1b8:	ldrsw	x13, [x0, #4]
   1f1bc:	lsr	x11, x1, #6
   1f1c0:	cmp	x13, #0x0
   1f1c4:	cneg	x10, x13, mi  // mi = first
   1f1c8:	cmp	x11, x10
   1f1cc:	b.ge	1f20c <__gmpz_scan1@@Base+0x54>  // b.tcont
   1f1d0:	ldr	x8, [x0, #8]
   1f1d4:	add	x9, x8, x11, lsl #3
   1f1d8:	cbz	x1, 1f284 <__gmpz_scan1@@Base+0xcc>
   1f1dc:	ldr	x12, [x9]
   1f1e0:	tbnz	w13, #31, 1f218 <__gmpz_scan1@@Base+0x60>
   1f1e4:	mov	x11, #0xffffffffffffffff    	// #-1
   1f1e8:	lsl	x11, x11, x1
   1f1ec:	ands	x11, x12, x11
   1f1f0:	b.ne	1f28c <__gmpz_scan1@@Base+0xd4>  // b.any
   1f1f4:	add	x10, x8, x10, lsl #3
   1f1f8:	sub	x10, x10, #0x8
   1f1fc:	cmp	x9, x10
   1f200:	b.ne	1f280 <__gmpz_scan1@@Base+0xc8>  // b.any
   1f204:	mov	x0, #0xffffffffffffffff    	// #-1
   1f208:	ret
   1f20c:	cmp	w13, #0x0
   1f210:	csinv	x0, x1, xzr, lt  // lt = tstop
   1f214:	ret
   1f218:	cbz	x11, 1f234 <__gmpz_scan1@@Base+0x7c>
   1f21c:	lsl	x13, x11, #3
   1f220:	sub	x14, x8, #0x8
   1f224:	ldr	x15, [x14, x13]
   1f228:	cbnz	x15, 1f23c <__gmpz_scan1@@Base+0x84>
   1f22c:	subs	x13, x13, #0x8
   1f230:	b.ne	1f224 <__gmpz_scan1@@Base+0x6c>  // b.any
   1f234:	cbz	x12, 1f280 <__gmpz_scan1@@Base+0xc8>
   1f238:	sub	x12, x12, #0x1
   1f23c:	mov	x13, #0xffffffffffffffff    	// #-1
   1f240:	lsl	x13, x13, x1
   1f244:	orn	x12, x12, x13
   1f248:	cmn	x12, #0x1
   1f24c:	b.ne	1f270 <__gmpz_scan1@@Base+0xb8>  // b.any
   1f250:	lsl	x12, x10, #3
   1f254:	sub	x11, x12, x11, lsl #3
   1f258:	sub	x11, x11, #0x8
   1f25c:	cbz	x11, 1f278 <__gmpz_scan1@@Base+0xc0>
   1f260:	ldr	x12, [x9, #8]!
   1f264:	sub	x11, x11, #0x8
   1f268:	cmn	x12, #0x1
   1f26c:	b.eq	1f25c <__gmpz_scan1@@Base+0xa4>  // b.none
   1f270:	mvn	x11, x12
   1f274:	b	1f28c <__gmpz_scan1@@Base+0xd4>
   1f278:	lsl	x0, x10, #6
   1f27c:	ret
   1f280:	add	x9, x9, #0x8
   1f284:	ldr	x11, [x9]
   1f288:	cbz	x11, 1f280 <__gmpz_scan1@@Base+0xc8>
   1f28c:	rbit	x10, x11
   1f290:	clz	x10, x10
   1f294:	sub	x8, x9, x8
   1f298:	add	x0, x10, x8, lsl #3
   1f29c:	ret

000000000001f2a0 <__gmpz_set@@Base>:
   1f2a0:	stp	x29, x30, [sp, #-48]!
   1f2a4:	stp	x22, x21, [sp, #16]
   1f2a8:	stp	x20, x19, [sp, #32]
   1f2ac:	ldrsw	x22, [x1, #4]
   1f2b0:	ldrsw	x8, [x0]
   1f2b4:	mov	x20, x1
   1f2b8:	mov	x19, x0
   1f2bc:	cmp	x22, #0x0
   1f2c0:	cneg	x21, x22, mi  // mi = first
   1f2c4:	cmp	x21, x8
   1f2c8:	mov	x29, sp
   1f2cc:	b.gt	1f2f4 <__gmpz_set@@Base+0x54>
   1f2d0:	ldr	x0, [x19, #8]
   1f2d4:	ldr	x1, [x20, #8]
   1f2d8:	mov	x2, x21
   1f2dc:	bl	ca70 <__gmpn_copyi@plt>
   1f2e0:	str	w22, [x19, #4]
   1f2e4:	ldp	x20, x19, [sp, #32]
   1f2e8:	ldp	x22, x21, [sp, #16]
   1f2ec:	ldp	x29, x30, [sp], #48
   1f2f0:	ret
   1f2f4:	mov	x0, x19
   1f2f8:	mov	x1, x21
   1f2fc:	bl	c090 <__gmpz_realloc@plt>
   1f300:	b	1f2d4 <__gmpz_set@@Base+0x34>

000000000001f304 <__gmpz_set_d@@Base>:
   1f304:	sub	sp, sp, #0x50
   1f308:	str	d8, [sp, #16]
   1f30c:	mov	v8.16b, v0.16b
   1f310:	fmov	x8, d8
   1f314:	mvn	x8, x8
   1f318:	tst	x8, #0x7ff0000000000000
   1f31c:	stp	x29, x30, [sp, #32]
   1f320:	stp	x22, x21, [sp, #48]
   1f324:	stp	x20, x19, [sp, #64]
   1f328:	add	x29, sp, #0x10
   1f32c:	b.eq	1f3e4 <__gmpz_set_d@@Base+0xe0>  // b.none
   1f330:	fneg	d0, d8
   1f334:	fcmp	d8, #0.0
   1f338:	mov	x19, x0
   1f33c:	fcsel	d0, d8, d0, ge  // ge = tcont
   1f340:	mov	x0, sp
   1f344:	bl	d2a0 <__gmp_extract_double@plt>
   1f348:	ldrsw	x8, [x19]
   1f34c:	sxtw	x9, w0
   1f350:	bic	x20, x9, x9, asr #63
   1f354:	cmp	x20, x8
   1f358:	b.gt	1f3cc <__gmpz_set_d@@Base+0xc8>
   1f35c:	ldr	x21, [x19, #8]
   1f360:	cbz	x20, 1f3a4 <__gmpz_set_d@@Base+0xa0>
   1f364:	cmp	x20, #0x1
   1f368:	b.eq	1f39c <__gmpz_set_d@@Base+0x98>  // b.none
   1f36c:	cmp	x20, #0x2
   1f370:	b.eq	1f390 <__gmpz_set_d@@Base+0x8c>  // b.none
   1f374:	lsl	x8, x20, #3
   1f378:	sub	x22, x8, #0x10
   1f37c:	mov	x0, x21
   1f380:	mov	w1, wzr
   1f384:	mov	x2, x22
   1f388:	bl	c610 <memset@plt>
   1f38c:	add	x21, x21, x22
   1f390:	ldr	q0, [sp]
   1f394:	str	q0, [x21]
   1f398:	b	1f3a4 <__gmpz_set_d@@Base+0xa0>
   1f39c:	ldr	x8, [sp, #8]
   1f3a0:	str	x8, [x21]
   1f3a4:	neg	w8, w20
   1f3a8:	fcmp	d8, #0.0
   1f3ac:	csel	x8, x8, x20, mi  // mi = first
   1f3b0:	str	w8, [x19, #4]
   1f3b4:	ldp	x20, x19, [sp, #64]
   1f3b8:	ldp	x22, x21, [sp, #48]
   1f3bc:	ldp	x29, x30, [sp, #32]
   1f3c0:	ldr	d8, [sp, #16]
   1f3c4:	add	sp, sp, #0x50
   1f3c8:	ret
   1f3cc:	mov	x0, x19
   1f3d0:	mov	x1, x20
   1f3d4:	bl	c090 <__gmpz_realloc@plt>
   1f3d8:	mov	x21, x0
   1f3dc:	cbnz	x20, 1f364 <__gmpz_set_d@@Base+0x60>
   1f3e0:	b	1f3a4 <__gmpz_set_d@@Base+0xa0>
   1f3e4:	bl	c1c0 <__gmp_invalid_operation@plt>

000000000001f3e8 <__gmpz_set_f@@Base>:
   1f3e8:	stp	x29, x30, [sp, #-64]!
   1f3ec:	stp	x24, x23, [sp, #16]
   1f3f0:	stp	x22, x21, [sp, #32]
   1f3f4:	stp	x20, x19, [sp, #48]
   1f3f8:	ldr	x19, [x1, #8]
   1f3fc:	mov	x22, x0
   1f400:	mov	x29, sp
   1f404:	cmp	x19, #0x0
   1f408:	b.le	1f468 <__gmpz_set_f@@Base+0x80>
   1f40c:	ldrsw	x8, [x22]
   1f410:	mov	x21, x1
   1f414:	cmp	x19, x8
   1f418:	b.gt	1f4a8 <__gmpz_set_f@@Base+0xc0>
   1f41c:	ldr	x20, [x22, #8]
   1f420:	ldrsw	x8, [x21, #4]
   1f424:	ldr	x21, [x21, #16]
   1f428:	neg	w9, w19
   1f42c:	cmp	w8, #0x0
   1f430:	csel	x9, x19, x9, ge  // ge = tcont
   1f434:	cmp	x8, #0x0
   1f438:	cneg	x23, x8, mi  // mi = first
   1f43c:	subs	x24, x19, x23
   1f440:	str	w9, [x22, #4]
   1f444:	b.le	1f480 <__gmpz_set_f@@Base+0x98>
   1f448:	b.eq	1f45c <__gmpz_set_f@@Base+0x74>  // b.none
   1f44c:	lsl	x2, x24, #3
   1f450:	mov	x0, x20
   1f454:	mov	w1, wzr
   1f458:	bl	c610 <memset@plt>
   1f45c:	add	x20, x20, x24, lsl #3
   1f460:	mov	x19, x23
   1f464:	b	1f488 <__gmpz_set_f@@Base+0xa0>
   1f468:	str	wzr, [x22, #4]
   1f46c:	ldp	x20, x19, [sp, #48]
   1f470:	ldp	x22, x21, [sp, #32]
   1f474:	ldp	x24, x23, [sp, #16]
   1f478:	ldp	x29, x30, [sp], #64
   1f47c:	ret
   1f480:	sub	x8, x23, x19
   1f484:	add	x21, x21, x8, lsl #3
   1f488:	mov	x0, x20
   1f48c:	mov	x1, x21
   1f490:	mov	x2, x19
   1f494:	ldp	x20, x19, [sp, #48]
   1f498:	ldp	x22, x21, [sp, #32]
   1f49c:	ldp	x24, x23, [sp, #16]
   1f4a0:	ldp	x29, x30, [sp], #64
   1f4a4:	b	ca70 <__gmpn_copyi@plt>
   1f4a8:	mov	x0, x22
   1f4ac:	mov	x1, x19
   1f4b0:	bl	c090 <__gmpz_realloc@plt>
   1f4b4:	mov	x20, x0
   1f4b8:	b	1f420 <__gmpz_set_f@@Base+0x38>

000000000001f4bc <__gmpz_set_q@@Base>:
   1f4bc:	add	x2, x1, #0x10
   1f4c0:	b	c050 <__gmpz_tdiv_q@plt>

000000000001f4c4 <__gmpz_set_si@@Base>:
   1f4c4:	stp	x29, x30, [sp, #-48]!
   1f4c8:	stp	x20, x19, [sp, #32]
   1f4cc:	ldr	w8, [x0]
   1f4d0:	cmp	x1, #0x0
   1f4d4:	str	x21, [sp, #16]
   1f4d8:	mov	x19, x0
   1f4dc:	mov	x20, x1
   1f4e0:	cneg	x21, x1, mi  // mi = first
   1f4e4:	cmp	w8, #0x0
   1f4e8:	mov	x29, sp
   1f4ec:	b.le	1f51c <__gmpz_set_si@@Base+0x58>
   1f4f0:	ldr	x0, [x19, #8]
   1f4f4:	cmp	x20, #0x0
   1f4f8:	cset	w8, ne  // ne = any
   1f4fc:	csetm	w9, ne  // ne = any
   1f500:	csel	w8, w8, w9, ge  // ge = tcont
   1f504:	str	x21, [x0]
   1f508:	str	w8, [x19, #4]
   1f50c:	ldp	x20, x19, [sp, #32]
   1f510:	ldr	x21, [sp, #16]
   1f514:	ldp	x29, x30, [sp], #48
   1f518:	ret
   1f51c:	mov	w1, #0x1                   	// #1
   1f520:	mov	x0, x19
   1f524:	bl	c090 <__gmpz_realloc@plt>
   1f528:	b	1f4f4 <__gmpz_set_si@@Base+0x30>

000000000001f52c <__gmpz_set_str@@Base>:
   1f52c:	stp	x29, x30, [sp, #-96]!
   1f530:	str	x27, [sp, #16]
   1f534:	stp	x26, x25, [sp, #32]
   1f538:	stp	x24, x23, [sp, #48]
   1f53c:	stp	x22, x21, [sp, #64]
   1f540:	stp	x20, x19, [sp, #80]
   1f544:	adrp	x26, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1f548:	ldr	x26, [x26, #3920]
   1f54c:	mov	w20, w2
   1f550:	mov	x21, x1
   1f554:	mov	x19, x0
   1f558:	cmp	w2, #0x25
   1f55c:	mov	x29, sp
   1f560:	b.lt	1f570 <__gmpz_set_str@@Base+0x44>  // b.tstop
   1f564:	cmp	w20, #0x3e
   1f568:	b.gt	1f724 <__gmpz_set_str@@Base+0x1f8>
   1f56c:	add	x26, x26, #0xd0
   1f570:	bl	cb00 <__ctype_b_loc@plt>
   1f574:	ldr	x8, [x0]
   1f578:	mov	x22, x0
   1f57c:	ldrb	w27, [x21], #1
   1f580:	ldrh	w9, [x8, x27, lsl #1]
   1f584:	tbnz	w9, #13, 1f57c <__gmpz_set_str@@Base+0x50>
   1f588:	cmp	w27, #0x2d
   1f58c:	b.ne	1f59c <__gmpz_set_str@@Base+0x70>  // b.any
   1f590:	ldrb	w27, [x21], #1
   1f594:	mov	w25, #0x1                   	// #1
   1f598:	b	1f5a0 <__gmpz_set_str@@Base+0x74>
   1f59c:	mov	w25, wzr
   1f5a0:	ldrb	w9, [x26, w27, uxtw]
   1f5a4:	cmp	w20, #0x0
   1f5a8:	mov	w10, #0xa                   	// #10
   1f5ac:	csel	w10, w10, w20, eq  // eq = none
   1f5b0:	cmp	w10, w9
   1f5b4:	b.le	1f724 <__gmpz_set_str@@Base+0x1f8>
   1f5b8:	cbnz	w20, 1f618 <__gmpz_set_str@@Base+0xec>
   1f5bc:	cmp	w27, #0x30
   1f5c0:	b.ne	1f5e8 <__gmpz_set_str@@Base+0xbc>  // b.any
   1f5c4:	mov	x9, x21
   1f5c8:	ldrb	w27, [x9], #1
   1f5cc:	orr	w10, w27, #0x20
   1f5d0:	cmp	w10, #0x78
   1f5d4:	b.ne	1f5f0 <__gmpz_set_str@@Base+0xc4>  // b.any
   1f5d8:	ldrb	w27, [x21, #1]
   1f5dc:	add	x21, x21, #0x2
   1f5e0:	mov	w20, #0x10                  	// #16
   1f5e4:	b	1f618 <__gmpz_set_str@@Base+0xec>
   1f5e8:	mov	w20, #0xa                   	// #10
   1f5ec:	b	1f618 <__gmpz_set_str@@Base+0xec>
   1f5f0:	cmp	w10, #0x62
   1f5f4:	b.ne	1f608 <__gmpz_set_str@@Base+0xdc>  // b.any
   1f5f8:	ldrb	w27, [x21, #1]
   1f5fc:	add	x21, x21, #0x2
   1f600:	mov	w20, #0x2                   	// #2
   1f604:	b	1f618 <__gmpz_set_str@@Base+0xec>
   1f608:	mov	w20, #0x8                   	// #8
   1f60c:	mov	x21, x9
   1f610:	b	1f618 <__gmpz_set_str@@Base+0xec>
   1f614:	ldrb	w27, [x21], #1
   1f618:	cmp	w27, #0x30
   1f61c:	b.eq	1f614 <__gmpz_set_str@@Base+0xe8>  // b.none
   1f620:	ldrh	w9, [x8, w27, uxtw #1]
   1f624:	tbnz	w9, #13, 1f614 <__gmpz_set_str@@Base+0xe8>
   1f628:	cbz	w27, 1f710 <__gmpz_set_str@@Base+0x1e4>
   1f62c:	sub	x0, x21, #0x1
   1f630:	str	xzr, [x29, #24]
   1f634:	bl	bf70 <strlen@plt>
   1f638:	add	x1, x0, #0x1
   1f63c:	mov	w8, #0x7f01                	// #32513
   1f640:	mov	x24, x0
   1f644:	cmp	x1, x8
   1f648:	b.cs	1f748 <__gmpz_set_str@@Base+0x21c>  // b.hs, b.nlast
   1f64c:	add	x9, x1, #0xf
   1f650:	mov	x8, sp
   1f654:	and	x9, x9, #0xfffffffffffffff0
   1f658:	sub	x23, x8, x9
   1f65c:	mov	sp, x23
   1f660:	mov	x8, x23
   1f664:	cbz	x24, 1f6a0 <__gmpz_set_str@@Base+0x174>
   1f668:	mov	x9, xzr
   1f66c:	mov	x8, x23
   1f670:	ldr	x10, [x22]
   1f674:	ldrh	w10, [x10, w27, uxtw #1]
   1f678:	tbnz	w10, #13, 1f690 <__gmpz_set_str@@Base+0x164>
   1f67c:	mov	w10, w27
   1f680:	ldrb	w10, [x26, x10]
   1f684:	cmp	w20, w10
   1f688:	b.le	1f71c <__gmpz_set_str@@Base+0x1f0>
   1f68c:	strb	w10, [x8], #1
   1f690:	ldrb	w27, [x21, x9]
   1f694:	add	x9, x9, #0x1
   1f698:	cmp	x24, x9
   1f69c:	b.ne	1f670 <__gmpz_set_str@@Base+0x144>  // b.any
   1f6a0:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1f6a4:	ldr	x9, [x9, #3936]
   1f6a8:	mov	w10, #0x28                  	// #40
   1f6ac:	sub	x21, x8, x23
   1f6b0:	ldrsw	x8, [x19]
   1f6b4:	smaddl	x9, w20, w10, x9
   1f6b8:	ldr	x9, [x9, #16]
   1f6bc:	umulh	x9, x9, x21
   1f6c0:	ubfx	x9, x9, #3, #58
   1f6c4:	add	x1, x9, #0x2
   1f6c8:	cmp	x1, x8
   1f6cc:	b.gt	1f758 <__gmpz_set_str@@Base+0x22c>
   1f6d0:	ldr	x0, [x19, #8]
   1f6d4:	mov	x1, x23
   1f6d8:	mov	x2, x21
   1f6dc:	mov	w3, w20
   1f6e0:	bl	c0a0 <__gmpn_set_str@plt>
   1f6e4:	neg	w8, w0
   1f6e8:	cmp	w25, #0x0
   1f6ec:	csel	x8, x0, x8, eq  // eq = none
   1f6f0:	str	w8, [x19, #4]
   1f6f4:	ldr	x8, [x29, #24]
   1f6f8:	mov	w0, wzr
   1f6fc:	cbz	x8, 1f728 <__gmpz_set_str@@Base+0x1fc>
   1f700:	mov	x0, x8
   1f704:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1f708:	mov	w0, wzr
   1f70c:	b	1f728 <__gmpz_set_str@@Base+0x1fc>
   1f710:	mov	w0, wzr
   1f714:	str	wzr, [x19, #4]
   1f718:	b	1f728 <__gmpz_set_str@@Base+0x1fc>
   1f71c:	ldr	x0, [x29, #24]
   1f720:	cbnz	x0, 1f764 <__gmpz_set_str@@Base+0x238>
   1f724:	mov	w0, #0xffffffff            	// #-1
   1f728:	mov	sp, x29
   1f72c:	ldp	x20, x19, [sp, #80]
   1f730:	ldp	x22, x21, [sp, #64]
   1f734:	ldp	x24, x23, [sp, #48]
   1f738:	ldp	x26, x25, [sp, #32]
   1f73c:	ldr	x27, [sp, #16]
   1f740:	ldp	x29, x30, [sp], #96
   1f744:	ret
   1f748:	add	x0, x29, #0x18
   1f74c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1f750:	mov	x23, x0
   1f754:	b	1f668 <__gmpz_set_str@@Base+0x13c>
   1f758:	mov	x0, x19
   1f75c:	bl	c090 <__gmpz_realloc@plt>
   1f760:	b	1f6d0 <__gmpz_set_str@@Base+0x1a4>
   1f764:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1f768:	b	1f724 <__gmpz_set_str@@Base+0x1f8>

000000000001f76c <__gmpz_set_ui@@Base>:
   1f76c:	stp	x29, x30, [sp, #-32]!
   1f770:	stp	x20, x19, [sp, #16]
   1f774:	ldr	w8, [x0]
   1f778:	mov	x19, x0
   1f77c:	mov	x20, x1
   1f780:	mov	x29, sp
   1f784:	cmp	w8, #0x0
   1f788:	b.le	1f7ac <__gmpz_set_ui@@Base+0x40>
   1f78c:	ldr	x0, [x19, #8]
   1f790:	cmp	x20, #0x0
   1f794:	cset	w8, ne  // ne = any
   1f798:	str	x20, [x0]
   1f79c:	str	w8, [x19, #4]
   1f7a0:	ldp	x20, x19, [sp, #16]
   1f7a4:	ldp	x29, x30, [sp], #32
   1f7a8:	ret
   1f7ac:	mov	w1, #0x1                   	// #1
   1f7b0:	mov	x0, x19
   1f7b4:	bl	c090 <__gmpz_realloc@plt>
   1f7b8:	b	1f790 <__gmpz_set_ui@@Base+0x24>

000000000001f7bc <__gmpz_setbit@@Base>:
   1f7bc:	stp	x29, x30, [sp, #-64]!
   1f7c0:	stp	x24, x23, [sp, #16]
   1f7c4:	stp	x22, x21, [sp, #32]
   1f7c8:	stp	x20, x19, [sp, #48]
   1f7cc:	ldrsw	x23, [x0, #4]
   1f7d0:	ldr	x20, [x0, #8]
   1f7d4:	mov	w8, #0x1                   	// #1
   1f7d8:	mov	x19, x0
   1f7dc:	lsr	x22, x1, #6
   1f7e0:	lsl	x24, x8, x1
   1f7e4:	mov	x29, sp
   1f7e8:	tbnz	w23, #31, 1f804 <__gmpz_setbit@@Base+0x48>
   1f7ec:	cmp	x22, x23
   1f7f0:	b.ge	1f868 <__gmpz_setbit@@Base+0xac>  // b.tcont
   1f7f4:	ldr	x8, [x20, x22, lsl #3]
   1f7f8:	orr	x8, x8, x24
   1f7fc:	str	x8, [x20, x22, lsl #3]
   1f800:	b	1f898 <__gmpz_setbit@@Base+0xdc>
   1f804:	neg	x8, x23
   1f808:	cmp	x22, x8
   1f80c:	b.ge	1f898 <__gmpz_setbit@@Base+0xdc>  // b.tcont
   1f810:	mov	x9, xzr
   1f814:	ldr	x10, [x20, x9, lsl #3]
   1f818:	add	x9, x9, #0x1
   1f81c:	cbz	x10, 1f814 <__gmpz_setbit@@Base+0x58>
   1f820:	sub	x10, x9, #0x1
   1f824:	cmp	x22, x10
   1f828:	b.ls	1f8ac <__gmpz_setbit@@Base+0xf0>  // b.plast
   1f82c:	ldr	x9, [x20, x22, lsl #3]
   1f830:	bics	xzr, x9, x24
   1f834:	bic	x10, x9, x24
   1f838:	cinc	x9, x22, eq  // eq = none
   1f83c:	cmp	x9, x8
   1f840:	str	x10, [x20, x22, lsl #3]
   1f844:	b.ne	1f898 <__gmpz_setbit@@Base+0xdc>  // b.any
   1f848:	sub	x8, x20, #0x8
   1f84c:	subs	x9, x22, #0x1
   1f850:	b.lt	1f91c <__gmpz_setbit@@Base+0x160>  // b.tstop
   1f854:	ldr	x10, [x8, x22, lsl #3]
   1f858:	mov	x22, x9
   1f85c:	cbz	x10, 1f84c <__gmpz_setbit@@Base+0x90>
   1f860:	add	x8, x9, #0x1
   1f864:	b	1f920 <__gmpz_setbit@@Base+0x164>
   1f868:	ldrsw	x8, [x19]
   1f86c:	add	x21, x22, #0x1
   1f870:	cmp	x22, x8
   1f874:	b.ge	1f908 <__gmpz_setbit@@Base+0x14c>  // b.tcont
   1f878:	subs	x8, x22, x23
   1f87c:	str	w21, [x19, #4]
   1f880:	b.eq	1f894 <__gmpz_setbit@@Base+0xd8>  // b.none
   1f884:	add	x0, x20, x23, lsl #3
   1f888:	lsl	x2, x8, #3
   1f88c:	mov	w1, wzr
   1f890:	bl	c610 <memset@plt>
   1f894:	str	x24, [x20, x22, lsl #3]
   1f898:	ldp	x20, x19, [sp, #48]
   1f89c:	ldp	x22, x21, [sp, #32]
   1f8a0:	ldp	x24, x23, [sp, #16]
   1f8a4:	ldp	x29, x30, [sp], #64
   1f8a8:	ret
   1f8ac:	ldr	x8, [x20, x22, lsl #3]
   1f8b0:	add	x10, x22, #0x1
   1f8b4:	cmp	x10, x9
   1f8b8:	b.ne	1f8cc <__gmpz_setbit@@Base+0x110>  // b.any
   1f8bc:	sub	x8, x8, #0x1
   1f8c0:	bic	x8, x8, x24
   1f8c4:	add	x8, x8, #0x1
   1f8c8:	b	1f7fc <__gmpz_setbit@@Base+0x40>
   1f8cc:	subs	x8, x8, x24
   1f8d0:	str	x8, [x20, x22, lsl #3]
   1f8d4:	b.cs	1f8f0 <__gmpz_setbit@@Base+0x134>  // b.hs, b.nlast
   1f8d8:	add	x8, x20, x22, lsl #3
   1f8dc:	add	x8, x8, #0x8
   1f8e0:	ldr	x9, [x8]
   1f8e4:	sub	x10, x9, #0x1
   1f8e8:	str	x10, [x8], #8
   1f8ec:	cbz	x9, 1f8e0 <__gmpz_setbit@@Base+0x124>
   1f8f0:	mvn	x8, x23
   1f8f4:	ldr	x8, [x20, x8, lsl #3]
   1f8f8:	cmp	x8, #0x0
   1f8fc:	cinc	w8, w23, eq  // eq = none
   1f900:	str	w8, [x19, #4]
   1f904:	b	1f898 <__gmpz_setbit@@Base+0xdc>
   1f908:	mov	x0, x19
   1f90c:	mov	x1, x21
   1f910:	bl	c090 <__gmpz_realloc@plt>
   1f914:	mov	x20, x0
   1f918:	b	1f878 <__gmpz_setbit@@Base+0xbc>
   1f91c:	mov	x8, xzr
   1f920:	neg	w8, w8
   1f924:	b	1f900 <__gmpz_setbit@@Base+0x144>

000000000001f928 <__gmpz_size@@Base>:
   1f928:	ldr	w8, [x0, #4]
   1f92c:	cmp	w8, #0x0
   1f930:	cneg	w0, w8, mi  // mi = first
   1f934:	ret

000000000001f938 <__gmpz_sizeinbase@@Base>:
   1f938:	ldr	w8, [x0, #4]
   1f93c:	cmp	w8, #0x0
   1f940:	cneg	w8, w8, mi  // mi = first
   1f944:	cbz	w8, 1f998 <__gmpz_sizeinbase@@Base+0x60>
   1f948:	ldr	x9, [x0, #8]
   1f94c:	sub	w10, w8, #0x1
   1f950:	adrp	x11, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   1f954:	mov	w8, w8
   1f958:	ldr	x9, [x9, w10, sxtw #3]
   1f95c:	ldr	x11, [x11, #3936]
   1f960:	sub	w10, w1, #0x1
   1f964:	lsl	x8, x8, #6
   1f968:	clz	x9, x9
   1f96c:	tst	w1, w10
   1f970:	sub	x8, x8, x9
   1f974:	sxtw	x9, w1
   1f978:	mov	w10, #0x28                  	// #40
   1f97c:	madd	x9, x9, x10, x11
   1f980:	b.ne	1f9a0 <__gmpz_sizeinbase@@Base+0x68>  // b.any
   1f984:	ldrsw	x9, [x9, #24]
   1f988:	add	x8, x8, x9
   1f98c:	sub	x8, x8, #0x1
   1f990:	udiv	x0, x8, x9
   1f994:	ret
   1f998:	mov	w0, #0x1                   	// #1
   1f99c:	ret
   1f9a0:	ldr	x9, [x9, #8]
   1f9a4:	add	x9, x9, #0x1
   1f9a8:	umulh	x8, x9, x8
   1f9ac:	add	x0, x8, #0x1
   1f9b0:	ret

000000000001f9b4 <__gmpz_sqrt@@Base>:
   1f9b4:	stp	x29, x30, [sp, #-48]!
   1f9b8:	stp	x22, x21, [sp, #16]
   1f9bc:	stp	x20, x19, [sp, #32]
   1f9c0:	mov	x29, sp
   1f9c4:	sub	sp, sp, #0x10
   1f9c8:	ldrsw	x19, [x1, #4]
   1f9cc:	cmp	w19, #0x0
   1f9d0:	b.le	1fa90 <__gmpz_sqrt@@Base+0xdc>
   1f9d4:	add	x8, x19, #0x1
   1f9d8:	add	x9, x19, #0x2
   1f9dc:	cmp	x8, #0x0
   1f9e0:	csinc	x8, x9, x19, lt  // lt = tstop
   1f9e4:	asr	x21, x8, #1
   1f9e8:	str	w21, [x0, #4]
   1f9ec:	ldr	x20, [x1, #8]
   1f9f0:	cmp	x0, x1
   1f9f4:	b.eq	1fa28 <__gmpz_sqrt@@Base+0x74>  // b.none
   1f9f8:	ldrsw	x8, [x0]
   1f9fc:	cmp	x21, x8
   1fa00:	b.gt	1fa9c <__gmpz_sqrt@@Base+0xe8>
   1fa04:	ldr	x0, [x0, #8]
   1fa08:	mov	x1, xzr
   1fa0c:	mov	x2, x20
   1fa10:	mov	x3, x19
   1fa14:	mov	sp, x29
   1fa18:	ldp	x20, x19, [sp, #32]
   1fa1c:	ldp	x22, x21, [sp, #16]
   1fa20:	ldp	x29, x30, [sp], #48
   1fa24:	b	d3d0 <__gmpn_sqrtrem@plt>
   1fa28:	lsl	x1, x21, #3
   1fa2c:	mov	w8, #0x7f00                	// #32512
   1fa30:	cmp	x1, x8
   1fa34:	stur	xzr, [x29, #-8]
   1fa38:	b.hi	1faa8 <__gmpz_sqrt@@Base+0xf4>  // b.pmore
   1fa3c:	add	x9, x1, #0xf
   1fa40:	mov	x8, sp
   1fa44:	and	x9, x9, #0xfffffffffffffff0
   1fa48:	sub	x22, x8, x9
   1fa4c:	mov	sp, x22
   1fa50:	mov	x0, x22
   1fa54:	mov	x1, xzr
   1fa58:	mov	x2, x20
   1fa5c:	mov	x3, x19
   1fa60:	bl	d3d0 <__gmpn_sqrtrem@plt>
   1fa64:	mov	x0, x20
   1fa68:	mov	x1, x22
   1fa6c:	mov	x2, x21
   1fa70:	bl	ca70 <__gmpn_copyi@plt>
   1fa74:	ldur	x0, [x29, #-8]
   1fa78:	cbnz	x0, 1fab8 <__gmpz_sqrt@@Base+0x104>
   1fa7c:	mov	sp, x29
   1fa80:	ldp	x20, x19, [sp, #32]
   1fa84:	ldp	x22, x21, [sp, #16]
   1fa88:	ldp	x29, x30, [sp], #48
   1fa8c:	ret
   1fa90:	cbnz	w19, 1fac0 <__gmpz_sqrt@@Base+0x10c>
   1fa94:	str	wzr, [x0, #4]
   1fa98:	b	1fa7c <__gmpz_sqrt@@Base+0xc8>
   1fa9c:	mov	x1, x21
   1faa0:	bl	c090 <__gmpz_realloc@plt>
   1faa4:	b	1fa08 <__gmpz_sqrt@@Base+0x54>
   1faa8:	sub	x0, x29, #0x8
   1faac:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1fab0:	mov	x22, x0
   1fab4:	b	1fa50 <__gmpz_sqrt@@Base+0x9c>
   1fab8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1fabc:	b	1fa7c <__gmpz_sqrt@@Base+0xc8>
   1fac0:	bl	d010 <__gmp_sqrt_of_negative@plt>

000000000001fac4 <__gmpz_sqrtrem@@Base>:
   1fac4:	stp	x29, x30, [sp, #-80]!
   1fac8:	stp	x24, x23, [sp, #32]
   1facc:	stp	x22, x21, [sp, #48]
   1fad0:	stp	x20, x19, [sp, #64]
   1fad4:	ldrsw	x20, [x2, #4]
   1fad8:	str	x25, [sp, #16]
   1fadc:	mov	x19, x1
   1fae0:	mov	x25, x0
   1fae4:	cmp	w20, #0x0
   1fae8:	mov	x29, sp
   1faec:	b.le	1fbd0 <__gmpz_sqrtrem@@Base+0x10c>
   1faf0:	ldr	w8, [x19]
   1faf4:	mov	x21, x2
   1faf8:	cmp	w20, w8
   1fafc:	b.gt	1fbdc <__gmpz_sqrtrem@@Base+0x118>
   1fb00:	ldr	x22, [x19, #8]
   1fb04:	add	x8, x20, #0x1
   1fb08:	add	x9, x20, #0x2
   1fb0c:	cmp	x8, #0x0
   1fb10:	csinc	x8, x9, x20, lt  // lt = tstop
   1fb14:	asr	x24, x8, #1
   1fb18:	str	w24, [x25, #4]
   1fb1c:	ldr	x23, [x21, #8]
   1fb20:	cmp	x25, x21
   1fb24:	b.eq	1fb50 <__gmpz_sqrtrem@@Base+0x8c>  // b.none
   1fb28:	ldrsw	x8, [x25]
   1fb2c:	cmp	x24, x8
   1fb30:	b.gt	1fbf0 <__gmpz_sqrtrem@@Base+0x12c>
   1fb34:	ldr	x0, [x25, #8]
   1fb38:	mov	x1, x22
   1fb3c:	mov	x2, x23
   1fb40:	mov	x3, x20
   1fb44:	bl	d3d0 <__gmpn_sqrtrem@plt>
   1fb48:	mov	x20, x0
   1fb4c:	b	1fbb0 <__gmpz_sqrtrem@@Base+0xec>
   1fb50:	lsl	x1, x24, #3
   1fb54:	mov	w8, #0x7f00                	// #32512
   1fb58:	cmp	x1, x8
   1fb5c:	str	xzr, [x29, #24]
   1fb60:	b.hi	1fc00 <__gmpz_sqrtrem@@Base+0x13c>  // b.pmore
   1fb64:	add	x9, x1, #0xf
   1fb68:	mov	x8, sp
   1fb6c:	and	x9, x9, #0xfffffffffffffff0
   1fb70:	sub	x25, x8, x9
   1fb74:	mov	sp, x25
   1fb78:	mov	x0, x25
   1fb7c:	mov	x1, x22
   1fb80:	mov	x2, x23
   1fb84:	mov	x3, x20
   1fb88:	bl	d3d0 <__gmpn_sqrtrem@plt>
   1fb8c:	cmp	x19, x21
   1fb90:	mov	x20, x0
   1fb94:	b.eq	1fba8 <__gmpz_sqrtrem@@Base+0xe4>  // b.none
   1fb98:	mov	x0, x23
   1fb9c:	mov	x1, x25
   1fba0:	mov	x2, x24
   1fba4:	bl	ca70 <__gmpn_copyi@plt>
   1fba8:	ldr	x0, [x29, #24]
   1fbac:	cbnz	x0, 1fc10 <__gmpz_sqrtrem@@Base+0x14c>
   1fbb0:	str	w20, [x19, #4]
   1fbb4:	mov	sp, x29
   1fbb8:	ldp	x20, x19, [sp, #64]
   1fbbc:	ldp	x22, x21, [sp, #48]
   1fbc0:	ldp	x24, x23, [sp, #32]
   1fbc4:	ldr	x25, [sp, #16]
   1fbc8:	ldp	x29, x30, [sp], #80
   1fbcc:	ret
   1fbd0:	cbnz	w20, 1fc18 <__gmpz_sqrtrem@@Base+0x154>
   1fbd4:	str	wzr, [x25, #4]
   1fbd8:	b	1fbb0 <__gmpz_sqrtrem@@Base+0xec>
   1fbdc:	mov	x0, x19
   1fbe0:	mov	x1, x20
   1fbe4:	bl	c090 <__gmpz_realloc@plt>
   1fbe8:	mov	x22, x0
   1fbec:	b	1fb04 <__gmpz_sqrtrem@@Base+0x40>
   1fbf0:	mov	x0, x25
   1fbf4:	mov	x1, x24
   1fbf8:	bl	c090 <__gmpz_realloc@plt>
   1fbfc:	b	1fb38 <__gmpz_sqrtrem@@Base+0x74>
   1fc00:	add	x0, x29, #0x18
   1fc04:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   1fc08:	mov	x25, x0
   1fc0c:	b	1fb78 <__gmpz_sqrtrem@@Base+0xb4>
   1fc10:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   1fc14:	b	1fbb0 <__gmpz_sqrtrem@@Base+0xec>
   1fc18:	bl	d010 <__gmp_sqrt_of_negative@plt>

000000000001fc1c <__gmpz_stronglucas@@Base>:
   1fc1c:	sub	sp, sp, #0x70
   1fc20:	stp	x29, x30, [sp, #48]
   1fc24:	stp	x24, x23, [sp, #64]
   1fc28:	stp	x22, x21, [sp, #80]
   1fc2c:	stp	x20, x19, [sp, #96]
   1fc30:	ldr	w8, [x0, #4]
   1fc34:	mov	x19, x1
   1fc38:	ldr	x1, [x0, #8]
   1fc3c:	add	x29, sp, #0x30
   1fc40:	cmp	w8, #0x0
   1fc44:	mov	x20, x2
   1fc48:	cneg	w2, w8, mi  // mi = first
   1fc4c:	sub	x0, x29, #0x10
   1fc50:	bl	ccb0 <__gmpz_roinit_n@plt>
   1fc54:	ldur	w22, [x29, #-12]
   1fc58:	ldur	x21, [x29, #-8]
   1fc5c:	sxtw	x24, w22
   1fc60:	mov	x0, x21
   1fc64:	mov	x1, x24
   1fc68:	bl	cf80 <__gmpn_mod_34lsub1@plt>
   1fc6c:	mov	x8, #0xcccccccccccccccc    	// #-3689348814741910324
   1fc70:	movk	x8, #0xcccd
   1fc74:	umulh	x8, x0, x8
   1fc78:	ubfx	x9, x8, #2, #30
   1fc7c:	lsl	w9, w9, #2
   1fc80:	mov	x23, x0
   1fc84:	add	w8, w9, w8, lsr #2
   1fc88:	sub	w8, w23, w8
   1fc8c:	tbnz	w8, #1, 1fd38 <__gmpz_stronglucas@@Base+0x11c>
   1fc90:	mov	x8, #0x2493                	// #9363
   1fc94:	movk	x8, #0x9249, lsl #16
   1fc98:	movk	x8, #0x4924, lsl #32
   1fc9c:	movk	x8, #0x2492, lsl #48
   1fca0:	umulh	x8, x23, x8
   1fca4:	sub	x9, x23, x8
   1fca8:	add	x8, x8, x9, lsr #1
   1fcac:	lsr	x8, x8, #2
   1fcb0:	sub	x8, x8, x8, lsl #3
   1fcb4:	add	x8, x23, x8
   1fcb8:	sub	x9, x8, #0x1
   1fcbc:	tst	x8, x9
   1fcc0:	b.ne	1fd4c <__gmpz_stronglucas@@Base+0x130>  // b.any
   1fcc4:	sub	x0, x29, #0x10
   1fcc8:	mov	w1, #0xb                   	// #11
   1fccc:	mov	w24, #0xb                   	// #11
   1fcd0:	bl	cb50 <__gmpz_kronecker_ui@plt>
   1fcd4:	cmn	w0, #0x1
   1fcd8:	b.eq	1fd50 <__gmpz_stronglucas@@Base+0x134>  // b.none
   1fcdc:	mov	x8, #0x4ec5                	// #20165
   1fce0:	movk	x8, #0xc4ec, lsl #16
   1fce4:	movk	x8, #0xec4e, lsl #32
   1fce8:	movk	x8, #0x4ec4, lsl #48
   1fcec:	umulh	x8, x23, x8
   1fcf0:	lsr	x8, x8, #2
   1fcf4:	mov	w24, #0xd                   	// #13
   1fcf8:	msub	w8, w8, w24, w23
   1fcfc:	sub	w8, w8, w8, lsr #3
   1fd00:	and	x8, x8, #0x7
   1fd04:	cmp	x8, #0x4
   1fd08:	b.hi	1fd50 <__gmpz_stronglucas@@Base+0x134>  // b.pmore
   1fd0c:	cmp	x8, #0x2
   1fd10:	b.eq	1fd50 <__gmpz_stronglucas@@Base+0x134>  // b.none
   1fd14:	mov	x8, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   1fd18:	movk	x8, #0xaaab
   1fd1c:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   1fd20:	madd	x8, x23, x8, x9
   1fd24:	mov	x9, #0x5555555555555555    	// #6148914691236517205
   1fd28:	cmp	x8, x9
   1fd2c:	b.cs	1fe80 <__gmpz_stronglucas@@Base+0x264>  // b.hs, b.nlast
   1fd30:	mov	w24, #0xf                   	// #15
   1fd34:	b	1fd50 <__gmpz_stronglucas@@Base+0x134>
   1fd38:	ldr	x2, [x19, #8]
   1fd3c:	mov	x0, x21
   1fd40:	mov	x1, x24
   1fd44:	bl	d140 <__gmpn_strongfibo@plt>
   1fd48:	b	1fe68 <__gmpz_stronglucas@@Base+0x24c>
   1fd4c:	mov	w24, #0x7                   	// #7
   1fd50:	lsr	x8, x24, #2
   1fd54:	neg	x9, x24, lsr #2
   1fd58:	tst	x24, #0x2
   1fd5c:	sub	x0, x29, #0x10
   1fd60:	mov	x1, xzr
   1fd64:	csinc	x22, x9, x8, eq  // eq = none
   1fd68:	bl	c9c0 <__gmpz_scan0@plt>
   1fd6c:	mov	x21, x0
   1fd70:	add	x0, sp, #0x10
   1fd74:	bl	d270 <__gmpz_init@plt>
   1fd78:	mov	x0, sp
   1fd7c:	bl	d270 <__gmpz_init@plt>
   1fd80:	sub	x4, x29, #0x10
   1fd84:	add	x5, sp, #0x10
   1fd88:	mov	x6, sp
   1fd8c:	mov	x0, x19
   1fd90:	mov	x1, x20
   1fd94:	mov	x2, x22
   1fd98:	mov	x3, x21
   1fd9c:	bl	c540 <__gmpz_lucas_mod@plt>
   1fda0:	cbnz	w0, 1fe50 <__gmpz_stronglucas@@Base+0x234>
   1fda4:	subs	x22, x21, #0x1
   1fda8:	b.eq	1ffa0 <__gmpz_stronglucas@@Base+0x384>  // b.none
   1fdac:	mov	x0, sp
   1fdb0:	mov	x1, x19
   1fdb4:	mov	x2, x19
   1fdb8:	bl	c4d0 <__gmpz_mul@plt>
   1fdbc:	mov	x0, sp
   1fdc0:	mov	w2, #0x2                   	// #2
   1fdc4:	mov	x1, x20
   1fdc8:	bl	c890 <__gmpz_submul_ui@plt>
   1fdcc:	mov	x1, sp
   1fdd0:	sub	x2, x29, #0x10
   1fdd4:	mov	x0, x19
   1fdd8:	bl	caa0 <__gmpz_tdiv_r@plt>
   1fddc:	ldr	w8, [x19, #4]
   1fde0:	cbz	w8, 1fe4c <__gmpz_stronglucas@@Base+0x230>
   1fde4:	mov	w21, #0x1                   	// #1
   1fde8:	subs	x22, x22, #0x1
   1fdec:	b.eq	1ffa0 <__gmpz_stronglucas@@Base+0x384>  // b.none
   1fdf0:	mov	x0, sp
   1fdf4:	mov	x1, x20
   1fdf8:	mov	x2, x20
   1fdfc:	bl	c4d0 <__gmpz_mul@plt>
   1fe00:	mov	x1, sp
   1fe04:	sub	x2, x29, #0x10
   1fe08:	mov	x0, x20
   1fe0c:	bl	caa0 <__gmpz_tdiv_r@plt>
   1fe10:	mov	x0, sp
   1fe14:	mov	x1, x19
   1fe18:	mov	x2, x19
   1fe1c:	bl	c4d0 <__gmpz_mul@plt>
   1fe20:	mov	x0, sp
   1fe24:	mov	w2, #0x2                   	// #2
   1fe28:	mov	x1, x20
   1fe2c:	bl	c890 <__gmpz_submul_ui@plt>
   1fe30:	mov	x1, sp
   1fe34:	sub	x2, x29, #0x10
   1fe38:	mov	x0, x19
   1fe3c:	bl	caa0 <__gmpz_tdiv_r@plt>
   1fe40:	ldr	w8, [x19, #4]
   1fe44:	cbnz	w8, 1fde8 <__gmpz_stronglucas@@Base+0x1cc>
   1fe48:	b	1fe50 <__gmpz_stronglucas@@Base+0x234>
   1fe4c:	mov	w21, #0x1                   	// #1
   1fe50:	add	x0, sp, #0x10
   1fe54:	bl	cb70 <__gmpz_clear@plt>
   1fe58:	mov	x0, sp
   1fe5c:	bl	cb70 <__gmpz_clear@plt>
   1fe60:	cmp	x21, #0x0
   1fe64:	cset	w0, ne  // ne = any
   1fe68:	ldp	x20, x19, [sp, #96]
   1fe6c:	ldp	x22, x21, [sp, #80]
   1fe70:	ldp	x24, x23, [sp, #64]
   1fe74:	ldp	x29, x30, [sp, #48]
   1fe78:	add	sp, sp, #0x70
   1fe7c:	ret
   1fe80:	mov	x8, #0xf0f0f0f0f0f0f0f0    	// #-1085102592571150096
   1fe84:	movk	x8, #0xf0f1
   1fe88:	umulh	x8, x23, x8
   1fe8c:	lsr	x9, x8, #4
   1fe90:	lsl	x9, x9, #4
   1fe94:	add	x8, x9, x8, lsr #4
   1fe98:	sub	x8, x23, x8
   1fe9c:	sub	x9, x8, #0x1
   1fea0:	tst	x8, x9
   1fea4:	b.eq	1fec0 <__gmpz_stronglucas@@Base+0x2a4>  // b.none
   1fea8:	mov	w24, #0x11                  	// #17
   1feac:	mov	w9, #0x10                  	// #16
   1feb0:	sub	x10, x24, x8
   1feb4:	sub	x8, x9, x8
   1feb8:	tst	x10, x8
   1febc:	b.ne	1fd50 <__gmpz_stronglucas@@Base+0x134>  // b.any
   1fec0:	cmp	w22, #0x1
   1fec4:	b.lt	1ffb0 <__gmpz_stronglucas@@Base+0x394>  // b.tstop
   1fec8:	mov	x0, x21
   1fecc:	mov	x1, x22
   1fed0:	bl	d0d0 <__gmpn_perfect_square_p@plt>
   1fed4:	cbnz	w0, 1ffbc <__gmpz_stronglucas@@Base+0x3a0>
   1fed8:	cmp	w22, #0x2
   1fedc:	b.eq	1ff14 <__gmpz_stronglucas@@Base+0x2f8>  // b.none
   1fee0:	cmp	w22, #0x1
   1fee4:	b.ne	1ff38 <__gmpz_stronglucas@@Base+0x31c>  // b.any
   1fee8:	ldr	x8, [x21]
   1feec:	mov	w9, #0x40                  	// #64
   1fef0:	mov	w22, #0x1                   	// #1
   1fef4:	clz	x10, x8
   1fef8:	sub	w9, w9, w10
   1fefc:	asr	w9, w9, #1
   1ff00:	lsl	x10, x22, x9
   1ff04:	lsr	x8, x8, x9
   1ff08:	add	x8, x10, x8
   1ff0c:	lsr	x24, x8, #1
   1ff10:	b	1ff3c <__gmpz_stronglucas@@Base+0x320>
   1ff14:	add	x0, sp, #0x10
   1ff18:	mov	w3, #0x2                   	// #2
   1ff1c:	mov	x1, xzr
   1ff20:	mov	x2, x21
   1ff24:	bl	d3d0 <__gmpn_sqrtrem@plt>
   1ff28:	ldr	x24, [sp, #16]
   1ff2c:	ldur	x21, [x29, #-8]
   1ff30:	ldur	w22, [x29, #-12]
   1ff34:	b	1ff40 <__gmpz_stronglucas@@Base+0x324>
   1ff38:	mov	x24, #0xffffffffffffffff    	// #-1
   1ff3c:	str	x24, [sp, #16]
   1ff40:	sxtw	x23, w22
   1ff44:	mov	w22, #0x13                  	// #19
   1ff48:	sub	x8, x22, #0x2
   1ff4c:	cmp	x8, x24
   1ff50:	b.cs	1ffa8 <__gmpz_stronglucas@@Base+0x38c>  // b.hs, b.nlast
   1ff54:	mov	x0, x21
   1ff58:	mov	x1, x23
   1ff5c:	mov	x2, x22
   1ff60:	cmp	w23, #0x28
   1ff64:	b.lt	1ff74 <__gmpz_stronglucas@@Base+0x358>  // b.tstop
   1ff68:	bl	c400 <__gmpn_mod_1@plt>
   1ff6c:	mov	w2, wzr
   1ff70:	b	1ff80 <__gmpz_stronglucas@@Base+0x364>
   1ff74:	mov	x3, xzr
   1ff78:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   1ff7c:	mov	w2, w22
   1ff80:	cbz	x0, 1fe68 <__gmpz_stronglucas@@Base+0x24c>
   1ff84:	mov	x1, x22
   1ff88:	bl	c750 <__gmpn_jacobi_base@plt>
   1ff8c:	cmp	w0, #0x1
   1ff90:	add	x22, x22, #0x2
   1ff94:	b.eq	1ff48 <__gmpz_stronglucas@@Base+0x32c>  // b.none
   1ff98:	sub	x24, x22, #0x2
   1ff9c:	b	1fd50 <__gmpz_stronglucas@@Base+0x134>
   1ffa0:	mov	x21, xzr
   1ffa4:	b	1fe50 <__gmpz_stronglucas@@Base+0x234>
   1ffa8:	mov	w0, #0x1                   	// #1
   1ffac:	b	1fe68 <__gmpz_stronglucas@@Base+0x24c>
   1ffb0:	mvn	w8, w22
   1ffb4:	lsr	w0, w8, #31
   1ffb8:	cbz	w0, 1fed8 <__gmpz_stronglucas@@Base+0x2bc>
   1ffbc:	mov	w0, wzr
   1ffc0:	b	1fe68 <__gmpz_stronglucas@@Base+0x24c>

000000000001ffc4 <__gmpz_sub@@Base>:
   1ffc4:	stp	x29, x30, [sp, #-80]!
   1ffc8:	stp	x26, x25, [sp, #16]
   1ffcc:	stp	x24, x23, [sp, #32]
   1ffd0:	stp	x22, x21, [sp, #48]
   1ffd4:	stp	x20, x19, [sp, #64]
   1ffd8:	ldrsw	x8, [x2, #4]
   1ffdc:	ldrsw	x9, [x1, #4]
   1ffe0:	ldrsw	x10, [x0]
   1ffe4:	mov	x19, x0
   1ffe8:	neg	x11, x8
   1ffec:	cmp	x9, #0x0
   1fff0:	cneg	x12, x9, mi  // mi = first
   1fff4:	cmp	x11, #0x0
   1fff8:	cneg	x11, x8, pl  // pl = nfrst
   1fffc:	cmp	x12, x11
   20000:	csel	x20, x11, x12, lt  // lt = tstop
   20004:	csel	x23, x12, x11, lt  // lt = tstop
   20008:	csneg	x25, x9, x8, lt  // lt = tstop
   2000c:	csneg	x24, x9, x8, ge  // ge = tcont
   20010:	csel	x26, x1, x2, lt  // lt = tstop
   20014:	csel	x22, x2, x1, lt  // lt = tstop
   20018:	cmp	x20, x10
   2001c:	mov	x29, sp
   20020:	b.ge	2020c <__gmpz_sub@@Base+0x248>  // b.tcont
   20024:	ldr	x21, [x19, #8]
   20028:	ldr	x22, [x22, #8]
   2002c:	ldr	x2, [x26, #8]
   20030:	eor	x8, x24, x25
   20034:	tbnz	x8, #63, 20078 <__gmpz_sub@@Base+0xb4>
   20038:	cbz	x23, 200d4 <__gmpz_sub@@Base+0x110>
   2003c:	mov	x0, x21
   20040:	mov	x1, x22
   20044:	mov	x3, x23
   20048:	bl	ca90 <__gmpn_add_n@plt>
   2004c:	cbz	x0, 20118 <__gmpz_sub@@Base+0x154>
   20050:	mov	w8, #0x1                   	// #1
   20054:	cmp	x23, x20
   20058:	b.ge	2014c <__gmpz_sub@@Base+0x188>  // b.tcont
   2005c:	ldr	x9, [x22, x23, lsl #3]
   20060:	adds	x10, x9, #0x1
   20064:	add	x9, x23, #0x1
   20068:	str	x10, [x21, x23, lsl #3]
   2006c:	mov	x23, x9
   20070:	b.cs	20054 <__gmpz_sub@@Base+0x90>  // b.hs, b.nlast
   20074:	b	2011c <__gmpz_sub@@Base+0x158>
   20078:	cmp	x20, x23
   2007c:	b.ne	200dc <__gmpz_sub@@Base+0x118>  // b.any
   20080:	sub	x8, x20, #0x1
   20084:	add	x9, x8, #0x1
   20088:	cmp	x9, #0x1
   2008c:	b.lt	200a8 <__gmpz_sub@@Base+0xe4>  // b.tstop
   20090:	ldr	x9, [x22, x8, lsl #3]
   20094:	ldr	x10, [x2, x8, lsl #3]
   20098:	sub	x8, x8, #0x1
   2009c:	cmp	x9, x10
   200a0:	b.eq	20084 <__gmpz_sub@@Base+0xc0>  // b.none
   200a4:	b.ls	20168 <__gmpz_sub@@Base+0x1a4>  // b.plast
   200a8:	mov	x0, x21
   200ac:	mov	x1, x22
   200b0:	mov	x3, x20
   200b4:	bl	c2e0 <__gmpn_sub_n@plt>
   200b8:	sub	x8, x21, #0x8
   200bc:	mov	x9, x20
   200c0:	subs	x20, x20, #0x1
   200c4:	b.lt	201e8 <__gmpz_sub@@Base+0x224>  // b.tstop
   200c8:	ldr	x10, [x8, x9, lsl #3]
   200cc:	cbz	x10, 200bc <__gmpz_sub@@Base+0xf8>
   200d0:	b	201e8 <__gmpz_sub@@Base+0x224>
   200d4:	mov	x9, xzr
   200d8:	b	2011c <__gmpz_sub@@Base+0x158>
   200dc:	cbz	x23, 20160 <__gmpz_sub@@Base+0x19c>
   200e0:	mov	x0, x21
   200e4:	mov	x1, x22
   200e8:	mov	x3, x23
   200ec:	bl	c2e0 <__gmpn_sub_n@plt>
   200f0:	cbz	x0, 201a0 <__gmpz_sub@@Base+0x1dc>
   200f4:	cmp	x23, x20
   200f8:	b.ge	201d0 <__gmpz_sub@@Base+0x20c>  // b.tcont
   200fc:	ldr	x8, [x22, x23, lsl #3]
   20100:	add	x9, x23, #0x1
   20104:	sub	x10, x8, #0x1
   20108:	str	x10, [x21, x23, lsl #3]
   2010c:	mov	x23, x9
   20110:	cbz	x8, 200f4 <__gmpz_sub@@Base+0x130>
   20114:	b	201a4 <__gmpz_sub@@Base+0x1e0>
   20118:	mov	x9, x23
   2011c:	cmp	x21, x22
   20120:	mov	x8, xzr
   20124:	b.eq	2014c <__gmpz_sub@@Base+0x188>  // b.none
   20128:	cmp	x9, x20
   2012c:	b.ge	2014c <__gmpz_sub@@Base+0x188>  // b.tcont
   20130:	sub	x8, x20, x9
   20134:	add	x10, x21, x9, lsl #3
   20138:	add	x9, x22, x9, lsl #3
   2013c:	ldr	x11, [x9], #8
   20140:	subs	x8, x8, #0x1
   20144:	str	x11, [x10], #8
   20148:	b.ne	2013c <__gmpz_sub@@Base+0x178>  // b.any
   2014c:	str	x8, [x21, x20, lsl #3]
   20150:	add	x8, x8, x20
   20154:	cmp	x24, #0x0
   20158:	cneg	x8, x8, lt  // lt = tstop
   2015c:	b	201f0 <__gmpz_sub@@Base+0x22c>
   20160:	mov	x9, xzr
   20164:	b	201a4 <__gmpz_sub@@Base+0x1e0>
   20168:	mov	x0, x21
   2016c:	mov	x1, x2
   20170:	mov	x2, x22
   20174:	mov	x3, x20
   20178:	bl	c2e0 <__gmpn_sub_n@plt>
   2017c:	sub	x8, x21, #0x8
   20180:	mov	x9, x20
   20184:	subs	x20, x20, #0x1
   20188:	b.lt	20194 <__gmpz_sub@@Base+0x1d0>  // b.tstop
   2018c:	ldr	x10, [x8, x9, lsl #3]
   20190:	cbz	x10, 20180 <__gmpz_sub@@Base+0x1bc>
   20194:	cmp	x24, #0x0
   20198:	cneg	x8, x9, ge  // ge = tcont
   2019c:	b	201f0 <__gmpz_sub@@Base+0x22c>
   201a0:	mov	x9, x23
   201a4:	cmp	x21, x22
   201a8:	b.eq	201d0 <__gmpz_sub@@Base+0x20c>  // b.none
   201ac:	cmp	x9, x20
   201b0:	b.ge	201d0 <__gmpz_sub@@Base+0x20c>  // b.tcont
   201b4:	sub	x8, x20, x9
   201b8:	add	x10, x21, x9, lsl #3
   201bc:	add	x9, x22, x9, lsl #3
   201c0:	ldr	x11, [x9], #8
   201c4:	subs	x8, x8, #0x1
   201c8:	str	x11, [x10], #8
   201cc:	b.ne	201c0 <__gmpz_sub@@Base+0x1fc>  // b.any
   201d0:	sub	x8, x21, #0x8
   201d4:	mov	x9, x20
   201d8:	subs	x20, x20, #0x1
   201dc:	b.lt	201e8 <__gmpz_sub@@Base+0x224>  // b.tstop
   201e0:	ldr	x10, [x8, x9, lsl #3]
   201e4:	cbz	x10, 201d4 <__gmpz_sub@@Base+0x210>
   201e8:	cmp	x24, #0x0
   201ec:	cneg	x8, x9, lt  // lt = tstop
   201f0:	str	w8, [x19, #4]
   201f4:	ldp	x20, x19, [sp, #64]
   201f8:	ldp	x22, x21, [sp, #48]
   201fc:	ldp	x24, x23, [sp, #32]
   20200:	ldp	x26, x25, [sp, #16]
   20204:	ldp	x29, x30, [sp], #80
   20208:	ret
   2020c:	add	x1, x20, #0x1
   20210:	mov	x0, x19
   20214:	bl	c090 <__gmpz_realloc@plt>
   20218:	mov	x21, x0
   2021c:	b	20028 <__gmpz_sub@@Base+0x64>

0000000000020220 <__gmpz_sub_ui@@Base>:
   20220:	stp	x29, x30, [sp, #-64]!
   20224:	stp	x22, x21, [sp, #32]
   20228:	stp	x20, x19, [sp, #48]
   2022c:	str	x23, [sp, #16]
   20230:	ldrsw	x23, [x1, #4]
   20234:	mov	x20, x2
   20238:	mov	x19, x0
   2023c:	mov	x29, sp
   20240:	cbz	w23, 2028c <__gmpz_sub_ui@@Base+0x6c>
   20244:	ldrsw	x8, [x19]
   20248:	cmp	x23, #0x0
   2024c:	cneg	x22, x23, mi  // mi = first
   20250:	mov	x21, x1
   20254:	cmp	x22, x8
   20258:	b.ge	20420 <__gmpz_sub_ui@@Base+0x200>  // b.tcont
   2025c:	ldr	x0, [x19, #8]
   20260:	ldr	x8, [x21, #8]
   20264:	tbnz	w23, #31, 202ac <__gmpz_sub_ui@@Base+0x8c>
   20268:	ldr	x10, [x8]
   2026c:	subs	x9, x22, #0x1
   20270:	b.ne	20320 <__gmpz_sub_ui@@Base+0x100>  // b.any
   20274:	cmp	x10, x20
   20278:	b.cs	20320 <__gmpz_sub_ui@@Base+0x100>  // b.hs, b.nlast
   2027c:	sub	x8, x20, x10
   20280:	str	x8, [x0]
   20284:	mov	x8, #0xffffffffffffffff    	// #-1
   20288:	b	20408 <__gmpz_sub_ui@@Base+0x1e8>
   2028c:	ldr	w8, [x19]
   20290:	cmp	w8, #0x0
   20294:	b.le	20430 <__gmpz_sub_ui@@Base+0x210>
   20298:	ldr	x0, [x19, #8]
   2029c:	cmp	x20, #0x0
   202a0:	str	x20, [x0]
   202a4:	csetm	w8, ne  // ne = any
   202a8:	b	20408 <__gmpz_sub_ui@@Base+0x1e8>
   202ac:	ldr	x9, [x8]
   202b0:	adds	x9, x9, x20
   202b4:	str	x9, [x0]
   202b8:	b.cc	20388 <__gmpz_sub_ui@@Base+0x168>  // b.lo, b.ul, b.last
   202bc:	mov	x11, #0xfffffffffffffff8    	// #-8
   202c0:	mov	w10, #0x1                   	// #1
   202c4:	mov	w9, #0x1                   	// #1
   202c8:	cmp	x9, x22
   202cc:	b.ge	203bc <__gmpz_sub_ui@@Base+0x19c>  // b.tcont
   202d0:	ldr	x12, [x8, x9, lsl #3]
   202d4:	sub	x11, x11, #0x8
   202d8:	adds	x12, x12, #0x1
   202dc:	str	x12, [x0, x9, lsl #3]
   202e0:	add	x9, x9, #0x1
   202e4:	b.cs	202c8 <__gmpz_sub_ui@@Base+0xa8>  // b.hs, b.nlast
   202e8:	cmp	x8, x0
   202ec:	mov	x10, xzr
   202f0:	b.eq	203bc <__gmpz_sub_ui@@Base+0x19c>  // b.none
   202f4:	cmp	x9, x22
   202f8:	b.ge	203bc <__gmpz_sub_ui@@Base+0x19c>  // b.tcont
   202fc:	sub	x8, x8, x11
   20300:	sub	x10, x0, x11
   20304:	mov	x11, x22
   20308:	ldr	x12, [x8], #8
   2030c:	sub	x11, x11, #0x1
   20310:	cmp	x9, x11
   20314:	str	x12, [x10], #8
   20318:	b.ne	20308 <__gmpz_sub_ui@@Base+0xe8>  // b.any
   2031c:	b	203b8 <__gmpz_sub_ui@@Base+0x198>
   20320:	subs	x10, x10, x20
   20324:	str	x10, [x0]
   20328:	b.cs	203cc <__gmpz_sub_ui@@Base+0x1ac>  // b.hs, b.nlast
   2032c:	mov	x10, #0xfffffffffffffff8    	// #-8
   20330:	mov	w9, #0x1                   	// #1
   20334:	cmp	x9, x22
   20338:	b.ge	203f4 <__gmpz_sub_ui@@Base+0x1d4>  // b.tcont
   2033c:	ldr	x11, [x8, x9, lsl #3]
   20340:	sub	x10, x10, #0x8
   20344:	sub	x12, x11, #0x1
   20348:	str	x12, [x0, x9, lsl #3]
   2034c:	add	x9, x9, #0x1
   20350:	cbz	x11, 20334 <__gmpz_sub_ui@@Base+0x114>
   20354:	cmp	x8, x0
   20358:	b.eq	203f4 <__gmpz_sub_ui@@Base+0x1d4>  // b.none
   2035c:	cmp	x9, x22
   20360:	b.ge	203f4 <__gmpz_sub_ui@@Base+0x1d4>  // b.tcont
   20364:	sub	x8, x8, x10
   20368:	sub	x10, x0, x10
   2036c:	mov	x11, x22
   20370:	ldr	x12, [x8], #8
   20374:	sub	x11, x11, #0x1
   20378:	cmp	x9, x11
   2037c:	str	x12, [x10], #8
   20380:	b.ne	20370 <__gmpz_sub_ui@@Base+0x150>  // b.any
   20384:	b	203f4 <__gmpz_sub_ui@@Base+0x1d4>
   20388:	cmp	x22, #0x2
   2038c:	mov	x10, xzr
   20390:	b.lt	203bc <__gmpz_sub_ui@@Base+0x19c>  // b.tstop
   20394:	cmp	x8, x0
   20398:	b.eq	203bc <__gmpz_sub_ui@@Base+0x19c>  // b.none
   2039c:	sub	x9, x22, #0x1
   203a0:	add	x10, x0, #0x8
   203a4:	add	x8, x8, #0x8
   203a8:	ldr	x11, [x8], #8
   203ac:	subs	x9, x9, #0x1
   203b0:	str	x11, [x10], #8
   203b4:	b.ne	203a8 <__gmpz_sub_ui@@Base+0x188>  // b.any
   203b8:	mov	x10, xzr
   203bc:	add	x8, x22, x10
   203c0:	str	x10, [x0, x22, lsl #3]
   203c4:	neg	x8, x8
   203c8:	b	20408 <__gmpz_sub_ui@@Base+0x1e8>
   203cc:	cmp	x22, #0x2
   203d0:	b.lt	203f4 <__gmpz_sub_ui@@Base+0x1d4>  // b.tstop
   203d4:	cmp	x8, x0
   203d8:	b.eq	203f4 <__gmpz_sub_ui@@Base+0x1d4>  // b.none
   203dc:	add	x10, x0, #0x8
   203e0:	add	x8, x8, #0x8
   203e4:	ldr	x11, [x8], #8
   203e8:	subs	x9, x9, #0x1
   203ec:	str	x11, [x10], #8
   203f0:	b.ne	203e4 <__gmpz_sub_ui@@Base+0x1c4>  // b.any
   203f4:	add	x8, x0, x22, lsl #3
   203f8:	ldur	x8, [x8, #-8]
   203fc:	cmp	x8, #0x0
   20400:	cset	w8, eq  // eq = none
   20404:	sub	x8, x22, x8
   20408:	str	w8, [x19, #4]
   2040c:	ldp	x20, x19, [sp, #48]
   20410:	ldp	x22, x21, [sp, #32]
   20414:	ldr	x23, [sp, #16]
   20418:	ldp	x29, x30, [sp], #64
   2041c:	ret
   20420:	add	x1, x22, #0x1
   20424:	mov	x0, x19
   20428:	bl	c090 <__gmpz_realloc@plt>
   2042c:	b	20260 <__gmpz_sub_ui@@Base+0x40>
   20430:	mov	w1, #0x1                   	// #1
   20434:	mov	x0, x19
   20438:	bl	c090 <__gmpz_realloc@plt>
   2043c:	b	2029c <__gmpz_sub_ui@@Base+0x7c>

0000000000020440 <__gmpz_swap@@Base>:
   20440:	ldr	x8, [x1]
   20444:	ldr	x9, [x0]
   20448:	str	x8, [x0]
   2044c:	str	x9, [x1]
   20450:	ldr	x8, [x0, #8]
   20454:	ldr	x9, [x1, #8]
   20458:	str	x8, [x1, #8]
   2045c:	str	x9, [x0, #8]
   20460:	ret

0000000000020464 <__gmpz_tdiv_ui@@Base>:
   20464:	stp	x29, x30, [sp, #-16]!
   20468:	mov	x29, sp
   2046c:	cbz	x1, 2049c <__gmpz_tdiv_ui@@Base+0x38>
   20470:	ldrsw	x8, [x0, #4]
   20474:	cbz	w8, 20490 <__gmpz_tdiv_ui@@Base+0x2c>
   20478:	ldr	x0, [x0, #8]
   2047c:	cmp	x8, #0x0
   20480:	mov	x2, x1
   20484:	cneg	x1, x8, mi  // mi = first
   20488:	ldp	x29, x30, [sp], #16
   2048c:	b	c400 <__gmpn_mod_1@plt>
   20490:	mov	x0, xzr
   20494:	ldp	x29, x30, [sp], #16
   20498:	ret
   2049c:	bl	bfe0 <__gmp_divide_by_zero@plt>

00000000000204a0 <__gmpz_tdiv_q@@Base>:
   204a0:	stp	x29, x30, [sp, #-96]!
   204a4:	stp	x28, x27, [sp, #16]
   204a8:	stp	x26, x25, [sp, #32]
   204ac:	stp	x24, x23, [sp, #48]
   204b0:	stp	x22, x21, [sp, #64]
   204b4:	stp	x20, x19, [sp, #80]
   204b8:	mov	x29, sp
   204bc:	sub	sp, sp, #0x10
   204c0:	ldrsw	x27, [x1, #4]
   204c4:	ldrsw	x28, [x2, #4]
   204c8:	cmp	x27, #0x0
   204cc:	cneg	x20, x27, mi  // mi = first
   204d0:	cmp	x28, #0x0
   204d4:	cneg	x21, x28, mi  // mi = first
   204d8:	cbz	x21, 2062c <__gmpz_tdiv_q@@Base+0x18c>
   204dc:	mov	x19, x0
   204e0:	sub	x22, x20, x21
   204e4:	tbnz	x22, #63, 205d8 <__gmpz_tdiv_q@@Base+0x138>
   204e8:	ldrsw	x8, [x19]
   204ec:	mov	x23, x1
   204f0:	mov	x25, x2
   204f4:	add	x1, x22, #0x1
   204f8:	cmp	x22, x8
   204fc:	stur	x1, [x29, #-16]
   20500:	b.ge	205fc <__gmpz_tdiv_q@@Base+0x15c>  // b.tcont
   20504:	ldr	x24, [x19, #8]
   20508:	stur	xzr, [x29, #-8]
   2050c:	ldr	x25, [x25, #8]
   20510:	cmp	x25, x24
   20514:	b.ne	20548 <__gmpz_tdiv_q@@Base+0xa8>  // b.any
   20518:	cmp	x21, #0xfe0
   2051c:	lsl	x1, x21, #3
   20520:	b.hi	2061c <__gmpz_tdiv_q@@Base+0x17c>  // b.pmore
   20524:	add	x9, x1, #0xf
   20528:	mov	x8, sp
   2052c:	and	x9, x9, #0xfffffffffffffff0
   20530:	sub	x25, x8, x9
   20534:	mov	sp, x25
   20538:	mov	x0, x25
   2053c:	mov	x1, x24
   20540:	mov	x2, x21
   20544:	bl	ca70 <__gmpn_copyi@plt>
   20548:	lsl	x8, x20, #3
   2054c:	cmp	x20, #0xfdf
   20550:	add	x1, x8, #0x8
   20554:	b.hi	2060c <__gmpz_tdiv_q@@Base+0x16c>  // b.pmore
   20558:	add	x9, x1, #0xf
   2055c:	mov	x8, sp
   20560:	and	x9, x9, #0xfffffffffffffff0
   20564:	sub	x26, x8, x9
   20568:	mov	sp, x26
   2056c:	ldr	x1, [x23, #8]
   20570:	cmp	x1, x24
   20574:	b.ne	2058c <__gmpz_tdiv_q@@Base+0xec>  // b.any
   20578:	mov	x0, x26
   2057c:	mov	x1, x24
   20580:	mov	x2, x20
   20584:	bl	ca70 <__gmpn_copyi@plt>
   20588:	mov	x1, x26
   2058c:	mov	x0, x24
   20590:	mov	x2, x20
   20594:	mov	x3, x25
   20598:	mov	x4, x21
   2059c:	mov	x5, x26
   205a0:	bl	c340 <__gmpn_div_q@plt>
   205a4:	ldr	x8, [x24, x22, lsl #3]
   205a8:	ldp	x10, x0, [x29, #-16]
   205ac:	eor	w9, w28, w27
   205b0:	cmp	x8, #0x0
   205b4:	cset	w8, eq  // eq = none
   205b8:	sub	x8, x10, x8
   205bc:	neg	w10, w8
   205c0:	cmp	w9, #0x0
   205c4:	csel	x8, x8, x10, ge  // ge = tcont
   205c8:	str	w8, [x19, #4]
   205cc:	cbz	x0, 205dc <__gmpz_tdiv_q@@Base+0x13c>
   205d0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   205d4:	b	205dc <__gmpz_tdiv_q@@Base+0x13c>
   205d8:	str	wzr, [x19, #4]
   205dc:	mov	sp, x29
   205e0:	ldp	x20, x19, [sp, #80]
   205e4:	ldp	x22, x21, [sp, #64]
   205e8:	ldp	x24, x23, [sp, #48]
   205ec:	ldp	x26, x25, [sp, #32]
   205f0:	ldp	x28, x27, [sp, #16]
   205f4:	ldp	x29, x30, [sp], #96
   205f8:	ret
   205fc:	mov	x0, x19
   20600:	bl	c090 <__gmpz_realloc@plt>
   20604:	mov	x24, x0
   20608:	b	20508 <__gmpz_tdiv_q@@Base+0x68>
   2060c:	sub	x0, x29, #0x8
   20610:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   20614:	mov	x26, x0
   20618:	b	2056c <__gmpz_tdiv_q@@Base+0xcc>
   2061c:	sub	x0, x29, #0x8
   20620:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   20624:	mov	x25, x0
   20628:	b	20538 <__gmpz_tdiv_q@@Base+0x98>
   2062c:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000020630 <__gmpz_tdiv_q_2exp@@Base>:
   20630:	stp	x29, x30, [sp, #-80]!
   20634:	stp	x24, x23, [sp, #32]
   20638:	stp	x22, x21, [sp, #48]
   2063c:	stp	x20, x19, [sp, #64]
   20640:	ldrsw	x24, [x1, #4]
   20644:	mov	x19, x0
   20648:	str	x25, [sp, #16]
   2064c:	mov	x29, sp
   20650:	cmp	x24, #0x0
   20654:	cneg	x8, x24, mi  // mi = first
   20658:	sub	x20, x8, x2, lsr #6
   2065c:	cmp	x20, #0x1
   20660:	b.lt	206b4 <__gmpz_tdiv_q_2exp@@Base+0x84>  // b.tstop
   20664:	ldrsw	x8, [x19]
   20668:	mov	x21, x2
   2066c:	mov	x22, x1
   20670:	lsr	x25, x2, #6
   20674:	cmp	x20, x8
   20678:	b.gt	206f0 <__gmpz_tdiv_q_2exp@@Base+0xc0>
   2067c:	ldr	x23, [x19, #8]
   20680:	ldr	x8, [x22, #8]
   20684:	ands	x3, x21, #0x3f
   20688:	add	x1, x8, x25, lsl #3
   2068c:	b.eq	206bc <__gmpz_tdiv_q_2exp@@Base+0x8c>  // b.none
   20690:	mov	x0, x23
   20694:	mov	x2, x20
   20698:	bl	c1b0 <__gmpn_rshift@plt>
   2069c:	add	x8, x23, x20, lsl #3
   206a0:	ldur	x8, [x8, #-8]
   206a4:	cmp	x8, #0x0
   206a8:	cset	w8, eq  // eq = none
   206ac:	sub	x20, x20, x8
   206b0:	b	206c8 <__gmpz_tdiv_q_2exp@@Base+0x98>
   206b4:	mov	x20, xzr
   206b8:	b	206c8 <__gmpz_tdiv_q_2exp@@Base+0x98>
   206bc:	mov	x0, x23
   206c0:	mov	x2, x20
   206c4:	bl	ca70 <__gmpn_copyi@plt>
   206c8:	neg	w8, w20
   206cc:	cmp	w24, #0x0
   206d0:	csel	x8, x20, x8, ge  // ge = tcont
   206d4:	str	w8, [x19, #4]
   206d8:	ldp	x20, x19, [sp, #64]
   206dc:	ldp	x22, x21, [sp, #48]
   206e0:	ldp	x24, x23, [sp, #32]
   206e4:	ldr	x25, [sp, #16]
   206e8:	ldp	x29, x30, [sp], #80
   206ec:	ret
   206f0:	mov	x0, x19
   206f4:	mov	x1, x20
   206f8:	bl	c090 <__gmpz_realloc@plt>
   206fc:	mov	x23, x0
   20700:	b	20680 <__gmpz_tdiv_q_2exp@@Base+0x50>

0000000000020704 <__gmpz_tdiv_q_ui@@Base>:
   20704:	stp	x29, x30, [sp, #-64]!
   20708:	stp	x24, x23, [sp, #16]
   2070c:	stp	x22, x21, [sp, #32]
   20710:	stp	x20, x19, [sp, #48]
   20714:	mov	x29, sp
   20718:	cbz	x2, 207b4 <__gmpz_tdiv_q_ui@@Base+0xb0>
   2071c:	ldrsw	x24, [x1, #4]
   20720:	mov	x22, x1
   20724:	mov	x19, x0
   20728:	cbz	w24, 20780 <__gmpz_tdiv_q_ui@@Base+0x7c>
   2072c:	ldrsw	x8, [x19]
   20730:	cmp	w24, #0x0
   20734:	cneg	x21, x24, lt  // lt = tstop
   20738:	mov	x20, x2
   2073c:	cmp	x21, x8
   20740:	b.gt	207a0 <__gmpz_tdiv_q_ui@@Base+0x9c>
   20744:	ldr	x23, [x19, #8]
   20748:	ldr	x2, [x22, #8]
   2074c:	mov	x0, x23
   20750:	mov	x1, xzr
   20754:	mov	x3, x21
   20758:	mov	x4, x20
   2075c:	bl	cd20 <__gmpn_divrem_1@plt>
   20760:	add	x8, x23, x21, lsl #3
   20764:	ldur	x8, [x8, #-8]
   20768:	cmp	x8, #0x0
   2076c:	cset	w8, eq  // eq = none
   20770:	sub	w8, w21, w8
   20774:	cmp	w24, #0x0
   20778:	cneg	w8, w8, lt  // lt = tstop
   2077c:	b	20788 <__gmpz_tdiv_q_ui@@Base+0x84>
   20780:	mov	w8, wzr
   20784:	mov	x0, xzr
   20788:	str	w8, [x19, #4]
   2078c:	ldp	x20, x19, [sp, #48]
   20790:	ldp	x22, x21, [sp, #32]
   20794:	ldp	x24, x23, [sp, #16]
   20798:	ldp	x29, x30, [sp], #64
   2079c:	ret
   207a0:	mov	x0, x19
   207a4:	mov	x1, x21
   207a8:	bl	c090 <__gmpz_realloc@plt>
   207ac:	mov	x23, x0
   207b0:	b	20748 <__gmpz_tdiv_q_ui@@Base+0x44>
   207b4:	bl	bfe0 <__gmp_divide_by_zero@plt>

00000000000207b8 <__gmpz_tdiv_qr@@Base>:
   207b8:	stp	x29, x30, [sp, #-96]!
   207bc:	stp	x28, x27, [sp, #16]
   207c0:	stp	x26, x25, [sp, #32]
   207c4:	stp	x24, x23, [sp, #48]
   207c8:	stp	x22, x21, [sp, #64]
   207cc:	stp	x20, x19, [sp, #80]
   207d0:	mov	x29, sp
   207d4:	sub	sp, sp, #0x20
   207d8:	ldrsw	x24, [x2, #4]
   207dc:	ldrsw	x28, [x3, #4]
   207e0:	cmp	x24, #0x0
   207e4:	cneg	x22, x24, mi  // mi = first
   207e8:	cmp	x28, #0x0
   207ec:	cneg	x21, x28, mi  // mi = first
   207f0:	cbz	x21, 209e4 <__gmpz_tdiv_qr@@Base+0x22c>
   207f4:	ldrsw	x8, [x1]
   207f8:	mov	x26, x3
   207fc:	mov	x27, x2
   20800:	mov	x19, x1
   20804:	mov	x25, x0
   20808:	cmp	x21, x8
   2080c:	sub	x20, x22, x21
   20810:	b.gt	20958 <__gmpz_tdiv_qr@@Base+0x1a0>
   20814:	ldr	x23, [x19, #8]
   20818:	tbnz	x20, #63, 2096c <__gmpz_tdiv_qr@@Base+0x1b4>
   2081c:	ldrsw	x8, [x25]
   20820:	cmp	x20, x8
   20824:	add	x8, x20, #0x1
   20828:	stp	x25, x8, [x29, #-24]
   2082c:	b.ge	209b0 <__gmpz_tdiv_qr@@Base+0x1f8>  // b.tcont
   20830:	ldr	x25, [x25, #8]
   20834:	stur	xzr, [x29, #-8]
   20838:	ldr	x26, [x26, #8]
   2083c:	ldr	x27, [x27, #8]
   20840:	stur	x28, [x29, #-32]
   20844:	cmp	x26, x23
   20848:	b.eq	20854 <__gmpz_tdiv_qr@@Base+0x9c>  // b.none
   2084c:	cmp	x26, x25
   20850:	b.ne	2088c <__gmpz_tdiv_qr@@Base+0xd4>  // b.any
   20854:	cmp	x21, #0xfe0
   20858:	lsl	x1, x21, #3
   2085c:	b.hi	209c4 <__gmpz_tdiv_qr@@Base+0x20c>  // b.pmore
   20860:	add	x9, x1, #0xf
   20864:	mov	x8, sp
   20868:	and	x9, x9, #0xfffffffffffffff0
   2086c:	sub	x28, x8, x9
   20870:	mov	sp, x28
   20874:	mov	x0, x28
   20878:	mov	x1, x26
   2087c:	mov	x2, x21
   20880:	bl	ca70 <__gmpn_copyi@plt>
   20884:	mov	x26, x28
   20888:	ldur	x28, [x29, #-32]
   2088c:	cmp	x27, x23
   20890:	b.eq	2089c <__gmpz_tdiv_qr@@Base+0xe4>  // b.none
   20894:	cmp	x27, x25
   20898:	b.ne	208d4 <__gmpz_tdiv_qr@@Base+0x11c>  // b.any
   2089c:	cmp	x22, #0xfe0
   208a0:	lsl	x1, x22, #3
   208a4:	b.hi	209d4 <__gmpz_tdiv_qr@@Base+0x21c>  // b.pmore
   208a8:	add	x9, x1, #0xf
   208ac:	mov	x8, sp
   208b0:	and	x9, x9, #0xfffffffffffffff0
   208b4:	sub	x28, x8, x9
   208b8:	mov	sp, x28
   208bc:	mov	x0, x28
   208c0:	mov	x1, x27
   208c4:	mov	x2, x22
   208c8:	bl	ca70 <__gmpn_copyi@plt>
   208cc:	mov	x27, x28
   208d0:	ldur	x28, [x29, #-32]
   208d4:	mov	x0, x25
   208d8:	mov	x1, x23
   208dc:	mov	x2, xzr
   208e0:	mov	x3, x27
   208e4:	mov	x4, x22
   208e8:	mov	x5, x26
   208ec:	mov	x6, x21
   208f0:	bl	bf10 <__gmpn_tdiv_qr@plt>
   208f4:	ldr	x8, [x25, x20, lsl #3]
   208f8:	ldur	x9, [x29, #-16]
   208fc:	sub	x10, x23, #0x8
   20900:	cmp	x8, #0x0
   20904:	cset	w8, eq  // eq = none
   20908:	sub	x8, x9, x8
   2090c:	mov	x9, x21
   20910:	subs	x21, x21, #0x1
   20914:	b.lt	20920 <__gmpz_tdiv_qr@@Base+0x168>  // b.tstop
   20918:	ldr	x11, [x10, x9, lsl #3]
   2091c:	cbz	x11, 2090c <__gmpz_tdiv_qr@@Base+0x154>
   20920:	eor	w10, w28, w24
   20924:	cmp	w10, #0x0
   20928:	ldur	x10, [x29, #-24]
   2092c:	neg	w11, w8
   20930:	neg	w12, w9
   20934:	csel	x8, x8, x11, ge  // ge = tcont
   20938:	cmp	w24, #0x0
   2093c:	str	w8, [x10, #4]
   20940:	csel	x8, x9, x12, ge  // ge = tcont
   20944:	str	w8, [x19, #4]
   20948:	ldur	x0, [x29, #-8]
   2094c:	cbz	x0, 20990 <__gmpz_tdiv_qr@@Base+0x1d8>
   20950:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   20954:	b	20990 <__gmpz_tdiv_qr@@Base+0x1d8>
   20958:	mov	x0, x19
   2095c:	mov	x1, x21
   20960:	bl	c090 <__gmpz_realloc@plt>
   20964:	mov	x23, x0
   20968:	tbz	x20, #63, 2081c <__gmpz_tdiv_qr@@Base+0x64>
   2096c:	cmp	x27, x19
   20970:	b.eq	2098c <__gmpz_tdiv_qr@@Base+0x1d4>  // b.none
   20974:	ldr	x1, [x27, #8]
   20978:	mov	x0, x23
   2097c:	mov	x2, x22
   20980:	bl	ca70 <__gmpn_copyi@plt>
   20984:	ldr	w8, [x27, #4]
   20988:	str	w8, [x19, #4]
   2098c:	str	wzr, [x25, #4]
   20990:	mov	sp, x29
   20994:	ldp	x20, x19, [sp, #80]
   20998:	ldp	x22, x21, [sp, #64]
   2099c:	ldp	x24, x23, [sp, #48]
   209a0:	ldp	x26, x25, [sp, #32]
   209a4:	ldp	x28, x27, [sp, #16]
   209a8:	ldp	x29, x30, [sp], #96
   209ac:	ret
   209b0:	ldur	x1, [x29, #-16]
   209b4:	mov	x0, x25
   209b8:	bl	c090 <__gmpz_realloc@plt>
   209bc:	mov	x25, x0
   209c0:	b	20834 <__gmpz_tdiv_qr@@Base+0x7c>
   209c4:	sub	x0, x29, #0x8
   209c8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   209cc:	mov	x28, x0
   209d0:	b	20874 <__gmpz_tdiv_qr@@Base+0xbc>
   209d4:	sub	x0, x29, #0x8
   209d8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   209dc:	mov	x28, x0
   209e0:	b	208bc <__gmpz_tdiv_qr@@Base+0x104>
   209e4:	bl	bfe0 <__gmp_divide_by_zero@plt>

00000000000209e8 <__gmpz_tdiv_qr_ui@@Base>:
   209e8:	stp	x29, x30, [sp, #-80]!
   209ec:	str	x25, [sp, #16]
   209f0:	stp	x24, x23, [sp, #32]
   209f4:	stp	x22, x21, [sp, #48]
   209f8:	stp	x20, x19, [sp, #64]
   209fc:	mov	x29, sp
   20a00:	cbz	x3, 20af4 <__gmpz_tdiv_qr_ui@@Base+0x10c>
   20a04:	ldrsw	x25, [x2, #4]
   20a08:	mov	x24, x2
   20a0c:	mov	x20, x1
   20a10:	mov	x19, x0
   20a14:	cbz	w25, 20a7c <__gmpz_tdiv_qr_ui@@Base+0x94>
   20a18:	ldrsw	x8, [x19]
   20a1c:	cmp	w25, #0x0
   20a20:	cneg	x21, x25, lt  // lt = tstop
   20a24:	mov	x22, x3
   20a28:	cmp	x21, x8
   20a2c:	b.gt	20ad0 <__gmpz_tdiv_qr_ui@@Base+0xe8>
   20a30:	ldr	x23, [x19, #8]
   20a34:	ldr	x2, [x24, #8]
   20a38:	mov	x0, x23
   20a3c:	mov	x1, xzr
   20a40:	mov	x3, x21
   20a44:	mov	x4, x22
   20a48:	bl	cd20 <__gmpn_divrem_1@plt>
   20a4c:	mov	x22, x0
   20a50:	cbz	x0, 20a90 <__gmpz_tdiv_qr_ui@@Base+0xa8>
   20a54:	ldr	w8, [x20]
   20a58:	cmp	w25, #0x0
   20a5c:	mov	w9, #0x1                   	// #1
   20a60:	cneg	w9, w9, lt  // lt = tstop
   20a64:	cmp	w8, #0x0
   20a68:	str	w9, [x20, #4]
   20a6c:	b.le	20ae4 <__gmpz_tdiv_qr_ui@@Base+0xfc>
   20a70:	ldr	x0, [x20, #8]
   20a74:	str	x22, [x0]
   20a78:	b	20a94 <__gmpz_tdiv_qr_ui@@Base+0xac>
   20a7c:	mov	w8, wzr
   20a80:	mov	x22, xzr
   20a84:	str	wzr, [x19, #4]
   20a88:	mov	x19, x20
   20a8c:	b	20ab0 <__gmpz_tdiv_qr_ui@@Base+0xc8>
   20a90:	str	wzr, [x20, #4]
   20a94:	add	x8, x23, x21, lsl #3
   20a98:	ldur	x8, [x8, #-8]
   20a9c:	cmp	x8, #0x0
   20aa0:	cset	w8, eq  // eq = none
   20aa4:	sub	w8, w21, w8
   20aa8:	cmp	w25, #0x0
   20aac:	cneg	w8, w8, lt  // lt = tstop
   20ab0:	str	w8, [x19, #4]
   20ab4:	mov	x0, x22
   20ab8:	ldp	x20, x19, [sp, #64]
   20abc:	ldp	x22, x21, [sp, #48]
   20ac0:	ldp	x24, x23, [sp, #32]
   20ac4:	ldr	x25, [sp, #16]
   20ac8:	ldp	x29, x30, [sp], #80
   20acc:	ret
   20ad0:	mov	x0, x19
   20ad4:	mov	x1, x21
   20ad8:	bl	c090 <__gmpz_realloc@plt>
   20adc:	mov	x23, x0
   20ae0:	b	20a34 <__gmpz_tdiv_qr_ui@@Base+0x4c>
   20ae4:	mov	w1, #0x1                   	// #1
   20ae8:	mov	x0, x20
   20aec:	bl	c090 <__gmpz_realloc@plt>
   20af0:	b	20a74 <__gmpz_tdiv_qr_ui@@Base+0x8c>
   20af4:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000020af8 <__gmpz_tdiv_r@@Base>:
   20af8:	stp	x29, x30, [sp, #-80]!
   20afc:	stp	x26, x25, [sp, #16]
   20b00:	stp	x24, x23, [sp, #32]
   20b04:	stp	x22, x21, [sp, #48]
   20b08:	stp	x20, x19, [sp, #64]
   20b0c:	mov	x29, sp
   20b10:	sub	sp, sp, #0x10
   20b14:	ldrsw	x26, [x1, #4]
   20b18:	ldr	w8, [x2, #4]
   20b1c:	cmp	x26, #0x0
   20b20:	cneg	x20, x26, mi  // mi = first
   20b24:	cmp	w8, #0x0
   20b28:	cneg	w21, w8, mi  // mi = first
   20b2c:	cbz	w21, 20cf4 <__gmpz_tdiv_r@@Base+0x1fc>
   20b30:	mov	x24, x1
   20b34:	mov	x19, x0
   20b38:	sub	x23, x20, x21
   20b3c:	tbnz	x23, #63, 20c34 <__gmpz_tdiv_r@@Base+0x13c>
   20b40:	ldrsw	x8, [x19]
   20b44:	mov	x25, x2
   20b48:	cmp	x21, x8
   20b4c:	b.gt	20c98 <__gmpz_tdiv_r@@Base+0x1a0>
   20b50:	ldr	x22, [x19, #8]
   20b54:	lsl	x8, x23, #3
   20b58:	cmp	x23, #0xfdf
   20b5c:	add	x1, x8, #0x8
   20b60:	stur	xzr, [x29, #-8]
   20b64:	b.hi	20cac <__gmpz_tdiv_r@@Base+0x1b4>  // b.pmore
   20b68:	add	x9, x1, #0xf
   20b6c:	mov	x8, sp
   20b70:	and	x9, x9, #0xfffffffffffffff0
   20b74:	sub	x23, x8, x9
   20b78:	mov	sp, x23
   20b7c:	ldr	x25, [x25, #8]
   20b80:	ldr	x24, [x24, #8]
   20b84:	cmp	x25, x22
   20b88:	b.ne	20bbc <__gmpz_tdiv_r@@Base+0xc4>  // b.any
   20b8c:	cmp	w21, #0xfe0
   20b90:	lsl	x1, x21, #3
   20b94:	b.hi	20cc4 <__gmpz_tdiv_r@@Base+0x1cc>  // b.pmore
   20b98:	add	x9, x1, #0xf
   20b9c:	mov	x8, sp
   20ba0:	and	x9, x9, #0xffffffff0
   20ba4:	sub	x25, x8, x9
   20ba8:	mov	sp, x25
   20bac:	mov	x0, x25
   20bb0:	mov	x1, x22
   20bb4:	mov	x2, x21
   20bb8:	bl	ca70 <__gmpn_copyi@plt>
   20bbc:	cmp	x24, x22
   20bc0:	b.ne	20bf4 <__gmpz_tdiv_r@@Base+0xfc>  // b.any
   20bc4:	cmp	x20, #0xfe0
   20bc8:	lsl	x1, x20, #3
   20bcc:	b.hi	20cd4 <__gmpz_tdiv_r@@Base+0x1dc>  // b.pmore
   20bd0:	add	x9, x1, #0xf
   20bd4:	mov	x8, sp
   20bd8:	and	x9, x9, #0xfffffffffffffff0
   20bdc:	sub	x24, x8, x9
   20be0:	mov	sp, x24
   20be4:	mov	x0, x24
   20be8:	mov	x1, x22
   20bec:	mov	x2, x20
   20bf0:	bl	ca70 <__gmpn_copyi@plt>
   20bf4:	mov	x0, x23
   20bf8:	mov	x1, x22
   20bfc:	mov	x2, xzr
   20c00:	mov	x3, x24
   20c04:	mov	x4, x20
   20c08:	mov	x5, x25
   20c0c:	mov	x6, x21
   20c10:	bl	bf10 <__gmpn_tdiv_qr@plt>
   20c14:	sub	x8, x22, #0x8
   20c18:	subs	x9, x21, #0x1
   20c1c:	b.lt	20c60 <__gmpz_tdiv_r@@Base+0x168>  // b.tstop
   20c20:	ldr	x10, [x8, x21, lsl #3]
   20c24:	mov	x21, x9
   20c28:	cbz	x10, 20c18 <__gmpz_tdiv_r@@Base+0x120>
   20c2c:	add	x8, x9, #0x1
   20c30:	b	20c64 <__gmpz_tdiv_r@@Base+0x16c>
   20c34:	cmp	x24, x19
   20c38:	b.eq	20c7c <__gmpz_tdiv_r@@Base+0x184>  // b.none
   20c3c:	ldrsw	x8, [x19]
   20c40:	str	w26, [x19, #4]
   20c44:	cmp	x20, x8
   20c48:	b.gt	20ce4 <__gmpz_tdiv_r@@Base+0x1ec>
   20c4c:	ldr	x0, [x19, #8]
   20c50:	ldr	x1, [x24, #8]
   20c54:	mov	x2, x20
   20c58:	bl	ca70 <__gmpn_copyi@plt>
   20c5c:	b	20c7c <__gmpz_tdiv_r@@Base+0x184>
   20c60:	mov	x8, xzr
   20c64:	neg	w9, w8
   20c68:	cmp	w26, #0x0
   20c6c:	csel	x8, x8, x9, ge  // ge = tcont
   20c70:	str	w8, [x19, #4]
   20c74:	ldur	x0, [x29, #-8]
   20c78:	cbnz	x0, 20cbc <__gmpz_tdiv_r@@Base+0x1c4>
   20c7c:	mov	sp, x29
   20c80:	ldp	x20, x19, [sp, #64]
   20c84:	ldp	x22, x21, [sp, #48]
   20c88:	ldp	x24, x23, [sp, #32]
   20c8c:	ldp	x26, x25, [sp, #16]
   20c90:	ldp	x29, x30, [sp], #80
   20c94:	ret
   20c98:	mov	x0, x19
   20c9c:	mov	x1, x21
   20ca0:	bl	c090 <__gmpz_realloc@plt>
   20ca4:	mov	x22, x0
   20ca8:	b	20b54 <__gmpz_tdiv_r@@Base+0x5c>
   20cac:	sub	x0, x29, #0x8
   20cb0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   20cb4:	mov	x23, x0
   20cb8:	b	20b7c <__gmpz_tdiv_r@@Base+0x84>
   20cbc:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   20cc0:	b	20c7c <__gmpz_tdiv_r@@Base+0x184>
   20cc4:	sub	x0, x29, #0x8
   20cc8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   20ccc:	mov	x25, x0
   20cd0:	b	20bac <__gmpz_tdiv_r@@Base+0xb4>
   20cd4:	sub	x0, x29, #0x8
   20cd8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   20cdc:	mov	x24, x0
   20ce0:	b	20be4 <__gmpz_tdiv_r@@Base+0xec>
   20ce4:	mov	x0, x19
   20ce8:	mov	x1, x20
   20cec:	bl	c090 <__gmpz_realloc@plt>
   20cf0:	b	20c50 <__gmpz_tdiv_r@@Base+0x158>
   20cf4:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000020cf8 <__gmpz_tdiv_r_2exp@@Base>:
   20cf8:	stp	x29, x30, [sp, #-64]!
   20cfc:	stp	x22, x21, [sp, #32]
   20d00:	stp	x20, x19, [sp, #48]
   20d04:	ldr	w8, [x1, #4]
   20d08:	lsr	x21, x2, #6
   20d0c:	mov	x20, x1
   20d10:	mov	x19, x0
   20d14:	cmp	w8, #0x0
   20d18:	cneg	w22, w8, mi  // mi = first
   20d1c:	cmp	x21, x22
   20d20:	str	x23, [sp, #16]
   20d24:	mov	x29, sp
   20d28:	b.cs	20d60 <__gmpz_tdiv_r_2exp@@Base+0x68>  // b.hs, b.nlast
   20d2c:	ldr	x8, [x20, #8]
   20d30:	mov	x10, #0xffffffffffffffff    	// #-1
   20d34:	lsl	x10, x10, x2
   20d38:	ldr	x9, [x8, x21, lsl #3]
   20d3c:	bics	x23, x9, x10
   20d40:	b.eq	20d74 <__gmpz_tdiv_r_2exp@@Base+0x7c>  // b.none
   20d44:	ldrsw	x8, [x19]
   20d48:	add	x22, x21, #0x1
   20d4c:	cmp	x21, x8
   20d50:	b.ge	20df8 <__gmpz_tdiv_r_2exp@@Base+0x100>  // b.tcont
   20d54:	ldr	x8, [x19, #8]
   20d58:	str	x23, [x8, x21, lsl #3]
   20d5c:	b	20da8 <__gmpz_tdiv_r_2exp@@Base+0xb0>
   20d60:	ldrsw	x8, [x19]
   20d64:	cmp	x22, x8
   20d68:	b.gt	20de8 <__gmpz_tdiv_r_2exp@@Base+0xf0>
   20d6c:	mov	x21, x22
   20d70:	b	20da8 <__gmpz_tdiv_r_2exp@@Base+0xb0>
   20d74:	sub	x8, x8, #0x8
   20d78:	subs	x9, x21, #0x1
   20d7c:	b.lt	20d94 <__gmpz_tdiv_r_2exp@@Base+0x9c>  // b.tstop
   20d80:	ldr	x10, [x8, x21, lsl #3]
   20d84:	mov	x21, x9
   20d88:	cbz	x10, 20d78 <__gmpz_tdiv_r_2exp@@Base+0x80>
   20d8c:	add	x21, x9, #0x1
   20d90:	b	20d98 <__gmpz_tdiv_r_2exp@@Base+0xa0>
   20d94:	mov	x21, xzr
   20d98:	ldrsw	x8, [x19]
   20d9c:	cmp	x21, x8
   20da0:	b.gt	20e08 <__gmpz_tdiv_r_2exp@@Base+0x110>
   20da4:	mov	x22, x21
   20da8:	cmp	x19, x20
   20dac:	b.eq	20dc0 <__gmpz_tdiv_r_2exp@@Base+0xc8>  // b.none
   20db0:	ldr	x0, [x19, #8]
   20db4:	ldr	x1, [x20, #8]
   20db8:	mov	x2, x21
   20dbc:	bl	ca70 <__gmpn_copyi@plt>
   20dc0:	ldr	w8, [x20, #4]
   20dc4:	neg	w9, w22
   20dc8:	ldr	x23, [sp, #16]
   20dcc:	cmp	w8, #0x0
   20dd0:	csel	x8, x22, x9, ge  // ge = tcont
   20dd4:	str	w8, [x19, #4]
   20dd8:	ldp	x20, x19, [sp, #48]
   20ddc:	ldp	x22, x21, [sp, #32]
   20de0:	ldp	x29, x30, [sp], #64
   20de4:	ret
   20de8:	mov	x0, x19
   20dec:	mov	x1, x22
   20df0:	bl	c090 <__gmpz_realloc@plt>
   20df4:	b	20d6c <__gmpz_tdiv_r_2exp@@Base+0x74>
   20df8:	mov	x0, x19
   20dfc:	mov	x1, x22
   20e00:	bl	c090 <__gmpz_realloc@plt>
   20e04:	b	20d54 <__gmpz_tdiv_r_2exp@@Base+0x5c>
   20e08:	mov	x0, x19
   20e0c:	mov	x1, x21
   20e10:	bl	c090 <__gmpz_realloc@plt>
   20e14:	b	20da4 <__gmpz_tdiv_r_2exp@@Base+0xac>

0000000000020e18 <__gmpz_tdiv_r_ui@@Base>:
   20e18:	stp	x29, x30, [sp, #-48]!
   20e1c:	str	x21, [sp, #16]
   20e20:	stp	x20, x19, [sp, #32]
   20e24:	mov	x29, sp
   20e28:	cbz	x2, 20ea4 <__gmpz_tdiv_r_ui@@Base+0x8c>
   20e2c:	ldrsw	x21, [x1, #4]
   20e30:	mov	x20, x0
   20e34:	cbz	w21, 20e78 <__gmpz_tdiv_r_ui@@Base+0x60>
   20e38:	ldr	x0, [x1, #8]
   20e3c:	cmp	w21, #0x0
   20e40:	cneg	x1, x21, lt  // lt = tstop
   20e44:	bl	c400 <__gmpn_mod_1@plt>
   20e48:	mov	x19, x0
   20e4c:	cbz	x0, 20e7c <__gmpz_tdiv_r_ui@@Base+0x64>
   20e50:	ldr	w8, [x20]
   20e54:	cmp	w21, #0x0
   20e58:	mov	w9, #0x1                   	// #1
   20e5c:	cneg	w9, w9, lt  // lt = tstop
   20e60:	cmp	w8, #0x0
   20e64:	str	w9, [x20, #4]
   20e68:	b.le	20e94 <__gmpz_tdiv_r_ui@@Base+0x7c>
   20e6c:	ldr	x0, [x20, #8]
   20e70:	str	x19, [x0]
   20e74:	b	20e80 <__gmpz_tdiv_r_ui@@Base+0x68>
   20e78:	mov	x19, xzr
   20e7c:	str	wzr, [x20, #4]
   20e80:	mov	x0, x19
   20e84:	ldp	x20, x19, [sp, #32]
   20e88:	ldr	x21, [sp, #16]
   20e8c:	ldp	x29, x30, [sp], #48
   20e90:	ret
   20e94:	mov	w1, #0x1                   	// #1
   20e98:	mov	x0, x20
   20e9c:	bl	c090 <__gmpz_realloc@plt>
   20ea0:	b	20e70 <__gmpz_tdiv_r_ui@@Base+0x58>
   20ea4:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000020ea8 <__gmpz_tstbit@@Base>:
   20ea8:	ldr	w11, [x0, #4]
   20eac:	lsr	x10, x1, #6
   20eb0:	cmp	w11, #0x0
   20eb4:	cneg	w8, w11, mi  // mi = first
   20eb8:	cmp	x10, x8
   20ebc:	b.cs	20efc <__gmpz_tstbit@@Base+0x54>  // b.hs, b.nlast
   20ec0:	ldr	x12, [x0, #8]
   20ec4:	ldr	x9, [x12, x10, lsl #3]
   20ec8:	mov	x8, x9
   20ecc:	tbz	w11, #31, 20ef0 <__gmpz_tstbit@@Base+0x48>
   20ed0:	neg	x8, x9
   20ed4:	sub	x11, x12, #0x8
   20ed8:	lsl	x10, x10, #3
   20edc:	cbz	x10, 20ef0 <__gmpz_tstbit@@Base+0x48>
   20ee0:	ldr	x12, [x11, x10]
   20ee4:	sub	x10, x10, #0x8
   20ee8:	cbz	x12, 20edc <__gmpz_tstbit@@Base+0x34>
   20eec:	mvn	x8, x9
   20ef0:	lsr	x8, x8, x1
   20ef4:	and	w0, w8, #0x1
   20ef8:	ret
   20efc:	lsr	w0, w11, #31
   20f00:	ret

0000000000020f04 <__gmpz_ui_pow_ui@@Base>:
   20f04:	sub	sp, sp, #0x20
   20f08:	cmp	x1, #0x0
   20f0c:	mov	x3, x2
   20f10:	str	x1, [sp, #8]
   20f14:	cset	w2, ne  // ne = any
   20f18:	add	x1, sp, #0x8
   20f1c:	stp	x29, x30, [sp, #16]
   20f20:	add	x29, sp, #0x10
   20f24:	bl	c360 <__gmpz_n_pow_ui@plt>
   20f28:	ldp	x29, x30, [sp, #16]
   20f2c:	add	sp, sp, #0x20
   20f30:	ret

0000000000020f34 <__gmpz_ui_sub@@Base>:
   20f34:	sub	sp, sp, #0x40
   20f38:	stp	x29, x30, [sp, #16]
   20f3c:	stp	x22, x21, [sp, #32]
   20f40:	stp	x20, x19, [sp, #48]
   20f44:	ldrsw	x20, [x2, #4]
   20f48:	mov	x22, x2
   20f4c:	mov	x21, x1
   20f50:	mov	x19, x0
   20f54:	cmp	w20, #0x2
   20f58:	add	x29, sp, #0x10
   20f5c:	b.lt	20fe0 <__gmpz_ui_sub@@Base+0xac>  // b.tstop
   20f60:	ldr	w8, [x19]
   20f64:	cmp	w20, w8
   20f68:	b.gt	2114c <__gmpz_ui_sub@@Base+0x218>
   20f6c:	ldr	x0, [x19, #8]
   20f70:	ldr	x9, [x22, #8]
   20f74:	ldr	x8, [x9]
   20f78:	subs	x8, x8, x21
   20f7c:	str	x8, [x0]
   20f80:	b.cs	21018 <__gmpz_ui_sub@@Base+0xe4>  // b.hs, b.nlast
   20f84:	mov	x10, #0xfffffffffffffff8    	// #-8
   20f88:	mov	w8, #0x1                   	// #1
   20f8c:	cmp	x8, x20
   20f90:	b.ge	2103c <__gmpz_ui_sub@@Base+0x108>  // b.tcont
   20f94:	ldr	x11, [x9, x8, lsl #3]
   20f98:	sub	x10, x10, #0x8
   20f9c:	sub	x12, x11, #0x1
   20fa0:	str	x12, [x0, x8, lsl #3]
   20fa4:	add	x8, x8, #0x1
   20fa8:	cbz	x11, 20f8c <__gmpz_ui_sub@@Base+0x58>
   20fac:	cmp	x9, x0
   20fb0:	b.eq	2103c <__gmpz_ui_sub@@Base+0x108>  // b.none
   20fb4:	cmp	x8, x20
   20fb8:	b.ge	2103c <__gmpz_ui_sub@@Base+0x108>  // b.tcont
   20fbc:	sub	x9, x9, x10
   20fc0:	sub	x10, x0, x10
   20fc4:	mov	x11, x20
   20fc8:	ldr	x12, [x9], #8
   20fcc:	sub	x11, x11, #0x1
   20fd0:	cmp	x8, x11
   20fd4:	str	x12, [x10], #8
   20fd8:	b.ne	20fc8 <__gmpz_ui_sub@@Base+0x94>  // b.any
   20fdc:	b	2103c <__gmpz_ui_sub@@Base+0x108>
   20fe0:	tbnz	w20, #31, 21054 <__gmpz_ui_sub@@Base+0x120>
   20fe4:	ldr	x8, [x22, #8]
   20fe8:	ldr	w9, [x19]
   20fec:	neg	x10, x20
   20ff0:	ldr	x8, [x8]
   20ff4:	cmp	w9, #0x0
   20ff8:	and	x20, x8, x10
   20ffc:	b.le	2115c <__gmpz_ui_sub@@Base+0x228>
   21000:	ldr	x0, [x19, #8]
   21004:	subs	x8, x20, x21
   21008:	b.ls	210e8 <__gmpz_ui_sub@@Base+0x1b4>  // b.plast
   2100c:	str	x8, [x0]
   21010:	mov	w8, #0xffffffff            	// #-1
   21014:	b	21134 <__gmpz_ui_sub@@Base+0x200>
   21018:	cmp	x9, x0
   2101c:	b.eq	2103c <__gmpz_ui_sub@@Base+0x108>  // b.none
   21020:	sub	x8, x20, #0x1
   21024:	add	x10, x0, #0x8
   21028:	add	x9, x9, #0x8
   2102c:	ldr	x11, [x9], #8
   21030:	subs	x8, x8, #0x1
   21034:	str	x11, [x10], #8
   21038:	b.ne	2102c <__gmpz_ui_sub@@Base+0xf8>  // b.any
   2103c:	add	x8, x0, x20, lsl #3
   21040:	ldur	x8, [x8, #-8]
   21044:	cmp	x8, #0x0
   21048:	cset	w8, eq  // eq = none
   2104c:	sub	w8, w8, w20
   21050:	b	21134 <__gmpz_ui_sub@@Base+0x200>
   21054:	ldrsw	x8, [x19]
   21058:	mov	w9, #0x1                   	// #1
   2105c:	sub	x1, x9, x20
   21060:	cmp	x1, x8
   21064:	neg	x8, x20
   21068:	b.gt	2116c <__gmpz_ui_sub@@Base+0x238>
   2106c:	ldr	x0, [x19, #8]
   21070:	ldr	x9, [x22, #8]
   21074:	ldr	x10, [x9]
   21078:	adds	x10, x10, x21
   2107c:	str	x10, [x0]
   21080:	b.cc	210f8 <__gmpz_ui_sub@@Base+0x1c4>  // b.lo, b.ul, b.last
   21084:	mov	x12, #0xfffffffffffffff8    	// #-8
   21088:	mov	w11, #0x1                   	// #1
   2108c:	mov	w10, #0x1                   	// #1
   21090:	cmp	x10, x8
   21094:	b.ge	2112c <__gmpz_ui_sub@@Base+0x1f8>  // b.tcont
   21098:	ldr	x13, [x9, x10, lsl #3]
   2109c:	sub	x12, x12, #0x8
   210a0:	adds	x13, x13, #0x1
   210a4:	str	x13, [x0, x10, lsl #3]
   210a8:	add	x10, x10, #0x1
   210ac:	b.cs	21090 <__gmpz_ui_sub@@Base+0x15c>  // b.hs, b.nlast
   210b0:	cmp	x9, x0
   210b4:	mov	x11, xzr
   210b8:	b.eq	2112c <__gmpz_ui_sub@@Base+0x1f8>  // b.none
   210bc:	cmp	x10, x8
   210c0:	b.ge	2112c <__gmpz_ui_sub@@Base+0x1f8>  // b.tcont
   210c4:	sub	x9, x9, x12
   210c8:	sub	x11, x0, x12
   210cc:	mov	x12, x8
   210d0:	ldr	x13, [x9], #8
   210d4:	sub	x12, x12, #0x1
   210d8:	cmp	x10, x12
   210dc:	str	x13, [x11], #8
   210e0:	b.ne	210d0 <__gmpz_ui_sub@@Base+0x19c>  // b.any
   210e4:	b	21128 <__gmpz_ui_sub@@Base+0x1f4>
   210e8:	subs	x8, x21, x20
   210ec:	str	x8, [x0]
   210f0:	cset	w8, ne  // ne = any
   210f4:	b	21134 <__gmpz_ui_sub@@Base+0x200>
   210f8:	cmn	w20, #0x2
   210fc:	mov	x11, xzr
   21100:	b.gt	2112c <__gmpz_ui_sub@@Base+0x1f8>
   21104:	cmp	x9, x0
   21108:	b.eq	2112c <__gmpz_ui_sub@@Base+0x1f8>  // b.none
   2110c:	add	x10, x20, #0x1
   21110:	add	x11, x0, #0x8
   21114:	add	x9, x9, #0x8
   21118:	ldr	x12, [x9], #8
   2111c:	adds	x10, x10, #0x1
   21120:	str	x12, [x11], #8
   21124:	b.cc	21118 <__gmpz_ui_sub@@Base+0x1e4>  // b.lo, b.ul, b.last
   21128:	mov	x11, xzr
   2112c:	str	x11, [x0, x8, lsl #3]
   21130:	sub	w8, w11, w20
   21134:	str	w8, [x19, #4]
   21138:	ldp	x20, x19, [sp, #48]
   2113c:	ldp	x22, x21, [sp, #32]
   21140:	ldp	x29, x30, [sp, #16]
   21144:	add	sp, sp, #0x40
   21148:	ret
   2114c:	mov	x0, x19
   21150:	mov	x1, x20
   21154:	bl	c090 <__gmpz_realloc@plt>
   21158:	b	20f70 <__gmpz_ui_sub@@Base+0x3c>
   2115c:	mov	w1, #0x1                   	// #1
   21160:	mov	x0, x19
   21164:	bl	c090 <__gmpz_realloc@plt>
   21168:	b	21004 <__gmpz_ui_sub@@Base+0xd0>
   2116c:	mov	x0, x19
   21170:	str	x8, [sp, #8]
   21174:	bl	c090 <__gmpz_realloc@plt>
   21178:	ldr	x8, [sp, #8]
   2117c:	b	21070 <__gmpz_ui_sub@@Base+0x13c>

0000000000021180 <__gmpz_urandomb@@Base>:
   21180:	stp	x29, x30, [sp, #-64]!
   21184:	stp	x22, x21, [sp, #32]
   21188:	stp	x20, x19, [sp, #48]
   2118c:	ldrsw	x8, [x0]
   21190:	add	x9, x2, #0x3f
   21194:	lsr	x20, x9, #6
   21198:	mov	x19, x0
   2119c:	mov	x21, x2
   211a0:	cmp	x20, x8
   211a4:	mov	x22, x1
   211a8:	str	x23, [sp, #16]
   211ac:	mov	x29, sp
   211b0:	b.gt	2120c <__gmpz_urandomb@@Base+0x8c>
   211b4:	ldr	x23, [x19, #8]
   211b8:	ldr	x8, [x22, #24]
   211bc:	mov	x0, x22
   211c0:	mov	x1, x23
   211c4:	mov	x2, x21
   211c8:	ldr	x8, [x8, #8]
   211cc:	blr	x8
   211d0:	sub	x8, x23, #0x8
   211d4:	subs	x9, x20, #0x1
   211d8:	b.lt	211f0 <__gmpz_urandomb@@Base+0x70>  // b.tstop
   211dc:	ldr	x10, [x8, x20, lsl #3]
   211e0:	mov	x20, x9
   211e4:	cbz	x10, 211d4 <__gmpz_urandomb@@Base+0x54>
   211e8:	add	x8, x9, #0x1
   211ec:	b	211f4 <__gmpz_urandomb@@Base+0x74>
   211f0:	mov	x8, xzr
   211f4:	str	w8, [x19, #4]
   211f8:	ldp	x20, x19, [sp, #48]
   211fc:	ldp	x22, x21, [sp, #32]
   21200:	ldr	x23, [sp, #16]
   21204:	ldp	x29, x30, [sp], #64
   21208:	ret
   2120c:	mov	x0, x19
   21210:	mov	x1, x20
   21214:	bl	c090 <__gmpz_realloc@plt>
   21218:	mov	x23, x0
   2121c:	b	211b8 <__gmpz_urandomb@@Base+0x38>

0000000000021220 <__gmpz_urandomm@@Base>:
   21220:	stp	x29, x30, [sp, #-80]!
   21224:	stp	x26, x25, [sp, #16]
   21228:	stp	x24, x23, [sp, #32]
   2122c:	stp	x22, x21, [sp, #48]
   21230:	stp	x20, x19, [sp, #64]
   21234:	mov	x29, sp
   21238:	sub	sp, sp, #0x10
   2123c:	ldr	w8, [x2, #4]
   21240:	cmp	w8, #0x0
   21244:	cneg	w20, w8, mi  // mi = first
   21248:	cbz	w20, 213ec <__gmpz_urandomm@@Base+0x1cc>
   2124c:	ldr	x22, [x2, #8]
   21250:	sub	x25, x20, #0x1
   21254:	mov	x21, x1
   21258:	mov	x19, x0
   2125c:	ldr	x8, [x22, x25, lsl #3]
   21260:	sub	x9, x8, #0x1
   21264:	tst	x8, x9
   21268:	b.ne	21298 <__gmpz_urandomm@@Base+0x78>  // b.any
   2126c:	cmp	w20, #0x1
   21270:	b.eq	21290 <__gmpz_urandomm@@Base+0x70>  // b.none
   21274:	sub	x9, x22, #0x10
   21278:	mov	x10, x20
   2127c:	ldr	x11, [x9, x10, lsl #3]
   21280:	cbnz	x11, 21298 <__gmpz_urandomm@@Base+0x78>
   21284:	sub	x10, x10, #0x1
   21288:	cmp	x10, #0x1
   2128c:	b.ne	2127c <__gmpz_urandomm@@Base+0x5c>  // b.any
   21290:	mov	x9, #0xffffffffffffffff    	// #-1
   21294:	b	2129c <__gmpz_urandomm@@Base+0x7c>
   21298:	mov	x9, xzr
   2129c:	clz	x8, x8
   212a0:	lsl	x10, x20, #6
   212a4:	sub	x8, x10, x8
   212a8:	adds	x23, x9, x8
   212ac:	b.eq	21368 <__gmpz_urandomm@@Base+0x148>  // b.none
   212b0:	cmp	x19, x2
   212b4:	stur	xzr, [x29, #-8]
   212b8:	b.ne	212f0 <__gmpz_urandomm@@Base+0xd0>  // b.any
   212bc:	cmp	w20, #0xfe0
   212c0:	lsl	x1, x20, #3
   212c4:	b.hi	213dc <__gmpz_urandomm@@Base+0x1bc>  // b.pmore
   212c8:	add	x9, x1, #0xf
   212cc:	mov	x8, sp
   212d0:	and	x9, x9, #0xffffffff0
   212d4:	sub	x24, x8, x9
   212d8:	mov	sp, x24
   212dc:	mov	x0, x24
   212e0:	mov	x1, x22
   212e4:	mov	x2, x20
   212e8:	bl	ca70 <__gmpn_copyi@plt>
   212ec:	mov	x22, x24
   212f0:	ldrsw	x8, [x19]
   212f4:	cmp	x20, x8
   212f8:	b.gt	213c0 <__gmpz_urandomm@@Base+0x1a0>
   212fc:	ldr	x24, [x19, #8]
   21300:	mov	w26, #0x50                  	// #80
   21304:	str	xzr, [x24, x25, lsl #3]
   21308:	ldr	x8, [x21, #24]
   2130c:	mov	x0, x21
   21310:	mov	x1, x24
   21314:	mov	x2, x23
   21318:	ldr	x8, [x8, #8]
   2131c:	blr	x8
   21320:	mov	x8, x25
   21324:	add	x9, x8, #0x1
   21328:	cmp	x9, #0x1
   2132c:	b.lt	21348 <__gmpz_urandomm@@Base+0x128>  // b.tstop
   21330:	ldr	x9, [x24, x8, lsl #3]
   21334:	ldr	x10, [x22, x8, lsl #3]
   21338:	sub	x8, x8, #0x1
   2133c:	cmp	x9, x10
   21340:	b.eq	21324 <__gmpz_urandomm@@Base+0x104>  // b.none
   21344:	b.ls	21370 <__gmpz_urandomm@@Base+0x150>  // b.plast
   21348:	subs	w26, w26, #0x1
   2134c:	b.ne	21308 <__gmpz_urandomm@@Base+0xe8>  // b.any
   21350:	mov	x0, x24
   21354:	mov	x1, x24
   21358:	mov	x2, x22
   2135c:	mov	x3, x20
   21360:	bl	c2e0 <__gmpn_sub_n@plt>
   21364:	b	21374 <__gmpz_urandomm@@Base+0x154>
   21368:	str	wzr, [x19, #4]
   2136c:	b	213a4 <__gmpz_urandomm@@Base+0x184>
   21370:	cbz	w26, 21350 <__gmpz_urandomm@@Base+0x130>
   21374:	sub	x8, x24, #0x8
   21378:	subs	x9, x20, #0x1
   2137c:	b.lt	21394 <__gmpz_urandomm@@Base+0x174>  // b.tstop
   21380:	ldr	x10, [x8, x20, lsl #3]
   21384:	mov	x20, x9
   21388:	cbz	x10, 21378 <__gmpz_urandomm@@Base+0x158>
   2138c:	add	x8, x9, #0x1
   21390:	b	21398 <__gmpz_urandomm@@Base+0x178>
   21394:	mov	x8, xzr
   21398:	str	w8, [x19, #4]
   2139c:	ldur	x0, [x29, #-8]
   213a0:	cbnz	x0, 213d4 <__gmpz_urandomm@@Base+0x1b4>
   213a4:	mov	sp, x29
   213a8:	ldp	x20, x19, [sp, #64]
   213ac:	ldp	x22, x21, [sp, #48]
   213b0:	ldp	x24, x23, [sp, #32]
   213b4:	ldp	x26, x25, [sp, #16]
   213b8:	ldp	x29, x30, [sp], #80
   213bc:	ret
   213c0:	mov	x0, x19
   213c4:	mov	x1, x20
   213c8:	bl	c090 <__gmpz_realloc@plt>
   213cc:	mov	x24, x0
   213d0:	b	21300 <__gmpz_urandomm@@Base+0xe0>
   213d4:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   213d8:	b	213a4 <__gmpz_urandomm@@Base+0x184>
   213dc:	sub	x0, x29, #0x8
   213e0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   213e4:	mov	x24, x0
   213e8:	b	212dc <__gmpz_urandomm@@Base+0xbc>
   213ec:	bl	bfe0 <__gmp_divide_by_zero@plt>

00000000000213f0 <__gmpz_xor@@Base>:
   213f0:	stp	x29, x30, [sp, #-96]!
   213f4:	stp	x26, x25, [sp, #32]
   213f8:	stp	x24, x23, [sp, #48]
   213fc:	stp	x22, x21, [sp, #64]
   21400:	stp	x20, x19, [sp, #80]
   21404:	ldr	w8, [x1, #4]
   21408:	ldr	w9, [x2, #4]
   2140c:	ldr	x24, [x0, #8]
   21410:	str	x27, [sp, #16]
   21414:	mov	x19, x0
   21418:	cmp	w8, w9
   2141c:	csel	x25, x2, x1, lt  // lt = tstop
   21420:	ldr	x23, [x25, #8]
   21424:	csel	w10, w8, w9, gt
   21428:	csel	w8, w8, w9, lt  // lt = tstop
   2142c:	sxtw	x20, w10
   21430:	sxtw	x21, w8
   21434:	csel	x27, x1, x2, lt  // lt = tstop
   21438:	mov	x29, sp
   2143c:	tbnz	w8, #31, 214a4 <__gmpz_xor@@Base+0xb4>
   21440:	cmp	x24, x23
   21444:	mov	x22, x23
   21448:	b.eq	2146c <__gmpz_xor@@Base+0x7c>  // b.none
   2144c:	ldr	w8, [x19]
   21450:	cmp	w20, w8
   21454:	b.gt	21804 <__gmpz_xor@@Base+0x414>
   21458:	add	x0, x24, x21, lsl #3
   2145c:	add	x1, x23, x21, lsl #3
   21460:	sub	x2, x20, x21
   21464:	bl	ca70 <__gmpn_copyi@plt>
   21468:	mov	x22, x24
   2146c:	cbz	w21, 21484 <__gmpz_xor@@Base+0x94>
   21470:	ldr	x2, [x27, #8]
   21474:	mov	x0, x22
   21478:	mov	x1, x23
   2147c:	mov	x3, x21
   21480:	bl	cb60 <__gmpn_xor_n@plt>
   21484:	sub	x8, x22, #0x8
   21488:	mov	x9, x20
   2148c:	subs	x20, x20, #0x1
   21490:	b.lt	2149c <__gmpz_xor@@Base+0xac>  // b.tstop
   21494:	ldr	x10, [x8, x9, lsl #3]
   21498:	cbz	x10, 21488 <__gmpz_xor@@Base+0x98>
   2149c:	str	w9, [x19, #4]
   214a0:	b	217e4 <__gmpz_xor@@Base+0x3f4>
   214a4:	neg	x22, x21
   214a8:	str	xzr, [x29, #24]
   214ac:	tbnz	w20, #31, 21528 <__gmpz_xor@@Base+0x138>
   214b0:	ldrsw	x8, [x19]
   214b4:	cmp	x22, x20
   214b8:	csel	x26, x20, x22, lt  // lt = tstop
   214bc:	cmp	x26, x8
   214c0:	b.ge	21818 <__gmpz_xor@@Base+0x428>  // b.tcont
   214c4:	cmp	x22, #0xfe0
   214c8:	lsl	x1, x22, #3
   214cc:	b.hi	21830 <__gmpz_xor@@Base+0x440>  // b.pmore
   214d0:	add	x9, x1, #0xf
   214d4:	mov	x8, sp
   214d8:	and	x9, x9, #0xfffffffffffffff0
   214dc:	sub	x25, x8, x9
   214e0:	mov	sp, x25
   214e4:	ldr	x9, [x27, #8]
   214e8:	ldr	x8, [x9]
   214ec:	sub	x10, x8, #0x1
   214f0:	str	x10, [x25]
   214f4:	cbz	x8, 21598 <__gmpz_xor@@Base+0x1a8>
   214f8:	cmn	w21, #0x2
   214fc:	b.gt	215f0 <__gmpz_xor@@Base+0x200>
   21500:	cmp	x9, x25
   21504:	b.eq	215f0 <__gmpz_xor@@Base+0x200>  // b.none
   21508:	add	x8, x21, #0x1
   2150c:	add	x10, x25, #0x8
   21510:	add	x9, x9, #0x8
   21514:	ldr	x11, [x9], #8
   21518:	adds	x8, x8, #0x1
   2151c:	str	x11, [x10], #8
   21520:	b.cc	21514 <__gmpz_xor@@Base+0x124>  // b.lo, b.ul, b.last
   21524:	b	215f0 <__gmpz_xor@@Base+0x200>
   21528:	add	x8, x20, x21
   2152c:	neg	x1, x8, lsl #3
   21530:	mov	w8, #0x7f00                	// #32512
   21534:	cmp	x1, x8
   21538:	neg	x24, x20
   2153c:	b.hi	21848 <__gmpz_xor@@Base+0x458>  // b.pmore
   21540:	add	x9, x1, #0xf
   21544:	mov	x8, sp
   21548:	and	x9, x9, #0xfffffffffffffff0
   2154c:	sub	x25, x8, x9
   21550:	mov	sp, x25
   21554:	ldr	x8, [x23]
   21558:	add	x26, x25, x24, lsl #3
   2155c:	sub	x9, x8, #0x1
   21560:	str	x9, [x25]
   21564:	cbz	x8, 21678 <__gmpz_xor@@Base+0x288>
   21568:	cmn	w20, #0x2
   2156c:	b.gt	216d0 <__gmpz_xor@@Base+0x2e0>
   21570:	cmp	x23, x25
   21574:	b.eq	216d0 <__gmpz_xor@@Base+0x2e0>  // b.none
   21578:	add	x8, x20, #0x1
   2157c:	add	x9, x25, #0x8
   21580:	add	x10, x23, #0x8
   21584:	ldr	x11, [x10], #8
   21588:	adds	x8, x8, #0x1
   2158c:	str	x11, [x9], #8
   21590:	b.cc	21584 <__gmpz_xor@@Base+0x194>  // b.lo, b.ul, b.last
   21594:	b	216d0 <__gmpz_xor@@Base+0x2e0>
   21598:	mov	x10, #0xfffffffffffffff8    	// #-8
   2159c:	mov	w8, #0x1                   	// #1
   215a0:	cmp	x8, x22
   215a4:	b.ge	215f0 <__gmpz_xor@@Base+0x200>  // b.tcont
   215a8:	ldr	x11, [x9, x8, lsl #3]
   215ac:	sub	x10, x10, #0x8
   215b0:	sub	x12, x11, #0x1
   215b4:	str	x12, [x25, x8, lsl #3]
   215b8:	add	x8, x8, #0x1
   215bc:	cbz	x11, 215a0 <__gmpz_xor@@Base+0x1b0>
   215c0:	cmp	x9, x25
   215c4:	b.eq	215f0 <__gmpz_xor@@Base+0x200>  // b.none
   215c8:	cmp	x8, x22
   215cc:	b.ge	215f0 <__gmpz_xor@@Base+0x200>  // b.tcont
   215d0:	sub	x9, x9, x10
   215d4:	sub	x10, x25, x10
   215d8:	mov	x11, x22
   215dc:	ldr	x12, [x9], #8
   215e0:	sub	x11, x11, #0x1
   215e4:	cmp	x8, x11
   215e8:	str	x12, [x10], #8
   215ec:	b.ne	215dc <__gmpz_xor@@Base+0x1ec>  // b.any
   215f0:	subs	x2, x22, x20
   215f4:	b.le	2160c <__gmpz_xor@@Base+0x21c>
   215f8:	add	x0, x24, x20, lsl #3
   215fc:	add	x1, x25, x20, lsl #3
   21600:	bl	ca70 <__gmpn_copyi@plt>
   21604:	cbnz	w20, 21620 <__gmpz_xor@@Base+0x230>
   21608:	b	21634 <__gmpz_xor@@Base+0x244>
   2160c:	add	x0, x24, x22, lsl #3
   21610:	add	x1, x23, x22, lsl #3
   21614:	add	x2, x20, x21
   21618:	bl	ca70 <__gmpn_copyi@plt>
   2161c:	mov	x20, x22
   21620:	mov	x0, x24
   21624:	mov	x1, x23
   21628:	mov	x2, x25
   2162c:	mov	x3, x20
   21630:	bl	cb60 <__gmpn_xor_n@plt>
   21634:	ldr	x0, [x29, #24]
   21638:	cbnz	x0, 21840 <__gmpz_xor@@Base+0x450>
   2163c:	mov	x8, x24
   21640:	str	xzr, [x24, x26, lsl #3]
   21644:	ldr	x9, [x8]
   21648:	adds	x9, x9, #0x1
   2164c:	str	x9, [x8], #8
   21650:	b.cs	21644 <__gmpz_xor@@Base+0x254>  // b.hs, b.nlast
   21654:	ldr	x8, [x24, x26, lsl #3]
   21658:	add	x9, x8, x26
   2165c:	mvn	w8, w9
   21660:	add	x9, x24, x9, lsl #3
   21664:	sub	x9, x9, #0x8
   21668:	ldr	x10, [x9], #-8
   2166c:	add	w8, w8, #0x1
   21670:	cbz	x10, 21668 <__gmpz_xor@@Base+0x278>
   21674:	b	217e0 <__gmpz_xor@@Base+0x3f0>
   21678:	mov	x9, #0xfffffffffffffff8    	// #-8
   2167c:	mov	w8, #0x1                   	// #1
   21680:	cmp	x8, x24
   21684:	b.ge	216d0 <__gmpz_xor@@Base+0x2e0>  // b.tcont
   21688:	ldr	x10, [x23, x8, lsl #3]
   2168c:	sub	x9, x9, #0x8
   21690:	sub	x11, x10, #0x1
   21694:	str	x11, [x25, x8, lsl #3]
   21698:	add	x8, x8, #0x1
   2169c:	cbz	x10, 21680 <__gmpz_xor@@Base+0x290>
   216a0:	cmp	x23, x25
   216a4:	b.eq	216d0 <__gmpz_xor@@Base+0x2e0>  // b.none
   216a8:	cmp	x8, x24
   216ac:	b.ge	216d0 <__gmpz_xor@@Base+0x2e0>  // b.tcont
   216b0:	sub	x10, x23, x9
   216b4:	sub	x9, x25, x9
   216b8:	mov	x11, x24
   216bc:	ldr	x12, [x10], #8
   216c0:	sub	x11, x11, #0x1
   216c4:	cmp	x8, x11
   216c8:	str	x12, [x9], #8
   216cc:	b.ne	216bc <__gmpz_xor@@Base+0x2cc>  // b.any
   216d0:	ldr	x8, [x27, #8]
   216d4:	ldr	x9, [x8]
   216d8:	sub	x10, x9, #0x1
   216dc:	str	x10, [x26]
   216e0:	cbz	x9, 21718 <__gmpz_xor@@Base+0x328>
   216e4:	cmn	w21, #0x2
   216e8:	b.gt	21788 <__gmpz_xor@@Base+0x398>
   216ec:	cmp	x8, x26
   216f0:	b.eq	21788 <__gmpz_xor@@Base+0x398>  // b.none
   216f4:	sub	x10, x25, x20, lsl #3
   216f8:	add	x9, x21, #0x1
   216fc:	add	x10, x10, #0x8
   21700:	add	x8, x8, #0x8
   21704:	ldr	x11, [x8], #8
   21708:	adds	x9, x9, #0x1
   2170c:	str	x11, [x10], #8
   21710:	b.cc	21704 <__gmpz_xor@@Base+0x314>  // b.lo, b.ul, b.last
   21714:	b	21788 <__gmpz_xor@@Base+0x398>
   21718:	mov	w9, #0x10                  	// #16
   2171c:	sub	x11, x9, x20, lsl #3
   21720:	add	x9, x11, x25
   21724:	mov	x10, #0xfffffffffffffff8    	// #-8
   21728:	sub	x12, x9, #0x10
   2172c:	mov	w9, #0x1                   	// #1
   21730:	cmp	x9, x22
   21734:	b.ge	21788 <__gmpz_xor@@Base+0x398>  // b.tcont
   21738:	ldr	x13, [x8, x9, lsl #3]
   2173c:	sub	x10, x10, #0x8
   21740:	sub	x14, x13, #0x1
   21744:	str	x14, [x12, x9, lsl #3]
   21748:	add	x9, x9, #0x1
   2174c:	cbz	x13, 21730 <__gmpz_xor@@Base+0x340>
   21750:	cmp	x8, x26
   21754:	b.eq	21788 <__gmpz_xor@@Base+0x398>  // b.none
   21758:	cmp	x9, x22
   2175c:	b.ge	21788 <__gmpz_xor@@Base+0x398>  // b.tcont
   21760:	add	x11, x11, x25
   21764:	sub	x8, x8, x10
   21768:	sub	x10, x11, x10
   2176c:	sub	x10, x10, #0x10
   21770:	mov	x11, x22
   21774:	ldr	x12, [x8], #8
   21778:	sub	x11, x11, #0x1
   2177c:	cmp	x9, x11
   21780:	str	x12, [x10], #8
   21784:	b.ne	21774 <__gmpz_xor@@Base+0x384>  // b.any
   21788:	ldrsw	x8, [x19]
   2178c:	cmp	x22, x8
   21790:	b.gt	21858 <__gmpz_xor@@Base+0x468>
   21794:	ldr	x23, [x19, #8]
   21798:	add	x0, x23, x24, lsl #3
   2179c:	add	x1, x26, x24, lsl #3
   217a0:	sub	x2, x20, x21
   217a4:	bl	ca70 <__gmpn_copyi@plt>
   217a8:	mov	x0, x23
   217ac:	mov	x1, x25
   217b0:	mov	x2, x26
   217b4:	mov	x3, x24
   217b8:	bl	cb60 <__gmpn_xor_n@plt>
   217bc:	ldr	x0, [x29, #24]
   217c0:	cbnz	x0, 2186c <__gmpz_xor@@Base+0x47c>
   217c4:	sub	x9, x23, #0x8
   217c8:	subs	x10, x22, #0x1
   217cc:	mov	w8, w22
   217d0:	b.lt	217e0 <__gmpz_xor@@Base+0x3f0>  // b.tstop
   217d4:	ldr	x11, [x9, x22, lsl #3]
   217d8:	mov	x22, x10
   217dc:	cbz	x11, 217c8 <__gmpz_xor@@Base+0x3d8>
   217e0:	str	w8, [x19, #4]
   217e4:	mov	sp, x29
   217e8:	ldp	x20, x19, [sp, #80]
   217ec:	ldp	x22, x21, [sp, #64]
   217f0:	ldp	x24, x23, [sp, #48]
   217f4:	ldp	x26, x25, [sp, #32]
   217f8:	ldr	x27, [sp, #16]
   217fc:	ldp	x29, x30, [sp], #96
   21800:	ret
   21804:	mov	x0, x19
   21808:	mov	x1, x20
   2180c:	bl	c090 <__gmpz_realloc@plt>
   21810:	mov	x24, x0
   21814:	b	21458 <__gmpz_xor@@Base+0x68>
   21818:	add	x1, x26, #0x1
   2181c:	mov	x0, x19
   21820:	bl	c090 <__gmpz_realloc@plt>
   21824:	ldr	x23, [x25, #8]
   21828:	mov	x24, x0
   2182c:	b	214c4 <__gmpz_xor@@Base+0xd4>
   21830:	add	x0, x29, #0x18
   21834:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   21838:	mov	x25, x0
   2183c:	b	214e4 <__gmpz_xor@@Base+0xf4>
   21840:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   21844:	b	2163c <__gmpz_xor@@Base+0x24c>
   21848:	add	x0, x29, #0x18
   2184c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   21850:	mov	x25, x0
   21854:	b	21554 <__gmpz_xor@@Base+0x164>
   21858:	mov	x0, x19
   2185c:	mov	x1, x22
   21860:	bl	c090 <__gmpz_realloc@plt>
   21864:	mov	x23, x0
   21868:	b	21798 <__gmpz_xor@@Base+0x3a8>
   2186c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   21870:	b	217c4 <__gmpz_xor@@Base+0x3d4>

0000000000021874 <__gmpq_abs@@Base>:
   21874:	stp	x29, x30, [sp, #-64]!
   21878:	stp	x22, x21, [sp, #32]
   2187c:	stp	x20, x19, [sp, #48]
   21880:	ldr	w8, [x1, #4]
   21884:	mov	x19, x0
   21888:	str	x23, [sp, #16]
   2188c:	mov	x29, sp
   21890:	cmp	w8, #0x0
   21894:	cneg	w20, w8, mi  // mi = first
   21898:	cmp	x0, x1
   2189c:	b.eq	218ec <__gmpq_abs@@Base+0x78>  // b.none
   218a0:	ldrsw	x8, [x19]
   218a4:	ldr	w23, [x1, #20]
   218a8:	mov	x21, x1
   218ac:	cmp	x20, x8
   218b0:	sxtw	x22, w23
   218b4:	b.gt	21904 <__gmpq_abs@@Base+0x90>
   218b8:	ldr	x0, [x19, #8]
   218bc:	ldr	x1, [x21, #8]
   218c0:	mov	x2, x20
   218c4:	bl	ca70 <__gmpn_copyi@plt>
   218c8:	mov	x0, x19
   218cc:	ldr	w8, [x0, #16]!
   218d0:	cmp	w23, w8
   218d4:	b.gt	21914 <__gmpq_abs@@Base+0xa0>
   218d8:	ldr	x0, [x19, #24]
   218dc:	str	w23, [x19, #20]
   218e0:	ldr	x1, [x21, #24]
   218e4:	mov	x2, x22
   218e8:	bl	ca70 <__gmpn_copyi@plt>
   218ec:	str	w20, [x19, #4]
   218f0:	ldp	x20, x19, [sp, #48]
   218f4:	ldp	x22, x21, [sp, #32]
   218f8:	ldr	x23, [sp, #16]
   218fc:	ldp	x29, x30, [sp], #64
   21900:	ret
   21904:	mov	x0, x19
   21908:	mov	x1, x20
   2190c:	bl	c090 <__gmpz_realloc@plt>
   21910:	b	218bc <__gmpq_abs@@Base+0x48>
   21914:	mov	x1, x22
   21918:	bl	c090 <__gmpz_realloc@plt>
   2191c:	b	218dc <__gmpq_abs@@Base+0x68>

0000000000021920 <__gmpq_add@@Base>:
   21920:	adrp	x3, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   21924:	ldr	x3, [x3, #4000]
   21928:	b	2192c <__gmpq_add@@Base+0xc>
   2192c:	stp	x29, x30, [sp, #-96]!
   21930:	stp	x28, x27, [sp, #16]
   21934:	stp	x26, x25, [sp, #32]
   21938:	stp	x24, x23, [sp, #48]
   2193c:	stp	x22, x21, [sp, #64]
   21940:	stp	x20, x19, [sp, #80]
   21944:	mov	x29, sp
   21948:	sub	sp, sp, #0x50
   2194c:	ldr	w8, [x1, #4]
   21950:	ldr	w9, [x2, #4]
   21954:	ldrsw	x26, [x1, #20]
   21958:	ldrsw	x25, [x2, #20]
   2195c:	cmp	w8, #0x0
   21960:	cneg	w28, w8, mi  // mi = first
   21964:	cmp	w9, #0x0
   21968:	cneg	w27, w9, mi  // mi = first
   2196c:	cmp	x26, x25
   21970:	csel	x8, x26, x25, lt  // lt = tstop
   21974:	mov	x23, x1
   21978:	mov	w10, #0x7f00                	// #32512
   2197c:	lsl	x1, x8, #3
   21980:	mov	x21, x3
   21984:	mov	x22, x2
   21988:	mov	x19, x0
   2198c:	cmp	x1, x10
   21990:	stur	xzr, [x29, #-56]
   21994:	stur	w8, [x29, #-16]
   21998:	b.hi	21bb4 <__gmpq_add@@Base+0x294>  // b.pmore
   2199c:	add	x9, x1, #0xf
   219a0:	mov	x8, sp
   219a4:	and	x9, x9, #0xfffffffffffffff0
   219a8:	sub	x0, x8, x9
   219ac:	mov	sp, x0
   219b0:	add	x25, x25, x28
   219b4:	lsl	x1, x25, #3
   219b8:	mov	w8, #0x7f00                	// #32512
   219bc:	add	x24, x23, #0x10
   219c0:	add	x20, x22, #0x10
   219c4:	cmp	x1, x8
   219c8:	stur	x0, [x29, #-8]
   219cc:	stur	w25, [x29, #-32]
   219d0:	b.hi	21bc0 <__gmpq_add@@Base+0x2a0>  // b.pmore
   219d4:	add	x9, x1, #0xf
   219d8:	mov	x8, sp
   219dc:	and	x9, x9, #0xfffffffffffffff0
   219e0:	sub	x0, x8, x9
   219e4:	mov	sp, x0
   219e8:	add	x26, x27, x26
   219ec:	lsl	x1, x26, #3
   219f0:	mov	w8, #0x7f00                	// #32512
   219f4:	cmp	x1, x8
   219f8:	stur	x0, [x29, #-24]
   219fc:	stur	w26, [x29, #-48]
   21a00:	b.hi	21bcc <__gmpq_add@@Base+0x2ac>  // b.pmore
   21a04:	add	x9, x1, #0xf
   21a08:	mov	x8, sp
   21a0c:	and	x9, x9, #0xfffffffffffffff0
   21a10:	sub	x0, x8, x9
   21a14:	mov	sp, x0
   21a18:	stur	x0, [x29, #-40]
   21a1c:	sub	x0, x29, #0x10
   21a20:	mov	x1, x24
   21a24:	mov	x2, x20
   21a28:	bl	cf90 <__gmpz_gcd@plt>
   21a2c:	ldursw	x8, [x29, #-12]
   21a30:	cmp	w8, #0x1
   21a34:	b.ne	21a88 <__gmpq_add@@Base+0x168>  // b.any
   21a38:	ldur	x9, [x29, #-8]
   21a3c:	ldr	x9, [x9]
   21a40:	cmp	x9, #0x1
   21a44:	b.ne	21a88 <__gmpq_add@@Base+0x168>  // b.any
   21a48:	sub	x0, x29, #0x20
   21a4c:	mov	x1, x23
   21a50:	mov	x2, x20
   21a54:	bl	c4d0 <__gmpz_mul@plt>
   21a58:	sub	x0, x29, #0x30
   21a5c:	mov	x1, x22
   21a60:	mov	x2, x24
   21a64:	bl	c4d0 <__gmpz_mul@plt>
   21a68:	sub	x1, x29, #0x20
   21a6c:	sub	x2, x29, #0x30
   21a70:	mov	x0, x19
   21a74:	blr	x21
   21a78:	add	x0, x19, #0x10
   21a7c:	mov	x1, x24
   21a80:	mov	x2, x20
   21a84:	b	21b88 <__gmpq_add@@Base+0x268>
   21a88:	cmp	x25, x26
   21a8c:	csel	x9, x25, x26, gt
   21a90:	sub	w10, w9, w8
   21a94:	sub	x8, x9, x8
   21a98:	lsl	x8, x8, #3
   21a9c:	add	x1, x8, #0x10
   21aa0:	mov	w8, #0x7f00                	// #32512
   21aa4:	add	w9, w10, #0x2
   21aa8:	cmp	x1, x8
   21aac:	stur	w9, [x29, #-72]
   21ab0:	b.hi	21be0 <__gmpq_add@@Base+0x2c0>  // b.pmore
   21ab4:	add	x9, x1, #0xf
   21ab8:	mov	x8, sp
   21abc:	and	x9, x9, #0xfffffffffffffff0
   21ac0:	sub	x0, x8, x9
   21ac4:	mov	sp, x0
   21ac8:	stur	x0, [x29, #-64]
   21acc:	sub	x0, x29, #0x48
   21ad0:	sub	x2, x29, #0x10
   21ad4:	mov	x1, x20
   21ad8:	bl	ca20 <__gmpz_divexact_gcd@plt>
   21adc:	sub	x0, x29, #0x30
   21ae0:	sub	x2, x29, #0x10
   21ae4:	mov	x1, x24
   21ae8:	bl	ca20 <__gmpz_divexact_gcd@plt>
   21aec:	sub	x0, x29, #0x20
   21af0:	sub	x2, x29, #0x48
   21af4:	mov	x1, x23
   21af8:	bl	c4d0 <__gmpz_mul@plt>
   21afc:	sub	x0, x29, #0x48
   21b00:	sub	x2, x29, #0x30
   21b04:	mov	x1, x22
   21b08:	bl	c4d0 <__gmpz_mul@plt>
   21b0c:	sub	x0, x29, #0x48
   21b10:	sub	x1, x29, #0x20
   21b14:	sub	x2, x29, #0x48
   21b18:	blr	x21
   21b1c:	sub	x0, x29, #0x10
   21b20:	sub	x1, x29, #0x48
   21b24:	sub	x2, x29, #0x10
   21b28:	bl	cf90 <__gmpz_gcd@plt>
   21b2c:	ldur	w8, [x29, #-12]
   21b30:	cmp	w8, #0x1
   21b34:	b.ne	21b58 <__gmpq_add@@Base+0x238>  // b.any
   21b38:	ldur	x8, [x29, #-8]
   21b3c:	ldr	x8, [x8]
   21b40:	cmp	x8, #0x1
   21b44:	b.ne	21b58 <__gmpq_add@@Base+0x238>  // b.any
   21b48:	sub	x1, x29, #0x48
   21b4c:	mov	x0, x19
   21b50:	bl	c440 <__gmpz_set@plt>
   21b54:	b	21b7c <__gmpq_add@@Base+0x25c>
   21b58:	sub	x1, x29, #0x48
   21b5c:	sub	x2, x29, #0x10
   21b60:	mov	x0, x19
   21b64:	bl	ca20 <__gmpz_divexact_gcd@plt>
   21b68:	sub	x0, x29, #0x20
   21b6c:	sub	x2, x29, #0x10
   21b70:	mov	x1, x20
   21b74:	bl	ca20 <__gmpz_divexact_gcd@plt>
   21b78:	sub	x20, x29, #0x20
   21b7c:	add	x0, x19, #0x10
   21b80:	sub	x2, x29, #0x30
   21b84:	mov	x1, x20
   21b88:	bl	c4d0 <__gmpz_mul@plt>
   21b8c:	ldur	x0, [x29, #-56]
   21b90:	cbnz	x0, 21bd8 <__gmpq_add@@Base+0x2b8>
   21b94:	mov	sp, x29
   21b98:	ldp	x20, x19, [sp, #80]
   21b9c:	ldp	x22, x21, [sp, #64]
   21ba0:	ldp	x24, x23, [sp, #48]
   21ba4:	ldp	x26, x25, [sp, #32]
   21ba8:	ldp	x28, x27, [sp, #16]
   21bac:	ldp	x29, x30, [sp], #96
   21bb0:	ret
   21bb4:	sub	x0, x29, #0x38
   21bb8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   21bbc:	b	219b0 <__gmpq_add@@Base+0x90>
   21bc0:	sub	x0, x29, #0x38
   21bc4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   21bc8:	b	219e8 <__gmpq_add@@Base+0xc8>
   21bcc:	sub	x0, x29, #0x38
   21bd0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   21bd4:	b	21a18 <__gmpq_add@@Base+0xf8>
   21bd8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   21bdc:	b	21b94 <__gmpq_add@@Base+0x274>
   21be0:	sub	x0, x29, #0x38
   21be4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   21be8:	b	21ac8 <__gmpq_add@@Base+0x1a8>

0000000000021bec <__gmpq_sub@@Base>:
   21bec:	adrp	x3, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   21bf0:	ldr	x3, [x3, #3832]
   21bf4:	b	2192c <__gmpq_add@@Base+0xc>

0000000000021bf8 <__gmpq_canonicalize@@Base>:
   21bf8:	stp	x29, x30, [sp, #-32]!
   21bfc:	stp	x20, x19, [sp, #16]
   21c00:	mov	x29, sp
   21c04:	sub	sp, sp, #0x20
   21c08:	ldr	w8, [x0, #20]
   21c0c:	mov	x19, x0
   21c10:	tbnz	w8, #31, 21c20 <__gmpq_canonicalize@@Base+0x28>
   21c14:	cbz	w8, 21cf0 <__gmpq_canonicalize@@Base+0xf8>
   21c18:	ldr	w9, [x19, #4]
   21c1c:	b	21c34 <__gmpq_canonicalize@@Base+0x3c>
   21c20:	ldr	w9, [x19, #4]
   21c24:	neg	w8, w8
   21c28:	str	w8, [x19, #20]
   21c2c:	neg	w9, w9
   21c30:	str	w9, [x19, #4]
   21c34:	cmp	w9, #0x0
   21c38:	cneg	w9, w9, mi  // mi = first
   21c3c:	cmp	w9, w8
   21c40:	csel	w8, w9, w8, gt
   21c44:	add	w9, w8, #0x1
   21c48:	add	x20, x19, #0x10
   21c4c:	cmp	w8, #0xfdf
   21c50:	lsl	x1, x9, #3
   21c54:	stur	xzr, [x29, #-24]
   21c58:	stur	w9, [x29, #-16]
   21c5c:	b.hi	21cdc <__gmpq_canonicalize@@Base+0xe4>  // b.pmore
   21c60:	add	x9, x1, #0xf
   21c64:	mov	x8, sp
   21c68:	and	x9, x9, #0xffffffff0
   21c6c:	sub	x0, x8, x9
   21c70:	mov	sp, x0
   21c74:	stur	x0, [x29, #-8]
   21c78:	sub	x0, x29, #0x10
   21c7c:	mov	x1, x19
   21c80:	mov	x2, x20
   21c84:	bl	cf90 <__gmpz_gcd@plt>
   21c88:	ldur	w8, [x29, #-12]
   21c8c:	cmp	w8, #0x1
   21c90:	b.ne	21ca4 <__gmpq_canonicalize@@Base+0xac>  // b.any
   21c94:	ldur	x8, [x29, #-8]
   21c98:	ldr	x8, [x8]
   21c9c:	cmp	x8, #0x1
   21ca0:	b.eq	21cc4 <__gmpq_canonicalize@@Base+0xcc>  // b.none
   21ca4:	sub	x2, x29, #0x10
   21ca8:	mov	x0, x19
   21cac:	mov	x1, x19
   21cb0:	bl	ca20 <__gmpz_divexact_gcd@plt>
   21cb4:	sub	x2, x29, #0x10
   21cb8:	mov	x0, x20
   21cbc:	mov	x1, x20
   21cc0:	bl	ca20 <__gmpz_divexact_gcd@plt>
   21cc4:	ldur	x0, [x29, #-24]
   21cc8:	cbnz	x0, 21ce8 <__gmpq_canonicalize@@Base+0xf0>
   21ccc:	mov	sp, x29
   21cd0:	ldp	x20, x19, [sp, #16]
   21cd4:	ldp	x29, x30, [sp], #32
   21cd8:	ret
   21cdc:	sub	x0, x29, #0x18
   21ce0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   21ce4:	b	21c74 <__gmpq_canonicalize@@Base+0x7c>
   21ce8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   21cec:	b	21ccc <__gmpq_canonicalize@@Base+0xd4>
   21cf0:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000021cf4 <__gmpq_clear@@Base>:
   21cf4:	stp	x29, x30, [sp, #-32]!
   21cf8:	stp	x20, x19, [sp, #16]
   21cfc:	adrp	x20, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   21d00:	ldrsw	x8, [x0]
   21d04:	ldr	x20, [x20, #4016]
   21d08:	mov	x19, x0
   21d0c:	mov	x29, sp
   21d10:	cbz	w8, 21d24 <__gmpq_clear@@Base+0x30>
   21d14:	ldr	x9, [x20]
   21d18:	ldr	x0, [x19, #8]
   21d1c:	lsl	x1, x8, #3
   21d20:	blr	x9
   21d24:	ldrsw	x8, [x19, #16]
   21d28:	cbz	w8, 21d44 <__gmpq_clear@@Base+0x50>
   21d2c:	ldr	x2, [x20]
   21d30:	ldr	x0, [x19, #24]
   21d34:	ldp	x20, x19, [sp, #16]
   21d38:	lsl	x1, x8, #3
   21d3c:	ldp	x29, x30, [sp], #32
   21d40:	br	x2
   21d44:	ldp	x20, x19, [sp, #16]
   21d48:	ldp	x29, x30, [sp], #32
   21d4c:	ret

0000000000021d50 <__gmpq_clears@@Base>:
   21d50:	sub	sp, sp, #0x100
   21d54:	stp	x29, x30, [sp, #224]
   21d58:	add	x29, sp, #0xe0
   21d5c:	mov	x8, #0xffffffffffffffc8    	// #-56
   21d60:	mov	x9, sp
   21d64:	sub	x10, x29, #0x58
   21d68:	movk	x8, #0xff80, lsl #32
   21d6c:	add	x11, x29, #0x20
   21d70:	add	x9, x9, #0x80
   21d74:	add	x10, x10, #0x38
   21d78:	stp	x20, x19, [sp, #240]
   21d7c:	stp	x1, x2, [x29, #-88]
   21d80:	stp	x3, x4, [x29, #-72]
   21d84:	stp	x5, x6, [x29, #-56]
   21d88:	stur	x7, [x29, #-40]
   21d8c:	stp	q0, q1, [sp]
   21d90:	stp	q2, q3, [sp, #32]
   21d94:	stp	q4, q5, [sp, #64]
   21d98:	stp	q6, q7, [sp, #96]
   21d9c:	stp	x9, x8, [x29, #-16]
   21da0:	stp	x11, x10, [x29, #-32]
   21da4:	adrp	x20, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   21da8:	ldr	x20, [x20, #4016]
   21dac:	mov	x19, x0
   21db0:	ldrsw	x8, [x19]
   21db4:	cbz	w8, 21dc8 <__gmpq_clears@@Base+0x78>
   21db8:	ldr	x9, [x20]
   21dbc:	ldr	x0, [x19, #8]
   21dc0:	lsl	x1, x8, #3
   21dc4:	blr	x9
   21dc8:	ldrsw	x8, [x19, #16]
   21dcc:	cbz	w8, 21de0 <__gmpq_clears@@Base+0x90>
   21dd0:	ldr	x9, [x20]
   21dd4:	ldr	x0, [x19, #24]
   21dd8:	lsl	x1, x8, #3
   21ddc:	blr	x9
   21de0:	ldursw	x8, [x29, #-8]
   21de4:	tbz	w8, #31, 21e04 <__gmpq_clears@@Base+0xb4>
   21de8:	add	w9, w8, #0x8
   21dec:	cmn	w8, #0x8
   21df0:	stur	w9, [x29, #-8]
   21df4:	b.gt	21e04 <__gmpq_clears@@Base+0xb4>
   21df8:	ldur	x9, [x29, #-24]
   21dfc:	add	x8, x9, x8
   21e00:	b	21e10 <__gmpq_clears@@Base+0xc0>
   21e04:	ldur	x8, [x29, #-32]
   21e08:	add	x9, x8, #0x8
   21e0c:	stur	x9, [x29, #-32]
   21e10:	ldr	x19, [x8]
   21e14:	cbnz	x19, 21db0 <__gmpq_clears@@Base+0x60>
   21e18:	ldp	x20, x19, [sp, #240]
   21e1c:	ldp	x29, x30, [sp, #224]
   21e20:	add	sp, sp, #0x100
   21e24:	ret

0000000000021e28 <__gmpq_cmp@@Base>:
   21e28:	add	x2, x1, #0x10
   21e2c:	b	21e30 <__gmpq_cmp@@Base+0x8>
   21e30:	stp	x29, x30, [sp, #-96]!
   21e34:	str	x27, [sp, #16]
   21e38:	stp	x26, x25, [sp, #32]
   21e3c:	stp	x24, x23, [sp, #48]
   21e40:	stp	x22, x21, [sp, #64]
   21e44:	stp	x20, x19, [sp, #80]
   21e48:	mov	x29, sp
   21e4c:	sub	sp, sp, #0x10
   21e50:	ldr	w25, [x0, #4]
   21e54:	ldrsw	x11, [x1, #4]
   21e58:	cbz	w25, 21ef4 <__gmpq_cmp@@Base+0xcc>
   21e5c:	cbz	w11, 21f18 <__gmpq_cmp@@Base+0xf0>
   21e60:	eor	w8, w11, w25
   21e64:	tbnz	w8, #31, 21f18 <__gmpq_cmp@@Base+0xf0>
   21e68:	ldrsw	x8, [x2, #4]
   21e6c:	ldr	x9, [x2, #8]
   21e70:	ldrsw	x21, [x0, #20]
   21e74:	ldr	x10, [x0, #24]
   21e78:	sxtw	x14, w25
   21e7c:	add	x9, x9, x8, lsl #3
   21e80:	ldur	x12, [x9, #-8]
   21e84:	add	x9, x10, x21, lsl #3
   21e88:	ldur	x13, [x9, #-8]
   21e8c:	cmp	x14, #0x0
   21e90:	orr	x9, x12, x8
   21e94:	cneg	x4, x14, mi  // mi = first
   21e98:	cmp	x9, #0x1
   21e9c:	cset	w10, eq  // eq = none
   21ea0:	orr	x15, x13, x21
   21ea4:	mov	x19, x1
   21ea8:	mov	x20, x0
   21eac:	cmp	x15, x10
   21eb0:	b.ne	21efc <__gmpq_cmp@@Base+0xd4>  // b.any
   21eb4:	cmp	w25, w11
   21eb8:	b.ne	21f3c <__gmpq_cmp@@Base+0x114>  // b.any
   21ebc:	ldr	x8, [x19, #8]
   21ec0:	ldr	x9, [x20, #8]
   21ec4:	sub	x8, x8, #0x8
   21ec8:	sub	x9, x9, #0x8
   21ecc:	subs	x10, x4, #0x1
   21ed0:	b.lt	21f60 <__gmpq_cmp@@Base+0x138>  // b.tstop
   21ed4:	ldr	x11, [x9, x4, lsl #3]
   21ed8:	ldr	x12, [x8, x4, lsl #3]
   21edc:	mov	x4, x10
   21ee0:	cmp	x11, x12
   21ee4:	b.eq	21ecc <__gmpq_cmp@@Base+0xa4>  // b.none
   21ee8:	mov	w8, #0x1                   	// #1
   21eec:	cneg	w8, w8, ls  // ls = plast
   21ef0:	b	21f64 <__gmpq_cmp@@Base+0x13c>
   21ef4:	neg	w0, w11
   21ef8:	b	21f1c <__gmpq_cmp@@Base+0xf4>
   21efc:	cmp	x11, #0x0
   21f00:	cneg	x22, x11, mi  // mi = first
   21f04:	add	x26, x22, x21
   21f08:	add	x27, x4, x8
   21f0c:	add	x11, x26, #0x1
   21f10:	cmp	x27, x11
   21f14:	b.le	21f44 <__gmpq_cmp@@Base+0x11c>
   21f18:	mov	w0, w25
   21f1c:	mov	sp, x29
   21f20:	ldp	x20, x19, [sp, #80]
   21f24:	ldp	x22, x21, [sp, #64]
   21f28:	ldp	x24, x23, [sp, #48]
   21f2c:	ldp	x26, x25, [sp, #32]
   21f30:	ldr	x27, [sp, #16]
   21f34:	ldp	x29, x30, [sp], #96
   21f38:	ret
   21f3c:	sub	w0, w25, w11
   21f40:	b	21f1c <__gmpq_cmp@@Base+0xf4>
   21f44:	add	x11, x26, x10
   21f48:	add	x15, x27, #0x1
   21f4c:	cmp	x11, x15
   21f50:	neg	x11, x14
   21f54:	b.le	21f70 <__gmpq_cmp@@Base+0x148>
   21f58:	mov	w0, w11
   21f5c:	b	21f1c <__gmpq_cmp@@Base+0xf4>
   21f60:	mov	w8, wzr
   21f64:	cmp	w25, #0x0
   21f68:	cneg	w0, w8, le
   21f6c:	b	21f1c <__gmpq_cmp@@Base+0xf4>
   21f70:	ldr	x23, [x20, #8]
   21f74:	ldr	x14, [x19, #8]
   21f78:	lsl	x16, x27, #6
   21f7c:	clz	x13, x13
   21f80:	add	x15, x23, x4, lsl #3
   21f84:	ldur	x15, [x15, #-8]
   21f88:	add	x14, x14, x22, lsl #3
   21f8c:	ldur	x14, [x14, #-8]
   21f90:	clz	x12, x12
   21f94:	clz	x15, x15
   21f98:	sub	x15, x16, x15
   21f9c:	lsl	x16, x26, #6
   21fa0:	clz	x14, x14
   21fa4:	sub	x14, x16, x14
   21fa8:	sub	x13, x14, x13
   21fac:	sub	x12, x15, x12
   21fb0:	add	x14, x13, #0x1
   21fb4:	cmp	x12, x14
   21fb8:	mov	w0, w25
   21fbc:	b.hi	21f1c <__gmpq_cmp@@Base+0xf4>  // b.pmore
   21fc0:	add	x10, x13, x10
   21fc4:	add	x12, x12, #0x1
   21fc8:	cmp	x10, x12
   21fcc:	mov	w0, w11
   21fd0:	b.hi	21f1c <__gmpq_cmp@@Base+0xf4>  // b.pmore
   21fd4:	cmp	x9, #0x1
   21fd8:	str	xzr, [x29, #24]
   21fdc:	b.ne	2200c <__gmpq_cmp@@Base+0x1e4>  // b.any
   21fe0:	lsl	x1, x26, #3
   21fe4:	mov	w8, #0x7f00                	// #32512
   21fe8:	cmp	x1, x8
   21fec:	b.hi	22110 <__gmpq_cmp@@Base+0x2e8>  // b.pmore
   21ff0:	add	x9, x1, #0xf
   21ff4:	mov	x8, sp
   21ff8:	and	x9, x9, #0xfffffffffffffff0
   21ffc:	sub	x24, x8, x9
   22000:	mov	sp, x24
   22004:	mov	x8, #0xffffffffffffffff    	// #-1
   22008:	b	22074 <__gmpq_cmp@@Base+0x24c>
   2200c:	add	x9, x26, x27
   22010:	lsl	x1, x9, #3
   22014:	mov	w9, #0x7f00                	// #32512
   22018:	cmp	x1, x9
   2201c:	b.hi	22124 <__gmpq_cmp@@Base+0x2fc>  // b.pmore
   22020:	add	x10, x1, #0xf
   22024:	mov	x9, sp
   22028:	and	x10, x10, #0xfffffffffffffff0
   2202c:	sub	x23, x9, x10
   22030:	mov	sp, x23
   22034:	cmp	x4, x8
   22038:	add	x24, x23, x27, lsl #3
   2203c:	b.ge	22054 <__gmpq_cmp@@Base+0x22c>  // b.tcont
   22040:	ldr	x1, [x2, #8]
   22044:	ldr	x3, [x20, #8]
   22048:	mov	x0, x23
   2204c:	mov	x2, x8
   22050:	b	22068 <__gmpq_cmp@@Base+0x240>
   22054:	ldr	x1, [x20, #8]
   22058:	ldr	x3, [x2, #8]
   2205c:	mov	x0, x23
   22060:	mov	x2, x4
   22064:	mov	x4, x8
   22068:	bl	ccf0 <__gmpn_mul@plt>
   2206c:	cmp	x0, #0x0
   22070:	csetm	x8, eq  // eq = none
   22074:	cmp	x22, x21
   22078:	add	x27, x27, x8
   2207c:	b.ge	22098 <__gmpq_cmp@@Base+0x270>  // b.tcont
   22080:	ldr	x1, [x20, #24]
   22084:	ldr	x3, [x19, #8]
   22088:	mov	x0, x24
   2208c:	mov	x2, x21
   22090:	mov	x4, x22
   22094:	b	220ac <__gmpq_cmp@@Base+0x284>
   22098:	ldr	x1, [x19, #8]
   2209c:	ldr	x3, [x20, #24]
   220a0:	mov	x0, x24
   220a4:	mov	x2, x22
   220a8:	mov	x4, x21
   220ac:	bl	ccf0 <__gmpn_mul@plt>
   220b0:	sub	x8, x27, x26
   220b4:	cmp	x0, #0x0
   220b8:	cinc	x19, x8, eq  // eq = none
   220bc:	cbnz	x19, 220f4 <__gmpq_cmp@@Base+0x2cc>
   220c0:	sub	x8, x24, #0x8
   220c4:	sub	x9, x23, #0x8
   220c8:	subs	x10, x27, #0x1
   220cc:	b.lt	220f0 <__gmpq_cmp@@Base+0x2c8>  // b.tstop
   220d0:	ldr	x11, [x9, x27, lsl #3]
   220d4:	ldr	x12, [x8, x27, lsl #3]
   220d8:	mov	x27, x10
   220dc:	cmp	x11, x12
   220e0:	b.eq	220c8 <__gmpq_cmp@@Base+0x2a0>  // b.none
   220e4:	mov	w8, #0x1                   	// #1
   220e8:	cneg	x19, x8, ls  // ls = plast
   220ec:	b	220f4 <__gmpq_cmp@@Base+0x2cc>
   220f0:	mov	x19, xzr
   220f4:	ldr	x0, [x29, #24]
   220f8:	cbnz	x0, 22108 <__gmpq_cmp@@Base+0x2e0>
   220fc:	cmp	w25, #0x0
   22100:	cneg	w0, w19, lt  // lt = tstop
   22104:	b	21f1c <__gmpq_cmp@@Base+0xf4>
   22108:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2210c:	b	220fc <__gmpq_cmp@@Base+0x2d4>
   22110:	add	x0, x29, #0x18
   22114:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   22118:	ldr	x23, [x20, #8]
   2211c:	mov	x24, x0
   22120:	b	22004 <__gmpq_cmp@@Base+0x1dc>
   22124:	add	x0, x29, #0x18
   22128:	stur	x4, [x29, #-8]
   2212c:	mov	x23, x2
   22130:	mov	x24, x8
   22134:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   22138:	ldur	x4, [x29, #-8]
   2213c:	mov	x8, x24
   22140:	mov	x2, x23
   22144:	mov	x23, x0
   22148:	b	22034 <__gmpq_cmp@@Base+0x20c>

000000000002214c <__gmpq_cmp_z@@Base>:
   2214c:	adrp	x2, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   22150:	add	x2, x2, #0x9e0
   22154:	b	21e30 <__gmpq_cmp@@Base+0x8>

0000000000022158 <__gmpq_cmp_si@@Base>:
   22158:	tbnz	x1, #63, 22160 <__gmpq_cmp_si@@Base+0x8>
   2215c:	b	bf20 <__gmpq_cmp_ui@plt>
   22160:	sub	sp, sp, #0x30
   22164:	stp	x29, x30, [sp, #32]
   22168:	ldr	w8, [x0, #4]
   2216c:	add	x29, sp, #0x20
   22170:	tbnz	w8, #31, 2217c <__gmpq_cmp_si@@Base+0x24>
   22174:	mov	w0, #0x1                   	// #1
   22178:	b	221ac <__gmpq_cmp_si@@Base+0x54>
   2217c:	neg	w8, w8
   22180:	str	w8, [sp, #4]
   22184:	ldr	x8, [x0, #8]
   22188:	neg	x1, x1
   2218c:	str	x8, [sp, #8]
   22190:	ldr	w8, [x0, #20]
   22194:	str	w8, [sp, #20]
   22198:	ldr	x8, [x0, #24]
   2219c:	mov	x0, sp
   221a0:	str	x8, [sp, #24]
   221a4:	bl	bf20 <__gmpq_cmp_ui@plt>
   221a8:	neg	w0, w0
   221ac:	ldp	x29, x30, [sp, #32]
   221b0:	add	sp, sp, #0x30
   221b4:	ret

00000000000221b8 <__gmpq_cmp_ui@@Base>:
   221b8:	stp	x29, x30, [sp, #-80]!
   221bc:	str	x25, [sp, #16]
   221c0:	stp	x24, x23, [sp, #32]
   221c4:	stp	x22, x21, [sp, #48]
   221c8:	stp	x20, x19, [sp, #64]
   221cc:	mov	x29, sp
   221d0:	cbz	x2, 2233c <__gmpq_cmp_ui@@Base+0x184>
   221d4:	mov	x22, x0
   221d8:	ldr	w0, [x0, #4]
   221dc:	mov	x20, x1
   221e0:	cbz	x1, 222f4 <__gmpq_cmp_ui@@Base+0x13c>
   221e4:	cmp	w0, #0x1
   221e8:	b.lt	22220 <__gmpq_cmp_ui@@Base+0x68>  // b.tstop
   221ec:	ldrsw	x21, [x22, #20]
   221f0:	cmp	x20, x2
   221f4:	sxtw	x19, w0
   221f8:	mov	x3, x2
   221fc:	cinc	x8, x21, hi  // hi = pmore
   22200:	cmp	x8, x19
   22204:	b.lt	222f4 <__gmpq_cmp_ui@@Base+0x13c>  // b.tstop
   22208:	cmp	x3, x20
   2220c:	cinc	x8, x19, hi  // hi = pmore
   22210:	cmp	x8, x21
   22214:	b.ge	22228 <__gmpq_cmp_ui@@Base+0x70>  // b.tcont
   22218:	neg	w0, w0
   2221c:	b	222f4 <__gmpq_cmp_ui@@Base+0x13c>
   22220:	mov	w0, #0xffffffff            	// #-1
   22224:	b	222f4 <__gmpq_cmp_ui@@Base+0x13c>
   22228:	add	x24, x19, #0x1
   2222c:	add	x8, x21, x24
   22230:	lsl	x8, x8, #3
   22234:	add	x1, x8, #0x8
   22238:	mov	w8, #0x7f00                	// #32512
   2223c:	cmp	x1, x8
   22240:	str	xzr, [x29, #24]
   22244:	b.hi	22310 <__gmpq_cmp_ui@@Base+0x158>  // b.pmore
   22248:	add	x9, x1, #0xf
   2224c:	mov	x8, sp
   22250:	and	x9, x9, #0xfffffffffffffff0
   22254:	sub	x23, x8, x9
   22258:	mov	sp, x23
   2225c:	ldr	x1, [x22, #8]
   22260:	mov	x0, x23
   22264:	mov	x2, x19
   22268:	add	x24, x23, x24, lsl #3
   2226c:	bl	d4b0 <__gmpn_mul_1@plt>
   22270:	str	x0, [x23, x19, lsl #3]
   22274:	ldr	x1, [x22, #24]
   22278:	cmp	x0, #0x0
   2227c:	mov	x0, x24
   22280:	mov	x2, x21
   22284:	mov	x3, x20
   22288:	cset	w25, ne  // ne = any
   2228c:	cinc	x22, x19, ne  // ne = any
   22290:	bl	d4b0 <__gmpn_mul_1@plt>
   22294:	cmp	x0, #0x0
   22298:	cset	w9, ne  // ne = any
   2229c:	sub	w10, w22, w21
   222a0:	mov	x8, x0
   222a4:	subs	w0, w10, w9
   222a8:	str	x8, [x24, x21, lsl #3]
   222ac:	b.ne	222ec <__gmpq_cmp_ui@@Base+0x134>  // b.any
   222b0:	lsl	x8, x25, #3
   222b4:	bfi	x8, x19, #4, #60
   222b8:	add	x8, x23, x8
   222bc:	sub	x9, x23, #0x8
   222c0:	subs	x10, x22, #0x1
   222c4:	b.lt	222e8 <__gmpq_cmp_ui@@Base+0x130>  // b.tstop
   222c8:	ldr	x11, [x9, x22, lsl #3]
   222cc:	ldr	x12, [x8], #-8
   222d0:	mov	x22, x10
   222d4:	cmp	x11, x12
   222d8:	b.eq	222c0 <__gmpq_cmp_ui@@Base+0x108>  // b.none
   222dc:	mov	w8, #0x1                   	// #1
   222e0:	cneg	w0, w8, ls  // ls = plast
   222e4:	b	222ec <__gmpq_cmp_ui@@Base+0x134>
   222e8:	mov	w0, wzr
   222ec:	ldr	x8, [x29, #24]
   222f0:	cbnz	x8, 22328 <__gmpq_cmp_ui@@Base+0x170>
   222f4:	mov	sp, x29
   222f8:	ldp	x20, x19, [sp, #64]
   222fc:	ldp	x22, x21, [sp, #48]
   22300:	ldp	x24, x23, [sp, #32]
   22304:	ldr	x25, [sp, #16]
   22308:	ldp	x29, x30, [sp], #80
   2230c:	ret
   22310:	add	x0, x29, #0x18
   22314:	mov	x23, x3
   22318:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2231c:	mov	x3, x23
   22320:	mov	x23, x0
   22324:	b	2225c <__gmpq_cmp_ui@@Base+0xa4>
   22328:	mov	x19, x0
   2232c:	mov	x0, x8
   22330:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   22334:	mov	x0, x19
   22338:	b	222f4 <__gmpq_cmp_ui@@Base+0x13c>
   2233c:	bl	bfe0 <__gmp_divide_by_zero@plt>

0000000000022340 <__gmpq_div@@Base>:
   22340:	stp	x29, x30, [sp, #-80]!
   22344:	str	x25, [sp, #16]
   22348:	stp	x24, x23, [sp, #32]
   2234c:	stp	x22, x21, [sp, #48]
   22350:	stp	x20, x19, [sp, #64]
   22354:	mov	x29, sp
   22358:	sub	sp, sp, #0x40
   2235c:	ldrsw	x8, [x2, #4]
   22360:	cbz	w8, 225f0 <__gmpq_div@@Base+0x2b0>
   22364:	mov	x20, x2
   22368:	mov	x21, x1
   2236c:	mov	x19, x0
   22370:	cmp	x0, x2
   22374:	b.eq	22558 <__gmpq_div@@Base+0x218>  // b.none
   22378:	ldr	w9, [x21, #4]
   2237c:	cmp	w9, #0x0
   22380:	cneg	w22, w9, mi  // mi = first
   22384:	cbz	w22, 22518 <__gmpq_div@@Base+0x1d8>
   22388:	cmp	x8, #0x0
   2238c:	cneg	x23, x8, mi  // mi = first
   22390:	cmp	x23, x22
   22394:	csel	x8, x22, x23, gt
   22398:	cmp	x8, #0xfe0
   2239c:	lsl	x1, x8, #3
   223a0:	str	xzr, [x29, #24]
   223a4:	stur	w8, [x29, #-16]
   223a8:	b.hi	225a0 <__gmpq_div@@Base+0x260>  // b.pmore
   223ac:	add	x9, x1, #0xf
   223b0:	mov	x8, sp
   223b4:	and	x9, x9, #0xfffffffffffffff0
   223b8:	sub	x0, x8, x9
   223bc:	mov	sp, x0
   223c0:	cmp	x23, x22
   223c4:	csel	x8, x22, x23, lt  // lt = tstop
   223c8:	cmp	x8, #0xfe0
   223cc:	lsl	x1, x8, #3
   223d0:	stur	x0, [x29, #-8]
   223d4:	stur	w8, [x29, #-48]
   223d8:	b.hi	225ac <__gmpq_div@@Base+0x26c>  // b.pmore
   223dc:	add	x9, x1, #0xf
   223e0:	mov	x8, sp
   223e4:	and	x9, x9, #0xfffffffffffffff0
   223e8:	sub	x0, x8, x9
   223ec:	mov	sp, x0
   223f0:	stur	x0, [x29, #-40]
   223f4:	ldrsw	x24, [x20, #20]
   223f8:	ldrsw	x25, [x21, #20]
   223fc:	mov	w9, #0x7f00                	// #32512
   22400:	add	x23, x20, #0x10
   22404:	add	x22, x21, #0x10
   22408:	cmp	x25, x24
   2240c:	csel	x8, x25, x24, lt  // lt = tstop
   22410:	lsl	x1, x8, #3
   22414:	cmp	x1, x9
   22418:	stur	w8, [x29, #-32]
   2241c:	b.hi	225b8 <__gmpq_div@@Base+0x278>  // b.pmore
   22420:	add	x9, x1, #0xf
   22424:	mov	x8, sp
   22428:	and	x9, x9, #0xfffffffffffffff0
   2242c:	sub	x0, x8, x9
   22430:	mov	sp, x0
   22434:	cmp	x25, x24
   22438:	csel	x8, x25, x24, gt
   2243c:	lsl	x1, x8, #3
   22440:	mov	w9, #0x7f00                	// #32512
   22444:	cmp	x1, x9
   22448:	stur	x0, [x29, #-24]
   2244c:	stur	w8, [x29, #-64]
   22450:	b.hi	225c4 <__gmpq_div@@Base+0x284>  // b.pmore
   22454:	add	x9, x1, #0xf
   22458:	mov	x8, sp
   2245c:	and	x9, x9, #0xfffffffffffffff0
   22460:	sub	x0, x8, x9
   22464:	mov	sp, x0
   22468:	stur	x0, [x29, #-56]
   2246c:	sub	x0, x29, #0x10
   22470:	mov	x1, x21
   22474:	mov	x2, x20
   22478:	bl	cf90 <__gmpz_gcd@plt>
   2247c:	sub	x0, x29, #0x20
   22480:	mov	x1, x23
   22484:	mov	x2, x22
   22488:	bl	cf90 <__gmpz_gcd@plt>
   2248c:	sub	x0, x29, #0x30
   22490:	sub	x2, x29, #0x10
   22494:	mov	x1, x21
   22498:	bl	ca20 <__gmpz_divexact_gcd@plt>
   2249c:	sub	x0, x29, #0x40
   224a0:	sub	x2, x29, #0x20
   224a4:	mov	x1, x23
   224a8:	bl	ca20 <__gmpz_divexact_gcd@plt>
   224ac:	sub	x1, x29, #0x30
   224b0:	sub	x2, x29, #0x40
   224b4:	mov	x0, x19
   224b8:	bl	c4d0 <__gmpz_mul@plt>
   224bc:	sub	x0, x29, #0x30
   224c0:	sub	x2, x29, #0x10
   224c4:	mov	x1, x20
   224c8:	bl	ca20 <__gmpz_divexact_gcd@plt>
   224cc:	sub	x0, x29, #0x40
   224d0:	sub	x2, x29, #0x20
   224d4:	mov	x1, x22
   224d8:	bl	ca20 <__gmpz_divexact_gcd@plt>
   224dc:	add	x0, x19, #0x10
   224e0:	sub	x1, x29, #0x30
   224e4:	sub	x2, x29, #0x40
   224e8:	bl	c4d0 <__gmpz_mul@plt>
   224ec:	ldr	w8, [x19, #20]
   224f0:	tbz	w8, #31, 22508 <__gmpq_div@@Base+0x1c8>
   224f4:	ldr	w9, [x19, #4]
   224f8:	neg	w8, w8
   224fc:	str	w8, [x19, #20]
   22500:	neg	w8, w9
   22504:	str	w8, [x19, #4]
   22508:	ldr	x0, [x29, #24]
   2250c:	cbz	x0, 2253c <__gmpq_div@@Base+0x1fc>
   22510:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   22514:	b	2253c <__gmpq_div@@Base+0x1fc>
   22518:	mov	x0, x19
   2251c:	ldr	w8, [x0, #16]!
   22520:	cmp	w8, #0x0
   22524:	stur	wzr, [x0, #-12]
   22528:	b.le	225d0 <__gmpq_div@@Base+0x290>
   2252c:	ldr	x0, [x19, #24]
   22530:	mov	w8, #0x1                   	// #1
   22534:	str	x8, [x0]
   22538:	str	w8, [x19, #20]
   2253c:	mov	sp, x29
   22540:	ldp	x20, x19, [sp, #64]
   22544:	ldp	x22, x21, [sp, #48]
   22548:	ldp	x24, x23, [sp, #32]
   2254c:	ldr	x25, [sp, #16]
   22550:	ldp	x29, x30, [sp], #80
   22554:	ret
   22558:	cmp	x21, x20
   2255c:	b.eq	225dc <__gmpq_div@@Base+0x29c>  // b.none
   22560:	ldr	x9, [x20, #8]
   22564:	ldp	w12, w13, [x20, #16]
   22568:	ldr	x10, [x20, #24]
   2256c:	ldr	w11, [x20]
   22570:	cmp	w8, #0x0
   22574:	cneg	w8, w8, le
   22578:	str	x9, [x20, #24]
   2257c:	cneg	w9, w13, le
   22580:	mov	x0, x20
   22584:	mov	x1, x20
   22588:	mov	x2, x21
   2258c:	str	x10, [x20, #8]
   22590:	stp	w11, w8, [x20, #16]
   22594:	stp	w12, w9, [x20]
   22598:	bl	d000 <__gmpq_mul@plt>
   2259c:	b	2253c <__gmpq_div@@Base+0x1fc>
   225a0:	add	x0, x29, #0x18
   225a4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   225a8:	b	223c0 <__gmpq_div@@Base+0x80>
   225ac:	add	x0, x29, #0x18
   225b0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   225b4:	b	223f0 <__gmpq_div@@Base+0xb0>
   225b8:	add	x0, x29, #0x18
   225bc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   225c0:	b	22434 <__gmpq_div@@Base+0xf4>
   225c4:	add	x0, x29, #0x18
   225c8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   225cc:	b	22468 <__gmpq_div@@Base+0x128>
   225d0:	mov	w1, #0x1                   	// #1
   225d4:	bl	c090 <__gmpz_realloc@plt>
   225d8:	b	22530 <__gmpq_div@@Base+0x1f0>
   225dc:	mov	w1, #0x1                   	// #1
   225e0:	mov	w2, #0x1                   	// #1
   225e4:	mov	x0, x20
   225e8:	bl	ca80 <__gmpq_set_ui@plt>
   225ec:	b	2253c <__gmpq_div@@Base+0x1fc>
   225f0:	bl	bfe0 <__gmp_divide_by_zero@plt>

00000000000225f4 <__gmpq_get_d@@Base>:
   225f4:	str	d8, [sp, #-96]!
   225f8:	stp	x29, x30, [sp, #8]
   225fc:	str	x27, [sp, #24]
   22600:	stp	x26, x25, [sp, #32]
   22604:	stp	x24, x23, [sp, #48]
   22608:	stp	x22, x21, [sp, #64]
   2260c:	stp	x20, x19, [sp, #80]
   22610:	mov	x29, sp
   22614:	sub	sp, sp, #0x20
   22618:	ldrsw	x19, [x0, #4]
   2261c:	cbz	w19, 2274c <__gmpq_get_d@@Base+0x158>
   22620:	ldrsw	x8, [x0, #20]
   22624:	cmp	x19, #0x0
   22628:	stur	xzr, [x29, #-32]
   2262c:	cneg	x24, x19, mi  // mi = first
   22630:	cmp	x8, #0x0
   22634:	ldr	x25, [x0, #8]
   22638:	ldr	x21, [x0, #24]
   2263c:	cneg	x22, x8, mi  // mi = first
   22640:	mov	x9, #0xfffffffffffffffe    	// #-2
   22644:	sub	x8, x22, x24
   22648:	sub	x9, x9, x8
   2264c:	cmn	x8, #0x1
   22650:	lsl	x20, x9, #6
   22654:	b.lt	226b0 <__gmpq_get_d@@Base+0xbc>  // b.tstop
   22658:	add	x27, x8, #0x2
   2265c:	lsl	x8, x22, #3
   22660:	cmp	x22, #0xfdd
   22664:	add	x1, x8, #0x18
   22668:	b.hi	2275c <__gmpq_get_d@@Base+0x168>  // b.pmore
   2266c:	add	x9, x1, #0xf
   22670:	mov	x8, sp
   22674:	and	x9, x9, #0xfffffffffffffff0
   22678:	sub	x23, x8, x9
   2267c:	mov	sp, x23
   22680:	add	x26, x22, #0x2
   22684:	sub	x8, x26, x24
   22688:	lsl	x2, x8, #3
   2268c:	mov	x0, x23
   22690:	mov	w1, wzr
   22694:	bl	c610 <memset@plt>
   22698:	add	x0, x23, x27, lsl #3
   2269c:	mov	x1, x25
   226a0:	mov	x2, x24
   226a4:	bl	ca70 <__gmpn_copyi@plt>
   226a8:	mov	x24, x23
   226ac:	b	226dc <__gmpq_get_d@@Base+0xe8>
   226b0:	lsl	x8, x22, #3
   226b4:	add	x24, x25, x9, lsl #3
   226b8:	cmp	x22, #0xfdd
   226bc:	add	x1, x8, #0x18
   226c0:	b.hi	2276c <__gmpq_get_d@@Base+0x178>  // b.pmore
   226c4:	add	x9, x1, #0xf
   226c8:	mov	x8, sp
   226cc:	and	x9, x9, #0xfffffffffffffff0
   226d0:	sub	x23, x8, x9
   226d4:	mov	sp, x23
   226d8:	add	x26, x22, #0x2
   226dc:	sub	x0, x29, #0x18
   226e0:	mov	x1, x24
   226e4:	mov	x2, x26
   226e8:	mov	x3, x21
   226ec:	mov	x4, x22
   226f0:	mov	x5, x23
   226f4:	bl	c340 <__gmpn_div_q@plt>
   226f8:	ldur	x8, [x29, #-8]
   226fc:	sub	x0, x29, #0x18
   22700:	mov	x2, x19
   22704:	mov	x3, x20
   22708:	cmp	x8, #0x0
   2270c:	mov	w8, #0x2                   	// #2
   22710:	cinc	x1, x8, ne  // ne = any
   22714:	bl	bf50 <__gmpn_get_d@plt>
   22718:	ldur	x0, [x29, #-32]
   2271c:	mov	v8.16b, v0.16b
   22720:	cbnz	x0, 22754 <__gmpq_get_d@@Base+0x160>
   22724:	mov	v0.16b, v8.16b
   22728:	mov	sp, x29
   2272c:	ldp	x20, x19, [sp, #80]
   22730:	ldp	x22, x21, [sp, #64]
   22734:	ldp	x24, x23, [sp, #48]
   22738:	ldp	x26, x25, [sp, #32]
   2273c:	ldr	x27, [sp, #24]
   22740:	ldp	x29, x30, [sp, #8]
   22744:	ldr	d8, [sp], #96
   22748:	ret
   2274c:	fmov	d8, xzr
   22750:	b	22724 <__gmpq_get_d@@Base+0x130>
   22754:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   22758:	b	22724 <__gmpq_get_d@@Base+0x130>
   2275c:	sub	x0, x29, #0x20
   22760:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   22764:	mov	x23, x0
   22768:	b	22680 <__gmpq_get_d@@Base+0x8c>
   2276c:	sub	x0, x29, #0x20
   22770:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   22774:	mov	x23, x0
   22778:	b	226d8 <__gmpq_get_d@@Base+0xe4>

000000000002277c <__gmpq_get_den@@Base>:
   2277c:	stp	x29, x30, [sp, #-48]!
   22780:	stp	x22, x21, [sp, #16]
   22784:	stp	x20, x19, [sp, #32]
   22788:	ldr	w22, [x1, #20]
   2278c:	ldr	w8, [x0]
   22790:	mov	x19, x1
   22794:	mov	x20, x0
   22798:	sxtw	x21, w22
   2279c:	cmp	w22, w8
   227a0:	mov	x29, sp
   227a4:	b.gt	227c8 <__gmpq_get_den@@Base+0x4c>
   227a8:	ldr	x0, [x20, #8]
   227ac:	str	w22, [x20, #4]
   227b0:	ldr	x1, [x19, #24]
   227b4:	mov	x2, x21
   227b8:	ldp	x20, x19, [sp, #32]
   227bc:	ldp	x22, x21, [sp, #16]
   227c0:	ldp	x29, x30, [sp], #48
   227c4:	b	ca70 <__gmpn_copyi@plt>
   227c8:	mov	x0, x20
   227cc:	mov	x1, x21
   227d0:	bl	c090 <__gmpz_realloc@plt>
   227d4:	b	227ac <__gmpq_get_den@@Base+0x30>

00000000000227d8 <__gmpq_get_num@@Base>:
   227d8:	stp	x29, x30, [sp, #-48]!
   227dc:	stp	x22, x21, [sp, #16]
   227e0:	stp	x20, x19, [sp, #32]
   227e4:	ldrsw	x22, [x1, #4]
   227e8:	ldrsw	x8, [x0]
   227ec:	mov	x19, x1
   227f0:	mov	x20, x0
   227f4:	cmp	x22, #0x0
   227f8:	cneg	x21, x22, mi  // mi = first
   227fc:	cmp	x21, x8
   22800:	mov	x29, sp
   22804:	b.gt	22828 <__gmpq_get_num@@Base+0x50>
   22808:	ldr	x0, [x20, #8]
   2280c:	str	w22, [x20, #4]
   22810:	ldr	x1, [x19, #8]
   22814:	mov	x2, x21
   22818:	ldp	x20, x19, [sp, #32]
   2281c:	ldp	x22, x21, [sp, #16]
   22820:	ldp	x29, x30, [sp], #48
   22824:	b	ca70 <__gmpn_copyi@plt>
   22828:	mov	x0, x20
   2282c:	mov	x1, x21
   22830:	bl	c090 <__gmpz_realloc@plt>
   22834:	b	2280c <__gmpq_get_num@@Base+0x34>

0000000000022838 <__gmpq_get_str@@Base>:
   22838:	stp	x29, x30, [sp, #-64]!
   2283c:	add	w8, w1, #0x24
   22840:	cmp	w8, #0x62
   22844:	str	x23, [sp, #16]
   22848:	stp	x22, x21, [sp, #32]
   2284c:	stp	x20, x19, [sp, #48]
   22850:	mov	x29, sp
   22854:	b.ls	22860 <__gmpq_get_str@@Base+0x28>  // b.plast
   22858:	mov	x19, xzr
   2285c:	b	22950 <__gmpq_get_str@@Base+0x118>
   22860:	mov	x21, x2
   22864:	mov	w20, w1
   22868:	mov	x19, x0
   2286c:	cbz	x0, 22878 <__gmpq_get_str@@Base+0x40>
   22870:	mov	x22, xzr
   22874:	b	228e0 <__gmpq_get_str@@Base+0xa8>
   22878:	cmp	w20, #0x0
   2287c:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   22880:	cneg	w11, w20, mi  // mi = first
   22884:	mov	w8, #0xa                   	// #10
   22888:	ldr	x9, [x9, #3936]
   2288c:	cmp	w11, #0x2
   22890:	csel	w20, w8, w20, lt  // lt = tstop
   22894:	ldr	w11, [x21, #4]
   22898:	cmp	w20, #0x0
   2289c:	mov	w10, #0x28                  	// #40
   228a0:	cneg	w8, w20, mi  // mi = first
   228a4:	umaddl	x8, w8, w10, x9
   228a8:	ldr	w9, [x21, #20]
   228ac:	cmp	w11, #0x0
   228b0:	cneg	w10, w11, mi  // mi = first
   228b4:	ldr	x8, [x8, #8]
   228b8:	add	w9, w10, w9
   228bc:	adrp	x10, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   228c0:	ldr	x10, [x10, #3840]
   228c4:	sbfiz	x9, x9, #6, #32
   228c8:	umulh	x8, x8, x9
   228cc:	add	x22, x8, #0x6
   228d0:	ldr	x10, [x10]
   228d4:	mov	x0, x22
   228d8:	blr	x10
   228dc:	mov	x19, x0
   228e0:	mov	x0, x19
   228e4:	mov	w1, w20
   228e8:	mov	x2, x21
   228ec:	bl	c3c0 <__gmpz_get_str@plt>
   228f0:	mov	x0, x19
   228f4:	bl	bf70 <strlen@plt>
   228f8:	ldr	w8, [x21, #20]
   228fc:	cmp	w8, #0x1
   22900:	b.ne	22914 <__gmpq_get_str@@Base+0xdc>  // b.any
   22904:	ldr	x8, [x21, #24]
   22908:	ldr	x8, [x8]
   2290c:	cmp	x8, #0x1
   22910:	b.eq	22940 <__gmpq_get_str@@Base+0x108>  // b.none
   22914:	add	x23, x0, #0x1
   22918:	add	x2, x21, #0x10
   2291c:	mov	w8, #0x2f                  	// #47
   22920:	add	x21, x19, x23
   22924:	strb	w8, [x19, x0]
   22928:	mov	x0, x21
   2292c:	mov	w1, w20
   22930:	bl	c3c0 <__gmpz_get_str@plt>
   22934:	mov	x0, x21
   22938:	bl	bf70 <strlen@plt>
   2293c:	add	x0, x0, x23
   22940:	cbz	x22, 22950 <__gmpq_get_str@@Base+0x118>
   22944:	add	x2, x0, #0x1
   22948:	cmp	x22, x2
   2294c:	b.ne	22968 <__gmpq_get_str@@Base+0x130>  // b.any
   22950:	mov	x0, x19
   22954:	ldp	x20, x19, [sp, #48]
   22958:	ldp	x22, x21, [sp, #32]
   2295c:	ldr	x23, [sp, #16]
   22960:	ldp	x29, x30, [sp], #64
   22964:	ret
   22968:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2296c:	ldr	x8, [x8, #3792]
   22970:	mov	x0, x19
   22974:	mov	x1, x22
   22978:	ldp	x20, x19, [sp, #48]
   2297c:	ldr	x3, [x8]
   22980:	ldp	x22, x21, [sp, #32]
   22984:	ldr	x23, [sp, #16]
   22988:	ldp	x29, x30, [sp], #64
   2298c:	br	x3

0000000000022990 <__gmpq_init@@Base>:
   22990:	stp	x29, x30, [sp, #-32]!
   22994:	adrp	x8, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   22998:	stp	x20, x19, [sp, #16]
   2299c:	add	x8, x8, #0x3c8
   229a0:	mov	w20, #0x1                   	// #1
   229a4:	stp	xzr, x8, [x0]
   229a8:	str	w20, [x0, #16]
   229ac:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   229b0:	ldr	x8, [x8, #3840]
   229b4:	mov	x19, x0
   229b8:	mov	w0, #0x8                   	// #8
   229bc:	mov	x29, sp
   229c0:	ldr	x8, [x8]
   229c4:	blr	x8
   229c8:	str	x0, [x19, #24]
   229cc:	str	x20, [x0]
   229d0:	str	w20, [x19, #20]
   229d4:	ldp	x20, x19, [sp, #16]
   229d8:	ldp	x29, x30, [sp], #32
   229dc:	ret

00000000000229e0 <__gmpq_inits@@Base>:
   229e0:	sub	sp, sp, #0xf0
   229e4:	stp	x29, x30, [sp, #224]
   229e8:	add	x29, sp, #0xe0
   229ec:	mov	x8, #0xffffffffffffffc8    	// #-56
   229f0:	mov	x9, sp
   229f4:	sub	x10, x29, #0x58
   229f8:	movk	x8, #0xff80, lsl #32
   229fc:	add	x11, x29, #0x10
   22a00:	add	x9, x9, #0x80
   22a04:	add	x10, x10, #0x38
   22a08:	stp	x1, x2, [x29, #-88]
   22a0c:	stp	x3, x4, [x29, #-72]
   22a10:	stp	x5, x6, [x29, #-56]
   22a14:	stur	x7, [x29, #-40]
   22a18:	stp	q0, q1, [sp]
   22a1c:	stp	q2, q3, [sp, #32]
   22a20:	stp	q4, q5, [sp, #64]
   22a24:	stp	q6, q7, [sp, #96]
   22a28:	stp	x9, x8, [x29, #-16]
   22a2c:	stp	x11, x10, [x29, #-32]
   22a30:	bl	cdf0 <__gmpq_init@plt>
   22a34:	ldursw	x8, [x29, #-8]
   22a38:	tbz	w8, #31, 22a58 <__gmpq_inits@@Base+0x78>
   22a3c:	add	w9, w8, #0x8
   22a40:	cmn	w8, #0x8
   22a44:	stur	w9, [x29, #-8]
   22a48:	b.gt	22a58 <__gmpq_inits@@Base+0x78>
   22a4c:	ldur	x9, [x29, #-24]
   22a50:	add	x8, x9, x8
   22a54:	b	22a64 <__gmpq_inits@@Base+0x84>
   22a58:	ldur	x8, [x29, #-32]
   22a5c:	add	x9, x8, #0x8
   22a60:	stur	x9, [x29, #-32]
   22a64:	ldr	x0, [x8]
   22a68:	cbnz	x0, 22a30 <__gmpq_inits@@Base+0x50>
   22a6c:	ldp	x29, x30, [sp, #224]
   22a70:	add	sp, sp, #0xf0
   22a74:	ret

0000000000022a78 <__gmpq_inp_str@@Base>:
   22a78:	stp	x29, x30, [sp, #-64]!
   22a7c:	str	x23, [sp, #16]
   22a80:	stp	x22, x21, [sp, #32]
   22a84:	stp	x20, x19, [sp, #48]
   22a88:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   22a8c:	ldr	x8, [x8, #3888]
   22a90:	mov	x22, x0
   22a94:	cmp	x1, #0x0
   22a98:	mov	w20, w2
   22a9c:	ldr	x8, [x8]
   22aa0:	ldr	w9, [x22, #16]!
   22aa4:	mov	x19, x0
   22aa8:	mov	w10, #0x1                   	// #1
   22aac:	csel	x21, x8, x1, eq  // eq = none
   22ab0:	cmp	w9, #0x0
   22ab4:	mov	x29, sp
   22ab8:	str	w10, [x22, #4]
   22abc:	b.le	22b54 <__gmpq_inp_str@@Base+0xdc>
   22ac0:	ldr	x0, [x19, #24]
   22ac4:	mov	w8, #0x1                   	// #1
   22ac8:	str	x8, [x0]
   22acc:	mov	x0, x19
   22ad0:	mov	x1, x21
   22ad4:	mov	w2, w20
   22ad8:	bl	d0f0 <__gmpz_inp_str@plt>
   22adc:	mov	x23, x0
   22ae0:	cbz	x0, 22b3c <__gmpq_inp_str@@Base+0xc4>
   22ae4:	mov	x0, x21
   22ae8:	bl	c810 <getc@plt>
   22aec:	cmp	w0, #0x2f
   22af0:	b.ne	22b34 <__gmpq_inp_str@@Base+0xbc>  // b.any
   22af4:	mov	x0, x21
   22af8:	bl	c810 <getc@plt>
   22afc:	mov	w3, w0
   22b00:	add	x4, x23, #0x2
   22b04:	mov	x0, x22
   22b08:	mov	x1, x21
   22b0c:	mov	w2, w20
   22b10:	bl	c9f0 <__gmpz_inp_str_nowhite@plt>
   22b14:	mov	x23, x0
   22b18:	cbnz	x0, 22b3c <__gmpq_inp_str@@Base+0xc4>
   22b1c:	ldr	x8, [x19, #24]
   22b20:	mov	w9, #0x1                   	// #1
   22b24:	str	wzr, [x19, #4]
   22b28:	str	w9, [x19, #20]
   22b2c:	str	x9, [x8]
   22b30:	b	22b3c <__gmpq_inp_str@@Base+0xc4>
   22b34:	mov	x1, x21
   22b38:	bl	cc70 <ungetc@plt>
   22b3c:	mov	x0, x23
   22b40:	ldp	x20, x19, [sp, #48]
   22b44:	ldp	x22, x21, [sp, #32]
   22b48:	ldr	x23, [sp, #16]
   22b4c:	ldp	x29, x30, [sp], #64
   22b50:	ret
   22b54:	mov	w1, #0x1                   	// #1
   22b58:	mov	x0, x22
   22b5c:	bl	c090 <__gmpz_realloc@plt>
   22b60:	b	22ac4 <__gmpq_inp_str@@Base+0x4c>

0000000000022b64 <__gmpq_inv@@Base>:
   22b64:	stp	x29, x30, [sp, #-64]!
   22b68:	stp	x22, x21, [sp, #32]
   22b6c:	stp	x20, x19, [sp, #48]
   22b70:	ldrsw	x20, [x1, #4]
   22b74:	ldrsw	x8, [x1, #20]
   22b78:	mov	x19, x1
   22b7c:	mov	x21, x0
   22b80:	str	x23, [sp, #16]
   22b84:	mov	x29, sp
   22b88:	tbnz	w20, #31, 22b94 <__gmpq_inv@@Base+0x30>
   22b8c:	cbnz	w20, 22b9c <__gmpq_inv@@Base+0x38>
   22b90:	bl	bfe0 <__gmp_divide_by_zero@plt>
   22b94:	neg	x20, x20
   22b98:	neg	x8, x8
   22b9c:	add	x22, x21, #0x10
   22ba0:	cmp	x21, x19
   22ba4:	str	w20, [x21, #20]
   22ba8:	str	w8, [x21, #4]
   22bac:	b.eq	22c00 <__gmpq_inv@@Base+0x9c>  // b.none
   22bb0:	ldrsw	x9, [x21]
   22bb4:	cmp	x8, #0x0
   22bb8:	cneg	x23, x8, mi  // mi = first
   22bbc:	cmp	x23, x9
   22bc0:	b.gt	22c34 <__gmpq_inv@@Base+0xd0>
   22bc4:	ldr	x0, [x21, #8]
   22bc8:	ldr	x1, [x19, #24]
   22bcc:	mov	x2, x23
   22bd0:	bl	ca70 <__gmpn_copyi@plt>
   22bd4:	ldrsw	x8, [x22]
   22bd8:	cmp	x20, x8
   22bdc:	b.gt	22c44 <__gmpq_inv@@Base+0xe0>
   22be0:	ldr	x0, [x21, #24]
   22be4:	ldr	x1, [x19, #8]
   22be8:	mov	x2, x20
   22bec:	ldp	x20, x19, [sp, #48]
   22bf0:	ldp	x22, x21, [sp, #32]
   22bf4:	ldr	x23, [sp, #16]
   22bf8:	ldp	x29, x30, [sp], #64
   22bfc:	b	ca70 <__gmpn_copyi@plt>
   22c00:	ldr	x8, [x19, #24]
   22c04:	ldr	x9, [x19, #8]
   22c08:	ldr	x23, [sp, #16]
   22c0c:	str	x8, [x19, #8]
   22c10:	str	x9, [x19, #24]
   22c14:	ldr	w8, [x22]
   22c18:	ldr	w9, [x19]
   22c1c:	str	w8, [x19]
   22c20:	str	w9, [x22]
   22c24:	ldp	x20, x19, [sp, #48]
   22c28:	ldp	x22, x21, [sp, #32]
   22c2c:	ldp	x29, x30, [sp], #64
   22c30:	ret
   22c34:	mov	x0, x21
   22c38:	mov	x1, x23
   22c3c:	bl	c090 <__gmpz_realloc@plt>
   22c40:	b	22bc8 <__gmpq_inv@@Base+0x64>
   22c44:	mov	x0, x22
   22c48:	mov	x1, x20
   22c4c:	bl	c090 <__gmpz_realloc@plt>
   22c50:	b	22be4 <__gmpq_inv@@Base+0x80>

0000000000022c54 <__gmpq_mul_2exp@@Base>:
   22c54:	mov	x8, x1
   22c58:	add	x1, x0, #0x10
   22c5c:	add	x3, x8, #0x10
   22c60:	mov	x4, x2
   22c64:	mov	x2, x8
   22c68:	b	22c6c <__gmpq_mul_2exp@@Base+0x18>
   22c6c:	stp	x29, x30, [sp, #-96]!
   22c70:	stp	x28, x27, [sp, #16]
   22c74:	stp	x26, x25, [sp, #32]
   22c78:	stp	x24, x23, [sp, #48]
   22c7c:	stp	x22, x21, [sp, #64]
   22c80:	stp	x20, x19, [sp, #80]
   22c84:	ldr	x8, [x3, #8]
   22c88:	ldrsw	x27, [x3, #4]
   22c8c:	mov	x20, x4
   22c90:	mov	x19, x2
   22c94:	ldr	x26, [x8]
   22c98:	cmp	x27, #0x0
   22c9c:	cneg	x9, x27, mi  // mi = first
   22ca0:	mov	x21, x1
   22ca4:	cmp	x26, #0x0
   22ca8:	cset	w28, eq  // eq = none
   22cac:	cmp	x4, #0x40
   22cb0:	mov	x22, x0
   22cb4:	mov	x29, sp
   22cb8:	b.cc	22ce4 <__gmpq_mul_2exp@@Base+0x90>  // b.lo, b.ul, b.last
   22cbc:	cbnz	x26, 22ce4 <__gmpq_mul_2exp@@Base+0x90>
   22cc0:	mov	x23, x8
   22cc4:	ldr	x26, [x23, #8]!
   22cc8:	sub	x20, x20, #0x40
   22ccc:	cmp	x26, #0x0
   22cd0:	cset	w28, eq  // eq = none
   22cd4:	cmp	x20, #0x40
   22cd8:	b.cc	22ce8 <__gmpq_mul_2exp@@Base+0x94>  // b.lo, b.ul, b.last
   22cdc:	cbz	x26, 22cc4 <__gmpq_mul_2exp@@Base+0x70>
   22ce0:	b	22ce8 <__gmpq_mul_2exp@@Base+0x94>
   22ce4:	mov	x23, x8
   22ce8:	ldrsw	x10, [x21]
   22cec:	sub	x8, x23, x8
   22cf0:	sub	x24, x9, x8, asr #3
   22cf4:	cmp	x24, x10
   22cf8:	b.gt	22d50 <__gmpq_mul_2exp@@Base+0xfc>
   22cfc:	ldr	x25, [x21, #8]
   22d00:	cbz	x20, 22d64 <__gmpq_mul_2exp@@Base+0x110>
   22d04:	tbnz	w26, #0, 22d64 <__gmpq_mul_2exp@@Base+0x110>
   22d08:	rbit	x8, x26
   22d0c:	clz	x8, x8
   22d10:	cmp	x8, x20
   22d14:	csel	x8, x8, x20, cc  // cc = lo, ul, last
   22d18:	cmp	w28, #0x0
   22d1c:	csel	x26, x20, x8, ne  // ne = any
   22d20:	mov	x0, x25
   22d24:	mov	x1, x23
   22d28:	mov	x2, x24
   22d2c:	mov	w3, w26
   22d30:	bl	c1b0 <__gmpn_rshift@plt>
   22d34:	add	x8, x25, x24, lsl #3
   22d38:	ldur	x8, [x8, #-8]
   22d3c:	sub	x20, x20, x26
   22d40:	cmp	x8, #0x0
   22d44:	cset	w8, eq  // eq = none
   22d48:	sub	x24, x24, x8
   22d4c:	b	22d7c <__gmpq_mul_2exp@@Base+0x128>
   22d50:	mov	x0, x21
   22d54:	mov	x1, x24
   22d58:	bl	c090 <__gmpz_realloc@plt>
   22d5c:	mov	x25, x0
   22d60:	cbnz	x20, 22d04 <__gmpq_mul_2exp@@Base+0xb0>
   22d64:	cmp	x23, x25
   22d68:	b.eq	22d7c <__gmpq_mul_2exp@@Base+0x128>  // b.none
   22d6c:	mov	x0, x25
   22d70:	mov	x1, x23
   22d74:	mov	x2, x24
   22d78:	bl	ca70 <__gmpn_copyi@plt>
   22d7c:	neg	w8, w24
   22d80:	cmp	w27, #0x0
   22d84:	csel	x8, x24, x8, ge  // ge = tcont
   22d88:	str	w8, [x21, #4]
   22d8c:	cbz	x20, 22db8 <__gmpq_mul_2exp@@Base+0x164>
   22d90:	mov	x0, x22
   22d94:	mov	x1, x19
   22d98:	mov	x2, x20
   22d9c:	ldp	x20, x19, [sp, #80]
   22da0:	ldp	x22, x21, [sp, #64]
   22da4:	ldp	x24, x23, [sp, #48]
   22da8:	ldp	x26, x25, [sp, #32]
   22dac:	ldp	x28, x27, [sp, #16]
   22db0:	ldp	x29, x30, [sp], #96
   22db4:	b	c700 <__gmpz_mul_2exp@plt>
   22db8:	cmp	x22, x19
   22dbc:	b.eq	22de4 <__gmpq_mul_2exp@@Base+0x190>  // b.none
   22dc0:	mov	x0, x22
   22dc4:	mov	x1, x19
   22dc8:	ldp	x20, x19, [sp, #80]
   22dcc:	ldp	x22, x21, [sp, #64]
   22dd0:	ldp	x24, x23, [sp, #48]
   22dd4:	ldp	x26, x25, [sp, #32]
   22dd8:	ldp	x28, x27, [sp, #16]
   22ddc:	ldp	x29, x30, [sp], #96
   22de0:	b	c440 <__gmpz_set@plt>
   22de4:	ldp	x20, x19, [sp, #80]
   22de8:	ldp	x22, x21, [sp, #64]
   22dec:	ldp	x24, x23, [sp, #48]
   22df0:	ldp	x26, x25, [sp, #32]
   22df4:	ldp	x28, x27, [sp, #16]
   22df8:	ldp	x29, x30, [sp], #96
   22dfc:	ret

0000000000022e00 <__gmpq_div_2exp@@Base>:
   22e00:	stp	x29, x30, [sp, #-16]!
   22e04:	ldr	w8, [x1, #4]
   22e08:	mov	x3, x1
   22e0c:	mov	x1, x0
   22e10:	mov	x29, sp
   22e14:	cbz	w8, 22e2c <__gmpq_div_2exp@@Base+0x2c>
   22e18:	mov	x4, x2
   22e1c:	add	x0, x1, #0x10
   22e20:	add	x2, x3, #0x10
   22e24:	ldp	x29, x30, [sp], #16
   22e28:	b	22c6c <__gmpq_mul_2exp@@Base+0x18>
   22e2c:	mov	x0, x1
   22e30:	ldr	w8, [x0, #16]!
   22e34:	mov	w9, #0x1                   	// #1
   22e38:	cmp	w8, #0x0
   22e3c:	stur	wzr, [x0, #-12]
   22e40:	str	w9, [x0, #4]
   22e44:	b.le	22e5c <__gmpq_div_2exp@@Base+0x5c>
   22e48:	ldr	x0, [x1, #24]
   22e4c:	mov	w8, #0x1                   	// #1
   22e50:	str	x8, [x0]
   22e54:	ldp	x29, x30, [sp], #16
   22e58:	ret
   22e5c:	mov	w1, #0x1                   	// #1
   22e60:	bl	c090 <__gmpz_realloc@plt>
   22e64:	b	22e4c <__gmpq_div_2exp@@Base+0x4c>

0000000000022e68 <__gmpq_mul@@Base>:
   22e68:	stp	x29, x30, [sp, #-96]!
   22e6c:	str	x27, [sp, #16]
   22e70:	stp	x26, x25, [sp, #32]
   22e74:	stp	x24, x23, [sp, #48]
   22e78:	stp	x22, x21, [sp, #64]
   22e7c:	stp	x20, x19, [sp, #80]
   22e80:	mov	x29, sp
   22e84:	sub	sp, sp, #0x40
   22e88:	mov	x20, x1
   22e8c:	cmp	x1, x2
   22e90:	mov	x19, x0
   22e94:	b.eq	23028 <__gmpq_mul@@Base+0x1c0>  // b.none
   22e98:	ldr	w8, [x20, #4]
   22e9c:	ldr	w9, [x2, #4]
   22ea0:	mov	x21, x2
   22ea4:	cmp	w8, #0x0
   22ea8:	cneg	w26, w8, mi  // mi = first
   22eac:	cmp	w9, #0x0
   22eb0:	cneg	w24, w9, mi  // mi = first
   22eb4:	cbz	w26, 2304c <__gmpq_mul@@Base+0x1e4>
   22eb8:	cbz	w24, 2304c <__gmpq_mul@@Base+0x1e4>
   22ebc:	ldrsw	x27, [x21, #20]
   22ec0:	ldrsw	x25, [x20, #20]
   22ec4:	mov	w9, #0x7f00                	// #32512
   22ec8:	str	xzr, [x29, #24]
   22ecc:	cmp	x26, x27
   22ed0:	csel	x8, x26, x27, lt  // lt = tstop
   22ed4:	lsl	x1, x8, #3
   22ed8:	cmp	x1, x9
   22edc:	stur	w8, [x29, #-16]
   22ee0:	b.hi	23090 <__gmpq_mul@@Base+0x228>  // b.pmore
   22ee4:	add	x9, x1, #0xf
   22ee8:	mov	x8, sp
   22eec:	and	x9, x9, #0xfffffffffffffff0
   22ef0:	sub	x0, x8, x9
   22ef4:	mov	sp, x0
   22ef8:	cmp	x24, x25
   22efc:	csel	x8, x24, x25, lt  // lt = tstop
   22f00:	lsl	x1, x8, #3
   22f04:	mov	w9, #0x7f00                	// #32512
   22f08:	cmp	x1, x9
   22f0c:	stur	x0, [x29, #-8]
   22f10:	stur	w8, [x29, #-32]
   22f14:	b.hi	2309c <__gmpq_mul@@Base+0x234>  // b.pmore
   22f18:	add	x9, x1, #0xf
   22f1c:	mov	x8, sp
   22f20:	and	x9, x9, #0xfffffffffffffff0
   22f24:	sub	x0, x8, x9
   22f28:	mov	sp, x0
   22f2c:	cmp	x26, x27
   22f30:	csel	x8, x26, x27, gt
   22f34:	add	x22, x20, #0x10
   22f38:	add	x23, x21, #0x10
   22f3c:	cmp	x8, #0xfe0
   22f40:	lsl	x1, x8, #3
   22f44:	stur	x0, [x29, #-24]
   22f48:	stur	w8, [x29, #-48]
   22f4c:	b.hi	230a8 <__gmpq_mul@@Base+0x240>  // b.pmore
   22f50:	add	x9, x1, #0xf
   22f54:	mov	x8, sp
   22f58:	and	x9, x9, #0xfffffffffffffff0
   22f5c:	sub	x0, x8, x9
   22f60:	mov	sp, x0
   22f64:	cmp	x24, x25
   22f68:	csel	x8, x24, x25, gt
   22f6c:	cmp	x8, #0xfe0
   22f70:	lsl	x1, x8, #3
   22f74:	stur	x0, [x29, #-40]
   22f78:	stur	w8, [x29, #-64]
   22f7c:	b.hi	230b4 <__gmpq_mul@@Base+0x24c>  // b.pmore
   22f80:	add	x9, x1, #0xf
   22f84:	mov	x8, sp
   22f88:	and	x9, x9, #0xfffffffffffffff0
   22f8c:	sub	x0, x8, x9
   22f90:	mov	sp, x0
   22f94:	stur	x0, [x29, #-56]
   22f98:	sub	x0, x29, #0x10
   22f9c:	mov	x1, x20
   22fa0:	mov	x2, x23
   22fa4:	bl	cf90 <__gmpz_gcd@plt>
   22fa8:	sub	x0, x29, #0x20
   22fac:	mov	x1, x21
   22fb0:	mov	x2, x22
   22fb4:	bl	cf90 <__gmpz_gcd@plt>
   22fb8:	sub	x0, x29, #0x30
   22fbc:	sub	x2, x29, #0x10
   22fc0:	mov	x1, x20
   22fc4:	bl	ca20 <__gmpz_divexact_gcd@plt>
   22fc8:	sub	x0, x29, #0x40
   22fcc:	sub	x2, x29, #0x20
   22fd0:	mov	x1, x21
   22fd4:	bl	ca20 <__gmpz_divexact_gcd@plt>
   22fd8:	sub	x1, x29, #0x30
   22fdc:	sub	x2, x29, #0x40
   22fe0:	mov	x0, x19
   22fe4:	bl	c4d0 <__gmpz_mul@plt>
   22fe8:	sub	x0, x29, #0x30
   22fec:	sub	x2, x29, #0x10
   22ff0:	mov	x1, x23
   22ff4:	bl	ca20 <__gmpz_divexact_gcd@plt>
   22ff8:	sub	x0, x29, #0x40
   22ffc:	sub	x2, x29, #0x20
   23000:	mov	x1, x22
   23004:	bl	ca20 <__gmpz_divexact_gcd@plt>
   23008:	add	x0, x19, #0x10
   2300c:	sub	x1, x29, #0x30
   23010:	sub	x2, x29, #0x40
   23014:	bl	c4d0 <__gmpz_mul@plt>
   23018:	ldr	x0, [x29, #24]
   2301c:	cbz	x0, 23070 <__gmpq_mul@@Base+0x208>
   23020:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   23024:	b	23070 <__gmpq_mul@@Base+0x208>
   23028:	mov	x0, x19
   2302c:	mov	x1, x20
   23030:	mov	x2, x20
   23034:	bl	c4d0 <__gmpz_mul@plt>
   23038:	add	x1, x20, #0x10
   2303c:	add	x0, x19, #0x10
   23040:	mov	x2, x1
   23044:	bl	c4d0 <__gmpz_mul@plt>
   23048:	b	23070 <__gmpq_mul@@Base+0x208>
   2304c:	mov	x0, x19
   23050:	ldr	w8, [x0, #16]!
   23054:	cmp	w8, #0x0
   23058:	stur	wzr, [x0, #-12]
   2305c:	b.le	230c0 <__gmpq_mul@@Base+0x258>
   23060:	ldr	x0, [x19, #24]
   23064:	mov	w8, #0x1                   	// #1
   23068:	str	x8, [x0]
   2306c:	str	w8, [x19, #20]
   23070:	mov	sp, x29
   23074:	ldp	x20, x19, [sp, #80]
   23078:	ldp	x22, x21, [sp, #64]
   2307c:	ldp	x24, x23, [sp, #48]
   23080:	ldp	x26, x25, [sp, #32]
   23084:	ldr	x27, [sp, #16]
   23088:	ldp	x29, x30, [sp], #96
   2308c:	ret
   23090:	add	x0, x29, #0x18
   23094:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   23098:	b	22ef8 <__gmpq_mul@@Base+0x90>
   2309c:	add	x0, x29, #0x18
   230a0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   230a4:	b	22f2c <__gmpq_mul@@Base+0xc4>
   230a8:	add	x0, x29, #0x18
   230ac:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   230b0:	b	22f64 <__gmpq_mul@@Base+0xfc>
   230b4:	add	x0, x29, #0x18
   230b8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   230bc:	b	22f94 <__gmpq_mul@@Base+0x12c>
   230c0:	mov	w1, #0x1                   	// #1
   230c4:	bl	c090 <__gmpz_realloc@plt>
   230c8:	b	23064 <__gmpq_mul@@Base+0x1fc>

00000000000230cc <__gmpq_neg@@Base>:
   230cc:	stp	x29, x30, [sp, #-64]!
   230d0:	stp	x22, x21, [sp, #32]
   230d4:	stp	x20, x19, [sp, #48]
   230d8:	ldrsw	x22, [x1, #4]
   230dc:	mov	x19, x0
   230e0:	cmp	x1, x0
   230e4:	str	x23, [sp, #16]
   230e8:	mov	x29, sp
   230ec:	b.eq	23144 <__gmpq_neg@@Base+0x78>  // b.none
   230f0:	ldrsw	x8, [x19]
   230f4:	cmp	x22, #0x0
   230f8:	cneg	x21, x22, mi  // mi = first
   230fc:	mov	x20, x1
   23100:	cmp	x21, x8
   23104:	b.gt	23160 <__gmpq_neg@@Base+0x94>
   23108:	ldr	x0, [x19, #8]
   2310c:	ldr	x1, [x20, #8]
   23110:	mov	x2, x21
   23114:	bl	ca70 <__gmpn_copyi@plt>
   23118:	mov	x0, x19
   2311c:	ldr	w23, [x20, #20]
   23120:	ldr	w8, [x0, #16]!
   23124:	sxtw	x21, w23
   23128:	cmp	w23, w8
   2312c:	b.gt	23170 <__gmpq_neg@@Base+0xa4>
   23130:	ldr	x0, [x19, #24]
   23134:	str	w23, [x19, #20]
   23138:	ldr	x1, [x20, #24]
   2313c:	mov	x2, x21
   23140:	bl	ca70 <__gmpn_copyi@plt>
   23144:	neg	w8, w22
   23148:	str	w8, [x19, #4]
   2314c:	ldp	x20, x19, [sp, #48]
   23150:	ldp	x22, x21, [sp, #32]
   23154:	ldr	x23, [sp, #16]
   23158:	ldp	x29, x30, [sp], #64
   2315c:	ret
   23160:	mov	x0, x19
   23164:	mov	x1, x21
   23168:	bl	c090 <__gmpz_realloc@plt>
   2316c:	b	2310c <__gmpq_neg@@Base+0x40>
   23170:	mov	x1, x21
   23174:	bl	c090 <__gmpz_realloc@plt>
   23178:	b	23134 <__gmpq_neg@@Base+0x68>

000000000002317c <__gmpq_out_str@@Base>:
   2317c:	stp	x29, x30, [sp, #-48]!
   23180:	stp	x22, x21, [sp, #16]
   23184:	stp	x20, x19, [sp, #32]
   23188:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2318c:	ldr	x8, [x8, #3856]
   23190:	cmp	x0, #0x0
   23194:	mov	x29, sp
   23198:	mov	x22, x2
   2319c:	ldr	x8, [x8]
   231a0:	mov	w21, w1
   231a4:	csel	x19, x8, x0, eq  // eq = none
   231a8:	mov	x0, x19
   231ac:	bl	c560 <__gmpz_out_str@plt>
   231b0:	add	x22, x22, #0x10
   231b4:	mov	x20, x0
   231b8:	mov	w1, #0x1                   	// #1
   231bc:	mov	x0, x22
   231c0:	bl	d210 <__gmpz_cmp_ui@plt>
   231c4:	cbz	w0, 231ec <__gmpq_out_str@@Base+0x70>
   231c8:	mov	w0, #0x2f                  	// #47
   231cc:	mov	x1, x19
   231d0:	bl	c1f0 <putc@plt>
   231d4:	mov	x0, x19
   231d8:	mov	w1, w21
   231dc:	mov	x2, x22
   231e0:	bl	c560 <__gmpz_out_str@plt>
   231e4:	add	x8, x20, x0
   231e8:	add	x20, x8, #0x1
   231ec:	mov	x0, x19
   231f0:	bl	d4c0 <ferror@plt>
   231f4:	cmp	w0, #0x0
   231f8:	csel	x0, x20, xzr, eq  // eq = none
   231fc:	ldp	x20, x19, [sp, #32]
   23200:	ldp	x22, x21, [sp, #16]
   23204:	ldp	x29, x30, [sp], #48
   23208:	ret

000000000002320c <__gmpq_set@@Base>:
   2320c:	stp	x29, x30, [sp, #-48]!
   23210:	stp	x20, x19, [sp, #32]
   23214:	ldrsw	x8, [x1, #4]
   23218:	ldrsw	x9, [x0]
   2321c:	str	x21, [sp, #16]
   23220:	mov	x19, x1
   23224:	cmp	x8, #0x0
   23228:	cneg	x21, x8, mi  // mi = first
   2322c:	mov	x20, x0
   23230:	cmp	x21, x9
   23234:	mov	x29, sp
   23238:	str	w8, [x0, #4]
   2323c:	b.gt	23284 <__gmpq_set@@Base+0x78>
   23240:	ldr	x0, [x20, #8]
   23244:	ldr	x1, [x19, #8]
   23248:	mov	x2, x21
   2324c:	bl	ca70 <__gmpn_copyi@plt>
   23250:	mov	x0, x20
   23254:	ldrsw	x21, [x19, #20]
   23258:	ldr	w8, [x0, #16]!
   2325c:	cmp	w21, w8
   23260:	str	w21, [x0, #4]
   23264:	b.gt	23294 <__gmpq_set@@Base+0x88>
   23268:	ldr	x0, [x20, #24]
   2326c:	ldr	x1, [x19, #24]
   23270:	mov	x2, x21
   23274:	ldp	x20, x19, [sp, #32]
   23278:	ldr	x21, [sp, #16]
   2327c:	ldp	x29, x30, [sp], #48
   23280:	b	ca70 <__gmpn_copyi@plt>
   23284:	mov	x0, x20
   23288:	mov	x1, x21
   2328c:	bl	c090 <__gmpz_realloc@plt>
   23290:	b	23244 <__gmpq_set@@Base+0x38>
   23294:	mov	x1, x21
   23298:	bl	c090 <__gmpz_realloc@plt>
   2329c:	b	2326c <__gmpq_set@@Base+0x60>

00000000000232a0 <__gmpq_set_den@@Base>:
   232a0:	stp	x29, x30, [sp, #-32]!
   232a4:	stp	x20, x19, [sp, #16]
   232a8:	ldrsw	x9, [x1, #4]
   232ac:	mov	x8, x0
   232b0:	ldrsw	x10, [x8, #16]!
   232b4:	mov	x19, x1
   232b8:	cmp	x9, #0x0
   232bc:	cneg	x20, x9, mi  // mi = first
   232c0:	cmp	x20, x10
   232c4:	mov	x29, sp
   232c8:	str	w9, [x8, #4]
   232cc:	b.gt	232e8 <__gmpq_set_den@@Base+0x48>
   232d0:	ldr	x0, [x0, #24]
   232d4:	ldr	x1, [x19, #8]
   232d8:	mov	x2, x20
   232dc:	ldp	x20, x19, [sp, #16]
   232e0:	ldp	x29, x30, [sp], #32
   232e4:	b	ca70 <__gmpn_copyi@plt>
   232e8:	mov	x0, x8
   232ec:	mov	x1, x20
   232f0:	bl	c090 <__gmpz_realloc@plt>
   232f4:	b	232d4 <__gmpq_set_den@@Base+0x34>

00000000000232f8 <__gmpq_set_num@@Base>:
   232f8:	stp	x29, x30, [sp, #-32]!
   232fc:	stp	x20, x19, [sp, #16]
   23300:	ldrsw	x8, [x1, #4]
   23304:	ldrsw	x9, [x0]
   23308:	mov	x19, x1
   2330c:	mov	x29, sp
   23310:	cmp	x8, #0x0
   23314:	cneg	x20, x8, mi  // mi = first
   23318:	cmp	x20, x9
   2331c:	str	w8, [x0, #4]
   23320:	b.gt	2333c <__gmpq_set_num@@Base+0x44>
   23324:	ldr	x0, [x0, #8]
   23328:	ldr	x1, [x19, #8]
   2332c:	mov	x2, x20
   23330:	ldp	x20, x19, [sp, #16]
   23334:	ldp	x29, x30, [sp], #32
   23338:	b	ca70 <__gmpn_copyi@plt>
   2333c:	mov	x1, x20
   23340:	bl	c090 <__gmpz_realloc@plt>
   23344:	b	23328 <__gmpq_set_num@@Base+0x30>

0000000000023348 <__gmpq_set_si@@Base>:
   23348:	stp	x29, x30, [sp, #-48]!
   2334c:	stp	x20, x19, [sp, #32]
   23350:	mov	x19, x0
   23354:	stp	x22, x21, [sp, #16]
   23358:	mov	x29, sp
   2335c:	cbz	x1, 23394 <__gmpq_set_si@@Base+0x4c>
   23360:	ldr	w8, [x19]
   23364:	cmp	x1, #0x0
   23368:	mov	x20, x2
   2336c:	mov	x21, x1
   23370:	cneg	x22, x1, mi  // mi = first
   23374:	cmp	w8, #0x0
   23378:	b.le	233e0 <__gmpq_set_si@@Base+0x98>
   2337c:	ldr	x0, [x19, #8]
   23380:	cmp	x21, #0x0
   23384:	mov	w8, #0x1                   	// #1
   23388:	cneg	w8, w8, le
   2338c:	str	x22, [x0]
   23390:	b	2339c <__gmpq_set_si@@Base+0x54>
   23394:	mov	w8, wzr
   23398:	mov	w20, #0x1                   	// #1
   2339c:	mov	x0, x19
   233a0:	ldr	w9, [x0, #16]!
   233a4:	cmp	w9, #0x0
   233a8:	stur	w8, [x0, #-12]
   233ac:	b.le	233d4 <__gmpq_set_si@@Base+0x8c>
   233b0:	ldr	x0, [x19, #24]
   233b4:	cmp	x20, #0x0
   233b8:	cset	w8, ne  // ne = any
   233bc:	str	x20, [x0]
   233c0:	str	w8, [x19, #20]
   233c4:	ldp	x20, x19, [sp, #32]
   233c8:	ldp	x22, x21, [sp, #16]
   233cc:	ldp	x29, x30, [sp], #48
   233d0:	ret
   233d4:	mov	w1, #0x1                   	// #1
   233d8:	bl	c090 <__gmpz_realloc@plt>
   233dc:	b	233b4 <__gmpq_set_si@@Base+0x6c>
   233e0:	mov	w1, #0x1                   	// #1
   233e4:	mov	x0, x19
   233e8:	bl	c090 <__gmpz_realloc@plt>
   233ec:	b	23380 <__gmpq_set_si@@Base+0x38>

00000000000233f0 <__gmpq_set_str@@Base>:
   233f0:	stp	x29, x30, [sp, #-80]!
   233f4:	stp	x22, x21, [sp, #48]
   233f8:	mov	x21, x1
   233fc:	stp	x20, x19, [sp, #64]
   23400:	mov	x20, x0
   23404:	mov	w1, #0x2f                  	// #47
   23408:	mov	x0, x21
   2340c:	str	x25, [sp, #16]
   23410:	stp	x24, x23, [sp, #32]
   23414:	mov	x29, sp
   23418:	mov	w19, w2
   2341c:	bl	cdc0 <strchr@plt>
   23420:	cbz	x0, 234a4 <__gmpq_set_str@@Base+0xb4>
   23424:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   23428:	ldr	x8, [x8, #3840]
   2342c:	sub	x23, x0, x21
   23430:	add	x24, x23, #0x1
   23434:	mov	x22, x0
   23438:	ldr	x8, [x8]
   2343c:	mov	x0, x24
   23440:	blr	x8
   23444:	mov	x1, x21
   23448:	mov	x2, x23
   2344c:	mov	x25, x0
   23450:	bl	bee0 <memcpy@plt>
   23454:	mov	x0, x20
   23458:	mov	x1, x25
   2345c:	mov	w2, w19
   23460:	strb	wzr, [x25, x23]
   23464:	bl	c0e0 <__gmpz_set_str@plt>
   23468:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2346c:	ldr	x8, [x8, #4016]
   23470:	mov	w21, w0
   23474:	mov	x0, x25
   23478:	mov	x1, x24
   2347c:	ldr	x8, [x8]
   23480:	blr	x8
   23484:	cbz	w21, 234d4 <__gmpq_set_str@@Base+0xe4>
   23488:	mov	w0, w21
   2348c:	ldp	x20, x19, [sp, #64]
   23490:	ldp	x22, x21, [sp, #48]
   23494:	ldp	x24, x23, [sp, #32]
   23498:	ldr	x25, [sp, #16]
   2349c:	ldp	x29, x30, [sp], #80
   234a0:	ret
   234a4:	mov	x0, x20
   234a8:	ldr	w8, [x0, #16]!
   234ac:	mov	w9, #0x1                   	// #1
   234b0:	cmp	w8, #0x0
   234b4:	str	w9, [x0, #4]
   234b8:	b.le	234f8 <__gmpq_set_str@@Base+0x108>
   234bc:	ldr	x0, [x20, #24]
   234c0:	mov	w8, #0x1                   	// #1
   234c4:	str	x8, [x0]
   234c8:	mov	x0, x20
   234cc:	mov	x1, x21
   234d0:	b	234dc <__gmpq_set_str@@Base+0xec>
   234d4:	add	x0, x20, #0x10
   234d8:	add	x1, x22, #0x1
   234dc:	mov	w2, w19
   234e0:	ldp	x20, x19, [sp, #64]
   234e4:	ldp	x22, x21, [sp, #48]
   234e8:	ldp	x24, x23, [sp, #32]
   234ec:	ldr	x25, [sp, #16]
   234f0:	ldp	x29, x30, [sp], #80
   234f4:	b	c0e0 <__gmpz_set_str@plt>
   234f8:	mov	w1, #0x1                   	// #1
   234fc:	bl	c090 <__gmpz_realloc@plt>
   23500:	b	234c0 <__gmpq_set_str@@Base+0xd0>

0000000000023504 <__gmpq_set_ui@@Base>:
   23504:	stp	x29, x30, [sp, #-48]!
   23508:	stp	x20, x19, [sp, #32]
   2350c:	mov	x19, x0
   23510:	str	x21, [sp, #16]
   23514:	mov	x29, sp
   23518:	cbz	x1, 23540 <__gmpq_set_ui@@Base+0x3c>
   2351c:	ldr	w8, [x19]
   23520:	mov	x20, x2
   23524:	mov	x21, x1
   23528:	cmp	w8, #0x0
   2352c:	b.le	2358c <__gmpq_set_ui@@Base+0x88>
   23530:	ldr	x0, [x19, #8]
   23534:	mov	w8, #0x1                   	// #1
   23538:	str	x21, [x0]
   2353c:	b	23548 <__gmpq_set_ui@@Base+0x44>
   23540:	mov	w8, wzr
   23544:	mov	w20, #0x1                   	// #1
   23548:	mov	x0, x19
   2354c:	ldr	w9, [x0, #16]!
   23550:	cmp	w9, #0x0
   23554:	stur	w8, [x0, #-12]
   23558:	b.le	23580 <__gmpq_set_ui@@Base+0x7c>
   2355c:	ldr	x0, [x19, #24]
   23560:	cmp	x20, #0x0
   23564:	cset	w8, ne  // ne = any
   23568:	str	x20, [x0]
   2356c:	str	w8, [x19, #20]
   23570:	ldp	x20, x19, [sp, #32]
   23574:	ldr	x21, [sp, #16]
   23578:	ldp	x29, x30, [sp], #48
   2357c:	ret
   23580:	mov	w1, #0x1                   	// #1
   23584:	bl	c090 <__gmpz_realloc@plt>
   23588:	b	23560 <__gmpq_set_ui@@Base+0x5c>
   2358c:	mov	w1, #0x1                   	// #1
   23590:	mov	x0, x19
   23594:	bl	c090 <__gmpz_realloc@plt>
   23598:	b	23534 <__gmpq_set_ui@@Base+0x30>

000000000002359c <__gmpq_equal@@Base>:
   2359c:	ldrsw	x9, [x0, #4]
   235a0:	ldr	w8, [x1, #4]
   235a4:	cmp	w9, w8
   235a8:	b.ne	2362c <__gmpq_equal@@Base+0x90>  // b.any
   235ac:	ldrsw	x8, [x0, #20]
   235b0:	ldr	w10, [x1, #20]
   235b4:	cmp	w8, w10
   235b8:	b.ne	2362c <__gmpq_equal@@Base+0x90>  // b.any
   235bc:	cmp	x9, #0x0
   235c0:	cneg	x9, x9, mi  // mi = first
   235c4:	cmp	x9, #0x1
   235c8:	b.lt	235f4 <__gmpq_equal@@Base+0x58>  // b.tstop
   235cc:	ldr	x10, [x0, #8]
   235d0:	ldr	x11, [x1, #8]
   235d4:	ldr	x12, [x10]
   235d8:	ldr	x13, [x11]
   235dc:	cmp	x12, x13
   235e0:	b.ne	2362c <__gmpq_equal@@Base+0x90>  // b.any
   235e4:	subs	x9, x9, #0x1
   235e8:	add	x11, x11, #0x8
   235ec:	add	x10, x10, #0x8
   235f0:	b.ne	235d4 <__gmpq_equal@@Base+0x38>  // b.any
   235f4:	cmp	w8, #0x1
   235f8:	b.lt	23624 <__gmpq_equal@@Base+0x88>  // b.tstop
   235fc:	ldr	x9, [x0, #24]
   23600:	ldr	x10, [x1, #24]
   23604:	ldr	x11, [x9]
   23608:	ldr	x12, [x10]
   2360c:	cmp	x11, x12
   23610:	b.ne	2362c <__gmpq_equal@@Base+0x90>  // b.any
   23614:	subs	x8, x8, #0x1
   23618:	add	x10, x10, #0x8
   2361c:	add	x9, x9, #0x8
   23620:	b.ne	23604 <__gmpq_equal@@Base+0x68>  // b.any
   23624:	mov	w0, #0x1                   	// #1
   23628:	ret
   2362c:	mov	w0, wzr
   23630:	ret

0000000000023634 <__gmpq_set_z@@Base>:
   23634:	stp	x29, x30, [sp, #-48]!
   23638:	stp	x20, x19, [sp, #32]
   2363c:	ldrsw	x8, [x1, #4]
   23640:	ldrsw	x9, [x0]
   23644:	str	x21, [sp, #16]
   23648:	mov	x20, x1
   2364c:	cmp	x8, #0x0
   23650:	cneg	x21, x8, mi  // mi = first
   23654:	mov	x19, x0
   23658:	cmp	x21, x9
   2365c:	mov	x29, sp
   23660:	str	w8, [x0, #4]
   23664:	b.gt	236a8 <__gmpq_set_z@@Base+0x74>
   23668:	ldr	x0, [x19, #8]
   2366c:	ldr	x1, [x20, #8]
   23670:	mov	x2, x21
   23674:	bl	ca70 <__gmpn_copyi@plt>
   23678:	mov	x0, x19
   2367c:	ldr	w8, [x0, #16]!
   23680:	cmp	w8, #0x0
   23684:	b.le	236b8 <__gmpq_set_z@@Base+0x84>
   23688:	ldr	x0, [x19, #24]
   2368c:	mov	w8, #0x1                   	// #1
   23690:	str	x8, [x0]
   23694:	str	w8, [x19, #20]
   23698:	ldp	x20, x19, [sp, #32]
   2369c:	ldr	x21, [sp, #16]
   236a0:	ldp	x29, x30, [sp], #48
   236a4:	ret
   236a8:	mov	x0, x19
   236ac:	mov	x1, x21
   236b0:	bl	c090 <__gmpz_realloc@plt>
   236b4:	b	2366c <__gmpq_set_z@@Base+0x38>
   236b8:	mov	w1, #0x1                   	// #1
   236bc:	bl	c090 <__gmpz_realloc@plt>
   236c0:	b	2368c <__gmpq_set_z@@Base+0x58>

00000000000236c4 <__gmpq_set_d@@Base>:
   236c4:	sub	sp, sp, #0x70
   236c8:	stp	d9, d8, [sp, #16]
   236cc:	mov	v8.16b, v0.16b
   236d0:	fmov	x8, d8
   236d4:	mvn	x8, x8
   236d8:	tst	x8, #0x7ff0000000000000
   236dc:	stp	x29, x30, [sp, #32]
   236e0:	str	x25, [sp, #48]
   236e4:	stp	x24, x23, [sp, #64]
   236e8:	stp	x22, x21, [sp, #80]
   236ec:	stp	x20, x19, [sp, #96]
   236f0:	add	x29, sp, #0x10
   236f4:	b.eq	23904 <__gmpq_set_d@@Base+0x240>  // b.none
   236f8:	fneg	d0, d8
   236fc:	fcmp	d8, #0.0
   23700:	fcsel	d9, d8, d0, ge  // ge = tcont
   23704:	mov	x19, x0
   23708:	mov	x0, sp
   2370c:	mov	v0.16b, v9.16b
   23710:	bl	d2a0 <__gmp_extract_double@plt>
   23714:	cmp	w0, #0x1
   23718:	sxtw	x20, w0
   2371c:	b.gt	23754 <__gmpq_set_d@@Base+0x90>
   23720:	fcmp	d9, #0.0
   23724:	b.ne	237b4 <__gmpq_set_d@@Base+0xf0>  // b.any
   23728:	mov	x0, x19
   2372c:	ldr	w8, [x0, #16]!
   23730:	mov	w9, #0x1                   	// #1
   23734:	cmp	w8, #0x0
   23738:	stur	wzr, [x0, #-12]
   2373c:	str	w9, [x0, #4]
   23740:	b.le	238d4 <__gmpq_set_d@@Base+0x210>
   23744:	ldr	x0, [x19, #24]
   23748:	mov	w8, #0x1                   	// #1
   2374c:	str	x8, [x0]
   23750:	b	23894 <__gmpq_set_d@@Base+0x1d0>
   23754:	ldr	w8, [x19]
   23758:	cmp	w20, w8
   2375c:	b.gt	238b4 <__gmpq_set_d@@Base+0x1f0>
   23760:	ldr	x21, [x19, #8]
   23764:	cmp	w20, #0x2
   23768:	b.eq	2378c <__gmpq_set_d@@Base+0xc8>  // b.none
   2376c:	subs	x22, x20, #0x2
   23770:	b.eq	23788 <__gmpq_set_d@@Base+0xc4>  // b.none
   23774:	lsl	x8, x20, #3
   23778:	sub	x2, x8, #0x10
   2377c:	mov	x0, x21
   23780:	mov	w1, wzr
   23784:	bl	c610 <memset@plt>
   23788:	add	x21, x21, x22, lsl #3
   2378c:	ldr	q0, [sp]
   23790:	mov	x0, x19
   23794:	str	q0, [x21]
   23798:	ldr	w8, [x0, #16]!
   2379c:	cmp	w8, #0x0
   237a0:	b.le	238c8 <__gmpq_set_d@@Base+0x204>
   237a4:	ldr	x0, [x19, #24]
   237a8:	mov	w25, #0x1                   	// #1
   237ac:	str	x25, [x0]
   237b0:	b	23880 <__gmpq_set_d@@Base+0x1bc>
   237b4:	ldr	w8, [x19]
   237b8:	cmp	w8, #0x1
   237bc:	b.le	238e0 <__gmpq_set_d@@Base+0x21c>
   237c0:	ldr	x22, [x19, #8]
   237c4:	ldp	x9, x8, [sp]
   237c8:	cbz	x9, 237dc <__gmpq_set_d@@Base+0x118>
   237cc:	str	x8, [x22, #8]
   237d0:	mov	w21, #0x2                   	// #2
   237d4:	mov	x8, x9
   237d8:	b	237e0 <__gmpq_set_d@@Base+0x11c>
   237dc:	mov	w21, #0x1                   	// #1
   237e0:	str	x8, [x22]
   237e4:	mov	x0, x19
   237e8:	ldrsw	x8, [x0, #16]!
   237ec:	sub	x24, x21, x20
   237f0:	add	x20, x24, #0x1
   237f4:	cmp	x20, x8
   237f8:	b.gt	238f4 <__gmpq_set_d@@Base+0x230>
   237fc:	ldr	x23, [x19, #24]
   23800:	subs	x25, x20, #0x1
   23804:	b.eq	23818 <__gmpq_set_d@@Base+0x154>  // b.none
   23808:	lsl	x2, x24, #3
   2380c:	mov	x0, x23
   23810:	mov	w1, wzr
   23814:	bl	c610 <memset@plt>
   23818:	mov	w8, #0x1                   	// #1
   2381c:	str	x8, [x23, x25, lsl #3]
   23820:	ldr	x8, [x22]
   23824:	ldr	x9, [x23]
   23828:	orr	x8, x9, x8
   2382c:	rbit	x8, x8
   23830:	clz	x24, x8
   23834:	cbz	w24, 23878 <__gmpq_set_d@@Base+0x1b4>
   23838:	mov	x0, x22
   2383c:	mov	x1, x22
   23840:	mov	x2, x21
   23844:	mov	w3, w24
   23848:	bl	c1b0 <__gmpn_rshift@plt>
   2384c:	add	x8, x22, x21, lsl #3
   23850:	ldur	x8, [x8, #-8]
   23854:	neg	x9, x24
   23858:	mov	w10, #0x1                   	// #1
   2385c:	add	x11, x23, x20, lsl #3
   23860:	cmp	x8, #0x0
   23864:	cset	w8, eq  // eq = none
   23868:	lsl	x9, x10, x9
   2386c:	sub	x21, x21, x8
   23870:	stur	x9, [x11, #-16]
   23874:	b	2387c <__gmpq_set_d@@Base+0x1b8>
   23878:	mov	x25, x20
   2387c:	mov	x20, x21
   23880:	neg	w8, w20
   23884:	fcmp	d8, #0.0
   23888:	csel	x8, x8, x20, mi  // mi = first
   2388c:	str	w25, [x19, #20]
   23890:	str	w8, [x19, #4]
   23894:	ldp	x20, x19, [sp, #96]
   23898:	ldp	x22, x21, [sp, #80]
   2389c:	ldp	x24, x23, [sp, #64]
   238a0:	ldr	x25, [sp, #48]
   238a4:	ldp	x29, x30, [sp, #32]
   238a8:	ldp	d9, d8, [sp, #16]
   238ac:	add	sp, sp, #0x70
   238b0:	ret
   238b4:	mov	x0, x19
   238b8:	mov	x1, x20
   238bc:	bl	c090 <__gmpz_realloc@plt>
   238c0:	mov	x21, x0
   238c4:	b	23764 <__gmpq_set_d@@Base+0xa0>
   238c8:	mov	w1, #0x1                   	// #1
   238cc:	bl	c090 <__gmpz_realloc@plt>
   238d0:	b	237a8 <__gmpq_set_d@@Base+0xe4>
   238d4:	mov	w1, #0x1                   	// #1
   238d8:	bl	c090 <__gmpz_realloc@plt>
   238dc:	b	23748 <__gmpq_set_d@@Base+0x84>
   238e0:	mov	w1, #0x2                   	// #2
   238e4:	mov	x0, x19
   238e8:	bl	c090 <__gmpz_realloc@plt>
   238ec:	mov	x22, x0
   238f0:	b	237c4 <__gmpq_set_d@@Base+0x100>
   238f4:	mov	x1, x20
   238f8:	bl	c090 <__gmpz_realloc@plt>
   238fc:	mov	x23, x0
   23900:	b	23800 <__gmpq_set_d@@Base+0x13c>
   23904:	bl	c1c0 <__gmp_invalid_operation@plt>

0000000000023908 <__gmpq_set_f@@Base>:
   23908:	stp	x29, x30, [sp, #-96]!
   2390c:	stp	x26, x25, [sp, #32]
   23910:	stp	x24, x23, [sp, #48]
   23914:	stp	x22, x21, [sp, #64]
   23918:	stp	x20, x19, [sp, #80]
   2391c:	ldrsw	x26, [x1, #4]
   23920:	mov	x19, x0
   23924:	str	x27, [sp, #16]
   23928:	mov	x29, sp
   2392c:	cbz	w26, 239dc <__gmpq_set_f@@Base+0xd4>
   23930:	ldp	x21, x22, [x1, #8]
   23934:	cmp	w26, #0x0
   23938:	cneg	x20, x26, lt  // lt = tstop
   2393c:	ldr	x25, [x22]
   23940:	cbnz	x25, 23950 <__gmpq_set_f@@Base+0x48>
   23944:	ldr	x25, [x22, #8]!
   23948:	sub	x20, x20, #0x1
   2394c:	cbz	x25, 23944 <__gmpq_set_f@@Base+0x3c>
   23950:	subs	x27, x20, x21
   23954:	b.le	23a08 <__gmpq_set_f@@Base+0x100>
   23958:	ldrsw	x8, [x19]
   2395c:	cmp	x20, x8
   23960:	b.gt	23a7c <__gmpq_set_f@@Base+0x174>
   23964:	ldr	x24, [x19, #8]
   23968:	mov	x0, x19
   2396c:	ldrsw	x8, [x0, #16]!
   23970:	cmp	x27, x8
   23974:	b.ge	23a90 <__gmpq_set_f@@Base+0x188>  // b.tcont
   23978:	ldr	x23, [x19, #24]
   2397c:	tbnz	w25, #0, 23aa0 <__gmpq_set_f@@Base+0x198>
   23980:	rbit	x8, x25
   23984:	clz	x25, x8
   23988:	mov	x0, x24
   2398c:	mov	x1, x22
   23990:	mov	x2, x20
   23994:	mov	w3, w25
   23998:	sub	x27, x27, #0x1
   2399c:	bl	c1b0 <__gmpn_rshift@plt>
   239a0:	sub	x8, x20, #0x1
   239a4:	ldr	x9, [x24, x8, lsl #3]
   239a8:	cmp	x9, #0x0
   239ac:	cset	w9, eq  // eq = none
   239b0:	sub	x20, x20, x9
   239b4:	cbz	x27, 239cc <__gmpq_set_f@@Base+0xc4>
   239b8:	sub	x8, x8, x21
   239bc:	lsl	x2, x8, #3
   239c0:	mov	x0, x23
   239c4:	mov	w1, wzr
   239c8:	bl	c610 <memset@plt>
   239cc:	sub	w8, w25, #0x1
   239d0:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
   239d4:	lsr	x8, x9, x8
   239d8:	b	23ac8 <__gmpq_set_f@@Base+0x1c0>
   239dc:	mov	x0, x19
   239e0:	ldr	w8, [x0, #16]!
   239e4:	mov	w9, #0x1                   	// #1
   239e8:	cmp	w8, #0x0
   239ec:	stur	wzr, [x0, #-12]
   239f0:	str	w9, [x0, #4]
   239f4:	b.le	23a70 <__gmpq_set_f@@Base+0x168>
   239f8:	ldr	x0, [x19, #24]
   239fc:	mov	w8, #0x1                   	// #1
   23a00:	str	x8, [x0]
   23a04:	b	23ae4 <__gmpq_set_f@@Base+0x1dc>
   23a08:	ldrsw	x8, [x19]
   23a0c:	cmp	x21, x8
   23a10:	b.gt	23b00 <__gmpq_set_f@@Base+0x1f8>
   23a14:	ldr	x23, [x19, #8]
   23a18:	cmp	x20, x21
   23a1c:	b.eq	23a34 <__gmpq_set_f@@Base+0x12c>  // b.none
   23a20:	sub	x8, x21, x20
   23a24:	lsl	x2, x8, #3
   23a28:	mov	x0, x23
   23a2c:	mov	w1, wzr
   23a30:	bl	c610 <memset@plt>
   23a34:	add	x8, x23, x21, lsl #3
   23a38:	sub	x0, x8, x20, lsl #3
   23a3c:	mov	x1, x22
   23a40:	mov	x2, x20
   23a44:	bl	ca70 <__gmpn_copyi@plt>
   23a48:	mov	x0, x19
   23a4c:	ldr	w9, [x0, #16]!
   23a50:	neg	w8, w21
   23a54:	cmp	w26, #0x0
   23a58:	mov	w10, #0x1                   	// #1
   23a5c:	csel	x8, x21, x8, ge  // ge = tcont
   23a60:	cmp	w9, #0x0
   23a64:	stur	w8, [x0, #-12]
   23a68:	str	w10, [x0, #4]
   23a6c:	b.gt	239f8 <__gmpq_set_f@@Base+0xf0>
   23a70:	mov	w1, #0x1                   	// #1
   23a74:	bl	c090 <__gmpz_realloc@plt>
   23a78:	b	239fc <__gmpq_set_f@@Base+0xf4>
   23a7c:	mov	x0, x19
   23a80:	mov	x1, x20
   23a84:	bl	c090 <__gmpz_realloc@plt>
   23a88:	mov	x24, x0
   23a8c:	b	23968 <__gmpq_set_f@@Base+0x60>
   23a90:	add	x1, x27, #0x1
   23a94:	bl	c090 <__gmpz_realloc@plt>
   23a98:	mov	x23, x0
   23a9c:	tbz	w25, #0, 23980 <__gmpq_set_f@@Base+0x78>
   23aa0:	mov	x0, x24
   23aa4:	mov	x1, x22
   23aa8:	mov	x2, x20
   23aac:	bl	ca70 <__gmpn_copyi@plt>
   23ab0:	cbz	x27, 23ac4 <__gmpq_set_f@@Base+0x1bc>
   23ab4:	lsl	x2, x27, #3
   23ab8:	mov	x0, x23
   23abc:	mov	w1, wzr
   23ac0:	bl	c610 <memset@plt>
   23ac4:	mov	w8, #0x1                   	// #1
   23ac8:	str	x8, [x23, x27, lsl #3]
   23acc:	neg	w8, w20
   23ad0:	cmp	w26, #0x0
   23ad4:	add	w9, w27, #0x1
   23ad8:	csel	x8, x20, x8, ge  // ge = tcont
   23adc:	str	w8, [x19, #4]
   23ae0:	str	w9, [x19, #20]
   23ae4:	ldp	x20, x19, [sp, #80]
   23ae8:	ldp	x22, x21, [sp, #64]
   23aec:	ldp	x24, x23, [sp, #48]
   23af0:	ldp	x26, x25, [sp, #32]
   23af4:	ldr	x27, [sp, #16]
   23af8:	ldp	x29, x30, [sp], #96
   23afc:	ret
   23b00:	mov	x0, x19
   23b04:	mov	x1, x21
   23b08:	bl	c090 <__gmpz_realloc@plt>
   23b0c:	mov	x23, x0
   23b10:	b	23a18 <__gmpq_set_f@@Base+0x110>

0000000000023b14 <__gmpq_swap@@Base>:
   23b14:	ldr	w8, [x1]
   23b18:	ldr	w9, [x0]
   23b1c:	str	w8, [x0]
   23b20:	ldr	x8, [x1, #16]
   23b24:	str	w9, [x1]
   23b28:	ldr	x9, [x0, #16]
   23b2c:	ldr	w10, [x0, #4]
   23b30:	str	x8, [x0, #16]
   23b34:	ldr	w8, [x1, #4]
   23b38:	str	w8, [x0, #4]
   23b3c:	str	w10, [x1, #4]
   23b40:	str	x9, [x1, #16]
   23b44:	ldr	x8, [x1, #8]
   23b48:	ldr	x9, [x0, #8]
   23b4c:	str	x8, [x0, #8]
   23b50:	str	x9, [x1, #8]
   23b54:	ldr	x8, [x1, #24]
   23b58:	ldr	x9, [x0, #24]
   23b5c:	str	x8, [x0, #24]
   23b60:	str	x9, [x1, #24]
   23b64:	ret

0000000000023b68 <__gmpn_add@@Base>:
   23b68:	stp	x29, x30, [sp, #-48]!
   23b6c:	stp	x22, x21, [sp, #16]
   23b70:	stp	x20, x19, [sp, #32]
   23b74:	mov	x21, x2
   23b78:	mov	x19, x1
   23b7c:	mov	x20, x0
   23b80:	mov	x29, sp
   23b84:	cbz	x4, 23bcc <__gmpn_add@@Base+0x64>
   23b88:	mov	x0, x20
   23b8c:	mov	x1, x19
   23b90:	mov	x2, x3
   23b94:	mov	x3, x4
   23b98:	mov	x22, x4
   23b9c:	bl	ca90 <__gmpn_add_n@plt>
   23ba0:	cbz	x0, 23bd4 <__gmpn_add@@Base+0x6c>
   23ba4:	mov	w0, #0x1                   	// #1
   23ba8:	cmp	x22, x21
   23bac:	b.ge	23c0c <__gmpn_add@@Base+0xa4>  // b.tcont
   23bb0:	ldr	x8, [x19, x22, lsl #3]
   23bb4:	adds	x9, x8, #0x1
   23bb8:	add	x8, x22, #0x1
   23bbc:	str	x9, [x20, x22, lsl #3]
   23bc0:	mov	x22, x8
   23bc4:	b.cs	23ba8 <__gmpn_add@@Base+0x40>  // b.hs, b.nlast
   23bc8:	b	23bd8 <__gmpn_add@@Base+0x70>
   23bcc:	mov	x8, xzr
   23bd0:	b	23bd8 <__gmpn_add@@Base+0x70>
   23bd4:	mov	x8, x22
   23bd8:	cmp	x20, x19
   23bdc:	mov	x0, xzr
   23be0:	b.eq	23c0c <__gmpn_add@@Base+0xa4>  // b.none
   23be4:	cmp	x8, x21
   23be8:	b.ge	23c0c <__gmpn_add@@Base+0xa4>  // b.tcont
   23bec:	sub	x9, x21, x8
   23bf0:	add	x10, x20, x8, lsl #3
   23bf4:	add	x8, x19, x8, lsl #3
   23bf8:	ldr	x11, [x8], #8
   23bfc:	subs	x9, x9, #0x1
   23c00:	str	x11, [x10], #8
   23c04:	b.ne	23bf8 <__gmpn_add@@Base+0x90>  // b.any
   23c08:	mov	x0, xzr
   23c0c:	ldp	x20, x19, [sp, #32]
   23c10:	ldp	x22, x21, [sp, #16]
   23c14:	ldp	x29, x30, [sp], #48
   23c18:	ret

0000000000023c1c <__gmpn_add_1@@Base>:
   23c1c:	ldr	x8, [x1]
   23c20:	adds	x8, x8, x3
   23c24:	str	x8, [x0]
   23c28:	b.cc	23c90 <__gmpn_add_1@@Base+0x74>  // b.lo, b.ul, b.last
   23c2c:	mov	x10, #0xfffffffffffffff8    	// #-8
   23c30:	mov	w8, #0x1                   	// #1
   23c34:	mov	w9, #0x1                   	// #1
   23c38:	cmp	x9, x2
   23c3c:	b.ge	23cc0 <__gmpn_add_1@@Base+0xa4>  // b.tcont
   23c40:	ldr	x11, [x1, x9, lsl #3]
   23c44:	sub	x10, x10, #0x8
   23c48:	adds	x11, x11, #0x1
   23c4c:	str	x11, [x0, x9, lsl #3]
   23c50:	add	x9, x9, #0x1
   23c54:	b.cs	23c38 <__gmpn_add_1@@Base+0x1c>  // b.hs, b.nlast
   23c58:	cmp	x1, x0
   23c5c:	mov	x8, xzr
   23c60:	b.eq	23cc0 <__gmpn_add_1@@Base+0xa4>  // b.none
   23c64:	cmp	x9, x2
   23c68:	b.ge	23cc0 <__gmpn_add_1@@Base+0xa4>  // b.tcont
   23c6c:	sub	x8, x1, x10
   23c70:	sub	x10, x0, x10
   23c74:	ldr	x11, [x8], #8
   23c78:	sub	x2, x2, #0x1
   23c7c:	cmp	x9, x2
   23c80:	str	x11, [x10], #8
   23c84:	b.ne	23c74 <__gmpn_add_1@@Base+0x58>  // b.any
   23c88:	mov	x8, xzr
   23c8c:	b	23cc0 <__gmpn_add_1@@Base+0xa4>
   23c90:	cmp	x1, x0
   23c94:	mov	x8, xzr
   23c98:	b.eq	23cc0 <__gmpn_add_1@@Base+0xa4>  // b.none
   23c9c:	cmp	x2, #0x2
   23ca0:	b.lt	23cc0 <__gmpn_add_1@@Base+0xa4>  // b.tstop
   23ca4:	sub	x8, x2, #0x1
   23ca8:	add	x9, x0, #0x8
   23cac:	add	x10, x1, #0x8
   23cb0:	ldr	x11, [x10], #8
   23cb4:	subs	x8, x8, #0x1
   23cb8:	str	x11, [x9], #8
   23cbc:	b.ne	23cb0 <__gmpn_add_1@@Base+0x94>  // b.any
   23cc0:	mov	x0, x8
   23cc4:	ret
   23cc8:	nop
   23ccc:	nop

0000000000023cd0 <__gmpn_add_nc@@Base>:
   23cd0:	cmp	x4, #0x1
   23cd4:	b	23cdc <__gmpn_add_n@@Base+0x4>

0000000000023cd8 <__gmpn_add_n@@Base>:
   23cd8:	cmn	xzr, xzr
   23cdc:	lsr	x18, x3, #2
   23ce0:	tbz	w3, #0, 23d28 <__gmpn_add_n@@Base+0x50>
   23ce4:	ldr	x7, [x1]
   23ce8:	ldr	x11, [x2]
   23cec:	adcs	x13, x7, x11
   23cf0:	str	x13, [x0], #8
   23cf4:	tbnz	w3, #1, 23d10 <__gmpn_add_n@@Base+0x38>
   23cf8:	cbz	x18, 23d8c <__gmpn_add_n@@Base+0xb4>
   23cfc:	ldp	x4, x5, [x1, #8]
   23d00:	ldp	x8, x9, [x2, #8]
   23d04:	sub	x1, x1, #0x8
   23d08:	sub	x2, x2, #0x8
   23d0c:	b	23d64 <__gmpn_add_n@@Base+0x8c>
   23d10:	ldp	x6, x7, [x1, #8]
   23d14:	ldp	x10, x11, [x2, #8]
   23d18:	add	x1, x1, #0x8
   23d1c:	add	x2, x2, #0x8
   23d20:	cbz	x18, 23d80 <__gmpn_add_n@@Base+0xa8>
   23d24:	b	23d50 <__gmpn_add_n@@Base+0x78>
   23d28:	tbnz	w3, #1, 23d40 <__gmpn_add_n@@Base+0x68>
   23d2c:	ldp	x4, x5, [x1]
   23d30:	ldp	x8, x9, [x2]
   23d34:	sub	x1, x1, #0x10
   23d38:	sub	x2, x2, #0x10
   23d3c:	b	23d64 <__gmpn_add_n@@Base+0x8c>
   23d40:	ldp	x6, x7, [x1]
   23d44:	ldp	x10, x11, [x2]
   23d48:	cbz	x18, 23d80 <__gmpn_add_n@@Base+0xa8>
   23d4c:	nop
   23d50:	ldp	x4, x5, [x1, #16]
   23d54:	ldp	x8, x9, [x2, #16]
   23d58:	adcs	x12, x6, x10
   23d5c:	adcs	x13, x7, x11
   23d60:	stp	x12, x13, [x0], #16
   23d64:	ldp	x6, x7, [x1, #32]!
   23d68:	ldp	x10, x11, [x2, #32]!
   23d6c:	adcs	x12, x4, x8
   23d70:	adcs	x13, x5, x9
   23d74:	stp	x12, x13, [x0], #16
   23d78:	sub	x18, x18, #0x1
   23d7c:	cbnz	x18, 23d50 <__gmpn_add_n@@Base+0x78>
   23d80:	adcs	x12, x6, x10
   23d84:	adcs	x13, x7, x11
   23d88:	stp	x12, x13, [x0]
   23d8c:	cset	x0, cs  // cs = hs, nlast
   23d90:	ret

0000000000023d94 <__gmpn_sub@@Base>:
   23d94:	stp	x29, x30, [sp, #-48]!
   23d98:	stp	x22, x21, [sp, #16]
   23d9c:	stp	x20, x19, [sp, #32]
   23da0:	mov	x21, x2
   23da4:	mov	x19, x1
   23da8:	mov	x20, x0
   23dac:	mov	x29, sp
   23db0:	cbz	x4, 23df8 <__gmpn_sub@@Base+0x64>
   23db4:	mov	x0, x20
   23db8:	mov	x1, x19
   23dbc:	mov	x2, x3
   23dc0:	mov	x3, x4
   23dc4:	mov	x22, x4
   23dc8:	bl	c2e0 <__gmpn_sub_n@plt>
   23dcc:	cbz	x0, 23e00 <__gmpn_sub@@Base+0x6c>
   23dd0:	mov	w0, #0x1                   	// #1
   23dd4:	cmp	x22, x21
   23dd8:	b.ge	23e38 <__gmpn_sub@@Base+0xa4>  // b.tcont
   23ddc:	ldr	x9, [x19, x22, lsl #3]
   23de0:	add	x8, x22, #0x1
   23de4:	sub	x10, x9, #0x1
   23de8:	str	x10, [x20, x22, lsl #3]
   23dec:	mov	x22, x8
   23df0:	cbz	x9, 23dd4 <__gmpn_sub@@Base+0x40>
   23df4:	b	23e04 <__gmpn_sub@@Base+0x70>
   23df8:	mov	x8, xzr
   23dfc:	b	23e04 <__gmpn_sub@@Base+0x70>
   23e00:	mov	x8, x22
   23e04:	cmp	x20, x19
   23e08:	mov	x0, xzr
   23e0c:	b.eq	23e38 <__gmpn_sub@@Base+0xa4>  // b.none
   23e10:	cmp	x8, x21
   23e14:	b.ge	23e38 <__gmpn_sub@@Base+0xa4>  // b.tcont
   23e18:	sub	x9, x21, x8
   23e1c:	add	x10, x20, x8, lsl #3
   23e20:	add	x8, x19, x8, lsl #3
   23e24:	ldr	x11, [x8], #8
   23e28:	subs	x9, x9, #0x1
   23e2c:	str	x11, [x10], #8
   23e30:	b.ne	23e24 <__gmpn_sub@@Base+0x90>  // b.any
   23e34:	mov	x0, xzr
   23e38:	ldp	x20, x19, [sp, #32]
   23e3c:	ldp	x22, x21, [sp, #16]
   23e40:	ldp	x29, x30, [sp], #48
   23e44:	ret

0000000000023e48 <__gmpn_sub_1@@Base>:
   23e48:	ldr	x8, [x1]
   23e4c:	subs	x8, x8, x3
   23e50:	str	x8, [x0]
   23e54:	b.cs	23ebc <__gmpn_sub_1@@Base+0x74>  // b.hs, b.nlast
   23e58:	mov	x10, #0xfffffffffffffff8    	// #-8
   23e5c:	mov	w8, #0x1                   	// #1
   23e60:	mov	w9, #0x1                   	// #1
   23e64:	cmp	x9, x2
   23e68:	b.ge	23eec <__gmpn_sub_1@@Base+0xa4>  // b.tcont
   23e6c:	ldr	x11, [x1, x9, lsl #3]
   23e70:	sub	x10, x10, #0x8
   23e74:	sub	x12, x11, #0x1
   23e78:	str	x12, [x0, x9, lsl #3]
   23e7c:	add	x9, x9, #0x1
   23e80:	cbz	x11, 23e64 <__gmpn_sub_1@@Base+0x1c>
   23e84:	cmp	x1, x0
   23e88:	mov	x8, xzr
   23e8c:	b.eq	23eec <__gmpn_sub_1@@Base+0xa4>  // b.none
   23e90:	cmp	x9, x2
   23e94:	b.ge	23eec <__gmpn_sub_1@@Base+0xa4>  // b.tcont
   23e98:	sub	x8, x1, x10
   23e9c:	sub	x10, x0, x10
   23ea0:	ldr	x11, [x8], #8
   23ea4:	sub	x2, x2, #0x1
   23ea8:	cmp	x9, x2
   23eac:	str	x11, [x10], #8
   23eb0:	b.ne	23ea0 <__gmpn_sub_1@@Base+0x58>  // b.any
   23eb4:	mov	x8, xzr
   23eb8:	b	23eec <__gmpn_sub_1@@Base+0xa4>
   23ebc:	cmp	x1, x0
   23ec0:	mov	x8, xzr
   23ec4:	b.eq	23eec <__gmpn_sub_1@@Base+0xa4>  // b.none
   23ec8:	cmp	x2, #0x2
   23ecc:	b.lt	23eec <__gmpn_sub_1@@Base+0xa4>  // b.tstop
   23ed0:	sub	x8, x2, #0x1
   23ed4:	add	x9, x0, #0x8
   23ed8:	add	x10, x1, #0x8
   23edc:	ldr	x11, [x10], #8
   23ee0:	subs	x8, x8, #0x1
   23ee4:	str	x11, [x9], #8
   23ee8:	b.ne	23edc <__gmpn_sub_1@@Base+0x94>  // b.any
   23eec:	mov	x0, x8
   23ef0:	ret
   23ef4:	nop
   23ef8:	nop
   23efc:	nop

0000000000023f00 <__gmpn_sub_nc@@Base>:
   23f00:	cmp	xzr, x4
   23f04:	b	23f0c <__gmpn_sub_n@@Base+0x4>

0000000000023f08 <__gmpn_sub_n@@Base>:
   23f08:	cmp	xzr, xzr
   23f0c:	lsr	x18, x3, #2
   23f10:	tbz	w3, #0, 23f58 <__gmpn_sub_n@@Base+0x50>
   23f14:	ldr	x7, [x1]
   23f18:	ldr	x11, [x2]
   23f1c:	sbcs	x13, x7, x11
   23f20:	str	x13, [x0], #8
   23f24:	tbnz	w3, #1, 23f40 <__gmpn_sub_n@@Base+0x38>
   23f28:	cbz	x18, 23fbc <__gmpn_sub_n@@Base+0xb4>
   23f2c:	ldp	x4, x5, [x1, #8]
   23f30:	ldp	x8, x9, [x2, #8]
   23f34:	sub	x1, x1, #0x8
   23f38:	sub	x2, x2, #0x8
   23f3c:	b	23f94 <__gmpn_sub_n@@Base+0x8c>
   23f40:	ldp	x6, x7, [x1, #8]
   23f44:	ldp	x10, x11, [x2, #8]
   23f48:	add	x1, x1, #0x8
   23f4c:	add	x2, x2, #0x8
   23f50:	cbz	x18, 23fb0 <__gmpn_sub_n@@Base+0xa8>
   23f54:	b	23f80 <__gmpn_sub_n@@Base+0x78>
   23f58:	tbnz	w3, #1, 23f70 <__gmpn_sub_n@@Base+0x68>
   23f5c:	ldp	x4, x5, [x1]
   23f60:	ldp	x8, x9, [x2]
   23f64:	sub	x1, x1, #0x10
   23f68:	sub	x2, x2, #0x10
   23f6c:	b	23f94 <__gmpn_sub_n@@Base+0x8c>
   23f70:	ldp	x6, x7, [x1]
   23f74:	ldp	x10, x11, [x2]
   23f78:	cbz	x18, 23fb0 <__gmpn_sub_n@@Base+0xa8>
   23f7c:	nop
   23f80:	ldp	x4, x5, [x1, #16]
   23f84:	ldp	x8, x9, [x2, #16]
   23f88:	sbcs	x12, x6, x10
   23f8c:	sbcs	x13, x7, x11
   23f90:	stp	x12, x13, [x0], #16
   23f94:	ldp	x6, x7, [x1, #32]!
   23f98:	ldp	x10, x11, [x2, #32]!
   23f9c:	sbcs	x12, x4, x8
   23fa0:	sbcs	x13, x5, x9
   23fa4:	stp	x12, x13, [x0], #16
   23fa8:	sub	x18, x18, #0x1
   23fac:	cbnz	x18, 23f80 <__gmpn_sub_n@@Base+0x78>
   23fb0:	sbcs	x12, x6, x10
   23fb4:	sbcs	x13, x7, x11
   23fb8:	stp	x12, x13, [x0]
   23fbc:	cset	x0, cc  // cc = lo, ul, last
   23fc0:	ret
   23fc4:	nop
   23fc8:	nop
   23fcc:	nop

0000000000023fd0 <__gmpn_cnd_add_n@@Base>:
   23fd0:	cmp	x0, #0x1
   23fd4:	sbc	x0, x0, x0
   23fd8:	cmn	xzr, xzr
   23fdc:	lsr	x18, x4, #2
   23fe0:	tbz	w4, #0, 2402c <__gmpn_cnd_add_n@@Base+0x5c>
   23fe4:	ldr	x13, [x3]
   23fe8:	ldr	x11, [x2]
   23fec:	bic	x7, x13, x0
   23ff0:	adcs	x9, x11, x7
   23ff4:	str	x9, [x1]
   23ff8:	tbnz	w4, #1, 24018 <__gmpn_cnd_add_n@@Base+0x48>
   23ffc:	cbz	x18, 240a4 <__gmpn_cnd_add_n@@Base+0xd4>
   24000:	ldp	x12, x13, [x3, #8]
   24004:	ldp	x10, x11, [x2, #8]
   24008:	sub	x2, x2, #0x8
   2400c:	sub	x3, x3, #0x8
   24010:	sub	x1, x1, #0x18
   24014:	b	2406c <__gmpn_cnd_add_n@@Base+0x9c>
   24018:	ldp	x12, x13, [x3, #8]!
   2401c:	ldp	x10, x11, [x2, #8]!
   24020:	sub	x1, x1, #0x8
   24024:	cbz	x18, 24090 <__gmpn_cnd_add_n@@Base+0xc0>
   24028:	b	24050 <__gmpn_cnd_add_n@@Base+0x80>
   2402c:	ldp	x12, x13, [x3]
   24030:	ldp	x10, x11, [x2]
   24034:	tbnz	w4, #1, 24048 <__gmpn_cnd_add_n@@Base+0x78>
   24038:	sub	x2, x2, #0x10
   2403c:	sub	x3, x3, #0x10
   24040:	sub	x1, x1, #0x20
   24044:	b	2406c <__gmpn_cnd_add_n@@Base+0x9c>
   24048:	sub	x1, x1, #0x10
   2404c:	cbz	x18, 24090 <__gmpn_cnd_add_n@@Base+0xc0>
   24050:	bic	x6, x12, x0
   24054:	bic	x7, x13, x0
   24058:	ldp	x12, x13, [x3, #16]
   2405c:	adcs	x8, x10, x6
   24060:	adcs	x9, x11, x7
   24064:	ldp	x10, x11, [x2, #16]
   24068:	stp	x8, x9, [x1, #16]
   2406c:	bic	x6, x12, x0
   24070:	bic	x7, x13, x0
   24074:	ldp	x12, x13, [x3, #32]!
   24078:	adcs	x8, x10, x6
   2407c:	adcs	x9, x11, x7
   24080:	ldp	x10, x11, [x2, #32]!
   24084:	stp	x8, x9, [x1, #32]!
   24088:	sub	x18, x18, #0x1
   2408c:	cbnz	x18, 24050 <__gmpn_cnd_add_n@@Base+0x80>
   24090:	bic	x6, x12, x0
   24094:	bic	x7, x13, x0
   24098:	adcs	x8, x10, x6
   2409c:	adcs	x9, x11, x7
   240a0:	stp	x8, x9, [x1, #16]
   240a4:	cset	x0, cs  // cs = hs, nlast
   240a8:	ret
   240ac:	nop

00000000000240b0 <__gmpn_cnd_sub_n@@Base>:
   240b0:	cmp	x0, #0x1
   240b4:	sbc	x0, x0, x0
   240b8:	cmp	xzr, xzr
   240bc:	lsr	x18, x4, #2
   240c0:	tbz	w4, #0, 2410c <__gmpn_cnd_sub_n@@Base+0x5c>
   240c4:	ldr	x13, [x3]
   240c8:	ldr	x11, [x2]
   240cc:	bic	x7, x13, x0
   240d0:	sbcs	x9, x11, x7
   240d4:	str	x9, [x1]
   240d8:	tbnz	w4, #1, 240f8 <__gmpn_cnd_sub_n@@Base+0x48>
   240dc:	cbz	x18, 24184 <__gmpn_cnd_sub_n@@Base+0xd4>
   240e0:	ldp	x12, x13, [x3, #8]
   240e4:	ldp	x10, x11, [x2, #8]
   240e8:	sub	x2, x2, #0x8
   240ec:	sub	x3, x3, #0x8
   240f0:	sub	x1, x1, #0x18
   240f4:	b	2414c <__gmpn_cnd_sub_n@@Base+0x9c>
   240f8:	ldp	x12, x13, [x3, #8]!
   240fc:	ldp	x10, x11, [x2, #8]!
   24100:	sub	x1, x1, #0x8
   24104:	cbz	x18, 24170 <__gmpn_cnd_sub_n@@Base+0xc0>
   24108:	b	24130 <__gmpn_cnd_sub_n@@Base+0x80>
   2410c:	ldp	x12, x13, [x3]
   24110:	ldp	x10, x11, [x2]
   24114:	tbnz	w4, #1, 24128 <__gmpn_cnd_sub_n@@Base+0x78>
   24118:	sub	x2, x2, #0x10
   2411c:	sub	x3, x3, #0x10
   24120:	sub	x1, x1, #0x20
   24124:	b	2414c <__gmpn_cnd_sub_n@@Base+0x9c>
   24128:	sub	x1, x1, #0x10
   2412c:	cbz	x18, 24170 <__gmpn_cnd_sub_n@@Base+0xc0>
   24130:	bic	x6, x12, x0
   24134:	bic	x7, x13, x0
   24138:	ldp	x12, x13, [x3, #16]
   2413c:	sbcs	x8, x10, x6
   24140:	sbcs	x9, x11, x7
   24144:	ldp	x10, x11, [x2, #16]
   24148:	stp	x8, x9, [x1, #16]
   2414c:	bic	x6, x12, x0
   24150:	bic	x7, x13, x0
   24154:	ldp	x12, x13, [x3, #32]!
   24158:	sbcs	x8, x10, x6
   2415c:	sbcs	x9, x11, x7
   24160:	ldp	x10, x11, [x2, #32]!
   24164:	stp	x8, x9, [x1, #32]!
   24168:	sub	x18, x18, #0x1
   2416c:	cbnz	x18, 24130 <__gmpn_cnd_sub_n@@Base+0x80>
   24170:	bic	x6, x12, x0
   24174:	bic	x7, x13, x0
   24178:	sbcs	x8, x10, x6
   2417c:	sbcs	x9, x11, x7
   24180:	stp	x8, x9, [x1, #16]
   24184:	cset	x0, cc  // cc = lo, ul, last
   24188:	ret

000000000002418c <__gmpn_cnd_swap@@Base>:
   2418c:	sub	sp, sp, #0x10
   24190:	cmp	x0, #0x0
   24194:	csetm	x8, ne  // ne = any
   24198:	cmp	x3, #0x1
   2419c:	str	x8, [sp, #8]
   241a0:	b.lt	241d0 <__gmpn_cnd_swap@@Base+0x44>  // b.tstop
   241a4:	ldr	x8, [x1]
   241a8:	ldr	x9, [x2]
   241ac:	ldr	x10, [sp, #8]
   241b0:	subs	x3, x3, #0x1
   241b4:	eor	x11, x9, x8
   241b8:	and	x10, x11, x10
   241bc:	eor	x8, x10, x8
   241c0:	eor	x9, x10, x9
   241c4:	str	x8, [x1], #8
   241c8:	str	x9, [x2], #8
   241cc:	b.ne	241a4 <__gmpn_cnd_swap@@Base+0x18>  // b.any
   241d0:	add	sp, sp, #0x10
   241d4:	ret

00000000000241d8 <__gmpn_neg@@Base>:
   241d8:	stp	x29, x30, [sp, #-16]!
   241dc:	ldr	x8, [x1]
   241e0:	mov	x29, sp
   241e4:	cbz	x8, 24218 <__gmpn_neg@@Base+0x40>
   241e8:	neg	x8, x8
   241ec:	subs	x2, x2, #0x1
   241f0:	str	x8, [x0]
   241f4:	b.eq	24204 <__gmpn_neg@@Base+0x2c>  // b.none
   241f8:	add	x0, x0, #0x8
   241fc:	add	x1, x1, #0x8
   24200:	bl	c2a0 <__gmpn_com@plt>
   24204:	mov	w0, #0x1                   	// #1
   24208:	b	24228 <__gmpn_neg@@Base+0x50>
   2420c:	ldr	x8, [x1, #8]!
   24210:	add	x0, x0, #0x8
   24214:	cbnz	x8, 241e8 <__gmpn_neg@@Base+0x10>
   24218:	subs	x2, x2, #0x1
   2421c:	str	xzr, [x0]
   24220:	b.ne	2420c <__gmpn_neg@@Base+0x34>  // b.any
   24224:	mov	x0, xzr
   24228:	ldp	x29, x30, [sp], #16
   2422c:	ret

0000000000024230 <__gmpn_com@@Base>:
   24230:	cmp	x2, #0x3
   24234:	b.le	24288 <__gmpn_com@@Base+0x58>
   24238:	tbz	w0, #3, 2424c <__gmpn_com@@Base+0x1c>
   2423c:	ld1	{v22.1d}, [x1], #8
   24240:	sub	x2, x2, #0x1
   24244:	mvn	v22.8b, v22.8b
   24248:	st1	{v22.1d}, [x0], #8
   2424c:	ld1	{v26.2d}, [x1], #16
   24250:	subs	x2, x2, #0x6
   24254:	b.lt	24280 <__gmpn_com@@Base+0x50>  // b.tstop
   24258:	nop
   2425c:	nop
   24260:	ld1	{v22.2d}, [x1], #16
   24264:	mvn	v26.16b, v26.16b
   24268:	st1	{v26.2d}, [x0], #16
   2426c:	ld1	{v26.2d}, [x1], #16
   24270:	mvn	v22.16b, v22.16b
   24274:	st1	{v22.2d}, [x0], #16
   24278:	subs	x2, x2, #0x4
   2427c:	b.ge	24260 <__gmpn_com@@Base+0x30>  // b.tcont
   24280:	mvn	v26.16b, v26.16b
   24284:	st1	{v26.2d}, [x0], #16
   24288:	tbz	w2, #1, 24298 <__gmpn_com@@Base+0x68>
   2428c:	ld1	{v22.2d}, [x1], #16
   24290:	mvn	v22.16b, v22.16b
   24294:	st1	{v22.2d}, [x0], #16
   24298:	tbz	w2, #0, 242a8 <__gmpn_com@@Base+0x78>
   2429c:	ld1	{v22.1d}, [x1]
   242a0:	mvn	v22.8b, v22.8b
   242a4:	st1	{v22.1d}, [x0]
   242a8:	ret
   242ac:	nop

00000000000242b0 <__gmpn_mul_1c@@Base>:
   242b0:	cmn	xzr, xzr
   242b4:	b	242bc <__gmpn_mul_1@@Base+0x4>

00000000000242b8 <__gmpn_mul_1@@Base>:
   242b8:	adds	x4, xzr, xzr
   242bc:	lsr	x18, x2, #2
   242c0:	tbnz	w2, #0, 242f0 <__gmpn_mul_1@@Base+0x38>
   242c4:	mov	x11, x4
   242c8:	tbz	w2, #1, 2430c <__gmpn_mul_1@@Base+0x54>
   242cc:	ldp	x4, x5, [x1]
   242d0:	mul	x8, x4, x3
   242d4:	umulh	x10, x4, x3
   242d8:	cbz	x18, 242e8 <__gmpn_mul_1@@Base+0x30>
   242dc:	ldp	x6, x7, [x1, #16]!
   242e0:	mul	x9, x5, x3
   242e4:	b	24358 <__gmpn_mul_1@@Base+0xa0>
   242e8:	mul	x9, x5, x3
   242ec:	b	2439c <__gmpn_mul_1@@Base+0xe4>
   242f0:	ldr	x7, [x1], #8
   242f4:	mul	x9, x7, x3
   242f8:	umulh	x11, x7, x3
   242fc:	adds	x9, x9, x4
   24300:	str	x9, [x0], #8
   24304:	tbnz	w2, #1, 242cc <__gmpn_mul_1@@Base+0x14>
   24308:	cbz	x18, 243ac <__gmpn_mul_1@@Base+0xf4>
   2430c:	ldp	x6, x7, [x1]
   24310:	mul	x8, x6, x3
   24314:	umulh	x10, x6, x3
   24318:	ldp	x4, x5, [x1, #16]
   2431c:	mul	x9, x7, x3
   24320:	adcs	x12, x8, x11
   24324:	umulh	x11, x7, x3
   24328:	add	x0, x0, #0x10
   2432c:	sub	x18, x18, #0x1
   24330:	cbz	x18, 24388 <__gmpn_mul_1@@Base+0xd0>
   24334:	nop
   24338:	nop
   2433c:	nop
   24340:	mul	x8, x4, x3
   24344:	ldp	x6, x7, [x1, #32]!
   24348:	adcs	x13, x9, x10
   2434c:	umulh	x10, x4, x3
   24350:	mul	x9, x5, x3
   24354:	stp	x12, x13, [x0, #-16]
   24358:	adcs	x12, x8, x11
   2435c:	umulh	x11, x5, x3
   24360:	mul	x8, x6, x3
   24364:	ldp	x4, x5, [x1, #16]
   24368:	adcs	x13, x9, x10
   2436c:	umulh	x10, x6, x3
   24370:	mul	x9, x7, x3
   24374:	stp	x12, x13, [x0], #32
   24378:	adcs	x12, x8, x11
   2437c:	umulh	x11, x7, x3
   24380:	sub	x18, x18, #0x1
   24384:	cbnz	x18, 24340 <__gmpn_mul_1@@Base+0x88>
   24388:	mul	x8, x4, x3
   2438c:	adcs	x13, x9, x10
   24390:	umulh	x10, x4, x3
   24394:	mul	x9, x5, x3
   24398:	stp	x12, x13, [x0, #-16]
   2439c:	adcs	x12, x8, x11
   243a0:	umulh	x11, x5, x3
   243a4:	adcs	x13, x9, x10
   243a8:	stp	x12, x13, [x0]
   243ac:	adc	x0, x11, xzr
   243b0:	ret
   243b4:	nop
   243b8:	nop
   243bc:	nop

00000000000243c0 <__gmpn_addmul_1@@Base>:
   243c0:	adds	x15, xzr, xzr
   243c4:	tbz	w2, #0, 243e4 <__gmpn_addmul_1@@Base+0x24>
   243c8:	ldr	x4, [x1], #8
   243cc:	mul	x8, x4, x3
   243d0:	umulh	x12, x4, x3
   243d4:	ldr	x4, [x0]
   243d8:	adds	x8, x4, x8
   243dc:	cinc	x15, x12, cs  // cs = hs, nlast
   243e0:	str	x8, [x0], #8
   243e4:	tbz	w2, #1, 2441c <__gmpn_addmul_1@@Base+0x5c>
   243e8:	ldp	x4, x5, [x1], #16
   243ec:	mul	x8, x4, x3
   243f0:	umulh	x12, x4, x3
   243f4:	mul	x9, x5, x3
   243f8:	umulh	x13, x5, x3
   243fc:	adds	x8, x8, x15
   24400:	adcs	x9, x9, x12
   24404:	ldp	x4, x5, [x0]
   24408:	adc	x15, x13, xzr
   2440c:	adds	x8, x4, x8
   24410:	adcs	x9, x5, x9
   24414:	cinc	x15, x15, cs  // cs = hs, nlast
   24418:	stp	x8, x9, [x0], #16
   2441c:	lsr	x2, x2, #2
   24420:	cbz	x2, 24430 <__gmpn_addmul_1@@Base+0x70>
   24424:	ldp	x4, x5, [x1], #32
   24428:	ldp	x6, x7, [x1, #-16]
   2442c:	b	24464 <__gmpn_addmul_1@@Base+0xa4>
   24430:	mov	x0, x15
   24434:	ret
   24438:	nop
   2443c:	nop
   24440:	ldp	x4, x5, [x1], #32
   24444:	ldp	x6, x7, [x1, #-16]
   24448:	adds	x8, x16, x8
   2444c:	adcs	x9, x17, x9
   24450:	stp	x8, x9, [x0], #32
   24454:	adcs	x10, x12, x10
   24458:	adcs	x11, x13, x11
   2445c:	stp	x10, x11, [x0, #-16]
   24460:	cinc	x15, x15, cs  // cs = hs, nlast
   24464:	sub	x2, x2, #0x1
   24468:	mul	x8, x4, x3
   2446c:	umulh	x12, x4, x3
   24470:	mul	x9, x5, x3
   24474:	umulh	x13, x5, x3
   24478:	adds	x8, x8, x15
   2447c:	mul	x10, x6, x3
   24480:	umulh	x14, x6, x3
   24484:	adcs	x9, x9, x12
   24488:	mul	x11, x7, x3
   2448c:	umulh	x15, x7, x3
   24490:	adcs	x10, x10, x13
   24494:	ldp	x16, x17, [x0]
   24498:	adcs	x11, x11, x14
   2449c:	ldp	x12, x13, [x0, #16]
   244a0:	adc	x15, x15, xzr
   244a4:	cbnz	x2, 24440 <__gmpn_addmul_1@@Base+0x80>
   244a8:	adds	x8, x16, x8
   244ac:	adcs	x9, x17, x9
   244b0:	adcs	x10, x12, x10
   244b4:	adcs	x11, x13, x11
   244b8:	stp	x8, x9, [x0]
   244bc:	stp	x10, x11, [x0, #16]
   244c0:	cinc	x0, x15, cs  // cs = hs, nlast
   244c4:	ret
   244c8:	nop
   244cc:	nop

00000000000244d0 <__gmpn_submul_1@@Base>:
   244d0:	adds	x15, xzr, xzr
   244d4:	tbz	w2, #0, 244f4 <__gmpn_submul_1@@Base+0x24>
   244d8:	ldr	x4, [x1], #8
   244dc:	mul	x8, x4, x3
   244e0:	umulh	x12, x4, x3
   244e4:	ldr	x4, [x0]
   244e8:	subs	x8, x4, x8
   244ec:	cinc	x15, x12, cc  // cc = lo, ul, last
   244f0:	str	x8, [x0], #8
   244f4:	tbz	w2, #1, 2452c <__gmpn_submul_1@@Base+0x5c>
   244f8:	ldp	x4, x5, [x1], #16
   244fc:	mul	x8, x4, x3
   24500:	umulh	x12, x4, x3
   24504:	mul	x9, x5, x3
   24508:	umulh	x13, x5, x3
   2450c:	adds	x8, x8, x15
   24510:	adcs	x9, x9, x12
   24514:	ldp	x4, x5, [x0]
   24518:	adc	x15, x13, xzr
   2451c:	subs	x8, x4, x8
   24520:	sbcs	x9, x5, x9
   24524:	cinc	x15, x15, cc  // cc = lo, ul, last
   24528:	stp	x8, x9, [x0], #16
   2452c:	lsr	x2, x2, #2
   24530:	cbz	x2, 24540 <__gmpn_submul_1@@Base+0x70>
   24534:	ldp	x4, x5, [x1], #32
   24538:	ldp	x6, x7, [x1, #-16]
   2453c:	b	24574 <__gmpn_submul_1@@Base+0xa4>
   24540:	mov	x0, x15
   24544:	ret
   24548:	nop
   2454c:	nop
   24550:	ldp	x4, x5, [x1], #32
   24554:	ldp	x6, x7, [x1, #-16]
   24558:	subs	x8, x16, x8
   2455c:	sbcs	x9, x17, x9
   24560:	stp	x8, x9, [x0], #32
   24564:	sbcs	x10, x12, x10
   24568:	sbcs	x11, x13, x11
   2456c:	stp	x10, x11, [x0, #-16]
   24570:	cinc	x15, x15, cc  // cc = lo, ul, last
   24574:	sub	x2, x2, #0x1
   24578:	mul	x8, x4, x3
   2457c:	umulh	x12, x4, x3
   24580:	mul	x9, x5, x3
   24584:	umulh	x13, x5, x3
   24588:	adds	x8, x8, x15
   2458c:	mul	x10, x6, x3
   24590:	umulh	x14, x6, x3
   24594:	adcs	x9, x9, x12
   24598:	mul	x11, x7, x3
   2459c:	umulh	x15, x7, x3
   245a0:	adcs	x10, x10, x13
   245a4:	ldp	x16, x17, [x0]
   245a8:	adcs	x11, x11, x14
   245ac:	ldp	x12, x13, [x0, #16]
   245b0:	adc	x15, x15, xzr
   245b4:	cbnz	x2, 24550 <__gmpn_submul_1@@Base+0x80>
   245b8:	subs	x8, x16, x8
   245bc:	sbcs	x9, x17, x9
   245c0:	sbcs	x10, x12, x10
   245c4:	sbcs	x11, x13, x11
   245c8:	stp	x8, x9, [x0]
   245cc:	stp	x10, x11, [x0, #16]
   245d0:	cinc	x0, x15, cc  // cc = lo, ul, last
   245d4:	ret

00000000000245d8 <__gmpn_add_err1_n@@Base>:
   245d8:	mov	x8, xzr
   245dc:	mov	x9, xzr
   245e0:	sub	x10, x4, #0x8
   245e4:	ldr	x11, [x10, x5, lsl #3]
   245e8:	ldr	x12, [x1], #8
   245ec:	ldr	x13, [x2], #8
   245f0:	adds	x12, x13, x12
   245f4:	cset	w13, cs  // cs = hs, nlast
   245f8:	adds	x12, x12, x6
   245fc:	cset	w14, cs  // cs = hs, nlast
   24600:	orr	w6, w13, w14
   24604:	cmp	w6, #0x0
   24608:	csel	x11, x11, xzr, ne  // ne = any
   2460c:	adds	x9, x11, x9
   24610:	cinc	x8, x8, cs  // cs = hs, nlast
   24614:	subs	x5, x5, #0x1
   24618:	str	x12, [x0], #8
   2461c:	b.ne	245e4 <__gmpn_add_err1_n@@Base+0xc>  // b.any
   24620:	mov	x0, x6
   24624:	stp	x9, x8, [x3]
   24628:	ret

000000000002462c <__gmpn_add_err2_n@@Base>:
   2462c:	mov	x8, xzr
   24630:	mov	x9, xzr
   24634:	mov	x10, xzr
   24638:	mov	x11, xzr
   2463c:	sub	x12, x5, #0x8
   24640:	sub	x13, x4, #0x8
   24644:	ldr	x14, [x13, x6, lsl #3]
   24648:	ldr	x15, [x12, x6, lsl #3]
   2464c:	ldr	x16, [x1], #8
   24650:	ldr	x17, [x2], #8
   24654:	adds	x16, x17, x16
   24658:	cset	w17, cs  // cs = hs, nlast
   2465c:	adds	x16, x16, x7
   24660:	cset	w18, cs  // cs = hs, nlast
   24664:	orr	w7, w17, w18
   24668:	sbfx	x17, x7, #0, #1
   2466c:	and	x14, x14, x17
   24670:	and	x15, x15, x17
   24674:	adds	x11, x14, x11
   24678:	cinc	x10, x10, cs  // cs = hs, nlast
   2467c:	adds	x9, x15, x9
   24680:	cinc	x8, x8, cs  // cs = hs, nlast
   24684:	subs	x6, x6, #0x1
   24688:	str	x16, [x0], #8
   2468c:	b.ne	24644 <__gmpn_add_err2_n@@Base+0x18>  // b.any
   24690:	mov	x0, x7
   24694:	stp	x11, x10, [x3]
   24698:	stp	x9, x8, [x3, #16]
   2469c:	ret

00000000000246a0 <__gmpn_add_err3_n@@Base>:
   246a0:	stp	x20, x19, [sp, #-16]!
   246a4:	ldr	x8, [sp, #16]
   246a8:	lsl	x16, x7, #3
   246ac:	sub	x18, x16, #0x8
   246b0:	mov	x14, xzr
   246b4:	mov	x9, xzr
   246b8:	mov	x10, xzr
   246bc:	mov	x11, xzr
   246c0:	mov	x12, xzr
   246c4:	mov	x13, xzr
   246c8:	mov	x15, xzr
   246cc:	add	x16, x4, x18
   246d0:	add	x17, x5, x18
   246d4:	add	x18, x6, x18
   246d8:	ldr	x4, [x16], #-8
   246dc:	ldr	x5, [x17], #-8
   246e0:	ldr	x6, [x18], #-8
   246e4:	ldr	x19, [x1, x14, lsl #3]
   246e8:	ldr	x20, [x2, x14, lsl #3]
   246ec:	adds	x19, x20, x19
   246f0:	cset	w20, cs  // cs = hs, nlast
   246f4:	adds	x8, x19, x8
   246f8:	cset	w19, cs  // cs = hs, nlast
   246fc:	str	x8, [x0, x14, lsl #3]
   24700:	orr	w8, w20, w19
   24704:	sbfx	x19, x8, #0, #1
   24708:	and	x4, x4, x19
   2470c:	and	x5, x5, x19
   24710:	adds	x15, x4, x15
   24714:	and	x6, x6, x19
   24718:	cinc	x13, x13, cs  // cs = hs, nlast
   2471c:	adds	x12, x5, x12
   24720:	add	x14, x14, #0x1
   24724:	cinc	x11, x11, cs  // cs = hs, nlast
   24728:	adds	x10, x6, x10
   2472c:	cinc	x9, x9, cs  // cs = hs, nlast
   24730:	cmp	x7, x14
   24734:	b.ne	246d8 <__gmpn_add_err3_n@@Base+0x38>  // b.any
   24738:	stp	x15, x13, [x3]
   2473c:	stp	x12, x11, [x3, #16]
   24740:	stp	x10, x9, [x3, #32]
   24744:	mov	x0, x8
   24748:	ldp	x20, x19, [sp], #16
   2474c:	ret

0000000000024750 <__gmpn_sub_err1_n@@Base>:
   24750:	mov	x8, xzr
   24754:	mov	x9, xzr
   24758:	sub	x10, x4, #0x8
   2475c:	ldr	x11, [x10, x5, lsl #3]
   24760:	ldr	x12, [x1], #8
   24764:	ldr	x13, [x2], #8
   24768:	subs	x12, x12, x13
   2476c:	cset	w13, cc  // cc = lo, ul, last
   24770:	subs	x12, x12, x6
   24774:	cset	w14, cc  // cc = lo, ul, last
   24778:	orr	w6, w13, w14
   2477c:	cmp	w6, #0x0
   24780:	csel	x11, x11, xzr, ne  // ne = any
   24784:	adds	x9, x11, x9
   24788:	cinc	x8, x8, cs  // cs = hs, nlast
   2478c:	subs	x5, x5, #0x1
   24790:	str	x12, [x0], #8
   24794:	b.ne	2475c <__gmpn_sub_err1_n@@Base+0xc>  // b.any
   24798:	mov	x0, x6
   2479c:	stp	x9, x8, [x3]
   247a0:	ret

00000000000247a4 <__gmpn_sub_err2_n@@Base>:
   247a4:	mov	x8, xzr
   247a8:	mov	x9, xzr
   247ac:	mov	x10, xzr
   247b0:	mov	x11, xzr
   247b4:	sub	x12, x5, #0x8
   247b8:	sub	x13, x4, #0x8
   247bc:	ldr	x14, [x13, x6, lsl #3]
   247c0:	ldr	x15, [x12, x6, lsl #3]
   247c4:	ldr	x16, [x1], #8
   247c8:	ldr	x17, [x2], #8
   247cc:	subs	x16, x16, x17
   247d0:	cset	w17, cc  // cc = lo, ul, last
   247d4:	subs	x16, x16, x7
   247d8:	cset	w18, cc  // cc = lo, ul, last
   247dc:	orr	w7, w17, w18
   247e0:	sbfx	x17, x7, #0, #1
   247e4:	and	x14, x14, x17
   247e8:	and	x15, x15, x17
   247ec:	adds	x11, x14, x11
   247f0:	cinc	x10, x10, cs  // cs = hs, nlast
   247f4:	adds	x9, x15, x9
   247f8:	cinc	x8, x8, cs  // cs = hs, nlast
   247fc:	subs	x6, x6, #0x1
   24800:	str	x16, [x0], #8
   24804:	b.ne	247bc <__gmpn_sub_err2_n@@Base+0x18>  // b.any
   24808:	mov	x0, x7
   2480c:	stp	x11, x10, [x3]
   24810:	stp	x9, x8, [x3, #16]
   24814:	ret

0000000000024818 <__gmpn_sub_err3_n@@Base>:
   24818:	stp	x20, x19, [sp, #-16]!
   2481c:	ldr	x8, [sp, #16]
   24820:	lsl	x16, x7, #3
   24824:	sub	x18, x16, #0x8
   24828:	mov	x14, xzr
   2482c:	mov	x9, xzr
   24830:	mov	x10, xzr
   24834:	mov	x11, xzr
   24838:	mov	x12, xzr
   2483c:	mov	x13, xzr
   24840:	mov	x15, xzr
   24844:	add	x16, x4, x18
   24848:	add	x17, x5, x18
   2484c:	add	x18, x6, x18
   24850:	ldr	x4, [x16], #-8
   24854:	ldr	x5, [x17], #-8
   24858:	ldr	x6, [x18], #-8
   2485c:	ldr	x19, [x1, x14, lsl #3]
   24860:	ldr	x20, [x2, x14, lsl #3]
   24864:	subs	x19, x19, x20
   24868:	cset	w20, cc  // cc = lo, ul, last
   2486c:	subs	x8, x19, x8
   24870:	cset	w19, cc  // cc = lo, ul, last
   24874:	str	x8, [x0, x14, lsl #3]
   24878:	orr	w8, w20, w19
   2487c:	sbfx	x19, x8, #0, #1
   24880:	and	x4, x4, x19
   24884:	and	x5, x5, x19
   24888:	adds	x15, x4, x15
   2488c:	and	x6, x6, x19
   24890:	cinc	x13, x13, cs  // cs = hs, nlast
   24894:	adds	x12, x5, x12
   24898:	add	x14, x14, #0x1
   2489c:	cinc	x11, x11, cs  // cs = hs, nlast
   248a0:	adds	x10, x6, x10
   248a4:	cinc	x9, x9, cs  // cs = hs, nlast
   248a8:	cmp	x7, x14
   248ac:	b.ne	24850 <__gmpn_sub_err3_n@@Base+0x38>  // b.any
   248b0:	stp	x15, x13, [x3]
   248b4:	stp	x12, x11, [x3, #16]
   248b8:	stp	x10, x9, [x3, #32]
   248bc:	mov	x0, x8
   248c0:	ldp	x20, x19, [sp], #16
   248c4:	ret
   248c8:	nop
   248cc:	nop

00000000000248d0 <__gmpn_lshift@@Base>:
   248d0:	add	x16, x0, x2, lsl #3
   248d4:	add	x1, x1, x2, lsl #3
   248d8:	neg	x8, x3
   248dc:	lsr	x18, x2, #2
   248e0:	tbz	w2, #0, 24920 <__gmpn_lshift@@Base+0x50>
   248e4:	ldur	x4, [x1, #-8]
   248e8:	tbnz	w2, #1, 24910 <__gmpn_lshift@@Base+0x40>
   248ec:	lsr	x0, x4, x8
   248f0:	lsl	x2, x4, x3
   248f4:	cbnz	x18, 24900 <__gmpn_lshift@@Base+0x30>
   248f8:	stur	x2, [x16, #-8]
   248fc:	ret
   24900:	ldp	x4, x5, [x1, #-24]
   24904:	sub	x1, x1, #0x8
   24908:	add	x16, x16, #0x10
   2490c:	b	24994 <__gmpn_lshift@@Base+0xc4>
   24910:	lsr	x0, x4, x8
   24914:	lsl	x2, x4, x3
   24918:	ldp	x6, x7, [x1, #-24]!
   2491c:	b	249b8 <__gmpn_lshift@@Base+0xe8>
   24920:	ldp	x4, x5, [x1, #-16]
   24924:	tbz	w2, #1, 24960 <__gmpn_lshift@@Base+0x90>
   24928:	lsr	x0, x5, x8
   2492c:	lsl	x13, x5, x3
   24930:	lsr	x10, x4, x8
   24934:	lsl	x2, x4, x3
   24938:	cbnz	x18, 24948 <__gmpn_lshift@@Base+0x78>
   2493c:	orr	x10, x10, x13
   24940:	stp	x2, x10, [x16, #-16]
   24944:	ret
   24948:	ldp	x4, x5, [x1, #-32]
   2494c:	orr	x10, x10, x13
   24950:	stur	x10, [x16, #-8]
   24954:	sub	x1, x1, #0x10
   24958:	add	x16, x16, #0x8
   2495c:	b	24994 <__gmpn_lshift@@Base+0xc4>
   24960:	lsr	x0, x5, x8
   24964:	lsl	x13, x5, x3
   24968:	lsr	x10, x4, x8
   2496c:	lsl	x2, x4, x3
   24970:	ldp	x6, x7, [x1, #-32]!
   24974:	orr	x10, x10, x13
   24978:	str	x10, [x16, #-8]!
   2497c:	b	249b4 <__gmpn_lshift@@Base+0xe4>
   24980:	ldp	x4, x5, [x1, #-16]
   24984:	orr	x10, x10, x13
   24988:	orr	x11, x12, x2
   2498c:	stp	x10, x11, [x16, #-16]
   24990:	lsl	x2, x6, x3
   24994:	lsr	x10, x4, x8
   24998:	lsl	x13, x5, x3
   2499c:	lsr	x12, x5, x8
   249a0:	ldp	x6, x7, [x1, #-32]!
   249a4:	orr	x10, x10, x13
   249a8:	orr	x11, x12, x2
   249ac:	stp	x10, x11, [x16, #-32]!
   249b0:	lsl	x2, x4, x3
   249b4:	sub	x18, x18, #0x1
   249b8:	lsr	x10, x6, x8
   249bc:	lsl	x13, x7, x3
   249c0:	lsr	x12, x7, x8
   249c4:	cbnz	x18, 24980 <__gmpn_lshift@@Base+0xb0>
   249c8:	orr	x10, x10, x13
   249cc:	orr	x11, x12, x2
   249d0:	lsl	x2, x6, x3
   249d4:	stp	x10, x11, [x16, #-16]
   249d8:	stur	x2, [x16, #-24]
   249dc:	ret

00000000000249e0 <__gmpn_rshift@@Base>:
   249e0:	mov	x16, x0
   249e4:	neg	x8, x3
   249e8:	lsr	x18, x2, #2
   249ec:	tbz	w2, #0, 24a30 <__gmpn_rshift@@Base+0x50>
   249f0:	ldr	x5, [x1]
   249f4:	tbnz	w2, #1, 24a1c <__gmpn_rshift@@Base+0x3c>
   249f8:	lsl	x0, x5, x8
   249fc:	lsr	x2, x5, x3
   24a00:	cbnz	x18, 24a0c <__gmpn_rshift@@Base+0x2c>
   24a04:	str	x2, [x16]
   24a08:	ret
   24a0c:	ldp	x4, x5, [x1, #8]
   24a10:	sub	x1, x1, #0x8
   24a14:	sub	x16, x16, #0x20
   24a18:	b	24aa4 <__gmpn_rshift@@Base+0xc4>
   24a1c:	lsl	x0, x5, x8
   24a20:	lsr	x2, x5, x3
   24a24:	ldp	x6, x7, [x1, #8]!
   24a28:	sub	x16, x16, #0x10
   24a2c:	b	24ac8 <__gmpn_rshift@@Base+0xe8>
   24a30:	ldp	x4, x5, [x1]
   24a34:	tbz	w2, #1, 24a68 <__gmpn_rshift@@Base+0x88>
   24a38:	lsl	x0, x4, x8
   24a3c:	lsr	x13, x4, x3
   24a40:	lsl	x10, x5, x8
   24a44:	lsr	x2, x5, x3
   24a48:	cbnz	x18, 24a58 <__gmpn_rshift@@Base+0x78>
   24a4c:	orr	x10, x10, x13
   24a50:	stp	x10, x2, [x16]
   24a54:	ret
   24a58:	ldp	x4, x5, [x1, #16]
   24a5c:	orr	x10, x10, x13
   24a60:	str	x10, [x16], #-24
   24a64:	b	24aa4 <__gmpn_rshift@@Base+0xc4>
   24a68:	lsl	x0, x4, x8
   24a6c:	lsr	x13, x4, x3
   24a70:	lsl	x10, x5, x8
   24a74:	lsr	x2, x5, x3
   24a78:	ldp	x6, x7, [x1, #16]!
   24a7c:	orr	x10, x10, x13
   24a80:	str	x10, [x16], #-8
   24a84:	b	24ac4 <__gmpn_rshift@@Base+0xe4>
   24a88:	nop
   24a8c:	nop
   24a90:	ldp	x4, x5, [x1, #16]
   24a94:	orr	x10, x10, x13
   24a98:	orr	x11, x12, x2
   24a9c:	stp	x11, x10, [x16, #16]
   24aa0:	lsr	x2, x7, x3
   24aa4:	lsl	x10, x5, x8
   24aa8:	lsl	x12, x4, x8
   24aac:	lsr	x13, x4, x3
   24ab0:	ldp	x6, x7, [x1, #32]!
   24ab4:	orr	x10, x10, x13
   24ab8:	orr	x11, x12, x2
   24abc:	stp	x11, x10, [x16, #32]!
   24ac0:	lsr	x2, x5, x3
   24ac4:	sub	x18, x18, #0x1
   24ac8:	lsl	x10, x7, x8
   24acc:	lsl	x12, x6, x8
   24ad0:	lsr	x13, x6, x3
   24ad4:	cbnz	x18, 24a90 <__gmpn_rshift@@Base+0xb0>
   24ad8:	orr	x10, x10, x13
   24adc:	orr	x11, x12, x2
   24ae0:	lsr	x2, x7, x3
   24ae4:	stp	x11, x10, [x16, #16]
   24ae8:	str	x2, [x16, #32]
   24aec:	ret

0000000000024af0 <__gmpn_divexact_1@@Base>:
   24af0:	rbit	x8, x3
   24af4:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   24af8:	tst	x3, #0x1
   24afc:	ldr	x9, [x9, #3952]
   24b00:	clz	x10, x8
   24b04:	csel	x8, x10, xzr, eq  // eq = none
   24b08:	lsr	x8, x3, x8
   24b0c:	ubfx	x11, x8, #1, #7
   24b10:	ldrb	w9, [x9, x11]
   24b14:	mov	w12, #0x2                   	// #2
   24b18:	msub	x11, x8, x9, x12
   24b1c:	mul	x9, x11, x9
   24b20:	msub	x13, x9, x8, x12
   24b24:	ldr	x11, [x1]
   24b28:	mul	x9, x9, x13
   24b2c:	msub	x12, x9, x8, x12
   24b30:	mul	x9, x9, x12
   24b34:	cbz	x10, 24b94 <__gmpn_divexact_1@@Base+0xa4>
   24b38:	tbnz	w3, #0, 24b94 <__gmpn_divexact_1@@Base+0xa4>
   24b3c:	cmp	x2, #0x2
   24b40:	b.lt	24bdc <__gmpn_divexact_1@@Base+0xec>  // b.tstop
   24b44:	mov	w14, #0x40                  	// #64
   24b48:	mov	x12, xzr
   24b4c:	sub	x13, x2, #0x1
   24b50:	sub	x14, x14, x10
   24b54:	add	x15, x1, #0x8
   24b58:	mov	x16, x0
   24b5c:	mov	x17, x11
   24b60:	ldr	x11, [x15], #8
   24b64:	lsr	x17, x17, x10
   24b68:	lsl	x18, x11, x14
   24b6c:	orr	x17, x18, x17
   24b70:	subs	x12, x17, x12
   24b74:	mul	x17, x12, x9
   24b78:	umulh	x12, x17, x8
   24b7c:	cinc	x12, x12, cc  // cc = lo, ul, last
   24b80:	subs	x13, x13, #0x1
   24b84:	str	x17, [x16], #8
   24b88:	mov	x17, x11
   24b8c:	b.ne	24b60 <__gmpn_divexact_1@@Base+0x70>  // b.any
   24b90:	b	24be0 <__gmpn_divexact_1@@Base+0xf0>
   24b94:	mul	x10, x9, x11
   24b98:	cmp	x2, #0x2
   24b9c:	str	x10, [x0]
   24ba0:	b.lt	24bd8 <__gmpn_divexact_1@@Base+0xe8>  // b.tstop
   24ba4:	mov	x12, xzr
   24ba8:	sub	x11, x2, #0x1
   24bac:	add	x13, x0, #0x8
   24bb0:	add	x14, x1, #0x8
   24bb4:	ldr	x15, [x14], #8
   24bb8:	umulh	x10, x10, x8
   24bbc:	add	x10, x10, x12
   24bc0:	subs	x10, x15, x10
   24bc4:	mul	x10, x10, x9
   24bc8:	cset	w12, cc  // cc = lo, ul, last
   24bcc:	subs	x11, x11, #0x1
   24bd0:	str	x10, [x13], #8
   24bd4:	b.ne	24bb4 <__gmpn_divexact_1@@Base+0xc4>  // b.any
   24bd8:	ret
   24bdc:	mov	x12, xzr
   24be0:	lsr	x8, x11, x10
   24be4:	sub	x8, x8, x12
   24be8:	mul	x8, x8, x9
   24bec:	add	x9, x0, x2, lsl #3
   24bf0:	stur	x8, [x9, #-8]
   24bf4:	ret

0000000000024bf8 <__gmpn_divexact_by3c@@Base>:
   24bf8:	stp	x29, x30, [sp, #-16]!
   24bfc:	mov	x8, #0x5555555555555555    	// #6148914691236517205
   24c00:	mul	x4, x3, x8
   24c04:	mov	x3, #0x5555555555555555    	// #6148914691236517205
   24c08:	mov	x29, sp
   24c0c:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
   24c10:	and	x0, x0, #0x3
   24c14:	ldp	x29, x30, [sp], #16
   24c18:	ret

0000000000024c1c <__gmpn_divisible_p@@Base>:
   24c1c:	stp	x29, x30, [sp, #-80]!
   24c20:	stp	x26, x25, [sp, #16]
   24c24:	stp	x24, x23, [sp, #32]
   24c28:	stp	x22, x21, [sp, #48]
   24c2c:	stp	x20, x19, [sp, #64]
   24c30:	mov	x29, sp
   24c34:	sub	sp, sp, #0x10
   24c38:	mov	x20, x1
   24c3c:	cmp	x1, x3
   24c40:	b.ge	24c50 <__gmpn_divisible_p@@Base+0x34>  // b.tcont
   24c44:	cmp	x20, #0x0
   24c48:	cset	w19, eq  // eq = none
   24c4c:	b	24cb4 <__gmpn_divisible_p@@Base+0x98>
   24c50:	mov	x21, x2
   24c54:	ldr	x2, [x2]
   24c58:	ldr	x8, [x0]
   24c5c:	mov	x19, x3
   24c60:	mov	x23, x0
   24c64:	cbz	x2, 24cac <__gmpn_divisible_p@@Base+0x90>
   24c68:	neg	x9, x2
   24c6c:	and	x9, x2, x9
   24c70:	sub	x9, x9, #0x1
   24c74:	tst	x9, x8
   24c78:	b.ne	24cb0 <__gmpn_divisible_p@@Base+0x94>  // b.any
   24c7c:	cmp	x19, #0x1
   24c80:	b.ne	24cd4 <__gmpn_divisible_p@@Base+0xb8>  // b.any
   24c84:	cmp	x20, #0x28
   24c88:	b.lt	24d80 <__gmpn_divisible_p@@Base+0x164>  // b.tstop
   24c8c:	mov	x0, x23
   24c90:	mov	x1, x20
   24c94:	b	24db8 <__gmpn_divisible_p@@Base+0x19c>
   24c98:	ldr	x8, [x23, #8]!
   24c9c:	ldr	x2, [x21, #8]!
   24ca0:	sub	x20, x20, #0x1
   24ca4:	sub	x19, x19, #0x1
   24ca8:	cbnz	x2, 24c68 <__gmpn_divisible_p@@Base+0x4c>
   24cac:	cbz	x8, 24c98 <__gmpn_divisible_p@@Base+0x7c>
   24cb0:	mov	w19, wzr
   24cb4:	mov	w0, w19
   24cb8:	mov	sp, x29
   24cbc:	ldp	x20, x19, [sp, #64]
   24cc0:	ldp	x22, x21, [sp, #48]
   24cc4:	ldp	x24, x23, [sp, #32]
   24cc8:	ldp	x26, x25, [sp, #16]
   24ccc:	ldp	x29, x30, [sp], #80
   24cd0:	ret
   24cd4:	rbit	x8, x2
   24cd8:	cmp	x19, #0x2
   24cdc:	clz	x24, x8
   24ce0:	b.ne	24cf0 <__gmpn_divisible_p@@Base+0xd4>  // b.any
   24ce4:	ldr	x8, [x21, #8]
   24ce8:	cmp	x8, x9
   24cec:	b.ls	24d98 <__gmpn_divisible_p@@Base+0x17c>  // b.plast
   24cf0:	add	x26, x20, #0x1
   24cf4:	sub	x8, x20, x19
   24cf8:	add	x8, x8, x26
   24cfc:	lsl	x8, x8, #3
   24d00:	add	x1, x8, #0x8
   24d04:	mov	w8, #0x7f00                	// #32512
   24d08:	cmp	x1, x8
   24d0c:	stur	xzr, [x29, #-8]
   24d10:	b.hi	24dd0 <__gmpn_divisible_p@@Base+0x1b4>  // b.pmore
   24d14:	add	x9, x1, #0xf
   24d18:	mov	x8, sp
   24d1c:	and	x9, x9, #0xfffffffffffffff0
   24d20:	sub	x22, x8, x9
   24d24:	mov	sp, x22
   24d28:	cbz	w24, 24de0 <__gmpn_divisible_p@@Base+0x1c4>
   24d2c:	lsl	x1, x19, #3
   24d30:	mov	w8, #0x7f00                	// #32512
   24d34:	cmp	x1, x8
   24d38:	b.hi	24f78 <__gmpn_divisible_p@@Base+0x35c>  // b.pmore
   24d3c:	add	x9, x1, #0xf
   24d40:	mov	x8, sp
   24d44:	and	x9, x9, #0xfffffffffffffff0
   24d48:	sub	x25, x8, x9
   24d4c:	mov	sp, x25
   24d50:	mov	x0, x25
   24d54:	mov	x1, x21
   24d58:	mov	x2, x19
   24d5c:	mov	w3, w24
   24d60:	bl	c1b0 <__gmpn_rshift@plt>
   24d64:	mov	x0, x22
   24d68:	mov	x1, x23
   24d6c:	mov	x2, x20
   24d70:	mov	w3, w24
   24d74:	bl	c1b0 <__gmpn_rshift@plt>
   24d78:	mov	x21, x25
   24d7c:	b	24df0 <__gmpn_divisible_p@@Base+0x1d4>
   24d80:	rbit	x8, x2
   24d84:	clz	x8, x8
   24d88:	lsr	x2, x2, x8
   24d8c:	mov	x0, x23
   24d90:	mov	x1, x20
   24d94:	b	24dc0 <__gmpn_divisible_p@@Base+0x1a4>
   24d98:	neg	x10, x24
   24d9c:	lsr	x9, x2, x24
   24da0:	lsl	x8, x8, x10
   24da4:	cmp	x20, #0x27
   24da8:	orr	x2, x8, x9
   24dac:	mov	x0, x23
   24db0:	mov	x1, x20
   24db4:	b.le	24dc0 <__gmpn_divisible_p@@Base+0x1a4>
   24db8:	bl	c400 <__gmpn_mod_1@plt>
   24dbc:	b	24dc8 <__gmpn_divisible_p@@Base+0x1ac>
   24dc0:	mov	x3, xzr
   24dc4:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   24dc8:	cmp	x0, #0x0
   24dcc:	b	24c48 <__gmpn_divisible_p@@Base+0x2c>
   24dd0:	sub	x0, x29, #0x8
   24dd4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   24dd8:	mov	x22, x0
   24ddc:	cbnz	w24, 24d2c <__gmpn_divisible_p@@Base+0x110>
   24de0:	mov	x0, x22
   24de4:	mov	x1, x23
   24de8:	mov	x2, x20
   24dec:	bl	ca70 <__gmpn_copyi@plt>
   24df0:	add	x8, x22, x20, lsl #3
   24df4:	add	x9, x21, x19, lsl #3
   24df8:	ldur	x8, [x8, #-8]
   24dfc:	ldur	x9, [x9, #-8]
   24e00:	cmp	x8, x9
   24e04:	b.cs	24e20 <__gmpn_divisible_p@@Base+0x204>  // b.hs, b.nlast
   24e08:	cmp	x20, x19
   24e0c:	b.ne	24e28 <__gmpn_divisible_p@@Base+0x20c>  // b.any
   24e10:	ldur	x0, [x29, #-8]
   24e14:	cbz	x0, 24cb0 <__gmpn_divisible_p@@Base+0x94>
   24e18:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   24e1c:	b	24cb0 <__gmpn_divisible_p@@Base+0x94>
   24e20:	str	xzr, [x22, x20, lsl #3]
   24e24:	mov	x20, x26
   24e28:	add	x23, x22, x26, lsl #3
   24e2c:	cmp	x19, #0x27
   24e30:	sub	x24, x20, x19
   24e34:	b.lt	24e98 <__gmpn_divisible_p@@Base+0x27c>  // b.tstop
   24e38:	cmp	x24, #0x26
   24e3c:	b.le	24e98 <__gmpn_divisible_p@@Base+0x27c>
   24e40:	cmp	x19, #0x326
   24e44:	b.le	24ee8 <__gmpn_divisible_p@@Base+0x2cc>
   24e48:	mov	x0, x20
   24e4c:	mov	x1, x19
   24e50:	bl	d190 <__gmpn_mu_bdiv_qr_itch@plt>
   24e54:	lsl	x1, x0, #3
   24e58:	mov	w8, #0x7f00                	// #32512
   24e5c:	cmp	x1, x8
   24e60:	b.hi	24f88 <__gmpn_divisible_p@@Base+0x36c>  // b.pmore
   24e64:	add	x9, x1, #0xf
   24e68:	mov	x8, sp
   24e6c:	and	x9, x9, #0xfffffffffffffff0
   24e70:	sub	x6, x8, x9
   24e74:	mov	sp, x6
   24e78:	mov	x0, x23
   24e7c:	mov	x1, x22
   24e80:	mov	x2, x22
   24e84:	mov	x3, x20
   24e88:	mov	x4, x21
   24e8c:	mov	x5, x19
   24e90:	bl	ccd0 <__gmpn_mu_bdiv_qr@plt>
   24e94:	b	24f38 <__gmpn_divisible_p@@Base+0x31c>
   24e98:	ldr	x8, [x21]
   24e9c:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   24ea0:	ldr	x9, [x9, #3952]
   24ea4:	mov	x0, x23
   24ea8:	ubfx	x10, x8, #1, #7
   24eac:	mov	x1, x22
   24eb0:	ldrb	w9, [x9, x10]
   24eb4:	mov	w10, #0x2                   	// #2
   24eb8:	mov	x2, x20
   24ebc:	mov	x3, x21
   24ec0:	msub	x11, x8, x9, x10
   24ec4:	mul	x9, x11, x9
   24ec8:	msub	x10, x9, x8, x10
   24ecc:	mul	x9, x9, x10
   24ed0:	orr	x10, xzr, #0xfffffffffffffffe
   24ed4:	madd	x8, x9, x8, x10
   24ed8:	mul	x5, x8, x9
   24edc:	mov	x4, x19
   24ee0:	bl	c840 <__gmpn_sbpi1_bdiv_qr@plt>
   24ee4:	b	24f34 <__gmpn_divisible_p@@Base+0x318>
   24ee8:	ldr	x8, [x21]
   24eec:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   24ef0:	ldr	x9, [x9, #3952]
   24ef4:	mov	x0, x23
   24ef8:	ubfx	x10, x8, #1, #7
   24efc:	mov	x1, x22
   24f00:	ldrb	w9, [x9, x10]
   24f04:	mov	w10, #0x2                   	// #2
   24f08:	mov	x2, x20
   24f0c:	mov	x3, x21
   24f10:	msub	x11, x8, x9, x10
   24f14:	mul	x9, x11, x9
   24f18:	msub	x10, x9, x8, x10
   24f1c:	mul	x9, x9, x10
   24f20:	orr	x10, xzr, #0xfffffffffffffffe
   24f24:	madd	x8, x9, x8, x10
   24f28:	mul	x5, x8, x9
   24f2c:	mov	x4, x19
   24f30:	bl	c600 <__gmpn_dcpi1_bdiv_qr@plt>
   24f34:	add	x22, x22, x24, lsl #3
   24f38:	sub	x8, x22, #0x8
   24f3c:	sub	x9, x21, #0x8
   24f40:	subs	x10, x19, #0x1
   24f44:	b.lt	24f64 <__gmpn_divisible_p@@Base+0x348>  // b.tstop
   24f48:	ldr	x11, [x8, x19, lsl #3]
   24f4c:	ldr	x12, [x9, x19, lsl #3]
   24f50:	mov	x19, x10
   24f54:	cmp	x11, x12
   24f58:	b.eq	24f40 <__gmpn_divisible_p@@Base+0x324>  // b.none
   24f5c:	mov	w19, wzr
   24f60:	b	24f68 <__gmpn_divisible_p@@Base+0x34c>
   24f64:	mov	w19, #0x1                   	// #1
   24f68:	ldur	x0, [x29, #-8]
   24f6c:	cbz	x0, 24cb4 <__gmpn_divisible_p@@Base+0x98>
   24f70:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   24f74:	b	24cb4 <__gmpn_divisible_p@@Base+0x98>
   24f78:	sub	x0, x29, #0x8
   24f7c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   24f80:	mov	x25, x0
   24f84:	b	24d50 <__gmpn_divisible_p@@Base+0x134>
   24f88:	sub	x0, x29, #0x8
   24f8c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   24f90:	mov	x6, x0
   24f94:	b	24e78 <__gmpn_divisible_p@@Base+0x25c>

0000000000024f98 <__gmpn_divrem@@Base>:
   24f98:	stp	x29, x30, [sp, #-96]!
   24f9c:	stp	x28, x27, [sp, #16]
   24fa0:	stp	x26, x25, [sp, #32]
   24fa4:	stp	x24, x23, [sp, #48]
   24fa8:	stp	x22, x21, [sp, #64]
   24fac:	stp	x20, x19, [sp, #80]
   24fb0:	mov	x29, sp
   24fb4:	sub	sp, sp, #0x10
   24fb8:	mov	x21, x4
   24fbc:	mov	x22, x3
   24fc0:	mov	x20, x2
   24fc4:	mov	x24, x1
   24fc8:	cmp	x5, #0x2
   24fcc:	mov	x19, x0
   24fd0:	b.eq	2506c <__gmpn_divrem@@Base+0xd4>  // b.none
   24fd4:	mov	x23, x5
   24fd8:	cmp	x5, #0x1
   24fdc:	b.ne	250a0 <__gmpn_divrem@@Base+0x108>  // b.any
   24fe0:	add	x25, x22, x24
   24fe4:	lsl	x1, x25, #3
   24fe8:	mov	w8, #0x7f00                	// #32512
   24fec:	cmp	x1, x8
   24ff0:	stur	xzr, [x29, #-8]
   24ff4:	b.hi	2511c <__gmpn_divrem@@Base+0x184>  // b.pmore
   24ff8:	add	x9, x1, #0xf
   24ffc:	mov	x8, sp
   25000:	and	x9, x9, #0xfffffffffffffff0
   25004:	sub	x23, x8, x9
   25008:	mov	sp, x23
   2500c:	ldr	x4, [x21]
   25010:	mov	x0, x23
   25014:	mov	x1, x24
   25018:	mov	x2, x20
   2501c:	mov	x3, x22
   25020:	bl	cd20 <__gmpn_divrem_1@plt>
   25024:	str	x0, [x20]
   25028:	sub	x20, x25, #0x1
   2502c:	mov	x0, x19
   25030:	mov	x1, x23
   25034:	mov	x2, x20
   25038:	bl	ca70 <__gmpn_copyi@plt>
   2503c:	ldur	x0, [x29, #-8]
   25040:	ldr	x19, [x23, x20, lsl #3]
   25044:	cbnz	x0, 25114 <__gmpn_divrem@@Base+0x17c>
   25048:	mov	x0, x19
   2504c:	mov	sp, x29
   25050:	ldp	x20, x19, [sp, #80]
   25054:	ldp	x22, x21, [sp, #64]
   25058:	ldp	x24, x23, [sp, #48]
   2505c:	ldp	x26, x25, [sp, #32]
   25060:	ldp	x28, x27, [sp, #16]
   25064:	ldp	x29, x30, [sp], #96
   25068:	ret
   2506c:	mov	x0, x19
   25070:	mov	x1, x24
   25074:	mov	x2, x20
   25078:	mov	x3, x22
   2507c:	mov	x4, x21
   25080:	mov	sp, x29
   25084:	ldp	x20, x19, [sp, #80]
   25088:	ldp	x22, x21, [sp, #64]
   2508c:	ldp	x24, x23, [sp, #48]
   25090:	ldp	x26, x25, [sp, #32]
   25094:	ldp	x28, x27, [sp, #16]
   25098:	ldp	x29, x30, [sp], #96
   2509c:	b	c210 <__gmpn_divrem_2@plt>
   250a0:	stur	xzr, [x29, #-8]
   250a4:	cbnz	x24, 2512c <__gmpn_divrem@@Base+0x194>
   250a8:	sub	x24, x22, x23
   250ac:	lsl	x8, x24, #3
   250b0:	add	x1, x8, #0x8
   250b4:	mov	w8, #0x7f00                	// #32512
   250b8:	cmp	x1, x8
   250bc:	b.hi	251c0 <__gmpn_divrem@@Base+0x228>  // b.pmore
   250c0:	add	x9, x1, #0xf
   250c4:	mov	x8, sp
   250c8:	and	x9, x9, #0xfffffffffffffff0
   250cc:	sub	x25, x8, x9
   250d0:	mov	sp, x25
   250d4:	mov	x0, x25
   250d8:	mov	x1, x20
   250dc:	mov	x2, xzr
   250e0:	mov	x3, x20
   250e4:	mov	x4, x22
   250e8:	mov	x5, x21
   250ec:	mov	x6, x23
   250f0:	bl	bf10 <__gmpn_tdiv_qr@plt>
   250f4:	mov	x0, x19
   250f8:	mov	x1, x25
   250fc:	mov	x2, x24
   25100:	bl	ca70 <__gmpn_copyi@plt>
   25104:	add	x8, x25, x24, lsl #3
   25108:	ldur	x0, [x29, #-8]
   2510c:	ldr	x19, [x8]
   25110:	cbz	x0, 25048 <__gmpn_divrem@@Base+0xb0>
   25114:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   25118:	b	25048 <__gmpn_divrem@@Base+0xb0>
   2511c:	sub	x0, x29, #0x8
   25120:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   25124:	mov	x23, x0
   25128:	b	2500c <__gmpn_divrem@@Base+0x74>
   2512c:	sub	x8, x22, x23
   25130:	add	x26, x22, x24
   25134:	add	x25, x8, x24
   25138:	add	x8, x26, x25
   2513c:	lsl	x8, x8, #3
   25140:	add	x1, x8, #0x8
   25144:	mov	w8, #0x7f00                	// #32512
   25148:	cmp	x1, x8
   2514c:	b.hi	251d0 <__gmpn_divrem@@Base+0x238>  // b.pmore
   25150:	add	x9, x1, #0xf
   25154:	mov	x8, sp
   25158:	and	x9, x9, #0xfffffffffffffff0
   2515c:	sub	x27, x8, x9
   25160:	mov	sp, x27
   25164:	lsl	x2, x24, #3
   25168:	mov	x0, x27
   2516c:	mov	w1, wzr
   25170:	bl	c610 <memset@plt>
   25174:	add	x0, x27, x24, lsl #3
   25178:	mov	x1, x20
   2517c:	mov	x2, x22
   25180:	add	x28, x27, x26, lsl #3
   25184:	bl	ca70 <__gmpn_copyi@plt>
   25188:	mov	x0, x28
   2518c:	mov	x1, x20
   25190:	mov	x2, xzr
   25194:	mov	x3, x27
   25198:	mov	x4, x26
   2519c:	mov	x5, x21
   251a0:	mov	x6, x23
   251a4:	bl	bf10 <__gmpn_tdiv_qr@plt>
   251a8:	mov	x0, x19
   251ac:	mov	x1, x28
   251b0:	mov	x2, x25
   251b4:	bl	ca70 <__gmpn_copyi@plt>
   251b8:	add	x8, x28, x25, lsl #3
   251bc:	b	25108 <__gmpn_divrem@@Base+0x170>
   251c0:	sub	x0, x29, #0x8
   251c4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   251c8:	mov	x25, x0
   251cc:	b	250d4 <__gmpn_divrem@@Base+0x13c>
   251d0:	sub	x0, x29, #0x8
   251d4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   251d8:	mov	x27, x0
   251dc:	b	25164 <__gmpn_divrem@@Base+0x1cc>

00000000000251e0 <__gmpn_divrem_1@@Base>:
   251e0:	stp	x29, x30, [sp, #-80]!
   251e4:	adds	x8, x3, x1
   251e8:	str	x25, [sp, #16]
   251ec:	stp	x24, x23, [sp, #32]
   251f0:	stp	x22, x21, [sp, #48]
   251f4:	stp	x20, x19, [sp, #64]
   251f8:	mov	x29, sp
   251fc:	b.eq	25248 <__gmpn_divrem_1@@Base+0x68>  // b.none
   25200:	sub	x9, x8, #0x1
   25204:	mov	x20, x4
   25208:	mov	x21, x3
   2520c:	mov	x23, x2
   25210:	mov	x19, x1
   25214:	add	x24, x0, x9, lsl #3
   25218:	tbnz	x4, #63, 25304 <__gmpn_divrem_1@@Base+0x124>
   2521c:	cbz	x21, 25250 <__gmpn_divrem_1@@Base+0x70>
   25220:	sub	x10, x21, #0x1
   25224:	ldr	x22, [x23, x10, lsl #3]
   25228:	cmp	x22, x20
   2522c:	b.cs	25250 <__gmpn_divrem_1@@Base+0x70>  // b.hs, b.nlast
   25230:	str	xzr, [x24]
   25234:	cbz	x9, 2581c <__gmpn_divrem_1@@Base+0x63c>
   25238:	sub	x24, x24, #0x8
   2523c:	mov	x8, x9
   25240:	mov	x21, x10
   25244:	b	25254 <__gmpn_divrem_1@@Base+0x74>
   25248:	mov	x22, xzr
   2524c:	b	2581c <__gmpn_divrem_1@@Base+0x63c>
   25250:	mov	x22, xzr
   25254:	clz	x25, x20
   25258:	cmp	x8, #0x3
   2525c:	lsl	x20, x20, x25
   25260:	lsl	x22, x22, x25
   25264:	b.le	2532c <__gmpn_divrem_1@@Base+0x14c>
   25268:	mov	x0, x20
   2526c:	bl	d410 <__gmpn_invert_limb@plt>
   25270:	cbz	x21, 25684 <__gmpn_divrem_1@@Base+0x4a4>
   25274:	add	x8, x23, x21, lsl #3
   25278:	ldur	x12, [x8, #-8]
   2527c:	neg	x8, x25
   25280:	cmp	x21, #0x2
   25284:	lsr	x8, x12, x8
   25288:	orr	x11, x8, x22
   2528c:	b.lt	2563c <__gmpn_divrem_1@@Base+0x45c>  // b.tstop
   25290:	mov	w8, #0x40                  	// #64
   25294:	sub	x8, x8, x25
   25298:	sub	x9, x23, #0x10
   2529c:	ldr	x10, [x9, x21, lsl #3]
   252a0:	lsl	x12, x12, x25
   252a4:	umulh	x13, x11, x0
   252a8:	lsr	x14, x10, x8
   252ac:	orr	x12, x14, x12
   252b0:	mul	x14, x11, x0
   252b4:	add	x11, x11, #0x1
   252b8:	adds	x15, x14, x12
   252bc:	adc	x11, x13, x11
   252c0:	msub	x12, x11, x20, x12
   252c4:	cmp	x12, x15
   252c8:	cset	w14, hi  // hi = pmore
   252cc:	sub	x11, x11, x14
   252d0:	csel	x14, x20, xzr, hi  // hi = pmore
   252d4:	add	x12, x14, x12
   252d8:	cmp	x12, x20
   252dc:	sub	x13, x21, #0x2
   252e0:	cinc	x14, x11, cs  // cs = hs, nlast
   252e4:	csel	x11, xzr, x20, cc  // cc = lo, ul, last
   252e8:	sub	x21, x21, #0x1
   252ec:	cmp	x13, #0x0
   252f0:	sub	x11, x12, x11
   252f4:	str	x14, [x24], #-8
   252f8:	mov	x12, x10
   252fc:	b.gt	2529c <__gmpn_divrem_1@@Base+0xbc>
   25300:	b	25640 <__gmpn_divrem_1@@Base+0x460>
   25304:	cbz	x21, 25418 <__gmpn_divrem_1@@Base+0x238>
   25308:	sub	x21, x21, #0x1
   2530c:	ldr	x8, [x23, x21, lsl #3]
   25310:	cmp	x8, x20
   25314:	cset	w10, cs  // cs = hs, nlast
   25318:	csel	x11, x20, xzr, cs  // cs = hs, nlast
   2531c:	str	x10, [x24], #-8
   25320:	sub	x22, x8, x11
   25324:	mov	x8, x9
   25328:	b	2541c <__gmpn_divrem_1@@Base+0x23c>
   2532c:	cbz	x21, 25768 <__gmpn_divrem_1@@Base+0x588>
   25330:	add	x8, x23, x21, lsl #3
   25334:	ldur	x10, [x8, #-8]
   25338:	neg	x8, x25
   2533c:	cmp	x21, #0x1
   25340:	lsr	x8, x10, x8
   25344:	orr	x13, x8, x22
   25348:	b.le	256cc <__gmpn_divrem_1@@Base+0x4ec>
   2534c:	mov	w11, #0x40                  	// #64
   25350:	lsr	x8, x20, #32
   25354:	and	x9, x20, #0xffffffff
   25358:	sub	x11, x11, x25
   2535c:	sub	x12, x23, #0x10
   25360:	mov	x14, x10
   25364:	ldr	x10, [x12, x21, lsl #3]
   25368:	udiv	x17, x13, x8
   2536c:	lsl	x14, x14, x25
   25370:	msub	w16, w17, w8, w13
   25374:	lsr	x13, x10, x11
   25378:	orr	x13, x13, x14
   2537c:	mul	x15, x17, x9
   25380:	extr	x16, x16, x13, #32
   25384:	cmp	x16, x15
   25388:	b.cs	253b0 <__gmpn_divrem_1@@Base+0x1d0>  // b.hs, b.nlast
   2538c:	add	x16, x16, x20
   25390:	cmp	x16, x20
   25394:	sub	x14, x17, #0x1
   25398:	b.cc	253b4 <__gmpn_divrem_1@@Base+0x1d4>  // b.lo, b.ul, b.last
   2539c:	cmp	x16, x15
   253a0:	b.cs	253b4 <__gmpn_divrem_1@@Base+0x1d4>  // b.hs, b.nlast
   253a4:	sub	x14, x17, #0x2
   253a8:	add	x16, x16, x20
   253ac:	b	253b4 <__gmpn_divrem_1@@Base+0x1d4>
   253b0:	mov	x14, x17
   253b4:	sub	x15, x16, x15
   253b8:	udiv	x16, x15, x8
   253bc:	msub	w17, w16, w8, w15
   253c0:	mul	x15, x16, x9
   253c4:	bfi	x13, x17, #32, #32
   253c8:	cmp	x13, x15
   253cc:	b.cs	253f4 <__gmpn_divrem_1@@Base+0x214>  // b.hs, b.nlast
   253d0:	add	x13, x13, x20
   253d4:	cmp	x13, x20
   253d8:	sub	x17, x16, #0x1
   253dc:	b.cc	253f8 <__gmpn_divrem_1@@Base+0x218>  // b.lo, b.ul, b.last
   253e0:	cmp	x13, x15
   253e4:	b.cs	253f8 <__gmpn_divrem_1@@Base+0x218>  // b.hs, b.nlast
   253e8:	sub	x17, x16, #0x2
   253ec:	add	x13, x13, x20
   253f0:	b	253f8 <__gmpn_divrem_1@@Base+0x218>
   253f4:	mov	x17, x16
   253f8:	sub	x13, x13, x15
   253fc:	orr	x14, x17, x14, lsl #32
   25400:	sub	x15, x21, #0x2
   25404:	sub	x21, x21, #0x1
   25408:	cmp	x15, #0x0
   2540c:	str	x14, [x24], #-8
   25410:	b.gt	25360 <__gmpn_divrem_1@@Base+0x180>
   25414:	b	256d4 <__gmpn_divrem_1@@Base+0x4f4>
   25418:	mov	x22, xzr
   2541c:	cmp	x8, #0x2
   25420:	b.le	254d4 <__gmpn_divrem_1@@Base+0x2f4>
   25424:	mov	x0, x20
   25428:	bl	d410 <__gmpn_invert_limb@plt>
   2542c:	cmp	x21, #0x1
   25430:	b.lt	2548c <__gmpn_divrem_1@@Base+0x2ac>  // b.tstop
   25434:	add	x8, x21, #0x1
   25438:	sub	x9, x23, #0x10
   2543c:	ldr	x10, [x9, x8, lsl #3]
   25440:	umulh	x11, x22, x0
   25444:	mul	x12, x22, x0
   25448:	add	x13, x22, #0x1
   2544c:	adds	x14, x12, x10
   25450:	adc	x11, x11, x13
   25454:	msub	x10, x11, x20, x10
   25458:	cmp	x10, x14
   2545c:	csel	x13, x20, xzr, hi  // hi = pmore
   25460:	cset	w12, hi  // hi = pmore
   25464:	add	x10, x13, x10
   25468:	sub	x11, x11, x12
   2546c:	cmp	x10, x20
   25470:	sub	x8, x8, #0x1
   25474:	csel	x12, xzr, x20, cc  // cc = lo, ul, last
   25478:	cinc	x11, x11, cs  // cs = hs, nlast
   2547c:	cmp	x8, #0x1
   25480:	sub	x22, x10, x12
   25484:	str	x11, [x24], #-8
   25488:	b.gt	2543c <__gmpn_divrem_1@@Base+0x25c>
   2548c:	cmp	x19, #0x1
   25490:	b.lt	2581c <__gmpn_divrem_1@@Base+0x63c>  // b.tstop
   25494:	add	x8, x19, #0x1
   25498:	umulh	x9, x22, x0
   2549c:	add	x9, x22, x9
   254a0:	add	x9, x9, #0x1
   254a4:	mul	x10, x22, x0
   254a8:	mneg	x11, x9, x20
   254ac:	cmp	x10, x11
   254b0:	cset	w10, cc  // cc = lo, ul, last
   254b4:	sub	x8, x8, #0x1
   254b8:	csel	x11, x20, xzr, cc  // cc = lo, ul, last
   254bc:	sub	x10, x9, x10
   254c0:	msub	x22, x9, x20, x11
   254c4:	cmp	x8, #0x1
   254c8:	str	x10, [x24], #-8
   254cc:	b.gt	25498 <__gmpn_divrem_1@@Base+0x2b8>
   254d0:	b	2581c <__gmpn_divrem_1@@Base+0x63c>
   254d4:	cmp	x21, #0x1
   254d8:	lsr	x8, x20, #32
   254dc:	b.lt	2558c <__gmpn_divrem_1@@Base+0x3ac>  // b.tstop
   254e0:	and	x9, x20, #0xffffffff
   254e4:	add	x10, x21, #0x1
   254e8:	sub	x11, x23, #0x10
   254ec:	ldr	x12, [x11, x10, lsl #3]
   254f0:	udiv	x16, x22, x8
   254f4:	msub	w13, w16, w8, w22
   254f8:	mul	x14, x16, x9
   254fc:	extr	x15, x13, x12, #32
   25500:	cmp	x15, x14
   25504:	b.cs	2552c <__gmpn_divrem_1@@Base+0x34c>  // b.hs, b.nlast
   25508:	add	x15, x15, x20
   2550c:	cmp	x15, x20
   25510:	sub	x13, x16, #0x1
   25514:	b.cc	25530 <__gmpn_divrem_1@@Base+0x350>  // b.lo, b.ul, b.last
   25518:	cmp	x15, x14
   2551c:	b.cs	25530 <__gmpn_divrem_1@@Base+0x350>  // b.hs, b.nlast
   25520:	sub	x13, x16, #0x2
   25524:	add	x15, x15, x20
   25528:	b	25530 <__gmpn_divrem_1@@Base+0x350>
   2552c:	mov	x13, x16
   25530:	sub	x14, x15, x14
   25534:	udiv	x15, x14, x8
   25538:	msub	w16, w15, w8, w14
   2553c:	mul	x14, x15, x9
   25540:	bfi	x12, x16, #32, #32
   25544:	cmp	x12, x14
   25548:	b.cs	25570 <__gmpn_divrem_1@@Base+0x390>  // b.hs, b.nlast
   2554c:	add	x12, x12, x20
   25550:	cmp	x12, x20
   25554:	sub	x16, x15, #0x1
   25558:	b.cc	25574 <__gmpn_divrem_1@@Base+0x394>  // b.lo, b.ul, b.last
   2555c:	cmp	x12, x14
   25560:	b.cs	25574 <__gmpn_divrem_1@@Base+0x394>  // b.hs, b.nlast
   25564:	sub	x16, x15, #0x2
   25568:	add	x12, x12, x20
   2556c:	b	25574 <__gmpn_divrem_1@@Base+0x394>
   25570:	mov	x16, x15
   25574:	sub	x22, x12, x14
   25578:	orr	x12, x16, x13, lsl #32
   2557c:	sub	x10, x10, #0x1
   25580:	cmp	x10, #0x1
   25584:	str	x12, [x24], #-8
   25588:	b.gt	254ec <__gmpn_divrem_1@@Base+0x30c>
   2558c:	cmp	x19, #0x1
   25590:	b.lt	2581c <__gmpn_divrem_1@@Base+0x63c>  // b.tstop
   25594:	and	x9, x20, #0xffffffff
   25598:	add	x10, x19, #0x1
   2559c:	udiv	x14, x22, x8
   255a0:	msub	w11, w14, w8, w22
   255a4:	mul	x12, x14, x9
   255a8:	lsl	x13, x11, #32
   255ac:	cmp	x13, x12
   255b0:	b.cs	255d8 <__gmpn_divrem_1@@Base+0x3f8>  // b.hs, b.nlast
   255b4:	add	x13, x13, x20
   255b8:	cmp	x13, x20
   255bc:	sub	x11, x14, #0x1
   255c0:	b.cc	255dc <__gmpn_divrem_1@@Base+0x3fc>  // b.lo, b.ul, b.last
   255c4:	cmp	x13, x12
   255c8:	b.cs	255dc <__gmpn_divrem_1@@Base+0x3fc>  // b.hs, b.nlast
   255cc:	sub	x11, x14, #0x2
   255d0:	add	x13, x13, x20
   255d4:	b	255dc <__gmpn_divrem_1@@Base+0x3fc>
   255d8:	mov	x11, x14
   255dc:	sub	x12, x13, x12
   255e0:	udiv	x14, x12, x8
   255e4:	msub	w13, w14, w8, w12
   255e8:	mul	x12, x14, x9
   255ec:	lsl	x13, x13, #32
   255f0:	cmp	x13, x12
   255f4:	b.cs	2561c <__gmpn_divrem_1@@Base+0x43c>  // b.hs, b.nlast
   255f8:	add	x13, x13, x20
   255fc:	cmp	x13, x20
   25600:	sub	x15, x14, #0x1
   25604:	b.cc	25620 <__gmpn_divrem_1@@Base+0x440>  // b.lo, b.ul, b.last
   25608:	cmp	x13, x12
   2560c:	b.cs	25620 <__gmpn_divrem_1@@Base+0x440>  // b.hs, b.nlast
   25610:	sub	x15, x14, #0x2
   25614:	add	x13, x13, x20
   25618:	b	25620 <__gmpn_divrem_1@@Base+0x440>
   2561c:	mov	x15, x14
   25620:	orr	x11, x15, x11, lsl #32
   25624:	sub	x10, x10, #0x1
   25628:	sub	x22, x13, x12
   2562c:	cmp	x10, #0x1
   25630:	str	x11, [x24], #-8
   25634:	b.gt	2559c <__gmpn_divrem_1@@Base+0x3bc>
   25638:	b	2581c <__gmpn_divrem_1@@Base+0x63c>
   2563c:	mov	x10, x12
   25640:	umulh	x8, x11, x0
   25644:	mul	x9, x11, x0
   25648:	lsl	x10, x10, x25
   2564c:	add	x11, x11, #0x1
   25650:	adds	x12, x9, x10
   25654:	adc	x8, x8, x11
   25658:	msub	x9, x8, x20, x10
   2565c:	cmp	x9, x12
   25660:	csel	x11, x20, xzr, hi  // hi = pmore
   25664:	cset	w10, hi  // hi = pmore
   25668:	add	x9, x11, x9
   2566c:	sub	x8, x8, x10
   25670:	cmp	x9, x20
   25674:	cinc	x8, x8, cs  // cs = hs, nlast
   25678:	csel	x10, xzr, x20, cc  // cc = lo, ul, last
   2567c:	sub	x22, x9, x10
   25680:	str	x8, [x24], #-8
   25684:	cmp	x19, #0x1
   25688:	b.lt	25818 <__gmpn_divrem_1@@Base+0x638>  // b.tstop
   2568c:	add	x8, x19, #0x1
   25690:	umulh	x9, x22, x0
   25694:	add	x9, x22, x9
   25698:	add	x9, x9, #0x1
   2569c:	mul	x10, x22, x0
   256a0:	mneg	x11, x9, x20
   256a4:	cmp	x10, x11
   256a8:	cset	w10, cc  // cc = lo, ul, last
   256ac:	sub	x8, x8, #0x1
   256b0:	csel	x11, x20, xzr, cc  // cc = lo, ul, last
   256b4:	sub	x10, x9, x10
   256b8:	msub	x22, x9, x20, x11
   256bc:	cmp	x8, #0x1
   256c0:	str	x10, [x24], #-8
   256c4:	b.gt	25690 <__gmpn_divrem_1@@Base+0x4b0>
   256c8:	b	25818 <__gmpn_divrem_1@@Base+0x638>
   256cc:	lsr	x8, x20, #32
   256d0:	and	x9, x20, #0xffffffff
   256d4:	udiv	x14, x13, x8
   256d8:	msub	w11, w14, w8, w13
   256dc:	lsl	x10, x10, x25
   256e0:	mul	x12, x14, x9
   256e4:	extr	x13, x11, x10, #32
   256e8:	cmp	x13, x12
   256ec:	b.cs	25714 <__gmpn_divrem_1@@Base+0x534>  // b.hs, b.nlast
   256f0:	add	x13, x13, x20
   256f4:	cmp	x13, x20
   256f8:	sub	x11, x14, #0x1
   256fc:	b.cc	25718 <__gmpn_divrem_1@@Base+0x538>  // b.lo, b.ul, b.last
   25700:	cmp	x13, x12
   25704:	b.cs	25718 <__gmpn_divrem_1@@Base+0x538>  // b.hs, b.nlast
   25708:	sub	x11, x14, #0x2
   2570c:	add	x13, x13, x20
   25710:	b	25718 <__gmpn_divrem_1@@Base+0x538>
   25714:	mov	x11, x14
   25718:	sub	x13, x13, x12
   2571c:	udiv	x12, x13, x8
   25720:	msub	w13, w12, w8, w13
   25724:	mul	x8, x12, x9
   25728:	bfi	x10, x13, #32, #32
   2572c:	cmp	x10, x8
   25730:	b.cs	25758 <__gmpn_divrem_1@@Base+0x578>  // b.hs, b.nlast
   25734:	add	x10, x10, x20
   25738:	cmp	x10, x20
   2573c:	sub	x9, x12, #0x1
   25740:	b.cc	2575c <__gmpn_divrem_1@@Base+0x57c>  // b.lo, b.ul, b.last
   25744:	cmp	x10, x8
   25748:	b.cs	2575c <__gmpn_divrem_1@@Base+0x57c>  // b.hs, b.nlast
   2574c:	sub	x9, x12, #0x2
   25750:	add	x10, x10, x20
   25754:	b	2575c <__gmpn_divrem_1@@Base+0x57c>
   25758:	mov	x9, x12
   2575c:	sub	x22, x10, x8
   25760:	orr	x8, x9, x11, lsl #32
   25764:	str	x8, [x24], #-8
   25768:	cmp	x19, #0x1
   2576c:	b.lt	25818 <__gmpn_divrem_1@@Base+0x638>  // b.tstop
   25770:	lsr	x8, x20, #32
   25774:	and	x9, x20, #0xffffffff
   25778:	add	x10, x19, #0x1
   2577c:	udiv	x14, x22, x8
   25780:	msub	w11, w14, w8, w22
   25784:	mul	x12, x14, x9
   25788:	lsl	x13, x11, #32
   2578c:	cmp	x13, x12
   25790:	b.cs	257b8 <__gmpn_divrem_1@@Base+0x5d8>  // b.hs, b.nlast
   25794:	add	x13, x13, x20
   25798:	cmp	x13, x20
   2579c:	sub	x11, x14, #0x1
   257a0:	b.cc	257bc <__gmpn_divrem_1@@Base+0x5dc>  // b.lo, b.ul, b.last
   257a4:	cmp	x13, x12
   257a8:	b.cs	257bc <__gmpn_divrem_1@@Base+0x5dc>  // b.hs, b.nlast
   257ac:	sub	x11, x14, #0x2
   257b0:	add	x13, x13, x20
   257b4:	b	257bc <__gmpn_divrem_1@@Base+0x5dc>
   257b8:	mov	x11, x14
   257bc:	sub	x12, x13, x12
   257c0:	udiv	x14, x12, x8
   257c4:	msub	w13, w14, w8, w12
   257c8:	mul	x12, x14, x9
   257cc:	lsl	x13, x13, #32
   257d0:	cmp	x13, x12
   257d4:	b.cs	257fc <__gmpn_divrem_1@@Base+0x61c>  // b.hs, b.nlast
   257d8:	add	x13, x13, x20
   257dc:	cmp	x13, x20
   257e0:	sub	x15, x14, #0x1
   257e4:	b.cc	25800 <__gmpn_divrem_1@@Base+0x620>  // b.lo, b.ul, b.last
   257e8:	cmp	x13, x12
   257ec:	b.cs	25800 <__gmpn_divrem_1@@Base+0x620>  // b.hs, b.nlast
   257f0:	sub	x15, x14, #0x2
   257f4:	add	x13, x13, x20
   257f8:	b	25800 <__gmpn_divrem_1@@Base+0x620>
   257fc:	mov	x15, x14
   25800:	orr	x11, x15, x11, lsl #32
   25804:	sub	x10, x10, #0x1
   25808:	sub	x22, x13, x12
   2580c:	cmp	x10, #0x1
   25810:	str	x11, [x24], #-8
   25814:	b.gt	2577c <__gmpn_divrem_1@@Base+0x59c>
   25818:	lsr	x22, x22, x25
   2581c:	mov	x0, x22
   25820:	ldp	x20, x19, [sp, #64]
   25824:	ldp	x22, x21, [sp, #48]
   25828:	ldp	x24, x23, [sp, #32]
   2582c:	ldr	x25, [sp, #16]
   25830:	ldp	x29, x30, [sp], #80
   25834:	ret

0000000000025838 <__gmpn_divrem_2@@Base>:
   25838:	stp	x29, x30, [sp, #-96]!
   2583c:	stp	x28, x27, [sp, #16]
   25840:	stp	x26, x25, [sp, #32]
   25844:	stp	x24, x23, [sp, #48]
   25848:	stp	x22, x21, [sp, #64]
   2584c:	stp	x20, x19, [sp, #80]
   25850:	add	x28, x2, x3, lsl #3
   25854:	ldr	x27, [x28, #-16]!
   25858:	ldp	x25, x20, [x4]
   2585c:	mov	x24, x3
   25860:	mov	x22, x2
   25864:	ldr	x26, [x28, #8]
   25868:	mov	x19, x1
   2586c:	mov	x23, x0
   25870:	mov	x29, sp
   25874:	cmp	x26, x20
   25878:	b.cc	25888 <__gmpn_divrem_2@@Base+0x50>  // b.lo, b.ul, b.last
   2587c:	b.hi	25890 <__gmpn_divrem_2@@Base+0x58>  // b.pmore
   25880:	cmp	x27, x25
   25884:	b.cs	25890 <__gmpn_divrem_2@@Base+0x58>  // b.hs, b.nlast
   25888:	mov	x21, xzr
   2588c:	b	258a0 <__gmpn_divrem_2@@Base+0x68>
   25890:	subs	x8, x27, x25
   25894:	sbc	x26, x26, x20
   25898:	mov	w21, #0x1                   	// #1
   2589c:	mov	x27, x8
   258a0:	mov	x0, x20
   258a4:	bl	d410 <__gmpn_invert_limb@plt>
   258a8:	mul	x8, x0, x20
   258ac:	adds	x8, x8, x25
   258b0:	b.cc	258cc <__gmpn_divrem_2@@Base+0x94>  // b.lo, b.ul, b.last
   258b4:	subs	x8, x8, x20
   258b8:	cset	w9, cs  // cs = hs, nlast
   258bc:	csel	x10, x20, xzr, cs  // cs = hs, nlast
   258c0:	mvn	x9, x9
   258c4:	add	x0, x9, x0
   258c8:	sub	x8, x8, x10
   258cc:	umulh	x9, x25, x0
   258d0:	adds	x9, x9, x8
   258d4:	b.cc	258fc <__gmpn_divrem_2@@Base+0xc4>  // b.lo, b.ul, b.last
   258d8:	cmp	x9, x20
   258dc:	sub	x8, x0, #0x1
   258e0:	b.cc	25900 <__gmpn_divrem_2@@Base+0xc8>  // b.lo, b.ul, b.last
   258e4:	mul	x10, x0, x25
   258e8:	cmp	x9, x20
   258ec:	sub	x11, x0, #0x2
   258f0:	ccmp	x10, x25, #0x2, ls  // ls = plast
   258f4:	csel	x8, x8, x11, cc  // cc = lo, ul, last
   258f8:	b	25900 <__gmpn_divrem_2@@Base+0xc8>
   258fc:	mov	x8, x0
   25900:	subs	x9, x24, #0x3
   25904:	b.lt	259a8 <__gmpn_divrem_2@@Base+0x170>  // b.tstop
   25908:	add	x10, x23, x19, lsl #3
   2590c:	ldr	x11, [x22, x9, lsl #3]
   25910:	mul	x12, x26, x8
   25914:	umulh	x13, x26, x8
   25918:	adds	x14, x12, x27
   2591c:	adc	x12, x13, x26
   25920:	msub	x13, x12, x20, x27
   25924:	subs	x17, x11, x25
   25928:	sbc	x11, x13, x20
   2592c:	mul	x15, x12, x25
   25930:	umulh	x16, x25, x12
   25934:	subs	x13, x17, x15
   25938:	sbc	x11, x11, x16
   2593c:	cmp	x11, x14
   25940:	cset	w14, cs  // cs = hs, nlast
   25944:	csetm	x15, cs  // cs = hs, nlast
   25948:	sub	x12, x12, x14
   2594c:	and	x14, x25, x15
   25950:	and	x15, x20, x15
   25954:	adds	x27, x13, x14
   25958:	adc	x26, x11, x15
   2595c:	cmp	x26, x20
   25960:	add	x11, x12, #0x1
   25964:	b.cs	25980 <__gmpn_divrem_2@@Base+0x148>  // b.hs, b.nlast
   25968:	sub	x12, x9, #0x1
   2596c:	cmp	x9, #0x0
   25970:	str	x11, [x10, x9, lsl #3]
   25974:	mov	x9, x12
   25978:	b.gt	2590c <__gmpn_divrem_2@@Base+0xd4>
   2597c:	b	259a4 <__gmpn_divrem_2@@Base+0x16c>
   25980:	cmp	x27, x25
   25984:	b.cs	25990 <__gmpn_divrem_2@@Base+0x158>  // b.hs, b.nlast
   25988:	cmp	x26, x20
   2598c:	b.ls	25968 <__gmpn_divrem_2@@Base+0x130>  // b.plast
   25990:	subs	x12, x27, x25
   25994:	sbc	x26, x26, x20
   25998:	add	x11, x11, #0x1
   2599c:	mov	x27, x12
   259a0:	b	25968 <__gmpn_divrem_2@@Base+0x130>
   259a4:	mov	x28, x22
   259a8:	cmp	x19, #0x1
   259ac:	b.ge	259d4 <__gmpn_divrem_2@@Base+0x19c>  // b.tcont
   259b0:	stp	x27, x26, [x28]
   259b4:	mov	x0, x21
   259b8:	ldp	x20, x19, [sp, #80]
   259bc:	ldp	x22, x21, [sp, #64]
   259c0:	ldp	x24, x23, [sp, #48]
   259c4:	ldp	x26, x25, [sp, #32]
   259c8:	ldp	x28, x27, [sp, #16]
   259cc:	ldp	x29, x30, [sp], #96
   259d0:	ret
   259d4:	sub	x9, x23, #0x8
   259d8:	mov	x11, xzr
   259dc:	mul	x12, x26, x8
   259e0:	umulh	x13, x26, x8
   259e4:	adds	x14, x12, x27
   259e8:	adc	x12, x13, x26
   259ec:	msub	x13, x12, x20, x27
   259f0:	subs	x17, x11, x25
   259f4:	sbc	x11, x13, x20
   259f8:	mul	x15, x12, x25
   259fc:	umulh	x16, x25, x12
   25a00:	subs	x13, x17, x15
   25a04:	sbc	x11, x11, x16
   25a08:	cmp	x11, x14
   25a0c:	cset	w14, cs  // cs = hs, nlast
   25a10:	csetm	x15, cs  // cs = hs, nlast
   25a14:	sub	x12, x12, x14
   25a18:	and	x14, x25, x15
   25a1c:	and	x15, x20, x15
   25a20:	adds	x27, x13, x14
   25a24:	adc	x26, x11, x15
   25a28:	sub	x10, x19, #0x1
   25a2c:	cmp	x26, x20
   25a30:	add	x11, x12, #0x1
   25a34:	b.cs	25a50 <__gmpn_divrem_2@@Base+0x218>  // b.hs, b.nlast
   25a38:	add	x12, x10, #0x1
   25a3c:	cmp	x12, #0x1
   25a40:	str	x11, [x9, x19, lsl #3]
   25a44:	mov	x19, x10
   25a48:	b.gt	259d8 <__gmpn_divrem_2@@Base+0x1a0>
   25a4c:	b	259b0 <__gmpn_divrem_2@@Base+0x178>
   25a50:	cmp	x27, x25
   25a54:	b.cs	25a60 <__gmpn_divrem_2@@Base+0x228>  // b.hs, b.nlast
   25a58:	cmp	x26, x20
   25a5c:	b.ls	25a38 <__gmpn_divrem_2@@Base+0x200>  // b.plast
   25a60:	subs	x12, x27, x25
   25a64:	sbc	x26, x26, x20
   25a68:	add	x11, x11, #0x1
   25a6c:	mov	x27, x12
   25a70:	b	25a38 <__gmpn_divrem_2@@Base+0x200>

0000000000025a74 <__gmpn_fib2_ui@@Base>:
   25a74:	stp	x29, x30, [sp, #-80]!
   25a78:	stp	x26, x25, [sp, #16]
   25a7c:	stp	x24, x23, [sp, #32]
   25a80:	stp	x22, x21, [sp, #48]
   25a84:	stp	x20, x19, [sp, #64]
   25a88:	mov	x29, sp
   25a8c:	sub	sp, sp, #0x10
   25a90:	mov	x19, x2
   25a94:	mov	x20, x1
   25a98:	cmp	x2, #0x5e
   25a9c:	mov	x21, x0
   25aa0:	mov	w24, #0x1                   	// #1
   25aa4:	b.cc	25ac4 <__gmpn_fib2_ui@@Base+0x50>  // b.lo, b.ul, b.last
   25aa8:	mov	x8, x19
   25aac:	lsr	x9, x8, #1
   25ab0:	cmp	x8, #0xbb
   25ab4:	lsl	x24, x24, #1
   25ab8:	mov	x8, x9
   25abc:	b.hi	25aac <__gmpn_fib2_ui@@Base+0x38>  // b.pmore
   25ac0:	b	25ac8 <__gmpn_fib2_ui@@Base+0x54>
   25ac4:	mov	x9, x19
   25ac8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   25acc:	ldr	x8, [x8, #3808]
   25ad0:	cmp	x24, #0x1
   25ad4:	add	x8, x8, x9, lsl #3
   25ad8:	ldp	x9, x8, [x8]
   25adc:	str	x9, [x20]
   25ae0:	str	x8, [x21]
   25ae4:	b.ne	25af0 <__gmpn_fib2_ui@@Base+0x7c>  // b.any
   25ae8:	mov	w23, #0x1                   	// #1
   25aec:	b	25c3c <__gmpn_fib2_ui@@Base+0x1c8>
   25af0:	lsr	x8, x19, #5
   25af4:	mov	w9, #0x17                  	// #23
   25af8:	mul	x8, x8, x9
   25afc:	lsr	x8, x8, #6
   25b00:	lsl	x9, x8, #3
   25b04:	cmp	x8, #0xfdc
   25b08:	add	x1, x9, #0x20
   25b0c:	stur	xzr, [x29, #-8]
   25b10:	b.hi	25c5c <__gmpn_fib2_ui@@Base+0x1e8>  // b.pmore
   25b14:	add	x9, x1, #0xf
   25b18:	mov	x8, sp
   25b1c:	and	x9, x9, #0x7ffffffffffffff0
   25b20:	sub	x22, x8, x9
   25b24:	mov	sp, x22
   25b28:	add	x25, x21, #0x8
   25b2c:	mov	w23, #0x1                   	// #1
   25b30:	mov	x0, x22
   25b34:	mov	x1, x21
   25b38:	mov	x2, x23
   25b3c:	bl	c900 <__gmpn_sqr@plt>
   25b40:	mov	x0, x21
   25b44:	mov	x1, x20
   25b48:	mov	x2, x23
   25b4c:	bl	c900 <__gmpn_sqr@plt>
   25b50:	add	x8, x22, x23, lsl #4
   25b54:	ldur	x8, [x8, #-8]
   25b58:	lsl	x9, x23, #1
   25b5c:	mov	x0, x20
   25b60:	mov	x1, x22
   25b64:	cmp	x8, #0x0
   25b68:	cset	w8, eq  // eq = none
   25b6c:	sub	x23, x9, x8
   25b70:	mov	x2, x21
   25b74:	mov	x3, x23
   25b78:	bl	ca90 <__gmpn_add_n@plt>
   25b7c:	str	x0, [x20, x23, lsl #3]
   25b80:	ldr	x8, [x21]
   25b84:	tst	x24, x19
   25b88:	cset	w9, ne  // ne = any
   25b8c:	mov	x0, x21
   25b90:	orr	x8, x8, x9, lsl #1
   25b94:	mov	x1, x21
   25b98:	mov	x2, x22
   25b9c:	mov	x3, x23
   25ba0:	cset	w26, eq  // eq = none
   25ba4:	str	x8, [x21]
   25ba8:	bl	cc00 <__gmpn_rsblsh2_n@plt>
   25bac:	str	x0, [x21, x23, lsl #3]
   25bb0:	ldr	x8, [x21]
   25bb4:	adds	x8, x8, w26, uxtw #1
   25bb8:	str	x8, [x21]
   25bbc:	b.cc	25bd4 <__gmpn_fib2_ui@@Base+0x160>  // b.lo, b.ul, b.last
   25bc0:	mov	x8, x25
   25bc4:	ldr	x9, [x8]
   25bc8:	adds	x9, x9, #0x1
   25bcc:	str	x9, [x8], #8
   25bd0:	b.cs	25bc4 <__gmpn_fib2_ui@@Base+0x150>  // b.hs, b.nlast
   25bd4:	ldr	x8, [x21, x23, lsl #3]
   25bd8:	cmp	x8, #0x0
   25bdc:	cinc	x23, x23, ne  // ne = any
   25be0:	tst	x19, x24, lsr #1
   25be4:	lsr	x24, x24, #1
   25be8:	b.eq	25c04 <__gmpn_fib2_ui@@Base+0x190>  // b.none
   25bec:	mov	x0, x20
   25bf0:	mov	x1, x21
   25bf4:	mov	x2, x20
   25bf8:	mov	x3, x23
   25bfc:	bl	c2e0 <__gmpn_sub_n@plt>
   25c00:	b	25c2c <__gmpn_fib2_ui@@Base+0x1b8>
   25c04:	mov	x0, x21
   25c08:	mov	x1, x21
   25c0c:	mov	x2, x20
   25c10:	mov	x3, x23
   25c14:	bl	c2e0 <__gmpn_sub_n@plt>
   25c18:	add	x8, x21, x23, lsl #3
   25c1c:	ldur	x8, [x8, #-8]
   25c20:	cmp	x8, #0x0
   25c24:	cset	w8, eq  // eq = none
   25c28:	sub	x23, x23, x8
   25c2c:	cmp	x24, #0x1
   25c30:	b.ne	25b30 <__gmpn_fib2_ui@@Base+0xbc>  // b.any
   25c34:	ldur	x0, [x29, #-8]
   25c38:	cbnz	x0, 25c6c <__gmpn_fib2_ui@@Base+0x1f8>
   25c3c:	mov	x0, x23
   25c40:	mov	sp, x29
   25c44:	ldp	x20, x19, [sp, #64]
   25c48:	ldp	x22, x21, [sp, #48]
   25c4c:	ldp	x24, x23, [sp, #32]
   25c50:	ldp	x26, x25, [sp, #16]
   25c54:	ldp	x29, x30, [sp], #80
   25c58:	ret
   25c5c:	sub	x0, x29, #0x8
   25c60:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   25c64:	mov	x22, x0
   25c68:	b	25b28 <__gmpn_fib2_ui@@Base+0xb4>
   25c6c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   25c70:	b	25c3c <__gmpn_fib2_ui@@Base+0x1c8>

0000000000025c74 <__gmpn_fib2m@@Base>:
   25c74:	stp	x29, x30, [sp, #-96]!
   25c78:	stp	x28, x27, [sp, #16]
   25c7c:	stp	x26, x25, [sp, #32]
   25c80:	stp	x24, x23, [sp, #48]
   25c84:	stp	x22, x21, [sp, #64]
   25c88:	stp	x20, x19, [sp, #80]
   25c8c:	mov	x29, sp
   25c90:	sub	sp, sp, #0x40
   25c94:	mov	x11, #0x2c84                	// #11396
   25c98:	movk	x11, #0x2164, lsl #16
   25c9c:	sub	x10, x3, #0x1
   25ca0:	movk	x11, #0x590b, lsl #32
   25ca4:	ldr	x8, [x2, x10, lsl #3]
   25ca8:	mov	w9, #0x5c                  	// #92
   25cac:	movk	x11, #0x2c8, lsl #48
   25cb0:	mul	x9, x5, x9
   25cb4:	cmp	x5, x11
   25cb8:	csinv	x9, x9, xzr, ls  // ls = plast
   25cbc:	clz	x13, x8
   25cc0:	clz	x14, x9
   25cc4:	mov	x19, x5
   25cc8:	mov	x27, x4
   25ccc:	mov	x26, x2
   25cd0:	mov	x21, x1
   25cd4:	subs	w11, w14, w13
   25cd8:	mov	x23, x0
   25cdc:	b.cs	25d10 <__gmpn_fib2m@@Base+0x9c>  // b.hs, b.nlast
   25ce0:	subs	x12, x3, #0x2
   25ce4:	b.lt	25d18 <__gmpn_fib2m@@Base+0xa4>  // b.tstop
   25ce8:	sub	w10, w13, w14
   25cec:	ldr	x13, [x26, x12, lsl #3]
   25cf0:	mov	w11, #0x40                  	// #64
   25cf4:	lsl	x8, x8, x10
   25cf8:	sub	w11, w11, w10
   25cfc:	neg	w10, w10
   25d00:	lsr	x10, x13, x10
   25d04:	orr	x8, x10, x8
   25d08:	mov	x10, x12
   25d0c:	b	25d1c <__gmpn_fib2m@@Base+0xa8>
   25d10:	lsr	x8, x8, x11
   25d14:	b	25d1c <__gmpn_fib2m@@Base+0xa8>
   25d18:	mov	w11, wzr
   25d1c:	lsl	x10, x10, #6
   25d20:	cmp	x8, x9
   25d24:	add	x9, x10, w11, sxtw
   25d28:	cset	w10, hi  // hi = pmore
   25d2c:	lsr	x24, x8, x10
   25d30:	mov	x0, x23
   25d34:	mov	x1, x21
   25d38:	mov	x2, x24
   25d3c:	cinc	x22, x9, hi  // hi = pmore
   25d40:	bl	d090 <__gmpn_fib2_ui@plt>
   25d44:	mov	x25, x0
   25d48:	cmp	x0, x19
   25d4c:	stur	x19, [x29, #-48]
   25d50:	b.eq	25d88 <__gmpn_fib2m@@Base+0x114>  // b.none
   25d54:	sub	x8, x19, x25
   25d58:	mov	x19, x26
   25d5c:	lsl	x26, x8, #3
   25d60:	add	x0, x23, x25, lsl #3
   25d64:	mov	w1, wzr
   25d68:	mov	x2, x26
   25d6c:	bl	c610 <memset@plt>
   25d70:	mov	x2, x26
   25d74:	mov	x26, x19
   25d78:	ldur	x19, [x29, #-48]
   25d7c:	add	x0, x21, x25, lsl #3
   25d80:	mov	w1, wzr
   25d84:	bl	c610 <memset@plt>
   25d88:	cbz	x22, 2601c <__gmpn_fib2m@@Base+0x3a8>
   25d8c:	cmp	x19, #0x2
   25d90:	cset	w8, lt  // lt = tstop
   25d94:	bfi	x8, x19, #1, #63
   25d98:	lsl	x1, x8, #3
   25d9c:	mov	w8, #0x7f00                	// #32512
   25da0:	and	w20, w24, #0x1
   25da4:	cmp	x1, x8
   25da8:	lsl	x24, x19, #1
   25dac:	stur	xzr, [x29, #-16]
   25db0:	b.hi	26088 <__gmpn_fib2m@@Base+0x414>  // b.pmore
   25db4:	add	x9, x1, #0xf
   25db8:	mov	x8, sp
   25dbc:	and	x9, x9, #0xfffffffffffffff0
   25dc0:	sub	x25, x8, x9
   25dc4:	mov	sp, x25
   25dc8:	orr	x8, x24, #0x1
   25dcc:	add	x9, x23, #0x8
   25dd0:	stur	x8, [x29, #-24]
   25dd4:	sub	x8, x8, #0x1
   25dd8:	stur	x9, [x29, #-40]
   25ddc:	stur	x8, [x29, #-56]
   25de0:	mov	x0, x25
   25de4:	mov	x1, x23
   25de8:	mov	x2, x19
   25dec:	bl	c900 <__gmpn_sqr@plt>
   25df0:	mov	x0, x23
   25df4:	mov	x1, x21
   25df8:	mov	x2, x19
   25dfc:	bl	c900 <__gmpn_sqr@plt>
   25e00:	mov	x0, x21
   25e04:	mov	x1, x25
   25e08:	mov	x2, x23
   25e0c:	mov	x3, x24
   25e10:	bl	ca90 <__gmpn_add_n@plt>
   25e14:	str	x0, [x21, x24, lsl #3]
   25e18:	ldr	x8, [x23]
   25e1c:	lsl	w20, w20, #1
   25e20:	mov	x0, x23
   25e24:	mov	x1, x23
   25e28:	orr	x8, x8, x20
   25e2c:	mov	x2, x25
   25e30:	mov	x3, x24
   25e34:	str	x8, [x23]
   25e38:	bl	cc00 <__gmpn_rsblsh2_n@plt>
   25e3c:	add	x8, x0, #0x1
   25e40:	str	x8, [x23, x24, lsl #3]
   25e44:	ldr	x8, [x23]
   25e48:	eor	w9, w20, #0x2
   25e4c:	adds	x8, x8, x9
   25e50:	str	x8, [x23]
   25e54:	b.cc	25e6c <__gmpn_fib2m@@Base+0x1f8>  // b.lo, b.ul, b.last
   25e58:	ldur	x8, [x29, #-40]
   25e5c:	ldr	x9, [x8]
   25e60:	adds	x9, x9, #0x1
   25e64:	str	x9, [x8], #8
   25e68:	b.cs	25e5c <__gmpn_fib2m@@Base+0x1e8>  // b.hs, b.nlast
   25e6c:	ldr	x8, [x23, x24, lsl #3]
   25e70:	sub	x22, x22, #0x1
   25e74:	lsr	x9, x22, #3
   25e78:	and	x9, x9, #0x1ffffffffffffff8
   25e7c:	sub	x10, x8, #0x1
   25e80:	str	x10, [x23, x24, lsl #3]
   25e84:	ldr	x9, [x26, x9]
   25e88:	lsr	x9, x9, x22
   25e8c:	tst	w9, #0x1
   25e90:	and	w20, w9, #0x1
   25e94:	csel	x28, x21, x23, ne  // ne = any
   25e98:	cbz	x8, 25ed8 <__gmpn_fib2m@@Base+0x264>
   25e9c:	ldur	x8, [x29, #-24]
   25ea0:	cmp	x8, #0x1
   25ea4:	b.lt	25f8c <__gmpn_fib2m@@Base+0x318>  // b.tstop
   25ea8:	ldur	x8, [x29, #-56]
   25eac:	ldr	x9, [x23, x8, lsl #3]
   25eb0:	ldr	x10, [x21, x8, lsl #3]
   25eb4:	cmp	x9, x10
   25eb8:	b.ne	25f74 <__gmpn_fib2m@@Base+0x300>  // b.any
   25ebc:	add	x9, x8, #0x1
   25ec0:	sub	x10, x8, #0x1
   25ec4:	cmp	x9, #0x1
   25ec8:	str	xzr, [x28, x8, lsl #3]
   25ecc:	mov	x8, x10
   25ed0:	b.gt	25eac <__gmpn_fib2m@@Base+0x238>
   25ed4:	b	25f8c <__gmpn_fib2m@@Base+0x318>
   25ed8:	mov	x19, x26
   25edc:	mov	x26, x27
   25ee0:	ldr	x27, [x21, x24, lsl #3]
   25ee4:	cmp	w20, #0x0
   25ee8:	cset	w8, eq  // eq = none
   25eec:	mov	x0, x28
   25ef0:	mov	x1, x21
   25ef4:	mov	x2, x23
   25ef8:	mov	x3, x24
   25efc:	stur	w8, [x29, #-28]
   25f00:	bl	c2e0 <__gmpn_sub_n@plt>
   25f04:	sub	x8, x27, x0
   25f08:	add	x8, x8, #0x1
   25f0c:	str	x8, [x28, x24, lsl #3]
   25f10:	cbz	w20, 25f94 <__gmpn_fib2m@@Base+0x320>
   25f14:	ldr	x10, [x23]
   25f18:	mov	x27, x26
   25f1c:	mov	x26, x19
   25f20:	ldur	x19, [x29, #-48]
   25f24:	mov	x8, x23
   25f28:	mov	x9, x24
   25f2c:	cbnz	x10, 25f4c <__gmpn_fib2m@@Base+0x2d8>
   25f30:	mov	x9, x24
   25f34:	mov	x8, x23
   25f38:	subs	x9, x9, #0x1
   25f3c:	str	xzr, [x8]
   25f40:	b.eq	26004 <__gmpn_fib2m@@Base+0x390>  // b.none
   25f44:	ldr	x10, [x8, #8]!
   25f48:	cbz	x10, 25f38 <__gmpn_fib2m@@Base+0x2c4>
   25f4c:	neg	x10, x10
   25f50:	subs	x2, x9, #0x1
   25f54:	str	x10, [x8]
   25f58:	b.eq	25f68 <__gmpn_fib2m@@Base+0x2f4>  // b.none
   25f5c:	add	x0, x8, #0x8
   25f60:	mov	x1, x0
   25f64:	bl	c2a0 <__gmpn_com@plt>
   25f68:	mov	x8, xzr
   25f6c:	str	x8, [x23, x24, lsl #3]
   25f70:	b	25fb8 <__gmpn_fib2m@@Base+0x344>
   25f74:	add	x3, x8, #0x1
   25f78:	mov	x0, x28
   25f7c:	b.ls	25fa4 <__gmpn_fib2m@@Base+0x330>  // b.plast
   25f80:	mov	x1, x23
   25f84:	mov	x2, x21
   25f88:	bl	c2e0 <__gmpn_sub_n@plt>
   25f8c:	stur	wzr, [x29, #-28]
   25f90:	b	25fb8 <__gmpn_fib2m@@Base+0x344>
   25f94:	mov	x27, x26
   25f98:	mov	x26, x19
   25f9c:	ldur	x19, [x29, #-48]
   25fa0:	b	25fb8 <__gmpn_fib2m@@Base+0x344>
   25fa4:	mov	x1, x21
   25fa8:	mov	x2, x23
   25fac:	bl	c2e0 <__gmpn_sub_n@plt>
   25fb0:	mov	w8, #0x1                   	// #1
   25fb4:	stur	w8, [x29, #-28]
   25fb8:	ldur	x28, [x29, #-24]
   25fbc:	mov	x0, x25
   25fc0:	mov	x1, x23
   25fc4:	mov	x2, xzr
   25fc8:	mov	x3, x23
   25fcc:	mov	x4, x28
   25fd0:	mov	x5, x27
   25fd4:	mov	x6, x19
   25fd8:	bl	bf10 <__gmpn_tdiv_qr@plt>
   25fdc:	mov	x0, x25
   25fe0:	mov	x1, x21
   25fe4:	mov	x2, xzr
   25fe8:	mov	x3, x21
   25fec:	mov	x4, x28
   25ff0:	mov	x5, x27
   25ff4:	mov	x6, x19
   25ff8:	bl	bf10 <__gmpn_tdiv_qr@plt>
   25ffc:	cbnz	x22, 25de0 <__gmpn_fib2m@@Base+0x16c>
   26000:	b	2600c <__gmpn_fib2m@@Base+0x398>
   26004:	mov	w8, #0x1                   	// #1
   26008:	b	25f6c <__gmpn_fib2m@@Base+0x2f8>
   2600c:	ldur	x0, [x29, #-16]
   26010:	cbnz	x0, 26098 <__gmpn_fib2m@@Base+0x424>
   26014:	ldur	w0, [x29, #-28]
   26018:	b	26068 <__gmpn_fib2m@@Base+0x3f4>
   2601c:	cmp	x25, x19
   26020:	b.ne	26064 <__gmpn_fib2m@@Base+0x3f0>  // b.any
   26024:	sub	x0, x29, #0x10
   26028:	mov	x1, x23
   2602c:	mov	x2, xzr
   26030:	mov	x3, x23
   26034:	mov	x4, x19
   26038:	mov	x5, x27
   2603c:	mov	x6, x19
   26040:	bl	bf10 <__gmpn_tdiv_qr@plt>
   26044:	sub	x0, x29, #0x10
   26048:	mov	x1, x21
   2604c:	mov	x2, xzr
   26050:	mov	x3, x21
   26054:	mov	x4, x19
   26058:	mov	x5, x27
   2605c:	mov	x6, x19
   26060:	bl	bf10 <__gmpn_tdiv_qr@plt>
   26064:	mov	w0, wzr
   26068:	mov	sp, x29
   2606c:	ldp	x20, x19, [sp, #80]
   26070:	ldp	x22, x21, [sp, #64]
   26074:	ldp	x24, x23, [sp, #48]
   26078:	ldp	x26, x25, [sp, #32]
   2607c:	ldp	x28, x27, [sp, #16]
   26080:	ldp	x29, x30, [sp], #96
   26084:	ret
   26088:	sub	x0, x29, #0x10
   2608c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   26090:	mov	x25, x0
   26094:	b	25dc8 <__gmpn_fib2m@@Base+0x154>
   26098:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2609c:	b	26014 <__gmpn_fib2m@@Base+0x3a0>

00000000000260a0 <__gmpn_mod_1@@Base>:
   260a0:	sub	sp, sp, #0x90
   260a4:	stp	x29, x30, [sp, #64]
   260a8:	str	x25, [sp, #80]
   260ac:	stp	x24, x23, [sp, #96]
   260b0:	stp	x22, x21, [sp, #112]
   260b4:	stp	x20, x19, [sp, #128]
   260b8:	add	x29, sp, #0x40
   260bc:	cbz	x1, 26118 <__gmpn_mod_1@@Base+0x78>
   260c0:	mov	x20, x2
   260c4:	mov	x19, x1
   260c8:	mov	x21, x0
   260cc:	tbnz	x2, #63, 26378 <__gmpn_mod_1@@Base+0x2d8>
   260d0:	cmp	x19, #0x5
   260d4:	b.le	26120 <__gmpn_mod_1@@Base+0x80>
   260d8:	cmp	x19, #0x9
   260dc:	b.le	26144 <__gmpn_mod_1@@Base+0xa4>
   260e0:	cmp	x19, #0x14
   260e4:	b.lt	26338 <__gmpn_mod_1@@Base+0x298>  // b.tstop
   260e8:	lsr	x8, x20, #62
   260ec:	cbnz	x8, 26338 <__gmpn_mod_1@@Base+0x298>
   260f0:	add	x0, sp, #0x8
   260f4:	mov	x1, x20
   260f8:	bl	c6a0 <__gmpn_mod_1s_4p_cps@plt>
   260fc:	ldr	x8, [sp, #16]
   26100:	add	x3, sp, #0x8
   26104:	mov	x0, x21
   26108:	mov	x1, x19
   2610c:	lsl	x2, x20, x8
   26110:	bl	d430 <__gmpn_mod_1s_4p@plt>
   26114:	b	2635c <__gmpn_mod_1@@Base+0x2bc>
   26118:	mov	x0, xzr
   2611c:	b	2635c <__gmpn_mod_1@@Base+0x2bc>
   26120:	sub	x8, x19, #0x1
   26124:	ldr	x0, [x21, x8, lsl #3]
   26128:	cmp	x0, x20
   2612c:	b.cs	2616c <__gmpn_mod_1@@Base+0xcc>  // b.hs, b.nlast
   26130:	cbz	x8, 2635c <__gmpn_mod_1@@Base+0x2bc>
   26134:	add	x9, x21, x19, lsl #3
   26138:	ldur	x23, [x9, #-16]
   2613c:	mov	x19, x8
   26140:	b	26174 <__gmpn_mod_1@@Base+0xd4>
   26144:	add	x0, sp, #0x8
   26148:	mov	x1, x20
   2614c:	bl	cae0 <__gmpn_mod_1_1p_cps@plt>
   26150:	ldr	x8, [sp, #16]
   26154:	add	x3, sp, #0x8
   26158:	mov	x0, x21
   2615c:	mov	x1, x19
   26160:	lsl	x2, x20, x8
   26164:	bl	c260 <__gmpn_mod_1_1p@plt>
   26168:	b	2635c <__gmpn_mod_1@@Base+0x2bc>
   2616c:	mov	x23, x0
   26170:	mov	x0, xzr
   26174:	clz	x22, x20
   26178:	mov	w8, #0x40                  	// #64
   2617c:	sub	x24, x8, x22
   26180:	neg	x8, x22
   26184:	lsl	x9, x0, x22
   26188:	lsr	x8, x23, x8
   2618c:	lsl	x20, x20, x22
   26190:	cmp	x19, #0x3
   26194:	orr	x25, x9, x8
   26198:	b.le	26234 <__gmpn_mod_1@@Base+0x194>
   2619c:	mov	x0, x20
   261a0:	bl	d410 <__gmpn_invert_limb@plt>
   261a4:	sub	x8, x21, #0x10
   261a8:	ldr	x9, [x8, x19, lsl #3]
   261ac:	lsl	x10, x23, x22
   261b0:	umulh	x11, x25, x0
   261b4:	add	x13, x25, #0x1
   261b8:	lsr	x12, x9, x24
   261bc:	orr	x10, x12, x10
   261c0:	mul	x12, x25, x0
   261c4:	adds	x14, x12, x10
   261c8:	adc	x11, x11, x13
   261cc:	msub	x10, x11, x20, x10
   261d0:	cmp	x10, x14
   261d4:	csel	x11, x20, xzr, hi  // hi = pmore
   261d8:	add	x10, x11, x10
   261dc:	cmp	x10, x20
   261e0:	sub	x12, x19, #0x2
   261e4:	csel	x11, xzr, x20, cc  // cc = lo, ul, last
   261e8:	sub	x19, x19, #0x1
   261ec:	cmp	x12, #0x0
   261f0:	sub	x25, x10, x11
   261f4:	mov	x23, x9
   261f8:	b.gt	261a8 <__gmpn_mod_1@@Base+0x108>
   261fc:	umulh	x8, x25, x0
   26200:	mul	x10, x25, x0
   26204:	lsl	x9, x9, x22
   26208:	add	x11, x25, #0x1
   2620c:	adds	x12, x10, x9
   26210:	adc	x8, x8, x11
   26214:	msub	x8, x8, x20, x9
   26218:	cmp	x8, x12
   2621c:	csel	x9, x20, xzr, hi  // hi = pmore
   26220:	add	x8, x9, x8
   26224:	cmp	x8, x20
   26228:	csel	x9, xzr, x20, cc  // cc = lo, ul, last
   2622c:	sub	x8, x8, x9
   26230:	b	26330 <__gmpn_mod_1@@Base+0x290>
   26234:	lsr	x8, x20, #32
   26238:	and	x9, x20, #0xffffffff
   2623c:	cmp	x19, #0x1
   26240:	b.le	262cc <__gmpn_mod_1@@Base+0x22c>
   26244:	sub	x10, x21, #0x10
   26248:	mov	x11, x23
   2624c:	ldr	x23, [x10, x19, lsl #3]
   26250:	lsl	x11, x11, x22
   26254:	udiv	x12, x25, x8
   26258:	msub	w13, w12, w8, w25
   2625c:	lsr	x14, x23, x24
   26260:	orr	x11, x14, x11
   26264:	mul	x12, x12, x9
   26268:	extr	x13, x13, x11, #32
   2626c:	cmp	x13, x12
   26270:	b.cs	26288 <__gmpn_mod_1@@Base+0x1e8>  // b.hs, b.nlast
   26274:	add	x13, x13, x20
   26278:	cmp	x13, x12
   2627c:	ccmp	x13, x20, #0x0, cc  // cc = lo, ul, last
   26280:	csel	x14, x20, xzr, cs  // cs = hs, nlast
   26284:	add	x13, x14, x13
   26288:	sub	x12, x13, x12
   2628c:	udiv	x13, x12, x8
   26290:	msub	w14, w13, w8, w12
   26294:	mul	x12, x13, x9
   26298:	bfi	x11, x14, #32, #32
   2629c:	cmp	x11, x12
   262a0:	b.cs	262b8 <__gmpn_mod_1@@Base+0x218>  // b.hs, b.nlast
   262a4:	add	x11, x11, x20
   262a8:	cmp	x11, x12
   262ac:	ccmp	x11, x20, #0x0, cc  // cc = lo, ul, last
   262b0:	csel	x13, x20, xzr, cs  // cs = hs, nlast
   262b4:	add	x11, x13, x11
   262b8:	sub	x13, x19, #0x2
   262bc:	sub	x19, x19, #0x1
   262c0:	cmp	x13, #0x0
   262c4:	sub	x25, x11, x12
   262c8:	b.gt	26248 <__gmpn_mod_1@@Base+0x1a8>
   262cc:	udiv	x10, x25, x8
   262d0:	msub	w12, w10, w8, w25
   262d4:	mul	x11, x10, x9
   262d8:	lsl	x10, x23, x22
   262dc:	extr	x12, x12, x10, #32
   262e0:	cmp	x12, x11
   262e4:	b.cs	262fc <__gmpn_mod_1@@Base+0x25c>  // b.hs, b.nlast
   262e8:	add	x12, x12, x20
   262ec:	cmp	x12, x11
   262f0:	ccmp	x12, x20, #0x0, cc  // cc = lo, ul, last
   262f4:	csel	x13, x20, xzr, cs  // cs = hs, nlast
   262f8:	add	x12, x13, x12
   262fc:	sub	x11, x12, x11
   26300:	udiv	x12, x11, x8
   26304:	msub	w11, w12, w8, w11
   26308:	mul	x8, x12, x9
   2630c:	bfi	x10, x11, #32, #32
   26310:	cmp	x10, x8
   26314:	b.cs	2632c <__gmpn_mod_1@@Base+0x28c>  // b.hs, b.nlast
   26318:	add	x9, x10, x20
   2631c:	cmp	x9, x8
   26320:	ccmp	x9, x20, #0x0, cc  // cc = lo, ul, last
   26324:	csel	x10, x20, xzr, cs  // cs = hs, nlast
   26328:	add	x10, x10, x9
   2632c:	sub	x8, x10, x8
   26330:	lsr	x0, x8, x22
   26334:	b	2635c <__gmpn_mod_1@@Base+0x2bc>
   26338:	add	x0, sp, #0x8
   2633c:	mov	x1, x20
   26340:	bl	cce0 <__gmpn_mod_1s_2p_cps@plt>
   26344:	ldr	x8, [sp, #16]
   26348:	add	x3, sp, #0x8
   2634c:	mov	x0, x21
   26350:	mov	x1, x19
   26354:	lsl	x2, x20, x8
   26358:	bl	cea0 <__gmpn_mod_1s_2p@plt>
   2635c:	ldp	x20, x19, [sp, #128]
   26360:	ldp	x22, x21, [sp, #112]
   26364:	ldp	x24, x23, [sp, #96]
   26368:	ldr	x25, [sp, #80]
   2636c:	ldp	x29, x30, [sp, #64]
   26370:	add	sp, sp, #0x90
   26374:	ret
   26378:	cmp	x19, #0x7
   2637c:	b.le	263a0 <__gmpn_mod_1@@Base+0x300>
   26380:	add	x0, sp, #0x8
   26384:	mov	x1, x20
   26388:	bl	cae0 <__gmpn_mod_1_1p_cps@plt>
   2638c:	add	x3, sp, #0x8
   26390:	mov	x0, x21
   26394:	mov	x1, x19
   26398:	mov	x2, x20
   2639c:	b	26164 <__gmpn_mod_1@@Base+0xc4>
   263a0:	add	x8, x21, x19, lsl #3
   263a4:	ldur	x8, [x8, #-8]
   263a8:	cmp	x8, x20
   263ac:	csel	x9, xzr, x20, cc  // cc = lo, ul, last
   263b0:	cmp	x19, #0x1
   263b4:	sub	x0, x8, x9
   263b8:	b.eq	2635c <__gmpn_mod_1@@Base+0x2bc>  // b.none
   263bc:	mov	x22, x0
   263c0:	cmp	x19, #0x3
   263c4:	b.le	26424 <__gmpn_mod_1@@Base+0x384>
   263c8:	mov	x0, x20
   263cc:	bl	d410 <__gmpn_invert_limb@plt>
   263d0:	mov	x8, x0
   263d4:	sub	x9, x21, #0x10
   263d8:	mov	x0, x22
   263dc:	ldr	x10, [x9, x19, lsl #3]
   263e0:	umulh	x11, x0, x8
   263e4:	mul	x12, x0, x8
   263e8:	add	x13, x0, #0x1
   263ec:	adds	x14, x12, x10
   263f0:	adc	x11, x11, x13
   263f4:	msub	x10, x11, x20, x10
   263f8:	cmp	x10, x14
   263fc:	csel	x11, x20, xzr, hi  // hi = pmore
   26400:	add	x10, x11, x10
   26404:	cmp	x10, x20
   26408:	sub	x12, x19, #0x2
   2640c:	csel	x11, xzr, x20, cc  // cc = lo, ul, last
   26410:	sub	x19, x19, #0x1
   26414:	cmp	x12, #0x0
   26418:	sub	x0, x10, x11
   2641c:	b.gt	263dc <__gmpn_mod_1@@Base+0x33c>
   26420:	b	2635c <__gmpn_mod_1@@Base+0x2bc>
   26424:	cmp	x19, #0x2
   26428:	b.lt	264b4 <__gmpn_mod_1@@Base+0x414>  // b.tstop
   2642c:	lsr	x8, x20, #32
   26430:	and	x9, x20, #0xffffffff
   26434:	sub	x10, x21, #0x10
   26438:	mov	x0, x22
   2643c:	ldr	x11, [x10, x19, lsl #3]
   26440:	udiv	x12, x0, x8
   26444:	msub	w13, w12, w8, w0
   26448:	mul	x12, x12, x9
   2644c:	extr	x13, x13, x11, #32
   26450:	cmp	x13, x12
   26454:	b.cs	2646c <__gmpn_mod_1@@Base+0x3cc>  // b.hs, b.nlast
   26458:	add	x13, x13, x20
   2645c:	cmp	x13, x12
   26460:	ccmp	x13, x20, #0x0, cc  // cc = lo, ul, last
   26464:	csel	x14, x20, xzr, cs  // cs = hs, nlast
   26468:	add	x13, x14, x13
   2646c:	sub	x12, x13, x12
   26470:	udiv	x13, x12, x8
   26474:	msub	w14, w13, w8, w12
   26478:	mul	x12, x13, x9
   2647c:	bfi	x11, x14, #32, #32
   26480:	cmp	x11, x12
   26484:	b.cs	2649c <__gmpn_mod_1@@Base+0x3fc>  // b.hs, b.nlast
   26488:	add	x11, x11, x20
   2648c:	cmp	x11, x12
   26490:	ccmp	x11, x20, #0x0, cc  // cc = lo, ul, last
   26494:	csel	x13, x20, xzr, cs  // cs = hs, nlast
   26498:	add	x11, x13, x11
   2649c:	sub	x13, x19, #0x2
   264a0:	sub	x19, x19, #0x1
   264a4:	cmp	x13, #0x0
   264a8:	sub	x0, x11, x12
   264ac:	b.gt	2643c <__gmpn_mod_1@@Base+0x39c>
   264b0:	b	2635c <__gmpn_mod_1@@Base+0x2bc>
   264b4:	mov	x0, x22
   264b8:	b	2635c <__gmpn_mod_1@@Base+0x2bc>
   264bc:	nop

00000000000264c0 <__gmpn_mod_34lsub1@@Base>:
   264c0:	subs	x1, x1, #0x3
   264c4:	mov	x8, #0x0                   	// #0
   264c8:	b.lt	26564 <__gmpn_mod_34lsub1@@Base+0xa4>  // b.tstop
   264cc:	ldp	x2, x3, [x0]
   264d0:	ldr	x4, [x0, #16]
   264d4:	add	x0, x0, #0x18
   264d8:	subs	x1, x1, #0x3
   264dc:	b.lt	26508 <__gmpn_mod_34lsub1@@Base+0x48>  // b.tstop
   264e0:	cmn	x0, #0x0
   264e4:	ldp	x5, x6, [x0]
   264e8:	ldr	x7, [x0, #16]
   264ec:	add	x0, x0, #0x18
   264f0:	sub	x1, x1, #0x3
   264f4:	adcs	x2, x2, x5
   264f8:	adcs	x3, x3, x6
   264fc:	adcs	x4, x4, x7
   26500:	tbz	x1, #63, 264e4 <__gmpn_mod_34lsub1@@Base+0x24>
   26504:	adc	x8, xzr, xzr
   26508:	cmn	x1, #0x2
   2650c:	mov	x5, #0x0                   	// #0
   26510:	b.cc	26518 <__gmpn_mod_34lsub1@@Base+0x58>  // b.lo, b.ul, b.last
   26514:	ldr	x5, [x0], #8
   26518:	mov	x6, #0x0                   	// #0
   2651c:	b.ls	26524 <__gmpn_mod_34lsub1@@Base+0x64>  // b.plast
   26520:	ldr	x6, [x0], #8
   26524:	adds	x2, x2, x5
   26528:	adcs	x3, x3, x6
   2652c:	adcs	x4, x4, xzr
   26530:	adc	x8, x8, xzr
   26534:	and	x0, x2, #0xffffffffffff
   26538:	add	x0, x0, x2, lsr #48
   2653c:	add	x0, x0, x8
   26540:	lsl	x8, x3, #16
   26544:	and	x1, x8, #0xffffffffffff
   26548:	add	x0, x0, x1
   2654c:	add	x0, x0, x3, lsr #32
   26550:	lsl	x8, x4, #32
   26554:	and	x1, x8, #0xffffffffffff
   26558:	add	x0, x0, x1
   2655c:	add	x0, x0, x4, lsr #16
   26560:	ret
   26564:	cmn	x1, #0x1
   26568:	b.ne	26578 <__gmpn_mod_34lsub1@@Base+0xb8>  // b.any
   2656c:	ldp	x2, x3, [x0]
   26570:	mov	x4, #0x0                   	// #0
   26574:	b	26534 <__gmpn_mod_34lsub1@@Base+0x74>
   26578:	ldr	x2, [x0]
   2657c:	and	x0, x2, #0xffffffffffff
   26580:	add	x0, x0, x2, lsr #48
   26584:	ret

0000000000026588 <__gmpn_modexact_1c_odd@@Base>:
   26588:	subs	x8, x1, #0x1
   2658c:	b.ne	265b4 <__gmpn_modexact_1c_odd@@Base+0x2c>  // b.any
   26590:	ldr	x8, [x0]
   26594:	subs	x9, x8, x3
   26598:	b.ls	26624 <__gmpn_modexact_1c_odd@@Base+0x9c>  // b.plast
   2659c:	udiv	x8, x9, x2
   265a0:	msub	x8, x8, x2, x9
   265a4:	sub	x9, x2, x8
   265a8:	cmp	x8, #0x0
   265ac:	csel	x0, xzr, x9, eq  // eq = none
   265b0:	ret
   265b4:	adrp	x11, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   265b8:	ldr	x11, [x11, #3952]
   265bc:	ubfx	x10, x2, #1, #7
   265c0:	mov	x9, xzr
   265c4:	ldrb	w10, [x11, x10]
   265c8:	mov	w11, #0x2                   	// #2
   265cc:	msub	x12, x10, x2, x11
   265d0:	mul	x10, x12, x10
   265d4:	msub	x12, x10, x2, x11
   265d8:	mul	x10, x10, x12
   265dc:	msub	x11, x10, x2, x11
   265e0:	mul	x10, x10, x11
   265e4:	ldr	x11, [x0, x9, lsl #3]
   265e8:	add	x9, x9, #0x1
   265ec:	subs	x11, x11, x3
   265f0:	mul	x11, x11, x10
   265f4:	umulh	x11, x11, x2
   265f8:	cinc	x3, x11, cc  // cc = lo, ul, last
   265fc:	cmp	x9, x8
   26600:	b.lt	265e4 <__gmpn_modexact_1c_odd@@Base+0x5c>  // b.tstop
   26604:	ldr	x8, [x0, x9, lsl #3]
   26608:	cmp	x8, x2
   2660c:	b.ls	26634 <__gmpn_modexact_1c_odd@@Base+0xac>  // b.plast
   26610:	subs	x8, x8, x3
   26614:	mul	x8, x8, x10
   26618:	umulh	x8, x8, x2
   2661c:	cinc	x0, x8, cc  // cc = lo, ul, last
   26620:	ret
   26624:	sub	x8, x3, x8
   26628:	udiv	x9, x8, x2
   2662c:	msub	x0, x9, x2, x8
   26630:	ret
   26634:	subs	x8, x3, x8
   26638:	csel	x9, x2, xzr, cc  // cc = lo, ul, last
   2663c:	add	x0, x8, x9
   26640:	ret

0000000000026644 <__gmpn_preinv_divrem_1@@Base>:
   26644:	sub	x13, x3, #0x1
   26648:	ldr	x12, [x2, x13, lsl #3]
   2664c:	add	x10, x13, x1
   26650:	mov	w8, w6
   26654:	lsl	x9, x4, x6
   26658:	add	x10, x0, x10, lsl #3
   2665c:	cbz	w6, 26684 <__gmpn_preinv_divrem_1@@Base+0x40>
   26660:	cmp	x12, x4
   26664:	b.cs	266fc <__gmpn_preinv_divrem_1@@Base+0xb8>  // b.hs, b.nlast
   26668:	lsl	x11, x12, x8
   2666c:	str	xzr, [x10], #-8
   26670:	cbz	x13, 267d0 <__gmpn_preinv_divrem_1@@Base+0x18c>
   26674:	add	x12, x2, x3, lsl #3
   26678:	ldur	x12, [x12, #-16]
   2667c:	mov	x3, x13
   26680:	b	26700 <__gmpn_preinv_divrem_1@@Base+0xbc>
   26684:	cmp	x12, x9
   26688:	cset	w13, cs  // cs = hs, nlast
   2668c:	csel	x11, x9, xzr, cs  // cs = hs, nlast
   26690:	cmp	x3, #0x1
   26694:	sub	x11, x12, x11
   26698:	str	x13, [x10], #-8
   2669c:	b.le	267d0 <__gmpn_preinv_divrem_1@@Base+0x18c>
   266a0:	sub	x12, x2, #0x10
   266a4:	ldr	x13, [x12, x3, lsl #3]
   266a8:	umulh	x14, x11, x5
   266ac:	mul	x15, x11, x5
   266b0:	add	x11, x11, #0x1
   266b4:	adds	x16, x15, x13
   266b8:	adc	x11, x14, x11
   266bc:	msub	x13, x11, x9, x13
   266c0:	cmp	x13, x16
   266c4:	cset	w15, hi  // hi = pmore
   266c8:	sub	x11, x11, x15
   266cc:	csel	x15, x9, xzr, hi  // hi = pmore
   266d0:	add	x13, x15, x13
   266d4:	cmp	x13, x9
   266d8:	sub	x14, x3, #0x2
   266dc:	csel	x15, xzr, x9, cc  // cc = lo, ul, last
   266e0:	cinc	x16, x11, cs  // cs = hs, nlast
   266e4:	sub	x3, x3, #0x1
   266e8:	cmp	x14, #0x0
   266ec:	sub	x11, x13, x15
   266f0:	str	x16, [x10], #-8
   266f4:	b.gt	266a4 <__gmpn_preinv_divrem_1@@Base+0x60>
   266f8:	b	267d0 <__gmpn_preinv_divrem_1@@Base+0x18c>
   266fc:	mov	x11, xzr
   26700:	neg	w13, w6
   26704:	lsr	x13, x12, x13
   26708:	cmp	x3, #0x2
   2670c:	orr	x15, x13, x11
   26710:	b.lt	26788 <__gmpn_preinv_divrem_1@@Base+0x144>  // b.tstop
   26714:	mov	w11, #0x40                  	// #64
   26718:	sub	w11, w11, w6
   2671c:	sub	x13, x2, #0x10
   26720:	ldr	x14, [x13, x3, lsl #3]
   26724:	lsl	x12, x12, x8
   26728:	umulh	x16, x15, x5
   2672c:	mul	x17, x15, x5
   26730:	lsr	x18, x14, x11
   26734:	add	x15, x15, #0x1
   26738:	orr	x12, x18, x12
   2673c:	adds	x0, x17, x12
   26740:	adc	x15, x16, x15
   26744:	msub	x12, x15, x9, x12
   26748:	cmp	x12, x0
   2674c:	csel	x17, x9, xzr, hi  // hi = pmore
   26750:	cset	w16, hi  // hi = pmore
   26754:	add	x12, x17, x12
   26758:	sub	x15, x15, x16
   2675c:	cmp	x12, x9
   26760:	sub	x18, x3, #0x2
   26764:	cinc	x16, x15, cs  // cs = hs, nlast
   26768:	csel	x15, xzr, x9, cc  // cc = lo, ul, last
   2676c:	sub	x3, x3, #0x1
   26770:	cmp	x18, #0x0
   26774:	sub	x15, x12, x15
   26778:	str	x16, [x10], #-8
   2677c:	mov	x12, x14
   26780:	b.gt	26720 <__gmpn_preinv_divrem_1@@Base+0xdc>
   26784:	b	2678c <__gmpn_preinv_divrem_1@@Base+0x148>
   26788:	mov	x14, x12
   2678c:	umulh	x11, x15, x5
   26790:	mul	x12, x15, x5
   26794:	lsl	x13, x14, x8
   26798:	add	x14, x15, #0x1
   2679c:	adds	x15, x12, x13
   267a0:	adc	x11, x11, x14
   267a4:	msub	x12, x11, x9, x13
   267a8:	cmp	x12, x15
   267ac:	csel	x14, x9, xzr, hi  // hi = pmore
   267b0:	cset	w13, hi  // hi = pmore
   267b4:	add	x12, x14, x12
   267b8:	sub	x11, x11, x13
   267bc:	cmp	x12, x9
   267c0:	cinc	x13, x11, cs  // cs = hs, nlast
   267c4:	csel	x11, xzr, x9, cc  // cc = lo, ul, last
   267c8:	sub	x11, x12, x11
   267cc:	str	x13, [x10], #-8
   267d0:	cmp	x1, #0x1
   267d4:	b.lt	2680c <__gmpn_preinv_divrem_1@@Base+0x1c8>  // b.tstop
   267d8:	umulh	x12, x11, x5
   267dc:	mul	x13, x11, x5
   267e0:	add	x11, x11, x12
   267e4:	add	x11, x11, #0x1
   267e8:	mneg	x12, x11, x9
   267ec:	cmp	x13, x12
   267f0:	cset	w12, cc  // cc = lo, ul, last
   267f4:	csel	x13, x9, xzr, cc  // cc = lo, ul, last
   267f8:	sub	x12, x11, x12
   267fc:	msub	x11, x11, x9, x13
   26800:	subs	x1, x1, #0x1
   26804:	str	x12, [x10], #-8
   26808:	b.ne	267d8 <__gmpn_preinv_divrem_1@@Base+0x194>  // b.any
   2680c:	lsr	x0, x11, x8
   26810:	ret

0000000000026814 <__gmpn_preinv_mod_1@@Base>:
   26814:	add	x9, x0, x1, lsl #3
   26818:	ldur	x9, [x9, #-8]
   2681c:	mov	x8, x0
   26820:	cmp	x9, x2
   26824:	csel	x10, xzr, x2, cc  // cc = lo, ul, last
   26828:	cmp	x1, #0x2
   2682c:	sub	x0, x9, x10
   26830:	b.lt	2687c <__gmpn_preinv_mod_1@@Base+0x68>  // b.tstop
   26834:	sub	x8, x8, #0x10
   26838:	ldr	x9, [x8, x1, lsl #3]
   2683c:	umulh	x10, x0, x3
   26840:	mul	x11, x0, x3
   26844:	add	x12, x0, #0x1
   26848:	adds	x13, x11, x9
   2684c:	adc	x10, x10, x12
   26850:	msub	x9, x10, x2, x9
   26854:	cmp	x9, x13
   26858:	csel	x10, x2, xzr, hi  // hi = pmore
   2685c:	add	x9, x10, x9
   26860:	cmp	x9, x2
   26864:	sub	x11, x1, #0x2
   26868:	csel	x10, xzr, x2, cc  // cc = lo, ul, last
   2686c:	sub	x1, x1, #0x1
   26870:	cmp	x11, #0x0
   26874:	sub	x0, x9, x10
   26878:	b.gt	26838 <__gmpn_preinv_mod_1@@Base+0x24>
   2687c:	ret

0000000000026880 <__gmpn_dump@@Base>:
   26880:	stp	x29, x30, [sp, #-48]!
   26884:	stp	x20, x19, [sp, #32]
   26888:	sub	x20, x0, #0x8
   2688c:	stp	x22, x21, [sp, #16]
   26890:	mov	x29, sp
   26894:	subs	x21, x1, #0x1
   26898:	b.lt	268c0 <__gmpn_dump@@Base+0x40>  // b.tstop
   2689c:	ldr	x8, [x20, x1, lsl #3]
   268a0:	mov	x1, x21
   268a4:	cbz	x8, 26894 <__gmpn_dump@@Base+0x14>
   268a8:	adrp	x0, 53000 <__gmpn_bases@@Base+0x1938>
   268ac:	add	x0, x0, #0xef0
   268b0:	mov	x1, x8
   268b4:	bl	d300 <printf@plt>
   268b8:	cbnz	x21, 268d8 <__gmpn_dump@@Base+0x58>
   268bc:	b	268fc <__gmpn_dump@@Base+0x7c>
   268c0:	cbz	x1, 26910 <__gmpn_dump@@Base+0x90>
   268c4:	add	x8, x0, x1, lsl #3
   268c8:	ldur	x1, [x8, #-8]
   268cc:	adrp	x0, 53000 <__gmpn_bases@@Base+0x1938>
   268d0:	add	x0, x0, #0xef0
   268d4:	bl	d300 <printf@plt>
   268d8:	adrp	x19, 53000 <__gmpn_bases@@Base+0x1938>
   268dc:	add	x19, x19, #0xef4
   268e0:	ldr	x2, [x20, x21, lsl #3]
   268e4:	mov	w1, #0x10                  	// #16
   268e8:	mov	x0, x19
   268ec:	sub	x22, x21, #0x1
   268f0:	bl	d300 <printf@plt>
   268f4:	mov	x21, x22
   268f8:	cbnz	x22, 268e0 <__gmpn_dump@@Base+0x60>
   268fc:	ldp	x20, x19, [sp, #32]
   26900:	ldp	x22, x21, [sp, #16]
   26904:	mov	w0, #0xa                   	// #10
   26908:	ldp	x29, x30, [sp], #48
   2690c:	b	d330 <putchar@plt>
   26910:	ldp	x20, x19, [sp, #32]
   26914:	ldp	x22, x21, [sp, #16]
   26918:	adrp	x0, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   2691c:	add	x0, x0, #0x8fa
   26920:	ldp	x29, x30, [sp], #48
   26924:	b	c9d0 <puts@plt>

0000000000026928 <__gmpn_mod_1_1p_cps@@Base>:
   26928:	stp	x29, x30, [sp, #-48]!
   2692c:	str	x21, [sp, #16]
   26930:	clz	x21, x1
   26934:	stp	x20, x19, [sp, #32]
   26938:	lsl	x20, x1, x21
   2693c:	mov	x19, x0
   26940:	mov	x0, x20
   26944:	mov	x29, sp
   26948:	bl	d410 <__gmpn_invert_limb@plt>
   2694c:	stp	x0, x21, [x19]
   26950:	cbz	x21, 26974 <__gmpn_mod_1_1p_cps@@Base+0x4c>
   26954:	neg	x8, x21
   26958:	mov	w9, #0x1                   	// #1
   2695c:	lsr	x8, x0, x8
   26960:	lsl	x9, x9, x21
   26964:	orr	x8, x8, x9
   26968:	mneg	x8, x20, x8
   2696c:	lsr	x8, x8, x21
   26970:	str	x8, [x19, #16]
   26974:	mneg	x8, x20, x0
   26978:	str	x8, [x19, #24]
   2697c:	ldp	x20, x19, [sp, #32]
   26980:	ldr	x21, [sp, #16]
   26984:	ldp	x29, x30, [sp], #48
   26988:	ret

000000000002698c <__gmpn_mod_1_1p@@Base>:
   2698c:	add	x10, x0, x1, lsl #3
   26990:	ldp	x9, x11, [x10, #-16]
   26994:	cmp	x1, #0x3
   26998:	b.lt	26a38 <__gmpn_mod_1_1p@@Base+0xac>  // b.tstop
   2699c:	ldr	x8, [x3, #24]
   269a0:	ldur	x10, [x10, #-24]
   269a4:	umulh	x13, x11, x8
   269a8:	mov	w12, #0x2                   	// #2
   269ac:	mul	x11, x8, x11
   269b0:	adds	x10, x10, x11
   269b4:	cset	w11, cs  // cs = hs, nlast
   269b8:	adds	x9, x13, x9
   269bc:	cset	w13, cs  // cs = hs, nlast
   269c0:	csinc	x12, x12, xzr, cs  // cs = hs, nlast
   269c4:	adds	x9, x9, x11
   269c8:	csel	x11, x13, x12, cc  // cc = lo, ul, last
   269cc:	cmp	x1, #0x3
   269d0:	neg	x13, x11
   269d4:	b.eq	26a2c <__gmpn_mod_1_1p@@Base+0xa0>  // b.none
   269d8:	sub	x11, x0, #0x20
   269dc:	mov	w12, #0x2                   	// #2
   269e0:	ldr	x15, [x11, x1, lsl #3]
   269e4:	and	x13, x13, x8
   269e8:	adds	x10, x10, x13
   269ec:	umulh	x14, x9, x8
   269f0:	mul	x9, x9, x8
   269f4:	csel	x13, x2, xzr, cs  // cs = hs, nlast
   269f8:	sub	x13, x10, x13
   269fc:	adds	x10, x15, x9
   26a00:	cset	w9, cs  // cs = hs, nlast
   26a04:	adds	x13, x14, x13
   26a08:	cset	w14, cs  // cs = hs, nlast
   26a0c:	csinc	x15, x12, xzr, cs  // cs = hs, nlast
   26a10:	adds	x9, x13, x9
   26a14:	sub	x13, x1, #0x4
   26a18:	csel	x14, x14, x15, cc  // cc = lo, ul, last
   26a1c:	sub	x1, x1, #0x1
   26a20:	cmp	x13, #0x0
   26a24:	neg	x13, x14
   26a28:	b.gt	269e0 <__gmpn_mod_1_1p@@Base+0x54>
   26a2c:	and	x8, x13, x2
   26a30:	sub	x11, x9, x8
   26a34:	mov	x9, x10
   26a38:	ldr	x8, [x3, #8]
   26a3c:	cbz	w8, 26aa4 <__gmpn_mod_1_1p@@Base+0x118>
   26a40:	ldr	x10, [x3, #16]
   26a44:	umulh	x13, x11, x10
   26a48:	neg	w12, w8
   26a4c:	mul	x10, x10, x11
   26a50:	adds	x9, x10, x9
   26a54:	cinc	x10, x13, cs  // cs = hs, nlast
   26a58:	lsr	x11, x9, x12
   26a5c:	lsl	x10, x10, x8
   26a60:	orr	x10, x10, x11
   26a64:	lsl	x9, x9, x8
   26a68:	ldr	x11, [x3]
   26a6c:	umulh	x12, x10, x11
   26a70:	mul	x11, x11, x10
   26a74:	add	x10, x10, #0x1
   26a78:	adds	x13, x11, x9
   26a7c:	adc	x10, x12, x10
   26a80:	msub	x9, x10, x2, x9
   26a84:	cmp	x9, x13
   26a88:	csel	x10, x2, xzr, hi  // hi = pmore
   26a8c:	add	x9, x10, x9
   26a90:	cmp	x9, x2
   26a94:	csel	x10, xzr, x2, cc  // cc = lo, ul, last
   26a98:	sub	x9, x9, x10
   26a9c:	lsr	x0, x9, x8
   26aa0:	ret
   26aa4:	cmp	x11, x2
   26aa8:	csel	x10, xzr, x2, cc  // cc = lo, ul, last
   26aac:	sub	x10, x11, x10
   26ab0:	b	26a68 <__gmpn_mod_1_1p@@Base+0xdc>

0000000000026ab4 <__gmpn_mod_1s_2p_cps@@Base>:
   26ab4:	stp	x29, x30, [sp, #-48]!
   26ab8:	str	x21, [sp, #16]
   26abc:	clz	x21, x1
   26ac0:	stp	x20, x19, [sp, #32]
   26ac4:	lsl	x20, x1, x21
   26ac8:	mov	x19, x0
   26acc:	mov	x0, x20
   26ad0:	mov	x29, sp
   26ad4:	bl	d410 <__gmpn_invert_limb@plt>
   26ad8:	neg	x8, x21
   26adc:	mov	w9, #0x1                   	// #1
   26ae0:	lsr	x8, x0, x8
   26ae4:	lsl	x9, x9, x21
   26ae8:	orr	x8, x8, x9
   26aec:	mul	x9, x8, x20
   26af0:	mneg	x8, x8, x20
   26af4:	lsr	x10, x8, x21
   26af8:	umulh	x8, x8, x0
   26afc:	mvn	x8, x8
   26b00:	add	x8, x9, x8
   26b04:	mneg	x11, x9, x0
   26b08:	mul	x8, x8, x20
   26b0c:	cmp	x8, x11
   26b10:	csel	x9, x20, xzr, hi  // hi = pmore
   26b14:	add	x8, x9, x8
   26b18:	lsr	x9, x8, x21
   26b1c:	umulh	x11, x8, x0
   26b20:	mul	x12, x8, x0
   26b24:	add	x8, x8, x11
   26b28:	mvn	x8, x8
   26b2c:	mul	x8, x20, x8
   26b30:	cmp	x8, x12
   26b34:	stp	x10, x9, [x19, #16]
   26b38:	csel	x9, x20, xzr, hi  // hi = pmore
   26b3c:	add	x8, x9, x8
   26b40:	lsr	x8, x8, x21
   26b44:	stp	x0, x21, [x19]
   26b48:	str	x8, [x19, #32]
   26b4c:	ldp	x20, x19, [sp, #32]
   26b50:	ldr	x21, [sp, #16]
   26b54:	ldp	x29, x30, [sp], #48
   26b58:	ret

0000000000026b5c <__gmpn_mod_1s_2p@@Base>:
   26b5c:	ldp	x8, x9, [x3, #16]
   26b60:	ldr	x10, [x3, #32]
   26b64:	tbnz	w1, #0, 26b74 <__gmpn_mod_1s_2p@@Base+0x18>
   26b68:	add	x12, x0, x1, lsl #3
   26b6c:	ldp	x12, x11, [x12, #-16]
   26b70:	b	26be4 <__gmpn_mod_1s_2p@@Base+0x88>
   26b74:	subs	x13, x1, #0x1
   26b78:	b.ne	26bb0 <__gmpn_mod_1s_2p@@Base+0x54>  // b.any
   26b7c:	ldp	x11, x9, [x3]
   26b80:	ldr	x10, [x0]
   26b84:	neg	w12, w9
   26b88:	and	x8, x9, #0xffffffff
   26b8c:	lsl	x9, x10, x9
   26b90:	lsr	x10, x10, x12
   26b94:	umulh	x12, x10, x11
   26b98:	mul	x11, x10, x11
   26b9c:	add	x10, x10, #0x1
   26ba0:	adds	x13, x11, x9
   26ba4:	adc	x10, x12, x10
   26ba8:	msub	x9, x10, x2, x9
   26bac:	b	26c80 <__gmpn_mod_1s_2p@@Base+0x124>
   26bb0:	add	x12, x0, x1, lsl #3
   26bb4:	ldp	x12, x15, [x12, #-24]
   26bb8:	ldr	x14, [x0, x13, lsl #3]
   26bbc:	mov	x11, xzr
   26bc0:	mov	x1, x13
   26bc4:	mul	x17, x15, x8
   26bc8:	umulh	x15, x15, x8
   26bcc:	adds	x18, x17, x12
   26bd0:	adc	x11, x15, x11
   26bd4:	mul	x16, x14, x9
   26bd8:	umulh	x14, x14, x9
   26bdc:	adds	x12, x16, x18
   26be0:	adc	x11, x14, x11
   26be4:	cmp	x1, #0x4
   26be8:	b.lt	26c38 <__gmpn_mod_1s_2p@@Base+0xdc>  // b.tstop
   26bec:	add	x14, x0, x1, lsl #3
   26bf0:	ldp	x14, x15, [x14, #-32]
   26bf4:	mov	x13, xzr
   26bf8:	mul	x16, x15, x8
   26bfc:	umulh	x15, x15, x8
   26c00:	adds	x17, x16, x14
   26c04:	adc	x13, x15, x13
   26c08:	mul	x14, x12, x9
   26c0c:	umulh	x12, x12, x9
   26c10:	mul	x15, x11, x10
   26c14:	umulh	x11, x11, x10
   26c18:	adds	x16, x17, x14
   26c1c:	adc	x13, x13, x12
   26c20:	sub	x14, x1, #0x4
   26c24:	adds	x12, x15, x16
   26c28:	adc	x11, x11, x13
   26c2c:	sub	x1, x1, #0x2
   26c30:	cmp	x14, #0x1
   26c34:	b.gt	26bec <__gmpn_mod_1s_2p@@Base+0x90>
   26c38:	mul	x10, x11, x8
   26c3c:	umulh	x8, x11, x8
   26c40:	ldp	x11, x13, [x3]
   26c44:	mov	x9, xzr
   26c48:	adds	x14, x12, x10
   26c4c:	adc	x9, x8, x9
   26c50:	neg	w10, w13
   26c54:	lsl	x9, x9, x13
   26c58:	lsr	x10, x14, x10
   26c5c:	orr	x9, x10, x9
   26c60:	umulh	x10, x9, x11
   26c64:	mul	x11, x9, x11
   26c68:	add	x9, x9, #0x1
   26c6c:	and	x8, x13, #0xffffffff
   26c70:	lsl	x12, x14, x13
   26c74:	adds	x13, x11, x12
   26c78:	adc	x9, x10, x9
   26c7c:	msub	x9, x9, x2, x12
   26c80:	cmp	x9, x13
   26c84:	cset	w10, hi  // hi = pmore
   26c88:	cmp	w10, #0x0
   26c8c:	csel	x10, x2, xzr, ne  // ne = any
   26c90:	add	x9, x10, x9
   26c94:	cmp	x9, x2
   26c98:	csel	x10, xzr, x2, cc  // cc = lo, ul, last
   26c9c:	sub	x9, x9, x10
   26ca0:	lsr	x0, x9, x8
   26ca4:	ret

0000000000026ca8 <__gmpn_mod_1s_3p_cps@@Base>:
   26ca8:	stp	x29, x30, [sp, #-48]!
   26cac:	str	x21, [sp, #16]
   26cb0:	clz	x21, x1
   26cb4:	stp	x20, x19, [sp, #32]
   26cb8:	lsl	x20, x1, x21
   26cbc:	mov	x19, x0
   26cc0:	mov	x0, x20
   26cc4:	mov	x29, sp
   26cc8:	bl	d410 <__gmpn_invert_limb@plt>
   26ccc:	neg	x8, x21
   26cd0:	mov	w9, #0x1                   	// #1
   26cd4:	lsr	x8, x0, x8
   26cd8:	lsl	x9, x9, x21
   26cdc:	orr	x8, x8, x9
   26ce0:	mul	x9, x8, x20
   26ce4:	mneg	x8, x8, x20
   26ce8:	lsr	x10, x8, x21
   26cec:	umulh	x8, x8, x0
   26cf0:	mvn	x8, x8
   26cf4:	add	x8, x9, x8
   26cf8:	mneg	x11, x9, x0
   26cfc:	mul	x8, x8, x20
   26d00:	cmp	x8, x11
   26d04:	csel	x9, x20, xzr, hi  // hi = pmore
   26d08:	add	x8, x9, x8
   26d0c:	lsr	x9, x8, x21
   26d10:	umulh	x11, x8, x0
   26d14:	stp	x10, x9, [x19, #16]
   26d18:	mul	x9, x8, x0
   26d1c:	add	x8, x8, x11
   26d20:	mvn	x8, x8
   26d24:	mul	x8, x20, x8
   26d28:	cmp	x8, x9
   26d2c:	csel	x9, x20, xzr, hi  // hi = pmore
   26d30:	add	x8, x9, x8
   26d34:	lsr	x9, x8, x21
   26d38:	umulh	x10, x8, x0
   26d3c:	mul	x11, x8, x0
   26d40:	add	x8, x8, x10
   26d44:	mvn	x8, x8
   26d48:	mul	x8, x20, x8
   26d4c:	cmp	x8, x11
   26d50:	csel	x10, x20, xzr, hi  // hi = pmore
   26d54:	add	x8, x10, x8
   26d58:	lsr	x8, x8, x21
   26d5c:	stp	x0, x21, [x19]
   26d60:	stp	x9, x8, [x19, #32]
   26d64:	ldp	x20, x19, [sp, #32]
   26d68:	ldr	x21, [sp, #16]
   26d6c:	ldp	x29, x30, [sp], #48
   26d70:	ret

0000000000026d74 <__gmpn_mod_1s_3p@@Base>:
   26d74:	mov	x12, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   26d78:	ldp	x8, x9, [x3, #16]
   26d7c:	ldp	x10, x11, [x3, #32]
   26d80:	movk	x12, #0xaaab
   26d84:	mul	x12, x1, x12
   26d88:	lsr	x12, x12, #62
   26d8c:	cmp	w12, #0x2
   26d90:	b.eq	26dd8 <__gmpn_mod_1s_3p@@Base+0x64>  // b.none
   26d94:	cmp	w12, #0x1
   26d98:	b.eq	26de8 <__gmpn_mod_1s_3p@@Base+0x74>  // b.none
   26d9c:	cbnz	w12, 26dfc <__gmpn_mod_1s_3p@@Base+0x88>
   26da0:	add	x13, x0, x1, lsl #3
   26da4:	ldp	x14, x13, [x13, #-16]
   26da8:	mov	x12, xzr
   26dac:	sub	x1, x1, #0x3
   26db0:	ldr	x15, [x0, x1, lsl #3]
   26db4:	mul	x16, x14, x8
   26db8:	umulh	x14, x14, x8
   26dbc:	adds	x18, x16, x15
   26dc0:	adc	x12, x14, x12
   26dc4:	mul	x17, x13, x9
   26dc8:	umulh	x14, x13, x9
   26dcc:	adds	x13, x17, x18
   26dd0:	adc	x12, x14, x12
   26dd4:	b	26dfc <__gmpn_mod_1s_3p@@Base+0x88>
   26dd8:	sub	x1, x1, #0x1
   26ddc:	ldr	x13, [x0, x1, lsl #3]
   26de0:	mov	x12, xzr
   26de4:	b	26dfc <__gmpn_mod_1s_3p@@Base+0x88>
   26de8:	add	x12, x0, x1, lsl #3
   26dec:	sub	x1, x1, #0x2
   26df0:	ldur	x12, [x12, #-8]
   26df4:	ldr	x13, [x0, x1, lsl #3]
   26df8:	b	26dfc <__gmpn_mod_1s_3p@@Base+0x88>
   26dfc:	cmp	x1, #0x3
   26e00:	b.lt	26e60 <__gmpn_mod_1s_3p@@Base+0xec>  // b.tstop
   26e04:	add	x15, x0, x1, lsl #3
   26e08:	ldp	x18, x17, [x15, #-24]
   26e0c:	ldur	x15, [x15, #-8]
   26e10:	mov	x14, xzr
   26e14:	mul	x16, x13, x10
   26e18:	mul	x4, x17, x8
   26e1c:	umulh	x17, x17, x8
   26e20:	adds	x5, x4, x18
   26e24:	adc	x14, x17, x14
   26e28:	umulh	x13, x13, x10
   26e2c:	mul	x17, x12, x11
   26e30:	umulh	x12, x12, x11
   26e34:	mul	x18, x15, x9
   26e38:	umulh	x15, x15, x9
   26e3c:	adds	x4, x5, x18
   26e40:	adc	x14, x14, x15
   26e44:	adds	x15, x4, x16
   26e48:	adc	x14, x14, x13
   26e4c:	adds	x13, x17, x15
   26e50:	adc	x12, x12, x14
   26e54:	cmp	x1, #0x5
   26e58:	sub	x1, x1, #0x3
   26e5c:	b.gt	26e04 <__gmpn_mod_1s_3p@@Base+0x90>
   26e60:	mul	x10, x12, x8
   26e64:	umulh	x8, x12, x8
   26e68:	ldp	x12, x11, [x3]
   26e6c:	mov	x9, xzr
   26e70:	adds	x14, x13, x10
   26e74:	adc	x8, x8, x9
   26e78:	neg	w10, w11
   26e7c:	lsl	x8, x8, x11
   26e80:	lsr	x10, x14, x10
   26e84:	orr	x8, x10, x8
   26e88:	umulh	x10, x8, x12
   26e8c:	mul	x12, x8, x12
   26e90:	add	x8, x8, #0x1
   26e94:	lsl	x13, x14, x11
   26e98:	adds	x14, x12, x13
   26e9c:	adc	x8, x10, x8
   26ea0:	msub	x8, x8, x2, x13
   26ea4:	cmp	x8, x14
   26ea8:	csel	x10, x2, x9, hi  // hi = pmore
   26eac:	add	x8, x10, x8
   26eb0:	cmp	x8, x2
   26eb4:	csel	x9, x9, x2, cc  // cc = lo, ul, last
   26eb8:	sub	x8, x8, x9
   26ebc:	lsr	x0, x8, x11
   26ec0:	ret

0000000000026ec4 <__gmpn_mod_1s_4p_cps@@Base>:
   26ec4:	stp	x29, x30, [sp, #-48]!
   26ec8:	str	x21, [sp, #16]
   26ecc:	clz	x21, x1
   26ed0:	stp	x20, x19, [sp, #32]
   26ed4:	lsl	x20, x1, x21
   26ed8:	mov	x19, x0
   26edc:	mov	x0, x20
   26ee0:	mov	x29, sp
   26ee4:	bl	d410 <__gmpn_invert_limb@plt>
   26ee8:	neg	x8, x21
   26eec:	mov	w9, #0x1                   	// #1
   26ef0:	lsr	x8, x0, x8
   26ef4:	lsl	x9, x9, x21
   26ef8:	orr	x8, x8, x9
   26efc:	mul	x9, x8, x20
   26f00:	mneg	x8, x8, x20
   26f04:	lsr	x10, x8, x21
   26f08:	umulh	x8, x8, x0
   26f0c:	mvn	x8, x8
   26f10:	add	x8, x9, x8
   26f14:	mneg	x11, x9, x0
   26f18:	mul	x8, x8, x20
   26f1c:	cmp	x8, x11
   26f20:	csel	x9, x20, xzr, hi  // hi = pmore
   26f24:	add	x8, x9, x8
   26f28:	lsr	x9, x8, x21
   26f2c:	umulh	x11, x8, x0
   26f30:	mul	x12, x8, x0
   26f34:	add	x8, x8, x11
   26f38:	mvn	x8, x8
   26f3c:	mul	x8, x20, x8
   26f40:	cmp	x8, x12
   26f44:	stp	x10, x9, [x19, #16]
   26f48:	csel	x9, x20, xzr, hi  // hi = pmore
   26f4c:	add	x8, x9, x8
   26f50:	lsr	x9, x8, x21
   26f54:	umulh	x10, x8, x0
   26f58:	mul	x11, x8, x0
   26f5c:	add	x8, x8, x10
   26f60:	mvn	x8, x8
   26f64:	mul	x8, x20, x8
   26f68:	cmp	x8, x11
   26f6c:	csel	x10, x20, xzr, hi  // hi = pmore
   26f70:	add	x8, x10, x8
   26f74:	lsr	x10, x8, x21
   26f78:	umulh	x11, x8, x0
   26f7c:	mul	x12, x8, x0
   26f80:	add	x8, x8, x11
   26f84:	mvn	x8, x8
   26f88:	mul	x8, x20, x8
   26f8c:	cmp	x8, x12
   26f90:	stp	x9, x10, [x19, #32]
   26f94:	csel	x9, x20, xzr, hi  // hi = pmore
   26f98:	add	x8, x9, x8
   26f9c:	lsr	x8, x8, x21
   26fa0:	stp	x0, x21, [x19]
   26fa4:	str	x8, [x19, #48]
   26fa8:	ldp	x20, x19, [sp, #32]
   26fac:	ldr	x21, [sp, #16]
   26fb0:	ldp	x29, x30, [sp], #48
   26fb4:	ret

0000000000026fb8 <__gmpn_mod_1s_4p@@Base>:
   26fb8:	ldp	x8, x9, [x3, #16]
   26fbc:	ldp	x10, x11, [x3, #32]
   26fc0:	ldr	x12, [x3, #48]
   26fc4:	adrp	x14, 53000 <__gmpn_bases@@Base+0x1938>
   26fc8:	and	x13, x1, #0x3
   26fcc:	add	x14, x14, #0xefa
   26fd0:	adr	x15, 26fe0 <__gmpn_mod_1s_4p@@Base+0x28>
   26fd4:	ldrb	w16, [x14, x13]
   26fd8:	add	x15, x15, x16, lsl #2
   26fdc:	br	x15
   26fe0:	add	x14, x0, x1, lsl #3
   26fe4:	ldp	x16, x18, [x14, #-24]
   26fe8:	ldur	x14, [x14, #-8]
   26fec:	mov	x13, xzr
   26ff0:	sub	x15, x1, #0x4
   26ff4:	ldr	x17, [x0, x15, lsl #3]
   26ff8:	mul	x1, x16, x8
   26ffc:	umulh	x16, x16, x8
   27000:	adds	x4, x1, x17
   27004:	adc	x13, x16, x13
   27008:	mul	x16, x18, x9
   2700c:	umulh	x17, x18, x9
   27010:	adds	x18, x4, x16
   27014:	adc	x13, x13, x17
   27018:	mul	x16, x14, x10
   2701c:	umulh	x17, x14, x10
   27020:	adds	x14, x16, x18
   27024:	adc	x13, x17, x13
   27028:	b	27084 <__gmpn_mod_1s_4p@@Base+0xcc>
   2702c:	add	x13, x0, x1, lsl #3
   27030:	sub	x15, x1, #0x2
   27034:	ldur	x13, [x13, #-8]
   27038:	ldr	x14, [x0, x15, lsl #3]
   2703c:	b	27084 <__gmpn_mod_1s_4p@@Base+0xcc>
   27040:	add	x14, x0, x1, lsl #3
   27044:	ldp	x16, x14, [x14, #-16]
   27048:	mov	x13, xzr
   2704c:	sub	x15, x1, #0x3
   27050:	ldr	x17, [x0, x15, lsl #3]
   27054:	mul	x18, x16, x8
   27058:	umulh	x16, x16, x8
   2705c:	adds	x4, x18, x17
   27060:	adc	x13, x16, x13
   27064:	mul	x1, x14, x9
   27068:	umulh	x16, x14, x9
   2706c:	adds	x14, x1, x4
   27070:	adc	x13, x16, x13
   27074:	b	27084 <__gmpn_mod_1s_4p@@Base+0xcc>
   27078:	sub	x15, x1, #0x1
   2707c:	ldr	x14, [x0, x15, lsl #3]
   27080:	mov	x13, xzr
   27084:	cmp	x15, #0x4
   27088:	b.lt	27100 <__gmpn_mod_1s_4p@@Base+0x148>  // b.tstop
   2708c:	add	x16, x15, #0x4
   27090:	add	x15, x0, x15, lsl #3
   27094:	sub	x15, x15, #0x10
   27098:	ldp	x0, x18, [x15, #-16]
   2709c:	mov	x17, xzr
   270a0:	sub	x16, x16, #0x4
   270a4:	mul	x1, x18, x8
   270a8:	umulh	x18, x18, x8
   270ac:	adds	x5, x1, x0
   270b0:	adc	x17, x18, x17
   270b4:	ldp	x4, x18, [x15], #-32
   270b8:	umulh	x1, x4, x9
   270bc:	mul	x0, x4, x9
   270c0:	adds	x4, x5, x0
   270c4:	adc	x17, x17, x1
   270c8:	mul	x0, x18, x10
   270cc:	umulh	x18, x18, x10
   270d0:	adds	x1, x4, x0
   270d4:	adc	x17, x17, x18
   270d8:	mul	x18, x14, x11
   270dc:	umulh	x14, x14, x11
   270e0:	mul	x0, x13, x12
   270e4:	umulh	x13, x13, x12
   270e8:	adds	x4, x1, x18
   270ec:	adc	x17, x17, x14
   270f0:	adds	x14, x0, x4
   270f4:	adc	x13, x13, x17
   270f8:	cmp	x16, #0x7
   270fc:	b.gt	27098 <__gmpn_mod_1s_4p@@Base+0xe0>
   27100:	ldp	x12, x11, [x3]
   27104:	mul	x10, x13, x8
   27108:	umulh	x8, x13, x8
   2710c:	mov	x9, xzr
   27110:	adds	x13, x14, x10
   27114:	adc	x8, x8, x9
   27118:	neg	w10, w11
   2711c:	lsl	x8, x8, x11
   27120:	lsr	x10, x13, x10
   27124:	orr	x8, x10, x8
   27128:	umulh	x10, x8, x12
   2712c:	mul	x12, x8, x12
   27130:	add	x8, x8, #0x1
   27134:	lsl	x13, x13, x11
   27138:	adds	x14, x12, x13
   2713c:	adc	x8, x10, x8
   27140:	msub	x8, x8, x2, x13
   27144:	cmp	x8, x14
   27148:	csel	x10, x2, x9, hi  // hi = pmore
   2714c:	add	x8, x10, x8
   27150:	cmp	x8, x2
   27154:	csel	x9, x9, x2, cc  // cc = lo, ul, last
   27158:	sub	x8, x8, x9
   2715c:	lsr	x0, x8, x11
   27160:	ret
   27164:	nop
   27168:	nop
   2716c:	nop

0000000000027170 <__gmpn_lshiftc@@Base>:
   27170:	add	x16, x0, x2, lsl #3
   27174:	add	x1, x1, x2, lsl #3
   27178:	neg	x8, x3
   2717c:	lsr	x18, x2, #2
   27180:	tbz	w2, #0, 271c4 <__gmpn_lshiftc@@Base+0x54>
   27184:	ldur	x4, [x1, #-8]
   27188:	tbnz	w2, #1, 271b4 <__gmpn_lshiftc@@Base+0x44>
   2718c:	lsr	x0, x4, x8
   27190:	lsl	x2, x4, x3
   27194:	cbnz	x18, 271a4 <__gmpn_lshiftc@@Base+0x34>
   27198:	mvn	x2, x2
   2719c:	stur	x2, [x16, #-8]
   271a0:	ret
   271a4:	ldp	x4, x5, [x1, #-24]
   271a8:	sub	x1, x1, #0x8
   271ac:	add	x16, x16, #0x10
   271b0:	b	27244 <__gmpn_lshiftc@@Base+0xd4>
   271b4:	lsr	x0, x4, x8
   271b8:	lsl	x2, x4, x3
   271bc:	ldp	x6, x7, [x1, #-24]!
   271c0:	b	27268 <__gmpn_lshiftc@@Base+0xf8>
   271c4:	ldp	x4, x5, [x1, #-16]
   271c8:	tbz	w2, #1, 27208 <__gmpn_lshiftc@@Base+0x98>
   271cc:	lsr	x0, x5, x8
   271d0:	lsl	x13, x5, x3
   271d4:	lsr	x10, x4, x8
   271d8:	lsl	x2, x4, x3
   271dc:	cbnz	x18, 271f0 <__gmpn_lshiftc@@Base+0x80>
   271e0:	eon	x10, x10, x13
   271e4:	mvn	x2, x2
   271e8:	stp	x2, x10, [x16, #-16]
   271ec:	ret
   271f0:	ldp	x4, x5, [x1, #-32]
   271f4:	eon	x10, x10, x13
   271f8:	stur	x10, [x16, #-8]
   271fc:	sub	x1, x1, #0x10
   27200:	add	x16, x16, #0x8
   27204:	b	27244 <__gmpn_lshiftc@@Base+0xd4>
   27208:	lsr	x0, x5, x8
   2720c:	lsl	x13, x5, x3
   27210:	lsr	x10, x4, x8
   27214:	lsl	x2, x4, x3
   27218:	ldp	x6, x7, [x1, #-32]!
   2721c:	eon	x10, x10, x13
   27220:	str	x10, [x16, #-8]!
   27224:	b	27264 <__gmpn_lshiftc@@Base+0xf4>
   27228:	nop
   2722c:	nop
   27230:	ldp	x4, x5, [x1, #-16]
   27234:	eon	x10, x10, x13
   27238:	eon	x11, x12, x2
   2723c:	stp	x10, x11, [x16, #-16]
   27240:	lsl	x2, x6, x3
   27244:	lsr	x10, x4, x8
   27248:	lsl	x13, x5, x3
   2724c:	lsr	x12, x5, x8
   27250:	ldp	x6, x7, [x1, #-32]!
   27254:	eon	x10, x10, x13
   27258:	eon	x11, x12, x2
   2725c:	stp	x10, x11, [x16, #-32]!
   27260:	lsl	x2, x4, x3
   27264:	sub	x18, x18, #0x1
   27268:	lsr	x10, x6, x8
   2726c:	lsl	x13, x7, x3
   27270:	lsr	x12, x7, x8
   27274:	cbnz	x18, 27230 <__gmpn_lshiftc@@Base+0xc0>
   27278:	eon	x10, x10, x13
   2727c:	eon	x11, x12, x2
   27280:	lsl	x2, x6, x3
   27284:	stp	x10, x11, [x16, #-16]
   27288:	mvn	x2, x2
   2728c:	stur	x2, [x16, #-24]
   27290:	ret

0000000000027294 <__gmpn_mul@@Base>:
   27294:	stp	x29, x30, [sp, #-96]!
   27298:	stp	x28, x27, [sp, #16]
   2729c:	stp	x26, x25, [sp, #32]
   272a0:	stp	x24, x23, [sp, #48]
   272a4:	stp	x22, x21, [sp, #64]
   272a8:	stp	x20, x19, [sp, #80]
   272ac:	mov	x29, sp
   272b0:	sub	sp, sp, #0x90
   272b4:	mov	x19, x4
   272b8:	mov	x28, x3
   272bc:	mov	x20, x2
   272c0:	mov	x23, x1
   272c4:	cmp	x2, #0xd
   272c8:	mov	x21, x0
   272cc:	b.le	273d0 <__gmpn_mul@@Base+0x13c>
   272d0:	cmp	x20, x19
   272d4:	b.ne	272f0 <__gmpn_mul@@Base+0x5c>  // b.any
   272d8:	mov	x0, x21
   272dc:	mov	x1, x23
   272e0:	mov	x2, x28
   272e4:	mov	x3, x20
   272e8:	bl	c9b0 <__gmpn_mul_n@plt>
   272ec:	b	273e8 <__gmpn_mul@@Base+0x154>
   272f0:	cmp	x19, #0xd
   272f4:	b.gt	27414 <__gmpn_mul@@Base+0x180>
   272f8:	cmp	x20, #0x1f5
   272fc:	b.lt	273d0 <__gmpn_mul@@Base+0x13c>  // b.tstop
   27300:	cmp	x19, #0x1
   27304:	b.eq	273d0 <__gmpn_mul@@Base+0x13c>  // b.none
   27308:	mov	w2, #0x1f4                 	// #500
   2730c:	mov	x0, x21
   27310:	mov	x1, x23
   27314:	mov	x3, x28
   27318:	mov	x4, x19
   2731c:	bl	c570 <__gmpn_mul_basecase@plt>
   27320:	add	x24, x21, #0xfa0
   27324:	sub	x0, x29, #0x70
   27328:	mov	x1, x24
   2732c:	mov	x2, x19
   27330:	bl	ca70 <__gmpn_copyi@plt>
   27334:	sub	x22, x20, #0x1f4
   27338:	cmp	x20, #0x3e9
   2733c:	add	x23, x23, #0xfa0
   27340:	b.lt	275cc <__gmpn_mul@@Base+0x338>  // b.tstop
   27344:	add	x8, x21, x19, lsl #3
   27348:	add	x25, x8, #0xfa8
   2734c:	mov	x21, x24
   27350:	mov	w2, #0x1f4                 	// #500
   27354:	mov	x0, x21
   27358:	mov	x1, x23
   2735c:	mov	x3, x28
   27360:	mov	x4, x19
   27364:	bl	c570 <__gmpn_mul_basecase@plt>
   27368:	sub	x2, x29, #0x70
   2736c:	mov	x0, x21
   27370:	mov	x1, x21
   27374:	mov	x3, x19
   27378:	bl	ca90 <__gmpn_add_n@plt>
   2737c:	ldr	x8, [x21, x19, lsl #3]
   27380:	adds	x8, x8, x0
   27384:	str	x8, [x21, x19, lsl #3]
   27388:	b.cc	273a0 <__gmpn_mul@@Base+0x10c>  // b.lo, b.ul, b.last
   2738c:	mov	x8, x25
   27390:	ldr	x9, [x8]
   27394:	adds	x9, x9, #0x1
   27398:	str	x9, [x8], #8
   2739c:	b.cs	27390 <__gmpn_mul@@Base+0xfc>  // b.hs, b.nlast
   273a0:	add	x21, x21, #0xfa0
   273a4:	sub	x0, x29, #0x70
   273a8:	mov	x1, x21
   273ac:	mov	x2, x19
   273b0:	bl	ca70 <__gmpn_copyi@plt>
   273b4:	sub	x20, x22, #0x1f4
   273b8:	add	x23, x23, #0xfa0
   273bc:	cmp	x22, #0x3e8
   273c0:	add	x25, x25, #0xfa0
   273c4:	mov	x22, x20
   273c8:	b.gt	27350 <__gmpn_mul@@Base+0xbc>
   273cc:	b	275d4 <__gmpn_mul@@Base+0x340>
   273d0:	mov	x0, x21
   273d4:	mov	x1, x23
   273d8:	mov	x2, x20
   273dc:	mov	x3, x28
   273e0:	mov	x4, x19
   273e4:	bl	c570 <__gmpn_mul_basecase@plt>
   273e8:	add	x8, x19, x20
   273ec:	add	x8, x21, x8, lsl #3
   273f0:	ldur	x0, [x8, #-8]
   273f4:	mov	sp, x29
   273f8:	ldp	x20, x19, [sp, #80]
   273fc:	ldp	x22, x21, [sp, #64]
   27400:	ldp	x24, x23, [sp, #48]
   27404:	ldp	x26, x25, [sp, #32]
   27408:	ldp	x28, x27, [sp, #16]
   2740c:	ldp	x29, x30, [sp], #96
   27410:	ret
   27414:	cmp	x19, #0x30
   27418:	stur	x28, [x29, #-120]
   2741c:	b.le	27460 <__gmpn_mul@@Base+0x1cc>
   27420:	add	x8, x19, x20
   27424:	mov	w9, #0x1900                	// #6400
   27428:	cmp	x8, x9
   2742c:	b.lt	274c0 <__gmpn_mul@@Base+0x22c>  // b.tstop
   27430:	add	x25, x19, x19, lsl #1
   27434:	cmp	x25, #0xc7f
   27438:	b.le	274c0 <__gmpn_mul@@Base+0x22c>
   2743c:	cmp	x20, x19, lsl #3
   27440:	b.ge	279b8 <__gmpn_mul@@Base+0x724>  // b.tcont
   27444:	mov	x0, x21
   27448:	mov	x1, x23
   2744c:	mov	x2, x20
   27450:	mov	x3, x28
   27454:	mov	x4, x19
   27458:	bl	ccc0 <__gmpn_nussbaumer_mul@plt>
   2745c:	b	273e8 <__gmpn_mul@@Base+0x154>
   27460:	add	x8, x19, x19, lsl #3
   27464:	cmp	x8, #0x0
   27468:	cinc	x8, x8, lt  // lt = tstop
   2746c:	lsl	x8, x8, #2
   27470:	and	x8, x8, #0xfffffffffffffff8
   27474:	add	x8, x8, #0x40f
   27478:	and	x8, x8, #0xfffffffffffffff0
   2747c:	mov	x9, sp
   27480:	sub	x5, x9, x8
   27484:	mov	sp, x5
   27488:	add	x24, x19, x19, lsl #1
   2748c:	cmp	x24, x20
   27490:	b.le	275f4 <__gmpn_mul@@Base+0x360>
   27494:	lsl	x8, x20, #2
   27498:	add	x9, x19, x19, lsl #2
   2749c:	cmp	x8, x9
   274a0:	b.ge	276e8 <__gmpn_mul@@Base+0x454>  // b.tcont
   274a4:	mov	x0, x21
   274a8:	mov	x1, x23
   274ac:	mov	x2, x20
   274b0:	mov	x3, x28
   274b4:	mov	x4, x19
   274b8:	bl	d470 <__gmpn_toom22_mul@plt>
   274bc:	b	273e8 <__gmpn_mul@@Base+0x154>
   274c0:	cmp	x19, #0x52
   274c4:	b.lt	27550 <__gmpn_mul@@Base+0x2bc>  // b.tstop
   274c8:	add	x9, x20, x20, lsl #1
   274cc:	add	x9, x9, #0xc
   274d0:	cmp	x9, x19, lsl #2
   274d4:	b.ge	27550 <__gmpn_mul@@Base+0x2bc>  // b.tcont
   274d8:	cmp	x19, #0xac
   274dc:	stur	xzr, [x29, #-112]
   274e0:	b.le	27a7c <__gmpn_mul@@Base+0x7e8>
   274e4:	cmp	x19, #0xeb
   274e8:	b.le	27c1c <__gmpn_mul@@Base+0x988>
   274ec:	mov	x9, #0x4925                	// #18725
   274f0:	movk	x9, #0x2492, lsl #16
   274f4:	movk	x9, #0x9249, lsl #32
   274f8:	lsr	x8, x8, #1
   274fc:	movk	x9, #0x4924, lsl #48
   27500:	umulh	x8, x8, x9
   27504:	mov	w10, #0x78                  	// #120
   27508:	lsr	x8, x8, #1
   2750c:	mul	x8, x8, x10
   27510:	add	x1, x8, #0xd68
   27514:	mov	w8, #0x7f00                	// #32512
   27518:	cmp	x1, x8
   2751c:	b.hi	27cf8 <__gmpn_mul@@Base+0xa64>  // b.pmore
   27520:	add	x9, x1, #0xf
   27524:	mov	x8, sp
   27528:	and	x9, x9, #0xfffffffffffffff0
   2752c:	sub	x5, x8, x9
   27530:	mov	sp, x5
   27534:	mov	x0, x21
   27538:	mov	x1, x23
   2753c:	mov	x2, x20
   27540:	mov	x3, x28
   27544:	mov	x4, x19
   27548:	bl	cb40 <__gmpn_toom8h_mul@plt>
   2754c:	b	27cc8 <__gmpn_mul@@Base+0xa34>
   27550:	lsl	x8, x19, #5
   27554:	add	x1, x8, #0x200
   27558:	mov	w8, #0x7f00                	// #32512
   2755c:	cmp	x1, x8
   27560:	stur	xzr, [x29, #-112]
   27564:	b.hi	27cd8 <__gmpn_mul@@Base+0xa44>  // b.pmore
   27568:	add	x9, x1, #0xf
   2756c:	mov	x8, sp
   27570:	and	x9, x9, #0xfffffffffffffff0
   27574:	sub	x8, x8, x9
   27578:	stur	x8, [x29, #-128]
   2757c:	mov	sp, x8
   27580:	lsl	x9, x20, #1
   27584:	add	x8, x19, x19, lsl #2
   27588:	cmp	x9, x8
   2758c:	stur	x8, [x29, #-136]
   27590:	b.ge	27690 <__gmpn_mul@@Base+0x3fc>  // b.tcont
   27594:	add	x8, x20, x20, lsl #1
   27598:	lsl	x11, x19, #3
   2759c:	lsl	x10, x8, #1
   275a0:	sub	x8, x11, x19
   275a4:	cmp	x10, x8
   275a8:	b.ge	2781c <__gmpn_mul@@Base+0x588>  // b.tcont
   275ac:	ldur	x5, [x29, #-128]
   275b0:	mov	x0, x21
   275b4:	mov	x1, x23
   275b8:	mov	x2, x20
   275bc:	mov	x3, x28
   275c0:	mov	x4, x19
   275c4:	bl	c0b0 <__gmpn_toom33_mul@plt>
   275c8:	b	27cc8 <__gmpn_mul@@Base+0xa34>
   275cc:	mov	x21, x24
   275d0:	mov	x20, x22
   275d4:	mov	x0, x21
   275d8:	cmp	x20, x19
   275dc:	b.le	2763c <__gmpn_mul@@Base+0x3a8>
   275e0:	mov	x1, x23
   275e4:	mov	x2, x20
   275e8:	mov	x3, x28
   275ec:	mov	x4, x19
   275f0:	b	2764c <__gmpn_mul@@Base+0x3b8>
   275f4:	mov	x8, sp
   275f8:	sub	x26, x8, x19, lsl #5
   275fc:	mov	sp, x26
   27600:	lsl	x27, x19, #1
   27604:	mov	x0, x21
   27608:	mov	x1, x23
   2760c:	mov	x2, x27
   27610:	mov	x3, x28
   27614:	mov	x4, x19
   27618:	stur	x5, [x29, #-128]
   2761c:	bl	d4a0 <__gmpn_toom42_mul@plt>
   27620:	sub	x20, x20, x19, lsl #1
   27624:	add	x25, x21, x19, lsl #4
   27628:	cmp	x20, x24
   2762c:	add	x23, x23, x19, lsl #4
   27630:	b.ge	27714 <__gmpn_mul@@Base+0x480>  // b.tcont
   27634:	ldur	x5, [x29, #-128]
   27638:	b	277c4 <__gmpn_mul@@Base+0x530>
   2763c:	mov	x1, x28
   27640:	mov	x2, x19
   27644:	mov	x3, x23
   27648:	mov	x4, x20
   2764c:	bl	c570 <__gmpn_mul_basecase@plt>
   27650:	sub	x2, x29, #0x70
   27654:	mov	x0, x21
   27658:	mov	x1, x21
   2765c:	mov	x3, x19
   27660:	bl	ca90 <__gmpn_add_n@plt>
   27664:	ldr	x8, [x21, x19, lsl #3]
   27668:	adds	x8, x8, x0
   2766c:	str	x8, [x21, x19, lsl #3]
   27670:	b.cc	273e8 <__gmpn_mul@@Base+0x154>  // b.lo, b.ul, b.last
   27674:	add	x8, x21, x19, lsl #3
   27678:	add	x8, x8, #0x8
   2767c:	ldr	x9, [x8]
   27680:	adds	x9, x9, #0x1
   27684:	str	x9, [x8], #8
   27688:	b.cs	2767c <__gmpn_mul@@Base+0x3e8>  // b.hs, b.nlast
   2768c:	b	273e8 <__gmpn_mul@@Base+0x154>
   27690:	mov	w8, #0x1c                  	// #28
   27694:	mul	x8, x19, x8
   27698:	and	x1, x8, #0xfffffffffffffff8
   2769c:	mov	w8, #0x7f00                	// #32512
   276a0:	cmp	x1, x8
   276a4:	b.hi	27ce8 <__gmpn_mul@@Base+0xa54>  // b.pmore
   276a8:	add	x9, x1, #0xf
   276ac:	mov	x8, sp
   276b0:	and	x9, x9, #0xfffffffffffffff0
   276b4:	sub	x25, x8, x9
   276b8:	mov	sp, x25
   276bc:	lsl	x27, x19, #1
   276c0:	cmp	x19, #0x4f
   276c4:	mov	x0, x21
   276c8:	mov	x1, x23
   276cc:	mov	x2, x27
   276d0:	mov	x3, x28
   276d4:	mov	x4, x19
   276d8:	b.le	27850 <__gmpn_mul@@Base+0x5bc>
   276dc:	ldur	x5, [x29, #-128]
   276e0:	bl	c760 <__gmpn_toom63_mul@plt>
   276e4:	b	27858 <__gmpn_mul@@Base+0x5c4>
   276e8:	lsl	x9, x19, #3
   276ec:	sub	x9, x9, x19
   276f0:	mov	x0, x21
   276f4:	mov	x1, x23
   276f8:	mov	x2, x20
   276fc:	mov	x3, x28
   27700:	mov	x4, x19
   27704:	cmp	x8, x9
   27708:	b.ge	27a14 <__gmpn_mul@@Base+0x780>  // b.tcont
   2770c:	bl	c870 <__gmpn_toom32_mul@plt>
   27710:	b	273e8 <__gmpn_mul@@Base+0x154>
   27714:	add	x8, x26, x19, lsl #3
   27718:	ldur	x5, [x29, #-128]
   2771c:	stur	x8, [x29, #-136]
   27720:	mov	w8, #0x18                  	// #24
   27724:	madd	x8, x19, x8, x21
   27728:	add	x22, x8, #0x8
   2772c:	lsl	x8, x19, #4
   27730:	stur	x8, [x29, #-144]
   27734:	ldur	x3, [x29, #-120]
   27738:	mov	x0, x26
   2773c:	mov	x1, x23
   27740:	mov	x2, x27
   27744:	mov	x4, x19
   27748:	mov	x28, x24
   2774c:	bl	d4a0 <__gmpn_toom42_mul@plt>
   27750:	mov	x0, x25
   27754:	mov	x1, x25
   27758:	mov	x2, x26
   2775c:	mov	x3, x19
   27760:	bl	ca90 <__gmpn_add_n@plt>
   27764:	ldur	x1, [x29, #-136]
   27768:	add	x24, x25, x19, lsl #3
   2776c:	mov	x21, x0
   27770:	mov	x0, x24
   27774:	mov	x2, x27
   27778:	bl	ca70 <__gmpn_copyi@plt>
   2777c:	ldr	x8, [x24]
   27780:	adds	x8, x8, x21
   27784:	str	x8, [x24]
   27788:	b.cc	277a0 <__gmpn_mul@@Base+0x50c>  // b.lo, b.ul, b.last
   2778c:	mov	x8, x22
   27790:	ldr	x9, [x8]
   27794:	adds	x9, x9, #0x1
   27798:	str	x9, [x8], #8
   2779c:	b.cs	27790 <__gmpn_mul@@Base+0x4fc>  // b.hs, b.nlast
   277a0:	ldur	x8, [x29, #-144]
   277a4:	ldur	x5, [x29, #-128]
   277a8:	sub	x20, x20, x27
   277ac:	add	x25, x25, x27, lsl #3
   277b0:	add	x23, x23, x27, lsl #3
   277b4:	mov	x24, x28
   277b8:	cmp	x20, x28
   277bc:	add	x22, x22, x8
   277c0:	b.ge	27734 <__gmpn_mul@@Base+0x4a0>  // b.tcont
   277c4:	lsl	x8, x20, #2
   277c8:	add	x9, x19, x19, lsl #2
   277cc:	cmp	x8, x9
   277d0:	lsl	x24, x19, #3
   277d4:	b.ge	277f4 <__gmpn_mul@@Base+0x560>  // b.tcont
   277d8:	ldur	x3, [x29, #-120]
   277dc:	mov	x0, x26
   277e0:	mov	x1, x23
   277e4:	mov	x2, x20
   277e8:	mov	x4, x19
   277ec:	bl	d470 <__gmpn_toom22_mul@plt>
   277f0:	b	27a20 <__gmpn_mul@@Base+0x78c>
   277f4:	ldur	x3, [x29, #-120]
   277f8:	sub	x9, x24, x19
   277fc:	cmp	x8, x9
   27800:	mov	x0, x26
   27804:	mov	x1, x23
   27808:	mov	x2, x20
   2780c:	mov	x4, x19
   27810:	b.ge	27a1c <__gmpn_mul@@Base+0x788>  // b.tcont
   27814:	bl	c870 <__gmpn_toom32_mul@plt>
   27818:	b	27a20 <__gmpn_mul@@Base+0x78c>
   2781c:	add	x11, x19, x19, lsl #1
   27820:	cmp	x9, x11
   27824:	b.ge	27ab4 <__gmpn_mul@@Base+0x820>  // b.tcont
   27828:	cmp	x19, #0x50
   2782c:	b.le	27ad4 <__gmpn_mul@@Base+0x840>
   27830:	ldur	x5, [x29, #-128]
   27834:	mov	x0, x21
   27838:	mov	x1, x23
   2783c:	mov	x2, x20
   27840:	mov	x3, x28
   27844:	mov	x4, x19
   27848:	bl	cf20 <__gmpn_toom43_mul@plt>
   2784c:	b	27cc8 <__gmpn_mul@@Base+0xa34>
   27850:	ldur	x5, [x29, #-128]
   27854:	bl	d4a0 <__gmpn_toom42_mul@plt>
   27858:	ldur	x8, [x29, #-136]
   2785c:	sub	x20, x20, x27
   27860:	add	x26, x21, x27, lsl #3
   27864:	add	x23, x23, x27, lsl #3
   27868:	cmp	x8, x20, lsl #1
   2786c:	b.gt	27924 <__gmpn_mul@@Base+0x690>
   27870:	add	x8, x25, x19, lsl #3
   27874:	stur	x8, [x29, #-144]
   27878:	mov	w8, #0x18                  	// #24
   2787c:	madd	x8, x19, x8, x21
   27880:	add	x22, x8, #0x8
   27884:	lsl	x28, x19, #4
   27888:	mov	x0, x25
   2788c:	mov	x1, x23
   27890:	mov	x2, x27
   27894:	cmp	x19, #0x4f
   27898:	b.le	278ac <__gmpn_mul@@Base+0x618>
   2789c:	ldp	x5, x3, [x29, #-128]
   278a0:	mov	x4, x19
   278a4:	bl	c760 <__gmpn_toom63_mul@plt>
   278a8:	b	278b8 <__gmpn_mul@@Base+0x624>
   278ac:	ldp	x5, x3, [x29, #-128]
   278b0:	mov	x4, x19
   278b4:	bl	d4a0 <__gmpn_toom42_mul@plt>
   278b8:	mov	x0, x26
   278bc:	mov	x1, x26
   278c0:	mov	x2, x25
   278c4:	mov	x3, x19
   278c8:	bl	ca90 <__gmpn_add_n@plt>
   278cc:	ldur	x1, [x29, #-144]
   278d0:	add	x24, x26, x19, lsl #3
   278d4:	mov	x21, x0
   278d8:	mov	x0, x24
   278dc:	mov	x2, x27
   278e0:	bl	ca70 <__gmpn_copyi@plt>
   278e4:	ldr	x8, [x24]
   278e8:	adds	x8, x8, x21
   278ec:	str	x8, [x24]
   278f0:	b.cc	27908 <__gmpn_mul@@Base+0x674>  // b.lo, b.ul, b.last
   278f4:	mov	x8, x22
   278f8:	ldr	x9, [x8]
   278fc:	adds	x9, x9, #0x1
   27900:	str	x9, [x8], #8
   27904:	b.cs	278f8 <__gmpn_mul@@Base+0x664>  // b.hs, b.nlast
   27908:	ldur	x8, [x29, #-136]
   2790c:	sub	x20, x20, x27
   27910:	add	x26, x26, x27, lsl #3
   27914:	add	x23, x23, x27, lsl #3
   27918:	cmp	x8, x20, lsl #1
   2791c:	add	x22, x22, x28
   27920:	b.le	27888 <__gmpn_mul@@Base+0x5f4>
   27924:	mov	x0, x25
   27928:	cmp	x20, x19
   2792c:	b.ge	27944 <__gmpn_mul@@Base+0x6b0>  // b.tcont
   27930:	ldur	x1, [x29, #-120]
   27934:	mov	x2, x19
   27938:	mov	x3, x23
   2793c:	mov	x4, x20
   27940:	b	27954 <__gmpn_mul@@Base+0x6c0>
   27944:	ldur	x3, [x29, #-120]
   27948:	mov	x1, x23
   2794c:	mov	x2, x20
   27950:	mov	x4, x19
   27954:	bl	ccf0 <__gmpn_mul@plt>
   27958:	mov	x0, x26
   2795c:	mov	x1, x26
   27960:	mov	x2, x25
   27964:	mov	x3, x19
   27968:	bl	ca90 <__gmpn_add_n@plt>
   2796c:	add	x22, x26, x19, lsl #3
   27970:	mov	x21, x0
   27974:	add	x1, x25, x19, lsl #3
   27978:	mov	x0, x22
   2797c:	mov	x2, x20
   27980:	bl	ca70 <__gmpn_copyi@plt>
   27984:	ldr	x8, [x22]
   27988:	adds	x8, x8, x21
   2798c:	str	x8, [x22]
   27990:	b.cc	279b0 <__gmpn_mul@@Base+0x71c>  // b.lo, b.ul, b.last
   27994:	lsl	x8, x19, #3
   27998:	add	x8, x8, #0x8
   2799c:	ldr	x9, [x26, x8]
   279a0:	adds	x9, x9, #0x1
   279a4:	str	x9, [x26, x8]
   279a8:	add	x8, x8, #0x8
   279ac:	b.cs	2799c <__gmpn_mul@@Base+0x708>  // b.hs, b.nlast
   279b0:	mov	x21, x26
   279b4:	b	27cc8 <__gmpn_mul@@Base+0xa34>
   279b8:	add	x8, x19, x19, lsl #3
   279bc:	lsl	x8, x8, #2
   279c0:	and	x1, x8, #0xfffffffffffffff8
   279c4:	sub	x0, x29, #0x70
   279c8:	stur	xzr, [x29, #-112]
   279cc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   279d0:	mov	x24, x0
   279d4:	mov	x0, x21
   279d8:	mov	x1, x23
   279dc:	mov	x2, x25
   279e0:	mov	x3, x28
   279e4:	mov	x4, x19
   279e8:	bl	ccc0 <__gmpn_nussbaumer_mul@plt>
   279ec:	lsl	x9, x19, #3
   279f0:	sub	x20, x20, x25
   279f4:	sub	x9, x9, x19
   279f8:	add	x8, x21, x25, lsl #3
   279fc:	cmp	x9, x20, lsl #1
   27a00:	add	x23, x23, x25, lsl #3
   27a04:	stur	x9, [x29, #-128]
   27a08:	b.le	27af4 <__gmpn_mul@@Base+0x860>
   27a0c:	mov	x21, x8
   27a10:	b	27b94 <__gmpn_mul@@Base+0x900>
   27a14:	bl	d4a0 <__gmpn_toom42_mul@plt>
   27a18:	b	273e8 <__gmpn_mul@@Base+0x154>
   27a1c:	bl	d4a0 <__gmpn_toom42_mul@plt>
   27a20:	mov	x0, x25
   27a24:	mov	x1, x25
   27a28:	mov	x2, x26
   27a2c:	mov	x3, x19
   27a30:	bl	ca90 <__gmpn_add_n@plt>
   27a34:	add	x22, x25, x19, lsl #3
   27a38:	mov	x21, x0
   27a3c:	add	x1, x26, x19, lsl #3
   27a40:	mov	x0, x22
   27a44:	mov	x2, x20
   27a48:	bl	ca70 <__gmpn_copyi@plt>
   27a4c:	ldr	x8, [x22]
   27a50:	adds	x8, x8, x21
   27a54:	str	x8, [x22]
   27a58:	b.cc	27a74 <__gmpn_mul@@Base+0x7e0>  // b.lo, b.ul, b.last
   27a5c:	add	x8, x24, #0x8
   27a60:	ldr	x9, [x25, x8]
   27a64:	adds	x9, x9, #0x1
   27a68:	str	x9, [x25, x8]
   27a6c:	add	x8, x8, #0x8
   27a70:	b.cs	27a60 <__gmpn_mul@@Base+0x7cc>  // b.hs, b.nlast
   27a74:	mov	x21, x25
   27a78:	b	273e8 <__gmpn_mul@@Base+0x154>
   27a7c:	mov	w8, #0x18                  	// #24
   27a80:	mul	x8, x20, x8
   27a84:	add	x8, x8, #0x20f
   27a88:	and	x8, x8, #0xfffffffffffffff0
   27a8c:	mov	x9, sp
   27a90:	sub	x5, x9, x8
   27a94:	mov	sp, x5
   27a98:	mov	x0, x21
   27a9c:	mov	x1, x23
   27aa0:	mov	x2, x20
   27aa4:	mov	x3, x28
   27aa8:	mov	x4, x19
   27aac:	bl	c740 <__gmpn_toom44_mul@plt>
   27ab0:	b	27cc8 <__gmpn_mul@@Base+0xa34>
   27ab4:	mov	w9, #0xb                   	// #11
   27ab8:	mul	x9, x19, x9
   27abc:	cmp	x10, x9
   27ac0:	b.ge	27c5c <__gmpn_mul@@Base+0x9c8>  // b.tcont
   27ac4:	cmp	x8, x20, lsl #2
   27ac8:	b.le	27c84 <__gmpn_mul@@Base+0x9f0>
   27acc:	cmp	x19, #0x4b
   27ad0:	b.gt	27c8c <__gmpn_mul@@Base+0x9f8>
   27ad4:	ldur	x5, [x29, #-128]
   27ad8:	mov	x0, x21
   27adc:	mov	x1, x23
   27ae0:	mov	x2, x20
   27ae4:	mov	x3, x28
   27ae8:	mov	x4, x19
   27aec:	bl	c870 <__gmpn_toom32_mul@plt>
   27af0:	b	27cc8 <__gmpn_mul@@Base+0xa34>
   27af4:	add	x9, x24, x19, lsl #3
   27af8:	stur	x9, [x29, #-136]
   27afc:	add	x9, x21, x19, lsl #5
   27b00:	add	x10, x19, x19, lsl #1
   27b04:	add	x26, x9, #0x8
   27b08:	lsl	x22, x10, #3
   27b0c:	mov	x21, x8
   27b10:	mov	x0, x24
   27b14:	mov	x1, x23
   27b18:	mov	x2, x25
   27b1c:	mov	x3, x28
   27b20:	mov	x4, x19
   27b24:	bl	ccc0 <__gmpn_nussbaumer_mul@plt>
   27b28:	mov	x0, x21
   27b2c:	mov	x1, x21
   27b30:	mov	x2, x24
   27b34:	mov	x3, x19
   27b38:	bl	ca90 <__gmpn_add_n@plt>
   27b3c:	ldur	x1, [x29, #-136]
   27b40:	add	x28, x21, x19, lsl #3
   27b44:	mov	x27, x0
   27b48:	mov	x0, x28
   27b4c:	mov	x2, x25
   27b50:	bl	ca70 <__gmpn_copyi@plt>
   27b54:	ldr	x8, [x28]
   27b58:	adds	x8, x8, x27
   27b5c:	str	x8, [x28]
   27b60:	b.cc	27b78 <__gmpn_mul@@Base+0x8e4>  // b.lo, b.ul, b.last
   27b64:	mov	x8, x26
   27b68:	ldr	x9, [x8]
   27b6c:	adds	x9, x9, #0x1
   27b70:	str	x9, [x8], #8
   27b74:	b.cs	27b68 <__gmpn_mul@@Base+0x8d4>  // b.hs, b.nlast
   27b78:	ldp	x8, x28, [x29, #-128]
   27b7c:	sub	x20, x20, x25
   27b80:	add	x21, x21, x25, lsl #3
   27b84:	add	x23, x23, x25, lsl #3
   27b88:	cmp	x8, x20, lsl #1
   27b8c:	add	x26, x26, x22
   27b90:	b.le	27b10 <__gmpn_mul@@Base+0x87c>
   27b94:	mov	x0, x24
   27b98:	cmp	x20, x19
   27b9c:	b.ge	27bb4 <__gmpn_mul@@Base+0x920>  // b.tcont
   27ba0:	mov	x1, x28
   27ba4:	mov	x2, x19
   27ba8:	mov	x3, x23
   27bac:	mov	x4, x20
   27bb0:	b	27bc4 <__gmpn_mul@@Base+0x930>
   27bb4:	mov	x1, x23
   27bb8:	mov	x2, x20
   27bbc:	mov	x3, x28
   27bc0:	mov	x4, x19
   27bc4:	bl	ccf0 <__gmpn_mul@plt>
   27bc8:	mov	x0, x21
   27bcc:	mov	x1, x21
   27bd0:	mov	x2, x24
   27bd4:	mov	x3, x19
   27bd8:	bl	ca90 <__gmpn_add_n@plt>
   27bdc:	add	x22, x21, x19, lsl #3
   27be0:	mov	x23, x0
   27be4:	add	x1, x24, x19, lsl #3
   27be8:	mov	x0, x22
   27bec:	mov	x2, x20
   27bf0:	bl	ca70 <__gmpn_copyi@plt>
   27bf4:	ldr	x8, [x22]
   27bf8:	adds	x8, x8, x23
   27bfc:	str	x8, [x22]
   27c00:	b.cc	27cc8 <__gmpn_mul@@Base+0xa34>  // b.lo, b.ul, b.last
   27c04:	add	x8, x22, #0x8
   27c08:	ldr	x9, [x8]
   27c0c:	adds	x9, x9, #0x1
   27c10:	str	x9, [x8], #8
   27c14:	b.cs	27c08 <__gmpn_mul@@Base+0x974>  // b.hs, b.nlast
   27c18:	b	27cc8 <__gmpn_mul@@Base+0xa34>
   27c1c:	mov	x9, #0xcccccccccccccccc    	// #-3689348814741910324
   27c20:	movk	x9, #0xcccd
   27c24:	umulh	x8, x8, x9
   27c28:	lsr	x8, x8, #3
   27c2c:	mov	w9, #0x60                  	// #96
   27c30:	mov	x10, sp
   27c34:	msub	x8, x8, x9, x10
   27c38:	sub	x5, x8, #0xc60
   27c3c:	mov	sp, x5
   27c40:	mov	x0, x21
   27c44:	mov	x1, x23
   27c48:	mov	x2, x20
   27c4c:	mov	x3, x28
   27c50:	mov	x4, x19
   27c54:	bl	cc40 <__gmpn_toom6h_mul@plt>
   27c58:	b	27cc8 <__gmpn_mul@@Base+0xa34>
   27c5c:	cmp	x19, #0x4f
   27c60:	b.le	27cac <__gmpn_mul@@Base+0xa18>
   27c64:	ldur	x5, [x29, #-128]
   27c68:	mov	x0, x21
   27c6c:	mov	x1, x23
   27c70:	mov	x2, x20
   27c74:	mov	x3, x28
   27c78:	mov	x4, x19
   27c7c:	bl	c760 <__gmpn_toom63_mul@plt>
   27c80:	b	27cc8 <__gmpn_mul@@Base+0xa34>
   27c84:	cmp	x19, #0x50
   27c88:	b.le	27cac <__gmpn_mul@@Base+0xa18>
   27c8c:	ldur	x5, [x29, #-128]
   27c90:	mov	x0, x21
   27c94:	mov	x1, x23
   27c98:	mov	x2, x20
   27c9c:	mov	x3, x28
   27ca0:	mov	x4, x19
   27ca4:	bl	ca60 <__gmpn_toom53_mul@plt>
   27ca8:	b	27cc8 <__gmpn_mul@@Base+0xa34>
   27cac:	ldur	x5, [x29, #-128]
   27cb0:	mov	x0, x21
   27cb4:	mov	x1, x23
   27cb8:	mov	x2, x20
   27cbc:	mov	x3, x28
   27cc0:	mov	x4, x19
   27cc4:	bl	d4a0 <__gmpn_toom42_mul@plt>
   27cc8:	ldur	x0, [x29, #-112]
   27ccc:	cbz	x0, 273e8 <__gmpn_mul@@Base+0x154>
   27cd0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   27cd4:	b	273e8 <__gmpn_mul@@Base+0x154>
   27cd8:	sub	x0, x29, #0x70
   27cdc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27ce0:	stur	x0, [x29, #-128]
   27ce4:	b	27580 <__gmpn_mul@@Base+0x2ec>
   27ce8:	sub	x0, x29, #0x70
   27cec:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27cf0:	mov	x25, x0
   27cf4:	b	276bc <__gmpn_mul@@Base+0x428>
   27cf8:	sub	x0, x29, #0x70
   27cfc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27d00:	mov	x5, x0
   27d04:	b	27534 <__gmpn_mul@@Base+0x2a0>

0000000000027d08 <__gmpn_fft_best_k@@Base>:
   27d08:	adrp	x8, 53000 <__gmpn_bases@@Base+0x1938>
   27d0c:	add	x8, x8, #0xf60
   27d10:	mov	w9, #0x1d8                 	// #472
   27d14:	smaddl	x9, w1, w9, x8
   27d18:	ldr	w10, [x9], #4
   27d1c:	lsr	w8, w10, #27
   27d20:	ldr	w10, [x9], #4
   27d24:	and	x11, x10, #0x7ffffff
   27d28:	lsl	x11, x11, x8
   27d2c:	cmp	x11, x0
   27d30:	b.lt	27d1c <__gmpn_fft_best_k@@Base+0x14>  // b.tstop
   27d34:	mov	w0, w8
   27d38:	ret

0000000000027d3c <__gmpn_fft_next_size@@Base>:
   27d3c:	sub	x8, x0, #0x1
   27d40:	asr	x8, x8, x1
   27d44:	add	x8, x8, #0x1
   27d48:	lsl	x0, x8, x1
   27d4c:	ret

0000000000027d50 <__gmpn_mul_fft@@Base>:
   27d50:	sub	sp, sp, #0xc0
   27d54:	stp	x20, x19, [sp, #176]
   27d58:	mov	w19, w6
   27d5c:	sub	x8, x1, #0x1
   27d60:	asr	x8, x8, x19
   27d64:	cmp	x2, x4
   27d68:	add	x8, x8, #0x1
   27d6c:	stp	x22, x21, [sp, #160]
   27d70:	cset	w21, eq  // eq = none
   27d74:	cmp	x3, x5
   27d78:	lsl	x8, x8, x19
   27d7c:	stp	x29, x30, [sp, #96]
   27d80:	stp	x24, x23, [sp, #144]
   27d84:	add	x29, sp, #0x60
   27d88:	cset	w23, eq  // eq = none
   27d8c:	cmp	x8, x1
   27d90:	stp	x28, x27, [sp, #112]
   27d94:	stp	x26, x25, [sp, #128]
   27d98:	str	x4, [sp, #32]
   27d9c:	str	x2, [sp, #48]
   27da0:	stur	x3, [x29, #-40]
   27da4:	b.ne	28074 <__gmpn_mul_fft@@Base+0x324>  // b.any
   27da8:	add	w25, w19, #0x1
   27dac:	mov	x26, x1
   27db0:	mov	x27, x0
   27db4:	lsl	x24, x1, #6
   27db8:	sbfiz	x1, x25, #3, #32
   27dbc:	sub	x0, x29, #0x8
   27dc0:	mov	x28, x5
   27dc4:	mov	w20, w19
   27dc8:	stur	xzr, [x29, #-8]
   27dcc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27dd0:	mov	w8, #0x8                   	// #8
   27dd4:	mov	x22, x0
   27dd8:	lsl	x1, x8, x20
   27ddc:	sub	x0, x29, #0x8
   27de0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27de4:	tbnz	w19, #31, 27e0c <__gmpn_mul_fft@@Base+0xbc>
   27de8:	mov	x8, xzr
   27dec:	mov	w9, w25
   27df0:	mov	w10, #0x1                   	// #1
   27df4:	str	x0, [x22, x8, lsl #3]
   27df8:	lsl	x11, x10, x8
   27dfc:	add	x8, x8, #0x1
   27e00:	cmp	x9, x8
   27e04:	add	x0, x0, x11, lsl #2
   27e08:	b.ne	27df4 <__gmpn_mul_fft@@Base+0xa4>  // b.any
   27e0c:	mov	x0, x22
   27e10:	mov	w1, w19
   27e14:	and	w21, w21, w23
   27e18:	bl	280a4 <__gmpn_mul_fft@@Base+0x354>
   27e1c:	asr	x9, x24, x20
   27e20:	sub	x8, x9, #0x1
   27e24:	add	x10, x9, #0x3e
   27e28:	cmp	x8, #0x0
   27e2c:	csel	x8, x10, x8, lt  // lt = tstop
   27e30:	mov	w10, #0x40                  	// #64
   27e34:	cmp	w19, #0x1
   27e38:	b.lt	27e58 <__gmpn_mul_fft@@Base+0x108>  // b.tstop
   27e3c:	mov	w11, w19
   27e40:	mov	x12, x10
   27e44:	cmp	w11, #0x2
   27e48:	lsr	x10, x10, #1
   27e4c:	b.lt	27e58 <__gmpn_mul_fft@@Base+0x108>  // b.tstop
   27e50:	sub	w11, w11, #0x1
   27e54:	tbz	w12, #1, 27e40 <__gmpn_mul_fft@@Base+0xf0>
   27e58:	lsl	x9, x9, #1
   27e5c:	add	x9, x9, w19, sxtw
   27e60:	lsl	x10, x10, x20
   27e64:	add	x9, x9, #0x2
   27e68:	sdiv	x9, x9, x10
   27e6c:	add	x9, x9, #0x1
   27e70:	mul	x23, x9, x10
   27e74:	add	x9, x23, #0x3f
   27e78:	cmp	x23, #0x0
   27e7c:	mov	w11, #0x13c                 	// #316
   27e80:	mov	w12, #0x110                 	// #272
   27e84:	csel	x9, x9, x23, lt  // lt = tstop
   27e88:	cmp	w21, #0x0
   27e8c:	stur	x27, [x29, #-32]
   27e90:	asr	x27, x9, #6
   27e94:	csel	x9, x12, x11, ne  // ne = any
   27e98:	cmp	x27, x9
   27e9c:	b.ge	27f68 <__gmpn_mul_fft@@Base+0x218>  // b.tcont
   27ea0:	cmp	x27, x26
   27ea4:	stur	w21, [x29, #-12]
   27ea8:	str	x28, [sp, #40]
   27eac:	stur	x26, [x29, #-24]
   27eb0:	b.ge	2808c <__gmpn_mul_fft@@Base+0x33c>  // b.tcont
   27eb4:	add	x24, x27, #0x1
   27eb8:	mov	w9, #0x1                   	// #1
   27ebc:	asr	x8, x8, #6
   27ec0:	lsl	x1, x24, #4
   27ec4:	sub	x0, x29, #0x8
   27ec8:	lsl	x25, x9, x20
   27ecc:	add	x28, x8, #0x1
   27ed0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27ed4:	lsl	x8, x24, x20
   27ed8:	asr	x23, x23, x20
   27edc:	lsl	x20, x8, #3
   27ee0:	mov	x21, x0
   27ee4:	sub	x0, x29, #0x8
   27ee8:	mov	x1, x20
   27eec:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27ef0:	lsl	x26, x25, #3
   27ef4:	mov	x24, x0
   27ef8:	sub	x0, x29, #0x8
   27efc:	mov	x1, x26
   27f00:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27f04:	ldr	x4, [sp, #48]
   27f08:	ldur	x5, [x29, #-40]
   27f0c:	mov	x1, x0
   27f10:	mov	x0, x24
   27f14:	mov	x2, x25
   27f18:	mov	x3, x27
   27f1c:	mov	x6, x28
   27f20:	mov	x7, x23
   27f24:	str	x21, [sp]
   27f28:	mov	x24, x1
   27f2c:	bl	28110 <__gmpn_mul_fft@@Base+0x3c0>
   27f30:	ldur	w8, [x29, #-12]
   27f34:	cbz	w8, 27fc4 <__gmpn_mul_fft@@Base+0x274>
   27f38:	sub	x8, x25, #0x1
   27f3c:	madd	x8, x28, x8, x27
   27f40:	lsl	x8, x8, #3
   27f44:	add	x1, x8, #0x8
   27f48:	sub	x0, x29, #0x8
   27f4c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27f50:	mov	x20, x0
   27f54:	sub	x0, x29, #0x8
   27f58:	mov	x1, x26
   27f5c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27f60:	mov	x26, x0
   27f64:	b	28008 <__gmpn_mul_fft@@Base+0x2b8>
   27f68:	adrp	x9, 53000 <__gmpn_bases@@Base+0x1938>
   27f6c:	add	x9, x9, #0xf60
   27f70:	mov	w10, #0x1d8                 	// #472
   27f74:	umaddl	x9, w21, w10, x9
   27f78:	ldr	w10, [x9], #4
   27f7c:	mov	w11, #0x1                   	// #1
   27f80:	mov	x12, x9
   27f84:	mov	w14, w10
   27f88:	lsr	w13, w14, #27
   27f8c:	ldr	w14, [x12], #4
   27f90:	and	x15, x14, #0x7ffffff
   27f94:	lsl	x15, x15, x13
   27f98:	cmp	x15, x27
   27f9c:	b.lt	27f88 <__gmpn_mul_fft@@Base+0x238>  // b.tstop
   27fa0:	lsl	x12, x11, x13
   27fa4:	sub	x13, x12, #0x1
   27fa8:	tst	x13, x27
   27fac:	b.eq	27ea0 <__gmpn_mul_fft@@Base+0x150>  // b.none
   27fb0:	add	x13, x13, x27
   27fb4:	neg	x12, x12
   27fb8:	and	x27, x13, x12
   27fbc:	lsl	x23, x27, #6
   27fc0:	b	27f80 <__gmpn_mul_fft@@Base+0x230>
   27fc4:	sub	x0, x29, #0x8
   27fc8:	mov	x1, x20
   27fcc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27fd0:	mov	x20, x0
   27fd4:	sub	x0, x29, #0x8
   27fd8:	mov	x1, x26
   27fdc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   27fe0:	ldp	x4, x5, [sp, #32]
   27fe4:	mov	x26, x0
   27fe8:	mov	x0, x20
   27fec:	mov	x1, x26
   27ff0:	mov	x2, x25
   27ff4:	mov	x3, x27
   27ff8:	mov	x6, x28
   27ffc:	mov	x7, x23
   28000:	str	x21, [sp]
   28004:	bl	28110 <__gmpn_mul_fft@@Base+0x3c0>
   28008:	ldur	w8, [x29, #-12]
   2800c:	ldp	x0, x1, [x29, #-32]
   28010:	mov	w2, w19
   28014:	mov	x3, x24
   28018:	mov	x4, x26
   2801c:	mov	x5, x20
   28020:	mov	x6, x27
   28024:	mov	x7, x28
   28028:	str	w8, [sp, #24]
   2802c:	stp	x22, x21, [sp, #8]
   28030:	str	x23, [sp]
   28034:	bl	284d0 <__gmpn_mul_fft@@Base+0x780>
   28038:	ldur	x8, [x29, #-8]
   2803c:	mov	x19, x0
   28040:	cbnz	x8, 28068 <__gmpn_mul_fft@@Base+0x318>
   28044:	mov	x0, x19
   28048:	ldp	x20, x19, [sp, #176]
   2804c:	ldp	x22, x21, [sp, #160]
   28050:	ldp	x24, x23, [sp, #144]
   28054:	ldp	x26, x25, [sp, #128]
   28058:	ldp	x28, x27, [sp, #112]
   2805c:	ldp	x29, x30, [sp, #96]
   28060:	add	sp, sp, #0xc0
   28064:	ret
   28068:	mov	x0, x8
   2806c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   28070:	b	28044 <__gmpn_mul_fft@@Base+0x2f4>
   28074:	adrp	x0, 53000 <__gmpn_bases@@Base+0x1938>
   28078:	adrp	x2, 53000 <__gmpn_bases@@Base+0x1938>
   2807c:	add	x0, x0, #0xefe
   28080:	add	x2, x2, #0xf08
   28084:	mov	w1, #0x365                 	// #869
   28088:	bl	c6e0 <__gmp_assert_fail@plt>
   2808c:	adrp	x0, 53000 <__gmpn_bases@@Base+0x1938>
   28090:	adrp	x2, 53000 <__gmpn_bases@@Base+0x1938>
   28094:	add	x0, x0, #0xefe
   28098:	add	x2, x2, #0xf2b
   2809c:	mov	w1, #0x38b                 	// #907
   280a0:	bl	c6e0 <__gmp_assert_fail@plt>
   280a4:	ldr	x8, [x0]
   280a8:	cmp	w1, #0x1
   280ac:	str	wzr, [x8]
   280b0:	b.lt	2810c <__gmpn_mul_fft@@Base+0x3bc>  // b.tstop
   280b4:	add	w8, w1, #0x1
   280b8:	mov	w9, #0x1                   	// #1
   280bc:	mov	w10, #0x1                   	// #1
   280c0:	cbz	w10, 280fc <__gmpn_mul_fft@@Base+0x3ac>
   280c4:	add	x12, x0, x9, lsl #3
   280c8:	ldr	x11, [x0, x9, lsl #3]
   280cc:	ldur	x12, [x12, #-8]
   280d0:	sxtw	x13, w10
   280d4:	mov	w14, w10
   280d8:	ldr	w15, [x12], #4
   280dc:	mov	w16, #0x1                   	// #1
   280e0:	subs	x14, x14, #0x1
   280e4:	lsl	w17, w15, #1
   280e8:	bfi	w16, w15, #1, #31
   280ec:	str	w17, [x11]
   280f0:	str	w16, [x11, x13, lsl #2]
   280f4:	add	x11, x11, #0x4
   280f8:	b.ne	280d8 <__gmpn_mul_fft@@Base+0x388>  // b.any
   280fc:	add	x9, x9, #0x1
   28100:	cmp	x9, x8
   28104:	lsl	w10, w10, #1
   28108:	b.ne	280c0 <__gmpn_mul_fft@@Base+0x370>  // b.any
   2810c:	ret
   28110:	sub	sp, sp, #0x90
   28114:	stp	x26, x25, [sp, #80]
   28118:	mul	x26, x6, x2
   2811c:	stp	x29, x30, [sp, #48]
   28120:	stp	x28, x27, [sp, #64]
   28124:	stp	x20, x19, [sp, #128]
   28128:	add	x29, sp, #0x30
   2812c:	mov	x19, x5
   28130:	mov	x28, x4
   28134:	mov	x25, x0
   28138:	cmp	x26, x5
   2813c:	stp	x24, x23, [sp, #96]
   28140:	stp	x22, x21, [sp, #112]
   28144:	stp	x1, x7, [sp, #8]
   28148:	str	x3, [sp]
   2814c:	stp	x6, xzr, [x29, #-16]
   28150:	str	x2, [sp, #24]
   28154:	b.ge	28380 <__gmpn_mul_fft@@Base+0x630>  // b.tcont
   28158:	sub	x22, x19, x26
   2815c:	add	x19, x26, #0x1
   28160:	lsl	x1, x19, #3
   28164:	sub	x0, x29, #0x8
   28168:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2816c:	mov	x27, x0
   28170:	subs	x20, x22, x26
   28174:	add	x2, x28, x26, lsl #3
   28178:	b.le	28280 <__gmpn_mul_fft@@Base+0x530>
   2817c:	mov	x0, x27
   28180:	mov	x1, x28
   28184:	mov	x3, x26
   28188:	bl	c2e0 <__gmpn_sub_n@plt>
   2818c:	mov	x22, x0
   28190:	cmp	x20, x26
   28194:	add	x28, x28, x26, lsl #4
   28198:	b.le	282bc <__gmpn_mul_fft@@Base+0x56c>
   2819c:	mov	w8, wzr
   281a0:	mov	w21, wzr
   281a4:	lsl	x23, x26, #3
   281a8:	mov	x0, x27
   281ac:	mov	x1, x27
   281b0:	mov	x2, x28
   281b4:	mov	x3, x26
   281b8:	tbz	w8, #0, 281c8 <__gmpn_mul_fft@@Base+0x478>
   281bc:	bl	c2e0 <__gmpn_sub_n@plt>
   281c0:	add	x22, x0, x22
   281c4:	b	281d0 <__gmpn_mul_fft@@Base+0x480>
   281c8:	bl	ca90 <__gmpn_add_n@plt>
   281cc:	sub	x22, x22, x0
   281d0:	eor	w21, w21, #0x1
   281d4:	sub	x20, x20, x26
   281d8:	cmp	w21, #0x0
   281dc:	cset	w8, ne  // ne = any
   281e0:	cmp	x20, x26
   281e4:	add	x28, x28, x23
   281e8:	b.gt	281a8 <__gmpn_mul_fft@@Base+0x458>
   281ec:	cbz	w21, 282bc <__gmpn_mul_fft@@Base+0x56c>
   281f0:	cbz	x20, 28230 <__gmpn_mul_fft@@Base+0x4e0>
   281f4:	mov	x0, x27
   281f8:	mov	x1, x27
   281fc:	mov	x2, x28
   28200:	mov	x3, x20
   28204:	bl	c2e0 <__gmpn_sub_n@plt>
   28208:	cbz	x0, 28230 <__gmpn_mul_fft@@Base+0x4e0>
   2820c:	mov	w8, #0x1                   	// #1
   28210:	cmp	x20, x26
   28214:	b.ge	28234 <__gmpn_mul_fft@@Base+0x4e4>  // b.tcont
   28218:	ldr	x9, [x27, x20, lsl #3]
   2821c:	add	x11, x20, #0x1
   28220:	sub	x10, x9, #0x1
   28224:	str	x10, [x27, x20, lsl #3]
   28228:	mov	x20, x11
   2822c:	cbz	x9, 28210 <__gmpn_mul_fft@@Base+0x4c0>
   28230:	mov	x8, xzr
   28234:	add	x9, x8, x22
   28238:	tbz	x9, #63, 28308 <__gmpn_mul_fft@@Base+0x5b8>
   2823c:	ldr	x10, [x27]
   28240:	neg	x11, x9
   28244:	mov	x8, xzr
   28248:	add	x9, x10, x9
   2824c:	cmp	x10, x11
   28250:	str	x9, [x27]
   28254:	b.cs	28378 <__gmpn_mul_fft@@Base+0x628>  // b.hs, b.nlast
   28258:	mov	w8, #0x1                   	// #1
   2825c:	mov	w9, #0x1                   	// #1
   28260:	cmp	x9, x26
   28264:	b.ge	28378 <__gmpn_mul_fft@@Base+0x628>  // b.tcont
   28268:	ldr	x10, [x27, x9, lsl #3]
   2826c:	sub	x11, x10, #0x1
   28270:	str	x11, [x27, x9, lsl #3]
   28274:	add	x9, x9, #0x1
   28278:	cbz	x10, 28260 <__gmpn_mul_fft@@Base+0x510>
   2827c:	b	28374 <__gmpn_mul_fft@@Base+0x624>
   28280:	cbz	x22, 28340 <__gmpn_mul_fft@@Base+0x5f0>
   28284:	mov	x0, x27
   28288:	mov	x1, x28
   2828c:	mov	x3, x22
   28290:	bl	c2e0 <__gmpn_sub_n@plt>
   28294:	cbz	x0, 28348 <__gmpn_mul_fft@@Base+0x5f8>
   28298:	cmp	x22, x26
   2829c:	b.ge	28470 <__gmpn_mul_fft@@Base+0x720>  // b.tcont
   282a0:	ldr	x8, [x28, x22, lsl #3]
   282a4:	add	x9, x22, #0x1
   282a8:	sub	x10, x8, #0x1
   282ac:	str	x10, [x27, x22, lsl #3]
   282b0:	mov	x22, x9
   282b4:	cbz	x8, 28298 <__gmpn_mul_fft@@Base+0x548>
   282b8:	b	2834c <__gmpn_mul_fft@@Base+0x5fc>
   282bc:	cbz	x20, 282fc <__gmpn_mul_fft@@Base+0x5ac>
   282c0:	mov	x0, x27
   282c4:	mov	x1, x27
   282c8:	mov	x2, x28
   282cc:	mov	x3, x20
   282d0:	bl	ca90 <__gmpn_add_n@plt>
   282d4:	cbz	x0, 282fc <__gmpn_mul_fft@@Base+0x5ac>
   282d8:	mov	w8, #0x1                   	// #1
   282dc:	cmp	x20, x26
   282e0:	b.ge	28300 <__gmpn_mul_fft@@Base+0x5b0>  // b.tcont
   282e4:	ldr	x9, [x27, x20, lsl #3]
   282e8:	add	x10, x20, #0x1
   282ec:	adds	x9, x9, #0x1
   282f0:	str	x9, [x27, x20, lsl #3]
   282f4:	mov	x20, x10
   282f8:	b.cs	282dc <__gmpn_mul_fft@@Base+0x58c>  // b.hs, b.nlast
   282fc:	mov	x8, xzr
   28300:	sub	x9, x22, x8
   28304:	tbnz	x9, #63, 2823c <__gmpn_mul_fft@@Base+0x4ec>
   28308:	ldr	x8, [x27]
   2830c:	adds	x8, x8, x9
   28310:	str	x8, [x27]
   28314:	b.cc	28374 <__gmpn_mul_fft@@Base+0x624>  // b.lo, b.ul, b.last
   28318:	mov	w8, #0x1                   	// #1
   2831c:	mov	w9, #0x1                   	// #1
   28320:	cmp	x9, x26
   28324:	b.ge	28378 <__gmpn_mul_fft@@Base+0x628>  // b.tcont
   28328:	ldr	x10, [x27, x9, lsl #3]
   2832c:	adds	x10, x10, #0x1
   28330:	str	x10, [x27, x9, lsl #3]
   28334:	add	x9, x9, #0x1
   28338:	b.cs	28320 <__gmpn_mul_fft@@Base+0x5d0>  // b.hs, b.nlast
   2833c:	b	28374 <__gmpn_mul_fft@@Base+0x624>
   28340:	mov	x9, xzr
   28344:	b	2834c <__gmpn_mul_fft@@Base+0x5fc>
   28348:	mov	x9, x22
   2834c:	cmp	x27, x28
   28350:	mov	x8, xzr
   28354:	b.eq	28378 <__gmpn_mul_fft@@Base+0x628>  // b.none
   28358:	cmp	x9, x26
   2835c:	b.ge	28378 <__gmpn_mul_fft@@Base+0x628>  // b.tcont
   28360:	lsl	x8, x26, #3
   28364:	add	x0, x27, x9, lsl #3
   28368:	add	x1, x28, x9, lsl #3
   2836c:	sub	x2, x8, x9, lsl #3
   28370:	bl	bee0 <memcpy@plt>
   28374:	mov	x8, xzr
   28378:	mov	x28, x27
   2837c:	str	x8, [x27, x26, lsl #3]
   28380:	ldr	x8, [sp, #24]
   28384:	subs	x24, x8, #0x1
   28388:	b.lt	28444 <__gmpn_mul_fft@@Base+0x6f4>  // b.tstop
   2838c:	ldr	x8, [sp]
   28390:	ldr	x22, [x29, #96]
   28394:	mov	x20, xzr
   28398:	mov	x23, xzr
   2839c:	add	x21, x8, #0x1
   283a0:	lsl	x8, x8, #3
   283a4:	add	x26, x8, #0x8
   283a8:	ldr	x8, [sp, #8]
   283ac:	cmp	x19, #0x1
   283b0:	str	x25, [x8, x23, lsl #3]
   283b4:	b.lt	28414 <__gmpn_mul_fft@@Base+0x6c4>  // b.tstop
   283b8:	ldur	x8, [x29, #-16]
   283bc:	mov	x0, x22
   283c0:	mov	x1, x28
   283c4:	cmp	x19, x8
   283c8:	ccmp	x23, x24, #0x0, ge  // ge = tcont
   283cc:	csel	x27, x8, x19, lt  // lt = tstop
   283d0:	mov	x2, x27
   283d4:	sub	x19, x19, x27
   283d8:	bl	ca70 <__gmpn_copyi@plt>
   283dc:	subs	x8, x21, x27
   283e0:	b.eq	283f4 <__gmpn_mul_fft@@Base+0x6a4>  // b.none
   283e4:	add	x0, x22, x27, lsl #3
   283e8:	lsl	x2, x8, #3
   283ec:	mov	w1, wzr
   283f0:	bl	c610 <memset@plt>
   283f4:	ldur	x8, [x29, #-16]
   283f8:	ldr	x3, [sp]
   283fc:	mov	x0, x25
   28400:	mov	x1, x22
   28404:	mov	x2, x20
   28408:	add	x28, x28, x8, lsl #3
   2840c:	bl	291b4 <__gmpn_mul_fft@@Base+0x1464>
   28410:	b	28428 <__gmpn_mul_fft@@Base+0x6d8>
   28414:	cbz	x21, 28428 <__gmpn_mul_fft@@Base+0x6d8>
   28418:	mov	x0, x25
   2841c:	mov	w1, wzr
   28420:	mov	x2, x26
   28424:	bl	c610 <memset@plt>
   28428:	ldr	x8, [sp, #24]
   2842c:	add	x23, x23, #0x1
   28430:	add	x25, x25, x26
   28434:	cmp	x8, x23
   28438:	ldr	x8, [sp, #16]
   2843c:	add	x20, x20, x8
   28440:	b.ne	283a8 <__gmpn_mul_fft@@Base+0x658>  // b.any
   28444:	cbnz	x19, 284b8 <__gmpn_mul_fft@@Base+0x768>
   28448:	ldur	x0, [x29, #-8]
   2844c:	cbnz	x0, 284b0 <__gmpn_mul_fft@@Base+0x760>
   28450:	ldp	x20, x19, [sp, #128]
   28454:	ldp	x22, x21, [sp, #112]
   28458:	ldp	x24, x23, [sp, #96]
   2845c:	ldp	x26, x25, [sp, #80]
   28460:	ldp	x28, x27, [sp, #64]
   28464:	ldp	x29, x30, [sp, #48]
   28468:	add	sp, sp, #0x90
   2846c:	ret
   28470:	ldr	x8, [x27]
   28474:	adds	x8, x8, #0x1
   28478:	str	x8, [x27]
   2847c:	b.cc	28374 <__gmpn_mul_fft@@Base+0x624>  // b.lo, b.ul, b.last
   28480:	mov	w9, #0x1                   	// #1
   28484:	cmp	x9, x26
   28488:	b.ge	284a8 <__gmpn_mul_fft@@Base+0x758>  // b.tcont
   2848c:	ldr	x10, [x27, x9, lsl #3]
   28490:	mov	x8, xzr
   28494:	adds	x10, x10, #0x1
   28498:	str	x10, [x27, x9, lsl #3]
   2849c:	add	x9, x9, #0x1
   284a0:	b.cs	28484 <__gmpn_mul_fft@@Base+0x734>  // b.hs, b.nlast
   284a4:	b	28378 <__gmpn_mul_fft@@Base+0x628>
   284a8:	mov	w8, #0x1                   	// #1
   284ac:	b	28378 <__gmpn_mul_fft@@Base+0x628>
   284b0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   284b4:	b	28450 <__gmpn_mul_fft@@Base+0x700>
   284b8:	adrp	x0, 53000 <__gmpn_bases@@Base+0x1938>
   284bc:	adrp	x2, 53000 <__gmpn_bases@@Base+0x1938>
   284c0:	add	x0, x0, #0xefe
   284c4:	add	x2, x2, #0xf37
   284c8:	mov	w1, #0x2e7                 	// #743
   284cc:	bl	c6e0 <__gmp_assert_fail@plt>
   284d0:	sub	sp, sp, #0x160
   284d4:	stp	x29, x30, [sp, #256]
   284d8:	add	x29, sp, #0x100
   284dc:	ldp	x10, x8, [x29, #96]
   284e0:	stp	x26, x25, [sp, #288]
   284e4:	ldr	x25, [x29, #112]
   284e8:	stp	x20, x19, [sp, #336]
   284ec:	mov	w26, w2
   284f0:	ldr	w20, [x29, #120]
   284f4:	mov	w9, #0x1                   	// #1
   284f8:	stp	x28, x27, [sp, #272]
   284fc:	stp	x24, x23, [sp, #304]
   28500:	lsl	x24, x9, x26
   28504:	add	x19, x8, w2, sxtw #3
   28508:	lsl	x27, x10, #1
   2850c:	stp	x22, x21, [sp, #320]
   28510:	stp	x7, x5, [x29, #-56]
   28514:	mov	x22, x6
   28518:	mov	x21, x4
   2851c:	mov	x28, x3
   28520:	mov	x23, x1
   28524:	str	x0, [sp, #56]
   28528:	mov	w5, #0x1                   	// #1
   2852c:	mov	x0, x3
   28530:	mov	x1, x24
   28534:	mov	x2, x19
   28538:	mov	x3, x27
   2853c:	mov	x4, x6
   28540:	mov	x6, x25
   28544:	stur	x10, [x29, #-80]
   28548:	bl	29470 <__gmpn_mul_fft@@Base+0x1720>
   2854c:	cbnz	w20, 28570 <__gmpn_mul_fft@@Base+0x820>
   28550:	mov	w5, #0x1                   	// #1
   28554:	mov	x0, x21
   28558:	mov	x1, x24
   2855c:	mov	x2, x19
   28560:	mov	x3, x27
   28564:	mov	x4, x22
   28568:	mov	x6, x25
   2856c:	bl	29470 <__gmpn_mul_fft@@Base+0x1720>
   28570:	cmp	w20, #0x0
   28574:	csel	x15, x28, x21, ne  // ne = any
   28578:	cmp	x15, x28
   2857c:	mov	w8, #0x13c                 	// #316
   28580:	mov	w9, #0x110                 	// #272
   28584:	cset	w10, eq  // eq = none
   28588:	stur	w10, [x29, #-104]
   2858c:	csel	x10, x9, x8, eq  // eq = none
   28590:	cmp	x10, x22
   28594:	str	x27, [sp, #48]
   28598:	stur	x21, [x29, #-64]
   2859c:	stur	x22, [x29, #-32]
   285a0:	str	x23, [sp, #64]
   285a4:	stp	x24, xzr, [x29, #-24]
   285a8:	str	x26, [sp, #72]
   285ac:	stur	x28, [x29, #-40]
   285b0:	stur	x15, [x29, #-72]
   285b4:	str	x25, [sp, #40]
   285b8:	b.le	2871c <__gmpn_mul_fft@@Base+0x9cc>
   285bc:	lsl	x1, x22, #4
   285c0:	sub	x0, x29, #0x10
   285c4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   285c8:	cmp	w26, #0x3f
   285cc:	b.eq	28a58 <__gmpn_mul_fft@@Base+0xd08>  // b.none
   285d0:	ldur	x25, [x29, #-40]
   285d4:	ldur	x28, [x29, #-72]
   285d8:	mov	x19, x0
   285dc:	mov	x26, xzr
   285e0:	lsl	x27, x22, #1
   285e4:	add	x20, x0, x22, lsl #3
   285e8:	ldr	x21, [x25], #8
   285ec:	ldr	x23, [x28], #8
   285f0:	ldur	x8, [x29, #-40]
   285f4:	ldur	x9, [x29, #-72]
   285f8:	mov	x0, x19
   285fc:	cmp	x9, x8
   28600:	b.eq	2861c <__gmpn_mul_fft@@Base+0x8cc>  // b.none
   28604:	ldur	x22, [x29, #-32]
   28608:	mov	x1, x23
   2860c:	mov	x2, x21
   28610:	mov	x3, x22
   28614:	bl	c9b0 <__gmpn_mul_n@plt>
   28618:	b	2862c <__gmpn_mul_fft@@Base+0x8dc>
   2861c:	ldur	x22, [x29, #-32]
   28620:	mov	x1, x21
   28624:	mov	x2, x22
   28628:	bl	c900 <__gmpn_sqr@plt>
   2862c:	ldr	x8, [x21, x22, lsl #3]
   28630:	cbz	x8, 28650 <__gmpn_mul_fft@@Base+0x900>
   28634:	mov	x0, x20
   28638:	mov	x1, x20
   2863c:	mov	x2, x23
   28640:	mov	x3, x22
   28644:	bl	ca90 <__gmpn_add_n@plt>
   28648:	mov	x24, x0
   2864c:	b	28654 <__gmpn_mul_fft@@Base+0x904>
   28650:	mov	x24, xzr
   28654:	ldr	x8, [x23, x22, lsl #3]
   28658:	cbz	x8, 2867c <__gmpn_mul_fft@@Base+0x92c>
   2865c:	mov	x0, x20
   28660:	mov	x1, x20
   28664:	mov	x2, x21
   28668:	mov	x3, x22
   2866c:	bl	ca90 <__gmpn_add_n@plt>
   28670:	ldr	x8, [x21, x22, lsl #3]
   28674:	add	x9, x0, x24
   28678:	add	x24, x9, x8
   2867c:	cbz	x24, 286b0 <__gmpn_mul_fft@@Base+0x960>
   28680:	ldr	x8, [x19]
   28684:	adds	x8, x8, x24
   28688:	str	x8, [x19]
   2868c:	b.cc	286b0 <__gmpn_mul_fft@@Base+0x960>  // b.lo, b.ul, b.last
   28690:	mov	w8, #0x1                   	// #1
   28694:	cmp	x8, x27
   28698:	b.ge	286b0 <__gmpn_mul_fft@@Base+0x960>  // b.tcont
   2869c:	ldr	x9, [x19, x8, lsl #3]
   286a0:	adds	x9, x9, #0x1
   286a4:	str	x9, [x19, x8, lsl #3]
   286a8:	add	x8, x8, #0x1
   286ac:	b.cs	28694 <__gmpn_mul_fft@@Base+0x944>  // b.hs, b.nlast
   286b0:	mov	x0, x21
   286b4:	mov	x1, x19
   286b8:	mov	x2, x20
   286bc:	mov	x3, x22
   286c0:	bl	c2e0 <__gmpn_sub_n@plt>
   286c4:	cbz	x0, 286f8 <__gmpn_mul_fft@@Base+0x9a8>
   286c8:	ldr	x8, [x21]
   286cc:	adds	x8, x8, #0x1
   286d0:	str	x8, [x21]
   286d4:	b.cc	286f8 <__gmpn_mul_fft@@Base+0x9a8>  // b.lo, b.ul, b.last
   286d8:	mov	w8, #0x1                   	// #1
   286dc:	cmp	x8, x22
   286e0:	b.ge	28714 <__gmpn_mul_fft@@Base+0x9c4>  // b.tcont
   286e4:	ldr	x9, [x21, x8, lsl #3]
   286e8:	adds	x9, x9, #0x1
   286ec:	str	x9, [x21, x8, lsl #3]
   286f0:	add	x8, x8, #0x1
   286f4:	b.cs	286dc <__gmpn_mul_fft@@Base+0x98c>  // b.hs, b.nlast
   286f8:	mov	x8, xzr
   286fc:	ldur	x9, [x29, #-24]
   28700:	add	x26, x26, #0x1
   28704:	str	x8, [x21, x22, lsl #3]
   28708:	cmp	x9, x26
   2870c:	b.gt	285e8 <__gmpn_mul_fft@@Base+0x898>
   28710:	b	28a58 <__gmpn_mul_fft@@Base+0xd08>
   28714:	mov	w8, #0x1                   	// #1
   28718:	b	286fc <__gmpn_mul_fft@@Base+0x9ac>
   2871c:	cmp	x15, x28
   28720:	adrp	x8, 53000 <__gmpn_bases@@Base+0x1938>
   28724:	add	x8, x8, #0xf60
   28728:	cset	w9, eq  // eq = none
   2872c:	mov	w11, #0x1d8                 	// #472
   28730:	umaddl	x8, w9, w11, x8
   28734:	ldr	w9, [x8], #4
   28738:	mov	x14, x22
   2873c:	mov	x11, x8
   28740:	mov	w12, w9
   28744:	lsr	w22, w12, #27
   28748:	ldr	w12, [x11], #4
   2874c:	and	x13, x12, #0x7ffffff
   28750:	lsl	x13, x13, x22
   28754:	cmp	x13, x14
   28758:	b.lt	28744 <__gmpn_mul_fft@@Base+0x9f4>  // b.tstop
   2875c:	mov	w11, #0x1                   	// #1
   28760:	lsl	x16, x11, x22
   28764:	sub	x11, x16, #0x1
   28768:	tst	x11, x14
   2876c:	b.ne	29184 <__gmpn_mul_fft@@Base+0x1434>  // b.any
   28770:	lsl	x12, x14, #6
   28774:	cmp	x16, #0x40
   28778:	mov	w11, #0x40                  	// #64
   2877c:	add	w13, w22, #0x2
   28780:	asr	x12, x12, x22
   28784:	csel	x11, x16, x11, gt
   28788:	add	x12, x13, x12, lsl #1
   2878c:	add	x12, x12, x11
   28790:	sdiv	x12, x12, x11
   28794:	mul	x21, x12, x11
   28798:	add	x11, x21, #0x3f
   2879c:	cmp	x21, #0x0
   287a0:	csel	x11, x11, x21, lt  // lt = tstop
   287a4:	asr	x19, x11, #6
   287a8:	cmp	x19, x10
   287ac:	b.ge	28ae8 <__gmpn_mul_fft@@Base+0xd98>  // b.tcont
   287b0:	ldur	x8, [x29, #-32]
   287b4:	cmp	x19, x8
   287b8:	b.ge	2919c <__gmpn_mul_fft@@Base+0x144c>  // b.tcont
   287bc:	lsl	x20, x16, #3
   287c0:	sub	x0, x29, #0x10
   287c4:	mov	x1, x20
   287c8:	asr	x23, x8, x22
   287cc:	stur	x16, [x29, #-120]
   287d0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   287d4:	stur	x0, [x29, #-88]
   287d8:	sub	x0, x29, #0x10
   287dc:	mov	x1, x20
   287e0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   287e4:	add	x20, x19, #0x1
   287e8:	lsl	x8, x20, #1
   287ec:	lsl	x8, x8, x22
   287f0:	stur	x0, [x29, #-96]
   287f4:	lsl	x1, x8, #3
   287f8:	sub	x0, x29, #0x10
   287fc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   28800:	stur	x0, [x29, #-112]
   28804:	lsl	x1, x20, #4
   28808:	sub	x0, x29, #0x10
   2880c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   28810:	lsl	w8, w22, #3
   28814:	str	x0, [sp, #128]
   28818:	add	w1, w8, #0x8
   2881c:	sub	x0, x29, #0x10
   28820:	lsl	x20, x20, x22
   28824:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   28828:	mov	w8, #0x8                   	// #8
   2882c:	mov	x28, x0
   28830:	lsl	x1, x8, x22
   28834:	sub	x0, x29, #0x10
   28838:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2883c:	mov	x8, xzr
   28840:	add	w9, w22, #0x1
   28844:	mov	w10, #0x1                   	// #1
   28848:	str	x0, [x28, x8, lsl #3]
   2884c:	lsl	x11, x10, x8
   28850:	add	x8, x8, #0x1
   28854:	cmp	x9, x8
   28858:	add	x0, x0, x11, lsl #2
   2885c:	b.ne	28848 <__gmpn_mul_fft@@Base+0xaf8>  // b.any
   28860:	mov	x0, x28
   28864:	mov	w1, w22
   28868:	bl	280a4 <__gmpn_mul_fft@@Base+0x354>
   2886c:	ldur	x27, [x29, #-32]
   28870:	cmp	w26, #0x3f
   28874:	b.eq	28a58 <__gmpn_mul_fft@@Base+0xd08>  // b.none
   28878:	asr	x8, x21, x22
   2887c:	str	x8, [sp, #104]
   28880:	ldur	x8, [x29, #-112]
   28884:	ldur	x21, [x29, #-40]
   28888:	mov	x26, xzr
   2888c:	stp	x28, x23, [sp, #112]
   28890:	add	x25, x8, x20, lsl #3
   28894:	ldur	x20, [x29, #-72]
   28898:	lsl	x8, x27, #3
   2889c:	str	x8, [sp, #80]
   288a0:	lsl	x8, x23, x22
   288a4:	add	x8, x8, #0x1
   288a8:	str	x8, [sp, #96]
   288ac:	str	x22, [sp, #88]
   288b0:	ldr	x23, [x21]
   288b4:	ldur	x24, [x29, #-96]
   288b8:	ldr	x8, [x23, x27, lsl #3]
   288bc:	cbz	x8, 2890c <__gmpn_mul_fft@@Base+0xbbc>
   288c0:	mov	x8, x23
   288c4:	ldr	x9, [x8]
   288c8:	sub	x10, x9, #0x1
   288cc:	str	x10, [x8], #8
   288d0:	cbz	x9, 288c4 <__gmpn_mul_fft@@Base+0xb74>
   288d4:	ldur	x10, [x29, #-32]
   288d8:	ldr	x9, [x23, x10, lsl #3]
   288dc:	cmp	x9, #0x0
   288e0:	cset	w8, eq  // eq = none
   288e4:	cbnz	x9, 28904 <__gmpn_mul_fft@@Base+0xbb4>
   288e8:	cbz	x10, 28904 <__gmpn_mul_fft@@Base+0xbb4>
   288ec:	ldr	x2, [sp, #80]
   288f0:	mov	x0, x23
   288f4:	mov	w1, wzr
   288f8:	bl	c610 <memset@plt>
   288fc:	ldur	x24, [x29, #-96]
   28900:	mov	w8, #0x1                   	// #1
   28904:	ldur	x9, [x29, #-32]
   28908:	str	x8, [x23, x9, lsl #3]
   2890c:	ldur	x8, [x29, #-40]
   28910:	ldur	x9, [x29, #-72]
   28914:	cmp	x9, x8
   28918:	b.eq	289d8 <__gmpn_mul_fft@@Base+0xc88>  // b.none
   2891c:	ldr	x23, [x20]
   28920:	ldur	x22, [x29, #-32]
   28924:	ldr	x28, [sp, #128]
   28928:	ldr	x27, [sp, #104]
   2892c:	ldr	x8, [x23, x22, lsl #3]
   28930:	cbz	x8, 28974 <__gmpn_mul_fft@@Base+0xc24>
   28934:	mov	x8, x23
   28938:	ldr	x9, [x8]
   2893c:	sub	x10, x9, #0x1
   28940:	str	x10, [x8], #8
   28944:	cbz	x9, 28938 <__gmpn_mul_fft@@Base+0xbe8>
   28948:	ldr	x9, [x23, x22, lsl #3]
   2894c:	cmp	x9, #0x0
   28950:	cset	w8, eq  // eq = none
   28954:	cbnz	x9, 28970 <__gmpn_mul_fft@@Base+0xc20>
   28958:	cbz	x22, 28970 <__gmpn_mul_fft@@Base+0xc20>
   2895c:	ldr	x2, [sp, #80]
   28960:	mov	x0, x23
   28964:	mov	w1, wzr
   28968:	bl	c610 <memset@plt>
   2896c:	mov	w8, #0x1                   	// #1
   28970:	str	x8, [x23, x22, lsl #3]
   28974:	ldp	x24, x0, [x29, #-120]
   28978:	ldr	x22, [sp, #96]
   2897c:	ldr	x23, [sp, #120]
   28980:	ldr	x4, [x21]
   28984:	ldur	x1, [x29, #-88]
   28988:	mov	x2, x24
   2898c:	mov	x3, x19
   28990:	mov	x5, x22
   28994:	mov	x6, x23
   28998:	mov	x7, x27
   2899c:	str	x28, [sp]
   289a0:	bl	28110 <__gmpn_mul_fft@@Base+0x3c0>
   289a4:	ldr	x4, [x20]
   289a8:	ldur	x1, [x29, #-96]
   289ac:	mov	x0, x25
   289b0:	mov	x2, x24
   289b4:	mov	x3, x19
   289b8:	mov	x5, x22
   289bc:	mov	x6, x23
   289c0:	mov	x7, x27
   289c4:	str	x28, [sp]
   289c8:	mov	x24, x1
   289cc:	bl	28110 <__gmpn_mul_fft@@Base+0x3c0>
   289d0:	ldr	x22, [sp, #88]
   289d4:	b	28a00 <__gmpn_mul_fft@@Base+0xcb0>
   289d8:	ldp	x23, x28, [sp, #120]
   289dc:	ldp	x5, x27, [sp, #96]
   289e0:	ldr	x4, [x21]
   289e4:	ldp	x2, x0, [x29, #-120]
   289e8:	ldur	x1, [x29, #-88]
   289ec:	mov	x3, x19
   289f0:	mov	x6, x23
   289f4:	mov	x7, x27
   289f8:	str	x28, [sp]
   289fc:	bl	28110 <__gmpn_mul_fft@@Base+0x3c0>
   28a00:	ldr	x0, [x21]
   28a04:	str	x28, [sp, #16]
   28a08:	ldr	x28, [sp, #112]
   28a0c:	ldur	w8, [x29, #-104]
   28a10:	ldur	x3, [x29, #-88]
   28a14:	mov	w2, w22
   28a18:	stp	x27, x28, [sp]
   28a1c:	ldur	x27, [x29, #-32]
   28a20:	mov	x4, x24
   28a24:	mov	x5, x25
   28a28:	mov	x6, x19
   28a2c:	mov	x1, x27
   28a30:	mov	x7, x23
   28a34:	str	w8, [sp, #24]
   28a38:	bl	284d0 <__gmpn_mul_fft@@Base+0x780>
   28a3c:	ldr	x8, [x21], #8
   28a40:	ldur	x9, [x29, #-24]
   28a44:	add	x26, x26, #0x1
   28a48:	add	x20, x20, #0x8
   28a4c:	str	x0, [x8, x27, lsl #3]
   28a50:	cmp	x9, x26
   28a54:	b.gt	288b0 <__gmpn_mul_fft@@Base+0xb60>
   28a58:	ldr	x8, [sp, #72]
   28a5c:	ldur	x0, [x29, #-16]
   28a60:	sxtw	x19, w8
   28a64:	cbnz	x0, 2917c <__gmpn_mul_fft@@Base+0x142c>
   28a68:	ldp	x21, x22, [x29, #-40]
   28a6c:	ldur	x26, [x29, #-24]
   28a70:	ldp	x25, x2, [sp, #40]
   28a74:	mov	x0, x21
   28a78:	mov	x1, x26
   28a7c:	mov	x3, x22
   28a80:	mov	x4, x25
   28a84:	bl	2970c <__gmpn_mul_fft@@Base+0x19bc>
   28a88:	ldur	x27, [x29, #-64]
   28a8c:	add	x8, x25, x22, lsl #3
   28a90:	add	x20, x8, #0x8
   28a94:	lsl	x8, x22, #7
   28a98:	str	x20, [x27]
   28a9c:	ldr	x1, [x21]
   28aa0:	sub	x19, x8, x19
   28aa4:	mov	x0, x20
   28aa8:	mov	x2, x19
   28aac:	mov	x3, x22
   28ab0:	mov	x28, x21
   28ab4:	bl	291b4 <__gmpn_mul_fft@@Base+0x1464>
   28ab8:	ldr	x8, [x20, x22, lsl #3]
   28abc:	ldr	x24, [sp, #64]
   28ac0:	cbz	x8, 28b4c <__gmpn_mul_fft@@Base+0xdfc>
   28ac4:	mov	x8, x20
   28ac8:	ldr	x9, [x8]
   28acc:	sub	x10, x9, #0x1
   28ad0:	str	x10, [x8], #8
   28ad4:	cbz	x9, 28ac8 <__gmpn_mul_fft@@Base+0xd78>
   28ad8:	ldr	x8, [x20, x22, lsl #3]
   28adc:	cbz	x8, 28b30 <__gmpn_mul_fft@@Base+0xde0>
   28ae0:	mov	x8, xzr
   28ae4:	b	28b48 <__gmpn_mul_fft@@Base+0xdf8>
   28ae8:	mov	w10, #0x1                   	// #1
   28aec:	mov	x11, x8
   28af0:	mov	w13, w9
   28af4:	lsr	w12, w13, #27
   28af8:	ldr	w13, [x11], #4
   28afc:	and	x14, x13, #0x7ffffff
   28b00:	lsl	x14, x14, x12
   28b04:	cmp	x14, x19
   28b08:	b.lt	28af4 <__gmpn_mul_fft@@Base+0xda4>  // b.tstop
   28b0c:	lsl	x11, x10, x12
   28b10:	sub	x12, x11, #0x1
   28b14:	tst	x12, x19
   28b18:	b.eq	287b0 <__gmpn_mul_fft@@Base+0xa60>  // b.none
   28b1c:	add	x12, x12, x19
   28b20:	neg	x11, x11
   28b24:	and	x19, x12, x11
   28b28:	lsl	x21, x19, #6
   28b2c:	b	28aec <__gmpn_mul_fft@@Base+0xd9c>
   28b30:	cbz	x22, 28b44 <__gmpn_mul_fft@@Base+0xdf4>
   28b34:	lsl	x2, x22, #3
   28b38:	mov	x0, x20
   28b3c:	mov	w1, wzr
   28b40:	bl	c610 <memset@plt>
   28b44:	mov	w8, #0x1                   	// #1
   28b48:	str	x8, [x20, x22, lsl #3]
   28b4c:	cmp	x26, #0x2
   28b50:	b.lt	28bd8 <__gmpn_mul_fft@@Base+0xe88>  // b.tstop
   28b54:	lsl	x20, x22, #3
   28b58:	mov	w23, #0x1                   	// #1
   28b5c:	add	x8, x28, x23, lsl #3
   28b60:	ldur	x21, [x8, #-8]
   28b64:	ldur	x9, [x29, #-80]
   28b68:	mov	x3, x22
   28b6c:	str	x21, [x27, x23, lsl #3]
   28b70:	ldr	x1, [x8]
   28b74:	sub	x8, x26, x23
   28b78:	msub	x2, x8, x9, x19
   28b7c:	mov	x0, x21
   28b80:	bl	291b4 <__gmpn_mul_fft@@Base+0x1464>
   28b84:	ldr	x8, [x21, x22, lsl #3]
   28b88:	cbz	x8, 28bcc <__gmpn_mul_fft@@Base+0xe7c>
   28b8c:	mov	x8, x21
   28b90:	ldr	x9, [x8]
   28b94:	sub	x10, x9, #0x1
   28b98:	str	x10, [x8], #8
   28b9c:	cbz	x9, 28b90 <__gmpn_mul_fft@@Base+0xe40>
   28ba0:	ldr	x9, [x21, x22, lsl #3]
   28ba4:	cmp	x9, #0x0
   28ba8:	cset	w8, eq  // eq = none
   28bac:	cbnz	x9, 28bc8 <__gmpn_mul_fft@@Base+0xe78>
   28bb0:	cbz	x22, 28bc8 <__gmpn_mul_fft@@Base+0xe78>
   28bb4:	mov	x0, x21
   28bb8:	mov	w1, wzr
   28bbc:	mov	x2, x20
   28bc0:	bl	c610 <memset@plt>
   28bc4:	mov	w8, #0x1                   	// #1
   28bc8:	str	x8, [x21, x22, lsl #3]
   28bcc:	add	x23, x23, #0x1
   28bd0:	cmp	x23, x26
   28bd4:	b.ne	28b5c <__gmpn_mul_fft@@Base+0xe0c>  // b.any
   28bd8:	adds	x8, x22, #0x1
   28bdc:	stur	x8, [x29, #-80]
   28be0:	b.cs	28bf8 <__gmpn_mul_fft@@Base+0xea8>  // b.hs, b.nlast
   28be4:	lsl	x8, x22, #3
   28be8:	add	x2, x8, #0x8
   28bec:	mov	x0, x25
   28bf0:	mov	w1, wzr
   28bf4:	bl	c610 <memset@plt>
   28bf8:	ldur	x8, [x29, #-56]
   28bfc:	sub	x9, x26, #0x1
   28c00:	stur	x9, [x29, #-72]
   28c04:	mul	x8, x9, x8
   28c08:	stur	x8, [x29, #-104]
   28c0c:	add	x8, x8, x22
   28c10:	adds	x20, x8, #0x1
   28c14:	stur	x8, [x29, #-120]
   28c18:	b.cs	28c2c <__gmpn_mul_fft@@Base+0xedc>  // b.hs, b.nlast
   28c1c:	ldur	x0, [x29, #-48]
   28c20:	lsl	x2, x20, #3
   28c24:	mov	w1, wzr
   28c28:	bl	c610 <memset@plt>
   28c2c:	ldr	x8, [sp, #72]
   28c30:	ldur	x14, [x29, #-48]
   28c34:	lsl	x13, x24, #1
   28c38:	cmp	w8, #0x3f
   28c3c:	b.eq	28f88 <__gmpn_mul_fft@@Base+0x1238>  // b.none
   28c40:	ldur	x9, [x29, #-56]
   28c44:	ldur	x24, [x29, #-104]
   28c48:	ldur	x28, [x29, #-72]
   28c4c:	ldur	x26, [x29, #-120]
   28c50:	lsl	x8, x9, #1
   28c54:	stur	x8, [x29, #-88]
   28c58:	add	x8, x22, x24
   28c5c:	add	x8, x14, x8, lsl #3
   28c60:	neg	x9, x9, lsl #3
   28c64:	add	x23, x14, x24, lsl #3
   28c68:	add	x21, x8, #0x10
   28c6c:	add	x19, x14, x20, lsl #3
   28c70:	str	x13, [sp, #128]
   28c74:	stur	xzr, [x29, #-40]
   28c78:	stur	x9, [x29, #-96]
   28c7c:	stur	x20, [x29, #-112]
   28c80:	ldur	x8, [x29, #-24]
   28c84:	ldp	x3, x10, [x29, #-80]
   28c88:	mov	x9, x27
   28c8c:	add	x20, x14, x24, lsl #3
   28c90:	sub	x8, x8, x28
   28c94:	and	x27, x8, x10
   28c98:	ldr	x2, [x9, x27, lsl #3]
   28c9c:	mov	x0, x20
   28ca0:	mov	x1, x20
   28ca4:	bl	ca90 <__gmpn_add_n@plt>
   28ca8:	cbz	x0, 28cf8 <__gmpn_mul_fft@@Base+0xfa8>
   28cac:	add	x8, x20, x22, lsl #3
   28cb0:	ldr	x9, [x8, #8]
   28cb4:	ldur	x14, [x29, #-48]
   28cb8:	adds	x9, x9, #0x1
   28cbc:	str	x9, [x8, #8]
   28cc0:	b.cc	28cf0 <__gmpn_mul_fft@@Base+0xfa0>  // b.lo, b.ul, b.last
   28cc4:	ldur	x8, [x29, #-104]
   28cc8:	mov	x9, xzr
   28ccc:	sub	x8, x8, x24
   28cd0:	add	x10, x9, #0x1
   28cd4:	cmp	x10, x8
   28cd8:	b.ge	28d00 <__gmpn_mul_fft@@Base+0xfb0>  // b.tcont
   28cdc:	ldr	x11, [x21, x9, lsl #3]
   28ce0:	adds	x11, x11, #0x1
   28ce4:	str	x11, [x21, x9, lsl #3]
   28ce8:	mov	x9, x10
   28cec:	b.cs	28cd0 <__gmpn_mul_fft@@Base+0xf80>  // b.hs, b.nlast
   28cf0:	mov	x8, xzr
   28cf4:	b	28d04 <__gmpn_mul_fft@@Base+0xfb4>
   28cf8:	ldur	x14, [x29, #-48]
   28cfc:	b	28d10 <__gmpn_mul_fft@@Base+0xfc0>
   28d00:	mov	w8, #0x1                   	// #1
   28d04:	ldur	x9, [x29, #-40]
   28d08:	add	x9, x8, x9
   28d0c:	stur	x9, [x29, #-40]
   28d10:	ldur	x9, [x29, #-88]
   28d14:	add	x8, x28, #0x1
   28d18:	str	x8, [x25, x9, lsl #3]
   28d1c:	ldur	x9, [x29, #-64]
   28d20:	ldr	x8, [x9, x27, lsl #3]
   28d24:	mov	x27, x9
   28d28:	mov	x9, x22
   28d2c:	add	x10, x9, #0x1
   28d30:	cmp	x10, #0x1
   28d34:	b.lt	28ddc <__gmpn_mul_fft@@Base+0x108c>  // b.tstop
   28d38:	ldr	x10, [x8, x9, lsl #3]
   28d3c:	ldr	x11, [x25, x9, lsl #3]
   28d40:	sub	x9, x9, #0x1
   28d44:	cmp	x10, x11
   28d48:	b.eq	28d2c <__gmpn_mul_fft@@Base+0xfdc>  // b.none
   28d4c:	b.ls	28ddc <__gmpn_mul_fft@@Base+0x108c>  // b.plast
   28d50:	ldr	x8, [x20]
   28d54:	sub	x9, x8, #0x1
   28d58:	str	x9, [x20]
   28d5c:	cbnz	x8, 28d88 <__gmpn_mul_fft@@Base+0x1038>
   28d60:	ldur	x8, [x29, #-112]
   28d64:	mov	w9, #0x1                   	// #1
   28d68:	sub	x8, x8, x24
   28d6c:	cmp	x9, x8
   28d70:	b.ge	28e08 <__gmpn_mul_fft@@Base+0x10b8>  // b.tcont
   28d74:	ldr	x10, [x23, x9, lsl #3]
   28d78:	sub	x11, x10, #0x1
   28d7c:	str	x11, [x23, x9, lsl #3]
   28d80:	add	x9, x9, #0x1
   28d84:	cbz	x10, 28d6c <__gmpn_mul_fft@@Base+0x101c>
   28d88:	mov	x8, xzr
   28d8c:	ldr	x9, [x14, x26, lsl #3]
   28d90:	ldur	x10, [x29, #-40]
   28d94:	add	x8, x8, x10
   28d98:	sub	x10, x9, #0x1
   28d9c:	str	x10, [x14, x26, lsl #3]
   28da0:	cbnz	x9, 28dd0 <__gmpn_mul_fft@@Base+0x1080>
   28da4:	ldur	x9, [x29, #-112]
   28da8:	mov	x10, xzr
   28dac:	sub	x9, x9, x26
   28db0:	add	x11, x10, #0x1
   28db4:	cmp	x11, x9
   28db8:	b.ge	28e10 <__gmpn_mul_fft@@Base+0x10c0>  // b.tcont
   28dbc:	ldr	x12, [x19, x10, lsl #3]
   28dc0:	sub	x13, x12, #0x1
   28dc4:	str	x13, [x19, x10, lsl #3]
   28dc8:	mov	x10, x11
   28dcc:	cbz	x12, 28db0 <__gmpn_mul_fft@@Base+0x1060>
   28dd0:	mov	x9, xzr
   28dd4:	add	x8, x8, x9
   28dd8:	stur	x8, [x29, #-40]
   28ddc:	ldur	x8, [x29, #-56]
   28de0:	cmp	x28, #0x0
   28de4:	sub	x28, x28, #0x1
   28de8:	sub	x26, x26, x8
   28dec:	sub	x24, x24, x8
   28df0:	ldur	x8, [x29, #-96]
   28df4:	add	x21, x21, x8
   28df8:	add	x23, x23, x8
   28dfc:	add	x19, x19, x8
   28e00:	b.gt	28c80 <__gmpn_mul_fft@@Base+0xf30>
   28e04:	b	28e18 <__gmpn_mul_fft@@Base+0x10c8>
   28e08:	mov	x8, #0xffffffffffffffff    	// #-1
   28e0c:	b	28d8c <__gmpn_mul_fft@@Base+0x103c>
   28e10:	mov	x9, #0xffffffffffffffff    	// #-1
   28e14:	b	28dd4 <__gmpn_mul_fft@@Base+0x1084>
   28e18:	ldur	x8, [x29, #-40]
   28e1c:	cmp	x8, #0x1
   28e20:	b.eq	28e8c <__gmpn_mul_fft@@Base+0x113c>  // b.none
   28e24:	ldr	x24, [sp, #64]
   28e28:	ldur	x20, [x29, #-112]
   28e2c:	ldr	x13, [sp, #128]
   28e30:	cmn	x8, #0x1
   28e34:	b.ne	28f88 <__gmpn_mul_fft@@Base+0x1238>  // b.any
   28e38:	add	x8, x14, x20, lsl #3
   28e3c:	sub	x8, x8, x24, lsl #3
   28e40:	ldr	x9, [x8]
   28e44:	adds	x9, x9, #0x1
   28e48:	str	x9, [x8]
   28e4c:	b.cc	28f88 <__gmpn_mul_fft@@Base+0x1238>  // b.lo, b.ul, b.last
   28e50:	ldur	x10, [x29, #-104]
   28e54:	mov	x9, xzr
   28e58:	add	x10, x22, x10
   28e5c:	sub	x10, x10, x24
   28e60:	add	x10, x14, x10, lsl #3
   28e64:	add	x10, x10, #0x10
   28e68:	add	x11, x9, #0x1
   28e6c:	cmp	x11, x24
   28e70:	b.ge	28f44 <__gmpn_mul_fft@@Base+0x11f4>  // b.tcont
   28e74:	ldr	x12, [x10, x9, lsl #3]
   28e78:	adds	x12, x12, #0x1
   28e7c:	str	x12, [x10, x9, lsl #3]
   28e80:	mov	x9, x11
   28e84:	b.cs	28e68 <__gmpn_mul_fft@@Base+0x1118>  // b.hs, b.nlast
   28e88:	b	28f88 <__gmpn_mul_fft@@Base+0x1238>
   28e8c:	ldr	x24, [sp, #64]
   28e90:	ldur	x20, [x29, #-112]
   28e94:	ldr	x13, [sp, #128]
   28e98:	cmp	x20, x24, lsl #1
   28e9c:	add	x8, x14, x20, lsl #3
   28ea0:	b.ge	28ef4 <__gmpn_mul_fft@@Base+0x11a4>  // b.tcont
   28ea4:	sub	x8, x8, x24, lsl #3
   28ea8:	ldr	x9, [x8]
   28eac:	sub	x10, x9, #0x1
   28eb0:	str	x10, [x8]
   28eb4:	cbnz	x9, 28f88 <__gmpn_mul_fft@@Base+0x1238>
   28eb8:	ldur	x9, [x29, #-104]
   28ebc:	mov	x8, xzr
   28ec0:	add	x9, x22, x9
   28ec4:	sub	x9, x9, x24
   28ec8:	add	x9, x14, x9, lsl #3
   28ecc:	add	x9, x9, #0x10
   28ed0:	add	x10, x8, #0x1
   28ed4:	cmp	x10, x24
   28ed8:	b.ge	28f88 <__gmpn_mul_fft@@Base+0x1238>  // b.tcont
   28edc:	ldr	x11, [x9, x8, lsl #3]
   28ee0:	sub	x12, x11, #0x1
   28ee4:	str	x12, [x9, x8, lsl #3]
   28ee8:	mov	x8, x10
   28eec:	cbz	x11, 28ed0 <__gmpn_mul_fft@@Base+0x1180>
   28ef0:	b	28f88 <__gmpn_mul_fft@@Base+0x1238>
   28ef4:	sub	x8, x8, x13, lsl #3
   28ef8:	ldr	x9, [x8]
   28efc:	adds	x9, x9, #0x1
   28f00:	str	x9, [x8]
   28f04:	b.cc	28f88 <__gmpn_mul_fft@@Base+0x1238>  // b.lo, b.ul, b.last
   28f08:	mov	w9, #0x1                   	// #1
   28f0c:	cmp	x9, x13
   28f10:	b.ge	28f2c <__gmpn_mul_fft@@Base+0x11dc>  // b.tcont
   28f14:	ldr	x10, [x8, x9, lsl #3]
   28f18:	adds	x10, x10, #0x1
   28f1c:	str	x10, [x8, x9, lsl #3]
   28f20:	add	x9, x9, #0x1
   28f24:	b.cs	28f0c <__gmpn_mul_fft@@Base+0x11bc>  // b.hs, b.nlast
   28f28:	b	28f88 <__gmpn_mul_fft@@Base+0x1238>
   28f2c:	ldr	x9, [x8]
   28f30:	adds	x9, x9, #0x1
   28f34:	str	x9, [x8]
   28f38:	mov	w9, #0x1                   	// #1
   28f3c:	b.cs	28f0c <__gmpn_mul_fft@@Base+0x11bc>  // b.hs, b.nlast
   28f40:	b	28f88 <__gmpn_mul_fft@@Base+0x1238>
   28f44:	ldur	x9, [x8, #-8]
   28f48:	sub	x10, x9, #0x1
   28f4c:	stur	x10, [x8, #-8]
   28f50:	cbnz	x9, 28f78 <__gmpn_mul_fft@@Base+0x1228>
   28f54:	b	28f6c <__gmpn_mul_fft@@Base+0x121c>
   28f58:	ldr	x11, [x8, x9, lsl #3]
   28f5c:	sub	x12, x11, #0x1
   28f60:	str	x12, [x8, x9, lsl #3]
   28f64:	mov	x9, x10
   28f68:	cbnz	x11, 28f78 <__gmpn_mul_fft@@Base+0x1228>
   28f6c:	add	x10, x9, #0x1
   28f70:	cmp	x10, x24
   28f74:	b.le	28f58 <__gmpn_mul_fft@@Base+0x1208>
   28f78:	ldur	x9, [x29, #-120]
   28f7c:	ldr	x8, [x14, x9, lsl #3]
   28f80:	sub	x8, x8, #0x1
   28f84:	str	x8, [x14, x9, lsl #3]
   28f88:	sub	x19, x20, x24, lsl #1
   28f8c:	cmp	x19, #0x1
   28f90:	b.lt	29054 <__gmpn_mul_fft@@Base+0x1304>  // b.tstop
   28f94:	ldr	x21, [sp, #56]
   28f98:	ldur	x1, [x29, #-48]
   28f9c:	add	x2, x14, x13, lsl #3
   28fa0:	mov	x3, x19
   28fa4:	mov	x0, x21
   28fa8:	bl	ca90 <__gmpn_add_n@plt>
   28fac:	ldur	x14, [x29, #-48]
   28fb0:	sub	x8, x24, x19
   28fb4:	ldr	x9, [x14, x19, lsl #3]
   28fb8:	adds	x9, x9, x0
   28fbc:	str	x9, [x21, x19, lsl #3]
   28fc0:	b.cc	29078 <__gmpn_mul_fft@@Base+0x1328>  // b.lo, b.ul, b.last
   28fc4:	ldur	x10, [x29, #-104]
   28fc8:	add	x9, x24, x24, lsl #1
   28fcc:	mov	w20, #0x1                   	// #1
   28fd0:	sub	x10, x10, x24, lsl #1
   28fd4:	lsl	x10, x10, #3
   28fd8:	add	x10, x10, #0x10
   28fdc:	add	x12, x14, x10
   28fe0:	add	x11, x21, x10
   28fe4:	mov	w10, #0x1                   	// #1
   28fe8:	cmp	x10, x8
   28fec:	b.ge	290c4 <__gmpn_mul_fft@@Base+0x1374>  // b.tcont
   28ff0:	ldr	x13, [x12, x22, lsl #3]
   28ff4:	add	x10, x10, #0x1
   28ff8:	add	x12, x12, #0x8
   28ffc:	adds	x13, x13, #0x1
   29000:	str	x13, [x11, x22, lsl #3]
   29004:	add	x11, x11, #0x8
   29008:	b.cs	28fe8 <__gmpn_mul_fft@@Base+0x1298>  // b.hs, b.nlast
   2900c:	cmp	x14, x21
   29010:	mov	x20, xzr
   29014:	b.eq	290c4 <__gmpn_mul_fft@@Base+0x1374>  // b.none
   29018:	cmp	x10, x8
   2901c:	mov	x19, x24
   29020:	b.ge	290c8 <__gmpn_mul_fft@@Base+0x1378>  // b.tcont
   29024:	add	x8, x12, x22, lsl #3
   29028:	ldur	x12, [x29, #-104]
   2902c:	add	x11, x11, x22, lsl #3
   29030:	add	x12, x22, x12
   29034:	sub	x9, x12, x9
   29038:	add	x9, x9, x10
   2903c:	add	x9, x9, #0x1
   29040:	ldr	x10, [x8], #8
   29044:	adds	x9, x9, #0x1
   29048:	str	x10, [x11], #8
   2904c:	b.cc	29040 <__gmpn_mul_fft@@Base+0x12f0>  // b.lo, b.ul, b.last
   29050:	b	290c0 <__gmpn_mul_fft@@Base+0x1370>
   29054:	ldr	x21, [sp, #56]
   29058:	ldur	x1, [x29, #-48]
   2905c:	mov	x2, x24
   29060:	sub	x19, x20, x24
   29064:	mov	x0, x21
   29068:	bl	ca70 <__gmpn_copyi@plt>
   2906c:	ldur	x14, [x29, #-48]
   29070:	mov	x20, xzr
   29074:	b	290c8 <__gmpn_mul_fft@@Base+0x1378>
   29078:	cmp	x14, x21
   2907c:	mov	x20, xzr
   29080:	b.eq	290c4 <__gmpn_mul_fft@@Base+0x1374>  // b.none
   29084:	cmp	x8, #0x2
   29088:	mov	x19, x24
   2908c:	b.lt	290c8 <__gmpn_mul_fft@@Base+0x1378>  // b.tstop
   29090:	ldur	x8, [x29, #-104]
   29094:	add	x9, x24, x24, lsl #1
   29098:	add	x8, x22, x8
   2909c:	add	x10, x8, #0x2
   290a0:	sub	x8, x10, x9
   290a4:	sub	x10, x10, x24, lsl #1
   290a8:	add	x9, x21, x10, lsl #3
   290ac:	add	x10, x14, x10, lsl #3
   290b0:	ldr	x11, [x10], #8
   290b4:	adds	x8, x8, #0x1
   290b8:	str	x11, [x9], #8
   290bc:	b.cc	290b0 <__gmpn_mul_fft@@Base+0x1360>  // b.lo, b.ul, b.last
   290c0:	mov	x20, xzr
   290c4:	mov	x19, x24
   290c8:	add	x2, x14, x24, lsl #3
   290cc:	mov	x0, x21
   290d0:	mov	x1, x21
   290d4:	mov	x3, x19
   290d8:	bl	c2e0 <__gmpn_sub_n@plt>
   290dc:	add	x9, x21, x19, lsl #3
   290e0:	ldr	x8, [x9]
   290e4:	subs	x8, x8, x0
   290e8:	str	x8, [x9]
   290ec:	b.cs	29118 <__gmpn_mul_fft@@Base+0x13c8>  // b.hs, b.nlast
   290f0:	sub	x10, x24, x19
   290f4:	mov	w8, #0x1                   	// #1
   290f8:	mov	w11, #0x1                   	// #1
   290fc:	cmp	x11, x10
   29100:	b.ge	2911c <__gmpn_mul_fft@@Base+0x13cc>  // b.tcont
   29104:	ldr	x12, [x9, x11, lsl #3]
   29108:	sub	x13, x12, #0x1
   2910c:	str	x13, [x9, x11, lsl #3]
   29110:	add	x11, x11, #0x1
   29114:	cbz	x12, 290fc <__gmpn_mul_fft@@Base+0x13ac>
   29118:	mov	x8, xzr
   2911c:	subs	x0, x20, x8
   29120:	b.pl	2915c <__gmpn_mul_fft@@Base+0x140c>  // b.nfrst
   29124:	ldr	x8, [x21]
   29128:	adds	x8, x8, #0x1
   2912c:	str	x8, [x21]
   29130:	b.cc	29158 <__gmpn_mul_fft@@Base+0x1408>  // b.lo, b.ul, b.last
   29134:	mov	w0, #0x1                   	// #1
   29138:	mov	w8, #0x1                   	// #1
   2913c:	cmp	x8, x24
   29140:	b.ge	2915c <__gmpn_mul_fft@@Base+0x140c>  // b.tcont
   29144:	ldr	x9, [x21, x8, lsl #3]
   29148:	adds	x9, x9, #0x1
   2914c:	str	x9, [x21, x8, lsl #3]
   29150:	add	x8, x8, #0x1
   29154:	b.cs	2913c <__gmpn_mul_fft@@Base+0x13ec>  // b.hs, b.nlast
   29158:	mov	x0, xzr
   2915c:	ldp	x20, x19, [sp, #336]
   29160:	ldp	x22, x21, [sp, #320]
   29164:	ldp	x24, x23, [sp, #304]
   29168:	ldp	x26, x25, [sp, #288]
   2916c:	ldp	x28, x27, [sp, #272]
   29170:	ldp	x29, x30, [sp, #256]
   29174:	add	sp, sp, #0x160
   29178:	ret
   2917c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   29180:	b	28a68 <__gmpn_mul_fft@@Base+0xd18>
   29184:	adrp	x0, 53000 <__gmpn_bases@@Base+0x1938>
   29188:	adrp	x2, 53000 <__gmpn_bases@@Base+0x1938>
   2918c:	add	x0, x0, #0xefe
   29190:	add	x2, x2, #0xf3f
   29194:	mov	w1, #0x1d9                 	// #473
   29198:	bl	c6e0 <__gmp_assert_fail@plt>
   2919c:	adrp	x0, 53000 <__gmpn_bases@@Base+0x1938>
   291a0:	adrp	x2, 53000 <__gmpn_bases@@Base+0x1938>
   291a4:	add	x0, x0, #0xefe
   291a8:	add	x2, x2, #0xf53
   291ac:	mov	w1, #0x1ef                 	// #495
   291b0:	bl	c6e0 <__gmp_assert_fail@plt>
   291b4:	stp	x29, x30, [sp, #-80]!
   291b8:	stp	x24, x23, [sp, #32]
   291bc:	lsr	x24, x2, #6
   291c0:	stp	x22, x21, [sp, #48]
   291c4:	stp	x20, x19, [sp, #64]
   291c8:	mov	x19, x3
   291cc:	mov	x22, x1
   291d0:	mov	x20, x0
   291d4:	subs	x21, x24, x3
   291d8:	and	w23, w2, #0x3f
   291dc:	add	x8, x1, x3, lsl #3
   291e0:	str	x25, [sp, #16]
   291e4:	mov	x29, sp
   291e8:	b.ge	29228 <__gmpn_mul_fft@@Base+0x14d8>  // b.tcont
   291ec:	sub	x1, x8, x24, lsl #3
   291f0:	add	x2, x24, #0x1
   291f4:	mov	x0, x20
   291f8:	cbz	w23, 29260 <__gmpn_mul_fft@@Base+0x1510>
   291fc:	mov	w3, w23
   29200:	bl	d180 <__gmpn_lshiftc@plt>
   29204:	add	x0, x20, x24, lsl #3
   29208:	ldr	x8, [x0]
   2920c:	sub	x2, x19, x24
   29210:	mov	x1, x22
   29214:	mov	w3, w23
   29218:	mvn	x21, x8
   2921c:	bl	c190 <__gmpn_lshift@plt>
   29220:	cbnz	x24, 29280 <__gmpn_mul_fft@@Base+0x1530>
   29224:	b	2938c <__gmpn_mul_fft@@Base+0x163c>
   29228:	sub	x1, x8, x21, lsl #3
   2922c:	cbz	w23, 292c0 <__gmpn_mul_fft@@Base+0x1570>
   29230:	add	x2, x21, #0x1
   29234:	mov	x0, x20
   29238:	mov	w3, w23
   2923c:	bl	c190 <__gmpn_lshift@plt>
   29240:	add	x0, x20, x21, lsl #3
   29244:	ldr	x25, [x0]
   29248:	sub	x2, x19, x21
   2924c:	mov	x1, x22
   29250:	mov	w3, w23
   29254:	bl	d180 <__gmpn_lshiftc@plt>
   29258:	add	x8, x0, #0x1
   2925c:	b	292e4 <__gmpn_mul_fft@@Base+0x1594>
   29260:	bl	c2a0 <__gmpn_com@plt>
   29264:	ldr	x21, [x22, x19, lsl #3]
   29268:	add	x0, x20, x24, lsl #3
   2926c:	sub	x2, x19, x24
   29270:	mov	x1, x22
   29274:	bl	ca70 <__gmpn_copyi@plt>
   29278:	mov	x0, xzr
   2927c:	cbz	x24, 2938c <__gmpn_mul_fft@@Base+0x163c>
   29280:	cbz	x0, 29350 <__gmpn_mul_fft@@Base+0x1600>
   29284:	sub	x0, x0, #0x1
   29288:	ldr	x8, [x20]
   2928c:	subs	x8, x8, x0
   29290:	str	x8, [x20]
   29294:	b.cs	29388 <__gmpn_mul_fft@@Base+0x1638>  // b.hs, b.nlast
   29298:	mov	w0, #0x2                   	// #2
   2929c:	mov	w8, #0x1                   	// #1
   292a0:	cmp	x8, x24
   292a4:	b.cs	2938c <__gmpn_mul_fft@@Base+0x163c>  // b.hs, b.nlast
   292a8:	ldr	x9, [x20, x8, lsl #3]
   292ac:	sub	x10, x9, #0x1
   292b0:	str	x10, [x20, x8, lsl #3]
   292b4:	add	x8, x8, #0x1
   292b8:	cbz	x9, 292a0 <__gmpn_mul_fft@@Base+0x1550>
   292bc:	b	29388 <__gmpn_mul_fft@@Base+0x1638>
   292c0:	mov	x0, x20
   292c4:	mov	x2, x21
   292c8:	bl	ca70 <__gmpn_copyi@plt>
   292cc:	ldr	x25, [x22, x19, lsl #3]
   292d0:	add	x0, x20, x21, lsl #3
   292d4:	sub	x2, x19, x21
   292d8:	mov	x1, x22
   292dc:	bl	c2a0 <__gmpn_com@plt>
   292e0:	mov	w8, #0x1                   	// #1
   292e4:	str	xzr, [x20, x19, lsl #3]
   292e8:	ldr	x9, [x20]
   292ec:	adds	x8, x9, x8
   292f0:	str	x8, [x20]
   292f4:	b.cc	2930c <__gmpn_mul_fft@@Base+0x15bc>  // b.lo, b.ul, b.last
   292f8:	add	x8, x20, #0x8
   292fc:	ldr	x9, [x8]
   29300:	adds	x9, x9, #0x1
   29304:	str	x9, [x8], #8
   29308:	b.cs	292fc <__gmpn_mul_fft@@Base+0x15ac>  // b.hs, b.nlast
   2930c:	adds	x9, x25, #0x1
   29310:	cset	w8, cs  // cs = hs, nlast
   29314:	add	x10, x20, x21, lsl #3
   29318:	ldr	x11, [x10, w8, uxtw #3]
   2931c:	csinc	x9, x9, xzr, cc  // cc = lo, ul, last
   29320:	adds	x9, x11, x9
   29324:	str	x9, [x10, w8, uxtw #3]
   29328:	b.cc	29458 <__gmpn_mul_fft@@Base+0x1708>  // b.lo, b.ul, b.last
   2932c:	add	x8, x24, x8
   29330:	sub	x8, x8, x19
   29334:	add	x8, x20, x8, lsl #3
   29338:	add	x8, x8, #0x8
   2933c:	ldr	x9, [x8]
   29340:	adds	x9, x9, #0x1
   29344:	str	x9, [x8], #8
   29348:	b.cs	2933c <__gmpn_mul_fft@@Base+0x15ec>  // b.hs, b.nlast
   2934c:	b	29458 <__gmpn_mul_fft@@Base+0x1708>
   29350:	ldr	x8, [x20]
   29354:	adds	x8, x8, #0x1
   29358:	str	x8, [x20]
   2935c:	b.cc	29388 <__gmpn_mul_fft@@Base+0x1638>  // b.lo, b.ul, b.last
   29360:	mov	w0, #0x1                   	// #1
   29364:	mov	w8, #0x1                   	// #1
   29368:	cmp	x8, x19
   2936c:	b.ge	29288 <__gmpn_mul_fft@@Base+0x1538>  // b.tcont
   29370:	ldr	x9, [x20, x8, lsl #3]
   29374:	adds	x9, x9, #0x1
   29378:	str	x9, [x20, x8, lsl #3]
   2937c:	add	x8, x8, #0x1
   29380:	b.cs	29368 <__gmpn_mul_fft@@Base+0x1618>  // b.hs, b.nlast
   29384:	b	2938c <__gmpn_mul_fft@@Base+0x163c>
   29388:	mov	w0, #0x1                   	// #1
   2938c:	add	x8, x20, x24, lsl #3
   29390:	ldr	x10, [x8]
   29394:	sub	x9, x19, x24
   29398:	subs	x10, x10, x0
   2939c:	str	x10, [x8]
   293a0:	b.cs	293c4 <__gmpn_mul_fft@@Base+0x1674>  // b.hs, b.nlast
   293a4:	mov	w10, #0x1                   	// #1
   293a8:	cmp	x10, x9
   293ac:	b.ge	293cc <__gmpn_mul_fft@@Base+0x167c>  // b.tcont
   293b0:	ldr	x11, [x8, x10, lsl #3]
   293b4:	sub	x12, x11, #0x1
   293b8:	str	x12, [x8, x10, lsl #3]
   293bc:	add	x10, x10, #0x1
   293c0:	cbz	x11, 293a8 <__gmpn_mul_fft@@Base+0x1658>
   293c4:	mov	x10, xzr
   293c8:	b	293d0 <__gmpn_mul_fft@@Base+0x1680>
   293cc:	mov	x10, #0xffffffffffffffff    	// #-1
   293d0:	str	x10, [x20, x19, lsl #3]
   293d4:	ldr	x10, [x8]
   293d8:	subs	x10, x10, x21
   293dc:	str	x10, [x8]
   293e0:	b.cs	29408 <__gmpn_mul_fft@@Base+0x16b8>  // b.hs, b.nlast
   293e4:	mov	w10, #0x1                   	// #1
   293e8:	mov	w11, #0x1                   	// #1
   293ec:	cmp	x11, x9
   293f0:	b.ge	2940c <__gmpn_mul_fft@@Base+0x16bc>  // b.tcont
   293f4:	ldr	x12, [x8, x11, lsl #3]
   293f8:	sub	x13, x12, #0x1
   293fc:	str	x13, [x8, x11, lsl #3]
   29400:	add	x11, x11, #0x1
   29404:	cbz	x12, 293ec <__gmpn_mul_fft@@Base+0x169c>
   29408:	mov	x10, xzr
   2940c:	ldr	x8, [x20, x19, lsl #3]
   29410:	subs	x8, x8, x10
   29414:	str	x8, [x20, x19, lsl #3]
   29418:	b.pl	29458 <__gmpn_mul_fft@@Base+0x1708>  // b.nfrst
   2941c:	ldr	x8, [x20]
   29420:	adds	x8, x8, #0x1
   29424:	str	x8, [x20]
   29428:	b.cc	29450 <__gmpn_mul_fft@@Base+0x1700>  // b.lo, b.ul, b.last
   2942c:	mov	w8, #0x1                   	// #1
   29430:	mov	w9, #0x1                   	// #1
   29434:	cmp	x9, x19
   29438:	b.ge	29454 <__gmpn_mul_fft@@Base+0x1704>  // b.tcont
   2943c:	ldr	x10, [x20, x9, lsl #3]
   29440:	adds	x10, x10, #0x1
   29444:	str	x10, [x20, x9, lsl #3]
   29448:	add	x9, x9, #0x1
   2944c:	b.cs	29434 <__gmpn_mul_fft@@Base+0x16e4>  // b.hs, b.nlast
   29450:	mov	x8, xzr
   29454:	str	x8, [x20, x19, lsl #3]
   29458:	ldp	x20, x19, [sp, #64]
   2945c:	ldp	x22, x21, [sp, #48]
   29460:	ldp	x24, x23, [sp, #32]
   29464:	ldr	x25, [sp, #16]
   29468:	ldp	x29, x30, [sp], #80
   2946c:	ret
   29470:	sub	sp, sp, #0x70
   29474:	stp	x22, x21, [sp, #80]
   29478:	stp	x20, x19, [sp, #96]
   2947c:	mov	x22, x6
   29480:	mov	x20, x5
   29484:	mov	x19, x4
   29488:	cmp	x1, #0x2
   2948c:	mov	x21, x0
   29490:	stp	x29, x30, [sp, #16]
   29494:	stp	x28, x27, [sp, #32]
   29498:	stp	x26, x25, [sp, #48]
   2949c:	stp	x24, x23, [sp, #64]
   294a0:	add	x29, sp, #0x10
   294a4:	b.ne	29530 <__gmpn_mul_fft@@Base+0x17e0>  // b.any
   294a8:	ldr	x1, [x21]
   294ac:	add	x23, x19, #0x1
   294b0:	mov	x0, x22
   294b4:	mov	x2, x23
   294b8:	bl	ca70 <__gmpn_copyi@plt>
   294bc:	ldr	x0, [x21]
   294c0:	ldr	x2, [x21, x20, lsl #3]
   294c4:	mov	x3, x23
   294c8:	mov	x1, x0
   294cc:	bl	ca90 <__gmpn_add_n@plt>
   294d0:	ldr	x0, [x21, x20, lsl #3]
   294d4:	mov	x1, x22
   294d8:	mov	x3, x23
   294dc:	mov	x2, x0
   294e0:	bl	c2e0 <__gmpn_sub_n@plt>
   294e4:	ldr	x8, [x21]
   294e8:	ldr	x9, [x8, x19, lsl #3]
   294ec:	cmp	x9, #0x2
   294f0:	b.cc	29698 <__gmpn_mul_fft@@Base+0x1948>  // b.lo, b.ul, b.last
   294f4:	ldr	x10, [x8]
   294f8:	sub	x9, x9, #0x1
   294fc:	subs	x9, x10, x9
   29500:	str	x9, [x8]
   29504:	mov	w9, #0x1                   	// #1
   29508:	b.cs	29694 <__gmpn_mul_fft@@Base+0x1944>  // b.hs, b.nlast
   2950c:	mov	w10, #0x1                   	// #1
   29510:	cmp	x10, x19
   29514:	b.ge	29690 <__gmpn_mul_fft@@Base+0x1940>  // b.tcont
   29518:	ldr	x11, [x8, x10, lsl #3]
   2951c:	sub	x12, x11, #0x1
   29520:	str	x12, [x8, x10, lsl #3]
   29524:	add	x10, x10, #0x1
   29528:	cbz	x11, 29510 <__gmpn_mul_fft@@Base+0x17c0>
   2952c:	b	29694 <__gmpn_mul_fft@@Base+0x1944>
   29530:	mov	x27, x2
   29534:	ldr	x28, [x27], #-8
   29538:	asr	x24, x1, #1
   2953c:	lsl	x25, x20, #1
   29540:	mov	x23, x3
   29544:	mov	x26, x1
   29548:	lsl	x3, x3, #1
   2954c:	mov	x0, x21
   29550:	mov	x1, x24
   29554:	mov	x2, x27
   29558:	mov	x4, x19
   2955c:	mov	x5, x25
   29560:	mov	x6, x22
   29564:	str	x3, [sp]
   29568:	bl	29470 <__gmpn_mul_fft@@Base+0x1720>
   2956c:	ldr	x3, [sp]
   29570:	add	x0, x21, x20, lsl #3
   29574:	mov	x1, x24
   29578:	mov	x2, x27
   2957c:	mov	x4, x19
   29580:	mov	x5, x25
   29584:	mov	x6, x22
   29588:	str	x24, [sp, #8]
   2958c:	bl	29470 <__gmpn_mul_fft@@Base+0x1720>
   29590:	cmp	x26, #0x2
   29594:	b.lt	296ec <__gmpn_mul_fft@@Base+0x199c>  // b.tstop
   29598:	mov	x27, xzr
   2959c:	ldrsw	x8, [x28]
   295a0:	ldr	x1, [x21, x20, lsl #3]
   295a4:	mov	x0, x22
   295a8:	mov	x3, x19
   295ac:	mul	x2, x8, x23
   295b0:	mov	x24, x23
   295b4:	bl	291b4 <__gmpn_mul_fft@@Base+0x1464>
   295b8:	ldr	x1, [x21]
   295bc:	ldr	x26, [x21, x20, lsl #3]
   295c0:	ldr	x9, [x22, x19, lsl #3]
   295c4:	mov	x2, x22
   295c8:	ldr	x8, [x1, x19, lsl #3]
   295cc:	mov	x0, x26
   295d0:	mov	x3, x19
   295d4:	sub	x23, x8, x9
   295d8:	bl	c2e0 <__gmpn_sub_n@plt>
   295dc:	sub	x8, x23, x0
   295e0:	neg	x9, x8
   295e4:	and	x9, x9, x8, asr #63
   295e8:	add	x8, x9, x8
   295ec:	str	x8, [x26, x19, lsl #3]
   295f0:	ldr	x8, [x26]
   295f4:	adds	x8, x8, x9
   295f8:	str	x8, [x26]
   295fc:	b.cc	29614 <__gmpn_mul_fft@@Base+0x18c4>  // b.lo, b.ul, b.last
   29600:	add	x8, x26, #0x8
   29604:	ldr	x9, [x8]
   29608:	adds	x9, x9, #0x1
   2960c:	str	x9, [x8], #8
   29610:	b.cs	29604 <__gmpn_mul_fft@@Base+0x18b4>  // b.hs, b.nlast
   29614:	ldr	x26, [x21]
   29618:	ldr	x9, [x22, x19, lsl #3]
   2961c:	mov	x2, x22
   29620:	mov	x3, x19
   29624:	ldr	x8, [x26, x19, lsl #3]
   29628:	mov	x0, x26
   2962c:	mov	x1, x26
   29630:	add	x23, x9, x8
   29634:	bl	ca90 <__gmpn_add_n@plt>
   29638:	adds	x8, x23, x0
   2963c:	sub	x9, x8, #0x1
   29640:	csel	x9, xzr, x9, eq  // eq = none
   29644:	sub	x8, x8, x9
   29648:	str	x8, [x26, x19, lsl #3]
   2964c:	ldr	x8, [x26]
   29650:	subs	x8, x8, x9
   29654:	str	x8, [x26]
   29658:	b.cs	29670 <__gmpn_mul_fft@@Base+0x1920>  // b.hs, b.nlast
   2965c:	add	x8, x26, #0x8
   29660:	ldr	x9, [x8]
   29664:	sub	x10, x9, #0x1
   29668:	str	x10, [x8], #8
   2966c:	cbz	x9, 29660 <__gmpn_mul_fft@@Base+0x1910>
   29670:	ldr	x8, [sp, #8]
   29674:	add	x27, x27, #0x1
   29678:	add	x28, x28, #0x8
   2967c:	add	x21, x21, x25, lsl #3
   29680:	cmp	x27, x8
   29684:	mov	x23, x24
   29688:	b.lt	2959c <__gmpn_mul_fft@@Base+0x184c>  // b.tstop
   2968c:	b	296ec <__gmpn_mul_fft@@Base+0x199c>
   29690:	mov	x9, xzr
   29694:	str	x9, [x8, x19, lsl #3]
   29698:	cbz	x0, 296ec <__gmpn_mul_fft@@Base+0x199c>
   2969c:	ldr	x8, [x21, x20, lsl #3]
   296a0:	mov	x9, xzr
   296a4:	ldr	x10, [x8, x19, lsl #3]
   296a8:	ldr	x11, [x8]
   296ac:	neg	x12, x10
   296b0:	sub	x10, x11, x10
   296b4:	cmp	x10, x12
   296b8:	str	x10, [x8]
   296bc:	b.cs	296e8 <__gmpn_mul_fft@@Base+0x1998>  // b.hs, b.nlast
   296c0:	mov	w9, #0x1                   	// #1
   296c4:	mov	w10, #0x1                   	// #1
   296c8:	cmp	x10, x19
   296cc:	b.ge	296e8 <__gmpn_mul_fft@@Base+0x1998>  // b.tcont
   296d0:	ldr	x11, [x8, x10, lsl #3]
   296d4:	adds	x11, x11, #0x1
   296d8:	str	x11, [x8, x10, lsl #3]
   296dc:	add	x10, x10, #0x1
   296e0:	b.cs	296c8 <__gmpn_mul_fft@@Base+0x1978>  // b.hs, b.nlast
   296e4:	mov	x9, xzr
   296e8:	str	x9, [x8, x19, lsl #3]
   296ec:	ldp	x20, x19, [sp, #96]
   296f0:	ldp	x22, x21, [sp, #80]
   296f4:	ldp	x24, x23, [sp, #64]
   296f8:	ldp	x26, x25, [sp, #48]
   296fc:	ldp	x28, x27, [sp, #32]
   29700:	ldp	x29, x30, [sp, #16]
   29704:	add	sp, sp, #0x70
   29708:	ret
   2970c:	stp	x29, x30, [sp, #-80]!
   29710:	stp	x22, x21, [sp, #48]
   29714:	stp	x20, x19, [sp, #64]
   29718:	mov	x21, x4
   2971c:	mov	x19, x3
   29720:	cmp	x1, #0x2
   29724:	mov	x20, x0
   29728:	stp	x26, x25, [sp, #16]
   2972c:	stp	x24, x23, [sp, #32]
   29730:	mov	x29, sp
   29734:	b.ne	297bc <__gmpn_mul_fft@@Base+0x1a6c>  // b.any
   29738:	ldr	x1, [x20]
   2973c:	add	x22, x19, #0x1
   29740:	mov	x0, x21
   29744:	mov	x2, x22
   29748:	bl	ca70 <__gmpn_copyi@plt>
   2974c:	ldp	x0, x2, [x20]
   29750:	mov	x3, x22
   29754:	mov	x1, x0
   29758:	bl	ca90 <__gmpn_add_n@plt>
   2975c:	ldr	x0, [x20, #8]
   29760:	mov	x1, x21
   29764:	mov	x3, x22
   29768:	mov	x2, x0
   2976c:	bl	c2e0 <__gmpn_sub_n@plt>
   29770:	ldr	x8, [x20]
   29774:	ldr	x9, [x8, x19, lsl #3]
   29778:	cmp	x9, #0x2
   2977c:	b.cc	298f0 <__gmpn_mul_fft@@Base+0x1ba0>  // b.lo, b.ul, b.last
   29780:	ldr	x10, [x8]
   29784:	sub	x9, x9, #0x1
   29788:	subs	x9, x10, x9
   2978c:	str	x9, [x8]
   29790:	mov	w9, #0x1                   	// #1
   29794:	b.cs	298ec <__gmpn_mul_fft@@Base+0x1b9c>  // b.hs, b.nlast
   29798:	mov	w10, #0x1                   	// #1
   2979c:	cmp	x10, x19
   297a0:	b.ge	298e8 <__gmpn_mul_fft@@Base+0x1b98>  // b.tcont
   297a4:	ldr	x11, [x8, x10, lsl #3]
   297a8:	sub	x12, x11, #0x1
   297ac:	str	x12, [x8, x10, lsl #3]
   297b0:	add	x10, x10, #0x1
   297b4:	cbz	x11, 2979c <__gmpn_mul_fft@@Base+0x1a4c>
   297b8:	b	298ec <__gmpn_mul_fft@@Base+0x1b9c>
   297bc:	asr	x23, x1, #1
   297c0:	lsl	x25, x2, #1
   297c4:	mov	x22, x2
   297c8:	mov	x24, x1
   297cc:	mov	x0, x20
   297d0:	mov	x1, x23
   297d4:	mov	x2, x25
   297d8:	mov	x3, x19
   297dc:	mov	x4, x21
   297e0:	bl	2970c <__gmpn_mul_fft@@Base+0x19bc>
   297e4:	add	x0, x20, x23, lsl #3
   297e8:	mov	x1, x23
   297ec:	mov	x2, x25
   297f0:	mov	x3, x19
   297f4:	mov	x4, x21
   297f8:	bl	2970c <__gmpn_mul_fft@@Base+0x19bc>
   297fc:	cmp	x24, #0x2
   29800:	b.lt	29944 <__gmpn_mul_fft@@Base+0x1bf4>  // b.tstop
   29804:	mov	x25, xzr
   29808:	ldr	x1, [x20, x23, lsl #3]
   2980c:	mul	x2, x25, x22
   29810:	mov	x0, x21
   29814:	mov	x3, x19
   29818:	bl	291b4 <__gmpn_mul_fft@@Base+0x1464>
   2981c:	ldr	x1, [x20]
   29820:	ldr	x24, [x20, x23, lsl #3]
   29824:	ldr	x9, [x21, x19, lsl #3]
   29828:	mov	x2, x21
   2982c:	ldr	x8, [x1, x19, lsl #3]
   29830:	mov	x0, x24
   29834:	mov	x3, x19
   29838:	sub	x26, x8, x9
   2983c:	bl	c2e0 <__gmpn_sub_n@plt>
   29840:	sub	x8, x26, x0
   29844:	neg	x9, x8
   29848:	and	x9, x9, x8, asr #63
   2984c:	add	x8, x9, x8
   29850:	str	x8, [x24, x19, lsl #3]
   29854:	ldr	x8, [x24]
   29858:	adds	x8, x8, x9
   2985c:	str	x8, [x24]
   29860:	b.cc	29878 <__gmpn_mul_fft@@Base+0x1b28>  // b.lo, b.ul, b.last
   29864:	add	x8, x24, #0x8
   29868:	ldr	x9, [x8]
   2986c:	adds	x9, x9, #0x1
   29870:	str	x9, [x8], #8
   29874:	b.cs	29868 <__gmpn_mul_fft@@Base+0x1b18>  // b.hs, b.nlast
   29878:	ldr	x24, [x20]
   2987c:	ldr	x9, [x21, x19, lsl #3]
   29880:	mov	x2, x21
   29884:	mov	x3, x19
   29888:	ldr	x8, [x24, x19, lsl #3]
   2988c:	mov	x0, x24
   29890:	mov	x1, x24
   29894:	add	x26, x9, x8
   29898:	bl	ca90 <__gmpn_add_n@plt>
   2989c:	adds	x8, x26, x0
   298a0:	sub	x9, x8, #0x1
   298a4:	csel	x9, xzr, x9, eq  // eq = none
   298a8:	sub	x8, x8, x9
   298ac:	str	x8, [x24, x19, lsl #3]
   298b0:	ldr	x8, [x24]
   298b4:	subs	x8, x8, x9
   298b8:	str	x8, [x24]
   298bc:	b.cs	298d4 <__gmpn_mul_fft@@Base+0x1b84>  // b.hs, b.nlast
   298c0:	add	x8, x24, #0x8
   298c4:	ldr	x9, [x8]
   298c8:	sub	x10, x9, #0x1
   298cc:	str	x10, [x8], #8
   298d0:	cbz	x9, 298c4 <__gmpn_mul_fft@@Base+0x1b74>
   298d4:	add	x25, x25, #0x1
   298d8:	cmp	x25, x23
   298dc:	add	x20, x20, #0x8
   298e0:	b.lt	29808 <__gmpn_mul_fft@@Base+0x1ab8>  // b.tstop
   298e4:	b	29944 <__gmpn_mul_fft@@Base+0x1bf4>
   298e8:	mov	x9, xzr
   298ec:	str	x9, [x8, x19, lsl #3]
   298f0:	cbz	x0, 29944 <__gmpn_mul_fft@@Base+0x1bf4>
   298f4:	ldr	x8, [x20, #8]
   298f8:	mov	x9, xzr
   298fc:	ldr	x10, [x8, x19, lsl #3]
   29900:	ldr	x11, [x8]
   29904:	neg	x12, x10
   29908:	sub	x10, x11, x10
   2990c:	cmp	x10, x12
   29910:	str	x10, [x8]
   29914:	b.cs	29940 <__gmpn_mul_fft@@Base+0x1bf0>  // b.hs, b.nlast
   29918:	mov	w9, #0x1                   	// #1
   2991c:	mov	w10, #0x1                   	// #1
   29920:	cmp	x10, x19
   29924:	b.ge	29940 <__gmpn_mul_fft@@Base+0x1bf0>  // b.tcont
   29928:	ldr	x11, [x8, x10, lsl #3]
   2992c:	adds	x11, x11, #0x1
   29930:	str	x11, [x8, x10, lsl #3]
   29934:	add	x10, x10, #0x1
   29938:	b.cs	29920 <__gmpn_mul_fft@@Base+0x1bd0>  // b.hs, b.nlast
   2993c:	mov	x9, xzr
   29940:	str	x9, [x8, x19, lsl #3]
   29944:	ldp	x20, x19, [sp, #64]
   29948:	ldp	x22, x21, [sp, #48]
   2994c:	ldp	x24, x23, [sp, #32]
   29950:	ldp	x26, x25, [sp, #16]
   29954:	ldp	x29, x30, [sp], #80
   29958:	ret

000000000002995c <__gmpn_mul_n@@Base>:
   2995c:	stp	x29, x30, [sp, #-32]!
   29960:	stp	x28, x19, [sp, #16]
   29964:	mov	x29, sp
   29968:	sub	sp, sp, #0x720
   2996c:	mov	x4, x3
   29970:	mov	x3, x2
   29974:	cmp	x4, #0xd
   29978:	mov	x19, sp
   2997c:	b.le	299bc <__gmpn_mul_n@@Base+0x60>
   29980:	cmp	x4, #0x30
   29984:	b.le	299d0 <__gmpn_mul_n@@Base+0x74>
   29988:	cmp	x4, #0x51
   2998c:	b.le	299e0 <__gmpn_mul_n@@Base+0x84>
   29990:	cmp	x4, #0xac
   29994:	b.le	29a08 <__gmpn_mul_n@@Base+0xac>
   29998:	cmp	x4, #0xeb
   2999c:	b.le	29a30 <__gmpn_mul_n@@Base+0xd4>
   299a0:	cmp	x4, #0xc7f
   299a4:	b.le	29a4c <__gmpn_mul_n@@Base+0xf0>
   299a8:	mov	x2, x4
   299ac:	mov	sp, x29
   299b0:	ldp	x28, x19, [sp, #16]
   299b4:	ldp	x29, x30, [sp], #32
   299b8:	b	ccc0 <__gmpn_nussbaumer_mul@plt>
   299bc:	mov	x2, x4
   299c0:	mov	sp, x29
   299c4:	ldp	x28, x19, [sp, #16]
   299c8:	ldp	x29, x30, [sp], #32
   299cc:	b	c570 <__gmpn_mul_basecase@plt>
   299d0:	add	x5, x19, #0x20
   299d4:	mov	x2, x4
   299d8:	bl	d470 <__gmpn_toom22_mul@plt>
   299dc:	b	29a90 <__gmpn_mul_n@@Base+0x134>
   299e0:	mov	w8, #0x18                  	// #24
   299e4:	mul	x8, x4, x8
   299e8:	add	x8, x8, #0x20f
   299ec:	and	x8, x8, #0xfffffffffffffff0
   299f0:	mov	x9, sp
   299f4:	sub	x5, x9, x8
   299f8:	mov	sp, x5
   299fc:	mov	x2, x4
   29a00:	bl	c0b0 <__gmpn_toom33_mul@plt>
   29a04:	b	29a90 <__gmpn_mul_n@@Base+0x134>
   29a08:	mov	w8, #0x18                  	// #24
   29a0c:	mul	x8, x4, x8
   29a10:	add	x8, x8, #0x20f
   29a14:	and	x8, x8, #0xfffffffffffffff0
   29a18:	mov	x9, sp
   29a1c:	sub	x5, x9, x8
   29a20:	mov	sp, x5
   29a24:	mov	x2, x4
   29a28:	bl	c740 <__gmpn_toom44_mul@plt>
   29a2c:	b	29a90 <__gmpn_mul_n@@Base+0x134>
   29a30:	mov	x8, sp
   29a34:	sub	x8, x8, x4, lsl #4
   29a38:	sub	x5, x8, #0xc00
   29a3c:	mov	sp, x5
   29a40:	mov	x2, x4
   29a44:	bl	cc40 <__gmpn_toom6h_mul@plt>
   29a48:	b	29a90 <__gmpn_mul_n@@Base+0x134>
   29a4c:	lsl	x8, x4, #4
   29a50:	sub	x8, x8, x4
   29a54:	add	x8, x8, #0xcf0
   29a58:	and	x8, x8, #0xfffffffffffffff8
   29a5c:	mov	w9, #0x7f00                	// #32512
   29a60:	cmp	x8, x9
   29a64:	str	xzr, [x19, #32]
   29a68:	b.hi	29aa0 <__gmpn_mul_n@@Base+0x144>  // b.pmore
   29a6c:	add	x8, x8, #0xf
   29a70:	mov	x9, sp
   29a74:	and	x8, x8, #0xfffffffffffffff0
   29a78:	sub	x5, x9, x8
   29a7c:	mov	sp, x5
   29a80:	mov	x2, x4
   29a84:	bl	cb40 <__gmpn_toom8h_mul@plt>
   29a88:	ldr	x0, [x19, #32]
   29a8c:	cbnz	x0, 29ac8 <__gmpn_mul_n@@Base+0x16c>
   29a90:	mov	sp, x29
   29a94:	ldp	x28, x19, [sp, #16]
   29a98:	ldp	x29, x30, [sp], #32
   29a9c:	ret
   29aa0:	stp	x1, x0, [x19, #16]
   29aa4:	add	x0, x19, #0x20
   29aa8:	mov	x1, x8
   29aac:	stp	x3, x4, [x19]
   29ab0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   29ab4:	ldp	x4, x1, [x19, #8]
   29ab8:	ldr	x3, [x19]
   29abc:	mov	x5, x0
   29ac0:	ldr	x0, [x19, #24]
   29ac4:	b	29a80 <__gmpn_mul_n@@Base+0x124>
   29ac8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   29acc:	b	29a90 <__gmpn_mul_n@@Base+0x134>

0000000000029ad0 <__gmpn_sqr@@Base>:
   29ad0:	stp	x29, x30, [sp, #-32]!
   29ad4:	stp	x28, x19, [sp, #16]
   29ad8:	mov	x29, sp
   29adc:	sub	sp, sp, #0x840
   29ae0:	mov	x8, x1
   29ae4:	cmp	x2, #0x11
   29ae8:	mov	x19, sp
   29aec:	b.le	29b34 <__gmpn_sqr@@Base+0x64>
   29af0:	cmp	x2, #0x42
   29af4:	b.le	29b48 <__gmpn_sqr@@Base+0x78>
   29af8:	cmp	x2, #0xa5
   29afc:	b.le	29b58 <__gmpn_sqr@@Base+0x88>
   29b00:	cmp	x2, #0xdd
   29b04:	b.le	29b80 <__gmpn_sqr@@Base+0xb0>
   29b08:	cmp	x2, #0x14c
   29b0c:	b.le	29ba8 <__gmpn_sqr@@Base+0xd8>
   29b10:	cmp	x2, #0xa7f
   29b14:	b.le	29bc4 <__gmpn_sqr@@Base+0xf4>
   29b18:	mov	x1, x8
   29b1c:	mov	x3, x8
   29b20:	mov	x4, x2
   29b24:	mov	sp, x29
   29b28:	ldp	x28, x19, [sp, #16]
   29b2c:	ldp	x29, x30, [sp], #32
   29b30:	b	ccc0 <__gmpn_nussbaumer_mul@plt>
   29b34:	mov	x1, x8
   29b38:	mov	sp, x29
   29b3c:	ldp	x28, x19, [sp, #16]
   29b40:	ldp	x29, x30, [sp], #32
   29b44:	b	c1a0 <__gmpn_sqr_basecase@plt>
   29b48:	add	x3, x19, #0x20
   29b4c:	mov	x1, x8
   29b50:	bl	c060 <__gmpn_toom2_sqr@plt>
   29b54:	b	29c08 <__gmpn_sqr@@Base+0x138>
   29b58:	mov	w9, #0x18                  	// #24
   29b5c:	mul	x9, x2, x9
   29b60:	add	x9, x9, #0x20f
   29b64:	and	x9, x9, #0xfffffffffffffff0
   29b68:	mov	x10, sp
   29b6c:	sub	x3, x10, x9
   29b70:	mov	sp, x3
   29b74:	mov	x1, x8
   29b78:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   29b7c:	b	29c08 <__gmpn_sqr@@Base+0x138>
   29b80:	mov	w9, #0x18                  	// #24
   29b84:	mul	x9, x2, x9
   29b88:	add	x9, x9, #0x20f
   29b8c:	and	x9, x9, #0xfffffffffffffff0
   29b90:	mov	x10, sp
   29b94:	sub	x3, x10, x9
   29b98:	mov	sp, x3
   29b9c:	mov	x1, x8
   29ba0:	bl	c230 <__gmpn_toom4_sqr@plt>
   29ba4:	b	29c08 <__gmpn_sqr@@Base+0x138>
   29ba8:	mov	x9, sp
   29bac:	sub	x9, x9, x2, lsl #4
   29bb0:	sub	x3, x9, #0xc00
   29bb4:	mov	sp, x3
   29bb8:	mov	x1, x8
   29bbc:	bl	d490 <__gmpn_toom6_sqr@plt>
   29bc0:	b	29c08 <__gmpn_sqr@@Base+0x138>
   29bc4:	lsl	x9, x2, #4
   29bc8:	sub	x9, x9, x2
   29bcc:	add	x9, x9, #0xd50
   29bd0:	and	x1, x9, #0xfffffffffffffff8
   29bd4:	mov	w9, #0x7f00                	// #32512
   29bd8:	cmp	x1, x9
   29bdc:	str	xzr, [x19, #32]
   29be0:	b.hi	29c18 <__gmpn_sqr@@Base+0x148>  // b.pmore
   29be4:	add	x10, x1, #0xf
   29be8:	mov	x9, sp
   29bec:	and	x10, x10, #0xfffffffffffffff0
   29bf0:	sub	x3, x9, x10
   29bf4:	mov	sp, x3
   29bf8:	mov	x1, x8
   29bfc:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   29c00:	ldr	x0, [x19, #32]
   29c04:	cbnz	x0, 29c38 <__gmpn_sqr@@Base+0x168>
   29c08:	mov	sp, x29
   29c0c:	ldp	x28, x19, [sp, #16]
   29c10:	ldp	x29, x30, [sp], #32
   29c14:	ret
   29c18:	stp	x2, x0, [x19, #16]
   29c1c:	add	x0, x19, #0x20
   29c20:	str	x8, [x19, #8]
   29c24:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   29c28:	ldp	x8, x2, [x19, #8]
   29c2c:	mov	x3, x0
   29c30:	ldr	x0, [x19, #24]
   29c34:	b	29bf8 <__gmpn_sqr@@Base+0x128>
   29c38:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   29c3c:	b	29c08 <__gmpn_sqr@@Base+0x138>

0000000000029c40 <__gmpn_mul_basecase@@Base>:
   29c40:	stp	x29, x30, [sp, #-64]!
   29c44:	stp	x22, x21, [sp, #32]
   29c48:	stp	x20, x19, [sp, #48]
   29c4c:	str	x23, [sp, #16]
   29c50:	mov	x23, x3
   29c54:	ldr	x3, [x3]
   29c58:	mov	x29, sp
   29c5c:	mov	x22, x4
   29c60:	mov	x19, x2
   29c64:	mov	x20, x1
   29c68:	mov	x21, x0
   29c6c:	bl	d4b0 <__gmpn_mul_1@plt>
   29c70:	cmp	x22, #0x2
   29c74:	str	x0, [x21, x19, lsl #3]
   29c78:	b.lt	29cb0 <__gmpn_mul_basecase@@Base+0x70>  // b.tstop
   29c7c:	add	x21, x21, #0x8
   29c80:	add	x23, x23, #0x8
   29c84:	add	x22, x22, #0x1
   29c88:	ldr	x3, [x23], #8
   29c8c:	mov	x0, x21
   29c90:	mov	x1, x20
   29c94:	mov	x2, x19
   29c98:	bl	d420 <__gmpn_addmul_1@plt>
   29c9c:	sub	x22, x22, #0x1
   29ca0:	str	x0, [x21, x19, lsl #3]
   29ca4:	cmp	x22, #0x2
   29ca8:	add	x21, x21, #0x8
   29cac:	b.gt	29c88 <__gmpn_mul_basecase@@Base+0x48>
   29cb0:	ldp	x20, x19, [sp, #48]
   29cb4:	ldp	x22, x21, [sp, #32]
   29cb8:	ldr	x23, [sp, #16]
   29cbc:	ldp	x29, x30, [sp], #64
   29cc0:	ret

0000000000029cc4 <__gmpn_sqr_basecase@@Base>:
   29cc4:	stp	x29, x30, [sp, #-64]!
   29cc8:	stp	x24, x23, [sp, #16]
   29ccc:	stp	x20, x19, [sp, #48]
   29cd0:	mov	x19, x2
   29cd4:	mov	x20, x1
   29cd8:	subs	x2, x2, #0x1
   29cdc:	mov	x23, x0
   29ce0:	stp	x22, x21, [sp, #32]
   29ce4:	mov	x29, sp
   29ce8:	b.ne	29d10 <__gmpn_sqr_basecase@@Base+0x4c>  // b.any
   29cec:	ldr	x8, [x20]
   29cf0:	umulh	x9, x8, x8
   29cf4:	mul	x8, x8, x8
   29cf8:	stp	x8, x9, [x23]
   29cfc:	ldp	x20, x19, [sp, #48]
   29d00:	ldp	x22, x21, [sp, #32]
   29d04:	ldp	x24, x23, [sp, #16]
   29d08:	ldp	x29, x30, [sp], #64
   29d0c:	ret
   29d10:	mov	x1, x20
   29d14:	ldr	x3, [x1], #8
   29d18:	add	x22, x23, #0x8
   29d1c:	mov	x0, x22
   29d20:	bl	d4b0 <__gmpn_mul_1@plt>
   29d24:	subs	x21, x19, #0x2
   29d28:	str	x0, [x23, x19, lsl #3]
   29d2c:	b.eq	29d74 <__gmpn_sqr_basecase@@Base+0xb0>  // b.none
   29d30:	add	x8, x23, x19, lsl #3
   29d34:	mov	x24, xzr
   29d38:	add	x22, x23, #0x18
   29d3c:	add	x23, x8, #0x8
   29d40:	add	x8, x20, x24
   29d44:	ldr	x3, [x8, #8]
   29d48:	add	x1, x8, #0x10
   29d4c:	mov	x0, x22
   29d50:	mov	x2, x21
   29d54:	bl	d420 <__gmpn_addmul_1@plt>
   29d58:	str	x0, [x23, x24]
   29d5c:	subs	x21, x21, #0x1
   29d60:	add	x22, x22, #0x10
   29d64:	add	x24, x24, #0x8
   29d68:	b.ne	29d40 <__gmpn_sqr_basecase@@Base+0x7c>  // b.any
   29d6c:	sub	x22, x22, #0x10
   29d70:	add	x20, x20, x24
   29d74:	sub	x8, x22, x19, lsl #4
   29d78:	sub	x9, x20, x19, lsl #3
   29d7c:	mov	x3, x19
   29d80:	ldp	x20, x19, [sp, #48]
   29d84:	ldp	x22, x21, [sp, #32]
   29d88:	ldp	x24, x23, [sp, #16]
   29d8c:	add	x0, x8, #0x18
   29d90:	add	x1, x8, #0x20
   29d94:	add	x2, x9, #0x10
   29d98:	ldp	x29, x30, [sp], #64
   29d9c:	b	d350 <__gmpn_sqr_diag_addlsh1@plt>

0000000000029da0 <__gmpn_nussbaumer_mul@@Base>:
   29da0:	stp	x29, x30, [sp, #-64]!
   29da4:	stp	x24, x23, [sp, #16]
   29da8:	stp	x22, x21, [sp, #32]
   29dac:	stp	x20, x19, [sp, #48]
   29db0:	mov	x29, sp
   29db4:	sub	sp, sp, #0x10
   29db8:	mov	x22, x4
   29dbc:	mov	x23, x3
   29dc0:	mov	x19, x2
   29dc4:	mov	x20, x1
   29dc8:	mov	x21, x0
   29dcc:	cmp	x1, x3
   29dd0:	stur	xzr, [x29, #-8]
   29dd4:	b.ne	29e38 <__gmpn_nussbaumer_mul@@Base+0x98>  // b.any
   29dd8:	cmp	x19, x22
   29ddc:	b.ne	29e38 <__gmpn_nussbaumer_mul@@Base+0x98>  // b.any
   29de0:	lsl	x0, x19, #1
   29de4:	bl	c5f0 <__gmpn_sqrmod_bnm1_next_size@plt>
   29de8:	cmp	x19, x0, asr #1
   29dec:	csel	x8, x19, xzr, gt
   29df0:	add	x8, x0, x8
   29df4:	lsl	x8, x8, #3
   29df8:	add	x1, x8, #0x18
   29dfc:	mov	w8, #0x7f00                	// #32512
   29e00:	mov	x22, x0
   29e04:	cmp	x1, x8
   29e08:	b.hi	29ec8 <__gmpn_nussbaumer_mul@@Base+0x128>  // b.pmore
   29e0c:	add	x9, x1, #0xf
   29e10:	mov	x8, sp
   29e14:	and	x9, x9, #0xfffffffffffffff0
   29e18:	sub	x4, x8, x9
   29e1c:	mov	sp, x4
   29e20:	mov	x0, x21
   29e24:	mov	x1, x22
   29e28:	mov	x2, x20
   29e2c:	mov	x3, x19
   29e30:	bl	bf60 <__gmpn_sqrmod_bnm1@plt>
   29e34:	b	29ea0 <__gmpn_nussbaumer_mul@@Base+0x100>
   29e38:	add	x0, x22, x19
   29e3c:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   29e40:	asr	x8, x0, #1
   29e44:	cmp	x8, x22
   29e48:	csel	x9, x0, x8, lt  // lt = tstop
   29e4c:	cmp	x8, x19
   29e50:	csel	x8, x9, xzr, lt  // lt = tstop
   29e54:	add	x8, x0, x8
   29e58:	lsl	x8, x8, #3
   29e5c:	add	x1, x8, #0x20
   29e60:	mov	w8, #0x7f00                	// #32512
   29e64:	mov	x24, x0
   29e68:	cmp	x1, x8
   29e6c:	b.hi	29ed8 <__gmpn_nussbaumer_mul@@Base+0x138>  // b.pmore
   29e70:	add	x9, x1, #0xf
   29e74:	mov	x8, sp
   29e78:	and	x9, x9, #0xfffffffffffffff0
   29e7c:	sub	x6, x8, x9
   29e80:	mov	sp, x6
   29e84:	mov	x0, x21
   29e88:	mov	x1, x24
   29e8c:	mov	x2, x20
   29e90:	mov	x3, x19
   29e94:	mov	x4, x23
   29e98:	mov	x5, x22
   29e9c:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   29ea0:	ldur	x0, [x29, #-8]
   29ea4:	cbnz	x0, 29ec0 <__gmpn_nussbaumer_mul@@Base+0x120>
   29ea8:	mov	sp, x29
   29eac:	ldp	x20, x19, [sp, #48]
   29eb0:	ldp	x22, x21, [sp, #32]
   29eb4:	ldp	x24, x23, [sp, #16]
   29eb8:	ldp	x29, x30, [sp], #64
   29ebc:	ret
   29ec0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   29ec4:	b	29ea8 <__gmpn_nussbaumer_mul@@Base+0x108>
   29ec8:	sub	x0, x29, #0x8
   29ecc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   29ed0:	mov	x4, x0
   29ed4:	b	29e20 <__gmpn_nussbaumer_mul@@Base+0x80>
   29ed8:	sub	x0, x29, #0x8
   29edc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   29ee0:	mov	x6, x0
   29ee4:	b	29e84 <__gmpn_nussbaumer_mul@@Base+0xe4>

0000000000029ee8 <__gmpn_mulmid_basecase@@Base>:
   29ee8:	stp	x29, x30, [sp, #-80]!
   29eec:	stp	x26, x25, [sp, #16]
   29ef0:	stp	x24, x23, [sp, #32]
   29ef4:	stp	x22, x21, [sp, #48]
   29ef8:	stp	x20, x19, [sp, #64]
   29efc:	mov	x23, x3
   29f00:	ldr	x3, [x3]
   29f04:	sub	x26, x4, #0x1
   29f08:	sub	x20, x2, x26
   29f0c:	mov	x24, x1
   29f10:	add	x1, x1, x26, lsl #3
   29f14:	mov	x2, x20
   29f18:	mov	x29, sp
   29f1c:	mov	x22, x4
   29f20:	mov	x19, x0
   29f24:	bl	d4b0 <__gmpn_mul_1@plt>
   29f28:	mov	x21, x0
   29f2c:	mov	x25, xzr
   29f30:	cbz	x26, 29f74 <__gmpn_mulmid_basecase@@Base+0x8c>
   29f34:	add	x8, x24, x22, lsl #3
   29f38:	sub	x22, x8, #0x10
   29f3c:	add	x23, x23, #0x8
   29f40:	ldr	x3, [x23], #8
   29f44:	mov	x0, x19
   29f48:	mov	x1, x22
   29f4c:	mov	x2, x20
   29f50:	bl	d420 <__gmpn_addmul_1@plt>
   29f54:	mov	x9, xzr
   29f58:	adds	x8, x21, x0
   29f5c:	adc	x25, x25, x9
   29f60:	sub	x26, x26, #0x1
   29f64:	sub	x22, x22, #0x8
   29f68:	mov	x21, x8
   29f6c:	cbnz	x26, 29f40 <__gmpn_mulmid_basecase@@Base+0x58>
   29f70:	mov	x21, x8
   29f74:	add	x8, x19, x20, lsl #3
   29f78:	stp	x21, x25, [x8]
   29f7c:	ldp	x20, x19, [sp, #64]
   29f80:	ldp	x22, x21, [sp, #48]
   29f84:	ldp	x24, x23, [sp, #32]
   29f88:	ldp	x26, x25, [sp, #16]
   29f8c:	ldp	x29, x30, [sp], #80
   29f90:	ret

0000000000029f94 <__gmpn_toom42_mulmid@@Base>:
   29f94:	sub	sp, sp, #0x110
   29f98:	cmp	x3, #0x0
   29f9c:	stp	x20, x19, [sp, #256]
   29fa0:	and	x8, x3, #0x1
   29fa4:	cinc	x19, x3, lt  // lt = tstop
   29fa8:	stp	x28, x27, [sp, #192]
   29fac:	stp	x24, x23, [sp, #224]
   29fb0:	add	x28, x1, x8, lsl #3
   29fb4:	asr	x24, x19, #1
   29fb8:	stp	x26, x25, [sp, #208]
   29fbc:	add	x27, x4, #0x10
   29fc0:	add	x20, x28, x24, lsl #3
   29fc4:	add	x25, x2, x24, lsl #3
   29fc8:	stp	x22, x21, [sp, #240]
   29fcc:	mov	x22, x2
   29fd0:	mov	x21, x0
   29fd4:	str	x4, [sp, #32]
   29fd8:	str	x3, [sp, #48]
   29fdc:	sub	x5, x24, #0x1
   29fe0:	add	x3, sp, #0x48
   29fe4:	mov	x0, x27
   29fe8:	mov	x1, x28
   29fec:	mov	x2, x20
   29ff0:	mov	x4, x25
   29ff4:	mov	x6, xzr
   29ff8:	stp	x29, x30, [sp, #176]
   29ffc:	add	x29, sp, #0xb0
   2a000:	str	x8, [sp, #8]
   2a004:	bl	cd10 <__gmpn_add_err1_n@plt>
   2a008:	add	x9, x27, x24, lsl #3
   2a00c:	add	x8, x28, x24, lsl #4
   2a010:	stp	x9, x20, [sp, #16]
   2a014:	sub	x20, x20, #0x8
   2a018:	sub	x26, x8, #0x8
   2a01c:	add	x8, sp, #0x48
   2a020:	mov	x7, x0
   2a024:	sub	x0, x9, #0x8
   2a028:	add	x3, x8, #0x10
   2a02c:	mov	x1, x20
   2a030:	mov	x2, x26
   2a034:	mov	x4, x25
   2a038:	mov	x5, x22
   2a03c:	mov	x6, x24
   2a040:	and	x23, x19, #0xfffffffffffffffe
   2a044:	bl	c650 <__gmpn_add_err2_n@plt>
   2a048:	add	x8, x27, x24, lsl #4
   2a04c:	add	x19, x23, x19, asr #1
   2a050:	mov	x6, x0
   2a054:	sub	x0, x8, #0x8
   2a058:	add	x8, x28, x19, lsl #3
   2a05c:	sub	x2, x8, #0x8
   2a060:	add	x8, sp, #0x48
   2a064:	add	x3, x8, #0x30
   2a068:	mov	x1, x26
   2a06c:	mov	x4, x22
   2a070:	mov	x5, x24
   2a074:	str	x27, [sp, #56]
   2a078:	str	x23, [sp, #40]
   2a07c:	str	x28, [sp]
   2a080:	bl	cd10 <__gmpn_add_err1_n@plt>
   2a084:	sub	x8, x22, #0x8
   2a088:	lsl	x9, x24, #4
   2a08c:	mov	x10, x24
   2a090:	str	x22, [sp, #64]
   2a094:	subs	x11, x10, #0x1
   2a098:	b.lt	2a0b8 <__gmpn_toom42_mulmid@@Base+0x124>  // b.tstop
   2a09c:	ldr	x12, [x8, x9]
   2a0a0:	ldr	x10, [x8, x10, lsl #3]
   2a0a4:	sub	x9, x9, #0x8
   2a0a8:	cmp	x12, x10
   2a0ac:	mov	x10, x11
   2a0b0:	b.eq	2a094 <__gmpn_toom42_mulmid@@Base+0x100>  // b.none
   2a0b4:	b.ls	2a0f0 <__gmpn_toom42_mulmid@@Base+0x15c>  // b.plast
   2a0b8:	ldr	x2, [sp, #64]
   2a0bc:	add	x28, x21, x24, lsl #3
   2a0c0:	add	x8, sp, #0x48
   2a0c4:	add	x27, x28, #0x10
   2a0c8:	add	x3, x8, #0x40
   2a0cc:	mov	x0, x27
   2a0d0:	mov	x1, x25
   2a0d4:	mov	x4, x20
   2a0d8:	mov	x5, x26
   2a0dc:	mov	x6, x24
   2a0e0:	mov	x7, xzr
   2a0e4:	bl	d390 <__gmpn_sub_err2_n@plt>
   2a0e8:	mov	w26, wzr
   2a0ec:	b	2a124 <__gmpn_toom42_mulmid@@Base+0x190>
   2a0f0:	ldr	x1, [sp, #64]
   2a0f4:	add	x28, x21, x24, lsl #3
   2a0f8:	add	x8, sp, #0x48
   2a0fc:	add	x27, x28, #0x10
   2a100:	add	x3, x8, #0x40
   2a104:	mov	x0, x27
   2a108:	mov	x2, x25
   2a10c:	mov	x4, x20
   2a110:	mov	x5, x26
   2a114:	mov	x6, x24
   2a118:	mov	x7, xzr
   2a11c:	bl	d390 <__gmpn_sub_err2_n@plt>
   2a120:	mov	w26, #0x1                   	// #1
   2a124:	ldr	x22, [sp, #48]
   2a128:	ldr	x23, [sp, #32]
   2a12c:	cmp	x22, #0x27
   2a130:	b.gt	2a1a4 <__gmpn_toom42_mulmid@@Base+0x210>
   2a134:	ldr	x19, [sp, #40]
   2a138:	ldr	x1, [sp, #56]
   2a13c:	mov	x0, x21
   2a140:	mov	x3, x25
   2a144:	sub	x20, x19, #0x1
   2a148:	mov	x2, x20
   2a14c:	mov	x4, x24
   2a150:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2a154:	add	x8, x21, x24, lsl #3
   2a158:	ldp	x9, x8, [x8]
   2a15c:	ldp	x10, x11, [sp, #88]
   2a160:	ldr	x1, [sp, #24]
   2a164:	mov	x0, x23
   2a168:	mov	x2, x20
   2a16c:	adds	x9, x9, x10
   2a170:	cinc	x8, x8, cs  // cs = hs, nlast
   2a174:	add	x8, x8, x11
   2a178:	mov	x3, x27
   2a17c:	mov	x4, x24
   2a180:	stp	x9, x8, [sp, #88]
   2a184:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2a188:	ldr	x1, [sp, #16]
   2a18c:	ldr	x3, [sp, #64]
   2a190:	mov	x0, x28
   2a194:	mov	x2, x20
   2a198:	mov	x4, x24
   2a19c:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2a1a0:	b	2a214 <__gmpn_toom42_mulmid@@Base+0x280>
   2a1a4:	ldr	x1, [sp, #56]
   2a1a8:	add	x8, x23, x19, lsl #3
   2a1ac:	add	x20, x8, #0x8
   2a1b0:	mov	x0, x21
   2a1b4:	mov	x2, x25
   2a1b8:	mov	x3, x24
   2a1bc:	mov	x4, x20
   2a1c0:	bl	c7b0 <__gmpn_toom42_mulmid@plt>
   2a1c4:	add	x8, x21, x24, lsl #3
   2a1c8:	ldp	x9, x8, [x8]
   2a1cc:	ldp	x10, x11, [sp, #88]
   2a1d0:	ldr	x1, [sp, #24]
   2a1d4:	mov	x0, x23
   2a1d8:	mov	x2, x27
   2a1dc:	adds	x9, x9, x10
   2a1e0:	cinc	x8, x8, cs  // cs = hs, nlast
   2a1e4:	add	x8, x8, x11
   2a1e8:	mov	x3, x24
   2a1ec:	mov	x4, x20
   2a1f0:	stp	x9, x8, [sp, #88]
   2a1f4:	bl	c7b0 <__gmpn_toom42_mulmid@plt>
   2a1f8:	ldr	x1, [sp, #16]
   2a1fc:	ldr	x2, [sp, #64]
   2a200:	mov	x0, x28
   2a204:	mov	x3, x24
   2a208:	mov	x4, x20
   2a20c:	bl	c7b0 <__gmpn_toom42_mulmid@plt>
   2a210:	ldr	x19, [sp, #40]
   2a214:	ldr	x8, [sp, #72]
   2a218:	ldp	x9, x10, [x21]
   2a21c:	subs	x8, x9, x8
   2a220:	str	x8, [x21]
   2a224:	ldr	x8, [sp, #80]
   2a228:	cinc	x8, x8, cc  // cc = lo, ul, last
   2a22c:	subs	x8, x10, x8
   2a230:	str	x8, [x21, #8]
   2a234:	b.cc	2a4a8 <__gmpn_toom42_mulmid@@Base+0x514>  // b.lo, b.ul, b.last
   2a238:	ldp	x8, x9, [sp, #88]
   2a23c:	ldp	x10, x12, [sp, #104]
   2a240:	ldr	x11, [x21, x24, lsl #3]
   2a244:	subs	x8, x8, x10
   2a248:	cset	w10, cc  // cc = lo, ul, last
   2a24c:	adds	x11, x11, x8
   2a250:	add	x8, x24, #0x1
   2a254:	str	x11, [x21, x24, lsl #3]
   2a258:	ldr	x11, [x21, x8, lsl #3]
   2a25c:	sub	x9, x9, x12
   2a260:	sub	x9, x9, x10
   2a264:	cinc	x9, x9, cs  // cs = hs, nlast
   2a268:	adds	x10, x9, x11
   2a26c:	asr	x9, x9, #63
   2a270:	cinc	x9, x9, cs  // cs = hs, nlast
   2a274:	str	x10, [x21, x8, lsl #3]
   2a278:	cbnz	x9, 2a4f4 <__gmpn_toom42_mulmid@@Base+0x560>
   2a27c:	ldr	x9, [x21, x19, lsl #3]
   2a280:	ldr	x10, [sp, #120]
   2a284:	lsl	x11, x19, #3
   2a288:	orr	x11, x11, #0x8
   2a28c:	adds	x9, x10, x9
   2a290:	str	x9, [x21, x19, lsl #3]
   2a294:	ldr	x9, [x21, x11]
   2a298:	ldr	x10, [sp, #128]
   2a29c:	add	x9, x10, x9
   2a2a0:	cinc	x9, x9, cs  // cs = hs, nlast
   2a2a4:	str	x9, [x21, x11]
   2a2a8:	ldr	x9, [sp, #136]
   2a2ac:	ldp	x10, x11, [x23]
   2a2b0:	adds	x9, x9, x10
   2a2b4:	str	x9, [x23]
   2a2b8:	ldr	x9, [sp, #144]
   2a2bc:	cinc	x10, x11, cs  // cs = hs, nlast
   2a2c0:	add	x9, x10, x9
   2a2c4:	cmp	x9, x11
   2a2c8:	str	x9, [x23, #8]
   2a2cc:	b.cc	2a530 <__gmpn_toom42_mulmid@@Base+0x59c>  // b.lo, b.ul, b.last
   2a2d0:	ldr	x9, [x23, x24, lsl #3]
   2a2d4:	ldr	x10, [sp, #152]
   2a2d8:	subs	x9, x9, x10
   2a2dc:	str	x9, [x23, x24, lsl #3]
   2a2e0:	ldr	x9, [x23, x8, lsl #3]
   2a2e4:	ldr	x10, [sp, #160]
   2a2e8:	cset	w11, cc  // cc = lo, ul, last
   2a2ec:	sub	x9, x9, x10
   2a2f0:	sub	x9, x9, x11
   2a2f4:	str	x9, [x23, x8, lsl #3]
   2a2f8:	ldr	x8, [x27]
   2a2fc:	lsr	x9, x9, #63
   2a300:	cbz	w26, 2a390 <__gmpn_toom42_mulmid@@Base+0x3fc>
   2a304:	subs	x8, x8, x9
   2a308:	str	x8, [x27]
   2a30c:	b.cs	2a330 <__gmpn_toom42_mulmid@@Base+0x39c>  // b.hs, b.nlast
   2a310:	mov	w8, #0x1                   	// #1
   2a314:	cmp	x8, x24
   2a318:	b.ge	2a330 <__gmpn_toom42_mulmid@@Base+0x39c>  // b.tcont
   2a31c:	ldr	x9, [x27, x8, lsl #3]
   2a320:	sub	x10, x9, #0x1
   2a324:	str	x10, [x27, x8, lsl #3]
   2a328:	add	x8, x8, #0x1
   2a32c:	cbz	x9, 2a314 <__gmpn_toom42_mulmid@@Base+0x380>
   2a330:	adds	x20, x24, #0x2
   2a334:	b.eq	2a378 <__gmpn_toom42_mulmid@@Base+0x3e4>  // b.none
   2a338:	mov	x0, x21
   2a33c:	mov	x1, x21
   2a340:	mov	x2, x23
   2a344:	mov	x3, x20
   2a348:	bl	ca90 <__gmpn_add_n@plt>
   2a34c:	cbz	x0, 2a378 <__gmpn_toom42_mulmid@@Base+0x3e4>
   2a350:	add	x8, x19, #0x2
   2a354:	mov	x9, x20
   2a358:	cmp	x9, x8
   2a35c:	b.ge	2a378 <__gmpn_toom42_mulmid@@Base+0x3e4>  // b.tcont
   2a360:	ldr	x10, [x21, x9, lsl #3]
   2a364:	add	x11, x9, #0x1
   2a368:	adds	x10, x10, #0x1
   2a36c:	str	x10, [x21, x9, lsl #3]
   2a370:	mov	x9, x11
   2a374:	b.cs	2a358 <__gmpn_toom42_mulmid@@Base+0x3c4>  // b.hs, b.nlast
   2a378:	mov	x0, x28
   2a37c:	mov	x1, x28
   2a380:	mov	x2, x23
   2a384:	mov	x3, x20
   2a388:	bl	c2e0 <__gmpn_sub_n@plt>
   2a38c:	b	2a418 <__gmpn_toom42_mulmid@@Base+0x484>
   2a390:	adds	x8, x9, x8
   2a394:	str	x8, [x27]
   2a398:	b.cc	2a3bc <__gmpn_toom42_mulmid@@Base+0x428>  // b.lo, b.ul, b.last
   2a39c:	mov	w8, #0x1                   	// #1
   2a3a0:	cmp	x8, x24
   2a3a4:	b.ge	2a3bc <__gmpn_toom42_mulmid@@Base+0x428>  // b.tcont
   2a3a8:	ldr	x9, [x27, x8, lsl #3]
   2a3ac:	adds	x9, x9, #0x1
   2a3b0:	str	x9, [x27, x8, lsl #3]
   2a3b4:	add	x8, x8, #0x1
   2a3b8:	b.cs	2a3a0 <__gmpn_toom42_mulmid@@Base+0x40c>  // b.hs, b.nlast
   2a3bc:	adds	x20, x24, #0x2
   2a3c0:	b.eq	2a404 <__gmpn_toom42_mulmid@@Base+0x470>  // b.none
   2a3c4:	mov	x0, x21
   2a3c8:	mov	x1, x21
   2a3cc:	mov	x2, x23
   2a3d0:	mov	x3, x20
   2a3d4:	bl	c2e0 <__gmpn_sub_n@plt>
   2a3d8:	cbz	x0, 2a404 <__gmpn_toom42_mulmid@@Base+0x470>
   2a3dc:	add	x8, x19, #0x2
   2a3e0:	mov	x9, x20
   2a3e4:	cmp	x9, x8
   2a3e8:	b.ge	2a404 <__gmpn_toom42_mulmid@@Base+0x470>  // b.tcont
   2a3ec:	ldr	x10, [x21, x9, lsl #3]
   2a3f0:	add	x12, x9, #0x1
   2a3f4:	sub	x11, x10, #0x1
   2a3f8:	str	x11, [x21, x9, lsl #3]
   2a3fc:	mov	x9, x12
   2a400:	cbz	x10, 2a3e4 <__gmpn_toom42_mulmid@@Base+0x450>
   2a404:	mov	x0, x28
   2a408:	mov	x1, x28
   2a40c:	mov	x2, x23
   2a410:	mov	x3, x20
   2a414:	bl	ca90 <__gmpn_add_n@plt>
   2a418:	ldr	x8, [sp, #8]
   2a41c:	cbz	x8, 2a488 <__gmpn_toom42_mulmid@@Base+0x4f4>
   2a420:	sub	x20, x22, #0x1
   2a424:	mov	x23, x22
   2a428:	ldr	x22, [sp, #64]
   2a42c:	ldr	x24, [sp]
   2a430:	mov	x0, x21
   2a434:	mov	x2, x23
   2a438:	ldr	x3, [x22, x20, lsl #3]
   2a43c:	sub	x1, x24, #0x8
   2a440:	bl	d420 <__gmpn_addmul_1@plt>
   2a444:	add	x19, x21, x23, lsl #3
   2a448:	ldr	x8, [x19]
   2a44c:	add	x9, x24, x23, lsl #3
   2a450:	sub	x1, x9, #0x8
   2a454:	mov	x2, x20
   2a458:	adds	x8, x8, x0
   2a45c:	cset	w10, cs  // cs = hs, nlast
   2a460:	add	x0, sp, #0x48
   2a464:	mov	x3, x22
   2a468:	mov	x4, x20
   2a46c:	stp	x8, x10, [x19]
   2a470:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2a474:	sub	x0, x19, #0x8
   2a478:	add	x2, sp, #0x48
   2a47c:	mov	w3, #0x3                   	// #3
   2a480:	mov	x1, x0
   2a484:	bl	ca90 <__gmpn_add_n@plt>
   2a488:	ldp	x20, x19, [sp, #256]
   2a48c:	ldp	x22, x21, [sp, #240]
   2a490:	ldp	x24, x23, [sp, #224]
   2a494:	ldp	x26, x25, [sp, #208]
   2a498:	ldp	x28, x27, [sp, #192]
   2a49c:	ldp	x29, x30, [sp, #176]
   2a4a0:	add	sp, sp, #0x110
   2a4a4:	ret
   2a4a8:	cmp	x22, #0x6
   2a4ac:	b.lt	2a56c <__gmpn_toom42_mulmid@@Base+0x5d8>  // b.tstop
   2a4b0:	ldr	x8, [x21, #16]
   2a4b4:	sub	x9, x8, #0x1
   2a4b8:	str	x9, [x21, #16]
   2a4bc:	cbnz	x8, 2a4ec <__gmpn_toom42_mulmid@@Base+0x558>
   2a4c0:	sub	x9, x24, #0x2
   2a4c4:	mov	w10, #0x3                   	// #3
   2a4c8:	mov	w8, #0x1                   	// #1
   2a4cc:	sub	x11, x10, #0x2
   2a4d0:	cmp	x11, x9
   2a4d4:	b.ge	2a570 <__gmpn_toom42_mulmid@@Base+0x5dc>  // b.tcont
   2a4d8:	ldr	x11, [x21, x10, lsl #3]
   2a4dc:	sub	x12, x11, #0x1
   2a4e0:	str	x12, [x21, x10, lsl #3]
   2a4e4:	add	x10, x10, #0x1
   2a4e8:	cbz	x11, 2a4cc <__gmpn_toom42_mulmid@@Base+0x538>
   2a4ec:	mov	x8, xzr
   2a4f0:	b	2a570 <__gmpn_toom42_mulmid@@Base+0x5dc>
   2a4f4:	cmp	x9, #0x1
   2a4f8:	b.ne	2a588 <__gmpn_toom42_mulmid@@Base+0x5f4>  // b.any
   2a4fc:	ldr	x9, [x27]
   2a500:	adds	x9, x9, #0x1
   2a504:	str	x9, [x27]
   2a508:	b.cc	2a27c <__gmpn_toom42_mulmid@@Base+0x2e8>  // b.lo, b.ul, b.last
   2a50c:	mov	w9, #0x1                   	// #1
   2a510:	cmp	x9, x24
   2a514:	b.ge	2a27c <__gmpn_toom42_mulmid@@Base+0x2e8>  // b.tcont
   2a518:	ldr	x10, [x27, x9, lsl #3]
   2a51c:	adds	x10, x10, #0x1
   2a520:	str	x10, [x27, x9, lsl #3]
   2a524:	add	x9, x9, #0x1
   2a528:	b.cs	2a510 <__gmpn_toom42_mulmid@@Base+0x57c>  // b.hs, b.nlast
   2a52c:	b	2a27c <__gmpn_toom42_mulmid@@Base+0x2e8>
   2a530:	ldr	x10, [sp, #56]
   2a534:	ldr	x9, [x10]
   2a538:	adds	x9, x9, #0x1
   2a53c:	str	x9, [x10]
   2a540:	b.cc	2a2d0 <__gmpn_toom42_mulmid@@Base+0x33c>  // b.lo, b.ul, b.last
   2a544:	mov	w9, #0x3                   	// #3
   2a548:	sub	x10, x9, #0x2
   2a54c:	cmp	x10, x24
   2a550:	b.ge	2a2d0 <__gmpn_toom42_mulmid@@Base+0x33c>  // b.tcont
   2a554:	ldr	x10, [x23, x9, lsl #3]
   2a558:	adds	x10, x10, #0x1
   2a55c:	str	x10, [x23, x9, lsl #3]
   2a560:	add	x9, x9, #0x1
   2a564:	b.cs	2a548 <__gmpn_toom42_mulmid@@Base+0x5b4>  // b.hs, b.nlast
   2a568:	b	2a2d0 <__gmpn_toom42_mulmid@@Base+0x33c>
   2a56c:	mov	w8, #0x1                   	// #1
   2a570:	ldp	x9, x10, [sp, #88]
   2a574:	subs	x8, x9, x8
   2a578:	cset	w9, cc  // cc = lo, ul, last
   2a57c:	sub	x9, x10, x9
   2a580:	stp	x8, x9, [sp, #88]
   2a584:	b	2a23c <__gmpn_toom42_mulmid@@Base+0x2a8>
   2a588:	ldr	x9, [x27]
   2a58c:	sub	x10, x9, #0x1
   2a590:	str	x10, [x27]
   2a594:	cbnz	x9, 2a27c <__gmpn_toom42_mulmid@@Base+0x2e8>
   2a598:	mov	w9, #0x1                   	// #1
   2a59c:	cmp	x9, x24
   2a5a0:	b.ge	2a27c <__gmpn_toom42_mulmid@@Base+0x2e8>  // b.tcont
   2a5a4:	ldr	x10, [x27, x9, lsl #3]
   2a5a8:	sub	x11, x10, #0x1
   2a5ac:	str	x11, [x27, x9, lsl #3]
   2a5b0:	add	x9, x9, #0x1
   2a5b4:	cbz	x10, 2a59c <__gmpn_toom42_mulmid@@Base+0x608>
   2a5b8:	b	2a27c <__gmpn_toom42_mulmid@@Base+0x2e8>

000000000002a5bc <__gmpn_mulmid_n@@Base>:
   2a5bc:	stp	x29, x30, [sp, #-48]!
   2a5c0:	stp	x22, x21, [sp, #16]
   2a5c4:	stp	x20, x19, [sp, #32]
   2a5c8:	mov	x29, sp
   2a5cc:	sub	sp, sp, #0x10
   2a5d0:	mov	x19, x3
   2a5d4:	mov	x20, x2
   2a5d8:	mov	x21, x1
   2a5dc:	cmp	x3, #0x13
   2a5e0:	mov	x22, x0
   2a5e4:	b.gt	2a614 <__gmpn_mulmid_n@@Base+0x58>
   2a5e8:	lsl	x8, x19, #1
   2a5ec:	sub	x2, x8, #0x1
   2a5f0:	mov	x0, x22
   2a5f4:	mov	x1, x21
   2a5f8:	mov	x3, x20
   2a5fc:	mov	x4, x19
   2a600:	mov	sp, x29
   2a604:	ldp	x20, x19, [sp, #32]
   2a608:	ldp	x22, x21, [sp, #16]
   2a60c:	ldp	x29, x30, [sp], #48
   2a610:	b	c480 <__gmpn_mulmid_basecase@plt>
   2a614:	mov	w8, #0x18                  	// #24
   2a618:	orr	x9, xzr, #0x200
   2a61c:	madd	x1, x19, x8, x9
   2a620:	mov	w8, #0x7f00                	// #32512
   2a624:	cmp	x1, x8
   2a628:	stur	xzr, [x29, #-8]
   2a62c:	b.hi	2a674 <__gmpn_mulmid_n@@Base+0xb8>  // b.pmore
   2a630:	add	x9, x1, #0xf
   2a634:	mov	x8, sp
   2a638:	and	x9, x9, #0xfffffffffffffff0
   2a63c:	sub	x4, x8, x9
   2a640:	mov	sp, x4
   2a644:	mov	x0, x22
   2a648:	mov	x1, x21
   2a64c:	mov	x2, x20
   2a650:	mov	x3, x19
   2a654:	bl	c7b0 <__gmpn_toom42_mulmid@plt>
   2a658:	ldur	x0, [x29, #-8]
   2a65c:	cbnz	x0, 2a684 <__gmpn_mulmid_n@@Base+0xc8>
   2a660:	mov	sp, x29
   2a664:	ldp	x20, x19, [sp, #32]
   2a668:	ldp	x22, x21, [sp, #16]
   2a66c:	ldp	x29, x30, [sp], #48
   2a670:	ret
   2a674:	sub	x0, x29, #0x8
   2a678:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2a67c:	mov	x4, x0
   2a680:	b	2a644 <__gmpn_mulmid_n@@Base+0x88>
   2a684:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2a688:	b	2a660 <__gmpn_mulmid_n@@Base+0xa4>

000000000002a68c <__gmpn_mulmid@@Base>:
   2a68c:	stp	x29, x30, [sp, #-96]!
   2a690:	stp	x28, x27, [sp, #16]
   2a694:	stp	x26, x25, [sp, #32]
   2a698:	stp	x24, x23, [sp, #48]
   2a69c:	stp	x22, x21, [sp, #64]
   2a6a0:	stp	x20, x19, [sp, #80]
   2a6a4:	mov	x29, sp
   2a6a8:	sub	sp, sp, #0x30
   2a6ac:	mov	x20, x4
   2a6b0:	mov	x22, x3
   2a6b4:	mov	x24, x2
   2a6b8:	mov	x19, x1
   2a6bc:	cmp	x4, #0x13
   2a6c0:	mov	x21, x0
   2a6c4:	b.gt	2a704 <__gmpn_mulmid@@Base+0x78>
   2a6c8:	cmp	x24, #0xdb
   2a6cc:	b.gt	2a734 <__gmpn_mulmid@@Base+0xa8>
   2a6d0:	mov	x0, x21
   2a6d4:	mov	x1, x19
   2a6d8:	mov	x2, x24
   2a6dc:	mov	x3, x22
   2a6e0:	mov	x4, x20
   2a6e4:	mov	sp, x29
   2a6e8:	ldp	x20, x19, [sp, #80]
   2a6ec:	ldp	x22, x21, [sp, #64]
   2a6f0:	ldp	x24, x23, [sp, #48]
   2a6f4:	ldp	x26, x25, [sp, #32]
   2a6f8:	ldp	x28, x27, [sp, #16]
   2a6fc:	ldp	x29, x30, [sp], #96
   2a700:	b	c480 <__gmpn_mulmid_basecase@plt>
   2a704:	sub	x28, x24, x20
   2a708:	cmp	x28, #0x13
   2a70c:	b.ge	2a7e0 <__gmpn_mulmid@@Base+0x154>  // b.tcont
   2a710:	cmp	x20, #0xdb
   2a714:	b.gt	2a920 <__gmpn_mulmid@@Base+0x294>
   2a718:	mov	x0, x21
   2a71c:	mov	x1, x19
   2a720:	mov	x2, x24
   2a724:	mov	x3, x22
   2a728:	mov	x4, x20
   2a72c:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2a730:	b	2ab98 <__gmpn_mulmid@@Base+0x50c>
   2a734:	mov	w8, #0xdd                  	// #221
   2a738:	mov	w2, #0xdc                  	// #220
   2a73c:	mov	x0, x21
   2a740:	mov	x1, x19
   2a744:	mov	x3, x22
   2a748:	mov	x4, x20
   2a74c:	sub	x25, x8, x20
   2a750:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2a754:	sub	x23, x24, x25
   2a758:	cmp	x23, #0xdc
   2a75c:	b.lt	2a9fc <__gmpn_mulmid@@Base+0x370>  // b.tstop
   2a760:	mov	w8, #0x6e8                 	// #1768
   2a764:	mov	w9, #0x6f8                 	// #1784
   2a768:	sub	x26, x8, x20, lsl #3
   2a76c:	sub	x8, x9, x20, lsl #3
   2a770:	stur	x8, [x29, #-16]
   2a774:	add	x24, x21, x26
   2a778:	ldp	x28, x27, [x24]
   2a77c:	add	x19, x19, x25, lsl #3
   2a780:	mov	w2, #0xdc                  	// #220
   2a784:	mov	x0, x24
   2a788:	mov	x1, x19
   2a78c:	mov	x3, x22
   2a790:	mov	x4, x20
   2a794:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2a798:	ldp	x8, x9, [x24]
   2a79c:	adds	x8, x8, x28
   2a7a0:	str	x8, [x24]
   2a7a4:	cinc	x8, x27, cs  // cs = hs, nlast
   2a7a8:	adds	x8, x9, x8
   2a7ac:	str	x8, [x24, #8]
   2a7b0:	b.cc	2a7cc <__gmpn_mulmid@@Base+0x140>  // b.lo, b.ul, b.last
   2a7b4:	ldur	x8, [x29, #-16]
   2a7b8:	ldr	x9, [x21, x8]
   2a7bc:	adds	x9, x9, #0x1
   2a7c0:	str	x9, [x21, x8]
   2a7c4:	add	x8, x8, #0x8
   2a7c8:	b.cs	2a7b8 <__gmpn_mulmid@@Base+0x12c>  // b.hs, b.nlast
   2a7cc:	sub	x23, x23, x25
   2a7d0:	cmp	x23, #0xdb
   2a7d4:	mov	x21, x24
   2a7d8:	b.gt	2a774 <__gmpn_mulmid@@Base+0xe8>
   2a7dc:	b	2aa00 <__gmpn_mulmid@@Base+0x374>
   2a7e0:	add	x23, x28, #0x1
   2a7e4:	subs	x26, x23, x20
   2a7e8:	b.ge	2aa64 <__gmpn_mulmid@@Base+0x3d8>  // b.tcont
   2a7ec:	add	x8, x23, x23, lsl #1
   2a7f0:	add	x8, x28, x8
   2a7f4:	lsl	x8, x8, #3
   2a7f8:	add	x1, x8, #0x218
   2a7fc:	mov	w8, #0x7f00                	// #32512
   2a800:	cmp	x1, x8
   2a804:	add	x8, x28, #0x3
   2a808:	stp	x8, xzr, [x29, #-16]
   2a80c:	b.hi	2abb8 <__gmpn_mulmid@@Base+0x52c>  // b.pmore
   2a810:	add	x9, x1, #0xf
   2a814:	mov	x8, sp
   2a818:	and	x9, x9, #0xfffffffffffffff0
   2a81c:	sub	x26, x8, x9
   2a820:	mov	sp, x26
   2a824:	add	x8, x26, x23, lsl #3
   2a828:	sub	x27, x20, x23
   2a82c:	add	x4, x8, #0x10
   2a830:	add	x2, x22, x27, lsl #3
   2a834:	mov	x0, x21
   2a838:	mov	x1, x19
   2a83c:	mov	x3, x23
   2a840:	mov	x25, x2
   2a844:	stur	x4, [x29, #-40]
   2a848:	bl	c7b0 <__gmpn_toom42_mulmid@plt>
   2a84c:	cmp	x27, x28
   2a850:	b.le	2a8ec <__gmpn_mulmid@@Base+0x260>
   2a854:	lsl	x10, x24, #3
   2a858:	stur	x10, [x29, #-48]
   2a85c:	sub	x10, x10, x20, lsl #3
   2a860:	lsl	x8, x20, #3
   2a864:	mov	w9, #0x18                  	// #24
   2a868:	add	x10, x10, #0x8
   2a86c:	ldur	x25, [x29, #-40]
   2a870:	sub	x8, x8, x24, lsl #3
   2a874:	mul	x9, x20, x9
   2a878:	stp	x10, x28, [x29, #-32]
   2a87c:	mov	x10, x24
   2a880:	sub	x24, x8, #0x8
   2a884:	sub	x8, x9, x10, lsl #4
   2a888:	sub	x28, x8, #0x10
   2a88c:	ldur	x8, [x29, #-32]
   2a890:	add	x2, x22, x28
   2a894:	mov	x0, x26
   2a898:	mov	x3, x23
   2a89c:	add	x19, x19, x8
   2a8a0:	mov	x1, x19
   2a8a4:	mov	x4, x25
   2a8a8:	bl	c7b0 <__gmpn_toom42_mulmid@plt>
   2a8ac:	ldur	x3, [x29, #-16]
   2a8b0:	mov	x0, x21
   2a8b4:	mov	x1, x21
   2a8b8:	mov	x2, x26
   2a8bc:	bl	ca90 <__gmpn_add_n@plt>
   2a8c0:	ldur	x8, [x29, #-24]
   2a8c4:	sub	x27, x27, x23
   2a8c8:	add	x22, x22, x24
   2a8cc:	cmp	x27, x8
   2a8d0:	b.gt	2a88c <__gmpn_mulmid@@Base+0x200>
   2a8d4:	ldur	x9, [x29, #-48]
   2a8d8:	lsl	x8, x20, #4
   2a8dc:	ldur	x28, [x29, #-24]
   2a8e0:	sub	x8, x8, x9
   2a8e4:	add	x8, x8, x22
   2a8e8:	sub	x25, x8, #0x8
   2a8ec:	ldur	x20, [x29, #-16]
   2a8f0:	cbz	x27, 2a9ec <__gmpn_mulmid@@Base+0x360>
   2a8f4:	add	x1, x19, x23, lsl #3
   2a8f8:	sub	x3, x25, x27, lsl #3
   2a8fc:	add	x2, x27, x28
   2a900:	mov	x0, x26
   2a904:	mov	x4, x27
   2a908:	bl	c720 <__gmpn_mulmid@plt>
   2a90c:	mov	x0, x21
   2a910:	mov	x1, x21
   2a914:	mov	x2, x26
   2a918:	mov	x3, x20
   2a91c:	b	2a9e8 <__gmpn_mulmid@@Base+0x35c>
   2a920:	add	x23, x28, #0x3
   2a924:	lsl	x1, x23, #3
   2a928:	mov	w8, #0x7f00                	// #32512
   2a92c:	cmp	x1, x8
   2a930:	stur	xzr, [x29, #-8]
   2a934:	b.hi	2abc8 <__gmpn_mulmid@@Base+0x53c>  // b.pmore
   2a938:	add	x9, x1, #0xf
   2a93c:	mov	x8, sp
   2a940:	and	x9, x9, #0xfffffffffffffff0
   2a944:	sub	x25, x8, x9
   2a948:	mov	sp, x25
   2a94c:	sub	x26, x20, #0xdc
   2a950:	add	x22, x22, x26, lsl #3
   2a954:	sub	x24, x24, x26
   2a958:	mov	w4, #0xdc                  	// #220
   2a95c:	mov	x0, x21
   2a960:	mov	x1, x19
   2a964:	mov	x2, x24
   2a968:	mov	x3, x22
   2a96c:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2a970:	cmp	x20, #0x1b8
   2a974:	b.lt	2a9bc <__gmpn_mulmid@@Base+0x330>  // b.tstop
   2a978:	add	x19, x19, #0x6e0
   2a97c:	sub	x22, x22, #0x6e0
   2a980:	mov	w4, #0xdc                  	// #220
   2a984:	mov	x0, x25
   2a988:	mov	x1, x19
   2a98c:	mov	x2, x24
   2a990:	mov	x3, x22
   2a994:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2a998:	mov	x0, x21
   2a99c:	mov	x1, x21
   2a9a0:	mov	x2, x25
   2a9a4:	mov	x3, x23
   2a9a8:	bl	ca90 <__gmpn_add_n@plt>
   2a9ac:	sub	x20, x20, #0xdc
   2a9b0:	cmp	x20, #0x1b7
   2a9b4:	b.gt	2a978 <__gmpn_mulmid@@Base+0x2ec>
   2a9b8:	sub	x26, x20, #0xdc
   2a9bc:	cbz	x26, 2a9ec <__gmpn_mulmid@@Base+0x360>
   2a9c0:	add	x1, x19, #0x6e0
   2a9c4:	sub	x3, x22, x26, lsl #3
   2a9c8:	add	x2, x26, x28
   2a9cc:	mov	x0, x25
   2a9d0:	mov	x4, x26
   2a9d4:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2a9d8:	mov	x0, x21
   2a9dc:	mov	x1, x21
   2a9e0:	mov	x2, x25
   2a9e4:	mov	x3, x23
   2a9e8:	bl	ca90 <__gmpn_add_n@plt>
   2a9ec:	ldur	x0, [x29, #-8]
   2a9f0:	cbz	x0, 2ab98 <__gmpn_mulmid@@Base+0x50c>
   2a9f4:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2a9f8:	b	2ab98 <__gmpn_mulmid@@Base+0x50c>
   2a9fc:	mov	x24, x21
   2aa00:	cmp	x23, x20
   2aa04:	b.lt	2ab98 <__gmpn_mulmid@@Base+0x50c>  // b.tstop
   2aa08:	add	x21, x24, x25, lsl #3
   2aa0c:	ldp	x26, x27, [x21]
   2aa10:	add	x1, x19, x25, lsl #3
   2aa14:	mov	x0, x21
   2aa18:	mov	x2, x23
   2aa1c:	mov	x3, x22
   2aa20:	mov	x4, x20
   2aa24:	bl	c480 <__gmpn_mulmid_basecase@plt>
   2aa28:	ldp	x8, x9, [x21]
   2aa2c:	adds	x8, x8, x26
   2aa30:	str	x8, [x21]
   2aa34:	cinc	x8, x27, cs  // cs = hs, nlast
   2aa38:	adds	x8, x9, x8
   2aa3c:	str	x8, [x21, #8]
   2aa40:	b.cc	2ab98 <__gmpn_mulmid@@Base+0x50c>  // b.lo, b.ul, b.last
   2aa44:	mov	w8, #0xdf                  	// #223
   2aa48:	sub	x8, x8, x20
   2aa4c:	add	x8, x24, x8, lsl #3
   2aa50:	ldr	x9, [x8]
   2aa54:	adds	x9, x9, #0x1
   2aa58:	str	x9, [x8], #8
   2aa5c:	b.cs	2aa50 <__gmpn_mulmid@@Base+0x3c4>  // b.hs, b.nlast
   2aa60:	b	2ab98 <__gmpn_mulmid@@Base+0x50c>
   2aa64:	mov	w8, #0x18                  	// #24
   2aa68:	orr	x9, xzr, #0x200
   2aa6c:	madd	x1, x20, x8, x9
   2aa70:	mov	w8, #0x7f00                	// #32512
   2aa74:	cmp	x1, x8
   2aa78:	stur	xzr, [x29, #-8]
   2aa7c:	b.hi	2abd8 <__gmpn_mulmid@@Base+0x54c>  // b.pmore
   2aa80:	add	x9, x1, #0xf
   2aa84:	mov	x8, sp
   2aa88:	and	x9, x9, #0xfffffffffffffff0
   2aa8c:	sub	x24, x8, x9
   2aa90:	mov	sp, x24
   2aa94:	mov	x0, x21
   2aa98:	mov	x1, x19
   2aa9c:	mov	x2, x22
   2aaa0:	mov	x3, x20
   2aaa4:	mov	x4, x24
   2aaa8:	bl	c7b0 <__gmpn_toom42_mulmid@plt>
   2aaac:	cmp	x26, x20
   2aab0:	b.ge	2aabc <__gmpn_mulmid@@Base+0x430>  // b.tcont
   2aab4:	mov	x25, x21
   2aab8:	b	2ab3c <__gmpn_mulmid@@Base+0x4b0>
   2aabc:	lsl	x27, x20, #3
   2aac0:	add	x8, x27, #0x10
   2aac4:	stp	x8, x24, [x29, #-24]
   2aac8:	add	x25, x21, x27
   2aacc:	ldur	x4, [x29, #-16]
   2aad0:	ldr	x28, [x21, x20, lsl #3]
   2aad4:	ldr	x24, [x25, #8]
   2aad8:	add	x19, x19, x20, lsl #3
   2aadc:	mov	x0, x25
   2aae0:	mov	x1, x19
   2aae4:	mov	x2, x22
   2aae8:	mov	x3, x20
   2aaec:	mov	x23, x26
   2aaf0:	bl	c7b0 <__gmpn_toom42_mulmid@plt>
   2aaf4:	ldr	x8, [x21, x20, lsl #3]
   2aaf8:	adds	x8, x8, x28
   2aafc:	str	x8, [x21, x20, lsl #3]
   2ab00:	ldr	x8, [x25, #8]
   2ab04:	cinc	x9, x24, cs  // cs = hs, nlast
   2ab08:	adds	x8, x8, x9
   2ab0c:	str	x8, [x25, #8]
   2ab10:	b.cc	2ab2c <__gmpn_mulmid@@Base+0x4a0>  // b.lo, b.ul, b.last
   2ab14:	ldur	x8, [x29, #-24]
   2ab18:	ldr	x9, [x21, x8]
   2ab1c:	adds	x9, x9, #0x1
   2ab20:	str	x9, [x21, x8]
   2ab24:	add	x8, x8, #0x8
   2ab28:	b.cs	2ab18 <__gmpn_mulmid@@Base+0x48c>  // b.hs, b.nlast
   2ab2c:	sub	x26, x23, x20
   2ab30:	cmp	x26, x20
   2ab34:	mov	x21, x25
   2ab38:	b.ge	2aac8 <__gmpn_mulmid@@Base+0x43c>  // b.tcont
   2ab3c:	ldur	x0, [x29, #-8]
   2ab40:	cbnz	x0, 2abe8 <__gmpn_mulmid@@Base+0x55c>
   2ab44:	cbz	x26, 2ab98 <__gmpn_mulmid@@Base+0x50c>
   2ab48:	add	x21, x25, x20, lsl #3
   2ab4c:	ldp	x24, x25, [x21]
   2ab50:	add	x1, x19, x20, lsl #3
   2ab54:	sub	x2, x23, #0x1
   2ab58:	mov	x0, x21
   2ab5c:	mov	x3, x22
   2ab60:	mov	x4, x20
   2ab64:	bl	c720 <__gmpn_mulmid@plt>
   2ab68:	ldp	x8, x9, [x21]
   2ab6c:	adds	x8, x8, x24
   2ab70:	str	x8, [x21]
   2ab74:	cinc	x8, x25, cs  // cs = hs, nlast
   2ab78:	adds	x8, x9, x8
   2ab7c:	str	x8, [x21, #8]
   2ab80:	b.cc	2ab98 <__gmpn_mulmid@@Base+0x50c>  // b.lo, b.ul, b.last
   2ab84:	add	x8, x21, #0x10
   2ab88:	ldr	x9, [x8]
   2ab8c:	adds	x9, x9, #0x1
   2ab90:	str	x9, [x8], #8
   2ab94:	b.cs	2ab88 <__gmpn_mulmid@@Base+0x4fc>  // b.hs, b.nlast
   2ab98:	mov	sp, x29
   2ab9c:	ldp	x20, x19, [sp, #80]
   2aba0:	ldp	x22, x21, [sp, #64]
   2aba4:	ldp	x24, x23, [sp, #48]
   2aba8:	ldp	x26, x25, [sp, #32]
   2abac:	ldp	x28, x27, [sp, #16]
   2abb0:	ldp	x29, x30, [sp], #96
   2abb4:	ret
   2abb8:	sub	x0, x29, #0x8
   2abbc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2abc0:	mov	x26, x0
   2abc4:	b	2a824 <__gmpn_mulmid@@Base+0x198>
   2abc8:	sub	x0, x29, #0x8
   2abcc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2abd0:	mov	x25, x0
   2abd4:	b	2a94c <__gmpn_mulmid@@Base+0x2c0>
   2abd8:	sub	x0, x29, #0x8
   2abdc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2abe0:	mov	x24, x0
   2abe4:	b	2aa94 <__gmpn_mulmid@@Base+0x408>
   2abe8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2abec:	cbnz	x26, 2ab48 <__gmpn_mulmid@@Base+0x4bc>
   2abf0:	b	2ab98 <__gmpn_mulmid@@Base+0x50c>

000000000002abf4 <__gmpn_random@@Base>:
   2abf4:	stp	x29, x30, [sp, #-48]!
   2abf8:	str	x21, [sp, #16]
   2abfc:	stp	x20, x19, [sp, #32]
   2ac00:	mov	x29, sp
   2ac04:	cbz	x1, 2ac80 <__gmpn_random@@Base+0x8c>
   2ac08:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2ac0c:	ldr	x8, [x8, #4040]
   2ac10:	mov	x20, x1
   2ac14:	mov	x21, x0
   2ac18:	ldrb	w9, [x8]
   2ac1c:	cbnz	w9, 2ac34 <__gmpn_random@@Base+0x40>
   2ac20:	mov	w9, #0x1                   	// #1
   2ac24:	strb	w9, [x8]
   2ac28:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2ac2c:	ldr	x0, [x0, #3976]
   2ac30:	bl	bf40 <__gmp_randinit_mt_noseed@plt>
   2ac34:	adrp	x19, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2ac38:	ldr	x19, [x19, #3976]
   2ac3c:	lsl	x2, x20, #6
   2ac40:	mov	x1, x21
   2ac44:	ldr	x8, [x19, #24]
   2ac48:	mov	x0, x19
   2ac4c:	ldr	x8, [x8, #8]
   2ac50:	blr	x8
   2ac54:	add	x20, x21, x20, lsl #3
   2ac58:	ldr	x8, [x20, #-8]!
   2ac5c:	cbnz	x8, 2ac80 <__gmpn_random@@Base+0x8c>
   2ac60:	ldr	x8, [x19, #24]
   2ac64:	mov	w2, #0x40                  	// #64
   2ac68:	mov	x0, x19
   2ac6c:	mov	x1, x20
   2ac70:	ldr	x8, [x8, #8]
   2ac74:	blr	x8
   2ac78:	ldr	x8, [x20]
   2ac7c:	cbz	x8, 2ac60 <__gmpn_random@@Base+0x6c>
   2ac80:	ldp	x20, x19, [sp, #32]
   2ac84:	ldr	x21, [sp, #16]
   2ac88:	ldp	x29, x30, [sp], #48
   2ac8c:	ret

000000000002ac90 <__gmpn_random2@@Base>:
   2ac90:	sub	sp, sp, #0x60
   2ac94:	stp	x29, x30, [sp, #16]
   2ac98:	str	x25, [sp, #32]
   2ac9c:	stp	x24, x23, [sp, #48]
   2aca0:	stp	x22, x21, [sp, #64]
   2aca4:	stp	x20, x19, [sp, #80]
   2aca8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2acac:	ldr	x8, [x8, #4040]
   2acb0:	mov	x21, x1
   2acb4:	mov	x19, x0
   2acb8:	add	x29, sp, #0x10
   2acbc:	ldrb	w9, [x8]
   2acc0:	cbnz	w9, 2acd8 <__gmpn_random2@@Base+0x48>
   2acc4:	mov	w9, #0x1                   	// #1
   2acc8:	strb	w9, [x8]
   2accc:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2acd0:	ldr	x0, [x0, #3976]
   2acd4:	bl	bf40 <__gmp_randinit_mt_noseed@plt>
   2acd8:	adrp	x20, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2acdc:	ldr	x20, [x20, #3976]
   2ace0:	add	x1, sp, #0x8
   2ace4:	mov	w2, #0x20                  	// #32
   2ace8:	ldr	x8, [x20, #24]
   2acec:	mov	x0, x20
   2acf0:	ldr	x8, [x8, #8]
   2acf4:	blr	x8
   2acf8:	ldr	x8, [sp, #8]
   2acfc:	lsl	x9, x21, #6
   2ad00:	mov	x10, #0xffffffffffffffff    	// #-1
   2ad04:	and	x8, x8, #0x3f
   2ad08:	sub	x21, x9, x8
   2ad0c:	add	x11, x21, #0x3f
   2ad10:	neg	w8, w21
   2ad14:	lsr	x9, x11, #6
   2ad18:	lsr	x10, x10, x8
   2ad1c:	sub	x8, x9, #0x1
   2ad20:	cmp	x11, #0x80
   2ad24:	str	x10, [x19, x8, lsl #3]
   2ad28:	b.cc	2ad50 <__gmpn_random2@@Base+0xc0>  // b.lo, b.ul, b.last
   2ad2c:	cmp	x9, #0x2
   2ad30:	mov	w10, #0x2                   	// #2
   2ad34:	csel	x9, x9, x10, cc  // cc = lo, ul, last
   2ad38:	sub	x9, x9, #0x2
   2ad3c:	sub	x8, x8, x9
   2ad40:	add	x0, x19, x9, lsl #3
   2ad44:	lsl	x2, x8, #3
   2ad48:	mov	w1, #0xff                  	// #255
   2ad4c:	bl	c610 <memset@plt>
   2ad50:	ldr	x8, [x20, #24]
   2ad54:	add	x1, x29, #0x18
   2ad58:	mov	w2, #0x20                  	// #32
   2ad5c:	mov	x0, x20
   2ad60:	ldr	x8, [x8, #8]
   2ad64:	blr	x8
   2ad68:	ldr	x8, [x29, #24]
   2ad6c:	add	x22, x19, #0x8
   2ad70:	mov	w24, #0x1                   	// #1
   2ad74:	and	x8, x8, #0x3
   2ad78:	add	x8, x8, #0x1
   2ad7c:	udiv	x8, x21, x8
   2ad80:	cmp	w8, #0x0
   2ad84:	cinc	w23, w8, eq  // eq = none
   2ad88:	ldr	x8, [x20, #24]
   2ad8c:	add	x1, x29, #0x18
   2ad90:	mov	w2, #0x20                  	// #32
   2ad94:	mov	x0, x20
   2ad98:	ldr	x8, [x8, #8]
   2ad9c:	blr	x8
   2ada0:	ldr	x8, [x29, #24]
   2ada4:	udiv	x9, x8, x23
   2ada8:	msub	x8, x9, x23, x8
   2adac:	add	x8, x8, #0x1
   2adb0:	subs	x8, x21, x8
   2adb4:	csel	x25, xzr, x8, cc  // cc = lo, ul, last
   2adb8:	b.ls	2ae38 <__gmpn_random2@@Base+0x1a8>  // b.plast
   2adbc:	lsr	x8, x25, #3
   2adc0:	and	x8, x8, #0x1ffffffffffffff8
   2adc4:	ldr	x9, [x19, x8]
   2adc8:	lsl	x10, x24, x25
   2adcc:	add	x1, x29, #0x18
   2add0:	mov	w2, #0x20                  	// #32
   2add4:	eor	x9, x9, x10
   2add8:	str	x9, [x19, x8]
   2addc:	ldr	x8, [x20, #24]
   2ade0:	mov	x0, x20
   2ade4:	ldr	x8, [x8, #8]
   2ade8:	blr	x8
   2adec:	ldr	x8, [x29, #24]
   2adf0:	udiv	x9, x8, x23
   2adf4:	msub	x8, x9, x23, x8
   2adf8:	add	x8, x8, #0x1
   2adfc:	subs	x9, x25, x8
   2ae00:	csel	x21, xzr, x9, cc  // cc = lo, ul, last
   2ae04:	lsr	x9, x21, #6
   2ae08:	ldr	x10, [x19, x9, lsl #3]
   2ae0c:	lsl	x11, x24, x21
   2ae10:	adds	x10, x10, x11
   2ae14:	str	x10, [x19, x9, lsl #3]
   2ae18:	b.cc	2ae30 <__gmpn_random2@@Base+0x1a0>  // b.lo, b.ul, b.last
   2ae1c:	add	x9, x22, x9, lsl #3
   2ae20:	ldr	x10, [x9]
   2ae24:	adds	x10, x10, #0x1
   2ae28:	str	x10, [x9], #8
   2ae2c:	b.cs	2ae20 <__gmpn_random2@@Base+0x190>  // b.hs, b.nlast
   2ae30:	cmp	x25, x8
   2ae34:	b.hi	2ad88 <__gmpn_random2@@Base+0xf8>  // b.pmore
   2ae38:	ldp	x20, x19, [sp, #80]
   2ae3c:	ldp	x22, x21, [sp, #64]
   2ae40:	ldp	x24, x23, [sp, #48]
   2ae44:	ldr	x25, [sp, #32]
   2ae48:	ldp	x29, x30, [sp, #16]
   2ae4c:	add	sp, sp, #0x60
   2ae50:	ret

000000000002ae54 <__gmpn_pow_1@@Base>:
   2ae54:	stp	x29, x30, [sp, #-80]!
   2ae58:	stp	x20, x19, [sp, #64]
   2ae5c:	mov	x19, x2
   2ae60:	mov	x20, x1
   2ae64:	cmp	x3, #0x2
   2ae68:	stp	x26, x25, [sp, #16]
   2ae6c:	stp	x24, x23, [sp, #32]
   2ae70:	stp	x22, x21, [sp, #48]
   2ae74:	mov	x29, sp
   2ae78:	b.cs	2ae90 <__gmpn_pow_1@@Base+0x3c>  // b.hs, b.nlast
   2ae7c:	cbz	x3, 2b00c <__gmpn_pow_1@@Base+0x1b8>
   2ae80:	mov	x1, x20
   2ae84:	mov	x2, x19
   2ae88:	bl	ca70 <__gmpn_copyi@plt>
   2ae8c:	b	2b014 <__gmpn_pow_1@@Base+0x1c0>
   2ae90:	mov	x9, xzr
   2ae94:	mov	w8, #0x40                  	// #64
   2ae98:	mov	x10, x3
   2ae9c:	sxtw	x9, w9
   2aea0:	eor	x9, x9, x10
   2aea4:	lsr	x10, x10, #1
   2aea8:	sub	w8, w8, #0x1
   2aeac:	cbnz	x10, 2ae9c <__gmpn_pow_1@@Base+0x48>
   2aeb0:	lsl	x25, x3, x8
   2aeb4:	cmp	x19, #0x1
   2aeb8:	sub	w26, w8, #0x3e
   2aebc:	b.ne	2af50 <__gmpn_pow_1@@Base+0xfc>  // b.any
   2aec0:	ldr	x20, [x20]
   2aec4:	tst	w8, #0x1
   2aec8:	csel	x21, x0, x4, eq  // eq = none
   2aecc:	umulh	x9, x20, x20
   2aed0:	mul	x10, x20, x20
   2aed4:	csel	x8, x4, x0, eq  // eq = none
   2aed8:	stp	x10, x9, [x21]
   2aedc:	cmp	x9, #0x0
   2aee0:	mov	w9, #0x1                   	// #1
   2aee4:	cinc	x19, x9, ne  // ne = any
   2aee8:	lsl	x25, x25, #1
   2aeec:	mov	x22, x8
   2aef0:	tbz	x25, #63, 2af14 <__gmpn_pow_1@@Base+0xc0>
   2aef4:	mov	x0, x21
   2aef8:	mov	x1, x21
   2aefc:	mov	x2, x19
   2af00:	mov	x3, x20
   2af04:	bl	d4b0 <__gmpn_mul_1@plt>
   2af08:	cmp	x0, #0x0
   2af0c:	str	x0, [x21, x19, lsl #3]
   2af10:	cinc	x19, x19, ne  // ne = any
   2af14:	cbz	w26, 2b014 <__gmpn_pow_1@@Base+0x1c0>
   2af18:	mov	x0, x22
   2af1c:	mov	x1, x21
   2af20:	mov	x2, x19
   2af24:	bl	c900 <__gmpn_sqr@plt>
   2af28:	add	x8, x22, x19, lsl #4
   2af2c:	ldur	x8, [x8, #-8]
   2af30:	lsl	x9, x19, #1
   2af34:	add	w26, w26, #0x1
   2af38:	cmp	x8, #0x0
   2af3c:	cset	w8, eq  // eq = none
   2af40:	sub	x19, x9, x8
   2af44:	mov	x8, x21
   2af48:	mov	x21, x22
   2af4c:	b	2aee8 <__gmpn_pow_1@@Base+0x94>
   2af50:	eor	w8, w8, w9
   2af54:	tst	w8, #0x1
   2af58:	csel	x23, x4, x0, eq  // eq = none
   2af5c:	csel	x21, x0, x4, eq  // eq = none
   2af60:	mov	x0, x23
   2af64:	mov	x1, x20
   2af68:	mov	x2, x19
   2af6c:	bl	c900 <__gmpn_sqr@plt>
   2af70:	add	x8, x23, x19, lsl #4
   2af74:	ldur	x8, [x8, #-8]
   2af78:	lsl	x9, x19, #1
   2af7c:	cmp	x8, #0x0
   2af80:	cset	w8, eq  // eq = none
   2af84:	sub	x22, x9, x8
   2af88:	lsl	x25, x25, #1
   2af8c:	tbnz	x25, #63, 2afa0 <__gmpn_pow_1@@Base+0x14c>
   2af90:	mov	x24, x21
   2af94:	mov	x21, x23
   2af98:	cbnz	w26, 2afd0 <__gmpn_pow_1@@Base+0x17c>
   2af9c:	b	2b004 <__gmpn_pow_1@@Base+0x1b0>
   2afa0:	mov	x0, x21
   2afa4:	mov	x1, x23
   2afa8:	mov	x2, x22
   2afac:	mov	x3, x20
   2afb0:	mov	x4, x19
   2afb4:	add	x24, x22, x19
   2afb8:	bl	ccf0 <__gmpn_mul@plt>
   2afbc:	cmp	x0, #0x0
   2afc0:	cset	w8, eq  // eq = none
   2afc4:	sub	x22, x24, x8
   2afc8:	mov	x24, x23
   2afcc:	cbz	w26, 2b004 <__gmpn_pow_1@@Base+0x1b0>
   2afd0:	mov	x0, x24
   2afd4:	mov	x1, x21
   2afd8:	mov	x2, x22
   2afdc:	bl	c900 <__gmpn_sqr@plt>
   2afe0:	add	x8, x24, x22, lsl #4
   2afe4:	ldur	x8, [x8, #-8]
   2afe8:	lsl	x9, x22, #1
   2afec:	add	w26, w26, #0x1
   2aff0:	mov	x23, x24
   2aff4:	cmp	x8, #0x0
   2aff8:	cset	w8, eq  // eq = none
   2affc:	sub	x22, x9, x8
   2b000:	b	2af88 <__gmpn_pow_1@@Base+0x134>
   2b004:	mov	x19, x22
   2b008:	b	2b014 <__gmpn_pow_1@@Base+0x1c0>
   2b00c:	mov	w19, #0x1                   	// #1
   2b010:	str	x19, [x0]
   2b014:	mov	x0, x19
   2b018:	ldp	x20, x19, [sp, #64]
   2b01c:	ldp	x22, x21, [sp, #48]
   2b020:	ldp	x24, x23, [sp, #32]
   2b024:	ldp	x26, x25, [sp, #16]
   2b028:	ldp	x29, x30, [sp], #80
   2b02c:	ret

000000000002b030 <__gmpn_rootrem@@Base>:
   2b030:	stp	x29, x30, [sp, #-64]!
   2b034:	stp	x24, x23, [sp, #16]
   2b038:	stp	x22, x21, [sp, #32]
   2b03c:	stp	x20, x19, [sp, #48]
   2b040:	mov	x29, sp
   2b044:	sub	sp, sp, #0x10
   2b048:	cmp	x4, #0x2
   2b04c:	mov	x20, x0
   2b050:	b.eq	2b154 <__gmpn_rootrem@@Base+0x124>  // b.none
   2b054:	mov	x19, x4
   2b058:	cbnz	x1, 2b130 <__gmpn_rootrem@@Base+0x100>
   2b05c:	mov	x9, #0x5555555555555555    	// #6148914691236517205
   2b060:	add	x8, x3, #0x2
   2b064:	movk	x9, #0x5556
   2b068:	smulh	x8, x8, x9
   2b06c:	add	x8, x8, x8, lsr #63
   2b070:	cmp	x8, x19
   2b074:	b.ls	2b130 <__gmpn_rootrem@@Base+0x100>  // b.plast
   2b078:	sub	x8, x3, #0x1
   2b07c:	add	x21, x19, x3
   2b080:	udiv	x24, x8, x19
   2b084:	add	x8, x21, x24
   2b088:	lsl	x8, x8, #3
   2b08c:	add	x1, x8, #0x10
   2b090:	mov	w8, #0x7f00                	// #32512
   2b094:	cmp	x1, x8
   2b098:	stur	xzr, [x29, #-8]
   2b09c:	b.hi	2b170 <__gmpn_rootrem@@Base+0x140>  // b.pmore
   2b0a0:	add	x9, x1, #0xf
   2b0a4:	mov	x8, sp
   2b0a8:	and	x9, x9, #0xfffffffffffffff0
   2b0ac:	sub	x22, x8, x9
   2b0b0:	mov	sp, x22
   2b0b4:	add	x0, x22, x19, lsl #3
   2b0b8:	mov	x1, x2
   2b0bc:	mov	x2, x3
   2b0c0:	lsl	x23, x19, #3
   2b0c4:	bl	ca70 <__gmpn_copyi@plt>
   2b0c8:	mov	x0, x22
   2b0cc:	mov	w1, wzr
   2b0d0:	mov	x2, x23
   2b0d4:	bl	c610 <memset@plt>
   2b0d8:	add	x23, x22, x21, lsl #3
   2b0dc:	mov	w5, #0x1                   	// #1
   2b0e0:	mov	x0, x23
   2b0e4:	mov	x1, xzr
   2b0e8:	mov	x2, x22
   2b0ec:	mov	x3, x21
   2b0f0:	mov	x4, x19
   2b0f4:	bl	2b198 <__gmpn_rootrem@@Base+0x168>
   2b0f8:	mov	x19, x0
   2b0fc:	add	x1, x23, #0x8
   2b100:	add	x2, x24, #0x1
   2b104:	mov	x0, x20
   2b108:	bl	ca70 <__gmpn_copyi@plt>
   2b10c:	ldur	x0, [x29, #-8]
   2b110:	cbnz	x0, 2b190 <__gmpn_rootrem@@Base+0x160>
   2b114:	mov	x0, x19
   2b118:	mov	sp, x29
   2b11c:	ldp	x20, x19, [sp, #48]
   2b120:	ldp	x22, x21, [sp, #32]
   2b124:	ldp	x24, x23, [sp, #16]
   2b128:	ldp	x29, x30, [sp], #64
   2b12c:	ret
   2b130:	mov	x0, x20
   2b134:	mov	x4, x19
   2b138:	mov	w5, wzr
   2b13c:	mov	sp, x29
   2b140:	ldp	x20, x19, [sp, #48]
   2b144:	ldp	x22, x21, [sp, #32]
   2b148:	ldp	x24, x23, [sp, #16]
   2b14c:	ldp	x29, x30, [sp], #64
   2b150:	b	2b198 <__gmpn_rootrem@@Base+0x168>
   2b154:	mov	x0, x20
   2b158:	mov	sp, x29
   2b15c:	ldp	x20, x19, [sp, #48]
   2b160:	ldp	x22, x21, [sp, #32]
   2b164:	ldp	x24, x23, [sp, #16]
   2b168:	ldp	x29, x30, [sp], #64
   2b16c:	b	d3d0 <__gmpn_sqrtrem@plt>
   2b170:	sub	x0, x29, #0x8
   2b174:	mov	x22, x3
   2b178:	mov	x23, x2
   2b17c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2b180:	mov	x2, x23
   2b184:	mov	x3, x22
   2b188:	mov	x22, x0
   2b18c:	b	2b0b4 <__gmpn_rootrem@@Base+0x84>
   2b190:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2b194:	b	2b114 <__gmpn_rootrem@@Base+0xe4>
   2b198:	stp	x29, x30, [sp, #-96]!
   2b19c:	stp	x28, x27, [sp, #16]
   2b1a0:	stp	x26, x25, [sp, #32]
   2b1a4:	stp	x24, x23, [sp, #48]
   2b1a8:	stp	x22, x21, [sp, #64]
   2b1ac:	stp	x20, x19, [sp, #80]
   2b1b0:	mov	x29, sp
   2b1b4:	sub	sp, sp, #0x2d0
   2b1b8:	sub	x8, x3, #0x1
   2b1bc:	ldr	x11, [x2, x8, lsl #3]
   2b1c0:	lsl	x9, x3, #6
   2b1c4:	mov	x25, x3
   2b1c8:	mov	x14, x1
   2b1cc:	clz	x10, x11
   2b1d0:	add	w12, w10, #0x1
   2b1d4:	sub	x9, x9, x12
   2b1d8:	cmp	x9, x4
   2b1dc:	mov	x19, sp
   2b1e0:	b.cs	2b230 <__gmpn_rootrem@@Base+0x200>  // b.hs, b.nlast
   2b1e4:	mov	w9, #0x1                   	// #1
   2b1e8:	str	x9, [x0]
   2b1ec:	ldr	x9, [x2]
   2b1f0:	cbz	x14, 2b8e0 <__gmpn_rootrem@@Base+0x8b0>
   2b1f4:	sub	x10, x9, #0x1
   2b1f8:	str	x10, [x14]
   2b1fc:	cbz	x9, 2b9a4 <__gmpn_rootrem@@Base+0x974>
   2b200:	cmp	x2, x14
   2b204:	b.eq	2b9fc <__gmpn_rootrem@@Base+0x9cc>  // b.none
   2b208:	cmp	x25, #0x2
   2b20c:	b.lt	2b9fc <__gmpn_rootrem@@Base+0x9cc>  // b.tstop
   2b210:	add	x9, x14, #0x8
   2b214:	add	x10, x2, #0x8
   2b218:	mov	x11, x8
   2b21c:	ldr	x12, [x10], #8
   2b220:	subs	x11, x11, #0x1
   2b224:	str	x12, [x9], #8
   2b228:	b.ne	2b21c <__gmpn_rootrem@@Base+0x1ec>  // b.any
   2b22c:	b	2b9fc <__gmpn_rootrem@@Base+0x9cc>
   2b230:	mov	x27, x4
   2b234:	cmp	w12, #0x40
   2b238:	b.ne	2b248 <__gmpn_rootrem@@Base+0x218>  // b.any
   2b23c:	add	x8, x2, x25, lsl #3
   2b240:	ldur	x8, [x8, #-16]
   2b244:	b	2b26c <__gmpn_rootrem@@Base+0x23c>
   2b248:	cmp	x25, #0x1
   2b24c:	cset	w13, ne  // ne = any
   2b250:	sub	x8, x8, x13
   2b254:	ldr	x8, [x2, x8, lsl #3]
   2b258:	lsl	x11, x11, x12
   2b25c:	mov	w12, #0x3f                  	// #63
   2b260:	sub	w10, w12, w10
   2b264:	lsr	x8, x8, x10
   2b268:	orr	x8, x8, x11
   2b26c:	lsr	x8, x8, #56
   2b270:	lsr	x10, x9, #56
   2b274:	cbnz	x10, 2bae8 <__gmpn_rootrem@@Base+0xab8>
   2b278:	adrp	x10, 54000 <__gmpn_bases@@Base+0x2938>
   2b27c:	add	x10, x10, #0x334
   2b280:	ldrb	w8, [x10, x8]
   2b284:	bfi	x8, x9, #8, #56
   2b288:	udiv	x9, x8, x27
   2b28c:	lsr	x8, x9, #8
   2b290:	and	x9, x9, #0xff
   2b294:	adrp	x10, 54000 <__gmpn_bases@@Base+0x2938>
   2b298:	add	x10, x10, #0x434
   2b29c:	ldrb	w9, [x10, x9]
   2b2a0:	and	x20, x8, #0xffffffff
   2b2a4:	sub	x10, x27, #0x1
   2b2a8:	cmp	x20, #0x8
   2b2ac:	orr	x8, x9, #0x100
   2b2b0:	str	x8, [x0]
   2b2b4:	str	x20, [x19, #192]
   2b2b8:	str	x2, [x19, #112]
   2b2bc:	stp	x10, x0, [x19, #144]
   2b2c0:	str	w5, [x19, #20]
   2b2c4:	b.ls	2b33c <__gmpn_rootrem@@Base+0x30c>  // b.plast
   2b2c8:	lsr	x9, x10, #2
   2b2cc:	mov	w10, #0x43                  	// #67
   2b2d0:	add	x11, x19, #0xc0
   2b2d4:	clz	x9, x9
   2b2d8:	mov	x22, xzr
   2b2dc:	sub	x9, x10, x9
   2b2e0:	add	x10, x11, #0x8
   2b2e4:	mov	x24, x20
   2b2e8:	add	x11, x24, x9
   2b2ec:	sub	x12, x24, #0x1
   2b2f0:	cmp	x24, x9
   2b2f4:	lsr	x11, x11, #1
   2b2f8:	csel	x24, x11, x12, hi  // hi = pmore
   2b2fc:	str	x24, [x10, x22, lsl #3]
   2b300:	cmp	x24, #0x8
   2b304:	add	x22, x22, #0x1
   2b308:	b.hi	2b2e8 <__gmpn_rootrem@@Base+0x2b8>  // b.pmore
   2b30c:	mov	w9, #0x8                   	// #8
   2b310:	sub	x9, x9, x24
   2b314:	lsr	x8, x8, x9
   2b318:	cmp	w22, #0x40
   2b31c:	str	x8, [x0]
   2b320:	b.ls	2b354 <__gmpn_rootrem@@Base+0x324>  // b.plast
   2b324:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   2b328:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   2b32c:	add	x0, x0, #0x318
   2b330:	add	x2, x2, #0x322
   2b334:	mov	w1, #0x11b                 	// #283
   2b338:	bl	c6e0 <__gmp_assert_fail@plt>
   2b33c:	mov	w9, #0x8                   	// #8
   2b340:	sub	x9, x9, x20
   2b344:	lsr	x8, x8, x9
   2b348:	mov	w22, wzr
   2b34c:	str	x8, [x0]
   2b350:	mov	x24, x20
   2b354:	adrp	x8, 54000 <__gmpn_bases@@Base+0x2938>
   2b358:	ldr	d0, [x8, #784]
   2b35c:	ucvtf	d1, x27
   2b360:	mov	x8, #0x3f90000000000000    	// #4580160821035794432
   2b364:	add	x21, x25, #0x1
   2b368:	fmul	d0, d1, d0
   2b36c:	fmov	d1, x8
   2b370:	fmul	d0, d0, d1
   2b374:	fcvtzs	x8, d0
   2b378:	add	x8, x25, x8
   2b37c:	add	x23, x8, #0x2
   2b380:	add	x8, x21, x23, lsl #1
   2b384:	lsl	x1, x8, #3
   2b388:	mov	w8, #0x7f00                	// #32512
   2b38c:	cmp	x1, x8
   2b390:	str	xzr, [x19, #184]
   2b394:	b.hi	2bb08 <__gmpn_rootrem@@Base+0xad8>  // b.pmore
   2b398:	add	x9, x1, #0xf
   2b39c:	mov	x8, sp
   2b3a0:	and	x9, x9, #0xfffffffffffffff0
   2b3a4:	sub	x0, x8, x9
   2b3a8:	mov	sp, x0
   2b3ac:	add	x8, x0, x21, lsl #3
   2b3b0:	cmp	x14, #0x0
   2b3b4:	str	x8, [x19, #160]
   2b3b8:	add	x8, x8, x23, lsl #3
   2b3bc:	csel	x9, x0, x14, eq  // eq = none
   2b3c0:	str	x8, [x19, #168]
   2b3c4:	str	x14, [x19, #8]
   2b3c8:	str	x25, [x19, #80]
   2b3cc:	str	x27, [x19, #56]
   2b3d0:	str	x0, [x19, #32]
   2b3d4:	cbz	w22, 2b8e8 <__gmpn_rootrem@@Base+0x8b8>
   2b3d8:	add	x10, x0, x25, lsl #4
   2b3dc:	mov	w11, w22
   2b3e0:	str	x10, [x19, #48]
   2b3e4:	ldr	x10, [x19, #112]
   2b3e8:	ldp	x22, x23, [x19, #144]
   2b3ec:	mul	x8, x20, x27
   2b3f0:	sub	x28, x9, #0x8
   2b3f4:	str	x9, [x19, #128]
   2b3f8:	add	x9, x9, #0x8
   2b3fc:	sub	x21, x8, x24
   2b400:	mov	w8, #0x1                   	// #1
   2b404:	str	x9, [x19, #24]
   2b408:	str	x8, [x19, #176]
   2b40c:	ldr	x8, [x19, #80]
   2b410:	msub	x26, x24, x22, x21
   2b414:	lsr	x24, x26, #6
   2b418:	ands	x3, x26, #0x3f
   2b41c:	sub	x20, x8, x26, lsr #6
   2b420:	add	x1, x10, x24, lsl #3
   2b424:	str	x11, [x19, #120]
   2b428:	b.eq	2b440 <__gmpn_rootrem@@Base+0x410>  // b.none
   2b42c:	ldr	x21, [x19, #128]
   2b430:	mov	x2, x20
   2b434:	mov	x0, x21
   2b438:	bl	c1b0 <__gmpn_rshift@plt>
   2b43c:	b	2b450 <__gmpn_rootrem@@Base+0x420>
   2b440:	ldr	x21, [x19, #128]
   2b444:	mov	x2, x20
   2b448:	mov	x0, x21
   2b44c:	bl	ca70 <__gmpn_copyi@plt>
   2b450:	add	x8, x21, x20, lsl #3
   2b454:	ldur	x8, [x8, #-8]
   2b458:	str	x24, [x19, #136]
   2b45c:	cmp	x8, #0x0
   2b460:	cset	w8, eq  // eq = none
   2b464:	csetm	x9, eq  // eq = none
   2b468:	sub	x20, x20, x8
   2b46c:	str	x9, [x19, #104]
   2b470:	lsl	x8, x9, #3
   2b474:	ldr	x9, [x19, #48]
   2b478:	sub	x8, x8, x24, lsl #3
   2b47c:	add	x24, x9, x8
   2b480:	ldp	x25, x27, [x19, #168]
   2b484:	ldr	x21, [x19, #160]
   2b488:	mov	x1, x23
   2b48c:	mov	x3, x22
   2b490:	mov	x0, x25
   2b494:	mov	x2, x27
   2b498:	mov	x4, x21
   2b49c:	bl	d230 <__gmpn_pow_1@plt>
   2b4a0:	mov	x22, x0
   2b4a4:	mov	x0, x21
   2b4a8:	mov	x1, x25
   2b4ac:	mov	x2, x22
   2b4b0:	mov	x3, x23
   2b4b4:	mov	x4, x27
   2b4b8:	bl	ccf0 <__gmpn_mul@plt>
   2b4bc:	add	x8, x22, x27
   2b4c0:	add	x9, x21, x8, lsl #3
   2b4c4:	ldur	x9, [x9, #-8]
   2b4c8:	mov	x10, x23
   2b4cc:	cmp	x9, #0x0
   2b4d0:	cset	w9, eq  // eq = none
   2b4d4:	sub	x23, x8, x9
   2b4d8:	cmp	x23, x20
   2b4dc:	b.gt	2b510 <__gmpn_rootrem@@Base+0x4e0>
   2b4e0:	b.ne	2b8b0 <__gmpn_rootrem@@Base+0x880>  // b.any
   2b4e4:	mov	x8, x24
   2b4e8:	mov	x9, x20
   2b4ec:	subs	x10, x9, #0x1
   2b4f0:	b.lt	2b530 <__gmpn_rootrem@@Base+0x500>  // b.tstop
   2b4f4:	ldr	x11, [x8], #-8
   2b4f8:	ldr	x9, [x28, x9, lsl #3]
   2b4fc:	cmp	x11, x9
   2b500:	mov	x9, x10
   2b504:	b.eq	2b4ec <__gmpn_rootrem@@Base+0x4bc>  // b.none
   2b508:	ldr	x10, [x19, #152]
   2b50c:	b.ls	2b8b8 <__gmpn_rootrem@@Base+0x888>  // b.plast
   2b510:	ldr	x22, [x19, #144]
   2b514:	mov	x8, x10
   2b518:	mov	x23, x10
   2b51c:	ldr	x9, [x8]
   2b520:	sub	x10, x9, #0x1
   2b524:	str	x10, [x8], #8
   2b528:	cbz	x9, 2b51c <__gmpn_rootrem@@Base+0x4ec>
   2b52c:	b	2b480 <__gmpn_rootrem@@Base+0x450>
   2b530:	mov	w8, #0x1                   	// #1
   2b534:	mov	x23, x20
   2b538:	ldr	x9, [x19, #120]
   2b53c:	add	x10, x19, #0xc0
   2b540:	sub	x11, x9, #0x1
   2b544:	ldr	x9, [x10, x9, lsl #3]
   2b548:	ldr	x10, [x10, x11, lsl #3]
   2b54c:	str	x11, [x19, #96]
   2b550:	sub	x11, x26, #0x1
   2b554:	lsr	x11, x11, #6
   2b558:	sub	x24, x10, x9
   2b55c:	sub	x21, x26, x24
   2b560:	sub	x9, x11, x21, lsr #6
   2b564:	lsr	x27, x24, #6
   2b568:	lsr	x12, x21, #6
   2b56c:	add	x11, x9, #0x1
   2b570:	str	x21, [x19, #120]
   2b574:	tbz	w8, #0, 2b598 <__gmpn_rootrem@@Base+0x568>
   2b578:	ldr	x23, [x19, #152]
   2b57c:	ldr	x25, [x19, #176]
   2b580:	ldr	x26, [x19, #128]
   2b584:	ldr	x10, [x19, #112]
   2b588:	str	xzr, [x19, #88]
   2b58c:	str	xzr, [x19, #72]
   2b590:	str	x27, [x19, #104]
   2b594:	b	2b6d0 <__gmpn_rootrem@@Base+0x6a0>
   2b598:	ldr	x25, [x19, #176]
   2b59c:	ldr	x26, [x19, #128]
   2b5a0:	str	x12, [x19, #64]
   2b5a4:	str	x11, [x19, #88]
   2b5a8:	cbz	x23, 2b5e4 <__gmpn_rootrem@@Base+0x5b4>
   2b5ac:	ldr	x2, [x19, #160]
   2b5b0:	mov	x0, x26
   2b5b4:	mov	x1, x26
   2b5b8:	mov	x3, x23
   2b5bc:	bl	c2e0 <__gmpn_sub_n@plt>
   2b5c0:	cbz	x0, 2b5e4 <__gmpn_rootrem@@Base+0x5b4>
   2b5c4:	cmp	x23, x20
   2b5c8:	b.ge	2b5e4 <__gmpn_rootrem@@Base+0x5b4>  // b.tcont
   2b5cc:	ldr	x8, [x26, x23, lsl #3]
   2b5d0:	add	x10, x23, #0x1
   2b5d4:	sub	x9, x8, #0x1
   2b5d8:	str	x9, [x26, x23, lsl #3]
   2b5dc:	mov	x23, x10
   2b5e0:	cbz	x8, 2b5c4 <__gmpn_rootrem@@Base+0x594>
   2b5e4:	ldr	x21, [x19, #80]
   2b5e8:	ldr	x10, [x19, #104]
   2b5ec:	ldr	x9, [x19, #136]
   2b5f0:	mov	x20, xzr
   2b5f4:	add	x8, x21, x10
   2b5f8:	sub	x8, x8, x9
   2b5fc:	add	x8, x28, x8, lsl #3
   2b600:	ldr	x9, [x8, x20, lsl #3]
   2b604:	sub	x20, x20, #0x1
   2b608:	cbz	x9, 2b600 <__gmpn_rootrem@@Base+0x5d0>
   2b60c:	ldr	x23, [x19, #136]
   2b610:	add	x8, x21, x10
   2b614:	and	x3, x24, #0x3f
   2b618:	add	x0, x26, x27, lsl #3
   2b61c:	sub	x8, x8, x23
   2b620:	add	x8, x8, x20
   2b624:	add	x2, x8, #0x1
   2b628:	mov	x1, x26
   2b62c:	str	x0, [x19, #40]
   2b630:	cbz	x3, 2b664 <__gmpn_rootrem@@Base+0x634>
   2b634:	bl	c190 <__gmpn_lshift@plt>
   2b638:	ldr	x9, [x19, #104]
   2b63c:	add	x8, x21, x27
   2b640:	add	x8, x8, x9
   2b644:	sub	x9, x8, x23
   2b648:	add	x8, x9, x20
   2b64c:	cbz	x0, 2b694 <__gmpn_rootrem@@Base+0x664>
   2b650:	ldr	x10, [x19, #24]
   2b654:	add	x9, x10, x9, lsl #3
   2b658:	str	x0, [x9, x20, lsl #3]
   2b65c:	add	x9, x8, #0x2
   2b660:	b	2b698 <__gmpn_rootrem@@Base+0x668>
   2b664:	bl	c010 <__gmpn_copyd@plt>
   2b668:	ldp	x9, x10, [x19, #104]
   2b66c:	add	x8, x21, x27
   2b670:	ldr	x13, [x19, #40]
   2b674:	ldr	x21, [x19, #120]
   2b678:	add	x8, x8, x9
   2b67c:	ldr	x11, [x19, #88]
   2b680:	ldr	x12, [x19, #64]
   2b684:	sub	x8, x8, x23
   2b688:	add	x8, x8, x20
   2b68c:	add	x9, x8, #0x1
   2b690:	b	2b6a8 <__gmpn_rootrem@@Base+0x678>
   2b694:	add	x9, x8, #0x1
   2b698:	ldp	x10, x21, [x19, #112]
   2b69c:	ldr	x11, [x19, #88]
   2b6a0:	ldr	x12, [x19, #64]
   2b6a4:	ldr	x13, [x19, #40]
   2b6a8:	ldr	x13, [x13]
   2b6ac:	sub	x8, x11, #0x1
   2b6b0:	cmp	x8, x27
   2b6b4:	str	x9, [x19, #104]
   2b6b8:	str	x13, [x19, #88]
   2b6bc:	b.le	2b6cc <__gmpn_rootrem@@Base+0x69c>
   2b6c0:	add	x8, x26, x27, lsl #3
   2b6c4:	ldr	x8, [x8, #8]
   2b6c8:	str	x8, [x19, #72]
   2b6cc:	ldr	x23, [x19, #152]
   2b6d0:	ands	x3, x21, #0x3f
   2b6d4:	add	x1, x10, x12, lsl #3
   2b6d8:	mov	x0, x26
   2b6dc:	mov	x20, x11
   2b6e0:	mov	x2, x11
   2b6e4:	b.eq	2b6f0 <__gmpn_rootrem@@Base+0x6c0>  // b.none
   2b6e8:	bl	c1b0 <__gmpn_rshift@plt>
   2b6ec:	b	2b6f4 <__gmpn_rootrem@@Base+0x6c4>
   2b6f0:	bl	ca70 <__gmpn_copyi@plt>
   2b6f4:	and	x8, x24, #0x3f
   2b6f8:	str	x8, [x19, #136]
   2b6fc:	ldr	x8, [x26, x27, lsl #3]
   2b700:	mov	w9, #0x1                   	// #1
   2b704:	lsl	x10, x9, x24
   2b708:	str	x10, [x19, #64]
   2b70c:	sub	x10, x10, #0x1
   2b710:	and	x8, x8, x10
   2b714:	ldr	x10, [x19, #88]
   2b718:	sub	x9, x20, #0x1
   2b71c:	cmp	x9, x27
   2b720:	orr	x8, x8, x10
   2b724:	str	x8, [x26, x27, lsl #3]
   2b728:	b.le	2b738 <__gmpn_rootrem@@Base+0x708>
   2b72c:	ldr	x9, [x19, #72]
   2b730:	add	x8, x26, x27, lsl #3
   2b734:	str	x9, [x8, #8]
   2b738:	ldr	x20, [x19, #168]
   2b73c:	ldr	x3, [x19, #56]
   2b740:	mov	x2, x22
   2b744:	mov	x0, x20
   2b748:	mov	x1, x20
   2b74c:	bl	d4b0 <__gmpn_mul_1@plt>
   2b750:	ldr	x8, [x19, #136]
   2b754:	cmp	x0, #0x0
   2b758:	str	x0, [x20, x22, lsl #3]
   2b75c:	cinc	x22, x22, ne  // ne = any
   2b760:	add	x20, x23, x27, lsl #3
   2b764:	cbz	x8, 2b790 <__gmpn_rootrem@@Base+0x760>
   2b768:	mov	x0, x20
   2b76c:	mov	x1, x23
   2b770:	mov	x2, x25
   2b774:	ldr	x3, [x19, #136]
   2b778:	bl	c190 <__gmpn_lshift@plt>
   2b77c:	add	x25, x27, x25
   2b780:	cbz	x0, 2b7a4 <__gmpn_rootrem@@Base+0x774>
   2b784:	str	x0, [x23, x25, lsl #3]
   2b788:	add	x25, x25, #0x1
   2b78c:	b	2b7a4 <__gmpn_rootrem@@Base+0x774>
   2b790:	mov	x0, x20
   2b794:	mov	x1, x23
   2b798:	mov	x2, x25
   2b79c:	bl	c010 <__gmpn_copyd@plt>
   2b7a0:	add	x25, x27, x25
   2b7a4:	ldr	x2, [x19, #104]
   2b7a8:	ldr	x26, [x20]
   2b7ac:	sub	x8, x24, #0x1
   2b7b0:	lsr	x27, x8, #6
   2b7b4:	subs	x23, x2, x22
   2b7b8:	str	x25, [x19, #176]
   2b7bc:	b.lt	2b8c0 <__gmpn_rootrem@@Base+0x890>  // b.tstop
   2b7c0:	add	x21, x27, #0x1
   2b7c4:	cmp	x23, x21
   2b7c8:	str	x8, [x19, #88]
   2b7cc:	b.gt	2b7f4 <__gmpn_rootrem@@Base+0x7c4>
   2b7d0:	ldp	x25, x3, [x19, #160]
   2b7d4:	ldr	x1, [x19, #128]
   2b7d8:	ldr	x5, [x19, #32]
   2b7dc:	mov	x4, x22
   2b7e0:	mov	x0, x25
   2b7e4:	bl	c340 <__gmpn_div_q@plt>
   2b7e8:	ldr	x8, [x25, x23, lsl #3]
   2b7ec:	cmp	x8, #0x0
   2b7f0:	cinc	x23, x23, ne  // ne = any
   2b7f4:	ldr	x22, [x19, #144]
   2b7f8:	cmp	x21, x23
   2b7fc:	b.ge	2b840 <__gmpn_rootrem@@Base+0x810>  // b.tcont
   2b800:	ldr	x21, [x19, #152]
   2b804:	cbz	x27, 2b824 <__gmpn_rootrem@@Base+0x7f4>
   2b808:	lsl	x2, x27, #3
   2b80c:	mov	w1, #0xff                  	// #255
   2b810:	mov	x0, x21
   2b814:	bl	c610 <memset@plt>
   2b818:	mov	x8, x27
   2b81c:	subs	x8, x8, #0x1
   2b820:	b.ne	2b81c <__gmpn_rootrem@@Base+0x7ec>  // b.any
   2b824:	ldr	x8, [x19, #88]
   2b828:	mov	x9, #0xffffffffffffffff    	// #-1
   2b82c:	mvn	w8, w8
   2b830:	lsr	x8, x9, x8
   2b834:	str	x8, [x21, x27, lsl #3]
   2b838:	ldp	x10, x21, [x19, #112]
   2b83c:	b	2b894 <__gmpn_rootrem@@Base+0x864>
   2b840:	b.ne	2b860 <__gmpn_rootrem@@Base+0x830>  // b.any
   2b844:	ldr	x8, [x19, #136]
   2b848:	cbz	x8, 2b860 <__gmpn_rootrem@@Base+0x830>
   2b84c:	ldr	x8, [x19, #160]
   2b850:	ldr	x9, [x19, #64]
   2b854:	ldr	x8, [x8, x27, lsl #3]
   2b858:	cmp	x8, x9
   2b85c:	b.cs	2b800 <__gmpn_rootrem@@Base+0x7d0>  // b.hs, b.nlast
   2b860:	ldp	x0, x1, [x19, #152]
   2b864:	mov	x2, x23
   2b868:	bl	ca70 <__gmpn_copyi@plt>
   2b86c:	subs	x8, x21, x23
   2b870:	ldp	x10, x21, [x19, #112]
   2b874:	b.eq	2b894 <__gmpn_rootrem@@Base+0x864>  // b.none
   2b878:	ldr	x9, [x19, #152]
   2b87c:	lsl	x2, x8, #3
   2b880:	mov	w1, wzr
   2b884:	add	x0, x9, x23, lsl #3
   2b888:	mov	x23, x10
   2b88c:	bl	c610 <memset@plt>
   2b890:	mov	x10, x23
   2b894:	ldr	x8, [x20]
   2b898:	ldr	x23, [x19, #152]
   2b89c:	ldr	x11, [x19, #96]
   2b8a0:	orr	x8, x8, x26
   2b8a4:	str	x8, [x20]
   2b8a8:	cbnz	w11, 2b40c <__gmpn_rootrem@@Base+0x3dc>
   2b8ac:	b	2b8f8 <__gmpn_rootrem@@Base+0x8c8>
   2b8b0:	mov	w8, wzr
   2b8b4:	b	2b538 <__gmpn_rootrem@@Base+0x508>
   2b8b8:	mov	w8, wzr
   2b8bc:	b	2b534 <__gmpn_rootrem@@Base+0x504>
   2b8c0:	ldr	x0, [x19, #152]
   2b8c4:	lsl	x8, x27, #3
   2b8c8:	add	x2, x8, #0x8
   2b8cc:	mov	w1, wzr
   2b8d0:	bl	c610 <memset@plt>
   2b8d4:	ldr	x10, [x19, #112]
   2b8d8:	ldr	x22, [x19, #144]
   2b8dc:	b	2b894 <__gmpn_rootrem@@Base+0x864>
   2b8e0:	cmp	x9, #0x1
   2b8e4:	b	2ba04 <__gmpn_rootrem@@Base+0x9d4>
   2b8e8:	ldr	x10, [x19, #112]
   2b8ec:	ldr	x23, [x19, #152]
   2b8f0:	mov	w8, #0x1                   	// #1
   2b8f4:	str	x8, [x19, #176]
   2b8f8:	ldr	w8, [x19, #20]
   2b8fc:	ldr	x9, [x19, #104]
   2b900:	cbz	w8, 2b910 <__gmpn_rootrem@@Base+0x8e0>
   2b904:	ldr	x8, [x23]
   2b908:	cmp	x8, #0x1
   2b90c:	b.hi	2b98c <__gmpn_rootrem@@Base+0x95c>  // b.pmore
   2b910:	ldr	x23, [x19, #80]
   2b914:	ldr	x24, [x19, #56]
   2b918:	add	x8, x10, x23, lsl #3
   2b91c:	sub	x21, x8, #0x8
   2b920:	ldr	x8, [x19, #32]
   2b924:	add	x22, x8, x23, lsl #4
   2b928:	ldp	x26, x0, [x19, #152]
   2b92c:	ldp	x4, x2, [x19, #168]
   2b930:	mov	x3, x24
   2b934:	mov	x1, x26
   2b938:	bl	d230 <__gmpn_pow_1@plt>
   2b93c:	cmp	x0, x23
   2b940:	b.gt	2b974 <__gmpn_rootrem@@Base+0x944>
   2b944:	b.ne	2ba30 <__gmpn_rootrem@@Base+0xa00>  // b.any
   2b948:	mov	x8, xzr
   2b94c:	add	x9, x23, x8
   2b950:	cmp	x9, #0x1
   2b954:	b.lt	2b988 <__gmpn_rootrem@@Base+0x958>  // b.tstop
   2b958:	ldr	x9, [x22, x8, lsl #3]
   2b95c:	ldr	x10, [x21, x8, lsl #3]
   2b960:	sub	x8, x8, #0x1
   2b964:	cmp	x9, x10
   2b968:	b.eq	2b94c <__gmpn_rootrem@@Base+0x91c>  // b.none
   2b96c:	ldr	x26, [x19, #152]
   2b970:	b.ls	2ba38 <__gmpn_rootrem@@Base+0xa08>  // b.plast
   2b974:	ldr	x9, [x26]
   2b978:	sub	x10, x9, #0x1
   2b97c:	str	x10, [x26], #8
   2b980:	cbz	x9, 2b974 <__gmpn_rootrem@@Base+0x944>
   2b984:	b	2b928 <__gmpn_rootrem@@Base+0x8f8>
   2b988:	mov	x9, xzr
   2b98c:	ldr	x0, [x19, #184]
   2b990:	cbz	x0, 2ba0c <__gmpn_rootrem@@Base+0x9dc>
   2b994:	mov	x20, x9
   2b998:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2b99c:	mov	x9, x20
   2b9a0:	b	2ba0c <__gmpn_rootrem@@Base+0x9dc>
   2b9a4:	mov	x10, #0xfffffffffffffff8    	// #-8
   2b9a8:	mov	w9, #0x1                   	// #1
   2b9ac:	cmp	x9, x25
   2b9b0:	b.ge	2b9fc <__gmpn_rootrem@@Base+0x9cc>  // b.tcont
   2b9b4:	ldr	x11, [x2, x9, lsl #3]
   2b9b8:	sub	x10, x10, #0x8
   2b9bc:	sub	x12, x11, #0x1
   2b9c0:	str	x12, [x14, x9, lsl #3]
   2b9c4:	add	x9, x9, #0x1
   2b9c8:	cbz	x11, 2b9ac <__gmpn_rootrem@@Base+0x97c>
   2b9cc:	cmp	x2, x14
   2b9d0:	b.eq	2b9fc <__gmpn_rootrem@@Base+0x9cc>  // b.none
   2b9d4:	cmp	x9, x25
   2b9d8:	b.ge	2b9fc <__gmpn_rootrem@@Base+0x9cc>  // b.tcont
   2b9dc:	sub	x11, x2, x10
   2b9e0:	sub	x10, x14, x10
   2b9e4:	mov	x12, x25
   2b9e8:	ldr	x13, [x11], #8
   2b9ec:	sub	x12, x12, #0x1
   2b9f0:	cmp	x9, x12
   2b9f4:	str	x13, [x10], #8
   2b9f8:	b.ne	2b9e8 <__gmpn_rootrem@@Base+0x9b8>  // b.any
   2b9fc:	ldr	x8, [x14, x8, lsl #3]
   2ba00:	cmp	x8, #0x0
   2ba04:	cset	w8, eq  // eq = none
   2ba08:	sub	x9, x25, x8
   2ba0c:	mov	x0, x9
   2ba10:	mov	sp, x29
   2ba14:	ldp	x20, x19, [sp, #80]
   2ba18:	ldp	x22, x21, [sp, #64]
   2ba1c:	ldp	x24, x23, [sp, #48]
   2ba20:	ldp	x26, x25, [sp, #32]
   2ba24:	ldp	x28, x27, [sp, #16]
   2ba28:	ldp	x29, x30, [sp], #96
   2ba2c:	ret
   2ba30:	mov	x20, x0
   2ba34:	b	2ba3c <__gmpn_rootrem@@Base+0xa0c>
   2ba38:	mov	x20, x23
   2ba3c:	ldr	x0, [x19, #8]
   2ba40:	ldr	x21, [x19, #112]
   2ba44:	cbz	x0, 2ba88 <__gmpn_rootrem@@Base+0xa58>
   2ba48:	cbz	x20, 2ba90 <__gmpn_rootrem@@Base+0xa60>
   2ba4c:	ldr	x2, [x19, #160]
   2ba50:	mov	x1, x21
   2ba54:	mov	x3, x20
   2ba58:	bl	c2e0 <__gmpn_sub_n@plt>
   2ba5c:	cbz	x0, 2ba98 <__gmpn_rootrem@@Base+0xa68>
   2ba60:	ldr	x0, [x19, #8]
   2ba64:	cmp	x20, x23
   2ba68:	b.ge	2bacc <__gmpn_rootrem@@Base+0xa9c>  // b.tcont
   2ba6c:	ldr	x8, [x21, x20, lsl #3]
   2ba70:	add	x9, x20, #0x1
   2ba74:	sub	x10, x8, #0x1
   2ba78:	str	x10, [x0, x20, lsl #3]
   2ba7c:	mov	x20, x9
   2ba80:	cbz	x8, 2ba64 <__gmpn_rootrem@@Base+0xa34>
   2ba84:	b	2baa0 <__gmpn_rootrem@@Base+0xa70>
   2ba88:	mov	w9, #0x1                   	// #1
   2ba8c:	b	2b98c <__gmpn_rootrem@@Base+0x95c>
   2ba90:	mov	x9, xzr
   2ba94:	b	2baa0 <__gmpn_rootrem@@Base+0xa70>
   2ba98:	ldr	x0, [x19, #8]
   2ba9c:	mov	x9, x20
   2baa0:	cmp	x0, x21
   2baa4:	b.eq	2bacc <__gmpn_rootrem@@Base+0xa9c>  // b.none
   2baa8:	cmp	x9, x23
   2baac:	b.ge	2bacc <__gmpn_rootrem@@Base+0xa9c>  // b.tcont
   2bab0:	sub	x8, x23, x9
   2bab4:	add	x10, x0, x9, lsl #3
   2bab8:	add	x9, x21, x9, lsl #3
   2babc:	ldr	x11, [x9], #8
   2bac0:	subs	x8, x8, #0x1
   2bac4:	str	x11, [x10], #8
   2bac8:	b.ne	2babc <__gmpn_rootrem@@Base+0xa8c>  // b.any
   2bacc:	sub	x8, x0, #0x8
   2bad0:	ldr	x10, [x8, x23, lsl #3]
   2bad4:	sub	x9, x23, #0x1
   2bad8:	mov	x23, x9
   2badc:	cbz	x10, 2bad0 <__gmpn_rootrem@@Base+0xaa0>
   2bae0:	add	x9, x9, #0x1
   2bae4:	b	2b98c <__gmpn_rootrem@@Base+0x95c>
   2bae8:	adrp	x10, 54000 <__gmpn_bases@@Base+0x2938>
   2baec:	add	x10, x10, #0x334
   2baf0:	ldrb	w10, [x10, x8]
   2baf4:	udiv	x8, x9, x27
   2baf8:	msub	x9, x8, x27, x9
   2bafc:	bfi	x10, x9, #8, #56
   2bb00:	udiv	x9, x10, x27
   2bb04:	b	2b294 <__gmpn_rootrem@@Base+0x264>
   2bb08:	add	x0, x19, #0xb8
   2bb0c:	mov	x26, x14
   2bb10:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2bb14:	mov	x14, x26
   2bb18:	b	2b3ac <__gmpn_rootrem@@Base+0x37c>

000000000002bb1c <__gmpn_sqrtrem@@Base>:
   2bb1c:	stp	x29, x30, [sp, #-96]!
   2bb20:	str	x27, [sp, #16]
   2bb24:	stp	x26, x25, [sp, #32]
   2bb28:	stp	x24, x23, [sp, #48]
   2bb2c:	stp	x22, x21, [sp, #64]
   2bb30:	stp	x20, x19, [sp, #80]
   2bb34:	mov	x29, sp
   2bb38:	sub	sp, sp, #0x20
   2bb3c:	add	x8, x2, x3, lsl #3
   2bb40:	ldur	x20, [x8, #-8]
   2bb44:	mov	x22, x2
   2bb48:	mov	x21, x1
   2bb4c:	mov	x19, x0
   2bb50:	clz	x8, x20
   2bb54:	lsr	x9, x20, #62
   2bb58:	ubfx	x8, x8, #1, #31
   2bb5c:	cmp	x9, #0x0
   2bb60:	csel	w25, wzr, w8, ne  // ne = any
   2bb64:	cmp	x3, #0x2
   2bb68:	b.eq	2bba4 <__gmpn_sqrtrem@@Base+0x88>  // b.none
   2bb6c:	mov	x23, x3
   2bb70:	cmp	x3, #0x1
   2bb74:	b.ne	2bc00 <__gmpn_sqrtrem@@Base+0xe4>  // b.any
   2bb78:	cbz	w25, 2bcb4 <__gmpn_sqrtrem@@Base+0x198>
   2bb7c:	lsl	w8, w25, #1
   2bb80:	lsl	x1, x20, x8
   2bb84:	add	x0, x29, #0x18
   2bb88:	bl	2bf24 <__gmpn_sqrtrem@@Base+0x408>
   2bb8c:	lsr	x8, x0, x25
   2bb90:	str	x8, [x19]
   2bb94:	cbz	x21, 2bcd0 <__gmpn_sqrtrem@@Base+0x1b4>
   2bb98:	msub	x8, x8, x8, x20
   2bb9c:	str	x8, [x29, #24]
   2bba0:	b	2bccc <__gmpn_sqrtrem@@Base+0x1b0>
   2bba4:	cmp	x21, #0x0
   2bba8:	sub	x8, x29, #0x10
   2bbac:	csel	x21, x8, x21, eq  // eq = none
   2bbb0:	cbz	w25, 2bce0 <__gmpn_sqrtrem@@Base+0x1c4>
   2bbb4:	ldr	x22, [x22]
   2bbb8:	lsl	w8, w25, #1
   2bbbc:	neg	w10, w8
   2bbc0:	lsl	x9, x20, x8
   2bbc4:	lsr	x10, x22, x10
   2bbc8:	lsl	x8, x22, x8
   2bbcc:	orr	x9, x10, x9
   2bbd0:	mov	x0, x19
   2bbd4:	mov	x1, x21
   2bbd8:	mov	x2, x21
   2bbdc:	stp	x8, x9, [x21]
   2bbe0:	bl	2bfc0 <__gmpn_sqrtrem@@Base+0x4a4>
   2bbe4:	ldr	x8, [x19]
   2bbe8:	lsr	x8, x8, x25
   2bbec:	str	x8, [x19]
   2bbf0:	msub	x8, x8, x8, x22
   2bbf4:	str	x8, [x29, #24]
   2bbf8:	str	x8, [x21]
   2bbfc:	b	2bcd4 <__gmpn_sqrtrem@@Base+0x1b8>
   2bc00:	add	x24, x23, #0x1
   2bc04:	add	x8, x23, #0x2
   2bc08:	cmp	x24, #0x0
   2bc0c:	csinc	x8, x8, x23, lt  // lt = tstop
   2bc10:	asr	x20, x8, #1
   2bc14:	cbnz	x21, 2bc40 <__gmpn_sqrtrem@@Base+0x124>
   2bc18:	cmp	x23, #0x9
   2bc1c:	b.lt	2bc40 <__gmpn_sqrtrem@@Base+0x124>  // b.tstop
   2bc20:	and	w4, w23, #0x1
   2bc24:	mov	x0, x19
   2bc28:	mov	x1, x22
   2bc2c:	mov	x2, x20
   2bc30:	mov	w3, w25
   2bc34:	bl	2c048 <__gmpn_sqrtrem@@Base+0x52c>
   2bc38:	sxtw	x20, w0
   2bc3c:	b	2bed8 <__gmpn_sqrtrem@@Base+0x3bc>
   2bc40:	and	x27, x23, #0x1
   2bc44:	orr	x8, x27, x25
   2bc48:	stur	xzr, [x29, #-16]
   2bc4c:	cbz	x8, 2bd08 <__gmpn_sqrtrem@@Base+0x1ec>
   2bc50:	add	x8, x24, #0x3
   2bc54:	cmp	x24, #0x0
   2bc58:	csel	x8, x8, x24, lt  // lt = tstop
   2bc5c:	lsr	x8, x8, #2
   2bc60:	add	x8, x8, x20, lsl #1
   2bc64:	lsl	x8, x8, #3
   2bc68:	add	x1, x8, #0x8
   2bc6c:	mov	w8, #0x7f00                	// #32512
   2bc70:	cmp	x1, x8
   2bc74:	lsl	x26, x20, #1
   2bc78:	b.hi	2bf04 <__gmpn_sqrtrem@@Base+0x3e8>  // b.pmore
   2bc7c:	add	x9, x1, #0xf
   2bc80:	mov	x8, sp
   2bc84:	and	x9, x9, #0xfffffffffffffff0
   2bc88:	sub	x24, x8, x9
   2bc8c:	mov	sp, x24
   2bc90:	add	x26, x24, x26, lsl #3
   2bc94:	add	x0, x24, x27, lsl #3
   2bc98:	str	xzr, [x24]
   2bc9c:	cbz	w25, 2bd98 <__gmpn_sqrtrem@@Base+0x27c>
   2bca0:	lsl	w3, w25, #1
   2bca4:	mov	x1, x22
   2bca8:	mov	x2, x23
   2bcac:	bl	c190 <__gmpn_lshift@plt>
   2bcb0:	b	2bda4 <__gmpn_sqrtrem@@Base+0x288>
   2bcb4:	add	x0, x29, #0x18
   2bcb8:	mov	x1, x20
   2bcbc:	bl	2bf24 <__gmpn_sqrtrem@@Base+0x408>
   2bcc0:	str	x0, [x19]
   2bcc4:	cbz	x21, 2bcd0 <__gmpn_sqrtrem@@Base+0x1b4>
   2bcc8:	ldr	x8, [x29, #24]
   2bccc:	str	x8, [x21]
   2bcd0:	ldr	x8, [x29, #24]
   2bcd4:	cmp	x8, #0x0
   2bcd8:	cset	w20, ne  // ne = any
   2bcdc:	b	2bed8 <__gmpn_sqrtrem@@Base+0x3bc>
   2bce0:	mov	x0, x19
   2bce4:	mov	x1, x21
   2bce8:	mov	x2, x22
   2bcec:	bl	2bfc0 <__gmpn_sqrtrem@@Base+0x4a4>
   2bcf0:	ldr	x8, [x21]
   2bcf4:	str	x0, [x21, #8]
   2bcf8:	orr	x8, x8, x0
   2bcfc:	cmp	x8, #0x0
   2bd00:	cinc	x20, x0, ne  // ne = any
   2bd04:	b	2bed8 <__gmpn_sqrtrem@@Base+0x3bc>
   2bd08:	cmp	x21, x22
   2bd0c:	b.eq	2bd40 <__gmpn_sqrtrem@@Base+0x224>  // b.none
   2bd10:	cbnz	x21, 2bd2c <__gmpn_sqrtrem@@Base+0x210>
   2bd14:	lsl	x8, x23, #3
   2bd18:	add	x8, x8, #0xf
   2bd1c:	mov	x9, sp
   2bd20:	and	x8, x8, #0xfffffffffffffff0
   2bd24:	sub	x21, x9, x8
   2bd28:	mov	sp, x21
   2bd2c:	mov	x0, x21
   2bd30:	mov	x1, x22
   2bd34:	mov	x2, x23
   2bd38:	bl	ca70 <__gmpn_copyi@plt>
   2bd3c:	mov	x22, x21
   2bd40:	add	x8, x24, #0x3
   2bd44:	cmp	x24, #0x0
   2bd48:	csel	x8, x8, x24, lt  // lt = tstop
   2bd4c:	lsl	x8, x8, #1
   2bd50:	and	x8, x8, #0xfffffffffffffff8
   2bd54:	add	x1, x8, #0x8
   2bd58:	mov	w8, #0x7f00                	// #32512
   2bd5c:	cmp	x1, x8
   2bd60:	b.hi	2bf14 <__gmpn_sqrtrem@@Base+0x3f8>  // b.pmore
   2bd64:	add	x9, x1, #0xf
   2bd68:	mov	x8, sp
   2bd6c:	and	x9, x9, #0xfffffffffffffff0
   2bd70:	sub	x4, x8, x9
   2bd74:	mov	sp, x4
   2bd78:	mov	x0, x19
   2bd7c:	mov	x1, x22
   2bd80:	mov	x2, x20
   2bd84:	mov	x3, xzr
   2bd88:	bl	2c4a4 <__gmpn_sqrtrem@@Base+0x988>
   2bd8c:	add	x19, x0, x20
   2bd90:	str	x0, [x22, x20, lsl #3]
   2bd94:	b	2beb8 <__gmpn_sqrtrem@@Base+0x39c>
   2bd98:	mov	x1, x22
   2bd9c:	mov	x2, x23
   2bda0:	bl	ca70 <__gmpn_copyi@plt>
   2bda4:	add	w25, w25, w27, lsl #5
   2bda8:	mov	x8, #0xffffffffffffffff    	// #-1
   2bdac:	mov	x9, #0xfffffffffffffffe    	// #-2
   2bdb0:	lsl	x27, x8, x25
   2bdb4:	sub	x8, x9, x27
   2bdb8:	cmp	x21, #0x0
   2bdbc:	csel	x3, x8, xzr, eq  // eq = none
   2bdc0:	mov	x0, x19
   2bdc4:	mov	x1, x24
   2bdc8:	mov	x2, x20
   2bdcc:	mov	x4, x26
   2bdd0:	bl	2c4a4 <__gmpn_sqrtrem@@Base+0x988>
   2bdd4:	ldr	x8, [x19]
   2bdd8:	mov	x22, x0
   2bddc:	mov	x0, x24
   2bde0:	mov	x1, x19
   2bde4:	bic	x26, x8, x27
   2bde8:	lsl	x3, x26, #1
   2bdec:	mov	x2, x20
   2bdf0:	stur	x26, [x29, #-24]
   2bdf4:	bl	d420 <__gmpn_addmul_1@plt>
   2bdf8:	add	x22, x0, x22
   2bdfc:	sub	x1, x29, #0x18
   2be00:	mov	w2, #0x1                   	// #1
   2be04:	mov	x0, x24
   2be08:	mov	x3, x26
   2be0c:	str	x22, [x29, #24]
   2be10:	bl	ca00 <__gmpn_submul_1@plt>
   2be14:	cmp	x23, #0x3
   2be18:	b.lt	2be5c <__gmpn_sqrtrem@@Base+0x340>  // b.tstop
   2be1c:	ldr	x8, [x24, #8]
   2be20:	subs	x8, x8, x0
   2be24:	str	x8, [x24, #8]
   2be28:	b.cs	2be58 <__gmpn_sqrtrem@@Base+0x33c>  // b.hs, b.nlast
   2be2c:	sub	x8, x20, #0x1
   2be30:	mov	w9, #0x2                   	// #2
   2be34:	mov	w0, #0x1                   	// #1
   2be38:	sub	x10, x9, #0x1
   2be3c:	cmp	x10, x8
   2be40:	b.ge	2be5c <__gmpn_sqrtrem@@Base+0x340>  // b.tcont
   2be44:	ldr	x10, [x24, x9, lsl #3]
   2be48:	sub	x11, x10, #0x1
   2be4c:	str	x11, [x24, x9, lsl #3]
   2be50:	add	x9, x9, #0x1
   2be54:	cbz	x10, 2be38 <__gmpn_sqrtrem@@Base+0x31c>
   2be58:	mov	x0, xzr
   2be5c:	sub	x22, x22, x0
   2be60:	mov	x0, x19
   2be64:	mov	x1, x19
   2be68:	mov	x2, x20
   2be6c:	mov	w3, w25
   2be70:	str	x22, [x29, #24]
   2be74:	bl	c1b0 <__gmpn_rshift@plt>
   2be78:	cmp	x21, #0x0
   2be7c:	str	x22, [x24, x20, lsl #3]
   2be80:	lsl	w8, w25, #1
   2be84:	csel	x22, x24, x21, eq  // eq = none
   2be88:	cmp	w25, #0x20
   2be8c:	add	x9, x24, #0x8
   2be90:	sub	w10, w8, #0x40
   2be94:	cinc	x19, x20, cc  // cc = lo, ul, last
   2be98:	csel	w3, w8, w10, cc  // cc = lo, ul, last
   2be9c:	csel	x1, x24, x9, cc  // cc = lo, ul, last
   2bea0:	mov	x0, x22
   2bea4:	mov	x2, x19
   2bea8:	cbz	w3, 2beb4 <__gmpn_sqrtrem@@Base+0x398>
   2beac:	bl	c1b0 <__gmpn_rshift@plt>
   2beb0:	b	2beb8 <__gmpn_sqrtrem@@Base+0x39c>
   2beb4:	bl	ca70 <__gmpn_copyi@plt>
   2beb8:	sub	x8, x22, #0x8
   2bebc:	mov	x20, x19
   2bec0:	subs	x19, x19, #0x1
   2bec4:	b.lt	2bed0 <__gmpn_sqrtrem@@Base+0x3b4>  // b.tstop
   2bec8:	ldr	x9, [x8, x20, lsl #3]
   2becc:	cbz	x9, 2bebc <__gmpn_sqrtrem@@Base+0x3a0>
   2bed0:	ldur	x0, [x29, #-16]
   2bed4:	cbnz	x0, 2befc <__gmpn_sqrtrem@@Base+0x3e0>
   2bed8:	mov	x0, x20
   2bedc:	mov	sp, x29
   2bee0:	ldp	x20, x19, [sp, #80]
   2bee4:	ldp	x22, x21, [sp, #64]
   2bee8:	ldp	x24, x23, [sp, #48]
   2beec:	ldp	x26, x25, [sp, #32]
   2bef0:	ldr	x27, [sp, #16]
   2bef4:	ldp	x29, x30, [sp], #96
   2bef8:	ret
   2befc:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2bf00:	b	2bed8 <__gmpn_sqrtrem@@Base+0x3bc>
   2bf04:	sub	x0, x29, #0x10
   2bf08:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2bf0c:	mov	x24, x0
   2bf10:	b	2bc90 <__gmpn_sqrtrem@@Base+0x174>
   2bf14:	sub	x0, x29, #0x10
   2bf18:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2bf1c:	mov	x4, x0
   2bf20:	b	2bd78 <__gmpn_sqrtrem@@Base+0x25c>
   2bf24:	lsr	x8, x1, #55
   2bf28:	adrp	x9, 54000 <__gmpn_bases@@Base+0x2938>
   2bf2c:	add	x9, x9, #0x534
   2bf30:	sub	w8, w8, #0x80
   2bf34:	ldrb	w8, [x9, w8, uxtw]
   2bf38:	lsr	x10, x1, #31
   2bf3c:	mov	x9, #0x1ffff00000000       	// #562945658454016
   2bf40:	movk	x9, #0xfffd, lsl #16
   2bf44:	orr	x8, x8, #0x100
   2bf48:	mul	x10, x8, x10
   2bf4c:	msub	x9, x10, x8, x9
   2bf50:	asr	x9, x9, #16
   2bf54:	mul	x9, x9, x8
   2bf58:	asr	x9, x9, #18
   2bf5c:	lsr	x11, x1, #24
   2bf60:	add	x8, x9, x8, lsl #16
   2bf64:	mul	x9, x8, x11
   2bf68:	lsl	x12, x1, #14
   2bf6c:	lsr	x11, x9, #25
   2bf70:	mov	x10, #0xffffff0000000000    	// #-1099511627776
   2bf74:	msub	x11, x11, x11, x12
   2bf78:	add	x10, x11, x10
   2bf7c:	asr	x10, x10, #24
   2bf80:	mul	x8, x10, x8
   2bf84:	add	x8, x9, x8, asr #15
   2bf88:	lsr	x8, x8, #32
   2bf8c:	mul	x9, x8, x8
   2bf90:	sub	x12, x1, #0x1
   2bf94:	mov	w11, #0x1                   	// #1
   2bf98:	add	x10, x9, x8, lsl #1
   2bf9c:	bfi	x11, x8, #1, #32
   2bfa0:	cmp	x10, x12
   2bfa4:	csneg	x10, xzr, x11, hi  // hi = pmore
   2bfa8:	sub	x9, x1, x9
   2bfac:	cinc	x8, x8, ls  // ls = plast
   2bfb0:	add	x9, x9, x10
   2bfb4:	str	x9, [x0]
   2bfb8:	mov	x0, x8
   2bfbc:	ret
   2bfc0:	stp	x29, x30, [sp, #-48]!
   2bfc4:	str	x21, [sp, #16]
   2bfc8:	stp	x20, x19, [sp, #32]
   2bfcc:	mov	x20, x1
   2bfd0:	ldp	x21, x1, [x2]
   2bfd4:	mov	x19, x0
   2bfd8:	mov	x0, x20
   2bfdc:	mov	x29, sp
   2bfe0:	bl	2bf24 <__gmpn_sqrtrem@@Base+0x408>
   2bfe4:	ldr	x8, [x20]
   2bfe8:	extr	x8, x8, x21, #33
   2bfec:	udiv	x9, x8, x0
   2bff0:	sub	x11, x9, x9, lsr #32
   2bff4:	msub	x8, x11, x0, x8
   2bff8:	lsr	x9, x8, #31
   2bffc:	bfi	x21, x8, #33, #31
   2c000:	mul	x8, x11, x11
   2c004:	subs	x10, x21, x8
   2c008:	cset	w8, cc  // cc = lo, ul, last
   2c00c:	subs	w9, w9, w8
   2c010:	orr	x8, x11, x0, lsl #32
   2c014:	b.pl	2c02c <__gmpn_sqrtrem@@Base+0x510>  // b.nfrst
   2c018:	adds	x10, x10, x8
   2c01c:	sub	x8, x8, #0x1
   2c020:	cinc	w9, w9, cs  // cs = hs, nlast
   2c024:	adds	x10, x10, x8
   2c028:	cinc	w9, w9, cs  // cs = hs, nlast
   2c02c:	str	x10, [x20]
   2c030:	str	x8, [x19]
   2c034:	ldp	x20, x19, [sp, #32]
   2c038:	ldr	x21, [sp, #16]
   2c03c:	sxtw	x0, w9
   2c040:	ldp	x29, x30, [sp], #48
   2c044:	ret
   2c048:	stp	x29, x30, [sp, #-96]!
   2c04c:	stp	x28, x27, [sp, #16]
   2c050:	stp	x26, x25, [sp, #32]
   2c054:	stp	x24, x23, [sp, #48]
   2c058:	stp	x22, x21, [sp, #64]
   2c05c:	stp	x20, x19, [sp, #80]
   2c060:	mov	x29, sp
   2c064:	sub	sp, sp, #0x30
   2c068:	sub	x8, x2, #0x1
   2c06c:	cmp	x8, #0x0
   2c070:	csel	x8, x2, x8, lt  // lt = tstop
   2c074:	asr	x23, x8, #1
   2c078:	add	x9, x23, x2, lsl #1
   2c07c:	lsl	x9, x9, #3
   2c080:	mov	x24, x1
   2c084:	add	x1, x9, #0x20
   2c088:	mov	w9, #0x7f00                	// #32512
   2c08c:	mov	w21, w3
   2c090:	mov	x19, x2
   2c094:	mov	x20, x0
   2c098:	cmp	x1, x9
   2c09c:	sub	x27, x2, x8, asr #1
   2c0a0:	stur	xzr, [x29, #-8]
   2c0a4:	b.hi	2c47c <__gmpn_sqrtrem@@Base+0x960>  // b.pmore
   2c0a8:	add	x9, x1, #0xf
   2c0ac:	mov	x8, sp
   2c0b0:	and	x9, x9, #0xfffffffffffffff0
   2c0b4:	sub	x22, x8, x9
   2c0b8:	mov	sp, x22
   2c0bc:	add	x8, x22, x19, lsl #3
   2c0c0:	add	x26, x8, #0x8
   2c0c4:	stp	w4, w21, [x29, #-16]
   2c0c8:	cbz	w21, 2c108 <__gmpn_sqrtrem@@Base+0x5ec>
   2c0cc:	add	w8, w4, #0x1
   2c0d0:	mov	x9, #0xfffffffffffffff8    	// #-8
   2c0d4:	cmp	x23, x8
   2c0d8:	add	x10, x24, x23, lsl #3
   2c0dc:	csel	x8, x9, xzr, gt
   2c0e0:	add	x11, x19, x27
   2c0e4:	add	x0, x26, x8
   2c0e8:	add	x8, x10, x8
   2c0ec:	cinc	x9, x11, gt
   2c0f0:	sub	x8, x8, w4, uxtw #3
   2c0f4:	add	x2, x9, #0x1
   2c0f8:	sub	x1, x8, #0x8
   2c0fc:	lsl	w3, w21, #1
   2c100:	bl	c190 <__gmpn_lshift@plt>
   2c104:	b	2c124 <__gmpn_sqrtrem@@Base+0x608>
   2c108:	add	x8, x24, x23, lsl #3
   2c10c:	add	x9, x19, x27
   2c110:	sub	x8, x8, w4, uxtw #3
   2c114:	sub	x1, x8, #0x8
   2c118:	add	x2, x9, #0x1
   2c11c:	mov	x0, x26
   2c120:	bl	ca70 <__gmpn_copyi@plt>
   2c124:	add	x8, x26, x23, lsl #3
   2c128:	add	x28, x20, x23, lsl #3
   2c12c:	add	x21, x8, #0x8
   2c130:	mov	x0, x28
   2c134:	mov	x1, x21
   2c138:	mov	x2, x27
   2c13c:	mov	x3, xzr
   2c140:	mov	x4, x22
   2c144:	mov	x25, x20
   2c148:	bl	2c4a4 <__gmpn_sqrtrem@@Base+0x988>
   2c14c:	mov	x20, x0
   2c150:	cbz	x0, 2c168 <__gmpn_sqrtrem@@Base+0x64c>
   2c154:	mov	x0, x21
   2c158:	mov	x1, x21
   2c15c:	mov	x2, x28
   2c160:	mov	x3, x27
   2c164:	bl	c2e0 <__gmpn_sub_n@plt>
   2c168:	add	x8, x26, x19, lsl #3
   2c16c:	add	x21, x8, #0x8
   2c170:	add	x2, x19, #0x1
   2c174:	mov	x0, x21
   2c178:	mov	x1, x26
   2c17c:	mov	x3, x28
   2c180:	mov	x4, x27
   2c184:	mov	x5, x22
   2c188:	stp	x22, x26, [x29, #-32]
   2c18c:	bl	2c728 <__gmpn_sqrtrem@@Base+0xc0c>
   2c190:	add	x22, x23, #0x1
   2c194:	ldr	x8, [x21, x22, lsl #3]
   2c198:	add	x26, x8, x20
   2c19c:	cmp	x26, #0x2
   2c1a0:	b.cc	2c1c4 <__gmpn_sqrtrem@@Base+0x6a8>  // b.lo, b.ul, b.last
   2c1a4:	lsl	x2, x23, #3
   2c1a8:	mov	w1, #0xff                  	// #255
   2c1ac:	mov	x0, x25
   2c1b0:	mov	x21, x25
   2c1b4:	bl	c610 <memset@plt>
   2c1b8:	ldp	w13, w25, [x29, #-16]
   2c1bc:	mov	w24, #0x1                   	// #1
   2c1c0:	b	2c228 <__gmpn_sqrtrem@@Base+0x70c>
   2c1c4:	add	x20, x21, #0x8
   2c1c8:	mov	w3, #0x1                   	// #1
   2c1cc:	mov	x0, x25
   2c1d0:	mov	x1, x20
   2c1d4:	mov	x2, x23
   2c1d8:	stur	x24, [x29, #-40]
   2c1dc:	mov	w24, #0x1                   	// #1
   2c1e0:	bl	c1b0 <__gmpn_rshift@plt>
   2c1e4:	add	x8, x25, x23, lsl #3
   2c1e8:	ldur	x9, [x8, #-8]
   2c1ec:	ldur	w13, [x29, #-16]
   2c1f0:	mov	w10, #0x40                  	// #64
   2c1f4:	orr	x9, x9, x26, lsl #63
   2c1f8:	stur	x9, [x8, #-8]
   2c1fc:	ldp	x8, x9, [x21]
   2c200:	mov	x21, x25
   2c204:	ldur	w25, [x29, #-12]
   2c208:	lsr	w10, w10, w13
   2c20c:	mvn	w11, w25
   2c210:	add	w10, w10, w11
   2c214:	mov	x11, #0xffffffffffffffff    	// #-1
   2c218:	lsr	x10, x11, x10
   2c21c:	and	x9, x9, x10
   2c220:	orr	x8, x9, x8, lsr #3
   2c224:	cbz	x8, 2c278 <__gmpn_sqrtrem@@Base+0x75c>
   2c228:	ldur	x0, [x29, #-8]
   2c22c:	cbnz	x0, 2c494 <__gmpn_sqrtrem@@Base+0x978>
   2c230:	orr	w8, w13, w25
   2c234:	cbz	w8, 2c254 <__gmpn_sqrtrem@@Base+0x738>
   2c238:	cmp	w13, #0x0
   2c23c:	cset	w8, ne  // ne = any
   2c240:	add	w3, w25, w8, lsl #5
   2c244:	mov	x0, x21
   2c248:	mov	x1, x21
   2c24c:	mov	x2, x19
   2c250:	bl	c1b0 <__gmpn_rshift@plt>
   2c254:	mov	w0, w24
   2c258:	mov	sp, x29
   2c25c:	ldp	x20, x19, [sp, #80]
   2c260:	ldp	x22, x21, [sp, #64]
   2c264:	ldp	x24, x23, [sp, #48]
   2c268:	ldp	x26, x25, [sp, #32]
   2c26c:	ldp	x28, x27, [sp, #16]
   2c270:	ldp	x29, x30, [sp], #96
   2c274:	ret
   2c278:	ldur	x0, [x29, #-32]
   2c27c:	mov	x1, x28
   2c280:	mov	x2, x27
   2c284:	mov	x3, x20
   2c288:	mov	x4, x22
   2c28c:	mov	w26, w13
   2c290:	mov	x22, x0
   2c294:	bl	ccf0 <__gmpn_mul@plt>
   2c298:	ldur	x8, [x29, #-24]
   2c29c:	mov	x2, x22
   2c2a0:	mov	x3, x27
   2c2a4:	add	x24, x8, #0x8
   2c2a8:	mov	x0, x24
   2c2ac:	mov	x1, x24
   2c2b0:	bl	c2e0 <__gmpn_sub_n@plt>
   2c2b4:	ldr	x8, [x24, x27, lsl #3]
   2c2b8:	lsl	x20, x19, #4
   2c2bc:	subs	x8, x8, x0
   2c2c0:	str	x8, [x24, x27, lsl #3]
   2c2c4:	b.cs	2c2e4 <__gmpn_sqrtrem@@Base+0x7c8>  // b.hs, b.nlast
   2c2c8:	sub	x8, x20, x23, lsl #3
   2c2cc:	add	x8, x8, x22
   2c2d0:	add	x8, x8, #0x18
   2c2d4:	ldr	x9, [x8]
   2c2d8:	sub	x10, x9, #0x1
   2c2dc:	str	x10, [x8], #8
   2c2e0:	cbz	x9, 2c2d4 <__gmpn_sqrtrem@@Base+0x7b8>
   2c2e4:	add	x9, x22, x19, lsl #3
   2c2e8:	add	x10, x22, x19, lsl #4
   2c2ec:	mov	x8, xzr
   2c2f0:	sub	x9, x9, #0x8
   2c2f4:	add	x10, x10, #0x8
   2c2f8:	mov	w13, w26
   2c2fc:	add	x11, x23, x8
   2c300:	cmp	x11, #0x1
   2c304:	b.lt	2c388 <__gmpn_sqrtrem@@Base+0x86c>  // b.tstop
   2c308:	ldr	x11, [x10, x8, lsl #3]
   2c30c:	ldr	x12, [x9, x8, lsl #3]
   2c310:	sub	x8, x8, #0x1
   2c314:	cmp	x11, x12
   2c318:	b.eq	2c2fc <__gmpn_sqrtrem@@Base+0x7e0>  // b.none
   2c31c:	b.hi	2c388 <__gmpn_sqrtrem@@Base+0x86c>  // b.pmore
   2c320:	mov	x0, x24
   2c324:	mov	x1, x24
   2c328:	mov	x2, x28
   2c32c:	mov	x3, x27
   2c330:	bl	cc60 <__gmpn_addlsh1_n@plt>
   2c334:	ldr	x8, [x24, x27, lsl #3]
   2c338:	adds	x8, x8, x0
   2c33c:	str	x8, [x24, x27, lsl #3]
   2c340:	b.cc	2c370 <__gmpn_sqrtrem@@Base+0x854>  // b.lo, b.ul, b.last
   2c344:	sub	x8, x20, x23, lsl #3
   2c348:	add	x8, x22, x8
   2c34c:	mov	w9, #0x3                   	// #3
   2c350:	sub	x10, x9, #0x2
   2c354:	cmp	x10, x23
   2c358:	b.ge	2c370 <__gmpn_sqrtrem@@Base+0x854>  // b.tcont
   2c35c:	ldr	x10, [x8, x9, lsl #3]
   2c360:	adds	x10, x10, #0x1
   2c364:	str	x10, [x8, x9, lsl #3]
   2c368:	add	x9, x9, #0x1
   2c36c:	b.cs	2c350 <__gmpn_sqrtrem@@Base+0x834>  // b.hs, b.nlast
   2c370:	mov	x8, x21
   2c374:	mov	w13, w26
   2c378:	ldr	x9, [x8]
   2c37c:	sub	x10, x9, #0x1
   2c380:	str	x10, [x8], #8
   2c384:	cbz	x9, 2c378 <__gmpn_sqrtrem@@Base+0x85c>
   2c388:	sub	x9, x20, x23, lsl #3
   2c38c:	ldur	x20, [x29, #-40]
   2c390:	add	x9, x9, x22
   2c394:	sub	x8, x27, x23
   2c398:	add	x9, x9, #0x8
   2c39c:	ldr	x10, [x9]
   2c3a0:	cbnz	x10, 2c1bc <__gmpn_sqrtrem@@Base+0x6a0>
   2c3a4:	sub	x8, x8, #0x1
   2c3a8:	sub	x9, x9, #0x8
   2c3ac:	cbnz	x8, 2c39c <__gmpn_sqrtrem@@Base+0x880>
   2c3b0:	mov	x0, x22
   2c3b4:	mov	x1, x21
   2c3b8:	mov	x2, x23
   2c3bc:	bl	c900 <__gmpn_sqr@plt>
   2c3c0:	lsl	x10, x23, #3
   2c3c4:	add	x10, x10, x19, lsl #3
   2c3c8:	add	x9, x22, x23, lsl #4
   2c3cc:	add	x10, x10, x22
   2c3d0:	mov	w13, w26
   2c3d4:	mov	x8, xzr
   2c3d8:	sub	x9, x9, #0x8
   2c3dc:	add	x10, x10, #0x8
   2c3e0:	add	x11, x23, x8
   2c3e4:	cmp	x11, #0x1
   2c3e8:	b.lt	2c404 <__gmpn_sqrtrem@@Base+0x8e8>  // b.tstop
   2c3ec:	ldr	x11, [x10, x8, lsl #3]
   2c3f0:	ldr	x12, [x9, x8, lsl #3]
   2c3f4:	sub	x8, x8, #0x1
   2c3f8:	cmp	x11, x12
   2c3fc:	b.eq	2c3e0 <__gmpn_sqrtrem@@Base+0x8c4>  // b.none
   2c400:	b	2c458 <__gmpn_sqrtrem@@Base+0x93c>
   2c404:	cbz	w25, 2c428 <__gmpn_sqrtrem@@Base+0x90c>
   2c408:	ldur	x24, [x29, #-24]
   2c40c:	lsl	w3, w25, #1
   2c410:	mov	x1, x20
   2c414:	mov	x2, x23
   2c418:	mov	x0, x24
   2c41c:	bl	c190 <__gmpn_lshift@plt>
   2c420:	mov	w13, w26
   2c424:	b	2c42c <__gmpn_sqrtrem@@Base+0x910>
   2c428:	mov	x24, x20
   2c42c:	add	x8, x22, x23, lsl #3
   2c430:	sub	x10, x23, w13, uxtw
   2c434:	sub	x8, x8, #0x8
   2c438:	sub	x9, x24, #0x8
   2c43c:	subs	x11, x10, #0x1
   2c440:	b.lt	2c474 <__gmpn_sqrtrem@@Base+0x958>  // b.tstop
   2c444:	ldr	x10, [x9, x10, lsl #3]
   2c448:	ldr	x12, [x8], #-8
   2c44c:	cmp	x10, x12
   2c450:	mov	x10, x11
   2c454:	b.eq	2c43c <__gmpn_sqrtrem@@Base+0x920>  // b.none
   2c458:	b.hi	2c1bc <__gmpn_sqrtrem@@Base+0x6a0>  // b.pmore
   2c45c:	mov	x8, x21
   2c460:	ldr	x9, [x8]
   2c464:	sub	x10, x9, #0x1
   2c468:	str	x10, [x8], #8
   2c46c:	cbz	x9, 2c460 <__gmpn_sqrtrem@@Base+0x944>
   2c470:	b	2c1bc <__gmpn_sqrtrem@@Base+0x6a0>
   2c474:	mov	w24, wzr
   2c478:	b	2c228 <__gmpn_sqrtrem@@Base+0x70c>
   2c47c:	sub	x0, x29, #0x8
   2c480:	mov	w22, w4
   2c484:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2c488:	mov	w4, w22
   2c48c:	mov	x22, x0
   2c490:	b	2c0bc <__gmpn_sqrtrem@@Base+0x5a0>
   2c494:	mov	w20, w13
   2c498:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2c49c:	mov	w13, w20
   2c4a0:	b	2c230 <__gmpn_sqrtrem@@Base+0x714>
   2c4a4:	sub	sp, sp, #0x80
   2c4a8:	cmp	x2, #0x0
   2c4ac:	cinc	x8, x2, lt  // lt = tstop
   2c4b0:	stp	x24, x23, [sp, #80]
   2c4b4:	asr	x24, x8, #1
   2c4b8:	stp	x26, x25, [sp, #64]
   2c4bc:	stp	x22, x21, [sp, #96]
   2c4c0:	sub	x22, x2, x8, asr #1
   2c4c4:	add	x23, x0, x24, lsl #3
   2c4c8:	add	x25, x1, x24, lsl #4
   2c4cc:	stp	x29, x30, [sp, #32]
   2c4d0:	stp	x28, x27, [sp, #48]
   2c4d4:	stp	x20, x19, [sp, #112]
   2c4d8:	add	x29, sp, #0x20
   2c4dc:	mov	x27, x4
   2c4e0:	mov	x19, x2
   2c4e4:	mov	x21, x1
   2c4e8:	mov	x20, x0
   2c4ec:	cmp	x22, #0x1
   2c4f0:	mov	x0, x23
   2c4f4:	mov	x1, x25
   2c4f8:	stur	x3, [x29, #-8]
   2c4fc:	str	x8, [sp, #8]
   2c500:	b.ne	2c510 <__gmpn_sqrtrem@@Base+0x9f4>  // b.any
   2c504:	mov	x2, x25
   2c508:	bl	2bfc0 <__gmpn_sqrtrem@@Base+0x4a4>
   2c50c:	b	2c520 <__gmpn_sqrtrem@@Base+0xa04>
   2c510:	mov	x2, x22
   2c514:	mov	x3, xzr
   2c518:	mov	x4, x27
   2c51c:	bl	2c4a4 <__gmpn_sqrtrem@@Base+0x988>
   2c520:	mov	x26, x0
   2c524:	cbz	x0, 2c53c <__gmpn_sqrtrem@@Base+0xa20>
   2c528:	mov	x0, x25
   2c52c:	mov	x1, x25
   2c530:	mov	x2, x23
   2c534:	mov	x3, x22
   2c538:	bl	c2e0 <__gmpn_sub_n@plt>
   2c53c:	add	x28, x21, x24, lsl #3
   2c540:	mov	x0, x27
   2c544:	mov	x1, x28
   2c548:	mov	x2, xzr
   2c54c:	mov	x3, x28
   2c550:	mov	x4, x19
   2c554:	mov	x5, x23
   2c558:	mov	x6, x22
   2c55c:	str	x25, [sp]
   2c560:	str	x19, [sp, #16]
   2c564:	bl	bf10 <__gmpn_tdiv_qr@plt>
   2c568:	ldr	x8, [x27, x24, lsl #3]
   2c56c:	ldr	x25, [x27]
   2c570:	mov	w3, #0x1                   	// #1
   2c574:	mov	x0, x20
   2c578:	mov	x1, x27
   2c57c:	mov	x2, x24
   2c580:	add	x19, x8, x26
   2c584:	mov	w26, #0x1                   	// #1
   2c588:	bl	c1b0 <__gmpn_rshift@plt>
   2c58c:	add	x8, x20, x24, lsl #3
   2c590:	ldur	x9, [x8, #-8]
   2c594:	orr	x9, x9, x19, lsl #63
   2c598:	stur	x9, [x8, #-8]
   2c59c:	ldr	x8, [x20]
   2c5a0:	ldur	x9, [x29, #-8]
   2c5a4:	tst	x8, x9
   2c5a8:	b.ne	2c704 <__gmpn_sqrtrem@@Base+0xbe8>  // b.any
   2c5ac:	ldr	x8, [sp, #8]
   2c5b0:	and	x26, x8, #0xfffffffffffffffe
   2c5b4:	lsr	x8, x19, #1
   2c5b8:	stur	x8, [x29, #-8]
   2c5bc:	tbnz	w25, #0, 2c5c8 <__gmpn_sqrtrem@@Base+0xaac>
   2c5c0:	mov	x28, xzr
   2c5c4:	b	2c5e0 <__gmpn_sqrtrem@@Base+0xac4>
   2c5c8:	mov	x0, x28
   2c5cc:	mov	x1, x28
   2c5d0:	mov	x2, x23
   2c5d4:	mov	x3, x22
   2c5d8:	bl	ca90 <__gmpn_add_n@plt>
   2c5dc:	sxtw	x28, w0
   2c5e0:	ldr	x19, [sp, #16]
   2c5e4:	mov	x1, x20
   2c5e8:	mov	x2, x24
   2c5ec:	add	x27, x21, x19, lsl #3
   2c5f0:	mov	x0, x27
   2c5f4:	bl	c900 <__gmpn_sqr@plt>
   2c5f8:	mov	x0, x21
   2c5fc:	mov	x1, x21
   2c600:	mov	x2, x27
   2c604:	mov	x3, x26
   2c608:	bl	c2e0 <__gmpn_sub_n@plt>
   2c60c:	ldur	x11, [x29, #-8]
   2c610:	cmp	x24, x22
   2c614:	add	w8, w0, w11
   2c618:	sxtw	x8, w8
   2c61c:	b.eq	2c634 <__gmpn_sqrtrem@@Base+0xb18>  // b.none
   2c620:	ldr	x10, [sp]
   2c624:	ldr	x9, [x10]
   2c628:	subs	x8, x9, x8
   2c62c:	str	x8, [x10]
   2c630:	cset	w8, cc  // cc = lo, ul, last
   2c634:	sub	x24, x28, x8
   2c638:	tbz	w24, #31, 2c700 <__gmpn_sqrtrem@@Base+0xbe4>
   2c63c:	ldr	x8, [x23]
   2c640:	adds	x8, x8, x11
   2c644:	str	x8, [x23]
   2c648:	b.cc	2c670 <__gmpn_sqrtrem@@Base+0xb54>  // b.lo, b.ul, b.last
   2c64c:	mov	w8, #0x1                   	// #1
   2c650:	mov	w25, #0x2                   	// #2
   2c654:	cmp	x8, x22
   2c658:	b.ge	2c674 <__gmpn_sqrtrem@@Base+0xb58>  // b.tcont
   2c65c:	ldr	x9, [x23, x8, lsl #3]
   2c660:	adds	x9, x9, #0x1
   2c664:	str	x9, [x23, x8, lsl #3]
   2c668:	add	x8, x8, #0x1
   2c66c:	b.cs	2c654 <__gmpn_sqrtrem@@Base+0xb38>  // b.hs, b.nlast
   2c670:	mov	x25, xzr
   2c674:	mov	x0, x21
   2c678:	mov	x1, x21
   2c67c:	mov	x2, x20
   2c680:	mov	x3, x19
   2c684:	bl	cc60 <__gmpn_addlsh1_n@plt>
   2c688:	ldr	x9, [x21]
   2c68c:	add	x8, x25, x24
   2c690:	add	x8, x8, x0
   2c694:	sub	x10, x9, #0x1
   2c698:	str	x10, [x21]
   2c69c:	cbnz	x9, 2c6c4 <__gmpn_sqrtrem@@Base+0xba8>
   2c6a0:	mov	w9, #0x1                   	// #1
   2c6a4:	mov	w10, #0x1                   	// #1
   2c6a8:	cmp	x10, x19
   2c6ac:	b.ge	2c6c8 <__gmpn_sqrtrem@@Base+0xbac>  // b.tcont
   2c6b0:	ldr	x11, [x21, x10, lsl #3]
   2c6b4:	sub	x12, x11, #0x1
   2c6b8:	str	x12, [x21, x10, lsl #3]
   2c6bc:	add	x10, x10, #0x1
   2c6c0:	cbz	x11, 2c6a8 <__gmpn_sqrtrem@@Base+0xb8c>
   2c6c4:	mov	x9, xzr
   2c6c8:	ldr	x10, [x20]
   2c6cc:	sxtw	x8, w8
   2c6d0:	sub	x24, x8, x9
   2c6d4:	sub	x8, x10, #0x1
   2c6d8:	str	x8, [x20]
   2c6dc:	cbnz	x10, 2c700 <__gmpn_sqrtrem@@Base+0xbe4>
   2c6e0:	mov	w8, #0x1                   	// #1
   2c6e4:	cmp	x8, x19
   2c6e8:	b.ge	2c700 <__gmpn_sqrtrem@@Base+0xbe4>  // b.tcont
   2c6ec:	ldr	x9, [x20, x8, lsl #3]
   2c6f0:	sub	x10, x9, #0x1
   2c6f4:	str	x10, [x20, x8, lsl #3]
   2c6f8:	add	x8, x8, #0x1
   2c6fc:	cbz	x9, 2c6e4 <__gmpn_sqrtrem@@Base+0xbc8>
   2c700:	sxtw	x26, w24
   2c704:	mov	x0, x26
   2c708:	ldp	x20, x19, [sp, #112]
   2c70c:	ldp	x22, x21, [sp, #96]
   2c710:	ldp	x24, x23, [sp, #80]
   2c714:	ldp	x26, x25, [sp, #64]
   2c718:	ldp	x28, x27, [sp, #48]
   2c71c:	ldp	x29, x30, [sp, #32]
   2c720:	add	sp, sp, #0x80
   2c724:	ret
   2c728:	stp	x29, x30, [sp, #-80]!
   2c72c:	stp	x26, x25, [sp, #16]
   2c730:	stp	x24, x23, [sp, #32]
   2c734:	stp	x22, x21, [sp, #48]
   2c738:	stp	x20, x19, [sp, #64]
   2c73c:	mov	x29, sp
   2c740:	sub	sp, sp, #0x10
   2c744:	mov	x21, x0
   2c748:	mov	x0, x5
   2c74c:	mov	x24, x5
   2c750:	mov	x19, x4
   2c754:	mov	x22, x3
   2c758:	mov	x20, x2
   2c75c:	mov	x23, x1
   2c760:	bl	ca70 <__gmpn_copyi@plt>
   2c764:	add	x26, x22, x19, lsl #3
   2c768:	ldur	x25, [x26, #-8]
   2c76c:	mov	x0, x25
   2c770:	bl	d410 <__gmpn_invert_limb@plt>
   2c774:	ldur	x8, [x26, #-16]
   2c778:	mul	x9, x0, x25
   2c77c:	adds	x9, x9, x8
   2c780:	b.cc	2c79c <__gmpn_sqrtrem@@Base+0xc80>  // b.lo, b.ul, b.last
   2c784:	subs	x9, x9, x25
   2c788:	cset	w10, cs  // cs = hs, nlast
   2c78c:	csel	x11, x25, xzr, cs  // cs = hs, nlast
   2c790:	mvn	x10, x10
   2c794:	add	x0, x10, x0
   2c798:	sub	x9, x9, x11
   2c79c:	umulh	x10, x8, x0
   2c7a0:	adds	x9, x10, x9
   2c7a4:	b.cc	2c7cc <__gmpn_sqrtrem@@Base+0xcb0>  // b.lo, b.ul, b.last
   2c7a8:	cmp	x9, x25
   2c7ac:	sub	x5, x0, #0x1
   2c7b0:	b.cc	2c7d0 <__gmpn_sqrtrem@@Base+0xcb4>  // b.lo, b.ul, b.last
   2c7b4:	mul	x10, x0, x8
   2c7b8:	cmp	x9, x25
   2c7bc:	sub	x11, x0, #0x2
   2c7c0:	ccmp	x10, x8, #0x2, ls  // ls = plast
   2c7c4:	csel	x5, x5, x11, cc  // cc = lo, ul, last
   2c7c8:	b	2c7d0 <__gmpn_sqrtrem@@Base+0xcb4>
   2c7cc:	mov	x5, x0
   2c7d0:	cmp	x19, #0x97
   2c7d4:	stur	x5, [x29, #-8]
   2c7d8:	b.le	2c84c <__gmpn_sqrtrem@@Base+0xd30>
   2c7dc:	cmp	x19, #0x3e5
   2c7e0:	b.le	2c868 <__gmpn_sqrtrem@@Base+0xd4c>
   2c7e4:	mov	x0, x20
   2c7e8:	mov	x1, x19
   2c7ec:	mov	w2, wzr
   2c7f0:	bl	c0f0 <__gmpn_mu_divappr_q_itch@plt>
   2c7f4:	lsl	x1, x0, #3
   2c7f8:	mov	w8, #0x7f00                	// #32512
   2c7fc:	cmp	x1, x8
   2c800:	stur	xzr, [x29, #-16]
   2c804:	b.hi	2c8ac <__gmpn_sqrtrem@@Base+0xd90>  // b.pmore
   2c808:	add	x9, x1, #0xf
   2c80c:	mov	x8, sp
   2c810:	and	x9, x9, #0xfffffffffffffff0
   2c814:	sub	x5, x8, x9
   2c818:	mov	sp, x5
   2c81c:	mov	x0, x21
   2c820:	mov	x1, x23
   2c824:	mov	x2, x20
   2c828:	mov	x3, x22
   2c82c:	mov	x4, x19
   2c830:	bl	c730 <__gmpn_mu_divappr_q@plt>
   2c834:	ldur	x8, [x29, #-16]
   2c838:	mov	x22, x0
   2c83c:	cbz	x8, 2c888 <__gmpn_sqrtrem@@Base+0xd6c>
   2c840:	mov	x0, x8
   2c844:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2c848:	b	2c888 <__gmpn_sqrtrem@@Base+0xd6c>
   2c84c:	mov	x0, x21
   2c850:	mov	x1, x24
   2c854:	mov	x2, x20
   2c858:	mov	x3, x22
   2c85c:	mov	x4, x19
   2c860:	bl	c710 <__gmpn_sbpi1_divappr_q@plt>
   2c864:	b	2c884 <__gmpn_sqrtrem@@Base+0xd68>
   2c868:	sub	x5, x29, #0x8
   2c86c:	mov	x0, x21
   2c870:	mov	x1, x24
   2c874:	mov	x2, x20
   2c878:	mov	x3, x22
   2c87c:	mov	x4, x19
   2c880:	bl	c4f0 <__gmpn_dcpi1_divappr_q@plt>
   2c884:	mov	x22, x0
   2c888:	sub	x8, x20, x19
   2c88c:	str	x22, [x21, x8, lsl #3]
   2c890:	mov	sp, x29
   2c894:	ldp	x20, x19, [sp, #64]
   2c898:	ldp	x22, x21, [sp, #48]
   2c89c:	ldp	x24, x23, [sp, #32]
   2c8a0:	ldp	x26, x25, [sp, #16]
   2c8a4:	ldp	x29, x30, [sp], #80
   2c8a8:	ret
   2c8ac:	sub	x0, x29, #0x10
   2c8b0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2c8b4:	mov	x5, x0
   2c8b8:	b	2c81c <__gmpn_sqrtrem@@Base+0xd00>

000000000002c8bc <__gmpn_sizeinbase@@Base>:
   2c8bc:	cbz	x1, 2c908 <__gmpn_sizeinbase@@Base+0x4c>
   2c8c0:	add	x8, x0, x1, lsl #3
   2c8c4:	ldur	x8, [x8, #-8]
   2c8c8:	adrp	x11, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2c8cc:	ldr	x11, [x11, #3936]
   2c8d0:	lsl	x9, x1, #6
   2c8d4:	sub	w10, w2, #0x1
   2c8d8:	clz	x8, x8
   2c8dc:	tst	w2, w10
   2c8e0:	sub	x8, x9, x8
   2c8e4:	sxtw	x9, w2
   2c8e8:	mov	w10, #0x28                  	// #40
   2c8ec:	madd	x9, x9, x10, x11
   2c8f0:	b.ne	2c910 <__gmpn_sizeinbase@@Base+0x54>  // b.any
   2c8f4:	ldrsw	x9, [x9, #24]
   2c8f8:	add	x8, x8, x9
   2c8fc:	sub	x8, x8, #0x1
   2c900:	udiv	x0, x8, x9
   2c904:	ret
   2c908:	mov	w0, #0x1                   	// #1
   2c90c:	ret
   2c910:	ldr	x9, [x9, #8]
   2c914:	add	x9, x9, #0x1
   2c918:	umulh	x8, x9, x8
   2c91c:	add	x0, x8, #0x1
   2c920:	ret

000000000002c924 <__gmpn_get_str@@Base>:
   2c924:	stp	x29, x30, [sp, #-80]!
   2c928:	stp	x28, x25, [sp, #16]
   2c92c:	stp	x24, x23, [sp, #32]
   2c930:	stp	x22, x21, [sp, #48]
   2c934:	stp	x20, x19, [sp, #64]
   2c938:	mov	x29, sp
   2c93c:	sub	sp, sp, #0xa10
   2c940:	mov	x19, x0
   2c944:	cbz	x3, 2ca00 <__gmpn_get_str@@Base+0xdc>
   2c948:	sub	w8, w1, #0x1
   2c94c:	mov	x21, x3
   2c950:	mov	x20, x2
   2c954:	mov	w22, w1
   2c958:	tst	w1, w8
   2c95c:	b.ne	2ca0c <__gmpn_get_str@@Base+0xe8>  // b.any
   2c960:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2c964:	ldr	x9, [x9, #3936]
   2c968:	mov	w11, #0x28                  	// #40
   2c96c:	sub	x8, x21, #0x1
   2c970:	ldr	x10, [x20, x8, lsl #3]
   2c974:	smaddl	x9, w22, w11, x9
   2c978:	ldr	x9, [x9, #24]
   2c97c:	lsl	x12, x21, #6
   2c980:	clz	x13, x10
   2c984:	sub	x12, x12, x13
   2c988:	sxtw	x13, w9
   2c98c:	udiv	x13, x12, x13
   2c990:	msub	w13, w13, w9, w12
   2c994:	mov	w11, #0xffffffff            	// #-1
   2c998:	cmp	w13, #0x0
   2c99c:	sub	w13, w9, w13
   2c9a0:	lsl	w11, w11, w9
   2c9a4:	sub	w12, w12, w8, lsl #6
   2c9a8:	csel	w13, wzr, w13, eq  // eq = none
   2c9ac:	add	w14, w12, w13
   2c9b0:	eor	w12, w11, #0xff
   2c9b4:	mov	x11, x19
   2c9b8:	subs	w13, w14, w9
   2c9bc:	b.mi	2c9d4 <__gmpn_get_str@@Base+0xb0>  // b.first
   2c9c0:	lsr	x14, x10, x13
   2c9c4:	and	w14, w14, w12
   2c9c8:	subs	w13, w13, w9
   2c9cc:	strb	w14, [x11], #1
   2c9d0:	b.pl	2c9c0 <__gmpn_get_str@@Base+0x9c>  // b.nfrst
   2c9d4:	subs	x8, x8, #0x1
   2c9d8:	b.lt	2caa8 <__gmpn_get_str@@Base+0x184>  // b.tstop
   2c9dc:	neg	w14, w13
   2c9e0:	lsl	x14, x10, x14
   2c9e4:	ldr	x10, [x20, x8, lsl #3]
   2c9e8:	and	w15, w14, w12
   2c9ec:	add	w14, w13, #0x40
   2c9f0:	lsr	x13, x10, x13
   2c9f4:	orr	w13, w13, w15
   2c9f8:	strb	w13, [x11], #1
   2c9fc:	b	2c9b8 <__gmpn_get_str@@Base+0x94>
   2ca00:	strb	wzr, [x19]
   2ca04:	mov	w19, #0x1                   	// #1
   2ca08:	b	2cacc <__gmpn_get_str@@Base+0x1a8>
   2ca0c:	cmp	x21, #0x1c
   2ca10:	b.le	2cab0 <__gmpn_get_str@@Base+0x18c>
   2ca14:	lsl	x23, x21, #3
   2ca18:	add	x1, x23, #0x400
   2ca1c:	add	x0, sp, #0x8
   2ca20:	str	xzr, [sp, #8]
   2ca24:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2ca28:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2ca2c:	ldr	x8, [x8, #3936]
   2ca30:	mov	w24, #0x28                  	// #40
   2ca34:	lsl	x10, x21, #6
   2ca38:	mov	x1, x0
   2ca3c:	smaddl	x8, w22, w24, x8
   2ca40:	ldr	x9, [x8, #8]
   2ca44:	ldrsw	x8, [x8]
   2ca48:	umulh	x9, x9, x10
   2ca4c:	add	x0, sp, #0x10
   2ca50:	mov	w3, w22
   2ca54:	udiv	x8, x9, x8
   2ca58:	add	x2, x8, #0x1
   2ca5c:	add	x25, sp, #0x10
   2ca60:	bl	cb30 <__gmpn_compute_powtab@plt>
   2ca64:	mov	x22, x0
   2ca68:	add	x1, x23, #0x200
   2ca6c:	add	x0, sp, #0x8
   2ca70:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2ca74:	mov	x5, x0
   2ca78:	smaddl	x4, w22, w24, x25
   2ca7c:	mov	x0, x19
   2ca80:	mov	x1, xzr
   2ca84:	mov	x2, x20
   2ca88:	mov	x3, x21
   2ca8c:	bl	2cd9c <__gmpn_get_str@@Base+0x478>
   2ca90:	ldr	x8, [sp, #8]
   2ca94:	sub	x19, x0, x19
   2ca98:	cbz	x8, 2cacc <__gmpn_get_str@@Base+0x1a8>
   2ca9c:	mov	x0, x8
   2caa0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2caa4:	b	2cacc <__gmpn_get_str@@Base+0x1a8>
   2caa8:	sub	x19, x11, x19
   2caac:	b	2cacc <__gmpn_get_str@@Base+0x1a8>
   2cab0:	mov	x0, x19
   2cab4:	mov	x1, xzr
   2cab8:	mov	x2, x20
   2cabc:	mov	x3, x21
   2cac0:	mov	w4, w22
   2cac4:	bl	2caec <__gmpn_get_str@@Base+0x1c8>
   2cac8:	sub	x19, x0, x19
   2cacc:	mov	x0, x19
   2cad0:	add	sp, sp, #0xa10
   2cad4:	ldp	x20, x19, [sp, #64]
   2cad8:	ldp	x22, x21, [sp, #48]
   2cadc:	ldp	x24, x23, [sp, #32]
   2cae0:	ldp	x28, x25, [sp, #16]
   2cae4:	ldp	x29, x30, [sp], #80
   2cae8:	ret
   2caec:	stp	x29, x30, [sp, #-96]!
   2caf0:	stp	x28, x27, [sp, #16]
   2caf4:	stp	x26, x25, [sp, #32]
   2caf8:	stp	x24, x23, [sp, #48]
   2cafc:	stp	x22, x21, [sp, #64]
   2cb00:	stp	x20, x19, [sp, #80]
   2cb04:	mov	x29, sp
   2cb08:	sub	sp, sp, #0x5a0
   2cb0c:	mov	x21, x3
   2cb10:	mov	x20, x1
   2cb14:	cmp	w4, #0xa
   2cb18:	mov	x19, x0
   2cb1c:	b.ne	2cc48 <__gmpn_get_str@@Base+0x324>  // b.any
   2cb20:	add	x23, sp, #0x10
   2cb24:	add	x22, x23, #0x8
   2cb28:	mov	x0, x22
   2cb2c:	mov	x1, x2
   2cb30:	mov	x2, x21
   2cb34:	bl	ca70 <__gmpn_copyi@plt>
   2cb38:	add	x8, sp, #0xf8
   2cb3c:	cmp	x21, #0x2
   2cb40:	add	x26, x8, #0x49d
   2cb44:	b.lt	2cc14 <__gmpn_get_str@@Base+0x2f0>  // b.tstop
   2cb48:	mov	w24, #0xa                   	// #10
   2cb4c:	mov	w25, #0x64                  	// #100
   2cb50:	mov	w27, #0x3e8                 	// #1000
   2cb54:	mov	w28, #0x2710                	// #10000
   2cb58:	mov	x5, #0xc34a                	// #49994
   2cb5c:	mov	x4, #0x89e80000            	// #2313682944
   2cb60:	movk	x5, #0x6d2a, lsl #16
   2cb64:	movk	x4, #0x2304, lsl #32
   2cb68:	movk	x5, #0x94fb, lsl #32
   2cb6c:	add	x0, sp, #0x10
   2cb70:	mov	w1, #0x1                   	// #1
   2cb74:	movk	x4, #0x8ac7, lsl #48
   2cb78:	movk	x5, #0xd83c, lsl #48
   2cb7c:	mov	x2, x22
   2cb80:	mov	x3, x21
   2cb84:	mov	w6, wzr
   2cb88:	bl	cd00 <__gmpn_preinv_divrem_1@plt>
   2cb8c:	ldr	x10, [sp, #16]
   2cb90:	ldr	x9, [x23, x21, lsl #3]
   2cb94:	mov	x8, xzr
   2cb98:	add	x10, x10, #0x1
   2cb9c:	umulh	x11, x10, x24
   2cba0:	sturb	w11, [x26, #-19]
   2cba4:	mul	x11, x10, x25
   2cba8:	umulh	x11, x11, x24
   2cbac:	sturb	w11, [x26, #-17]
   2cbb0:	mul	x11, x10, x27
   2cbb4:	umulh	x11, x11, x24
   2cbb8:	cmp	x9, #0x0
   2cbbc:	sturb	w11, [x26, #-16]
   2cbc0:	add	x11, x10, x10, lsl #2
   2cbc4:	mul	x10, x10, x28
   2cbc8:	csetm	x9, eq  // eq = none
   2cbcc:	lsl	x11, x11, #1
   2cbd0:	lsr	x10, x10, #4
   2cbd4:	umulh	x11, x11, x24
   2cbd8:	sturb	w11, [x26, #-18]
   2cbdc:	add	x10, x10, x10, lsl #2
   2cbe0:	add	x11, x26, x8
   2cbe4:	add	x8, x8, #0x1
   2cbe8:	lsl	x12, x10, #1
   2cbec:	ubfx	x10, x10, #59, #4
   2cbf0:	cmp	w8, #0xf
   2cbf4:	sturb	w10, [x11, #-15]
   2cbf8:	and	x10, x12, #0xffffffffffffffe
   2cbfc:	b.ne	2cbdc <__gmpn_get_str@@Base+0x2b8>  // b.any
   2cc00:	add	x21, x21, x9
   2cc04:	add	x8, x26, x8
   2cc08:	cmp	x21, #0x1
   2cc0c:	sub	x26, x8, #0x22
   2cc10:	b.gt	2cb58 <__gmpn_get_str@@Base+0x234>
   2cc14:	ldr	x8, [sp, #24]
   2cc18:	cbz	x8, 2cd28 <__gmpn_get_str@@Base+0x404>
   2cc1c:	mov	x9, #0xcccccccccccccccc    	// #-3689348814741910324
   2cc20:	movk	x9, #0xcccd
   2cc24:	mov	w10, #0xfffffff6            	// #-10
   2cc28:	umulh	x11, x8, x9
   2cc2c:	lsr	x11, x11, #3
   2cc30:	madd	w12, w11, w10, w8
   2cc34:	cmp	x8, #0xa
   2cc38:	strb	w12, [x26, #-1]!
   2cc3c:	mov	x8, x11
   2cc40:	b.cs	2cc28 <__gmpn_get_str@@Base+0x304>  // b.hs, b.nlast
   2cc44:	b	2cd28 <__gmpn_get_str@@Base+0x404>
   2cc48:	add	x8, sp, #0x10
   2cc4c:	add	x22, x8, #0x8
   2cc50:	mov	w23, w4
   2cc54:	mov	x0, x22
   2cc58:	mov	x1, x2
   2cc5c:	mov	x2, x21
   2cc60:	sxtw	x27, w23
   2cc64:	bl	ca70 <__gmpn_copyi@plt>
   2cc68:	add	x8, sp, #0xf8
   2cc6c:	cmp	x21, #0x2
   2cc70:	add	x26, x8, #0x49d
   2cc74:	b.lt	2cd08 <__gmpn_get_str@@Base+0x3e4>  // b.tstop
   2cc78:	str	x22, [sp, #8]
   2cc7c:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2cc80:	ldr	x8, [x8, #3936]
   2cc84:	mov	w9, #0x28                  	// #40
   2cc88:	smaddl	x8, w23, w9, x8
   2cc8c:	ldr	w28, [x8]
   2cc90:	ldp	x23, x8, [x8, #24]
   2cc94:	neg	x22, x28
   2cc98:	clz	x25, x23
   2cc9c:	neg	x24, x28, lsl #1
   2cca0:	str	x8, [sp]
   2cca4:	ldp	x5, x2, [sp]
   2cca8:	add	x0, sp, #0x10
   2ccac:	mov	w1, #0x1                   	// #1
   2ccb0:	mov	x3, x21
   2ccb4:	mov	x4, x23
   2ccb8:	mov	w6, w25
   2ccbc:	bl	cd00 <__gmpn_preinv_divrem_1@plt>
   2ccc0:	add	x8, sp, #0x10
   2ccc4:	ldr	x9, [x8, x21, lsl #3]
   2ccc8:	ldr	x10, [sp, #16]
   2cccc:	add	x8, x26, x22
   2ccd0:	add	x26, x26, x24
   2ccd4:	cmp	x9, #0x0
   2ccd8:	add	x10, x10, #0x1
   2ccdc:	csetm	x9, eq  // eq = none
   2cce0:	mov	w11, w28
   2cce4:	umulh	x12, x10, x27
   2cce8:	mul	x10, x10, x27
   2ccec:	subs	w11, w11, #0x1
   2ccf0:	strb	w12, [x8], #1
   2ccf4:	add	x26, x26, #0x1
   2ccf8:	b.ne	2cce4 <__gmpn_get_str@@Base+0x3c0>  // b.any
   2ccfc:	add	x21, x21, x9
   2cd00:	cmp	x21, #0x1
   2cd04:	b.gt	2cca4 <__gmpn_get_str@@Base+0x380>
   2cd08:	ldr	x8, [sp, #24]
   2cd0c:	cbz	x8, 2cd28 <__gmpn_get_str@@Base+0x404>
   2cd10:	udiv	x9, x8, x27
   2cd14:	msub	w10, w9, w27, w8
   2cd18:	cmp	x8, x27
   2cd1c:	strb	w10, [x26, #-1]!
   2cd20:	mov	x8, x9
   2cd24:	b.cs	2cd10 <__gmpn_get_str@@Base+0x3ec>  // b.hs, b.nlast
   2cd28:	add	x8, sp, #0xf8
   2cd2c:	add	x21, x8, #0x49d
   2cd30:	sub	x22, x21, x26
   2cd34:	cmp	x22, x20
   2cd38:	b.cs	2cd60 <__gmpn_get_str@@Base+0x43c>  // b.hs, b.nlast
   2cd3c:	add	x8, x26, x20
   2cd40:	sub	x2, x8, x21
   2cd44:	mov	x0, x19
   2cd48:	mov	w1, wzr
   2cd4c:	bl	c610 <memset@plt>
   2cd50:	sub	x20, x20, #0x1
   2cd54:	cmp	x22, x20
   2cd58:	add	x19, x19, #0x1
   2cd5c:	b.cc	2cd50 <__gmpn_get_str@@Base+0x42c>  // b.lo, b.ul, b.last
   2cd60:	cbz	x22, 2cd78 <__gmpn_get_str@@Base+0x454>
   2cd64:	sub	x8, x26, x21
   2cd68:	ldrb	w9, [x26], #1
   2cd6c:	adds	x8, x8, #0x1
   2cd70:	strb	w9, [x19], #1
   2cd74:	b.cc	2cd68 <__gmpn_get_str@@Base+0x444>  // b.lo, b.ul, b.last
   2cd78:	mov	x0, x19
   2cd7c:	add	sp, sp, #0x5a0
   2cd80:	ldp	x20, x19, [sp, #80]
   2cd84:	ldp	x22, x21, [sp, #64]
   2cd88:	ldp	x24, x23, [sp, #48]
   2cd8c:	ldp	x26, x25, [sp, #32]
   2cd90:	ldp	x28, x27, [sp, #16]
   2cd94:	ldp	x29, x30, [sp], #96
   2cd98:	ret
   2cd9c:	stp	x29, x30, [sp, #-96]!
   2cda0:	stp	x24, x23, [sp, #48]
   2cda4:	stp	x22, x21, [sp, #64]
   2cda8:	stp	x20, x19, [sp, #80]
   2cdac:	mov	x24, x4
   2cdb0:	mov	x22, x3
   2cdb4:	mov	x21, x2
   2cdb8:	mov	x20, x1
   2cdbc:	cmp	x3, #0xf
   2cdc0:	mov	x19, x0
   2cdc4:	str	x27, [sp, #16]
   2cdc8:	stp	x26, x25, [sp, #32]
   2cdcc:	mov	x29, sp
   2cdd0:	b.lt	2cea4 <__gmpn_get_str@@Base+0x580>  // b.tstop
   2cdd4:	mov	x23, x5
   2cdd8:	sub	x26, x21, #0x8
   2cddc:	add	x9, x26, x22, lsl #3
   2cde0:	mov	x27, x24
   2cde4:	ldp	x24, x8, [x27, #8]
   2cde8:	add	x10, x8, x24
   2cdec:	cmp	x10, x22
   2cdf0:	b.gt	2ce2c <__gmpn_get_str@@Base+0x508>
   2cdf4:	ldr	x5, [x27]
   2cdf8:	b.ne	2ce34 <__gmpn_get_str@@Base+0x510>  // b.any
   2cdfc:	sub	x25, x22, x8
   2ce00:	sub	x10, x5, #0x8
   2ce04:	mov	x11, x9
   2ce08:	mov	x12, x25
   2ce0c:	subs	x13, x12, #0x1
   2ce10:	b.lt	2ce3c <__gmpn_get_str@@Base+0x518>  // b.tstop
   2ce14:	ldr	x14, [x11], #-8
   2ce18:	ldr	x12, [x10, x12, lsl #3]
   2ce1c:	cmp	x14, x12
   2ce20:	mov	x12, x13
   2ce24:	b.eq	2ce0c <__gmpn_get_str@@Base+0x4e8>  // b.none
   2ce28:	b.hi	2ce3c <__gmpn_get_str@@Base+0x518>  // b.pmore
   2ce2c:	sub	x27, x27, #0x28
   2ce30:	b	2cde4 <__gmpn_get_str@@Base+0x4c0>
   2ce34:	sub	x25, x22, x8
   2ce38:	mov	x22, x10
   2ce3c:	add	x1, x21, x8, lsl #3
   2ce40:	mov	x0, x23
   2ce44:	mov	x2, xzr
   2ce48:	mov	x3, x1
   2ce4c:	mov	x4, x25
   2ce50:	mov	x6, x24
   2ce54:	bl	bf10 <__gmpn_tdiv_qr@plt>
   2ce58:	sub	x8, x25, x24
   2ce5c:	ldr	x9, [x23, x8, lsl #3]
   2ce60:	cmp	x9, #0x0
   2ce64:	cinc	x3, x8, ne  // ne = any
   2ce68:	cbz	x20, 2ce78 <__gmpn_get_str@@Base+0x554>
   2ce6c:	ldr	x8, [x27, #24]
   2ce70:	sub	x1, x20, x8
   2ce74:	b	2ce7c <__gmpn_get_str@@Base+0x558>
   2ce78:	mov	x1, xzr
   2ce7c:	sub	x24, x27, #0x28
   2ce80:	add	x5, x23, x3, lsl #3
   2ce84:	mov	x0, x19
   2ce88:	mov	x2, x23
   2ce8c:	mov	x4, x24
   2ce90:	bl	2cd9c <__gmpn_get_str@@Base+0x478>
   2ce94:	ldr	x20, [x27, #24]
   2ce98:	cmp	x22, #0xe
   2ce9c:	mov	x19, x0
   2cea0:	b.gt	2cddc <__gmpn_get_str@@Base+0x4b8>
   2cea4:	cbz	x22, 2ced8 <__gmpn_get_str@@Base+0x5b4>
   2cea8:	ldr	w4, [x24, #32]
   2ceac:	mov	x0, x19
   2ceb0:	mov	x1, x20
   2ceb4:	mov	x2, x21
   2ceb8:	mov	x3, x22
   2cebc:	ldp	x20, x19, [sp, #80]
   2cec0:	ldp	x22, x21, [sp, #64]
   2cec4:	ldp	x24, x23, [sp, #48]
   2cec8:	ldp	x26, x25, [sp, #32]
   2cecc:	ldr	x27, [sp, #16]
   2ced0:	ldp	x29, x30, [sp], #96
   2ced4:	b	2caec <__gmpn_get_str@@Base+0x1c8>
   2ced8:	cbz	x20, 2cef8 <__gmpn_get_str@@Base+0x5d4>
   2cedc:	mov	x0, x19
   2cee0:	mov	w1, wzr
   2cee4:	mov	x2, x20
   2cee8:	bl	c610 <memset@plt>
   2ceec:	subs	x20, x20, #0x1
   2cef0:	add	x19, x19, #0x1
   2cef4:	b.ne	2ceec <__gmpn_get_str@@Base+0x5c8>  // b.any
   2cef8:	mov	x0, x19
   2cefc:	ldp	x20, x19, [sp, #80]
   2cf00:	ldp	x22, x21, [sp, #64]
   2cf04:	ldp	x24, x23, [sp, #48]
   2cf08:	ldp	x26, x25, [sp, #32]
   2cf0c:	ldr	x27, [sp, #16]
   2cf10:	ldp	x29, x30, [sp], #96
   2cf14:	ret

000000000002cf18 <__gmpn_set_str@@Base>:
   2cf18:	stp	x29, x30, [sp, #-96]!
   2cf1c:	str	x28, [sp, #16]
   2cf20:	stp	x26, x25, [sp, #32]
   2cf24:	stp	x24, x23, [sp, #48]
   2cf28:	stp	x22, x21, [sp, #64]
   2cf2c:	stp	x20, x19, [sp, #80]
   2cf30:	mov	x29, sp
   2cf34:	sub	sp, sp, #0xa00
   2cf38:	sub	w8, w3, #0x1
   2cf3c:	mov	w22, w3
   2cf40:	mov	x21, x2
   2cf44:	mov	x19, x1
   2cf48:	tst	w3, w8
   2cf4c:	mov	x20, x0
   2cf50:	b.ne	2cf6c <__gmpn_set_str@@Base+0x54>  // b.any
   2cf54:	add	x8, x19, x21
   2cf58:	sub	x8, x8, #0x1
   2cf5c:	cmp	x8, x19
   2cf60:	b.cs	2d000 <__gmpn_set_str@@Base+0xe8>  // b.hs, b.nlast
   2cf64:	mov	x0, xzr
   2cf68:	b	2d068 <__gmpn_set_str@@Base+0x150>
   2cf6c:	cmp	x21, #0x717
   2cf70:	b.ls	2d088 <__gmpn_set_str@@Base+0x170>  // b.plast
   2cf74:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2cf78:	ldr	x8, [x8, #3936]
   2cf7c:	mov	w24, #0x28                  	// #40
   2cf80:	smull	x9, w22, w24
   2cf84:	add	x0, x29, #0x18
   2cf88:	ldrsw	x8, [x8, x9]
   2cf8c:	str	xzr, [x29, #24]
   2cf90:	udiv	x8, x21, x8
   2cf94:	lsl	x25, x8, #3
   2cf98:	add	x1, x25, #0x408
   2cf9c:	add	x23, x8, #0x1
   2cfa0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2cfa4:	mov	x1, x0
   2cfa8:	mov	x0, sp
   2cfac:	mov	x2, x23
   2cfb0:	mov	w3, w22
   2cfb4:	mov	x26, sp
   2cfb8:	bl	cb30 <__gmpn_compute_powtab@plt>
   2cfbc:	madd	x22, x0, x24, x26
   2cfc0:	add	x1, x25, #0x208
   2cfc4:	add	x0, x29, #0x18
   2cfc8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2cfcc:	mov	x4, x0
   2cfd0:	mov	x0, x20
   2cfd4:	mov	x1, x19
   2cfd8:	mov	x2, x21
   2cfdc:	mov	x3, x22
   2cfe0:	bl	c380 <__gmpn_dc_set_str@plt>
   2cfe4:	ldr	x8, [x29, #24]
   2cfe8:	cbz	x8, 2d068 <__gmpn_set_str@@Base+0x150>
   2cfec:	mov	x19, x0
   2cff0:	mov	x0, x8
   2cff4:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2cff8:	mov	x0, x19
   2cffc:	b	2d068 <__gmpn_set_str@@Base+0x150>
   2d000:	adrp	x10, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2d004:	ldr	x10, [x10, #3936]
   2d008:	mov	w12, #0x28                  	// #40
   2d00c:	mov	w11, wzr
   2d010:	mov	x9, xzr
   2d014:	smaddl	x10, w22, w12, x10
   2d018:	ldr	w10, [x10, #24]
   2d01c:	mov	x0, xzr
   2d020:	ldrb	w12, [x8]
   2d024:	lsl	x14, x12, x11
   2d028:	add	w11, w11, w10
   2d02c:	subs	w13, w11, #0x40
   2d030:	orr	x9, x14, x9
   2d034:	b.lt	2d04c <__gmpn_set_str@@Base+0x134>  // b.tstop
   2d038:	str	x9, [x20, x0, lsl #3]
   2d03c:	sub	w9, w10, w13
   2d040:	add	x0, x0, #0x1
   2d044:	lsr	w9, w12, w9
   2d048:	mov	w11, w13
   2d04c:	sub	x8, x8, #0x1
   2d050:	cmp	x8, x19
   2d054:	b.cs	2d020 <__gmpn_set_str@@Base+0x108>  // b.hs, b.nlast
   2d058:	cbz	x9, 2d068 <__gmpn_set_str@@Base+0x150>
   2d05c:	add	x8, x0, #0x1
   2d060:	str	x9, [x20, x0, lsl #3]
   2d064:	mov	x0, x8
   2d068:	add	sp, sp, #0xa00
   2d06c:	ldp	x20, x19, [sp, #80]
   2d070:	ldp	x22, x21, [sp, #64]
   2d074:	ldp	x24, x23, [sp, #48]
   2d078:	ldp	x26, x25, [sp, #32]
   2d07c:	ldr	x28, [sp, #16]
   2d080:	ldp	x29, x30, [sp], #96
   2d084:	ret
   2d088:	mov	x0, x20
   2d08c:	mov	x1, x19
   2d090:	mov	x2, x21
   2d094:	mov	w3, w22
   2d098:	add	sp, sp, #0xa00
   2d09c:	ldp	x20, x19, [sp, #80]
   2d0a0:	ldp	x22, x21, [sp, #64]
   2d0a4:	ldp	x24, x23, [sp, #48]
   2d0a8:	ldp	x26, x25, [sp, #32]
   2d0ac:	ldr	x28, [sp, #16]
   2d0b0:	ldp	x29, x30, [sp], #96
   2d0b4:	b	c120 <__gmpn_bc_set_str@plt>

000000000002d0b8 <__gmpn_bc_set_str@@Base>:
   2d0b8:	sub	sp, sp, #0x70
   2d0bc:	stp	x29, x30, [sp, #16]
   2d0c0:	stp	x28, x27, [sp, #32]
   2d0c4:	stp	x26, x25, [sp, #48]
   2d0c8:	stp	x24, x23, [sp, #64]
   2d0cc:	stp	x22, x21, [sp, #80]
   2d0d0:	stp	x20, x19, [sp, #96]
   2d0d4:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2d0d8:	ldr	x8, [x8, #3936]
   2d0dc:	mov	w9, #0x28                  	// #40
   2d0e0:	mov	x21, x1
   2d0e4:	ldrb	w4, [x21], #1
   2d0e8:	smaddl	x8, w3, w9, x8
   2d0ec:	ldrsw	x26, [x8]
   2d0f0:	mov	w23, w3
   2d0f4:	mov	x22, x2
   2d0f8:	mov	x19, x0
   2d0fc:	cmp	x26, x2
   2d100:	sxtw	x25, w23
   2d104:	mov	x20, xzr
   2d108:	add	x29, sp, #0x10
   2d10c:	b.cs	2d1c4 <__gmpn_bc_set_str@@Base+0x10c>  // b.hs, b.nlast
   2d110:	ldr	x8, [x8, #24]
   2d114:	mov	w24, #0xa                   	// #10
   2d118:	mov	x27, x26
   2d11c:	str	x8, [sp, #8]
   2d120:	sub	w8, w26, #0x1
   2d124:	sxtw	x28, w8
   2d128:	cmp	w23, #0xa
   2d12c:	b.ne	2d150 <__gmpn_bc_set_str@@Base+0x98>  // b.any
   2d130:	mov	x8, xzr
   2d134:	ldrb	w9, [x21, x8]
   2d138:	add	x8, x8, #0x1
   2d13c:	cmp	x8, #0x12
   2d140:	madd	x4, x4, x24, x9
   2d144:	b.ne	2d134 <__gmpn_bc_set_str@@Base+0x7c>  // b.any
   2d148:	add	x21, x21, #0x12
   2d14c:	b	2d170 <__gmpn_bc_set_str@@Base+0xb8>
   2d150:	cbz	w28, 2d170 <__gmpn_bc_set_str@@Base+0xb8>
   2d154:	mov	x8, x21
   2d158:	mov	x9, x28
   2d15c:	ldrb	w10, [x8], #1
   2d160:	subs	x9, x9, #0x1
   2d164:	madd	x4, x4, x25, x10
   2d168:	b.ne	2d15c <__gmpn_bc_set_str@@Base+0xa4>  // b.any
   2d16c:	add	x21, x21, x28
   2d170:	cbz	x20, 2d19c <__gmpn_bc_set_str@@Base+0xe4>
   2d174:	ldr	x3, [sp, #8]
   2d178:	mov	x0, x19
   2d17c:	mov	x1, x19
   2d180:	mov	x2, x20
   2d184:	bl	d260 <__gmpn_mul_1c@plt>
   2d188:	cbz	x0, 2d1b0 <__gmpn_bc_set_str@@Base+0xf8>
   2d18c:	add	x8, x20, #0x1
   2d190:	str	x0, [x19, x20, lsl #3]
   2d194:	mov	x20, x8
   2d198:	b	2d1b0 <__gmpn_bc_set_str@@Base+0xf8>
   2d19c:	cbz	x4, 2d1ac <__gmpn_bc_set_str@@Base+0xf4>
   2d1a0:	str	x4, [x19]
   2d1a4:	mov	w20, #0x1                   	// #1
   2d1a8:	b	2d1b0 <__gmpn_bc_set_str@@Base+0xf8>
   2d1ac:	mov	x20, xzr
   2d1b0:	ldrb	w4, [x21], #1
   2d1b4:	add	x27, x27, x26
   2d1b8:	cmp	x27, x22
   2d1bc:	b.cc	2d128 <__gmpn_bc_set_str@@Base+0x70>  // b.lo, b.ul, b.last
   2d1c0:	b	2d1c8 <__gmpn_bc_set_str@@Base+0x110>
   2d1c4:	mov	x27, x26
   2d1c8:	cmp	w23, #0xa
   2d1cc:	b.ne	2d20c <__gmpn_bc_set_str@@Base+0x154>  // b.any
   2d1d0:	sub	x8, x22, x27
   2d1d4:	add	x9, x8, #0x12
   2d1d8:	cmp	x9, #0x1
   2d1dc:	b.lt	2d248 <__gmpn_bc_set_str@@Base+0x190>  // b.tstop
   2d1e0:	add	x8, x8, #0x13
   2d1e4:	mov	w9, #0xa                   	// #10
   2d1e8:	mov	w3, #0xa                   	// #10
   2d1ec:	ldrb	w10, [x21], #1
   2d1f0:	add	x11, x3, x3, lsl #2
   2d1f4:	sub	x8, x8, #0x1
   2d1f8:	cmp	x8, #0x1
   2d1fc:	madd	x4, x4, x9, x10
   2d200:	lsl	x3, x11, #1
   2d204:	b.gt	2d1ec <__gmpn_bc_set_str@@Base+0x134>
   2d208:	b	2d24c <__gmpn_bc_set_str@@Base+0x194>
   2d20c:	add	x8, x26, x22
   2d210:	mvn	x9, x27
   2d214:	add	x8, x8, x9
   2d218:	cmp	x8, #0x1
   2d21c:	b.lt	2d274 <__gmpn_bc_set_str@@Base+0x1bc>  // b.tstop
   2d220:	add	x8, x22, x26
   2d224:	sub	x8, x8, x27
   2d228:	mov	x3, x25
   2d22c:	ldrb	w9, [x21], #1
   2d230:	sub	x8, x8, #0x1
   2d234:	cmp	x8, #0x1
   2d238:	mul	x3, x3, x25
   2d23c:	madd	x4, x4, x25, x9
   2d240:	b.gt	2d22c <__gmpn_bc_set_str@@Base+0x174>
   2d244:	b	2d24c <__gmpn_bc_set_str@@Base+0x194>
   2d248:	mov	w3, #0xa                   	// #10
   2d24c:	cbz	x20, 2d27c <__gmpn_bc_set_str@@Base+0x1c4>
   2d250:	mov	x0, x19
   2d254:	mov	x1, x19
   2d258:	mov	x2, x20
   2d25c:	bl	d260 <__gmpn_mul_1c@plt>
   2d260:	cbz	x0, 2d290 <__gmpn_bc_set_str@@Base+0x1d8>
   2d264:	add	x8, x20, #0x1
   2d268:	str	x0, [x19, x20, lsl #3]
   2d26c:	mov	x20, x8
   2d270:	b	2d290 <__gmpn_bc_set_str@@Base+0x1d8>
   2d274:	mov	x3, x25
   2d278:	cbnz	x20, 2d250 <__gmpn_bc_set_str@@Base+0x198>
   2d27c:	cbz	x4, 2d28c <__gmpn_bc_set_str@@Base+0x1d4>
   2d280:	str	x4, [x19]
   2d284:	mov	w20, #0x1                   	// #1
   2d288:	b	2d290 <__gmpn_bc_set_str@@Base+0x1d8>
   2d28c:	mov	x20, xzr
   2d290:	mov	x0, x20
   2d294:	ldp	x20, x19, [sp, #96]
   2d298:	ldp	x22, x21, [sp, #80]
   2d29c:	ldp	x24, x23, [sp, #64]
   2d2a0:	ldp	x26, x25, [sp, #48]
   2d2a4:	ldp	x28, x27, [sp, #32]
   2d2a8:	ldp	x29, x30, [sp, #16]
   2d2ac:	add	sp, sp, #0x70
   2d2b0:	ret

000000000002d2b4 <__gmpn_dc_set_str@@Base>:
   2d2b4:	stp	x29, x30, [sp, #-80]!
   2d2b8:	stp	x26, x25, [sp, #16]
   2d2bc:	stp	x24, x23, [sp, #32]
   2d2c0:	stp	x22, x21, [sp, #48]
   2d2c4:	stp	x20, x19, [sp, #64]
   2d2c8:	ldr	x22, [x3, #24]
   2d2cc:	mov	x20, x4
   2d2d0:	mov	x23, x2
   2d2d4:	mov	x24, x1
   2d2d8:	cmp	x22, x2
   2d2dc:	mov	x19, x0
   2d2e0:	mov	x29, sp
   2d2e4:	b.cs	2d2f0 <__gmpn_dc_set_str@@Base+0x3c>  // b.hs, b.nlast
   2d2e8:	mov	x25, x3
   2d2ec:	b	2d310 <__gmpn_dc_set_str@@Base+0x5c>
   2d2f0:	mov	x8, x3
   2d2f4:	cmp	x23, #0x313
   2d2f8:	b.ls	2d388 <__gmpn_dc_set_str@@Base+0xd4>  // b.plast
   2d2fc:	ldur	x22, [x8, #-16]
   2d300:	sub	x25, x8, #0x28
   2d304:	mov	x8, x25
   2d308:	cmp	x22, x23
   2d30c:	b.cs	2d2f4 <__gmpn_dc_set_str@@Base+0x40>  // b.hs, b.nlast
   2d310:	sub	x2, x23, x22
   2d314:	cmp	x2, #0x313
   2d318:	b.ls	2d334 <__gmpn_dc_set_str@@Base+0x80>  // b.plast
   2d31c:	sub	x3, x25, #0x28
   2d320:	mov	x0, x20
   2d324:	mov	x1, x24
   2d328:	mov	x4, x19
   2d32c:	bl	c380 <__gmpn_dc_set_str@plt>
   2d330:	b	2d344 <__gmpn_dc_set_str@@Base+0x90>
   2d334:	ldr	w3, [x25, #32]
   2d338:	mov	x0, x20
   2d33c:	mov	x1, x24
   2d340:	bl	c120 <__gmpn_bc_set_str@plt>
   2d344:	ldp	x4, x26, [x25, #8]
   2d348:	mov	x21, x0
   2d34c:	cbz	x0, 2d374 <__gmpn_dc_set_str@@Base+0xc0>
   2d350:	ldr	x3, [x25]
   2d354:	cmp	x4, x21
   2d358:	add	x0, x19, x26, lsl #3
   2d35c:	b.le	2d3b0 <__gmpn_dc_set_str@@Base+0xfc>
   2d360:	mov	x1, x3
   2d364:	mov	x2, x4
   2d368:	mov	x3, x20
   2d36c:	mov	x4, x21
   2d370:	b	2d3b8 <__gmpn_dc_set_str@@Base+0x104>
   2d374:	add	x8, x26, x4
   2d378:	adds	x8, x8, #0x1
   2d37c:	b.eq	2d3d0 <__gmpn_dc_set_str@@Base+0x11c>  // b.none
   2d380:	lsl	x2, x8, #3
   2d384:	b	2d3c4 <__gmpn_dc_set_str@@Base+0x110>
   2d388:	ldr	w3, [x3, #32]
   2d38c:	mov	x0, x19
   2d390:	mov	x1, x24
   2d394:	mov	x2, x23
   2d398:	ldp	x20, x19, [sp, #64]
   2d39c:	ldp	x22, x21, [sp, #48]
   2d3a0:	ldp	x24, x23, [sp, #32]
   2d3a4:	ldp	x26, x25, [sp, #16]
   2d3a8:	ldp	x29, x30, [sp], #80
   2d3ac:	b	c120 <__gmpn_bc_set_str@plt>
   2d3b0:	mov	x1, x20
   2d3b4:	mov	x2, x21
   2d3b8:	bl	ccf0 <__gmpn_mul@plt>
   2d3bc:	cbz	x26, 2d3d0 <__gmpn_dc_set_str@@Base+0x11c>
   2d3c0:	lsl	x2, x26, #3
   2d3c4:	mov	x0, x19
   2d3c8:	mov	w1, wzr
   2d3cc:	bl	c610 <memset@plt>
   2d3d0:	add	x8, x24, x23
   2d3d4:	cmp	x22, #0x313
   2d3d8:	sub	x1, x8, x22
   2d3dc:	b.ls	2d404 <__gmpn_dc_set_str@@Base+0x150>  // b.plast
   2d3e0:	ldr	x8, [x25, #8]
   2d3e4:	sub	x3, x25, #0x28
   2d3e8:	mov	x0, x20
   2d3ec:	mov	x2, x22
   2d3f0:	add	x8, x20, x8, lsl #3
   2d3f4:	add	x8, x8, x26, lsl #3
   2d3f8:	add	x4, x8, #0x8
   2d3fc:	bl	c380 <__gmpn_dc_set_str@plt>
   2d400:	b	2d414 <__gmpn_dc_set_str@@Base+0x160>
   2d404:	ldr	w3, [x25, #32]
   2d408:	mov	x0, x20
   2d40c:	mov	x2, x22
   2d410:	bl	c120 <__gmpn_bc_set_str@plt>
   2d414:	mov	x22, x0
   2d418:	cbz	x0, 2d458 <__gmpn_dc_set_str@@Base+0x1a4>
   2d41c:	mov	x0, x19
   2d420:	mov	x1, x19
   2d424:	mov	x2, x20
   2d428:	mov	x3, x22
   2d42c:	bl	ca90 <__gmpn_add_n@plt>
   2d430:	ldr	x8, [x19, x22, lsl #3]
   2d434:	adds	x8, x8, x0
   2d438:	str	x8, [x19, x22, lsl #3]
   2d43c:	b.cc	2d458 <__gmpn_dc_set_str@@Base+0x1a4>  // b.lo, b.ul, b.last
   2d440:	add	x8, x19, x22, lsl #3
   2d444:	add	x8, x8, #0x8
   2d448:	ldr	x9, [x8]
   2d44c:	adds	x9, x9, #0x1
   2d450:	str	x9, [x8], #8
   2d454:	b.cs	2d448 <__gmpn_dc_set_str@@Base+0x194>  // b.hs, b.nlast
   2d458:	ldr	x8, [x25, #8]
   2d45c:	add	x9, x26, x21
   2d460:	ldp	x22, x21, [sp, #48]
   2d464:	ldp	x24, x23, [sp, #32]
   2d468:	add	x8, x9, x8
   2d46c:	add	x9, x19, x8, lsl #3
   2d470:	ldur	x9, [x9, #-8]
   2d474:	ldp	x20, x19, [sp, #64]
   2d478:	ldp	x26, x25, [sp, #16]
   2d47c:	cmp	x9, #0x0
   2d480:	cset	w9, eq  // eq = none
   2d484:	sub	x0, x8, x9
   2d488:	ldp	x29, x30, [sp], #80
   2d48c:	ret

000000000002d490 <__gmpn_compute_powtab@@Base>:
   2d490:	stp	x29, x30, [sp, #-96]!
   2d494:	stp	x28, x27, [sp, #16]
   2d498:	stp	x26, x25, [sp, #32]
   2d49c:	stp	x24, x23, [sp, #48]
   2d4a0:	stp	x22, x21, [sp, #64]
   2d4a4:	stp	x20, x19, [sp, #80]
   2d4a8:	mov	x29, sp
   2d4ac:	sub	sp, sp, #0x240
   2d4b0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2d4b4:	ldr	x8, [x8, #3936]
   2d4b8:	mov	w9, #0x28                  	// #40
   2d4bc:	smull	x9, w3, w9
   2d4c0:	mov	x22, x1
   2d4c4:	ldrsw	x27, [x8, x9]
   2d4c8:	add	x9, x2, #0x1
   2d4cc:	lsr	x11, x9, #1
   2d4d0:	mov	x21, x0
   2d4d4:	cmp	x11, #0x1
   2d4d8:	sxtw	x9, w3
   2d4dc:	mov	x10, xzr
   2d4e0:	str	x3, [sp, #48]
   2d4e4:	b.ne	2d4f4 <__gmpn_compute_powtab@@Base+0x64>  // b.any
   2d4e8:	mov	w12, #0x1                   	// #1
   2d4ec:	str	x27, [sp, #56]
   2d4f0:	b	2d59c <__gmpn_compute_powtab@@Base+0x10c>
   2d4f4:	add	x12, sp, #0x38
   2d4f8:	mov	x13, x11
   2d4fc:	mul	x14, x13, x27
   2d500:	add	x13, x13, #0x1
   2d504:	lsr	x13, x13, #1
   2d508:	str	x14, [x12, x10, lsl #3]
   2d50c:	cmp	x13, #0x1
   2d510:	add	x10, x10, #0x1
   2d514:	b.ne	2d4fc <__gmpn_compute_powtab@@Base+0x6c>  // b.any
   2d518:	add	x12, sp, #0x38
   2d51c:	subs	x13, x10, #0x1
   2d520:	str	x27, [x12, x10, lsl #3]
   2d524:	b.ne	2d534 <__gmpn_compute_powtab@@Base+0xa4>  // b.any
   2d528:	mov	w12, #0x1                   	// #1
   2d52c:	mov	w11, #0x1                   	// #1
   2d530:	b	2d59c <__gmpn_compute_powtab@@Base+0x10c>
   2d534:	sub	x15, x2, #0x1
   2d538:	mov	w14, #0x1                   	// #1
   2d53c:	mov	w12, #0x1                   	// #1
   2d540:	lsr	x16, x15, x13
   2d544:	add	x17, x16, #0x1
   2d548:	tst	x17, #0x1
   2d54c:	cset	w18, eq  // eq = none
   2d550:	csel	w0, wzr, w17, eq  // eq = none
   2d554:	subs	x1, x13, #0x1
   2d558:	cmp	x16, #0x1
   2d55c:	cset	w16, hi  // hi = pmore
   2d560:	lsl	x1, x17, x1
   2d564:	and	w16, w16, w18
   2d568:	cmp	x11, x1
   2d56c:	lsl	w16, w17, w16
   2d570:	csel	w16, w0, w16, eq  // eq = none
   2d574:	subs	x13, x13, #0x1
   2d578:	add	w14, w0, w14
   2d57c:	add	w12, w16, w12
   2d580:	b.gt	2d540 <__gmpn_compute_powtab@@Base+0xb0>
   2d584:	mov	w11, #0x9f                  	// #159
   2d588:	mov	w13, #0x851f                	// #34079
   2d58c:	mul	w11, w14, w11
   2d590:	movk	w13, #0x51eb, lsl #16
   2d594:	umull	x11, w11, w13
   2d598:	lsr	x11, x11, #37
   2d59c:	mov	w13, #0x28                  	// #40
   2d5a0:	madd	x8, x9, x13, x8
   2d5a4:	ldr	x3, [x8, #24]
   2d5a8:	cmp	w12, w11
   2d5ac:	cneg	x9, x10, hi  // hi = pmore
   2d5b0:	str	x9, [sp, #8]
   2d5b4:	str	x3, [sp, #24]
   2d5b8:	tbnz	x9, #63, 2d644 <__gmpn_compute_powtab@@Base+0x1b4>
   2d5bc:	adrp	x8, 54000 <__gmpn_bases@@Base+0x2938>
   2d5c0:	ldr	q0, [x8, #1728]
   2d5c4:	ldr	x20, [sp, #48]
   2d5c8:	add	x25, x22, #0x8
   2d5cc:	mov	w2, #0x1                   	// #1
   2d5d0:	mov	x0, x25
   2d5d4:	mov	x1, x22
   2d5d8:	str	x3, [x22]
   2d5dc:	str	x22, [x21]
   2d5e0:	str	x27, [x21, #24]
   2d5e4:	str	w20, [x21, #32]
   2d5e8:	stur	q0, [x21, #8]
   2d5ec:	add	x24, x22, #0x18
   2d5f0:	mov	w19, #0x1                   	// #1
   2d5f4:	bl	d4b0 <__gmpn_mul_1@plt>
   2d5f8:	ldr	x8, [x22, #8]
   2d5fc:	lsl	x9, x27, #1
   2d600:	ldr	x10, [sp, #8]
   2d604:	str	x0, [x22, #16]
   2d608:	cmp	x8, #0x0
   2d60c:	cset	w26, eq  // eq = none
   2d610:	cinc	x23, x19, ne  // ne = any
   2d614:	add	x25, x25, w26, uxtw #3
   2d618:	str	w20, [x21, #72]
   2d61c:	stp	x25, x23, [x21, #40]
   2d620:	stp	x26, x9, [x21, #56]
   2d624:	ldr	x28, [sp, #56]
   2d628:	lsl	x8, x27, x10
   2d62c:	mov	x11, x9
   2d630:	cmp	x28, x8
   2d634:	b.ne	2d7f0 <__gmpn_compute_powtab@@Base+0x360>  // b.any
   2d638:	add	x8, x21, #0x50
   2d63c:	mov	x9, #0xfffffffffffffffe    	// #-2
   2d640:	b	2d884 <__gmpn_compute_powtab@@Base+0x3f4>
   2d644:	adrp	x8, 54000 <__gmpn_bases@@Base+0x2938>
   2d648:	ldr	q0, [x8, #1728]
   2d64c:	ldr	x8, [sp, #48]
   2d650:	mvn	x23, x9
   2d654:	lsr	x9, x3, #19
   2d658:	mov	x24, x22
   2d65c:	str	x9, [sp, #40]
   2d660:	neg	x9, x3
   2d664:	str	x3, [x24], #8
   2d668:	str	w8, [x21, #32]
   2d66c:	and	x8, x3, x9
   2d670:	mov	x28, xzr
   2d674:	add	x10, x21, #0x30
   2d678:	mov	w26, #0x1                   	// #1
   2d67c:	sub	x19, x8, #0x1
   2d680:	str	x22, [x21]
   2d684:	str	x27, [x21, #24]
   2d688:	stur	q0, [x21, #8]
   2d68c:	str	x27, [sp, #32]
   2d690:	mov	x0, x24
   2d694:	mov	x1, x22
   2d698:	mov	x2, x26
   2d69c:	mov	x20, x10
   2d6a0:	lsl	x25, x26, #1
   2d6a4:	bl	c900 <__gmpn_sqr@plt>
   2d6a8:	sub	x8, x25, #0x1
   2d6ac:	ldr	x9, [x24, x8, lsl #3]
   2d6b0:	add	x10, sp, #0x38
   2d6b4:	ldr	x10, [x10, x23, lsl #3]
   2d6b8:	lsl	x27, x27, #1
   2d6bc:	cmp	x9, #0x0
   2d6c0:	csel	x25, x8, x25, eq  // eq = none
   2d6c4:	cmp	x27, x10
   2d6c8:	b.eq	2d71c <__gmpn_compute_powtab@@Base+0x28c>  // b.none
   2d6cc:	ldr	x8, [sp, #48]
   2d6d0:	cmp	w8, #0xa
   2d6d4:	b.ne	2d784 <__gmpn_compute_powtab@@Base+0x2f4>  // b.any
   2d6d8:	mov	x4, #0xce15                	// #52757
   2d6dc:	ldr	x3, [sp, #40]
   2d6e0:	movk	x4, #0x6559, lsl #16
   2d6e4:	movk	x4, #0x7250, lsl #32
   2d6e8:	movk	x4, #0x26b1, lsl #48
   2d6ec:	mov	w5, #0x13                  	// #19
   2d6f0:	mov	x0, x24
   2d6f4:	mov	x1, x24
   2d6f8:	mov	x2, x25
   2d6fc:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   2d700:	add	x8, x24, x25, lsl #3
   2d704:	ldur	x8, [x8, #-8]
   2d708:	cmp	x8, #0x0
   2d70c:	cset	w8, eq  // eq = none
   2d710:	sub	x25, x25, x8
   2d714:	ldr	x8, [sp, #32]
   2d718:	sub	x27, x27, x8
   2d71c:	ldr	x10, [x24]
   2d720:	add	x9, x21, #0x28
   2d724:	add	x8, x24, x26, lsl #4
   2d728:	lsl	x28, x28, #1
   2d72c:	cbz	x10, 2d760 <__gmpn_compute_powtab@@Base+0x2d0>
   2d730:	mov	x22, x24
   2d734:	stp	x22, x25, [x21, #40]
   2d738:	ldr	x10, [sp, #48]
   2d73c:	stp	x28, x27, [x21, #56]
   2d740:	subs	x23, x23, #0x1
   2d744:	mov	x24, x8
   2d748:	str	w10, [x21, #72]
   2d74c:	add	x10, x20, #0x28
   2d750:	mov	x21, x9
   2d754:	mov	x26, x25
   2d758:	b.pl	2d690 <__gmpn_compute_powtab@@Base+0x200>  // b.nfrst
   2d75c:	b	2d79c <__gmpn_compute_powtab@@Base+0x30c>
   2d760:	mov	x22, x24
   2d764:	ldr	x10, [x22, #8]!
   2d768:	tst	x10, x19
   2d76c:	b.ne	2d730 <__gmpn_compute_powtab@@Base+0x2a0>  // b.any
   2d770:	sub	x25, x25, #0x1
   2d774:	add	x28, x28, #0x1
   2d778:	mov	x24, x22
   2d77c:	cbz	x10, 2d764 <__gmpn_compute_powtab@@Base+0x2d4>
   2d780:	b	2d734 <__gmpn_compute_powtab@@Base+0x2a4>
   2d784:	ldr	x3, [sp, #24]
   2d788:	mov	x0, x24
   2d78c:	mov	x1, x24
   2d790:	mov	x2, x25
   2d794:	bl	c790 <__gmpn_divexact_1@plt>
   2d798:	b	2d700 <__gmpn_compute_powtab@@Base+0x270>
   2d79c:	ldr	x9, [sp, #8]
   2d7a0:	cmp	x9, #0x0
   2d7a4:	neg	x0, x9
   2d7a8:	b.gt	2d9e0 <__gmpn_compute_powtab@@Base+0x550>
   2d7ac:	mov	w8, #0x1                   	// #1
   2d7b0:	sub	x8, x8, x9
   2d7b4:	ldp	x9, x12, [x20, #-8]
   2d7b8:	ldr	x11, [x20, #8]
   2d7bc:	sub	x8, x8, #0x1
   2d7c0:	ldr	x10, [x9]
   2d7c4:	cmp	x10, #0x0
   2d7c8:	cset	w10, eq  // eq = none
   2d7cc:	cinc	x11, x11, eq  // eq = none
   2d7d0:	add	x9, x9, w10, uxtw #3
   2d7d4:	sub	x10, x12, x10
   2d7d8:	cmp	x8, #0x0
   2d7dc:	stp	x9, x10, [x20, #-8]
   2d7e0:	str	x11, [x20, #8]
   2d7e4:	sub	x20, x20, #0x28
   2d7e8:	b.gt	2d7b4 <__gmpn_compute_powtab@@Base+0x324>
   2d7ec:	b	2d9e0 <__gmpn_compute_powtab@@Base+0x550>
   2d7f0:	add	x20, x27, x27, lsl #1
   2d7f4:	sub	x8, x10, #0x2
   2d7f8:	lsl	x8, x20, x8
   2d7fc:	cmp	x8, x28
   2d800:	b.ls	2d820 <__gmpn_compute_powtab@@Base+0x390>  // b.plast
   2d804:	ldr	x8, [x25]
   2d808:	add	x19, x22, #0x30
   2d80c:	mov	x20, x11
   2d810:	str	x8, [x22, #24]
   2d814:	ldr	x8, [x25, #8]
   2d818:	str	x8, [x22, #32]
   2d81c:	b	2d860 <__gmpn_compute_powtab@@Base+0x3d0>
   2d820:	ldr	x3, [sp, #24]
   2d824:	mov	x0, x24
   2d828:	mov	x1, x25
   2d82c:	mov	x2, x23
   2d830:	add	x19, x22, #0x38
   2d834:	bl	d4b0 <__gmpn_mul_1@plt>
   2d838:	str	x0, [x24, x23, lsl #3]
   2d83c:	ldr	x8, [x22, #24]
   2d840:	ldr	x10, [sp, #8]
   2d844:	cmp	x0, #0x0
   2d848:	cinc	x9, x23, ne  // ne = any
   2d84c:	cmp	x8, #0x0
   2d850:	cset	w8, eq  // eq = none
   2d854:	cinc	x26, x26, eq  // eq = none
   2d858:	add	x24, x24, w8, uxtw #3
   2d85c:	sub	x23, x9, x8
   2d860:	stp	x24, x23, [x21, #80]
   2d864:	ldr	x8, [sp, #48]
   2d868:	mov	x25, x24
   2d86c:	mov	x11, x20
   2d870:	mov	x9, #0xfffffffffffffffd    	// #-3
   2d874:	str	w8, [x21, #112]
   2d878:	add	x8, x21, #0x78
   2d87c:	mov	x24, x19
   2d880:	stp	x26, x20, [x21, #96]
   2d884:	adds	x19, x10, x9
   2d888:	b.mi	2d9dc <__gmpn_compute_powtab@@Base+0x54c>  // b.first
   2d88c:	add	x9, sp, #0x38
   2d890:	stp	x27, x26, [sp, #32]
   2d894:	add	x9, x9, #0x8
   2d898:	sub	x27, x8, #0x28
   2d89c:	mov	x26, x11
   2d8a0:	str	x9, [sp, #16]
   2d8a4:	mov	x0, x24
   2d8a8:	mov	x1, x25
   2d8ac:	mov	x2, x23
   2d8b0:	lsl	x22, x23, #1
   2d8b4:	add	x20, x24, x23, lsl #4
   2d8b8:	bl	c900 <__gmpn_sqr@plt>
   2d8bc:	ldur	x8, [x20, #-8]
   2d8c0:	ldr	x9, [x24]
   2d8c4:	ldr	x10, [sp, #32]
   2d8c8:	cmp	x8, #0x0
   2d8cc:	cset	w8, eq  // eq = none
   2d8d0:	add	x21, x10, x26, lsl #1
   2d8d4:	cmp	x9, #0x0
   2d8d8:	mov	x9, x26
   2d8dc:	sub	x26, x22, x8
   2d8e0:	ldr	x8, [sp, #40]
   2d8e4:	lsl	x10, x21, x19
   2d8e8:	cset	w22, eq  // eq = none
   2d8ec:	cmp	x10, x28
   2d8f0:	add	x25, x24, w22, uxtw #3
   2d8f4:	sub	x23, x26, x22
   2d8f8:	bfi	x22, x8, #1, #63
   2d8fc:	b.ls	2d90c <__gmpn_compute_powtab@@Base+0x47c>  // b.plast
   2d900:	lsl	x26, x9, #1
   2d904:	mov	x28, x22
   2d908:	b	2d948 <__gmpn_compute_powtab@@Base+0x4b8>
   2d90c:	ldr	x3, [sp, #24]
   2d910:	mov	x0, x25
   2d914:	mov	x1, x25
   2d918:	mov	x2, x23
   2d91c:	bl	d4b0 <__gmpn_mul_1@plt>
   2d920:	str	x0, [x24, x26, lsl #3]
   2d924:	ldr	x8, [x25]
   2d928:	cmp	x0, #0x0
   2d92c:	cinc	x9, x23, ne  // ne = any
   2d930:	mov	x26, x21
   2d934:	cmp	x8, #0x0
   2d938:	cset	w8, eq  // eq = none
   2d93c:	cinc	x28, x22, eq  // eq = none
   2d940:	add	x25, x25, w8, uxtw #3
   2d944:	sub	x23, x9, x8
   2d948:	stp	x25, x23, [x27, #40]
   2d94c:	ldr	x8, [sp, #48]
   2d950:	stp	x28, x26, [x27, #56]
   2d954:	ldr	x9, [sp, #16]
   2d958:	str	w8, [x27, #72]
   2d95c:	ldr	x8, [x27, #24]
   2d960:	ldr	x24, [x9, x19, lsl #3]
   2d964:	cmp	x8, x24
   2d968:	b.cs	2d9b8 <__gmpn_compute_powtab@@Base+0x528>  // b.hs, b.nlast
   2d96c:	ldp	x22, x21, [x27]
   2d970:	ldr	x3, [sp, #24]
   2d974:	mov	x0, x22
   2d978:	mov	x1, x22
   2d97c:	mov	x2, x21
   2d980:	bl	d4b0 <__gmpn_mul_1@plt>
   2d984:	str	x0, [x22, x21, lsl #3]
   2d988:	str	x24, [x27, #24]
   2d98c:	ldr	x8, [x22]
   2d990:	ldr	x9, [x27, #16]
   2d994:	cmp	x0, #0x0
   2d998:	cinc	x10, x21, ne  // ne = any
   2d99c:	cmp	x8, #0x0
   2d9a0:	cset	w8, eq  // eq = none
   2d9a4:	cinc	x9, x9, eq  // eq = none
   2d9a8:	add	x11, x22, w8, uxtw #3
   2d9ac:	sub	x8, x10, x8
   2d9b0:	stp	x11, x8, [x27]
   2d9b4:	str	x9, [x27, #16]
   2d9b8:	subs	x19, x19, #0x1
   2d9bc:	b.lt	2d9d4 <__gmpn_compute_powtab@@Base+0x544>  // b.tstop
   2d9c0:	str	x28, [sp, #40]
   2d9c4:	ldr	x28, [sp, #56]
   2d9c8:	add	x24, x20, #0x10
   2d9cc:	add	x27, x27, #0x28
   2d9d0:	b	2d8a4 <__gmpn_compute_powtab@@Base+0x414>
   2d9d4:	ldr	x0, [sp, #8]
   2d9d8:	b	2d9e0 <__gmpn_compute_powtab@@Base+0x550>
   2d9dc:	mov	x0, x10
   2d9e0:	add	sp, sp, #0x240
   2d9e4:	ldp	x20, x19, [sp, #80]
   2d9e8:	ldp	x22, x21, [sp, #64]
   2d9ec:	ldp	x24, x23, [sp, #48]
   2d9f0:	ldp	x26, x25, [sp, #32]
   2d9f4:	ldp	x28, x27, [sp, #16]
   2d9f8:	ldp	x29, x30, [sp], #96
   2d9fc:	ret

000000000002da00 <__gmpn_scan0@@Base>:
   2da00:	lsr	x8, x1, #3
   2da04:	and	x8, x8, #0x1ffffffffffffff8
   2da08:	add	x8, x0, x8
   2da0c:	ldr	x9, [x8], #8
   2da10:	mov	x10, #0xffffffffffffffff    	// #-1
   2da14:	lsl	x10, x10, x1
   2da18:	bics	x9, x10, x9
   2da1c:	b.ne	2da30 <__gmpn_scan0@@Base+0x30>  // b.any
   2da20:	ldr	x9, [x8], #8
   2da24:	cmn	x9, #0x1
   2da28:	b.eq	2da20 <__gmpn_scan0@@Base+0x20>  // b.none
   2da2c:	mvn	x9, x9
   2da30:	rbit	x9, x9
   2da34:	clz	x9, x9
   2da38:	sub	x8, x8, x0
   2da3c:	orr	x9, x9, #0xffffffffffffffc0
   2da40:	add	x0, x9, x8, lsl #3
   2da44:	ret

000000000002da48 <__gmpn_scan1@@Base>:
   2da48:	lsr	x8, x1, #3
   2da4c:	and	x8, x8, #0x1ffffffffffffff8
   2da50:	add	x8, x0, x8
   2da54:	ldr	x9, [x8], #8
   2da58:	mov	x10, #0xffffffffffffffff    	// #-1
   2da5c:	lsl	x10, x10, x1
   2da60:	ands	x9, x9, x10
   2da64:	b.ne	2da70 <__gmpn_scan1@@Base+0x28>  // b.any
   2da68:	ldr	x9, [x8], #8
   2da6c:	cbz	x9, 2da68 <__gmpn_scan1@@Base+0x20>
   2da70:	rbit	x9, x9
   2da74:	clz	x9, x9
   2da78:	sub	x8, x8, x0
   2da7c:	orr	x9, x9, #0xffffffffffffffc0
   2da80:	add	x0, x9, x8, lsl #3
   2da84:	ret

000000000002da88 <__gmpn_popcount@@Base>:
   2da88:	mov	x11, #0x1fff                	// #8191
   2da8c:	cmp	x1, x11
   2da90:	b.hi	2db6c <__gmpn_popcount@@Base+0xe4>  // b.pmore
   2da94:	movi	v4.16b, #0x0
   2da98:	movi	v5.16b, #0x0
   2da9c:	tbz	w1, #0, 2dab0 <__gmpn_popcount@@Base+0x28>
   2daa0:	sub	x1, x1, #0x1
   2daa4:	ld1	{v0.1d}, [x0], #8
   2daa8:	cnt	v6.16b, v0.16b
   2daac:	uadalp	v4.8h, v6.16b
   2dab0:	tbz	w1, #1, 2dac4 <__gmpn_popcount@@Base+0x3c>
   2dab4:	sub	x1, x1, #0x2
   2dab8:	ld1	{v0.2d}, [x0], #16
   2dabc:	cnt	v6.16b, v0.16b
   2dac0:	uadalp	v4.8h, v6.16b
   2dac4:	tbz	w1, #2, 2dae8 <__gmpn_popcount@@Base+0x60>
   2dac8:	subs	x1, x1, #0x4
   2dacc:	ld1	{v0.2d, v1.2d}, [x0], #32
   2dad0:	b.ls	2db40 <__gmpn_popcount@@Base+0xb8>  // b.plast
   2dad4:	ld1	{v2.2d, v3.2d}, [x0], #32
   2dad8:	sub	x1, x1, #0x4
   2dadc:	cnt	v6.16b, v0.16b
   2dae0:	cnt	v7.16b, v1.16b
   2dae4:	b	2db1c <__gmpn_popcount@@Base+0x94>
   2dae8:	subs	x1, x1, #0x8
   2daec:	b.cc	2db54 <__gmpn_popcount@@Base+0xcc>  // b.lo, b.ul, b.last
   2daf0:	ld1	{v2.2d, v3.2d}, [x0], #32
   2daf4:	ld1	{v0.2d, v1.2d}, [x0], #32
   2daf8:	cnt	v6.16b, v2.16b
   2dafc:	cnt	v7.16b, v3.16b
   2db00:	subs	x1, x1, #0x8
   2db04:	b.cc	2db38 <__gmpn_popcount@@Base+0xb0>  // b.lo, b.ul, b.last
   2db08:	ld1	{v2.2d, v3.2d}, [x0], #32
   2db0c:	uadalp	v4.8h, v6.16b
   2db10:	cnt	v6.16b, v0.16b
   2db14:	uadalp	v5.8h, v7.16b
   2db18:	cnt	v7.16b, v1.16b
   2db1c:	ld1	{v0.2d, v1.2d}, [x0], #32
   2db20:	subs	x1, x1, #0x8
   2db24:	uadalp	v4.8h, v6.16b
   2db28:	cnt	v6.16b, v2.16b
   2db2c:	uadalp	v5.8h, v7.16b
   2db30:	cnt	v7.16b, v3.16b
   2db34:	b.cs	2db08 <__gmpn_popcount@@Base+0x80>  // b.hs, b.nlast
   2db38:	uadalp	v4.8h, v6.16b
   2db3c:	uadalp	v5.8h, v7.16b
   2db40:	cnt	v6.16b, v0.16b
   2db44:	cnt	v7.16b, v1.16b
   2db48:	uadalp	v4.8h, v6.16b
   2db4c:	uadalp	v5.8h, v7.16b
   2db50:	add	v4.8h, v4.8h, v5.8h
   2db54:	uaddlp	v4.4s, v4.8h
   2db58:	uaddlp	v4.2d, v4.4s
   2db5c:	mov	x0, v4.d[0]
   2db60:	mov	x1, v4.d[1]
   2db64:	add	x0, x0, x1
   2db68:	ret
   2db6c:	mov	x8, x30
   2db70:	mov	x7, x1
   2db74:	mov	x4, #0x0                   	// #0
   2db78:	mov	x9, #0xff80                	// #65408
   2db7c:	mov	x10, #0x1ff0                	// #8176
   2db80:	add	x5, x0, x9
   2db84:	mov	x1, #0x1fe8                	// #8168
   2db88:	movi	v4.16b, #0x0
   2db8c:	movi	v5.16b, #0x0
   2db90:	bl	2daf0 <__gmpn_popcount@@Base+0x68>
   2db94:	add	x4, x4, x0
   2db98:	mov	x0, x5
   2db9c:	sub	x7, x7, x10
   2dba0:	cmp	x7, x11
   2dba4:	b.hi	2db80 <__gmpn_popcount@@Base+0xf8>  // b.pmore
   2dba8:	mov	x1, x7
   2dbac:	bl	2da94 <__gmpn_popcount@@Base+0xc>
   2dbb0:	add	x0, x4, x0
   2dbb4:	mov	x30, x8
   2dbb8:	ret
   2dbbc:	nop

000000000002dbc0 <__gmpn_hamdist@@Base>:
   2dbc0:	mov	x11, #0x1fff                	// #8191
   2dbc4:	cmp	x2, x11
   2dbc8:	b.hi	2dcf4 <__gmpn_hamdist@@Base+0x134>  // b.pmore
   2dbcc:	movi	v4.16b, #0x0
   2dbd0:	movi	v5.16b, #0x0
   2dbd4:	tbz	w2, #0, 2dbf0 <__gmpn_hamdist@@Base+0x30>
   2dbd8:	sub	x2, x2, #0x1
   2dbdc:	ld1	{v0.1d}, [x0], #8
   2dbe0:	ld1	{v16.1d}, [x1], #8
   2dbe4:	eor	v0.16b, v0.16b, v16.16b
   2dbe8:	cnt	v6.16b, v0.16b
   2dbec:	uadalp	v4.8h, v6.16b
   2dbf0:	tbz	w2, #1, 2dc0c <__gmpn_hamdist@@Base+0x4c>
   2dbf4:	sub	x2, x2, #0x2
   2dbf8:	ld1	{v0.2d}, [x0], #16
   2dbfc:	ld1	{v16.2d}, [x1], #16
   2dc00:	eor	v0.16b, v0.16b, v16.16b
   2dc04:	cnt	v6.16b, v0.16b
   2dc08:	uadalp	v4.8h, v6.16b
   2dc0c:	tbz	w2, #2, 2dc40 <__gmpn_hamdist@@Base+0x80>
   2dc10:	subs	x2, x2, #0x4
   2dc14:	ld1	{v0.2d, v1.2d}, [x0], #32
   2dc18:	ld1	{v16.2d, v17.2d}, [x1], #32
   2dc1c:	b.ls	2dcc0 <__gmpn_hamdist@@Base+0x100>  // b.plast
   2dc20:	ld1	{v2.2d, v3.2d}, [x0], #32
   2dc24:	ld1	{v18.2d, v19.2d}, [x1], #32
   2dc28:	eor	v0.16b, v0.16b, v16.16b
   2dc2c:	eor	v1.16b, v1.16b, v17.16b
   2dc30:	sub	x2, x2, #0x4
   2dc34:	cnt	v6.16b, v0.16b
   2dc38:	cnt	v7.16b, v1.16b
   2dc3c:	b	2dc90 <__gmpn_hamdist@@Base+0xd0>
   2dc40:	subs	x2, x2, #0x8
   2dc44:	b.cc	2dcdc <__gmpn_hamdist@@Base+0x11c>  // b.lo, b.ul, b.last
   2dc48:	ld1	{v2.2d, v3.2d}, [x0], #32
   2dc4c:	ld1	{v0.2d, v1.2d}, [x0], #32
   2dc50:	ld1	{v18.2d, v19.2d}, [x1], #32
   2dc54:	ld1	{v16.2d, v17.2d}, [x1], #32
   2dc58:	eor	v2.16b, v2.16b, v18.16b
   2dc5c:	eor	v3.16b, v3.16b, v19.16b
   2dc60:	cnt	v6.16b, v2.16b
   2dc64:	cnt	v7.16b, v3.16b
   2dc68:	subs	x2, x2, #0x8
   2dc6c:	b.cc	2dcb8 <__gmpn_hamdist@@Base+0xf8>  // b.lo, b.ul, b.last
   2dc70:	ld1	{v2.2d, v3.2d}, [x0], #32
   2dc74:	ld1	{v18.2d, v19.2d}, [x1], #32
   2dc78:	eor	v0.16b, v0.16b, v16.16b
   2dc7c:	eor	v1.16b, v1.16b, v17.16b
   2dc80:	uadalp	v4.8h, v6.16b
   2dc84:	cnt	v6.16b, v0.16b
   2dc88:	uadalp	v5.8h, v7.16b
   2dc8c:	cnt	v7.16b, v1.16b
   2dc90:	ld1	{v0.2d, v1.2d}, [x0], #32
   2dc94:	ld1	{v16.2d, v17.2d}, [x1], #32
   2dc98:	eor	v2.16b, v2.16b, v18.16b
   2dc9c:	eor	v3.16b, v3.16b, v19.16b
   2dca0:	subs	x2, x2, #0x8
   2dca4:	uadalp	v4.8h, v6.16b
   2dca8:	cnt	v6.16b, v2.16b
   2dcac:	uadalp	v5.8h, v7.16b
   2dcb0:	cnt	v7.16b, v3.16b
   2dcb4:	b.cs	2dc70 <__gmpn_hamdist@@Base+0xb0>  // b.hs, b.nlast
   2dcb8:	uadalp	v4.8h, v6.16b
   2dcbc:	uadalp	v5.8h, v7.16b
   2dcc0:	eor	v0.16b, v0.16b, v16.16b
   2dcc4:	eor	v1.16b, v1.16b, v17.16b
   2dcc8:	cnt	v6.16b, v0.16b
   2dccc:	cnt	v7.16b, v1.16b
   2dcd0:	uadalp	v4.8h, v6.16b
   2dcd4:	uadalp	v5.8h, v7.16b
   2dcd8:	add	v4.8h, v4.8h, v5.8h
   2dcdc:	uaddlp	v4.4s, v4.8h
   2dce0:	uaddlp	v4.2d, v4.4s
   2dce4:	mov	x0, v4.d[0]
   2dce8:	mov	x1, v4.d[1]
   2dcec:	add	x0, x0, x1
   2dcf0:	ret
   2dcf4:	mov	x8, x30
   2dcf8:	mov	x7, x2
   2dcfc:	mov	x4, #0x0                   	// #0
   2dd00:	mov	x9, #0xff80                	// #65408
   2dd04:	mov	x10, #0x1ff0                	// #8176
   2dd08:	add	x5, x0, x9
   2dd0c:	add	x6, x1, x9
   2dd10:	mov	x2, #0x1fe8                	// #8168
   2dd14:	movi	v4.16b, #0x0
   2dd18:	movi	v5.16b, #0x0
   2dd1c:	bl	2dc48 <__gmpn_hamdist@@Base+0x88>
   2dd20:	add	x4, x4, x0
   2dd24:	mov	x0, x5
   2dd28:	mov	x1, x6
   2dd2c:	sub	x7, x7, x10
   2dd30:	cmp	x7, x11
   2dd34:	b.hi	2dd08 <__gmpn_hamdist@@Base+0x148>  // b.pmore
   2dd38:	mov	x2, x7
   2dd3c:	bl	2dbcc <__gmpn_hamdist@@Base+0xc>
   2dd40:	add	x0, x4, x0
   2dd44:	mov	x30, x8
   2dd48:	ret

000000000002dd4c <__gmpn_cmp@@Base>:
   2dd4c:	sub	x8, x0, #0x8
   2dd50:	sub	x9, x1, #0x8
   2dd54:	subs	x10, x2, #0x1
   2dd58:	b.lt	2dd7c <__gmpn_cmp@@Base+0x30>  // b.tstop
   2dd5c:	ldr	x11, [x8, x2, lsl #3]
   2dd60:	ldr	x12, [x9, x2, lsl #3]
   2dd64:	mov	x2, x10
   2dd68:	cmp	x11, x12
   2dd6c:	b.eq	2dd54 <__gmpn_cmp@@Base+0x8>  // b.none
   2dd70:	mov	w8, #0x1                   	// #1
   2dd74:	cneg	w0, w8, ls  // ls = plast
   2dd78:	ret
   2dd7c:	mov	w0, wzr
   2dd80:	ret

000000000002dd84 <__gmpn_zero_p@@Base>:
   2dd84:	sub	x8, x0, #0x8
   2dd88:	ldr	x9, [x8, x1, lsl #3]
   2dd8c:	cbnz	x9, 2dda0 <__gmpn_zero_p@@Base+0x1c>
   2dd90:	sub	x1, x1, #0x1
   2dd94:	cbnz	x1, 2dd88 <__gmpn_zero_p@@Base+0x4>
   2dd98:	mov	w0, #0x1                   	// #1
   2dd9c:	ret
   2dda0:	mov	w0, wzr
   2dda4:	ret

000000000002dda8 <__gmpn_perfect_square_p@@Base>:
   2dda8:	stp	x29, x30, [sp, #-32]!
   2ddac:	stp	x20, x19, [sp, #16]
   2ddb0:	mov	x29, sp
   2ddb4:	sub	sp, sp, #0x10
   2ddb8:	ldr	x8, [x0]
   2ddbc:	adrp	x10, 54000 <__gmpn_bases@@Base+0x2938>
   2ddc0:	add	x10, x10, #0x6d0
   2ddc4:	ubfx	x9, x8, #6, #2
   2ddc8:	ldr	x9, [x10, x9, lsl #3]
   2ddcc:	lsr	x8, x9, x8
   2ddd0:	tbz	w8, #0, 2df54 <__gmpn_perfect_square_p@@Base+0x1ac>
   2ddd4:	mov	x19, x0
   2ddd8:	mov	x20, x1
   2dddc:	bl	cf80 <__gmpn_mod_34lsub1@plt>
   2dde0:	mov	x9, #0x2fd3                	// #12243
   2dde4:	and	x8, x0, #0xffffffffffff
   2dde8:	movk	x9, #0xd2fd, lsl #16
   2ddec:	movk	x9, #0xfd2f, lsl #32
   2ddf0:	add	x8, x8, x0, lsr #48
   2ddf4:	mul	x9, x8, x9
   2ddf8:	mov	w10, #0x5b                  	// #91
   2ddfc:	and	x9, x9, #0x1ffffffffffff
   2de00:	mul	x9, x9, x10
   2de04:	mov	x10, #0x20e1                	// #8417
   2de08:	movk	x10, #0x9538, lsl #16
   2de0c:	mov	w11, #0x1240                	// #4672
   2de10:	lsr	x9, x9, #49
   2de14:	movk	x10, #0xa206, lsl #32
   2de18:	movk	w11, #0x219, lsl #16
   2de1c:	cmp	w9, #0x40
   2de20:	movk	x10, #0x8850, lsl #48
   2de24:	csel	x10, x10, x11, cc  // cc = lo, ul, last
   2de28:	lsr	x9, x10, x9
   2de2c:	tbz	w9, #0, 2df54 <__gmpn_perfect_square_p@@Base+0x1ac>
   2de30:	mov	x9, #0xfcfd                	// #64765
   2de34:	movk	x9, #0xfcfc, lsl #16
   2de38:	movk	x9, #0xfcfc, lsl #32
   2de3c:	mul	x9, x8, x9
   2de40:	mov	w10, #0x55                  	// #85
   2de44:	and	x9, x9, #0x1ffffffffffff
   2de48:	mul	x9, x9, x10
   2de4c:	mov	x10, #0xa105                	// #41221
   2de50:	movk	x10, #0x4206, lsl #16
   2de54:	mov	w11, #0x2158                	// #8536
   2de58:	lsr	x9, x9, #49
   2de5c:	movk	x10, #0x8c4b, lsl #32
   2de60:	movk	w11, #0x8, lsl #16
   2de64:	cmp	w9, #0x40
   2de68:	movk	x10, #0x10b4, lsl #48
   2de6c:	csel	x10, x10, x11, cc  // cc = lo, ul, last
   2de70:	lsr	x9, x10, x9
   2de74:	tbz	w9, #0, 2df54 <__gmpn_perfect_square_p@@Base+0x1ac>
   2de78:	mov	x9, #0x8e39                	// #36409
   2de7c:	movk	x9, #0x38e3, lsl #16
   2de80:	movk	x9, #0xe38e, lsl #32
   2de84:	mul	x9, x8, x9
   2de88:	and	x9, x9, #0x1ffffffffffff
   2de8c:	add	x9, x9, x9, lsl #3
   2de90:	lsr	x9, x9, #49
   2de94:	mov	w10, #0x93                  	// #147
   2de98:	lsr	x9, x10, x9
   2de9c:	tbz	w9, #0, 2df54 <__gmpn_perfect_square_p@@Base+0x1ac>
   2dea0:	mov	x9, #0xa3a1                	// #41889
   2dea4:	movk	x9, #0x5f02, lsl #16
   2dea8:	movk	x9, #0xfd5c, lsl #32
   2deac:	mul	x8, x8, x9
   2deb0:	mov	w10, #0x61                  	// #97
   2deb4:	and	x8, x8, #0x1ffffffffffff
   2deb8:	mov	x9, #0x1b5f                	// #7007
   2debc:	mov	x11, #0x8b47                	// #35655
   2dec0:	mul	x8, x8, x10
   2dec4:	movk	x9, #0x8b45, lsl #16
   2dec8:	movk	x11, #0xeb62, lsl #16
   2decc:	lsr	x8, x8, #49
   2ded0:	movk	x9, #0x981b, lsl #32
   2ded4:	movk	x11, #0x1, lsl #32
   2ded8:	cmp	w8, #0x40
   2dedc:	movk	x9, #0x6067, lsl #48
   2dee0:	csel	x9, x9, x11, cc  // cc = lo, ul, last
   2dee4:	lsr	x8, x9, x8
   2dee8:	tbz	w8, #0, 2df54 <__gmpn_perfect_square_p@@Base+0x1ac>
   2deec:	add	x8, x20, #0x1
   2def0:	add	x9, x20, #0x2
   2def4:	cmp	x8, #0x0
   2def8:	csinc	x8, x9, x20, lt  // lt = tstop
   2defc:	lsl	x8, x8, #2
   2df00:	and	x1, x8, #0xfffffffffffffff8
   2df04:	mov	w8, #0x7f00                	// #32512
   2df08:	cmp	x1, x8
   2df0c:	stur	xzr, [x29, #-8]
   2df10:	b.hi	2df6c <__gmpn_perfect_square_p@@Base+0x1c4>  // b.pmore
   2df14:	add	x9, x1, #0xf
   2df18:	mov	x8, sp
   2df1c:	and	x9, x9, #0xfffffffffffffff0
   2df20:	sub	x0, x8, x9
   2df24:	mov	sp, x0
   2df28:	mov	x1, xzr
   2df2c:	mov	x2, x19
   2df30:	mov	x3, x20
   2df34:	bl	d3d0 <__gmpn_sqrtrem@plt>
   2df38:	ldur	x8, [x29, #-8]
   2df3c:	cmp	x0, #0x0
   2df40:	cset	w19, eq  // eq = none
   2df44:	cbz	x8, 2df58 <__gmpn_perfect_square_p@@Base+0x1b0>
   2df48:	mov	x0, x8
   2df4c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2df50:	b	2df58 <__gmpn_perfect_square_p@@Base+0x1b0>
   2df54:	mov	w19, wzr
   2df58:	mov	w0, w19
   2df5c:	mov	sp, x29
   2df60:	ldp	x20, x19, [sp, #16]
   2df64:	ldp	x29, x30, [sp], #32
   2df68:	ret
   2df6c:	sub	x0, x29, #0x8
   2df70:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2df74:	b	2df28 <__gmpn_perfect_square_p@@Base+0x180>

000000000002df78 <__gmpn_perfect_power_p@@Base>:
   2df78:	stp	x29, x30, [sp, #-80]!
   2df7c:	stp	x26, x25, [sp, #16]
   2df80:	stp	x24, x23, [sp, #32]
   2df84:	stp	x22, x21, [sp, #48]
   2df88:	stp	x20, x19, [sp, #64]
   2df8c:	mov	x29, sp
   2df90:	sub	sp, sp, #0x30
   2df94:	mov	x19, x1
   2df98:	mov	x20, x0
   2df9c:	mov	x22, x1
   2dfa0:	stur	x1, [x29, #-8]
   2dfa4:	tbnz	x1, #63, 2dfb0 <__gmpn_perfect_power_p@@Base+0x38>
   2dfa8:	cbnz	x22, 2dfbc <__gmpn_perfect_power_p@@Base+0x44>
   2dfac:	b	2dfd0 <__gmpn_perfect_power_p@@Base+0x58>
   2dfb0:	neg	x22, x19
   2dfb4:	stur	x22, [x29, #-8]
   2dfb8:	cbz	x22, 2dfd0 <__gmpn_perfect_power_p@@Base+0x58>
   2dfbc:	cmp	x22, #0x1
   2dfc0:	b.ne	2dfd8 <__gmpn_perfect_power_p@@Base+0x60>  // b.any
   2dfc4:	ldr	x8, [x20]
   2dfc8:	cmp	x8, #0x1
   2dfcc:	b.ne	2dfd8 <__gmpn_perfect_power_p@@Base+0x60>  // b.any
   2dfd0:	mov	w19, #0x1                   	// #1
   2dfd4:	b	2e258 <__gmpn_perfect_power_p@@Base+0x2e0>
   2dfd8:	mov	x0, x20
   2dfdc:	mov	x1, xzr
   2dfe0:	stur	xzr, [x29, #-40]
   2dfe4:	bl	d170 <__gmpn_scan1@plt>
   2dfe8:	mov	x23, x0
   2dfec:	cbz	x0, 2e000 <__gmpn_perfect_power_p@@Base+0x88>
   2dff0:	subs	x8, x23, #0x1
   2dff4:	b.ne	2e008 <__gmpn_perfect_power_p@@Base+0x90>  // b.any
   2dff8:	mov	w19, wzr
   2dffc:	b	2e258 <__gmpn_perfect_power_p@@Base+0x2e0>
   2e000:	mov	x26, x23
   2e004:	b	2e0b8 <__gmpn_perfect_power_p@@Base+0x140>
   2e008:	lsr	x9, x23, #6
   2e00c:	add	x10, x9, #0x1
   2e010:	cmp	x10, x22
   2e014:	b.ne	2e040 <__gmpn_perfect_power_p@@Base+0xc8>  // b.any
   2e018:	ldr	x10, [x20, x9, lsl #3]
   2e01c:	sub	x11, x10, #0x1
   2e020:	tst	x10, x11
   2e024:	b.ne	2e040 <__gmpn_perfect_power_p@@Base+0xc8>  // b.any
   2e028:	cmp	x19, #0x0
   2e02c:	cset	w9, ge  // ge = tcont
   2e030:	tst	x23, x8
   2e034:	cset	w8, ne  // ne = any
   2e038:	orr	w19, w8, w9
   2e03c:	b	2e258 <__gmpn_perfect_power_p@@Base+0x2e0>
   2e040:	and	x24, x23, #0x3f
   2e044:	sub	x22, x22, x9
   2e048:	add	x20, x20, x9, lsl #3
   2e04c:	stur	x22, [x29, #-8]
   2e050:	cbz	x24, 2e0b4 <__gmpn_perfect_power_p@@Base+0x13c>
   2e054:	lsl	x1, x22, #3
   2e058:	mov	w8, #0x7f00                	// #32512
   2e05c:	cmp	x1, x8
   2e060:	b.hi	2e280 <__gmpn_perfect_power_p@@Base+0x308>  // b.pmore
   2e064:	add	x9, x1, #0xf
   2e068:	mov	x8, sp
   2e06c:	and	x9, x9, #0xfffffffffffffff0
   2e070:	sub	x21, x8, x9
   2e074:	mov	sp, x21
   2e078:	mov	x0, x21
   2e07c:	mov	x1, x20
   2e080:	mov	x2, x22
   2e084:	mov	w3, w24
   2e088:	bl	c1b0 <__gmpn_rshift@plt>
   2e08c:	ldur	x8, [x29, #-8]
   2e090:	mov	w26, #0x1                   	// #1
   2e094:	mov	x20, x21
   2e098:	add	x9, x21, x8, lsl #3
   2e09c:	ldur	x9, [x9, #-8]
   2e0a0:	cmp	x9, #0x0
   2e0a4:	cset	w9, eq  // eq = none
   2e0a8:	sub	x22, x8, x9
   2e0ac:	stur	x22, [x29, #-8]
   2e0b0:	b	2e0b8 <__gmpn_perfect_power_p@@Base+0x140>
   2e0b4:	mov	x26, xzr
   2e0b8:	cmp	x22, #0x64
   2e0bc:	mov	w8, #0x2                   	// #2
   2e0c0:	cset	w9, gt
   2e0c4:	csinc	x8, x8, xzr, gt
   2e0c8:	cmp	x22, #0x14
   2e0cc:	csel	x25, x9, x8, le
   2e0d0:	adrp	x8, 54000 <__gmpn_bases@@Base+0x2938>
   2e0d4:	add	x8, x8, #0x6f8
   2e0d8:	ldrh	w24, [x8, x25, lsl #1]
   2e0dc:	sub	x3, x29, #0x1c
   2e0e0:	mov	x0, x20
   2e0e4:	mov	x1, x22
   2e0e8:	mov	x2, x24
   2e0ec:	stur	x23, [x29, #-16]
   2e0f0:	stur	wzr, [x29, #-28]
   2e0f4:	bl	c630 <__gmpn_trialdiv@plt>
   2e0f8:	cbz	x0, 2e1d4 <__gmpn_perfect_power_p@@Base+0x25c>
   2e0fc:	cbnz	x26, 2e124 <__gmpn_perfect_power_p@@Base+0x1ac>
   2e100:	lsl	x1, x22, #3
   2e104:	mov	w8, #0x7f00                	// #32512
   2e108:	cmp	x1, x8
   2e10c:	b.hi	2e294 <__gmpn_perfect_power_p@@Base+0x31c>  // b.pmore
   2e110:	add	x9, x1, #0xf
   2e114:	mov	x8, sp
   2e118:	and	x9, x9, #0xfffffffffffffff0
   2e11c:	sub	x21, x8, x9
   2e120:	mov	sp, x21
   2e124:	adrp	x22, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2e128:	ldr	x22, [x22, #3952]
   2e12c:	mov	w23, #0x2                   	// #2
   2e130:	ubfx	x8, x0, #1, #7
   2e134:	ldrb	w8, [x22, x8]
   2e138:	ldur	x3, [x29, #-8]
   2e13c:	sub	x1, x29, #0x8
   2e140:	sub	x4, x29, #0x18
   2e144:	msub	x9, x0, x8, x23
   2e148:	mul	x8, x9, x8
   2e14c:	msub	x9, x8, x0, x23
   2e150:	mul	x8, x8, x9
   2e154:	msub	x9, x8, x0, x23
   2e158:	mul	x8, x8, x9
   2e15c:	mov	w5, #0x1                   	// #1
   2e160:	mov	x6, #0xffffffffffffffff    	// #-1
   2e164:	mov	x0, x21
   2e168:	mov	x2, x20
   2e16c:	stur	x8, [x29, #-24]
   2e170:	bl	cd60 <__gmpn_remove@plt>
   2e174:	ldur	x8, [x29, #-16]
   2e178:	mov	x2, x0
   2e17c:	cbz	x8, 2e190 <__gmpn_perfect_power_p@@Base+0x218>
   2e180:	sub	x0, x29, #0x10
   2e184:	mov	w1, #0x1                   	// #1
   2e188:	bl	bfa0 <__gmpn_gcd_1@plt>
   2e18c:	mov	x2, x0
   2e190:	subs	x8, x2, #0x1
   2e194:	stur	x2, [x29, #-16]
   2e198:	b.eq	2e234 <__gmpn_perfect_power_p@@Base+0x2bc>  // b.none
   2e19c:	ldur	x1, [x29, #-8]
   2e1a0:	cmp	x1, #0x1
   2e1a4:	b.ne	2e1b4 <__gmpn_perfect_power_p@@Base+0x23c>  // b.any
   2e1a8:	ldr	x9, [x21]
   2e1ac:	cmp	x9, #0x1
   2e1b0:	b.eq	2e23c <__gmpn_perfect_power_p@@Base+0x2c4>  // b.none
   2e1b4:	sub	x3, x29, #0x1c
   2e1b8:	mov	x0, x21
   2e1bc:	mov	x2, x24
   2e1c0:	bl	c630 <__gmpn_trialdiv@plt>
   2e1c4:	mov	x20, x21
   2e1c8:	cbnz	x0, 2e130 <__gmpn_perfect_power_p@@Base+0x1b8>
   2e1cc:	ldp	x23, x22, [x29, #-16]
   2e1d0:	b	2e1d8 <__gmpn_perfect_power_p@@Base+0x260>
   2e1d4:	mov	x21, x20
   2e1d8:	add	x8, x21, x22, lsl #3
   2e1dc:	ldur	x8, [x8, #-8]
   2e1e0:	adrp	x9, 54000 <__gmpn_bases@@Base+0x2938>
   2e1e4:	add	x9, x9, #0x700
   2e1e8:	ldr	d0, [x9, x25, lsl #3]
   2e1ec:	adrp	x10, 54000 <__gmpn_bases@@Base+0x2938>
   2e1f0:	lsl	x9, x22, #6
   2e1f4:	ldr	d1, [x10, #1776]
   2e1f8:	clz	x8, x8
   2e1fc:	sub	x4, x9, x8
   2e200:	ucvtf	d2, x4
   2e204:	fmul	d0, d0, d2
   2e208:	fadd	d0, d0, d1
   2e20c:	fcvtzu	x8, d0
   2e210:	lsr	x5, x19, #63
   2e214:	add	x2, x8, #0x1
   2e218:	mov	x0, x21
   2e21c:	mov	x1, x22
   2e220:	mov	x3, x23
   2e224:	stur	x2, [x29, #-24]
   2e228:	bl	2e2ac <__gmpn_perfect_power_p@@Base+0x334>
   2e22c:	mov	w19, w0
   2e230:	b	2e250 <__gmpn_perfect_power_p@@Base+0x2d8>
   2e234:	mov	w19, wzr
   2e238:	b	2e250 <__gmpn_perfect_power_p@@Base+0x2d8>
   2e23c:	cmp	x19, #0x0
   2e240:	cset	w9, ge  // ge = tcont
   2e244:	tst	x2, x8
   2e248:	cset	w8, ne  // ne = any
   2e24c:	orr	w19, w8, w9
   2e250:	ldur	x0, [x29, #-40]
   2e254:	cbnz	x0, 2e278 <__gmpn_perfect_power_p@@Base+0x300>
   2e258:	mov	w0, w19
   2e25c:	mov	sp, x29
   2e260:	ldp	x20, x19, [sp, #64]
   2e264:	ldp	x22, x21, [sp, #48]
   2e268:	ldp	x24, x23, [sp, #32]
   2e26c:	ldp	x26, x25, [sp, #16]
   2e270:	ldp	x29, x30, [sp], #80
   2e274:	ret
   2e278:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2e27c:	b	2e258 <__gmpn_perfect_power_p@@Base+0x2e0>
   2e280:	sub	x0, x29, #0x28
   2e284:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2e288:	ldur	x22, [x29, #-8]
   2e28c:	mov	x21, x0
   2e290:	b	2e078 <__gmpn_perfect_power_p@@Base+0x100>
   2e294:	mov	x22, x0
   2e298:	sub	x0, x29, #0x28
   2e29c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2e2a0:	mov	x21, x0
   2e2a4:	mov	x0, x22
   2e2a8:	b	2e124 <__gmpn_perfect_power_p@@Base+0x1ac>
   2e2ac:	stp	x29, x30, [sp, #-96]!
   2e2b0:	stp	x28, x27, [sp, #16]
   2e2b4:	stp	x26, x25, [sp, #32]
   2e2b8:	stp	x24, x23, [sp, #48]
   2e2bc:	stp	x22, x21, [sp, #64]
   2e2c0:	stp	x20, x19, [sp, #80]
   2e2c4:	mov	x29, sp
   2e2c8:	sub	sp, sp, #0x240
   2e2cc:	mov	x19, sp
   2e2d0:	mov	x22, x0
   2e2d4:	add	x0, x19, #0x18
   2e2d8:	str	w5, [x19, #12]
   2e2dc:	mov	x20, x4
   2e2e0:	mov	x23, x3
   2e2e4:	mov	x25, x2
   2e2e8:	mov	x21, x1
   2e2ec:	str	xzr, [x19, #16]
   2e2f0:	bl	d1c0 <__gmp_init_primesieve@plt>
   2e2f4:	mov	w8, #0x38                  	// #56
   2e2f8:	mul	x1, x21, x8
   2e2fc:	mov	w8, #0x7f00                	// #32512
   2e300:	cmp	x1, x8
   2e304:	add	x26, x20, #0x3
   2e308:	b.hi	2e464 <__gmpn_perfect_power_p@@Base+0x4ec>  // b.pmore
   2e30c:	add	x9, x1, #0xf
   2e310:	mov	x8, sp
   2e314:	and	x9, x9, #0xfffffffffffffff0
   2e318:	sub	x24, x8, x9
   2e31c:	mov	sp, x24
   2e320:	str	x26, [x19]
   2e324:	lsr	x28, x26, #1
   2e328:	add	x26, x24, x21, lsl #3
   2e32c:	add	x27, x26, x21, lsl #3
   2e330:	cbz	x21, 2e344 <__gmpn_perfect_power_p@@Base+0x3cc>
   2e334:	lsl	x2, x21, #3
   2e338:	mov	x0, x26
   2e33c:	mov	w1, wzr
   2e340:	bl	c610 <memset@plt>
   2e344:	sub	x8, x28, #0x1
   2e348:	lsr	x28, x8, #6
   2e34c:	add	x2, x28, #0x1
   2e350:	mov	x0, x24
   2e354:	mov	x1, x22
   2e358:	mov	x3, x27
   2e35c:	bl	cd40 <__gmpn_binvert@plt>
   2e360:	ldr	x8, [x19]
   2e364:	ubfx	x8, x8, #1, #6
   2e368:	cbz	x8, 2e380 <__gmpn_perfect_power_p@@Base+0x408>
   2e36c:	ldr	x9, [x24, x28, lsl #3]
   2e370:	mov	x10, #0xffffffffffffffff    	// #-1
   2e374:	lsl	x8, x10, x8
   2e378:	bic	x8, x9, x8
   2e37c:	str	x8, [x24, x28, lsl #3]
   2e380:	ldr	w8, [x19, #12]
   2e384:	cbz	w8, 2e390 <__gmpn_perfect_power_p@@Base+0x418>
   2e388:	add	x0, x19, #0x18
   2e38c:	bl	cca0 <__gmp_nextprime@plt>
   2e390:	cbz	x23, 2e41c <__gmpn_perfect_power_p@@Base+0x4a4>
   2e394:	add	x8, x23, #0x1
   2e398:	cmp	x8, x25
   2e39c:	add	x0, x19, #0x18
   2e3a0:	csinc	x25, x25, x23, hi  // hi = pmore
   2e3a4:	bl	cca0 <__gmp_nextprime@plt>
   2e3a8:	cmp	x0, x25
   2e3ac:	b.cs	2e42c <__gmpn_perfect_power_p@@Base+0x4b4>  // b.hs, b.nlast
   2e3b0:	mov	x2, x0
   2e3b4:	udiv	x8, x23, x2
   2e3b8:	msub	x8, x8, x2, x23
   2e3bc:	cbnz	x8, 2e3e0 <__gmpn_perfect_power_p@@Base+0x468>
   2e3c0:	mov	x0, x26
   2e3c4:	mov	x1, x22
   2e3c8:	mov	x3, x24
   2e3cc:	mov	x4, x21
   2e3d0:	mov	x5, x20
   2e3d4:	mov	x6, x27
   2e3d8:	bl	2e47c <__gmpn_perfect_power_p@@Base+0x504>
   2e3dc:	cbnz	w0, 2e434 <__gmpn_perfect_power_p@@Base+0x4bc>
   2e3e0:	add	x0, x19, #0x18
   2e3e4:	bl	cca0 <__gmp_nextprime@plt>
   2e3e8:	mov	x2, x0
   2e3ec:	cmp	x0, x25
   2e3f0:	b.cc	2e3b4 <__gmpn_perfect_power_p@@Base+0x43c>  // b.lo, b.ul, b.last
   2e3f4:	b	2e42c <__gmpn_perfect_power_p@@Base+0x4b4>
   2e3f8:	mov	x2, x0
   2e3fc:	mov	x0, x26
   2e400:	mov	x1, x22
   2e404:	mov	x3, x24
   2e408:	mov	x4, x21
   2e40c:	mov	x5, x20
   2e410:	mov	x6, x27
   2e414:	bl	2e47c <__gmpn_perfect_power_p@@Base+0x504>
   2e418:	cbnz	w0, 2e434 <__gmpn_perfect_power_p@@Base+0x4bc>
   2e41c:	add	x0, x19, #0x18
   2e420:	bl	cca0 <__gmp_nextprime@plt>
   2e424:	cmp	x0, x25
   2e428:	b.cc	2e3f8 <__gmpn_perfect_power_p@@Base+0x480>  // b.lo, b.ul, b.last
   2e42c:	mov	w20, wzr
   2e430:	b	2e438 <__gmpn_perfect_power_p@@Base+0x4c0>
   2e434:	mov	w20, #0x1                   	// #1
   2e438:	ldr	x0, [x19, #16]
   2e43c:	cbnz	x0, 2e474 <__gmpn_perfect_power_p@@Base+0x4fc>
   2e440:	mov	w0, w20
   2e444:	mov	sp, x29
   2e448:	ldp	x20, x19, [sp, #80]
   2e44c:	ldp	x22, x21, [sp, #64]
   2e450:	ldp	x24, x23, [sp, #48]
   2e454:	ldp	x26, x25, [sp, #32]
   2e458:	ldp	x28, x27, [sp, #16]
   2e45c:	ldp	x29, x30, [sp], #96
   2e460:	ret
   2e464:	add	x0, x19, #0x10
   2e468:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2e46c:	mov	x24, x0
   2e470:	b	2e320 <__gmpn_perfect_power_p@@Base+0x3a8>
   2e474:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2e478:	b	2e440 <__gmpn_perfect_power_p@@Base+0x4c8>
   2e47c:	stp	x29, x30, [sp, #-96]!
   2e480:	stp	x24, x23, [sp, #48]
   2e484:	stp	x22, x21, [sp, #64]
   2e488:	stp	x20, x19, [sp, #80]
   2e48c:	mov	x20, x6
   2e490:	mov	x21, x5
   2e494:	mov	x22, x4
   2e498:	mov	x23, x1
   2e49c:	cmp	x2, #0x2
   2e4a0:	mov	x19, x0
   2e4a4:	str	x27, [sp, #16]
   2e4a8:	stp	x26, x25, [sp, #32]
   2e4ac:	mov	x29, sp
   2e4b0:	b.ne	2e518 <__gmpn_perfect_power_p@@Base+0x5a0>  // b.any
   2e4b4:	add	x8, x21, #0x1
   2e4b8:	lsr	x25, x8, #1
   2e4bc:	lsr	x26, x8, #7
   2e4c0:	mov	x0, x19
   2e4c4:	mov	x1, x3
   2e4c8:	mov	x2, x25
   2e4cc:	mov	x3, x20
   2e4d0:	add	x24, x26, #0x1
   2e4d4:	bl	c770 <__gmpn_bsqrtinv@plt>
   2e4d8:	cbz	w0, 2e5a8 <__gmpn_perfect_power_p@@Base+0x630>
   2e4dc:	ldr	x8, [x19, x26, lsl #3]
   2e4e0:	mov	x9, #0xffffffffffffffff    	// #-1
   2e4e4:	lsl	x9, x9, x25
   2e4e8:	mvn	x25, x9
   2e4ec:	bic	x8, x8, x9
   2e4f0:	str	x8, [x19, x26, lsl #3]
   2e4f4:	mov	x8, x26
   2e4f8:	add	x9, x8, #0x1
   2e4fc:	cmp	x9, #0x1
   2e500:	b.lt	2e5c0 <__gmpn_perfect_power_p@@Base+0x648>  // b.tstop
   2e504:	ldr	x9, [x19, x8, lsl #3]
   2e508:	sub	x8, x8, #0x1
   2e50c:	cbz	x9, 2e4f8 <__gmpn_perfect_power_p@@Base+0x580>
   2e510:	add	x3, x8, #0x2
   2e514:	b	2e5c4 <__gmpn_perfect_power_p@@Base+0x64c>
   2e518:	sub	x8, x21, #0x1
   2e51c:	udiv	x8, x8, x2
   2e520:	lsr	x24, x8, #6
   2e524:	mov	x25, x2
   2e528:	add	x26, x24, #0x1
   2e52c:	mov	x0, x19
   2e530:	mov	x1, x3
   2e534:	mov	x2, x26
   2e538:	mov	x3, x25
   2e53c:	mov	x4, x20
   2e540:	add	w27, w8, #0x1
   2e544:	bl	c6d0 <__gmpn_brootinv@plt>
   2e548:	ands	x8, x27, #0x3f
   2e54c:	b.eq	2e564 <__gmpn_perfect_power_p@@Base+0x5ec>  // b.none
   2e550:	ldr	x9, [x19, x24, lsl #3]
   2e554:	mov	x10, #0xffffffffffffffff    	// #-1
   2e558:	lsl	x8, x10, x8
   2e55c:	bic	x8, x9, x8
   2e560:	str	x8, [x19, x24, lsl #3]
   2e564:	mov	x24, x26
   2e568:	subs	x26, x26, #0x1
   2e56c:	b.lt	2e57c <__gmpn_perfect_power_p@@Base+0x604>  // b.tstop
   2e570:	ldr	x8, [x19, x26, lsl #3]
   2e574:	cbz	x8, 2e564 <__gmpn_perfect_power_p@@Base+0x5ec>
   2e578:	b	2e580 <__gmpn_perfect_power_p@@Base+0x608>
   2e57c:	mov	x24, xzr
   2e580:	mov	x0, x23
   2e584:	mov	x1, x22
   2e588:	mov	x2, x19
   2e58c:	mov	x3, x24
   2e590:	mov	x4, x25
   2e594:	mov	x5, x21
   2e598:	mov	x6, x20
   2e59c:	bl	2e690 <__gmpn_perfect_power_p@@Base+0x718>
   2e5a0:	cbnz	w0, 2e5e4 <__gmpn_perfect_power_p@@Base+0x66c>
   2e5a4:	cbz	x24, 2e5b8 <__gmpn_perfect_power_p@@Base+0x640>
   2e5a8:	lsl	x2, x24, #3
   2e5ac:	mov	x0, x19
   2e5b0:	mov	w1, wzr
   2e5b4:	bl	c610 <memset@plt>
   2e5b8:	mov	w0, wzr
   2e5bc:	b	2e5e8 <__gmpn_perfect_power_p@@Base+0x670>
   2e5c0:	mov	x3, xzr
   2e5c4:	mov	w4, #0x2                   	// #2
   2e5c8:	mov	x0, x23
   2e5cc:	mov	x1, x22
   2e5d0:	mov	x2, x19
   2e5d4:	mov	x5, x21
   2e5d8:	mov	x6, x20
   2e5dc:	bl	2e690 <__gmpn_perfect_power_p@@Base+0x718>
   2e5e0:	cbz	w0, 2e604 <__gmpn_perfect_power_p@@Base+0x68c>
   2e5e4:	mov	w0, #0x1                   	// #1
   2e5e8:	ldp	x20, x19, [sp, #80]
   2e5ec:	ldp	x22, x21, [sp, #64]
   2e5f0:	ldp	x24, x23, [sp, #48]
   2e5f4:	ldp	x26, x25, [sp, #32]
   2e5f8:	ldr	x27, [sp, #16]
   2e5fc:	ldp	x29, x30, [sp], #96
   2e600:	ret
   2e604:	ldr	x9, [x19]
   2e608:	cbz	x9, 2e614 <__gmpn_perfect_power_p@@Base+0x69c>
   2e60c:	mov	x8, x19
   2e610:	b	2e62c <__gmpn_perfect_power_p@@Base+0x6b4>
   2e614:	mov	x8, x19
   2e618:	subs	x24, x24, #0x1
   2e61c:	str	xzr, [x8]
   2e620:	b.eq	2e648 <__gmpn_perfect_power_p@@Base+0x6d0>  // b.none
   2e624:	ldr	x9, [x8, #8]!
   2e628:	cbz	x9, 2e618 <__gmpn_perfect_power_p@@Base+0x6a0>
   2e62c:	neg	x9, x9
   2e630:	subs	x2, x24, #0x1
   2e634:	str	x9, [x8]
   2e638:	b.eq	2e648 <__gmpn_perfect_power_p@@Base+0x6d0>  // b.none
   2e63c:	add	x0, x8, #0x8
   2e640:	mov	x1, x0
   2e644:	bl	c2a0 <__gmpn_com@plt>
   2e648:	ldr	x8, [x19, x26, lsl #3]
   2e64c:	and	x8, x8, x25
   2e650:	str	x8, [x19, x26, lsl #3]
   2e654:	add	x8, x26, #0x1
   2e658:	cmp	x8, #0x1
   2e65c:	b.lt	2e674 <__gmpn_perfect_power_p@@Base+0x6fc>  // b.tstop
   2e660:	ldr	x8, [x19, x26, lsl #3]
   2e664:	sub	x26, x26, #0x1
   2e668:	cbz	x8, 2e654 <__gmpn_perfect_power_p@@Base+0x6dc>
   2e66c:	add	x24, x26, #0x2
   2e670:	b	2e678 <__gmpn_perfect_power_p@@Base+0x700>
   2e674:	mov	x24, xzr
   2e678:	mov	w4, #0x2                   	// #2
   2e67c:	mov	x0, x23
   2e680:	mov	x1, x22
   2e684:	mov	x2, x19
   2e688:	mov	x3, x24
   2e68c:	b	2e594 <__gmpn_perfect_power_p@@Base+0x61c>
   2e690:	stp	x29, x30, [sp, #-96]!
   2e694:	stp	x28, x27, [sp, #16]
   2e698:	stp	x26, x25, [sp, #32]
   2e69c:	stp	x24, x23, [sp, #48]
   2e6a0:	stp	x22, x21, [sp, #64]
   2e6a4:	stp	x20, x19, [sp, #80]
   2e6a8:	mov	x29, sp
   2e6ac:	sub	sp, sp, #0x10
   2e6b0:	mov	x20, x6
   2e6b4:	mov	x24, x5
   2e6b8:	mov	x22, x3
   2e6bc:	mov	x23, x2
   2e6c0:	mov	x19, x1
   2e6c4:	mov	x21, x0
   2e6c8:	cmp	x3, #0x1
   2e6cc:	stur	x4, [x29, #-8]
   2e6d0:	b.ne	2e6e8 <__gmpn_perfect_power_p@@Base+0x770>  // b.any
   2e6d4:	ldr	x8, [x23]
   2e6d8:	cmp	x8, #0x1
   2e6dc:	b.ne	2e6e8 <__gmpn_perfect_power_p@@Base+0x770>  // b.any
   2e6e0:	mov	w24, wzr
   2e6e4:	b	2e820 <__gmpn_perfect_power_p@@Base+0x8a8>
   2e6e8:	asr	x8, x19, #1
   2e6ec:	add	x26, x8, #0x1
   2e6f0:	cmp	x26, #0x2
   2e6f4:	b.cc	2e754 <__gmpn_perfect_power_p@@Base+0x7dc>  // b.lo, b.ul, b.last
   2e6f8:	sub	x27, x21, #0x8
   2e6fc:	sub	x28, x20, #0x8
   2e700:	mov	w25, #0x1                   	// #1
   2e704:	add	x5, x20, x25, lsl #3
   2e708:	sub	x2, x29, #0x8
   2e70c:	mov	w3, #0x1                   	// #1
   2e710:	mov	x0, x20
   2e714:	mov	x1, x23
   2e718:	mov	x4, x25
   2e71c:	bl	c3e0 <__gmpn_powlo@plt>
   2e720:	mov	x8, x25
   2e724:	subs	x9, x8, #0x1
   2e728:	b.lt	2e744 <__gmpn_perfect_power_p@@Base+0x7cc>  // b.tstop
   2e72c:	ldr	x10, [x28, x8, lsl #3]
   2e730:	ldr	x8, [x27, x8, lsl #3]
   2e734:	cmp	x10, x8
   2e738:	mov	x8, x9
   2e73c:	b.eq	2e724 <__gmpn_perfect_power_p@@Base+0x7ac>  // b.none
   2e740:	b	2e6e0 <__gmpn_perfect_power_p@@Base+0x768>
   2e744:	lsl	x25, x25, #1
   2e748:	cmp	x25, x26
   2e74c:	b.cc	2e704 <__gmpn_perfect_power_p@@Base+0x78c>  // b.lo, b.ul, b.last
   2e750:	ldur	x4, [x29, #-8]
   2e754:	add	x8, x23, x22, lsl #3
   2e758:	ldur	x8, [x8, #-8]
   2e75c:	sub	x11, x24, #0x1
   2e760:	mov	w24, wzr
   2e764:	clz	x8, x8
   2e768:	mvn	x8, x8
   2e76c:	add	x10, x8, x22, lsl #6
   2e770:	mul	x8, x10, x4
   2e774:	cmp	x8, #0x0
   2e778:	sub	x8, x8, #0x1
   2e77c:	cset	w9, eq  // eq = none
   2e780:	cmp	x8, x11
   2e784:	b.hi	2e820 <__gmpn_perfect_power_p@@Base+0x8a8>  // b.pmore
   2e788:	umulh	x10, x4, x10
   2e78c:	cmp	x10, x9
   2e790:	b.ne	2e820 <__gmpn_perfect_power_p@@Base+0x8a8>  // b.any
   2e794:	adds	x8, x8, x4
   2e798:	b.cs	2e860 <__gmpn_perfect_power_p@@Base+0x8e8>  // b.hs, b.nlast
   2e79c:	lsr	x8, x8, #6
   2e7a0:	lsl	x9, x8, #3
   2e7a4:	cmp	x8, #0xfde
   2e7a8:	add	x1, x9, #0x10
   2e7ac:	stur	xzr, [x29, #-16]
   2e7b0:	b.hi	2e844 <__gmpn_perfect_power_p@@Base+0x8cc>  // b.pmore
   2e7b4:	add	x9, x1, #0xf
   2e7b8:	mov	x8, sp
   2e7bc:	and	x9, x9, #0x7ffffffffffffff0
   2e7c0:	sub	x8, x8, x9
   2e7c4:	mov	sp, x8
   2e7c8:	mov	x0, x20
   2e7cc:	mov	x1, x23
   2e7d0:	mov	x2, x22
   2e7d4:	mov	x3, x4
   2e7d8:	mov	x4, x8
   2e7dc:	bl	d230 <__gmpn_pow_1@plt>
   2e7e0:	cmp	x0, x19
   2e7e4:	b.ne	2e80c <__gmpn_perfect_power_p@@Base+0x894>  // b.any
   2e7e8:	sub	x8, x21, #0x8
   2e7ec:	sub	x9, x20, #0x8
   2e7f0:	subs	x10, x19, #0x1
   2e7f4:	b.lt	2e814 <__gmpn_perfect_power_p@@Base+0x89c>  // b.tstop
   2e7f8:	ldr	x11, [x9, x19, lsl #3]
   2e7fc:	ldr	x12, [x8, x19, lsl #3]
   2e800:	mov	x19, x10
   2e804:	cmp	x11, x12
   2e808:	b.eq	2e7f0 <__gmpn_perfect_power_p@@Base+0x878>  // b.none
   2e80c:	mov	w24, wzr
   2e810:	b	2e818 <__gmpn_perfect_power_p@@Base+0x8a0>
   2e814:	mov	w24, #0x1                   	// #1
   2e818:	ldur	x0, [x29, #-16]
   2e81c:	cbnz	x0, 2e858 <__gmpn_perfect_power_p@@Base+0x8e0>
   2e820:	mov	w0, w24
   2e824:	mov	sp, x29
   2e828:	ldp	x20, x19, [sp, #80]
   2e82c:	ldp	x22, x21, [sp, #64]
   2e830:	ldp	x24, x23, [sp, #48]
   2e834:	ldp	x26, x25, [sp, #32]
   2e838:	ldp	x28, x27, [sp, #16]
   2e83c:	ldp	x29, x30, [sp], #96
   2e840:	ret
   2e844:	sub	x0, x29, #0x10
   2e848:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2e84c:	ldur	x4, [x29, #-8]
   2e850:	mov	x8, x0
   2e854:	b	2e7c8 <__gmpn_perfect_power_p@@Base+0x850>
   2e858:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2e85c:	b	2e820 <__gmpn_perfect_power_p@@Base+0x8a8>
   2e860:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   2e864:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   2e868:	add	x0, x0, #0x718
   2e86c:	add	x2, x2, #0x722
   2e870:	mov	w1, #0x60                  	// #96
   2e874:	bl	c6e0 <__gmp_assert_fail@plt>

000000000002e878 <__gmpn_strongfibo@@Base>:
   2e878:	stp	x29, x30, [sp, #-96]!
   2e87c:	stp	x28, x27, [sp, #16]
   2e880:	stp	x26, x25, [sp, #32]
   2e884:	stp	x24, x23, [sp, #48]
   2e888:	stp	x22, x21, [sp, #64]
   2e88c:	stp	x20, x19, [sp, #80]
   2e890:	mov	x29, sp
   2e894:	sub	sp, sp, #0x10
   2e898:	mov	x19, x1
   2e89c:	mov	x1, xzr
   2e8a0:	mov	x25, x2
   2e8a4:	mov	x20, x0
   2e8a8:	bl	c6b0 <__gmpn_scan0@plt>
   2e8ac:	mov	x21, x0
   2e8b0:	lsr	x8, x0, #6
   2e8b4:	sub	x22, x19, x0, lsr #6
   2e8b8:	and	w3, w21, #0x3f
   2e8bc:	add	x1, x20, x8, lsl #3
   2e8c0:	mov	x0, x25
   2e8c4:	mov	x2, x22
   2e8c8:	cbz	w3, 2ebcc <__gmpn_strongfibo@@Base+0x354>
   2e8cc:	bl	c1b0 <__gmpn_rshift@plt>
   2e8d0:	ldr	x8, [x25]
   2e8d4:	add	x9, x25, x22, lsl #3
   2e8d8:	mov	w10, #0x7f00                	// #32512
   2e8dc:	orr	x8, x8, #0x1
   2e8e0:	str	x8, [x25]
   2e8e4:	ldur	x8, [x9, #-8]
   2e8e8:	lsl	x9, x19, #5
   2e8ec:	add	x1, x9, #0x30
   2e8f0:	stur	xzr, [x29, #-8]
   2e8f4:	cmp	x8, #0x0
   2e8f8:	cset	w8, eq  // eq = none
   2e8fc:	cmp	x1, x10
   2e900:	sub	x26, x22, x8
   2e904:	b.hi	2ebd4 <__gmpn_strongfibo@@Base+0x35c>  // b.pmore
   2e908:	add	x9, x1, #0xf
   2e90c:	mov	x8, sp
   2e910:	and	x9, x9, #0xfffffffffffffff0
   2e914:	sub	x22, x8, x9
   2e918:	mov	sp, x22
   2e91c:	add	x8, x22, x19, lsl #4
   2e920:	add	x24, x8, #0x18
   2e924:	mov	x0, x24
   2e928:	mov	x1, x22
   2e92c:	mov	x2, x25
   2e930:	mov	x3, x26
   2e934:	mov	x4, x20
   2e938:	mov	x5, x19
   2e93c:	lsl	x23, x19, #1
   2e940:	bl	d070 <__gmpn_fib2m@plt>
   2e944:	mov	w9, #0x18                  	// #24
   2e948:	madd	x9, x19, x9, x22
   2e94c:	mov	x8, xzr
   2e950:	add	x9, x9, #0x10
   2e954:	ldr	x10, [x9, x8, lsl #3]
   2e958:	cbnz	x10, 2e96c <__gmpn_strongfibo@@Base+0xf4>
   2e95c:	sub	x8, x8, #0x1
   2e960:	cmn	x19, x8
   2e964:	b.ne	2e954 <__gmpn_strongfibo@@Base+0xdc>  // b.any
   2e968:	b	2eb9c <__gmpn_strongfibo@@Base+0x324>
   2e96c:	cbz	w0, 2e9ac <__gmpn_strongfibo@@Base+0x134>
   2e970:	mov	x0, x24
   2e974:	mov	x1, x24
   2e978:	mov	x2, x22
   2e97c:	mov	x3, x19
   2e980:	bl	d0b0 <__gmpn_rsblsh1_n@plt>
   2e984:	mov	x25, x0
   2e988:	cmp	x0, #0x2
   2e98c:	b.cc	2e9c4 <__gmpn_strongfibo@@Base+0x14c>  // b.lo, b.ul, b.last
   2e990:	mov	x0, x24
   2e994:	mov	x1, x24
   2e998:	mov	x2, x20
   2e99c:	mov	x3, x19
   2e9a0:	bl	ca90 <__gmpn_add_n@plt>
   2e9a4:	add	x25, x0, x25
   2e9a8:	b	2e9c4 <__gmpn_strongfibo@@Base+0x14c>
   2e9ac:	mov	x0, x24
   2e9b0:	mov	x1, x24
   2e9b4:	mov	x2, x22
   2e9b8:	mov	x3, x19
   2e9bc:	bl	cc60 <__gmpn_addlsh1_n@plt>
   2e9c0:	mov	x25, x0
   2e9c4:	mov	w8, #0x18                  	// #24
   2e9c8:	madd	x8, x19, x8, x22
   2e9cc:	add	x26, x8, #0x10
   2e9d0:	cbnz	x25, 2ea00 <__gmpn_strongfibo@@Base+0x188>
   2e9d4:	mov	x8, x26
   2e9d8:	mov	x9, x19
   2e9dc:	subs	x10, x9, #0x1
   2e9e0:	b.lt	2ea00 <__gmpn_strongfibo@@Base+0x188>  // b.tstop
   2e9e4:	add	x9, x20, x9, lsl #3
   2e9e8:	ldr	x11, [x8], #-8
   2e9ec:	ldur	x9, [x9, #-8]
   2e9f0:	cmp	x11, x9
   2e9f4:	mov	x9, x10
   2e9f8:	b.eq	2e9dc <__gmpn_strongfibo@@Base+0x164>  // b.none
   2e9fc:	b.ls	2ea20 <__gmpn_strongfibo@@Base+0x1a8>  // b.plast
   2ea00:	mov	x0, x24
   2ea04:	mov	x1, x24
   2ea08:	mov	x2, x20
   2ea0c:	mov	x3, x19
   2ea10:	bl	c2e0 <__gmpn_sub_n@plt>
   2ea14:	sub	x25, x25, x0
   2ea18:	cbnz	x25, 2ea00 <__gmpn_strongfibo@@Base+0x188>
   2ea1c:	b	2e9d4 <__gmpn_strongfibo@@Base+0x15c>
   2ea20:	mov	w8, #0x18                  	// #24
   2ea24:	madd	x8, x19, x8, x22
   2ea28:	mov	x10, xzr
   2ea2c:	neg	x11, x19, lsl #3
   2ea30:	add	x9, x8, #0x10
   2ea34:	mov	x12, x23
   2ea38:	mov	x8, x10
   2ea3c:	add	x10, x19, x10
   2ea40:	cmp	x10, #0x1
   2ea44:	mov	x25, x12
   2ea48:	mov	x26, x11
   2ea4c:	b.lt	2ea68 <__gmpn_strongfibo@@Base+0x1f0>  // b.tstop
   2ea50:	ldr	x13, [x9, x8, lsl #3]
   2ea54:	sub	x12, x25, #0x2
   2ea58:	sub	x10, x8, #0x1
   2ea5c:	add	x11, x26, #0x10
   2ea60:	cbz	x13, 2ea38 <__gmpn_strongfibo@@Base+0x1c0>
   2ea64:	b	2ea70 <__gmpn_strongfibo@@Base+0x1f8>
   2ea68:	cmn	x19, x8
   2ea6c:	b.eq	2eb9c <__gmpn_strongfibo@@Base+0x324>  // b.none
   2ea70:	cmp	x21, #0x1
   2ea74:	b.eq	2ebec <__gmpn_strongfibo@@Base+0x374>  // b.none
   2ea78:	add	x2, x19, x8
   2ea7c:	mov	x0, x22
   2ea80:	mov	x1, x24
   2ea84:	bl	c900 <__gmpn_sqr@plt>
   2ea88:	ldr	x8, [x22]
   2ea8c:	cmp	x25, x19
   2ea90:	orr	x8, x8, #0x2
   2ea94:	str	x8, [x22]
   2ea98:	b.lt	2ebf4 <__gmpn_strongfibo@@Base+0x37c>  // b.tstop
   2ea9c:	mov	x0, x24
   2eaa0:	mov	x1, x22
   2eaa4:	mov	x2, xzr
   2eaa8:	mov	x3, x22
   2eaac:	mov	x4, x25
   2eab0:	mov	x5, x20
   2eab4:	mov	x6, x19
   2eab8:	bl	bf10 <__gmpn_tdiv_qr@plt>
   2eabc:	sub	x8, x22, #0x8
   2eac0:	mov	x9, x19
   2eac4:	ldr	x10, [x8, x9, lsl #3]
   2eac8:	cbnz	x10, 2eadc <__gmpn_strongfibo@@Base+0x264>
   2eacc:	sub	x9, x9, #0x1
   2ead0:	cbnz	x9, 2eac4 <__gmpn_strongfibo@@Base+0x24c>
   2ead4:	mov	w21, #0x1                   	// #1
   2ead8:	b	2eb9c <__gmpn_strongfibo@@Base+0x324>
   2eadc:	subs	x26, x21, #0x2
   2eae0:	b.eq	2ebec <__gmpn_strongfibo@@Base+0x374>  // b.none
   2eae4:	add	x8, x22, x19, lsl #3
   2eae8:	add	x24, x8, #0x8
   2eaec:	sub	x27, x19, #0x1
   2eaf0:	add	x25, x24, x23, lsl #3
   2eaf4:	add	x28, x22, #0x8
   2eaf8:	mov	x0, x24
   2eafc:	mov	x1, x22
   2eb00:	mov	x2, x19
   2eb04:	bl	c900 <__gmpn_sqr@plt>
   2eb08:	mov	x0, x25
   2eb0c:	mov	x1, x22
   2eb10:	mov	x2, xzr
   2eb14:	mov	x3, x24
   2eb18:	mov	x4, x23
   2eb1c:	mov	x5, x20
   2eb20:	mov	x6, x19
   2eb24:	bl	bf10 <__gmpn_tdiv_qr@plt>
   2eb28:	ldr	x8, [x22]
   2eb2c:	cmp	x8, #0x4
   2eb30:	b.hi	2eb54 <__gmpn_strongfibo@@Base+0x2dc>  // b.pmore
   2eb34:	cmp	x19, #0x1
   2eb38:	b.eq	2eb94 <__gmpn_strongfibo@@Base+0x31c>  // b.none
   2eb3c:	mov	x9, x27
   2eb40:	ldr	x10, [x22, x9, lsl #3]
   2eb44:	cbnz	x10, 2eb6c <__gmpn_strongfibo@@Base+0x2f4>
   2eb48:	sub	x9, x9, #0x1
   2eb4c:	cbnz	x9, 2eb40 <__gmpn_strongfibo@@Base+0x2c8>
   2eb50:	b	2eb94 <__gmpn_strongfibo@@Base+0x31c>
   2eb54:	sub	x8, x8, #0x2
   2eb58:	str	x8, [x22]
   2eb5c:	subs	x26, x26, #0x1
   2eb60:	mov	x21, xzr
   2eb64:	b.ne	2eaf8 <__gmpn_strongfibo@@Base+0x280>  // b.any
   2eb68:	b	2eb9c <__gmpn_strongfibo@@Base+0x324>
   2eb6c:	sub	x9, x8, #0x2
   2eb70:	cmp	x8, #0x1
   2eb74:	str	x9, [x22]
   2eb78:	b.hi	2eb5c <__gmpn_strongfibo@@Base+0x2e4>  // b.pmore
   2eb7c:	mov	x8, x28
   2eb80:	ldr	x9, [x8]
   2eb84:	sub	x10, x9, #0x1
   2eb88:	str	x10, [x8], #8
   2eb8c:	cbz	x9, 2eb80 <__gmpn_strongfibo@@Base+0x308>
   2eb90:	b	2eb5c <__gmpn_strongfibo@@Base+0x2e4>
   2eb94:	cmp	x8, #0x2
   2eb98:	csel	x21, x26, xzr, eq  // eq = none
   2eb9c:	ldur	x0, [x29, #-8]
   2eba0:	cbnz	x0, 2ebe4 <__gmpn_strongfibo@@Base+0x36c>
   2eba4:	cmp	x21, #0x0
   2eba8:	cset	w0, ne  // ne = any
   2ebac:	mov	sp, x29
   2ebb0:	ldp	x20, x19, [sp, #80]
   2ebb4:	ldp	x22, x21, [sp, #64]
   2ebb8:	ldp	x24, x23, [sp, #48]
   2ebbc:	ldp	x26, x25, [sp, #32]
   2ebc0:	ldp	x28, x27, [sp, #16]
   2ebc4:	ldp	x29, x30, [sp], #96
   2ebc8:	ret
   2ebcc:	bl	ca70 <__gmpn_copyi@plt>
   2ebd0:	b	2e8d0 <__gmpn_strongfibo@@Base+0x58>
   2ebd4:	sub	x0, x29, #0x8
   2ebd8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2ebdc:	mov	x22, x0
   2ebe0:	b	2e91c <__gmpn_strongfibo@@Base+0xa4>
   2ebe4:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2ebe8:	b	2eba4 <__gmpn_strongfibo@@Base+0x32c>
   2ebec:	mov	x21, xzr
   2ebf0:	b	2eb9c <__gmpn_strongfibo@@Base+0x324>
   2ebf4:	add	x0, x22, x25, lsl #3
   2ebf8:	mov	w1, wzr
   2ebfc:	mov	x2, x26
   2ec00:	bl	c610 <memset@plt>
   2ec04:	b	2eabc <__gmpn_strongfibo@@Base+0x244>
   2ec08:	nop
   2ec0c:	nop

000000000002ec10 <__gmpn_gcd_11@@Base>:
   2ec10:	subs	x3, x0, x1
   2ec14:	b.eq	2ec3c <__gmpn_gcd_11@@Base+0x2c>  // b.none
   2ec18:	nop
   2ec1c:	nop
   2ec20:	rbit	x12, x3
   2ec24:	clz	x12, x12
   2ec28:	cneg	x3, x3, cc  // cc = lo, ul, last
   2ec2c:	csel	x0, x1, x0, cs  // cs = hs, nlast
   2ec30:	lsr	x1, x3, x12
   2ec34:	subs	x3, x0, x1
   2ec38:	b.ne	2ec20 <__gmpn_gcd_11@@Base+0x10>  // b.any
   2ec3c:	ret

000000000002ec40 <__gmpn_gcd_22@@Base>:
   2ec40:	subs	x5, x1, x3
   2ec44:	cbz	x5, 2ecb8 <__gmpn_gcd_22@@Base+0x78>
   2ec48:	sbcs	x6, x0, x2
   2ec4c:	rbit	x7, x5
   2ec50:	cneg	x5, x5, cc  // cc = lo, ul, last
   2ec54:	cinv	x6, x6, cc  // cc = lo, ul, last
   2ec58:	csel	x3, x3, x1, cs  // cs = hs, nlast
   2ec5c:	csel	x2, x2, x0, cs  // cs = hs, nlast
   2ec60:	clz	x7, x7
   2ec64:	neg	x8, x7
   2ec68:	lsr	x1, x5, x7
   2ec6c:	lsl	x14, x6, x8
   2ec70:	lsr	x0, x6, x7
   2ec74:	orr	x1, x1, x14
   2ec78:	orr	x11, x0, x2
   2ec7c:	cbnz	x11, 2ec40 <__gmpn_gcd_22@@Base>
   2ec80:	subs	x4, x1, x3
   2ec84:	b.eq	2ecac <__gmpn_gcd_22@@Base+0x6c>  // b.none
   2ec88:	nop
   2ec8c:	nop
   2ec90:	rbit	x12, x4
   2ec94:	clz	x12, x12
   2ec98:	cneg	x4, x4, cc  // cc = lo, ul, last
   2ec9c:	csel	x1, x3, x1, cs  // cs = hs, nlast
   2eca0:	lsr	x3, x4, x12
   2eca4:	subs	x4, x1, x3
   2eca8:	b.ne	2ec90 <__gmpn_gcd_22@@Base+0x50>  // b.any
   2ecac:	mov	x0, x1
   2ecb0:	mov	x1, #0x0                   	// #0
   2ecb4:	ret
   2ecb8:	subs	x5, x0, x2
   2ecbc:	b.eq	2ecd0 <__gmpn_gcd_22@@Base+0x90>  // b.none
   2ecc0:	mov	x6, #0x0                   	// #0
   2ecc4:	rbit	x7, x5
   2ecc8:	cneg	x5, x5, cc  // cc = lo, ul, last
   2eccc:	b	2ec58 <__gmpn_gcd_22@@Base+0x18>
   2ecd0:	mov	x0, x3
   2ecd4:	mov	x1, x2
   2ecd8:	ret

000000000002ecdc <__gmpn_gcd_1@@Base>:
   2ecdc:	stp	x29, x30, [sp, #-32]!
   2ece0:	stp	x20, x19, [sp, #16]
   2ece4:	ldr	x9, [x0]
   2ece8:	rbit	x8, x2
   2ecec:	clz	x8, x8
   2ecf0:	cmp	x1, #0x2
   2ecf4:	rbit	x10, x9
   2ecf8:	lsr	x19, x2, x8
   2ecfc:	clz	x10, x10
   2ed00:	mov	x29, sp
   2ed04:	b.lt	2ed2c <__gmpn_gcd_1@@Base+0x50>  // b.tstop
   2ed08:	cmp	x8, x10
   2ed0c:	ccmp	x9, #0x0, #0x4, cs  // cs = hs, nlast
   2ed10:	csel	x20, x8, x10, eq  // eq = none
   2ed14:	mov	x2, x19
   2ed18:	cmp	x1, #0x27
   2ed1c:	b.le	2ed68 <__gmpn_gcd_1@@Base+0x8c>
   2ed20:	bl	c400 <__gmpn_mod_1@plt>
   2ed24:	cbnz	x0, 2ed74 <__gmpn_gcd_1@@Base+0x98>
   2ed28:	b	2ed8c <__gmpn_gcd_1@@Base+0xb0>
   2ed2c:	lsr	x9, x9, x10
   2ed30:	cmp	x8, x10
   2ed34:	csel	x20, x8, x10, cc  // cc = lo, ul, last
   2ed38:	cmp	x19, x9
   2ed3c:	csel	x0, x19, x9, hi  // hi = pmore
   2ed40:	csel	x19, x9, x19, hi  // hi = pmore
   2ed44:	cmp	x19, x0, lsr #16
   2ed48:	b.cs	2ed80 <__gmpn_gcd_1@@Base+0xa4>  // b.hs, b.nlast
   2ed4c:	udiv	x8, x0, x19
   2ed50:	msub	x8, x8, x19, x0
   2ed54:	cbz	x8, 2ed8c <__gmpn_gcd_1@@Base+0xb0>
   2ed58:	rbit	x9, x8
   2ed5c:	clz	x9, x9
   2ed60:	lsr	x0, x8, x9
   2ed64:	b	2ed80 <__gmpn_gcd_1@@Base+0xa4>
   2ed68:	mov	x3, xzr
   2ed6c:	bl	c800 <__gmpn_modexact_1c_odd@plt>
   2ed70:	cbz	x0, 2ed8c <__gmpn_gcd_1@@Base+0xb0>
   2ed74:	rbit	x8, x0
   2ed78:	clz	x8, x8
   2ed7c:	lsr	x0, x0, x8
   2ed80:	mov	x1, x19
   2ed84:	bl	d360 <__gmpn_gcd_11@plt>
   2ed88:	mov	x19, x0
   2ed8c:	lsl	x0, x19, x20
   2ed90:	ldp	x20, x19, [sp, #16]
   2ed94:	ldp	x29, x30, [sp], #32
   2ed98:	ret

000000000002ed9c <__gmpn_gcd@@Base>:
   2ed9c:	stp	x29, x30, [sp, #-96]!
   2eda0:	stp	x28, x27, [sp, #16]
   2eda4:	stp	x26, x25, [sp, #32]
   2eda8:	stp	x24, x23, [sp, #48]
   2edac:	stp	x22, x21, [sp, #64]
   2edb0:	stp	x20, x19, [sp, #80]
   2edb4:	mov	x29, sp
   2edb8:	sub	sp, sp, #0x50
   2edbc:	sub	x8, x2, x4
   2edc0:	cmp	x8, x4
   2edc4:	mov	x22, x4
   2edc8:	mov	x20, x3
   2edcc:	mov	x24, x2
   2edd0:	mov	x21, x1
   2edd4:	csinc	x23, x4, x8, lt  // lt = tstop
   2edd8:	cmp	x4, #0x14a
   2eddc:	mov	x19, x0
   2ede0:	b.lt	2ee38 <__gmpn_gcd@@Base+0x9c>  // b.tstop
   2ede4:	mov	x9, #0x5555555555555555    	// #6148914691236517205
   2ede8:	lsl	x8, x22, #1
   2edec:	movk	x9, #0x5556
   2edf0:	smulh	x8, x8, x9
   2edf4:	add	x25, x8, x8, lsr #63
   2edf8:	sub	x0, x22, x25
   2edfc:	add	x8, x0, #0x1
   2ee00:	add	x9, x0, #0x2
   2ee04:	cmp	x8, #0x0
   2ee08:	csinc	x8, x9, x0, lt  // lt = tstop
   2ee0c:	lsl	x8, x8, #1
   2ee10:	and	x26, x8, #0xfffffffffffffffc
   2ee14:	bl	c5b0 <__gmpn_hgcd_itch@plt>
   2ee18:	add	x8, x25, x22
   2ee1c:	sub	x9, x8, #0x1
   2ee20:	cmp	x0, x8
   2ee24:	csel	x8, x9, x0, lt  // lt = tstop
   2ee28:	add	x8, x26, x8
   2ee2c:	add	x8, x8, #0x4
   2ee30:	cmp	x8, x23
   2ee34:	csel	x23, x8, x23, gt
   2ee38:	lsl	x1, x23, #3
   2ee3c:	mov	w8, #0x7f00                	// #32512
   2ee40:	cmp	x1, x8
   2ee44:	stur	xzr, [x29, #-24]
   2ee48:	b.hi	2f134 <__gmpn_gcd@@Base+0x398>  // b.pmore
   2ee4c:	add	x9, x1, #0xf
   2ee50:	mov	x8, sp
   2ee54:	and	x9, x9, #0xfffffffffffffff0
   2ee58:	sub	x23, x8, x9
   2ee5c:	mov	sp, x23
   2ee60:	cmp	x24, x22
   2ee64:	b.le	2eeb8 <__gmpn_gcd@@Base+0x11c>
   2ee68:	mov	x0, x23
   2ee6c:	mov	x1, x21
   2ee70:	mov	x2, xzr
   2ee74:	mov	x3, x21
   2ee78:	mov	x4, x24
   2ee7c:	mov	x5, x20
   2ee80:	mov	x6, x22
   2ee84:	bl	bf10 <__gmpn_tdiv_qr@plt>
   2ee88:	sub	x8, x21, #0x8
   2ee8c:	mov	x9, x22
   2ee90:	ldr	x10, [x8, x9, lsl #3]
   2ee94:	cbnz	x10, 2eeb8 <__gmpn_gcd@@Base+0x11c>
   2ee98:	sub	x9, x9, #0x1
   2ee9c:	cbnz	x9, 2ee90 <__gmpn_gcd@@Base+0xf4>
   2eea0:	mov	x0, x19
   2eea4:	mov	x1, x20
   2eea8:	mov	x2, x22
   2eeac:	bl	ca70 <__gmpn_copyi@plt>
   2eeb0:	stur	x22, [x29, #-8]
   2eeb4:	b	2f108 <__gmpn_gcd@@Base+0x36c>
   2eeb8:	cmp	x22, #0x14a
   2eebc:	stur	x19, [x29, #-16]
   2eec0:	b.lt	2ef88 <__gmpn_gcd@@Base+0x1ec>  // b.tstop
   2eec4:	mov	x28, #0x5555555555555555    	// #6148914691236517205
   2eec8:	adrp	x24, 2f000 <__gmpn_gcd@@Base+0x264>
   2eecc:	movk	x28, #0x5556
   2eed0:	add	x24, x24, #0x14c
   2eed4:	lsl	x8, x22, #1
   2eed8:	smulh	x8, x8, x28
   2eedc:	add	x25, x8, x8, lsr #63
   2eee0:	sub	x27, x22, x25
   2eee4:	add	x8, x27, #0x1
   2eee8:	add	x9, x27, #0x2
   2eeec:	cmp	x8, #0x0
   2eef0:	csinc	x8, x9, x27, lt  // lt = tstop
   2eef4:	lsl	x8, x8, #4
   2eef8:	sub	x0, x29, #0x48
   2eefc:	mov	x1, x27
   2ef00:	mov	x2, x23
   2ef04:	and	x26, x8, #0xffffffffffffffe0
   2ef08:	bl	c850 <__gmpn_hgcd_matrix_init@plt>
   2ef0c:	add	x8, x26, x23
   2ef10:	add	x26, x8, #0x20
   2ef14:	add	x0, x21, x25, lsl #3
   2ef18:	add	x1, x20, x25, lsl #3
   2ef1c:	sub	x3, x29, #0x48
   2ef20:	mov	x2, x27
   2ef24:	mov	x4, x26
   2ef28:	bl	ce00 <__gmpn_hgcd@plt>
   2ef2c:	cmp	x0, #0x1
   2ef30:	b.lt	2ef58 <__gmpn_gcd@@Base+0x1bc>  // b.tstop
   2ef34:	add	x1, x0, x25
   2ef38:	sub	x0, x29, #0x48
   2ef3c:	mov	x2, x21
   2ef40:	mov	x3, x20
   2ef44:	mov	x4, x25
   2ef48:	mov	x5, x26
   2ef4c:	bl	c8c0 <__gmpn_hgcd_matrix_adjust@plt>
   2ef50:	mov	x22, x0
   2ef54:	b	2ef80 <__gmpn_gcd@@Base+0x1e4>
   2ef58:	sub	x5, x29, #0x10
   2ef5c:	mov	x0, x21
   2ef60:	mov	x1, x20
   2ef64:	mov	x2, x22
   2ef68:	mov	x3, xzr
   2ef6c:	mov	x4, x24
   2ef70:	mov	x6, x23
   2ef74:	bl	d2d0 <__gmpn_gcd_subdiv_step@plt>
   2ef78:	mov	x22, x0
   2ef7c:	cbz	x0, 2f108 <__gmpn_gcd@@Base+0x36c>
   2ef80:	cmp	x22, #0x149
   2ef84:	b.gt	2eed4 <__gmpn_gcd@@Base+0x138>
   2ef88:	cmp	x22, #0x3
   2ef8c:	b.lt	2f078 <__gmpn_gcd@@Base+0x2dc>  // b.tstop
   2ef90:	adrp	x24, 2f000 <__gmpn_gcd@@Base+0x264>
   2ef94:	add	x24, x24, #0x14c
   2ef98:	lsl	x8, x22, #3
   2ef9c:	sub	x9, x8, #0x8
   2efa0:	ldr	x0, [x21, x9]
   2efa4:	ldr	x2, [x20, x9]
   2efa8:	orr	x9, x2, x0
   2efac:	tbnz	x9, #63, 2f004 <__gmpn_gcd@@Base+0x268>
   2efb0:	sub	x10, x8, #0x10
   2efb4:	sub	x8, x8, #0x18
   2efb8:	ldr	x12, [x21, x10]
   2efbc:	ldr	x14, [x21, x8]
   2efc0:	ldr	x10, [x20, x10]
   2efc4:	ldr	x8, [x20, x8]
   2efc8:	clz	x9, x9
   2efcc:	neg	x13, x9
   2efd0:	lsl	x11, x0, x9
   2efd4:	lsl	x15, x2, x9
   2efd8:	lsr	x16, x12, x13
   2efdc:	lsl	x12, x12, x9
   2efe0:	lsr	x14, x14, x13
   2efe4:	lsl	x9, x10, x9
   2efe8:	lsr	x10, x10, x13
   2efec:	lsr	x8, x8, x13
   2eff0:	orr	x0, x16, x11
   2eff4:	orr	x1, x14, x12
   2eff8:	orr	x2, x10, x15
   2effc:	orr	x3, x8, x9
   2f000:	b	2f010 <__gmpn_gcd@@Base+0x274>
   2f004:	sub	x8, x8, #0x10
   2f008:	ldr	x1, [x21, x8]
   2f00c:	ldr	x3, [x20, x8]
   2f010:	sub	x4, x29, #0x48
   2f014:	bl	c5c0 <__gmpn_hgcd2@plt>
   2f018:	cbz	w0, 2f048 <__gmpn_gcd@@Base+0x2ac>
   2f01c:	sub	x0, x29, #0x48
   2f020:	mov	x1, x23
   2f024:	mov	x2, x21
   2f028:	mov	x3, x20
   2f02c:	mov	x4, x22
   2f030:	bl	c510 <__gmpn_matrix22_mul1_inverse_vector@plt>
   2f034:	mov	x22, x0
   2f038:	mov	x0, x21
   2f03c:	mov	x21, x23
   2f040:	mov	x23, x0
   2f044:	b	2f070 <__gmpn_gcd@@Base+0x2d4>
   2f048:	sub	x5, x29, #0x10
   2f04c:	mov	x0, x21
   2f050:	mov	x1, x20
   2f054:	mov	x2, x22
   2f058:	mov	x3, xzr
   2f05c:	mov	x4, x24
   2f060:	mov	x6, x23
   2f064:	bl	d2d0 <__gmpn_gcd_subdiv_step@plt>
   2f068:	mov	x22, x0
   2f06c:	cbz	x0, 2f108 <__gmpn_gcd@@Base+0x36c>
   2f070:	cmp	x22, #0x2
   2f074:	b.gt	2ef98 <__gmpn_gcd@@Base+0x1fc>
   2f078:	ldr	x8, [x21]
   2f07c:	tst	x8, #0x1
   2f080:	csel	x11, x21, x20, eq  // eq = none
   2f084:	csel	x9, x20, x21, eq  // eq = none
   2f088:	ldr	x8, [x9]
   2f08c:	ldr	x10, [x11]
   2f090:	cmp	x22, #0x1
   2f094:	b.ne	2f0b8 <__gmpn_gcd@@Base+0x31c>  // b.any
   2f098:	rbit	x9, x10
   2f09c:	clz	x9, x9
   2f0a0:	lsr	x1, x10, x9
   2f0a4:	mov	x0, x8
   2f0a8:	bl	d360 <__gmpn_gcd_11@plt>
   2f0ac:	str	x0, [x19]
   2f0b0:	mov	w8, #0x1                   	// #1
   2f0b4:	b	2f104 <__gmpn_gcd@@Base+0x368>
   2f0b8:	ldr	x11, [x11, #8]
   2f0bc:	cmp	x10, #0x0
   2f0c0:	csel	x3, x11, x10, eq  // eq = none
   2f0c4:	csel	x2, xzr, x11, eq  // eq = none
   2f0c8:	tbnz	w3, #0, 2f0e8 <__gmpn_gcd@@Base+0x34c>
   2f0cc:	rbit	x10, x3
   2f0d0:	clz	x10, x10
   2f0d4:	neg	x11, x10
   2f0d8:	lsr	x12, x3, x10
   2f0dc:	lsl	x11, x2, x11
   2f0e0:	orr	x3, x11, x12
   2f0e4:	lsr	x2, x2, x10
   2f0e8:	ldr	x0, [x9, #8]
   2f0ec:	mov	x1, x8
   2f0f0:	bl	c040 <__gmpn_gcd_22@plt>
   2f0f4:	cmp	x1, #0x0
   2f0f8:	mov	w8, #0x1                   	// #1
   2f0fc:	cinc	x8, x8, ne  // ne = any
   2f100:	stp	x0, x1, [x19]
   2f104:	stur	x8, [x29, #-8]
   2f108:	ldur	x0, [x29, #-24]
   2f10c:	cbnz	x0, 2f144 <__gmpn_gcd@@Base+0x3a8>
   2f110:	ldur	x0, [x29, #-8]
   2f114:	mov	sp, x29
   2f118:	ldp	x20, x19, [sp, #80]
   2f11c:	ldp	x22, x21, [sp, #64]
   2f120:	ldp	x24, x23, [sp, #48]
   2f124:	ldp	x26, x25, [sp, #32]
   2f128:	ldp	x28, x27, [sp, #16]
   2f12c:	ldp	x29, x30, [sp], #96
   2f130:	ret
   2f134:	sub	x0, x29, #0x18
   2f138:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2f13c:	mov	x23, x0
   2f140:	b	2ee60 <__gmpn_gcd@@Base+0xc4>
   2f144:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2f148:	b	2f110 <__gmpn_gcd@@Base+0x374>
   2f14c:	stp	x29, x30, [sp, #-32]!
   2f150:	stp	x20, x19, [sp, #16]
   2f154:	mov	x20, x0
   2f158:	ldr	x0, [x0]
   2f15c:	mov	x29, sp
   2f160:	mov	x19, x2
   2f164:	bl	ca70 <__gmpn_copyi@plt>
   2f168:	str	x19, [x20, #8]
   2f16c:	ldp	x20, x19, [sp, #16]
   2f170:	ldp	x29, x30, [sp], #32
   2f174:	ret

000000000002f178 <__gmpn_gcdext_1@@Base>:
   2f178:	mov	x8, xzr
   2f17c:	mov	x10, xzr
   2f180:	mov	w9, #0x1                   	// #1
   2f184:	cmp	x2, x3
   2f188:	mov	w11, #0x1                   	// #1
   2f18c:	b.cc	2f1a4 <__gmpn_gcdext_1@@Base+0x2c>  // b.lo, b.ul, b.last
   2f190:	udiv	x12, x2, x3
   2f194:	msub	x2, x12, x3, x2
   2f198:	cbz	x2, 2f1bc <__gmpn_gcdext_1@@Base+0x44>
   2f19c:	msub	x9, x12, x10, x9
   2f1a0:	msub	x8, x12, x11, x8
   2f1a4:	udiv	x12, x3, x2
   2f1a8:	msub	x3, x12, x2, x3
   2f1ac:	cbz	x3, 2f1c8 <__gmpn_gcdext_1@@Base+0x50>
   2f1b0:	msub	x10, x12, x9, x10
   2f1b4:	msub	x11, x12, x8, x11
   2f1b8:	b	2f190 <__gmpn_gcdext_1@@Base+0x18>
   2f1bc:	mov	x9, x10
   2f1c0:	mov	x8, x11
   2f1c4:	mov	x2, x3
   2f1c8:	str	x9, [x0]
   2f1cc:	mov	x0, x2
   2f1d0:	str	x8, [x1]
   2f1d4:	ret

000000000002f1d8 <__gmpn_gcdext@@Base>:
   2f1d8:	stp	x29, x30, [sp, #-96]!
   2f1dc:	stp	x28, x27, [sp, #16]
   2f1e0:	stp	x26, x25, [sp, #32]
   2f1e4:	stp	x24, x23, [sp, #48]
   2f1e8:	stp	x22, x21, [sp, #64]
   2f1ec:	stp	x20, x19, [sp, #80]
   2f1f0:	mov	x29, sp
   2f1f4:	sub	sp, sp, #0xf0
   2f1f8:	mov	w8, #0x3                   	// #3
   2f1fc:	sub	x9, x4, x6
   2f200:	bfi	x8, x6, #2, #62
   2f204:	cmp	x9, x8
   2f208:	mov	x23, x6
   2f20c:	mov	x21, x5
   2f210:	mov	x19, x4
   2f214:	mov	x26, x2
   2f218:	mov	x28, x1
   2f21c:	mov	x27, x0
   2f220:	add	x20, x6, #0x1
   2f224:	csinc	x22, x8, x9, lt  // lt = tstop
   2f228:	cmp	x6, #0xf2
   2f22c:	stur	xzr, [x29, #-80]
   2f230:	stur	x3, [x29, #-136]
   2f234:	b.lt	2f2b8 <__gmpn_gcdext@@Base+0xe0>  // b.tstop
   2f238:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   2f23c:	movk	x9, #0xaaab
   2f240:	lsr	x8, x23, #1
   2f244:	umulh	x9, x23, x9
   2f248:	lsr	x10, x9, #1
   2f24c:	cmp	x8, x9, lsr #1
   2f250:	csel	x9, x8, x10, lt  // lt = tstop
   2f254:	mov	x25, x23
   2f258:	sub	x0, x25, x9
   2f25c:	csel	x23, x8, x10, gt
   2f260:	add	x8, x0, #0x1
   2f264:	add	x9, x0, #0x2
   2f268:	cmp	x8, #0x0
   2f26c:	csinc	x8, x9, x0, lt  // lt = tstop
   2f270:	lsl	x8, x8, #1
   2f274:	and	x8, x8, #0xfffffffffffffffc
   2f278:	add	x24, x8, #0x4
   2f27c:	bl	c5b0 <__gmpn_hgcd_itch@plt>
   2f280:	add	x8, x23, x25
   2f284:	sub	x9, x8, #0x1
   2f288:	cmp	x0, x8
   2f28c:	csel	x8, x9, x0, lt  // lt = tstop
   2f290:	add	x8, x8, x24
   2f294:	cmp	x8, x22
   2f298:	ldur	x3, [x29, #-136]
   2f29c:	csel	x8, x8, x22, gt
   2f2a0:	cmp	x8, #0x6a1
   2f2a4:	mov	w9, #0x6a1                 	// #1697
   2f2a8:	csel	x8, x8, x9, gt
   2f2ac:	mov	x23, x25
   2f2b0:	add	x22, x8, x20, lsl #1
   2f2b4:	b	2f2b8 <__gmpn_gcdext@@Base+0xe0>
   2f2b8:	lsl	x1, x22, #3
   2f2bc:	mov	w8, #0x7f00                	// #32512
   2f2c0:	cmp	x1, x8
   2f2c4:	b.hi	2fd04 <__gmpn_gcdext@@Base+0xb2c>  // b.pmore
   2f2c8:	add	x9, x1, #0xf
   2f2cc:	mov	x8, sp
   2f2d0:	and	x9, x9, #0xfffffffffffffff0
   2f2d4:	sub	x22, x8, x9
   2f2d8:	mov	sp, x22
   2f2dc:	cmp	x19, x23
   2f2e0:	b.le	2f340 <__gmpn_gcdext@@Base+0x168>
   2f2e4:	mov	x1, x3
   2f2e8:	ldur	x3, [x29, #-136]
   2f2ec:	mov	x0, x22
   2f2f0:	mov	x2, xzr
   2f2f4:	mov	x4, x19
   2f2f8:	mov	x5, x21
   2f2fc:	mov	x6, x23
   2f300:	bl	bf10 <__gmpn_tdiv_qr@plt>
   2f304:	ldur	x3, [x29, #-136]
   2f308:	mov	x9, x23
   2f30c:	sub	x8, x3, #0x8
   2f310:	ldr	x10, [x8, x9, lsl #3]
   2f314:	cbnz	x10, 2f340 <__gmpn_gcdext@@Base+0x168>
   2f318:	sub	x9, x9, #0x1
   2f31c:	cbnz	x9, 2f310 <__gmpn_gcdext@@Base+0x138>
   2f320:	mov	x0, x27
   2f324:	mov	x1, x21
   2f328:	mov	x2, x23
   2f32c:	bl	ca70 <__gmpn_copyi@plt>
   2f330:	str	xzr, [x26]
   2f334:	ldur	x0, [x29, #-80]
   2f338:	cbz	x0, 2fce0 <__gmpn_gcdext@@Base+0xb08>
   2f33c:	b	2f474 <__gmpn_gcdext@@Base+0x29c>
   2f340:	cmp	x23, #0xf1
   2f344:	b.le	2f448 <__gmpn_gcdext@@Base+0x270>
   2f348:	stp	x21, x24, [x29, #-152]
   2f34c:	cbz	x20, 2f364 <__gmpn_gcdext@@Base+0x18c>
   2f350:	lsl	x8, x23, #4
   2f354:	add	x2, x8, #0x10
   2f358:	mov	x0, x22
   2f35c:	mov	w1, wzr
   2f360:	bl	c610 <memset@plt>
   2f364:	cmp	x23, #0x0
   2f368:	add	x21, x22, x20, lsl #3
   2f36c:	cinc	x8, x23, lt  // lt = tstop
   2f370:	stp	x28, x26, [x29, #-56]
   2f374:	stur	x26, [x29, #-200]
   2f378:	mov	x26, x28
   2f37c:	add	x28, x21, x20, lsl #3
   2f380:	sub	x25, x23, x8, asr #1
   2f384:	sub	x0, x29, #0x80
   2f388:	mov	x1, x25
   2f38c:	mov	x2, x28
   2f390:	stur	x27, [x29, #-184]
   2f394:	stur	x27, [x29, #-72]
   2f398:	asr	x19, x8, #1
   2f39c:	bl	c850 <__gmpn_hgcd_matrix_init@plt>
   2f3a0:	ldp	x8, x27, [x29, #-144]
   2f3a4:	ldur	x20, [x29, #-152]
   2f3a8:	sub	x3, x29, #0x80
   2f3ac:	mov	x2, x25
   2f3b0:	add	x24, x28, x8, lsl #3
   2f3b4:	add	x0, x27, x19, lsl #3
   2f3b8:	add	x1, x20, x19, lsl #3
   2f3bc:	mov	x4, x24
   2f3c0:	bl	ce00 <__gmpn_hgcd@plt>
   2f3c4:	cmp	x0, #0x1
   2f3c8:	stur	x21, [x29, #-144]
   2f3cc:	stur	x28, [x29, #-160]
   2f3d0:	b.lt	2f47c <__gmpn_gcdext@@Base+0x2a4>  // b.tstop
   2f3d4:	add	x1, x0, x19
   2f3d8:	sub	x0, x29, #0x80
   2f3dc:	mov	x2, x27
   2f3e0:	mov	x3, x20
   2f3e4:	mov	x4, x19
   2f3e8:	mov	x5, x24
   2f3ec:	stur	x26, [x29, #-208]
   2f3f0:	bl	c8c0 <__gmpn_hgcd_matrix_adjust@plt>
   2f3f4:	ldur	x1, [x29, #-96]
   2f3f8:	ldur	x2, [x29, #-120]
   2f3fc:	mov	x19, x0
   2f400:	mov	x0, x22
   2f404:	bl	ca70 <__gmpn_copyi@plt>
   2f408:	ldur	x1, [x29, #-88]
   2f40c:	ldur	x2, [x29, #-120]
   2f410:	mov	x0, x21
   2f414:	bl	ca70 <__gmpn_copyi@plt>
   2f418:	ldur	x8, [x29, #-120]
   2f41c:	sub	x9, x22, #0x8
   2f420:	add	x10, x22, x23, lsl #3
   2f424:	mov	x25, x22
   2f428:	ldr	x12, [x9, x8, lsl #3]
   2f42c:	ldr	x13, [x10, x8, lsl #3]
   2f430:	sub	x11, x8, #0x1
   2f434:	mov	x8, x11
   2f438:	orr	x12, x13, x12
   2f43c:	cbz	x12, 2f428 <__gmpn_gcdext@@Base+0x250>
   2f440:	add	x28, x11, #0x1
   2f444:	b	2f4d0 <__gmpn_gcdext@@Base+0x2f8>
   2f448:	mov	x0, x27
   2f44c:	mov	x1, x28
   2f450:	mov	x2, x26
   2f454:	mov	x4, x21
   2f458:	mov	x5, x23
   2f45c:	mov	x6, x22
   2f460:	bl	d1d0 <__gmpn_gcdext_lehmer_n@plt>
   2f464:	ldur	x8, [x29, #-80]
   2f468:	mov	x23, x0
   2f46c:	cbz	x8, 2fce0 <__gmpn_gcdext@@Base+0xb08>
   2f470:	mov	x0, x8
   2f474:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2f478:	b	2fce0 <__gmpn_gcdext@@Base+0xb08>
   2f47c:	mov	w8, #0x1                   	// #1
   2f480:	add	x9, x28, x23, lsl #3
   2f484:	stur	x24, [x29, #-168]
   2f488:	str	x8, [x21]
   2f48c:	stp	x21, x9, [x29, #-24]
   2f490:	stp	x8, x22, [x29, #-40]
   2f494:	adrp	x4, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2f498:	ldr	x4, [x4, #3968]
   2f49c:	sub	x5, x29, #0x48
   2f4a0:	mov	x0, x27
   2f4a4:	mov	x1, x20
   2f4a8:	mov	x2, x23
   2f4ac:	mov	x3, xzr
   2f4b0:	mov	x6, x28
   2f4b4:	bl	d2d0 <__gmpn_gcd_subdiv_step@plt>
   2f4b8:	cbz	x0, 2f820 <__gmpn_gcdext@@Base+0x648>
   2f4bc:	ldur	x28, [x29, #-40]
   2f4c0:	ldur	x24, [x29, #-168]
   2f4c4:	mov	x19, x0
   2f4c8:	mov	x25, x22
   2f4cc:	stur	x26, [x29, #-208]
   2f4d0:	cmp	x19, #0xf2
   2f4d4:	stur	x23, [x29, #-192]
   2f4d8:	b.lt	2f71c <__gmpn_gcdext@@Base+0x544>  // b.tstop
   2f4dc:	ldur	x27, [x29, #-160]
   2f4e0:	add	x8, x25, x23, lsl #3
   2f4e4:	sub	x23, x25, #0x8
   2f4e8:	mov	x20, x24
   2f4ec:	stp	x8, x24, [x29, #-176]
   2f4f0:	mov	x8, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   2f4f4:	movk	x8, #0xaaab
   2f4f8:	umulh	x8, x19, x8
   2f4fc:	sub	x26, x19, x8, lsr #1
   2f500:	sub	x0, x29, #0x80
   2f504:	mov	x1, x26
   2f508:	mov	x2, x27
   2f50c:	mov	x21, x28
   2f510:	mov	x24, x25
   2f514:	lsr	x25, x8, #1
   2f518:	bl	c850 <__gmpn_hgcd_matrix_init@plt>
   2f51c:	ldur	x22, [x29, #-136]
   2f520:	mov	x28, x19
   2f524:	ldur	x19, [x29, #-152]
   2f528:	sub	x3, x29, #0x80
   2f52c:	add	x0, x22, x25, lsl #3
   2f530:	mov	x2, x26
   2f534:	add	x1, x19, x25, lsl #3
   2f538:	mov	x4, x20
   2f53c:	bl	ce00 <__gmpn_hgcd@plt>
   2f540:	cmp	x0, #0x1
   2f544:	b.lt	2f5b4 <__gmpn_gcdext@@Base+0x3dc>  // b.tstop
   2f548:	add	x1, x0, x25
   2f54c:	sub	x0, x29, #0x80
   2f550:	mov	x2, x22
   2f554:	mov	x3, x19
   2f558:	mov	x4, x25
   2f55c:	mov	x5, x20
   2f560:	bl	c8c0 <__gmpn_hgcd_matrix_adjust@plt>
   2f564:	mov	x19, x0
   2f568:	mov	x0, x20
   2f56c:	mov	x1, x24
   2f570:	mov	x2, x21
   2f574:	mov	x22, x24
   2f578:	bl	ca70 <__gmpn_copyi@plt>
   2f57c:	ldp	x4, x3, [x29, #-120]
   2f580:	add	x26, x20, x21, lsl #3
   2f584:	mov	x0, x26
   2f588:	cmp	x4, x21
   2f58c:	b.ge	2f5fc <__gmpn_gcdext@@Base+0x424>  // b.tcont
   2f590:	mov	x1, x20
   2f594:	mov	x2, x21
   2f598:	bl	ccf0 <__gmpn_mul@plt>
   2f59c:	ldur	x3, [x29, #-96]
   2f5a0:	ldur	x4, [x29, #-120]
   2f5a4:	ldur	x1, [x29, #-144]
   2f5a8:	mov	x0, x22
   2f5ac:	mov	x2, x21
   2f5b0:	b	2f624 <__gmpn_gcdext@@Base+0x44c>
   2f5b4:	ldur	x9, [x29, #-144]
   2f5b8:	add	x8, x27, x28, lsl #3
   2f5bc:	stp	x21, x24, [x29, #-40]
   2f5c0:	adrp	x4, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   2f5c4:	stp	x9, x8, [x29, #-24]
   2f5c8:	ldr	x4, [x4, #3968]
   2f5cc:	sub	x5, x29, #0x48
   2f5d0:	mov	x0, x22
   2f5d4:	mov	x1, x19
   2f5d8:	mov	x2, x28
   2f5dc:	mov	x3, xzr
   2f5e0:	mov	x6, x27
   2f5e4:	mov	x25, x24
   2f5e8:	bl	d2d0 <__gmpn_gcd_subdiv_step@plt>
   2f5ec:	cbz	x0, 2f820 <__gmpn_gcdext@@Base+0x648>
   2f5f0:	ldur	x28, [x29, #-40]
   2f5f4:	mov	x19, x0
   2f5f8:	b	2f714 <__gmpn_gcdext@@Base+0x53c>
   2f5fc:	mov	x1, x3
   2f600:	mov	x2, x4
   2f604:	mov	x3, x20
   2f608:	mov	x4, x21
   2f60c:	bl	ccf0 <__gmpn_mul@plt>
   2f610:	ldur	x1, [x29, #-96]
   2f614:	ldur	x2, [x29, #-120]
   2f618:	ldur	x3, [x29, #-144]
   2f61c:	mov	x0, x22
   2f620:	mov	x4, x21
   2f624:	bl	ccf0 <__gmpn_mul@plt>
   2f628:	ldur	x8, [x29, #-120]
   2f62c:	mov	x0, x22
   2f630:	mov	x1, x22
   2f634:	mov	x2, x26
   2f638:	add	x3, x8, x21
   2f63c:	mov	x24, x22
   2f640:	bl	ca90 <__gmpn_add_n@plt>
   2f644:	ldur	x4, [x29, #-120]
   2f648:	ldur	x3, [x29, #-88]
   2f64c:	mov	x25, x0
   2f650:	mov	x0, x26
   2f654:	cmp	x4, x21
   2f658:	b.ge	2f684 <__gmpn_gcdext@@Base+0x4ac>  // b.tcont
   2f65c:	ldur	x22, [x29, #-144]
   2f660:	mov	x2, x21
   2f664:	mov	x1, x22
   2f668:	bl	ccf0 <__gmpn_mul@plt>
   2f66c:	ldur	x3, [x29, #-104]
   2f670:	ldur	x4, [x29, #-120]
   2f674:	mov	x0, x22
   2f678:	mov	x1, x20
   2f67c:	mov	x2, x21
   2f680:	b	2f6b0 <__gmpn_gcdext@@Base+0x4d8>
   2f684:	ldur	x22, [x29, #-144]
   2f688:	mov	x1, x3
   2f68c:	mov	x2, x4
   2f690:	mov	x4, x21
   2f694:	mov	x3, x22
   2f698:	bl	ccf0 <__gmpn_mul@plt>
   2f69c:	ldur	x1, [x29, #-104]
   2f6a0:	ldur	x2, [x29, #-120]
   2f6a4:	mov	x0, x22
   2f6a8:	mov	x3, x20
   2f6ac:	mov	x4, x21
   2f6b0:	bl	ccf0 <__gmpn_mul@plt>
   2f6b4:	ldur	x8, [x29, #-120]
   2f6b8:	mov	x0, x22
   2f6bc:	mov	x1, x22
   2f6c0:	mov	x2, x26
   2f6c4:	add	x3, x8, x21
   2f6c8:	bl	ca90 <__gmpn_add_n@plt>
   2f6cc:	ldur	x8, [x29, #-120]
   2f6d0:	orr	x9, x0, x25
   2f6d4:	add	x8, x8, x21
   2f6d8:	cbz	x9, 2f6f0 <__gmpn_gcdext@@Base+0x518>
   2f6dc:	str	x25, [x24, x8, lsl #3]
   2f6e0:	str	x0, [x22, x8, lsl #3]
   2f6e4:	mov	x25, x24
   2f6e8:	add	x28, x8, #0x1
   2f6ec:	b	2f714 <__gmpn_gcdext@@Base+0x53c>
   2f6f0:	ldur	x12, [x29, #-176]
   2f6f4:	ldr	x10, [x23, x8, lsl #3]
   2f6f8:	ldr	x11, [x12, x8, lsl #3]
   2f6fc:	sub	x9, x8, #0x1
   2f700:	mov	x8, x9
   2f704:	orr	x10, x11, x10
   2f708:	cbz	x10, 2f6f4 <__gmpn_gcdext@@Base+0x51c>
   2f70c:	add	x28, x9, #0x1
   2f710:	mov	x25, x24
   2f714:	cmp	x19, #0xf1
   2f718:	b.gt	2f4f0 <__gmpn_gcdext@@Base+0x318>
   2f71c:	ldur	x21, [x29, #-192]
   2f720:	ldp	x23, x22, [x29, #-160]
   2f724:	ldur	x3, [x29, #-136]
   2f728:	sub	x20, x19, #0x1
   2f72c:	mov	x8, x20
   2f730:	add	x9, x8, #0x1
   2f734:	cmp	x9, #0x1
   2f738:	b.lt	2f778 <__gmpn_gcdext@@Base+0x5a0>  // b.tstop
   2f73c:	ldr	x9, [x3, x8, lsl #3]
   2f740:	ldr	x10, [x22, x8, lsl #3]
   2f744:	sub	x8, x8, #0x1
   2f748:	cmp	x9, x10
   2f74c:	b.eq	2f730 <__gmpn_gcdext@@Base+0x558>  // b.none
   2f750:	cmp	x28, #0x1
   2f754:	b.ne	2f830 <__gmpn_gcdext@@Base+0x658>  // b.any
   2f758:	ldr	x8, [x25]
   2f75c:	cbnz	x8, 2f830 <__gmpn_gcdext@@Base+0x658>
   2f760:	ldur	x0, [x29, #-184]
   2f764:	ldp	x1, x2, [x29, #-208]
   2f768:	mov	x4, x22
   2f76c:	mov	x5, x19
   2f770:	mov	x6, x23
   2f774:	b	2f460 <__gmpn_gcdext@@Base+0x288>
   2f778:	ldur	x0, [x29, #-184]
   2f77c:	mov	x1, x3
   2f780:	mov	x2, x19
   2f784:	bl	ca70 <__gmpn_copyi@plt>
   2f788:	sub	x8, x25, #0x8
   2f78c:	add	x9, x25, x21, lsl #3
   2f790:	mov	x10, x28
   2f794:	subs	x11, x10, #0x1
   2f798:	b.lt	2f7b4 <__gmpn_gcdext@@Base+0x5dc>  // b.tstop
   2f79c:	ldr	x12, [x8, x10, lsl #3]
   2f7a0:	ldr	x10, [x9, x10, lsl #3]
   2f7a4:	cmp	x12, x10
   2f7a8:	mov	x10, x11
   2f7ac:	b.eq	2f794 <__gmpn_gcdext@@Base+0x5bc>  // b.none
   2f7b0:	b.ls	2f7e0 <__gmpn_gcdext@@Base+0x608>  // b.plast
   2f7b4:	add	x8, x25, x21, lsl #3
   2f7b8:	ldr	x10, [x8, x28, lsl #3]
   2f7bc:	sub	x9, x28, #0x1
   2f7c0:	mov	x28, x9
   2f7c4:	cbz	x10, 2f7b8 <__gmpn_gcdext@@Base+0x5e0>
   2f7c8:	ldur	x0, [x29, #-208]
   2f7cc:	ldur	x1, [x29, #-144]
   2f7d0:	add	x20, x9, #0x1
   2f7d4:	mov	x2, x20
   2f7d8:	bl	ca70 <__gmpn_copyi@plt>
   2f7dc:	b	2f808 <__gmpn_gcdext@@Base+0x630>
   2f7e0:	mov	x20, x28
   2f7e4:	subs	x28, x28, #0x1
   2f7e8:	b.lt	2f7f4 <__gmpn_gcdext@@Base+0x61c>  // b.tstop
   2f7ec:	ldr	x9, [x8, x20, lsl #3]
   2f7f0:	cbz	x9, 2f7e0 <__gmpn_gcdext@@Base+0x608>
   2f7f4:	ldur	x0, [x29, #-208]
   2f7f8:	mov	x1, x25
   2f7fc:	mov	x2, x20
   2f800:	bl	ca70 <__gmpn_copyi@plt>
   2f804:	neg	x20, x20
   2f808:	ldur	x8, [x29, #-200]
   2f80c:	str	x20, [x8]
   2f810:	ldur	x0, [x29, #-80]
   2f814:	cbnz	x0, 2fd18 <__gmpn_gcdext@@Base+0xb40>
   2f818:	mov	x23, x19
   2f81c:	b	2fce0 <__gmpn_gcdext@@Base+0xb08>
   2f820:	ldur	x0, [x29, #-80]
   2f824:	cbnz	x0, 2fd20 <__gmpn_gcdext@@Base+0xb48>
   2f828:	ldur	x23, [x29, #-64]
   2f82c:	b	2fce0 <__gmpn_gcdext@@Base+0xb08>
   2f830:	add	x26, x23, x19, lsl #3
   2f834:	mov	x0, x26
   2f838:	mov	x1, x3
   2f83c:	mov	x2, x19
   2f840:	bl	ca70 <__gmpn_copyi@plt>
   2f844:	mov	x24, x25
   2f848:	add	x25, x26, x19, lsl #3
   2f84c:	mov	x0, x25
   2f850:	mov	x1, x22
   2f854:	mov	x2, x19
   2f858:	bl	ca70 <__gmpn_copyi@plt>
   2f85c:	ldur	x0, [x29, #-184]
   2f860:	add	x6, x26, x19, lsl #4
   2f864:	sub	x2, x29, #0x80
   2f868:	mov	x1, x23
   2f86c:	mov	x3, x26
   2f870:	mov	x4, x25
   2f874:	mov	x5, x19
   2f878:	stur	x26, [x29, #-216]
   2f87c:	bl	d1d0 <__gmpn_gcdext_lehmer_n@plt>
   2f880:	mov	x23, x0
   2f884:	sub	x8, x24, #0x8
   2f888:	mov	x9, x28
   2f88c:	stur	x24, [x29, #-168]
   2f890:	mov	x26, x9
   2f894:	subs	x9, x9, #0x1
   2f898:	b.lt	2f8a4 <__gmpn_gcdext@@Base+0x6cc>  // b.tstop
   2f89c:	ldr	x10, [x8, x26, lsl #3]
   2f8a0:	cbz	x10, 2f890 <__gmpn_gcdext@@Base+0x6b8>
   2f8a4:	ldur	x11, [x29, #-128]
   2f8a8:	cbz	x11, 2f938 <__gmpn_gcdext@@Base+0x760>
   2f8ac:	lsl	x10, x21, #4
   2f8b0:	mov	w9, #0x18                  	// #24
   2f8b4:	stur	x10, [x29, #-232]
   2f8b8:	ldur	x10, [x29, #-168]
   2f8bc:	cmp	x11, #0x0
   2f8c0:	mul	x9, x19, x9
   2f8c4:	ldur	x3, [x29, #-136]
   2f8c8:	cneg	x27, x11, mi  // mi = first
   2f8cc:	add	x9, x9, x21, lsl #4
   2f8d0:	add	x9, x9, x27, lsl #3
   2f8d4:	add	x9, x9, x10
   2f8d8:	add	x0, x25, #0x8
   2f8dc:	add	x25, x9, #0x10
   2f8e0:	add	x9, x3, x19, lsl #3
   2f8e4:	mov	x8, xzr
   2f8e8:	mov	x22, x11
   2f8ec:	sub	x9, x9, #0x8
   2f8f0:	mov	x10, x25
   2f8f4:	stur	x23, [x29, #-176]
   2f8f8:	add	x4, x19, x8
   2f8fc:	mov	x21, x8
   2f900:	cmp	x4, #0x1
   2f904:	mov	x23, x10
   2f908:	b.lt	2f91c <__gmpn_gcdext@@Base+0x744>  // b.tstop
   2f90c:	ldr	x11, [x9, x21, lsl #3]
   2f910:	sub	x10, x23, #0x8
   2f914:	sub	x8, x21, #0x1
   2f918:	cbz	x11, 2f8f8 <__gmpn_gcdext@@Base+0x720>
   2f91c:	ldur	x24, [x29, #-152]
   2f920:	cmp	x4, x27
   2f924:	stur	x0, [x29, #-224]
   2f928:	b.ge	2f958 <__gmpn_gcdext@@Base+0x780>  // b.tcont
   2f92c:	ldur	x1, [x29, #-160]
   2f930:	mov	x2, x27
   2f934:	b	2f968 <__gmpn_gcdext@@Base+0x790>
   2f938:	ldur	x0, [x29, #-208]
   2f93c:	ldur	x1, [x29, #-168]
   2f940:	mov	x2, x26
   2f944:	bl	ca70 <__gmpn_copyi@plt>
   2f948:	ldur	x9, [x29, #-200]
   2f94c:	neg	x8, x26
   2f950:	str	x8, [x9]
   2f954:	b	2f334 <__gmpn_gcdext@@Base+0x15c>
   2f958:	mov	x1, x3
   2f95c:	ldur	x3, [x29, #-160]
   2f960:	mov	x2, x4
   2f964:	mov	x4, x27
   2f968:	bl	ccf0 <__gmpn_mul@plt>
   2f96c:	add	x8, x27, x19
   2f970:	cmp	x22, #0x1
   2f974:	mov	x9, x27
   2f978:	add	x27, x8, x21
   2f97c:	b.lt	2f9f0 <__gmpn_gcdext@@Base+0x818>  // b.tstop
   2f980:	ldp	x8, x25, [x29, #-176]
   2f984:	cbz	x8, 2f9dc <__gmpn_gcdext@@Base+0x804>
   2f988:	ldur	x0, [x29, #-224]
   2f98c:	ldp	x2, x3, [x29, #-184]
   2f990:	mov	x1, x0
   2f994:	bl	c2e0 <__gmpn_sub_n@plt>
   2f998:	cbz	x0, 2f9dc <__gmpn_gcdext@@Base+0x804>
   2f99c:	ldur	x8, [x29, #-232]
   2f9a0:	ldur	x9, [x29, #-176]
   2f9a4:	add	x8, x8, x19, lsl #4
   2f9a8:	add	x8, x25, x8
   2f9ac:	add	x9, x9, #0x3
   2f9b0:	sub	x10, x9, #0x3
   2f9b4:	cmp	x10, x27
   2f9b8:	b.ge	2f9dc <__gmpn_gcdext@@Base+0x804>  // b.tcont
   2f9bc:	ldr	x10, [x8, x9, lsl #3]
   2f9c0:	sub	x11, x10, #0x1
   2f9c4:	str	x11, [x8, x9, lsl #3]
   2f9c8:	add	x9, x9, #0x1
   2f9cc:	cbz	x10, 2f9b0 <__gmpn_gcdext@@Base+0x7d8>
   2f9d0:	b	2f9dc <__gmpn_gcdext@@Base+0x804>
   2f9d4:	ldr	x8, [x23], #-8
   2f9d8:	cbnz	x8, 2fa68 <__gmpn_gcdext@@Base+0x890>
   2f9dc:	mov	x19, x27
   2f9e0:	subs	x27, x27, #0x1
   2f9e4:	b.ge	2f9d4 <__gmpn_gcdext@@Base+0x7fc>  // b.tcont
   2f9e8:	cbnz	x19, 2fa68 <__gmpn_gcdext@@Base+0x890>
   2f9ec:	b	2fac0 <__gmpn_gcdext@@Base+0x8e8>
   2f9f0:	ldur	x23, [x29, #-176]
   2f9f4:	stur	x9, [x29, #-136]
   2f9f8:	cbz	x23, 2fa48 <__gmpn_gcdext@@Base+0x870>
   2f9fc:	ldur	x0, [x29, #-224]
   2fa00:	ldur	x2, [x29, #-184]
   2fa04:	mov	x3, x23
   2fa08:	mov	x1, x0
   2fa0c:	bl	ca90 <__gmpn_add_n@plt>
   2fa10:	cbz	x0, 2fa48 <__gmpn_gcdext@@Base+0x870>
   2fa14:	ldur	x8, [x29, #-232]
   2fa18:	ldur	x9, [x29, #-168]
   2fa1c:	add	x8, x8, x19, lsl #4
   2fa20:	add	x8, x9, x8
   2fa24:	add	x9, x23, #0x3
   2fa28:	sub	x10, x9, #0x3
   2fa2c:	cmp	x10, x27
   2fa30:	b.ge	2fa48 <__gmpn_gcdext@@Base+0x870>  // b.tcont
   2fa34:	ldr	x10, [x8, x9, lsl #3]
   2fa38:	adds	x10, x10, #0x1
   2fa3c:	str	x10, [x8, x9, lsl #3]
   2fa40:	add	x9, x9, #0x1
   2fa44:	b.cs	2fa28 <__gmpn_gcdext@@Base+0x850>  // b.hs, b.nlast
   2fa48:	ldr	x8, [x25, x21, lsl #3]
   2fa4c:	ldur	x9, [x29, #-136]
   2fa50:	ldur	x25, [x29, #-168]
   2fa54:	cmp	x8, #0x0
   2fa58:	cset	w8, eq  // eq = none
   2fa5c:	add	x9, x9, x19
   2fa60:	sub	x8, x9, x8
   2fa64:	add	x19, x8, x21
   2fa68:	ldur	x8, [x29, #-232]
   2fa6c:	add	x8, x8, x19, lsl #3
   2fa70:	add	x8, x8, x25
   2fa74:	add	x8, x8, #0x10
   2fa78:	add	x4, x20, #0x1
   2fa7c:	mov	x21, x20
   2fa80:	cmp	x4, #0x1
   2fa84:	mov	x23, x8
   2fa88:	b.lt	2fa9c <__gmpn_gcdext@@Base+0x8c4>  // b.tstop
   2fa8c:	ldr	x9, [x24, x21, lsl #3]
   2fa90:	sub	x20, x21, #0x1
   2fa94:	add	x8, x23, #0x8
   2fa98:	cbz	x9, 2fa78 <__gmpn_gcdext@@Base+0x8a0>
   2fa9c:	ldp	x1, x0, [x29, #-224]
   2faa0:	mov	x2, x19
   2faa4:	mov	x3, x24
   2faa8:	bl	c450 <__gmpn_divexact@plt>
   2faac:	ldr	x8, [x23]
   2fab0:	cmp	x8, #0x0
   2fab4:	cset	w8, eq  // eq = none
   2fab8:	sub	x8, x19, x8
   2fabc:	sub	x19, x8, x21
   2fac0:	ldur	x4, [x29, #-128]
   2fac4:	ldur	x8, [x29, #-192]
   2fac8:	cmp	x4, #0x0
   2facc:	b.le	2fad8 <__gmpn_gcdext@@Base+0x900>
   2fad0:	mov	w20, wzr
   2fad4:	b	2fae4 <__gmpn_gcdext@@Base+0x90c>
   2fad8:	neg	x4, x4
   2fadc:	mov	w20, #0x1                   	// #1
   2fae0:	stur	x4, [x29, #-128]
   2fae4:	add	x8, x25, x8, lsl #3
   2fae8:	mov	x24, x28
   2faec:	subs	x28, x28, #0x1
   2faf0:	b.lt	2fafc <__gmpn_gcdext@@Base+0x924>  // b.tstop
   2faf4:	ldr	x9, [x8, x24, lsl #3]
   2faf8:	cbz	x9, 2fae8 <__gmpn_gcdext@@Base+0x910>
   2fafc:	cmp	x4, x24
   2fb00:	b.le	2fb24 <__gmpn_gcdext@@Base+0x94c>
   2fb04:	ldur	x27, [x29, #-208]
   2fb08:	ldur	x28, [x29, #-144]
   2fb0c:	ldur	x1, [x29, #-160]
   2fb10:	mov	x2, x4
   2fb14:	mov	x0, x27
   2fb18:	mov	x3, x28
   2fb1c:	mov	x4, x24
   2fb20:	b	2fb3c <__gmpn_gcdext@@Base+0x964>
   2fb24:	ldur	x27, [x29, #-208]
   2fb28:	ldur	x28, [x29, #-144]
   2fb2c:	ldur	x3, [x29, #-160]
   2fb30:	mov	x2, x24
   2fb34:	mov	x0, x27
   2fb38:	mov	x1, x28
   2fb3c:	bl	ccf0 <__gmpn_mul@plt>
   2fb40:	ldur	x8, [x29, #-128]
   2fb44:	ldur	x23, [x29, #-200]
   2fb48:	add	x9, x8, x24
   2fb4c:	add	x9, x27, x9, lsl #3
   2fb50:	ldur	x9, [x9, #-8]
   2fb54:	cmp	x9, #0x0
   2fb58:	cset	w9, eq  // eq = none
   2fb5c:	sub	x8, x8, x9
   2fb60:	cmp	x19, #0x1
   2fb64:	add	x24, x8, x24
   2fb68:	b.lt	2fcc8 <__gmpn_gcdext@@Base+0xaf0>  // b.tstop
   2fb6c:	mov	x0, x28
   2fb70:	cmp	x19, x26
   2fb74:	b.le	2fb8c <__gmpn_gcdext@@Base+0x9b4>
   2fb78:	ldur	x1, [x29, #-216]
   2fb7c:	mov	x2, x19
   2fb80:	mov	x3, x25
   2fb84:	mov	x4, x26
   2fb88:	b	2fb9c <__gmpn_gcdext@@Base+0x9c4>
   2fb8c:	ldur	x3, [x29, #-216]
   2fb90:	mov	x1, x25
   2fb94:	mov	x2, x26
   2fb98:	mov	x4, x19
   2fb9c:	bl	ccf0 <__gmpn_mul@plt>
   2fba0:	add	x8, x19, x26
   2fba4:	add	x8, x28, x8, lsl #3
   2fba8:	ldur	x8, [x8, #-8]
   2fbac:	cmp	x8, #0x0
   2fbb0:	cset	w8, eq  // eq = none
   2fbb4:	sub	x8, x19, x8
   2fbb8:	add	x25, x8, x26
   2fbbc:	csetm	x21, eq  // eq = none
   2fbc0:	cmp	x25, x24
   2fbc4:	b.le	2fc1c <__gmpn_gcdext@@Base+0xa44>
   2fbc8:	cbz	x24, 2fc6c <__gmpn_gcdext@@Base+0xa94>
   2fbcc:	mov	x0, x27
   2fbd0:	mov	x1, x28
   2fbd4:	mov	x2, x27
   2fbd8:	mov	x3, x24
   2fbdc:	bl	ca90 <__gmpn_add_n@plt>
   2fbe0:	cbz	x0, 2fc74 <__gmpn_gcdext@@Base+0xa9c>
   2fbe4:	ldur	x8, [x29, #-192]
   2fbe8:	ldur	x9, [x29, #-168]
   2fbec:	add	x8, x9, x8, lsl #3
   2fbf0:	add	x10, x8, #0x8
   2fbf4:	mov	w8, #0x1                   	// #1
   2fbf8:	cmp	x24, x25
   2fbfc:	b.ge	2fcbc <__gmpn_gcdext@@Base+0xae4>  // b.tcont
   2fc00:	ldr	x9, [x10, x24, lsl #3]
   2fc04:	adds	x11, x9, #0x1
   2fc08:	add	x9, x24, #0x1
   2fc0c:	str	x11, [x27, x24, lsl #3]
   2fc10:	mov	x24, x9
   2fc14:	b.cs	2fbf8 <__gmpn_gcdext@@Base+0xa20>  // b.hs, b.nlast
   2fc18:	b	2fc78 <__gmpn_gcdext@@Base+0xaa0>
   2fc1c:	neg	x8, x8
   2fc20:	cmp	x8, x26
   2fc24:	b.eq	2fc64 <__gmpn_gcdext@@Base+0xa8c>  // b.none
   2fc28:	mov	x0, x27
   2fc2c:	mov	x1, x27
   2fc30:	mov	x2, x28
   2fc34:	mov	x3, x25
   2fc38:	bl	ca90 <__gmpn_add_n@plt>
   2fc3c:	cbz	x0, 2fc64 <__gmpn_gcdext@@Base+0xa8c>
   2fc40:	mov	w8, #0x1                   	// #1
   2fc44:	cmp	x25, x24
   2fc48:	b.ge	2fcc0 <__gmpn_gcdext@@Base+0xae8>  // b.tcont
   2fc4c:	ldr	x9, [x27, x25, lsl #3]
   2fc50:	add	x10, x25, #0x1
   2fc54:	adds	x9, x9, #0x1
   2fc58:	str	x9, [x27, x25, lsl #3]
   2fc5c:	mov	x25, x10
   2fc60:	b.cs	2fc44 <__gmpn_gcdext@@Base+0xa6c>  // b.hs, b.nlast
   2fc64:	mov	x8, xzr
   2fc68:	b	2fcc0 <__gmpn_gcdext@@Base+0xae8>
   2fc6c:	mov	x9, xzr
   2fc70:	b	2fc78 <__gmpn_gcdext@@Base+0xaa0>
   2fc74:	mov	x9, x24
   2fc78:	cmp	x28, x27
   2fc7c:	mov	x8, xzr
   2fc80:	b.eq	2fcbc <__gmpn_gcdext@@Base+0xae4>  // b.none
   2fc84:	cmp	x25, x9
   2fc88:	b.le	2fcbc <__gmpn_gcdext@@Base+0xae4>
   2fc8c:	ldur	x8, [x29, #-192]
   2fc90:	ldur	x11, [x29, #-168]
   2fc94:	add	x10, x19, x21
   2fc98:	add	x0, x27, x9, lsl #3
   2fc9c:	add	x8, x9, x8
   2fca0:	add	x8, x11, x8, lsl #3
   2fca4:	sub	x9, x10, x9
   2fca8:	add	x1, x8, #0x8
   2fcac:	add	x8, x9, x26
   2fcb0:	lsl	x2, x8, #3
   2fcb4:	bl	bee0 <memcpy@plt>
   2fcb8:	mov	x8, xzr
   2fcbc:	mov	x24, x25
   2fcc0:	str	x8, [x27, x24, lsl #3]
   2fcc4:	add	x24, x8, x24
   2fcc8:	cmp	w20, #0x0
   2fccc:	cneg	x8, x24, ne  // ne = any
   2fcd0:	str	x8, [x23]
   2fcd4:	ldur	x0, [x29, #-80]
   2fcd8:	ldur	x23, [x29, #-176]
   2fcdc:	cbnz	x0, 2f474 <__gmpn_gcdext@@Base+0x29c>
   2fce0:	mov	x0, x23
   2fce4:	mov	sp, x29
   2fce8:	ldp	x20, x19, [sp, #80]
   2fcec:	ldp	x22, x21, [sp, #64]
   2fcf0:	ldp	x24, x23, [sp, #48]
   2fcf4:	ldp	x26, x25, [sp, #32]
   2fcf8:	ldp	x28, x27, [sp, #16]
   2fcfc:	ldp	x29, x30, [sp], #96
   2fd00:	ret
   2fd04:	sub	x0, x29, #0x50
   2fd08:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   2fd0c:	ldur	x3, [x29, #-136]
   2fd10:	mov	x22, x0
   2fd14:	b	2f2dc <__gmpn_gcdext@@Base+0x104>
   2fd18:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2fd1c:	b	2f818 <__gmpn_gcdext@@Base+0x640>
   2fd20:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   2fd24:	b	2f828 <__gmpn_gcdext@@Base+0x650>

000000000002fd28 <__gmpn_gcd_subdiv_step@@Base>:
   2fd28:	sub	sp, sp, #0x70
   2fd2c:	add	x9, x0, x2, lsl #3
   2fd30:	stp	x22, x21, [sp, #80]
   2fd34:	stp	x20, x19, [sp, #96]
   2fd38:	mov	x21, x6
   2fd3c:	mov	x20, x5
   2fd40:	mov	x19, x4
   2fd44:	mov	x22, x3
   2fd48:	mov	x8, x0
   2fd4c:	mov	x11, xzr
   2fd50:	sub	x10, x9, #0x8
   2fd54:	stp	x29, x30, [sp, #16]
   2fd58:	stp	x28, x27, [sp, #32]
   2fd5c:	stp	x26, x25, [sp, #48]
   2fd60:	stp	x24, x23, [sp, #64]
   2fd64:	add	x29, sp, #0x10
   2fd68:	add	x24, x2, x11
   2fd6c:	mov	x9, x11
   2fd70:	cmp	x24, #0x1
   2fd74:	b.lt	2fd98 <__gmpn_gcd_subdiv_step@@Base+0x70>  // b.tstop
   2fd78:	ldr	x12, [x10, x9, lsl #3]
   2fd7c:	sub	x11, x9, #0x1
   2fd80:	cbz	x12, 2fd68 <__gmpn_gcd_subdiv_step@@Base+0x40>
   2fd84:	b	2fd98 <__gmpn_gcd_subdiv_step@@Base+0x70>
   2fd88:	add	x9, x1, x10, lsl #3
   2fd8c:	ldur	x12, [x9, #-8]
   2fd90:	add	x9, x11, #0x1
   2fd94:	cbnz	x12, 2fda8 <__gmpn_gcd_subdiv_step@@Base+0x80>
   2fd98:	mov	x10, x2
   2fd9c:	subs	x2, x2, #0x1
   2fda0:	mov	x11, x9
   2fda4:	b.ge	2fd88 <__gmpn_gcd_subdiv_step@@Base+0x60>  // b.tcont
   2fda8:	cbz	x11, 2fdc0 <__gmpn_gcd_subdiv_step@@Base+0x98>
   2fdac:	cmp	x24, x10
   2fdb0:	csel	x23, x10, x24, gt
   2fdb4:	csel	x24, x24, x10, gt
   2fdb8:	cset	w27, gt
   2fdbc:	b	2fdf0 <__gmpn_gcd_subdiv_step@@Base+0xc8>
   2fdc0:	sub	x9, x1, #0x8
   2fdc4:	mov	x10, x24
   2fdc8:	subs	x11, x10, #0x1
   2fdcc:	b.lt	2ff24 <__gmpn_gcd_subdiv_step@@Base+0x1fc>  // b.tstop
   2fdd0:	add	x12, x8, x10, lsl #3
   2fdd4:	ldur	x12, [x12, #-8]
   2fdd8:	ldr	x10, [x9, x10, lsl #3]
   2fddc:	cmp	x12, x10
   2fde0:	mov	x10, x11
   2fde4:	b.eq	2fdc8 <__gmpn_gcd_subdiv_step@@Base+0xa0>  // b.none
   2fde8:	cset	w27, hi  // hi = pmore
   2fdec:	mov	x23, x24
   2fdf0:	cmp	w27, #0x0
   2fdf4:	csel	x25, x8, x1, ne  // ne = any
   2fdf8:	csel	x26, x1, x8, ne  // ne = any
   2fdfc:	cmp	x23, x22
   2fe00:	b.le	2fed0 <__gmpn_gcd_subdiv_step@@Base+0x1a8>
   2fe04:	cbz	x23, 2fe54 <__gmpn_gcd_subdiv_step@@Base+0x12c>
   2fe08:	mov	x0, x25
   2fe0c:	mov	x1, x25
   2fe10:	mov	x2, x26
   2fe14:	mov	x3, x23
   2fe18:	bl	c2e0 <__gmpn_sub_n@plt>
   2fe1c:	cbz	x0, 2fe54 <__gmpn_gcd_subdiv_step@@Base+0x12c>
   2fe20:	mov	x8, x23
   2fe24:	cmp	x8, x24
   2fe28:	b.ge	2fe54 <__gmpn_gcd_subdiv_step@@Base+0x12c>  // b.tcont
   2fe2c:	ldr	x9, [x25, x8, lsl #3]
   2fe30:	add	x11, x8, #0x1
   2fe34:	sub	x10, x9, #0x1
   2fe38:	str	x10, [x25, x8, lsl #3]
   2fe3c:	mov	x8, x11
   2fe40:	cbz	x9, 2fe24 <__gmpn_gcd_subdiv_step@@Base+0xfc>
   2fe44:	b	2fe54 <__gmpn_gcd_subdiv_step@@Base+0x12c>
   2fe48:	add	x8, x25, x28, lsl #3
   2fe4c:	ldur	x8, [x8, #-8]
   2fe50:	cbnz	x8, 2fe60 <__gmpn_gcd_subdiv_step@@Base+0x138>
   2fe54:	mov	x28, x24
   2fe58:	subs	x24, x24, #0x1
   2fe5c:	b.ge	2fe48 <__gmpn_gcd_subdiv_step@@Base+0x120>  // b.tcont
   2fe60:	cmp	x28, x22
   2fe64:	b.le	2fee4 <__gmpn_gcd_subdiv_step@@Base+0x1bc>
   2fe68:	cmp	x23, x28
   2fe6c:	str	x19, [sp, #8]
   2fe70:	b.ne	2ff48 <__gmpn_gcd_subdiv_step@@Base+0x220>  // b.any
   2fe74:	sub	x8, x26, #0x8
   2fe78:	mov	x9, x23
   2fe7c:	subs	x10, x9, #0x1
   2fe80:	b.lt	30014 <__gmpn_gcd_subdiv_step@@Base+0x2ec>  // b.tstop
   2fe84:	ldr	x11, [x8, x9, lsl #3]
   2fe88:	add	x9, x25, x9, lsl #3
   2fe8c:	ldur	x9, [x9, #-8]
   2fe90:	cmp	x11, x9
   2fe94:	mov	x9, x10
   2fe98:	b.eq	2fe7c <__gmpn_gcd_subdiv_step@@Base+0x154>  // b.none
   2fe9c:	ldr	x8, [sp, #8]
   2fea0:	adrp	x3, 54000 <__gmpn_bases@@Base+0x2938>
   2fea4:	add	x3, x3, #0x730
   2fea8:	mov	w4, #0x1                   	// #1
   2feac:	mov	x0, x20
   2feb0:	mov	x1, xzr
   2feb4:	mov	x2, xzr
   2feb8:	mov	w5, w27
   2febc:	mov	x19, x21
   2fec0:	cset	w21, hi  // hi = pmore
   2fec4:	blr	x8
   2fec8:	mov	x24, x23
   2fecc:	b	2ff80 <__gmpn_gcd_subdiv_step@@Base+0x258>
   2fed0:	cbnz	x22, 300a0 <__gmpn_gcd_subdiv_step@@Base+0x378>
   2fed4:	eor	w5, w27, #0x1
   2fed8:	mov	x0, x20
   2fedc:	mov	x1, x25
   2fee0:	b	2ff34 <__gmpn_gcd_subdiv_step@@Base+0x20c>
   2fee4:	cbz	x28, 3000c <__gmpn_gcd_subdiv_step@@Base+0x2e4>
   2fee8:	mov	x0, x25
   2feec:	mov	x1, x26
   2fef0:	mov	x2, x25
   2fef4:	mov	x3, x28
   2fef8:	bl	ca90 <__gmpn_add_n@plt>
   2fefc:	cbz	x0, 30038 <__gmpn_gcd_subdiv_step@@Base+0x310>
   2ff00:	cmp	x28, x23
   2ff04:	b.ge	30070 <__gmpn_gcd_subdiv_step@@Base+0x348>  // b.tcont
   2ff08:	ldr	x8, [x26, x28, lsl #3]
   2ff0c:	adds	x9, x8, #0x1
   2ff10:	add	x8, x28, #0x1
   2ff14:	str	x9, [x25, x28, lsl #3]
   2ff18:	mov	x28, x8
   2ff1c:	b.cs	2ff00 <__gmpn_gcd_subdiv_step@@Base+0x1d8>  // b.hs, b.nlast
   2ff20:	b	3003c <__gmpn_gcd_subdiv_step@@Base+0x314>
   2ff24:	cbnz	x22, 300a0 <__gmpn_gcd_subdiv_step@@Base+0x378>
   2ff28:	mov	w5, #0xffffffff            	// #-1
   2ff2c:	mov	x0, x20
   2ff30:	mov	x1, x8
   2ff34:	mov	x2, x24
   2ff38:	mov	x3, xzr
   2ff3c:	mov	x4, xzr
   2ff40:	blr	x19
   2ff44:	b	300a0 <__gmpn_gcd_subdiv_step@@Base+0x378>
   2ff48:	ldr	x8, [sp, #8]
   2ff4c:	adrp	x3, 54000 <__gmpn_bases@@Base+0x2938>
   2ff50:	add	x3, x3, #0x730
   2ff54:	mov	w4, #0x1                   	// #1
   2ff58:	mov	x0, x20
   2ff5c:	mov	x1, xzr
   2ff60:	mov	x2, xzr
   2ff64:	mov	w5, w27
   2ff68:	mov	x19, x21
   2ff6c:	blr	x8
   2ff70:	cmp	x23, x28
   2ff74:	csel	x24, x28, x23, gt
   2ff78:	csel	x23, x23, x28, gt
   2ff7c:	cset	w21, gt
   2ff80:	cmp	w21, #0x0
   2ff84:	csel	x28, x26, x25, ne  // ne = any
   2ff88:	csel	x26, x25, x26, ne  // ne = any
   2ff8c:	mov	x0, x19
   2ff90:	mov	x1, x28
   2ff94:	mov	x2, xzr
   2ff98:	mov	x3, x28
   2ff9c:	mov	x4, x23
   2ffa0:	mov	x5, x26
   2ffa4:	mov	x6, x24
   2ffa8:	eor	w25, w27, w21
   2ffac:	bl	bf10 <__gmpn_tdiv_qr@plt>
   2ffb0:	ldr	x10, [sp, #8]
   2ffb4:	sub	x8, x23, x24
   2ffb8:	add	x23, x8, #0x1
   2ffbc:	mov	x8, x24
   2ffc0:	mov	x27, x8
   2ffc4:	subs	x8, x8, #0x1
   2ffc8:	b.lt	2ffe0 <__gmpn_gcd_subdiv_step@@Base+0x2b8>  // b.tstop
   2ffcc:	add	x9, x28, x27, lsl #3
   2ffd0:	ldur	x9, [x9, #-8]
   2ffd4:	cbz	x9, 2ffc0 <__gmpn_gcd_subdiv_step@@Base+0x298>
   2ffd8:	mov	w8, #0x1                   	// #1
   2ffdc:	b	2ffe4 <__gmpn_gcd_subdiv_step@@Base+0x2bc>
   2ffe0:	mov	w8, wzr
   2ffe4:	cmp	x27, x22
   2ffe8:	b.le	300c8 <__gmpn_gcd_subdiv_step@@Base+0x3a0>
   2ffec:	mov	x0, x20
   2fff0:	mov	x1, xzr
   2fff4:	mov	x2, xzr
   2fff8:	mov	x3, x19
   2fffc:	mov	x4, x23
   30000:	mov	w5, w25
   30004:	blr	x10
   30008:	b	300a4 <__gmpn_gcd_subdiv_step@@Base+0x37c>
   3000c:	mov	x8, xzr
   30010:	b	3003c <__gmpn_gcd_subdiv_step@@Base+0x314>
   30014:	cmp	x22, #0x1
   30018:	b.lt	30080 <__gmpn_gcd_subdiv_step@@Base+0x358>  // b.tstop
   3001c:	adrp	x3, 54000 <__gmpn_bases@@Base+0x2938>
   30020:	add	x3, x3, #0x730
   30024:	mov	w4, #0x1                   	// #1
   30028:	mov	x0, x20
   3002c:	mov	x1, xzr
   30030:	mov	x2, xzr
   30034:	b	30094 <__gmpn_gcd_subdiv_step@@Base+0x36c>
   30038:	mov	x8, x28
   3003c:	cmp	x25, x26
   30040:	mov	x24, xzr
   30044:	b.eq	300a4 <__gmpn_gcd_subdiv_step@@Base+0x37c>  // b.none
   30048:	cmp	x8, x23
   3004c:	b.ge	300a4 <__gmpn_gcd_subdiv_step@@Base+0x37c>  // b.tcont
   30050:	sub	x9, x23, x8
   30054:	add	x10, x25, x8, lsl #3
   30058:	add	x8, x26, x8, lsl #3
   3005c:	ldr	x11, [x8], #8
   30060:	subs	x9, x9, #0x1
   30064:	str	x11, [x10], #8
   30068:	b.ne	3005c <__gmpn_gcd_subdiv_step@@Base+0x334>  // b.any
   3006c:	b	300a0 <__gmpn_gcd_subdiv_step@@Base+0x378>
   30070:	mov	w8, #0x1                   	// #1
   30074:	mov	x24, xzr
   30078:	str	x8, [x25, x23, lsl #3]
   3007c:	b	300a4 <__gmpn_gcd_subdiv_step@@Base+0x37c>
   30080:	mov	x0, x20
   30084:	mov	x1, x25
   30088:	mov	x2, x23
   3008c:	mov	x3, xzr
   30090:	mov	x4, xzr
   30094:	mov	w5, w27
   30098:	ldr	x8, [sp, #8]
   3009c:	blr	x8
   300a0:	mov	x24, xzr
   300a4:	mov	x0, x24
   300a8:	ldp	x20, x19, [sp, #96]
   300ac:	ldp	x22, x21, [sp, #80]
   300b0:	ldp	x24, x23, [sp, #64]
   300b4:	ldp	x26, x25, [sp, #48]
   300b8:	ldp	x28, x27, [sp, #32]
   300bc:	ldp	x29, x30, [sp, #16]
   300c0:	add	sp, sp, #0x70
   300c4:	ret
   300c8:	cbz	x22, 3010c <__gmpn_gcd_subdiv_step@@Base+0x3e4>
   300cc:	cbz	w8, 30128 <__gmpn_gcd_subdiv_step@@Base+0x400>
   300d0:	mov	x0, x28
   300d4:	mov	x1, x26
   300d8:	mov	x2, x28
   300dc:	mov	x3, x27
   300e0:	bl	ca90 <__gmpn_add_n@plt>
   300e4:	cbz	x0, 3013c <__gmpn_gcd_subdiv_step@@Base+0x414>
   300e8:	cmp	x27, x24
   300ec:	b.ge	30168 <__gmpn_gcd_subdiv_step@@Base+0x440>  // b.tcont
   300f0:	ldr	x8, [x26, x27, lsl #3]
   300f4:	adds	x9, x8, #0x1
   300f8:	add	x8, x27, #0x1
   300fc:	str	x9, [x28, x27, lsl #3]
   30100:	mov	x27, x8
   30104:	b.cs	300e8 <__gmpn_gcd_subdiv_step@@Base+0x3c0>  // b.hs, b.nlast
   30108:	b	30140 <__gmpn_gcd_subdiv_step@@Base+0x418>
   3010c:	mov	x0, x20
   30110:	mov	x1, x26
   30114:	mov	x2, x24
   30118:	mov	x3, x19
   3011c:	mov	x4, x23
   30120:	mov	w5, w25
   30124:	b	30098 <__gmpn_gcd_subdiv_step@@Base+0x370>
   30128:	mov	x0, x28
   3012c:	mov	x1, x26
   30130:	mov	x2, x24
   30134:	bl	ca70 <__gmpn_copyi@plt>
   30138:	b	30178 <__gmpn_gcd_subdiv_step@@Base+0x450>
   3013c:	mov	x8, x27
   30140:	cmp	x28, x26
   30144:	b.eq	30178 <__gmpn_gcd_subdiv_step@@Base+0x450>  // b.none
   30148:	cmp	x8, x24
   3014c:	b.ge	30178 <__gmpn_gcd_subdiv_step@@Base+0x450>  // b.tcont
   30150:	ldr	x9, [x26, x8, lsl #3]
   30154:	str	x9, [x28, x8, lsl #3]
   30158:	add	x8, x8, #0x1
   3015c:	cmp	x24, x8
   30160:	b.ne	30150 <__gmpn_gcd_subdiv_step@@Base+0x428>  // b.any
   30164:	b	30178 <__gmpn_gcd_subdiv_step@@Base+0x450>
   30168:	add	x8, x24, #0x1
   3016c:	mov	w9, #0x1                   	// #1
   30170:	str	x9, [x28, x24, lsl #3]
   30174:	mov	x24, x8
   30178:	mov	x8, x19
   3017c:	ldr	x9, [x8]
   30180:	sub	x10, x9, #0x1
   30184:	str	x10, [x8], #8
   30188:	cbz	x9, 3017c <__gmpn_gcd_subdiv_step@@Base+0x454>
   3018c:	ldr	x10, [sp, #8]
   30190:	b	2ffec <__gmpn_gcd_subdiv_step@@Base+0x2c4>

0000000000030194 <__gmpn_gcdext_hook@@Base>:
   30194:	stp	x29, x30, [sp, #-96]!
   30198:	stp	x26, x25, [sp, #32]
   3019c:	stp	x24, x23, [sp, #48]
   301a0:	stp	x22, x21, [sp, #64]
   301a4:	stp	x20, x19, [sp, #80]
   301a8:	ldr	x20, [x0, #32]
   301ac:	mov	w21, w5
   301b0:	mov	x19, x0
   301b4:	str	x27, [sp, #16]
   301b8:	mov	x29, sp
   301bc:	cbz	x1, 30204 <__gmpn_gcdext_hook@@Base+0x70>
   301c0:	ldr	x0, [x19]
   301c4:	mov	x23, x2
   301c8:	bl	ca70 <__gmpn_copyi@plt>
   301cc:	str	x23, [x19, #8]
   301d0:	tbz	w21, #31, 30280 <__gmpn_gcdext_hook@@Base+0xec>
   301d4:	sub	x8, x20, #0x1
   301d8:	add	x9, x8, #0x1
   301dc:	cmp	x9, #0x1
   301e0:	b.lt	3027c <__gmpn_gcdext_hook@@Base+0xe8>  // b.tstop
   301e4:	ldp	x9, x10, [x19, #40]
   301e8:	ldr	x9, [x9, x8, lsl #3]
   301ec:	ldr	x10, [x10, x8, lsl #3]
   301f0:	sub	x8, x8, #0x1
   301f4:	cmp	x9, x10
   301f8:	b.eq	301d8 <__gmpn_gcdext_hook@@Base+0x44>  // b.none
   301fc:	cset	w21, ls  // ls = plast
   30200:	b	30280 <__gmpn_gcdext_hook@@Base+0xec>
   30204:	add	x10, x3, x4, lsl #3
   30208:	ldp	x8, x9, [x19, #40]
   3020c:	ldur	x10, [x10, #-8]
   30210:	cmp	w21, #0x0
   30214:	mov	x22, x4
   30218:	csel	x21, x8, x9, eq  // eq = none
   3021c:	csel	x8, x9, x8, eq  // eq = none
   30220:	cmp	x10, #0x0
   30224:	cset	w9, eq  // eq = none
   30228:	sub	x4, x4, x9
   3022c:	csetm	x26, eq  // eq = none
   30230:	cmp	x4, #0x1
   30234:	b.ne	3025c <__gmpn_gcdext_hook@@Base+0xc8>  // b.any
   30238:	ldr	x3, [x3]
   3023c:	mov	x0, x21
   30240:	cmp	x3, #0x1
   30244:	b.ne	302cc <__gmpn_gcdext_hook@@Base+0x138>  // b.any
   30248:	mov	x1, x21
   3024c:	mov	x2, x8
   30250:	mov	x3, x20
   30254:	bl	ca90 <__gmpn_add_n@plt>
   30258:	b	3042c <__gmpn_gcdext_hook@@Base+0x298>
   3025c:	sub	x9, x8, #0x8
   30260:	mov	x10, x20
   30264:	mov	x24, x10
   30268:	subs	x10, x10, #0x1
   3026c:	b.lt	302dc <__gmpn_gcdext_hook@@Base+0x148>  // b.tstop
   30270:	ldr	x11, [x9, x24, lsl #3]
   30274:	cbz	x11, 30264 <__gmpn_gcdext_hook@@Base+0xd0>
   30278:	b	302e0 <__gmpn_gcdext_hook@@Base+0x14c>
   3027c:	mov	w21, wzr
   30280:	cmp	w21, #0x0
   30284:	mov	w8, #0x30                  	// #48
   30288:	mov	w9, #0x28                  	// #40
   3028c:	csel	x8, x9, x8, ne  // ne = any
   30290:	ldr	x1, [x19, x8]
   30294:	mov	x22, x20
   30298:	subs	x20, x20, #0x1
   3029c:	b.lt	302ac <__gmpn_gcdext_hook@@Base+0x118>  // b.tstop
   302a0:	add	x8, x1, x22, lsl #3
   302a4:	ldur	x8, [x8, #-8]
   302a8:	cbz	x8, 30294 <__gmpn_gcdext_hook@@Base+0x100>
   302ac:	ldr	x0, [x19, #16]
   302b0:	mov	x2, x22
   302b4:	bl	ca70 <__gmpn_copyi@plt>
   302b8:	ldr	x8, [x19, #24]
   302bc:	cmp	w21, #0x0
   302c0:	cneg	x9, x22, ne  // ne = any
   302c4:	str	x9, [x8]
   302c8:	b	3043c <__gmpn_gcdext_hook@@Base+0x2a8>
   302cc:	mov	x1, x8
   302d0:	mov	x2, x20
   302d4:	bl	d420 <__gmpn_addmul_1@plt>
   302d8:	b	3042c <__gmpn_gcdext_hook@@Base+0x298>
   302dc:	cbz	x24, 3043c <__gmpn_gcdext_hook@@Base+0x2a8>
   302e0:	ldr	x25, [x19, #56]
   302e4:	cmp	x4, x24
   302e8:	mov	x0, x25
   302ec:	b.le	30304 <__gmpn_gcdext_hook@@Base+0x170>
   302f0:	mov	x1, x3
   302f4:	mov	x2, x4
   302f8:	mov	x3, x8
   302fc:	mov	x4, x24
   30300:	b	3030c <__gmpn_gcdext_hook@@Base+0x178>
   30304:	mov	x1, x8
   30308:	mov	x2, x24
   3030c:	bl	ccf0 <__gmpn_mul@plt>
   30310:	lsl	x8, x22, #3
   30314:	add	x8, x8, x26, lsl #3
   30318:	add	x8, x8, x25
   3031c:	add	x8, x8, x24, lsl #3
   30320:	ldur	x8, [x8, #-8]
   30324:	add	x9, x22, x26
   30328:	cmp	x8, #0x0
   3032c:	cset	w8, eq  // eq = none
   30330:	sub	x9, x9, x8
   30334:	add	x23, x9, x24
   30338:	csetm	x27, eq  // eq = none
   3033c:	cmp	x23, x20
   30340:	b.ge	30398 <__gmpn_gcdext_hook@@Base+0x204>  // b.tcont
   30344:	sub	x8, x26, x8
   30348:	add	x8, x8, x22
   3034c:	add	x8, x8, x24
   30350:	cbz	x8, 30390 <__gmpn_gcdext_hook@@Base+0x1fc>
   30354:	mov	x0, x21
   30358:	mov	x1, x21
   3035c:	mov	x2, x25
   30360:	mov	x3, x23
   30364:	bl	ca90 <__gmpn_add_n@plt>
   30368:	cbz	x0, 3042c <__gmpn_gcdext_hook@@Base+0x298>
   3036c:	mov	w0, #0x1                   	// #1
   30370:	cmp	x23, x20
   30374:	b.ge	3042c <__gmpn_gcdext_hook@@Base+0x298>  // b.tcont
   30378:	ldr	x8, [x21, x23, lsl #3]
   3037c:	add	x9, x23, #0x1
   30380:	adds	x8, x8, #0x1
   30384:	str	x8, [x21, x23, lsl #3]
   30388:	mov	x23, x9
   3038c:	b.cs	30370 <__gmpn_gcdext_hook@@Base+0x1dc>  // b.hs, b.nlast
   30390:	mov	x0, xzr
   30394:	b	3042c <__gmpn_gcdext_hook@@Base+0x298>
   30398:	cbz	x20, 303dc <__gmpn_gcdext_hook@@Base+0x248>
   3039c:	mov	x0, x21
   303a0:	mov	x1, x25
   303a4:	mov	x2, x21
   303a8:	mov	x3, x20
   303ac:	bl	ca90 <__gmpn_add_n@plt>
   303b0:	cbz	x0, 303e4 <__gmpn_gcdext_hook@@Base+0x250>
   303b4:	mov	w0, #0x1                   	// #1
   303b8:	cmp	x20, x23
   303bc:	b.ge	30428 <__gmpn_gcdext_hook@@Base+0x294>  // b.tcont
   303c0:	ldr	x8, [x25, x20, lsl #3]
   303c4:	adds	x9, x8, #0x1
   303c8:	add	x8, x20, #0x1
   303cc:	str	x9, [x21, x20, lsl #3]
   303d0:	mov	x20, x8
   303d4:	b.cs	303b8 <__gmpn_gcdext_hook@@Base+0x224>  // b.hs, b.nlast
   303d8:	b	303e8 <__gmpn_gcdext_hook@@Base+0x254>
   303dc:	mov	x8, xzr
   303e0:	b	303e8 <__gmpn_gcdext_hook@@Base+0x254>
   303e4:	mov	x8, x20
   303e8:	cmp	x21, x25
   303ec:	mov	x0, xzr
   303f0:	b.eq	30428 <__gmpn_gcdext_hook@@Base+0x294>  // b.none
   303f4:	cmp	x8, x23
   303f8:	b.ge	30428 <__gmpn_gcdext_hook@@Base+0x294>  // b.tcont
   303fc:	sub	x10, x27, x8
   30400:	add	x11, x22, x26
   30404:	add	x10, x10, x11
   30408:	add	x9, x21, x8, lsl #3
   3040c:	add	x10, x10, x24
   30410:	add	x8, x25, x8, lsl #3
   30414:	ldr	x11, [x8], #8
   30418:	subs	x10, x10, #0x1
   3041c:	str	x11, [x9], #8
   30420:	b.ne	30414 <__gmpn_gcdext_hook@@Base+0x280>  // b.any
   30424:	mov	x0, xzr
   30428:	mov	x20, x23
   3042c:	cmp	x0, #0x0
   30430:	cinc	x8, x20, ne  // ne = any
   30434:	str	x0, [x21, x20, lsl #3]
   30438:	str	x8, [x19, #32]
   3043c:	ldp	x20, x19, [sp, #80]
   30440:	ldp	x22, x21, [sp, #64]
   30444:	ldp	x24, x23, [sp, #48]
   30448:	ldp	x26, x25, [sp, #32]
   3044c:	ldr	x27, [sp, #16]
   30450:	ldp	x29, x30, [sp], #96
   30454:	ret

0000000000030458 <__gmpn_gcdext_lehmer_n@@Base>:
   30458:	sub	sp, sp, #0xe0
   3045c:	stp	x28, x27, [sp, #144]
   30460:	stp	x26, x25, [sp, #160]
   30464:	stp	x24, x23, [sp, #176]
   30468:	stp	x20, x19, [sp, #208]
   3046c:	mov	x19, x6
   30470:	mov	x26, x5
   30474:	mov	x27, x4
   30478:	mov	x28, x3
   3047c:	mov	x23, x2
   30480:	mov	x24, x1
   30484:	adds	x20, x5, #0x1
   30488:	mov	x25, x0
   3048c:	stp	x29, x30, [sp, #128]
   30490:	stp	x22, x21, [sp, #192]
   30494:	add	x29, sp, #0x80
   30498:	b.cs	304b4 <__gmpn_gcdext_lehmer_n@@Base+0x5c>  // b.hs, b.nlast
   3049c:	mov	w8, #0x18                  	// #24
   304a0:	orr	x9, xzr, #0x18
   304a4:	madd	x2, x26, x8, x9
   304a8:	mov	x0, x19
   304ac:	mov	w1, wzr
   304b0:	bl	c610 <memset@plt>
   304b4:	add	x22, x19, x20, lsl #3
   304b8:	mov	w21, #0x1                   	// #1
   304bc:	cmp	x26, #0x2
   304c0:	str	x21, [x22]
   304c4:	stp	x25, x24, [sp, #8]
   304c8:	str	x25, [sp, #64]
   304cc:	stp	x24, x23, [sp, #80]
   304d0:	str	x23, [sp]
   304d4:	b.lt	30640 <__gmpn_gcdext_lehmer_n@@Base+0x1e8>  // b.tstop
   304d8:	add	x23, x22, x20, lsl #3
   304dc:	mov	w21, #0x1                   	// #1
   304e0:	add	x20, x23, x20, lsl #3
   304e4:	mov	x25, x26
   304e8:	mov	x24, x19
   304ec:	lsl	x9, x25, #3
   304f0:	sub	x8, x9, #0x8
   304f4:	ldr	x0, [x28, x8]
   304f8:	ldr	x2, [x27, x8]
   304fc:	orr	x8, x2, x0
   30500:	tbnz	x8, #63, 30540 <__gmpn_gcdext_lehmer_n@@Base+0xe8>
   30504:	cmp	x25, #0x2
   30508:	clz	x8, x8
   3050c:	b.ne	30550 <__gmpn_gcdext_lehmer_n@@Base+0xf8>  // b.any
   30510:	ldp	x10, x9, [x28]
   30514:	ldp	x13, x12, [x27]
   30518:	neg	x11, x8
   3051c:	lsl	x9, x9, x8
   30520:	lsr	x14, x10, x11
   30524:	lsl	x1, x10, x8
   30528:	lsl	x10, x12, x8
   3052c:	lsr	x11, x13, x11
   30530:	orr	x0, x14, x9
   30534:	orr	x2, x11, x10
   30538:	lsl	x3, x13, x8
   3053c:	b	3059c <__gmpn_gcdext_lehmer_n@@Base+0x144>
   30540:	sub	x8, x9, #0x10
   30544:	ldr	x1, [x28, x8]
   30548:	ldr	x3, [x27, x8]
   3054c:	b	3059c <__gmpn_gcdext_lehmer_n@@Base+0x144>
   30550:	sub	x11, x9, #0x10
   30554:	sub	x9, x9, #0x18
   30558:	ldr	x14, [x28, x11]
   3055c:	ldr	x15, [x28, x9]
   30560:	ldr	x11, [x27, x11]
   30564:	ldr	x9, [x27, x9]
   30568:	neg	x12, x8
   3056c:	lsl	x10, x0, x8
   30570:	lsl	x13, x2, x8
   30574:	lsr	x16, x14, x12
   30578:	lsl	x14, x14, x8
   3057c:	lsr	x15, x15, x12
   30580:	lsl	x8, x11, x8
   30584:	lsr	x11, x11, x12
   30588:	lsr	x9, x9, x12
   3058c:	orr	x0, x16, x10
   30590:	orr	x1, x15, x14
   30594:	orr	x2, x11, x13
   30598:	orr	x3, x9, x8
   3059c:	add	x4, sp, #0x20
   305a0:	bl	c5c0 <__gmpn_hgcd2@plt>
   305a4:	cbz	w0, 305fc <__gmpn_gcdext_lehmer_n@@Base+0x1a4>
   305a8:	add	x0, sp, #0x20
   305ac:	mov	x1, x20
   305b0:	mov	x2, x28
   305b4:	mov	x3, x27
   305b8:	mov	x4, x25
   305bc:	bl	c510 <__gmpn_matrix22_mul1_inverse_vector@plt>
   305c0:	mov	x25, x0
   305c4:	add	x0, sp, #0x20
   305c8:	mov	x1, x23
   305cc:	mov	x2, x24
   305d0:	mov	x3, x22
   305d4:	mov	x4, x21
   305d8:	bl	d460 <__gmpn_hgcd_mul_matrix1_vector@plt>
   305dc:	mov	x21, x0
   305e0:	mov	x0, x24
   305e4:	mov	x1, x28
   305e8:	mov	x28, x20
   305ec:	mov	x24, x23
   305f0:	mov	x20, x1
   305f4:	mov	x23, x0
   305f8:	b	30634 <__gmpn_gcdext_lehmer_n@@Base+0x1dc>
   305fc:	stp	x22, x23, [sp, #112]
   30600:	stp	x21, x24, [sp, #96]
   30604:	adrp	x4, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   30608:	ldr	x4, [x4, #3968]
   3060c:	add	x5, sp, #0x40
   30610:	mov	x0, x28
   30614:	mov	x1, x27
   30618:	mov	x2, x25
   3061c:	mov	x3, xzr
   30620:	mov	x6, x20
   30624:	bl	d2d0 <__gmpn_gcd_subdiv_step@plt>
   30628:	cbz	x0, 30760 <__gmpn_gcdext_lehmer_n@@Base+0x308>
   3062c:	ldr	x21, [sp, #96]
   30630:	mov	x25, x0
   30634:	cmp	x25, #0x1
   30638:	b.gt	304ec <__gmpn_gcdext_lehmer_n@@Base+0x94>
   3063c:	b	30644 <__gmpn_gcdext_lehmer_n@@Base+0x1ec>
   30640:	mov	x24, x19
   30644:	ldr	x2, [x28]
   30648:	cbz	x2, 3084c <__gmpn_gcdext_lehmer_n@@Base+0x3f4>
   3064c:	ldr	x3, [x27]
   30650:	ldp	x20, x23, [sp, #8]
   30654:	cbz	x3, 30864 <__gmpn_gcdext_lehmer_n@@Base+0x40c>
   30658:	cmp	x2, x3
   3065c:	b.ne	306f4 <__gmpn_gcdext_lehmer_n@@Base+0x29c>  // b.any
   30660:	add	x8, x19, x26, lsl #3
   30664:	mov	x9, x21
   30668:	str	x2, [x20]
   3066c:	subs	x10, x9, #0x1
   30670:	b.lt	30690 <__gmpn_gcdext_lehmer_n@@Base+0x238>  // b.tstop
   30674:	add	x11, x24, x9, lsl #3
   30678:	ldur	x11, [x11, #-8]
   3067c:	ldr	x9, [x8, x9, lsl #3]
   30680:	cmp	x11, x9
   30684:	mov	x9, x10
   30688:	b.eq	3066c <__gmpn_gcdext_lehmer_n@@Base+0x214>  // b.none
   3068c:	b.ls	306bc <__gmpn_gcdext_lehmer_n@@Base+0x264>  // b.plast
   30690:	add	x8, x19, x26, lsl #3
   30694:	ldr	x10, [x8, x21, lsl #3]
   30698:	sub	x9, x21, #0x1
   3069c:	mov	x21, x9
   306a0:	cbz	x10, 30694 <__gmpn_gcdext_lehmer_n@@Base+0x23c>
   306a4:	add	x19, x9, #0x1
   306a8:	mov	x0, x23
   306ac:	mov	x1, x22
   306b0:	mov	x2, x19
   306b4:	bl	ca70 <__gmpn_copyi@plt>
   306b8:	b	306e8 <__gmpn_gcdext_lehmer_n@@Base+0x290>
   306bc:	mov	x19, x21
   306c0:	subs	x21, x21, #0x1
   306c4:	b.lt	306d4 <__gmpn_gcdext_lehmer_n@@Base+0x27c>  // b.tstop
   306c8:	add	x8, x24, x19, lsl #3
   306cc:	ldur	x8, [x8, #-8]
   306d0:	cbz	x8, 306bc <__gmpn_gcdext_lehmer_n@@Base+0x264>
   306d4:	mov	x0, x23
   306d8:	mov	x1, x24
   306dc:	mov	x2, x19
   306e0:	bl	ca70 <__gmpn_copyi@plt>
   306e4:	neg	x19, x19
   306e8:	ldr	x8, [sp]
   306ec:	str	x19, [x8]
   306f0:	b	30828 <__gmpn_gcdext_lehmer_n@@Base+0x3d0>
   306f4:	add	x0, sp, #0x20
   306f8:	add	x1, sp, #0x18
   306fc:	bl	d160 <__gmpn_gcdext_1@plt>
   30700:	str	x0, [x20]
   30704:	ldr	x3, [sp, #32]
   30708:	cbz	x3, 30738 <__gmpn_gcdext_lehmer_n@@Base+0x2e0>
   3070c:	ldr	x8, [sp, #24]
   30710:	cbz	x8, 30768 <__gmpn_gcdext_lehmer_n@@Base+0x310>
   30714:	cmp	x3, #0x1
   30718:	b.lt	30798 <__gmpn_gcdext_lehmer_n@@Base+0x340>  // b.tstop
   3071c:	neg	x8, x8
   30720:	mov	w20, wzr
   30724:	str	x8, [sp, #24]
   30728:	b	307a4 <__gmpn_gcdext_lehmer_n@@Base+0x34c>
   3072c:	add	x8, x24, x19, lsl #3
   30730:	ldur	x8, [x8, #-8]
   30734:	cbnz	x8, 30744 <__gmpn_gcdext_lehmer_n@@Base+0x2ec>
   30738:	mov	x19, x21
   3073c:	subs	x21, x21, #0x1
   30740:	b.ge	3072c <__gmpn_gcdext_lehmer_n@@Base+0x2d4>  // b.tcont
   30744:	mov	x0, x23
   30748:	mov	x1, x24
   3074c:	mov	x2, x19
   30750:	bl	ca70 <__gmpn_copyi@plt>
   30754:	ldr	x11, [sp]
   30758:	neg	x19, x19
   3075c:	b	30824 <__gmpn_gcdext_lehmer_n@@Base+0x3cc>
   30760:	ldr	x0, [sp, #72]
   30764:	b	3082c <__gmpn_gcdext_lehmer_n@@Base+0x3d4>
   30768:	add	x8, x19, x26, lsl #3
   3076c:	mov	x19, x21
   30770:	subs	x21, x21, #0x1
   30774:	b.lt	30780 <__gmpn_gcdext_lehmer_n@@Base+0x328>  // b.tstop
   30778:	ldr	x9, [x8, x19, lsl #3]
   3077c:	cbz	x9, 3076c <__gmpn_gcdext_lehmer_n@@Base+0x314>
   30780:	mov	x0, x23
   30784:	mov	x1, x22
   30788:	mov	x2, x19
   3078c:	bl	ca70 <__gmpn_copyi@plt>
   30790:	ldr	x11, [sp]
   30794:	b	30824 <__gmpn_gcdext_lehmer_n@@Base+0x3cc>
   30798:	neg	x3, x3
   3079c:	mov	w20, #0x1                   	// #1
   307a0:	str	x3, [sp, #32]
   307a4:	mov	x0, x23
   307a8:	mov	x1, x22
   307ac:	mov	x2, x21
   307b0:	bl	d4b0 <__gmpn_mul_1@plt>
   307b4:	ldr	x3, [sp, #24]
   307b8:	mov	x19, x0
   307bc:	mov	x0, x23
   307c0:	mov	x1, x24
   307c4:	mov	x2, x21
   307c8:	bl	d420 <__gmpn_addmul_1@plt>
   307cc:	orr	x8, x0, x19
   307d0:	cbz	x8, 307f8 <__gmpn_gcdext_lehmer_n@@Base+0x3a0>
   307d4:	ldr	x11, [sp]
   307d8:	adds	x9, x0, x19
   307dc:	add	x8, x21, #0x1
   307e0:	str	x9, [x23, x21, lsl #3]
   307e4:	b.cc	30800 <__gmpn_gcdext_lehmer_n@@Base+0x3a8>  // b.lo, b.ul, b.last
   307e8:	add	x21, x21, #0x2
   307ec:	mov	w9, #0x1                   	// #1
   307f0:	str	x9, [x23, x8, lsl #3]
   307f4:	b	30804 <__gmpn_gcdext_lehmer_n@@Base+0x3ac>
   307f8:	ldr	x11, [sp]
   307fc:	b	30804 <__gmpn_gcdext_lehmer_n@@Base+0x3ac>
   30800:	mov	x21, x8
   30804:	sub	x8, x23, #0x8
   30808:	ldr	x10, [x8, x21, lsl #3]
   3080c:	sub	x9, x21, #0x1
   30810:	mov	x21, x9
   30814:	cbz	x10, 30808 <__gmpn_gcdext_lehmer_n@@Base+0x3b0>
   30818:	mvn	x8, x9
   3081c:	cmp	w20, #0x0
   30820:	csinc	x19, x8, x9, ne  // ne = any
   30824:	str	x19, [x11]
   30828:	mov	w0, #0x1                   	// #1
   3082c:	ldp	x20, x19, [sp, #208]
   30830:	ldp	x22, x21, [sp, #192]
   30834:	ldp	x24, x23, [sp, #176]
   30838:	ldp	x26, x25, [sp, #160]
   3083c:	ldp	x28, x27, [sp, #144]
   30840:	ldp	x29, x30, [sp, #128]
   30844:	add	sp, sp, #0xe0
   30848:	ret
   3084c:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   30850:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   30854:	add	x0, x0, #0x738
   30858:	add	x2, x2, #0x748
   3085c:	mov	w1, #0xf9                  	// #249
   30860:	bl	c6e0 <__gmp_assert_fail@plt>
   30864:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   30868:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   3086c:	add	x0, x0, #0x738
   30870:	add	x2, x2, #0x752
   30874:	mov	w1, #0xfa                  	// #250
   30878:	bl	c6e0 <__gmp_assert_fail@plt>

000000000003087c <__gmpn_div_q@@Base>:
   3087c:	stp	x29, x30, [sp, #-96]!
   30880:	stp	x28, x27, [sp, #16]
   30884:	stp	x26, x25, [sp, #32]
   30888:	stp	x24, x23, [sp, #48]
   3088c:	stp	x22, x21, [sp, #64]
   30890:	stp	x20, x19, [sp, #80]
   30894:	mov	x29, sp
   30898:	sub	sp, sp, #0x40
   3089c:	stur	xzr, [x29, #-16]
   308a0:	subs	x25, x4, #0x1
   308a4:	ldr	x28, [x3, x25, lsl #3]
   308a8:	mov	x21, x2
   308ac:	mov	x24, x1
   308b0:	mov	x19, x0
   308b4:	b.ne	308d4 <__gmpn_div_q@@Base+0x58>  // b.any
   308b8:	mov	x0, x19
   308bc:	mov	x1, xzr
   308c0:	mov	x2, x24
   308c4:	mov	x3, x21
   308c8:	mov	x4, x28
   308cc:	bl	cd20 <__gmpn_divrem_1@plt>
   308d0:	b	312a0 <__gmpn_div_q@@Base+0xa24>
   308d4:	sub	x22, x21, x4
   308d8:	add	x8, x22, #0x6
   308dc:	mov	x23, x5
   308e0:	mov	x20, x4
   308e4:	mov	x26, x3
   308e8:	cmp	x8, x4
   308ec:	stur	x3, [x29, #-24]
   308f0:	b.ge	309c4 <__gmpn_div_q@@Base+0x148>  // b.tcont
   308f4:	add	x8, x22, #0x2
   308f8:	stur	x8, [x29, #-32]
   308fc:	lsl	x26, x8, #3
   30900:	mov	w8, #0x7f00                	// #32512
   30904:	cmp	x26, x8
   30908:	add	x25, x22, #0x1
   3090c:	b.hi	30e60 <__gmpn_div_q@@Base+0x5e4>  // b.pmore
   30910:	add	x9, x26, #0xf
   30914:	mov	x8, sp
   30918:	and	x9, x9, #0xfffffffffffffff0
   3091c:	sub	x8, x8, x9
   30920:	stur	x8, [x29, #-56]
   30924:	mov	sp, x8
   30928:	mov	w27, #0x1                   	// #1
   3092c:	cmp	x23, x24
   30930:	bfi	x27, x25, #1, #63
   30934:	b.ne	30960 <__gmpn_div_q@@Base+0xe4>  // b.any
   30938:	lsl	x8, x27, #3
   3093c:	add	x1, x8, #0x8
   30940:	mov	w8, #0x7f00                	// #32512
   30944:	cmp	x1, x8
   30948:	b.hi	31000 <__gmpn_div_q@@Base+0x784>  // b.pmore
   3094c:	add	x9, x1, #0xf
   30950:	mov	x8, sp
   30954:	and	x9, x9, #0xfffffffffffffff0
   30958:	sub	x23, x8, x9
   3095c:	mov	sp, x23
   30960:	stur	x25, [x29, #-40]
   30964:	tbnz	x28, #63, 30e74 <__gmpn_div_q@@Base+0x5f8>
   30968:	clz	x28, x28
   3096c:	add	x8, x24, x21, lsl #3
   30970:	sub	x1, x8, x27, lsl #3
   30974:	mov	x0, x23
   30978:	mov	x2, x27
   3097c:	mov	w3, w28
   30980:	bl	c190 <__gmpn_lshift@plt>
   30984:	cmp	x0, #0x0
   30988:	mov	w8, #0x7f00                	// #32512
   3098c:	mov	x25, x0
   30990:	cset	w9, ne  // ne = any
   30994:	cinc	x10, x27, ne  // ne = any
   30998:	cmp	x26, x8
   3099c:	stur	x10, [x29, #-48]
   309a0:	str	x0, [x23, x27, lsl #3]
   309a4:	stur	x9, [x29, #-64]
   309a8:	b.hi	30a50 <__gmpn_div_q@@Base+0x1d4>  // b.pmore
   309ac:	add	x9, x26, #0xf
   309b0:	mov	x8, sp
   309b4:	and	x9, x9, #0xfffffffffffffff0
   309b8:	sub	x27, x8, x9
   309bc:	mov	sp, x27
   309c0:	b	30a60 <__gmpn_div_q@@Base+0x1e4>
   309c4:	tbnz	x28, #63, 30f04 <__gmpn_div_q@@Base+0x688>
   309c8:	clz	x27, x28
   309cc:	mov	x0, x23
   309d0:	mov	x1, x24
   309d4:	mov	x2, x21
   309d8:	mov	w3, w27
   309dc:	bl	c190 <__gmpn_lshift@plt>
   309e0:	cmp	x0, #0x0
   309e4:	lsl	x1, x20, #3
   309e8:	mov	w8, #0x7f00                	// #32512
   309ec:	mov	x24, x0
   309f0:	cinc	x28, x21, ne  // ne = any
   309f4:	cmp	x1, x8
   309f8:	str	x0, [x23, x21, lsl #3]
   309fc:	b.hi	30f40 <__gmpn_div_q@@Base+0x6c4>  // b.pmore
   30a00:	add	x9, x1, #0xf
   30a04:	mov	x8, sp
   30a08:	and	x9, x9, #0xfffffffffffffff0
   30a0c:	sub	x26, x8, x9
   30a10:	mov	sp, x26
   30a14:	ldur	x1, [x29, #-24]
   30a18:	mov	x0, x26
   30a1c:	mov	x2, x20
   30a20:	mov	w3, w27
   30a24:	bl	c190 <__gmpn_lshift@plt>
   30a28:	cmp	x20, #0x2
   30a2c:	b.ne	30b10 <__gmpn_div_q@@Base+0x294>  // b.any
   30a30:	mov	x0, x19
   30a34:	mov	x1, xzr
   30a38:	mov	x2, x23
   30a3c:	mov	x3, x28
   30a40:	mov	x4, x26
   30a44:	bl	c210 <__gmpn_divrem_2@plt>
   30a48:	cbnz	x24, 31298 <__gmpn_div_q@@Base+0xa1c>
   30a4c:	b	30e58 <__gmpn_div_q@@Base+0x5dc>
   30a50:	sub	x0, x29, #0x10
   30a54:	mov	x1, x26
   30a58:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   30a5c:	mov	x27, x0
   30a60:	ldp	x2, x26, [x29, #-32]
   30a64:	mov	x9, #0xfffffffffffffffe    	// #-2
   30a68:	sub	x9, x9, x22
   30a6c:	mov	x0, x27
   30a70:	add	x8, x26, x20, lsl #3
   30a74:	add	x1, x8, x9, lsl #3
   30a78:	mov	w3, w28
   30a7c:	bl	c190 <__gmpn_lshift@plt>
   30a80:	sub	x8, x20, x22
   30a84:	add	x8, x26, x8, lsl #3
   30a88:	ldur	x8, [x8, #-24]
   30a8c:	ldr	x9, [x27]
   30a90:	neg	x10, x28
   30a94:	lsr	x8, x8, x10
   30a98:	orr	x8, x9, x8
   30a9c:	str	x8, [x27]
   30aa0:	cbz	x22, 30bc4 <__gmpn_div_q@@Base+0x348>
   30aa4:	ldur	x28, [x29, #-56]
   30aa8:	cmp	x22, #0x95
   30aac:	b.le	30bec <__gmpn_div_q@@Base+0x370>
   30ab0:	cmp	x22, #0x3e3
   30ab4:	b.le	30cbc <__gmpn_div_q@@Base+0x440>
   30ab8:	ldur	x0, [x29, #-48]
   30abc:	ldur	x1, [x29, #-32]
   30ac0:	mov	w2, wzr
   30ac4:	bl	c0f0 <__gmpn_mu_divappr_q_itch@plt>
   30ac8:	lsl	x1, x0, #3
   30acc:	mov	w8, #0x7f00                	// #32512
   30ad0:	cmp	x1, x8
   30ad4:	b.hi	31180 <__gmpn_div_q@@Base+0x904>  // b.pmore
   30ad8:	add	x9, x1, #0xf
   30adc:	mov	x8, sp
   30ae0:	and	x9, x9, #0xfffffffffffffff0
   30ae4:	sub	x5, x8, x9
   30ae8:	mov	sp, x5
   30aec:	mov	x1, x23
   30af0:	ldur	x23, [x29, #-48]
   30af4:	ldur	x4, [x29, #-32]
   30af8:	mov	x0, x28
   30afc:	mov	x3, x27
   30b00:	mov	x2, x23
   30b04:	bl	c730 <__gmpn_mu_divappr_q@plt>
   30b08:	cbnz	x25, 30dd0 <__gmpn_div_q@@Base+0x554>
   30b0c:	b	31208 <__gmpn_div_q@@Base+0x98c>
   30b10:	cmp	x20, #0x98
   30b14:	b.lt	30c54 <__gmpn_div_q@@Base+0x3d8>  // b.tstop
   30b18:	sub	x8, x28, x20
   30b1c:	cmp	x8, #0x97
   30b20:	b.le	30c54 <__gmpn_div_q@@Base+0x3d8>
   30b24:	cmp	x21, #0x7cc
   30b28:	b.lt	30b5c <__gmpn_div_q@@Base+0x2e0>  // b.tstop
   30b2c:	adrp	x8, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   30b30:	adrp	x9, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   30b34:	ldr	d0, [x8, #840]
   30b38:	ldr	d1, [x9, #848]
   30b3c:	scvtf	d2, x20
   30b40:	scvtf	d3, x21
   30b44:	fmul	d0, d2, d0
   30b48:	fmul	d1, d3, d1
   30b4c:	fadd	d0, d1, d0
   30b50:	fmul	d1, d3, d2
   30b54:	fcmp	d0, d1
   30b58:	b.le	30e08 <__gmpn_div_q@@Base+0x58c>
   30b5c:	ldr	x21, [x26, x25, lsl #3]
   30b60:	mov	x0, x21
   30b64:	bl	d410 <__gmpn_invert_limb@plt>
   30b68:	add	x8, x26, x20, lsl #3
   30b6c:	ldur	x8, [x8, #-16]
   30b70:	mul	x9, x0, x21
   30b74:	adds	x9, x9, x8
   30b78:	b.cc	30b94 <__gmpn_div_q@@Base+0x318>  // b.lo, b.ul, b.last
   30b7c:	subs	x9, x9, x21
   30b80:	cset	w10, cs  // cs = hs, nlast
   30b84:	csel	x11, x21, xzr, cs  // cs = hs, nlast
   30b88:	mvn	x10, x10
   30b8c:	add	x0, x10, x0
   30b90:	sub	x9, x9, x11
   30b94:	umulh	x10, x8, x0
   30b98:	adds	x10, x10, x9
   30b9c:	b.cc	30d74 <__gmpn_div_q@@Base+0x4f8>  // b.lo, b.ul, b.last
   30ba0:	cmp	x10, x21
   30ba4:	sub	x9, x0, #0x1
   30ba8:	b.cc	30d78 <__gmpn_div_q@@Base+0x4fc>  // b.lo, b.ul, b.last
   30bac:	mul	x11, x0, x8
   30bb0:	cmp	x10, x21
   30bb4:	sub	x12, x0, #0x2
   30bb8:	ccmp	x11, x8, #0x2, ls  // ls = plast
   30bbc:	csel	x9, x9, x12, cc  // cc = lo, ul, last
   30bc0:	b	30d78 <__gmpn_div_q@@Base+0x4fc>
   30bc4:	ldur	x28, [x29, #-56]
   30bc8:	mov	x2, x23
   30bcc:	ldur	x23, [x29, #-48]
   30bd0:	mov	x1, xzr
   30bd4:	mov	x0, x28
   30bd8:	mov	x4, x27
   30bdc:	mov	x3, x23
   30be0:	bl	c210 <__gmpn_divrem_2@plt>
   30be4:	cbnz	x25, 30dd0 <__gmpn_div_q@@Base+0x554>
   30be8:	b	31208 <__gmpn_div_q@@Base+0x98c>
   30bec:	ldur	x8, [x29, #-40]
   30bf0:	ldr	x26, [x27, x8, lsl #3]
   30bf4:	mov	x0, x26
   30bf8:	bl	d410 <__gmpn_invert_limb@plt>
   30bfc:	ldr	x8, [x27, x22, lsl #3]
   30c00:	mul	x9, x0, x26
   30c04:	adds	x9, x9, x8
   30c08:	b.cc	30c24 <__gmpn_div_q@@Base+0x3a8>  // b.lo, b.ul, b.last
   30c0c:	subs	x9, x9, x26
   30c10:	cset	w10, cs  // cs = hs, nlast
   30c14:	csel	x11, x26, xzr, cs  // cs = hs, nlast
   30c18:	mvn	x10, x10
   30c1c:	add	x0, x10, x0
   30c20:	sub	x9, x9, x11
   30c24:	umulh	x10, x8, x0
   30c28:	adds	x9, x10, x9
   30c2c:	b.cc	30d24 <__gmpn_div_q@@Base+0x4a8>  // b.lo, b.ul, b.last
   30c30:	cmp	x9, x26
   30c34:	sub	x5, x0, #0x1
   30c38:	b.cc	30d28 <__gmpn_div_q@@Base+0x4ac>  // b.lo, b.ul, b.last
   30c3c:	mul	x10, x0, x8
   30c40:	cmp	x9, x26
   30c44:	sub	x11, x0, #0x2
   30c48:	ccmp	x10, x8, #0x2, ls  // ls = plast
   30c4c:	csel	x5, x5, x11, cc  // cc = lo, ul, last
   30c50:	b	30d28 <__gmpn_div_q@@Base+0x4ac>
   30c54:	ldr	x21, [x26, x25, lsl #3]
   30c58:	mov	x0, x21
   30c5c:	bl	d410 <__gmpn_invert_limb@plt>
   30c60:	add	x8, x26, x20, lsl #3
   30c64:	ldur	x8, [x8, #-16]
   30c68:	mul	x9, x0, x21
   30c6c:	adds	x9, x9, x8
   30c70:	b.cc	30c8c <__gmpn_div_q@@Base+0x410>  // b.lo, b.ul, b.last
   30c74:	subs	x9, x9, x21
   30c78:	cset	w10, cs  // cs = hs, nlast
   30c7c:	csel	x11, x21, xzr, cs  // cs = hs, nlast
   30c80:	mvn	x10, x10
   30c84:	add	x0, x10, x0
   30c88:	sub	x9, x9, x11
   30c8c:	umulh	x10, x8, x0
   30c90:	adds	x9, x10, x9
   30c94:	b.cc	30d4c <__gmpn_div_q@@Base+0x4d0>  // b.lo, b.ul, b.last
   30c98:	cmp	x9, x21
   30c9c:	sub	x5, x0, #0x1
   30ca0:	b.cc	30d50 <__gmpn_div_q@@Base+0x4d4>  // b.lo, b.ul, b.last
   30ca4:	mul	x10, x0, x8
   30ca8:	cmp	x9, x21
   30cac:	sub	x11, x0, #0x2
   30cb0:	ccmp	x10, x8, #0x2, ls  // ls = plast
   30cb4:	csel	x5, x5, x11, cc  // cc = lo, ul, last
   30cb8:	b	30d50 <__gmpn_div_q@@Base+0x4d4>
   30cbc:	ldur	x8, [x29, #-40]
   30cc0:	ldr	x26, [x27, x8, lsl #3]
   30cc4:	mov	x0, x26
   30cc8:	bl	d410 <__gmpn_invert_limb@plt>
   30ccc:	ldr	x8, [x27, x22, lsl #3]
   30cd0:	mul	x9, x0, x26
   30cd4:	adds	x9, x9, x8
   30cd8:	b.cc	30cf4 <__gmpn_div_q@@Base+0x478>  // b.lo, b.ul, b.last
   30cdc:	subs	x9, x9, x26
   30ce0:	cset	w10, cs  // cs = hs, nlast
   30ce4:	csel	x11, x26, xzr, cs  // cs = hs, nlast
   30ce8:	mvn	x10, x10
   30cec:	add	x0, x10, x0
   30cf0:	sub	x9, x9, x11
   30cf4:	umulh	x10, x8, x0
   30cf8:	adds	x10, x10, x9
   30cfc:	b.cc	30da0 <__gmpn_div_q@@Base+0x524>  // b.lo, b.ul, b.last
   30d00:	cmp	x10, x26
   30d04:	sub	x9, x0, #0x1
   30d08:	b.cc	30da4 <__gmpn_div_q@@Base+0x528>  // b.lo, b.ul, b.last
   30d0c:	mul	x11, x0, x8
   30d10:	cmp	x10, x26
   30d14:	sub	x12, x0, #0x2
   30d18:	ccmp	x11, x8, #0x2, ls  // ls = plast
   30d1c:	csel	x9, x9, x12, cc  // cc = lo, ul, last
   30d20:	b	30da4 <__gmpn_div_q@@Base+0x528>
   30d24:	mov	x5, x0
   30d28:	mov	x1, x23
   30d2c:	ldur	x23, [x29, #-48]
   30d30:	ldur	x4, [x29, #-32]
   30d34:	mov	x0, x28
   30d38:	mov	x3, x27
   30d3c:	mov	x2, x23
   30d40:	stur	x5, [x29, #-8]
   30d44:	bl	c710 <__gmpn_sbpi1_divappr_q@plt>
   30d48:	b	30dc8 <__gmpn_div_q@@Base+0x54c>
   30d4c:	mov	x5, x0
   30d50:	mov	x0, x19
   30d54:	mov	x1, x23
   30d58:	mov	x2, x28
   30d5c:	mov	x3, x26
   30d60:	mov	x4, x20
   30d64:	stur	x5, [x29, #-8]
   30d68:	bl	cf00 <__gmpn_sbpi1_div_q@plt>
   30d6c:	cbnz	x24, 31298 <__gmpn_div_q@@Base+0xa1c>
   30d70:	b	30e58 <__gmpn_div_q@@Base+0x5dc>
   30d74:	mov	x9, x0
   30d78:	sub	x5, x29, #0x8
   30d7c:	mov	x0, x19
   30d80:	mov	x1, x23
   30d84:	mov	x2, x28
   30d88:	mov	x3, x26
   30d8c:	mov	x4, x20
   30d90:	stur	x9, [x29, #-8]
   30d94:	bl	cac0 <__gmpn_dcpi1_div_q@plt>
   30d98:	cbnz	x24, 31298 <__gmpn_div_q@@Base+0xa1c>
   30d9c:	b	30e58 <__gmpn_div_q@@Base+0x5dc>
   30da0:	mov	x9, x0
   30da4:	mov	x1, x23
   30da8:	ldur	x23, [x29, #-48]
   30dac:	ldur	x4, [x29, #-32]
   30db0:	sub	x5, x29, #0x8
   30db4:	mov	x0, x28
   30db8:	mov	x2, x23
   30dbc:	mov	x3, x27
   30dc0:	stur	x9, [x29, #-8]
   30dc4:	bl	c4f0 <__gmpn_dcpi1_divappr_q@plt>
   30dc8:	ldur	x26, [x29, #-24]
   30dcc:	cbz	x25, 31208 <__gmpn_div_q@@Base+0x98c>
   30dd0:	ldur	x22, [x29, #-40]
   30dd4:	cbz	x0, 31210 <__gmpn_div_q@@Base+0x994>
   30dd8:	ldur	x8, [x29, #-32]
   30ddc:	cmp	x23, x8
   30de0:	b.le	31210 <__gmpn_div_q@@Base+0x994>
   30de4:	ldur	x8, [x29, #-64]
   30de8:	mov	w1, #0xff                  	// #255
   30dec:	mov	x0, x28
   30df0:	add	x8, x8, x21
   30df4:	sub	x8, x8, x20
   30df8:	lsl	x8, x8, #3
   30dfc:	add	x2, x8, #0x8
   30e00:	bl	c610 <memset@plt>
   30e04:	b	31210 <__gmpn_div_q@@Base+0x994>
   30e08:	mov	x0, x28
   30e0c:	mov	x1, x20
   30e10:	mov	w2, wzr
   30e14:	bl	cff0 <__gmpn_mu_div_q_itch@plt>
   30e18:	lsl	x1, x0, #3
   30e1c:	mov	w8, #0x7f00                	// #32512
   30e20:	cmp	x1, x8
   30e24:	b.hi	31354 <__gmpn_div_q@@Base+0xad8>  // b.pmore
   30e28:	add	x9, x1, #0xf
   30e2c:	mov	x8, sp
   30e30:	and	x9, x9, #0xfffffffffffffff0
   30e34:	sub	x5, x8, x9
   30e38:	mov	sp, x5
   30e3c:	mov	x0, x19
   30e40:	mov	x1, x23
   30e44:	mov	x2, x28
   30e48:	mov	x3, x26
   30e4c:	mov	x4, x20
   30e50:	bl	c2f0 <__gmpn_mu_div_q@plt>
   30e54:	cbnz	x24, 31298 <__gmpn_div_q@@Base+0xa1c>
   30e58:	str	x0, [x19, x22, lsl #3]
   30e5c:	b	31298 <__gmpn_div_q@@Base+0xa1c>
   30e60:	sub	x0, x29, #0x10
   30e64:	mov	x1, x26
   30e68:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   30e6c:	stur	x0, [x29, #-56]
   30e70:	b	30928 <__gmpn_div_q@@Base+0xac>
   30e74:	add	x8, x24, x21, lsl #3
   30e78:	sub	x1, x8, x27, lsl #3
   30e7c:	mov	x0, x23
   30e80:	mov	x2, x27
   30e84:	bl	ca70 <__gmpn_copyi@plt>
   30e88:	ldur	x26, [x29, #-24]
   30e8c:	mov	x9, #0xfffffffffffffffe    	// #-2
   30e90:	sub	x9, x9, x22
   30e94:	add	x8, x26, x20, lsl #3
   30e98:	add	x25, x8, x9, lsl #3
   30e9c:	cbz	x22, 31010 <__gmpn_div_q@@Base+0x794>
   30ea0:	cmp	x22, #0x95
   30ea4:	b.le	31030 <__gmpn_div_q@@Base+0x7b4>
   30ea8:	cmp	x22, #0x3e3
   30eac:	b.le	310f8 <__gmpn_div_q@@Base+0x87c>
   30eb0:	ldur	x1, [x29, #-32]
   30eb4:	mov	x0, x27
   30eb8:	mov	w2, wzr
   30ebc:	bl	c0f0 <__gmpn_mu_divappr_q_itch@plt>
   30ec0:	lsl	x1, x0, #3
   30ec4:	mov	w8, #0x7f00                	// #32512
   30ec8:	cmp	x1, x8
   30ecc:	b.hi	31364 <__gmpn_div_q@@Base+0xae8>  // b.pmore
   30ed0:	add	x9, x1, #0xf
   30ed4:	mov	x8, sp
   30ed8:	and	x9, x9, #0xfffffffffffffff0
   30edc:	sub	x5, x8, x9
   30ee0:	mov	sp, x5
   30ee4:	ldur	x28, [x29, #-56]
   30ee8:	ldur	x4, [x29, #-32]
   30eec:	mov	x1, x23
   30ef0:	mov	x2, x27
   30ef4:	mov	x0, x28
   30ef8:	mov	x3, x25
   30efc:	bl	c730 <__gmpn_mu_divappr_q@plt>
   30f00:	b	31204 <__gmpn_div_q@@Base+0x988>
   30f04:	cmp	x23, x24
   30f08:	b.eq	30f1c <__gmpn_div_q@@Base+0x6a0>  // b.none
   30f0c:	mov	x0, x23
   30f10:	mov	x1, x24
   30f14:	mov	x2, x21
   30f18:	bl	ca70 <__gmpn_copyi@plt>
   30f1c:	cmp	x20, #0x2
   30f20:	b.ne	30f50 <__gmpn_div_q@@Base+0x6d4>  // b.any
   30f24:	mov	x0, x19
   30f28:	mov	x1, xzr
   30f2c:	mov	x2, x23
   30f30:	mov	x3, x21
   30f34:	mov	x4, x26
   30f38:	bl	c210 <__gmpn_divrem_2@plt>
   30f3c:	b	30e58 <__gmpn_div_q@@Base+0x5dc>
   30f40:	sub	x0, x29, #0x10
   30f44:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   30f48:	mov	x26, x0
   30f4c:	b	30a14 <__gmpn_div_q@@Base+0x198>
   30f50:	cmp	x20, #0x98
   30f54:	b.lt	31090 <__gmpn_div_q@@Base+0x814>  // b.tstop
   30f58:	cmp	x22, #0x97
   30f5c:	b.le	31090 <__gmpn_div_q@@Base+0x814>
   30f60:	cmp	x21, #0x7cc
   30f64:	b.lt	30f98 <__gmpn_div_q@@Base+0x71c>  // b.tstop
   30f68:	adrp	x8, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   30f6c:	adrp	x9, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   30f70:	ldr	d0, [x8, #840]
   30f74:	ldr	d1, [x9, #848]
   30f78:	scvtf	d2, x20
   30f7c:	scvtf	d3, x21
   30f80:	fmul	d0, d2, d0
   30f84:	fmul	d1, d3, d1
   30f88:	fadd	d0, d1, d0
   30f8c:	fmul	d1, d3, d2
   30f90:	fcmp	d0, d1
   30f94:	b.le	31304 <__gmpn_div_q@@Base+0xa88>
   30f98:	mov	x0, x28
   30f9c:	bl	d410 <__gmpn_invert_limb@plt>
   30fa0:	ldur	x8, [x29, #-24]
   30fa4:	mul	x9, x0, x28
   30fa8:	add	x8, x8, x20, lsl #3
   30fac:	ldur	x8, [x8, #-16]
   30fb0:	adds	x9, x9, x8
   30fb4:	b.cc	30fd0 <__gmpn_div_q@@Base+0x754>  // b.lo, b.ul, b.last
   30fb8:	subs	x9, x9, x28
   30fbc:	cset	w10, cs  // cs = hs, nlast
   30fc0:	csel	x11, x28, xzr, cs  // cs = hs, nlast
   30fc4:	mvn	x10, x10
   30fc8:	add	x0, x10, x0
   30fcc:	sub	x9, x9, x11
   30fd0:	umulh	x10, x8, x0
   30fd4:	adds	x10, x10, x9
   30fd8:	b.cc	311b4 <__gmpn_div_q@@Base+0x938>  // b.lo, b.ul, b.last
   30fdc:	cmp	x10, x28
   30fe0:	sub	x9, x0, #0x1
   30fe4:	b.cc	311b8 <__gmpn_div_q@@Base+0x93c>  // b.lo, b.ul, b.last
   30fe8:	mul	x11, x0, x8
   30fec:	cmp	x10, x28
   30ff0:	sub	x12, x0, #0x2
   30ff4:	ccmp	x11, x8, #0x2, ls  // ls = plast
   30ff8:	csel	x9, x9, x12, cc  // cc = lo, ul, last
   30ffc:	b	311b8 <__gmpn_div_q@@Base+0x93c>
   31000:	sub	x0, x29, #0x10
   31004:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31008:	mov	x23, x0
   3100c:	b	30960 <__gmpn_div_q@@Base+0xe4>
   31010:	ldur	x28, [x29, #-56]
   31014:	mov	x1, xzr
   31018:	mov	x2, x23
   3101c:	mov	x3, x27
   31020:	mov	x0, x28
   31024:	mov	x4, x25
   31028:	bl	c210 <__gmpn_divrem_2@plt>
   3102c:	b	31208 <__gmpn_div_q@@Base+0x98c>
   31030:	mov	x0, x28
   31034:	bl	d410 <__gmpn_invert_limb@plt>
   31038:	ldr	x8, [x25, x22, lsl #3]
   3103c:	mul	x9, x0, x28
   31040:	adds	x9, x9, x8
   31044:	b.cc	31060 <__gmpn_div_q@@Base+0x7e4>  // b.lo, b.ul, b.last
   31048:	subs	x9, x9, x28
   3104c:	cset	w10, cs  // cs = hs, nlast
   31050:	csel	x11, x28, xzr, cs  // cs = hs, nlast
   31054:	mvn	x10, x10
   31058:	add	x0, x10, x0
   3105c:	sub	x9, x9, x11
   31060:	umulh	x10, x8, x0
   31064:	adds	x9, x10, x9
   31068:	b.cc	31158 <__gmpn_div_q@@Base+0x8dc>  // b.lo, b.ul, b.last
   3106c:	cmp	x9, x28
   31070:	sub	x5, x0, #0x1
   31074:	b.cc	3115c <__gmpn_div_q@@Base+0x8e0>  // b.lo, b.ul, b.last
   31078:	mul	x10, x0, x8
   3107c:	cmp	x9, x28
   31080:	sub	x11, x0, #0x2
   31084:	ccmp	x10, x8, #0x2, ls  // ls = plast
   31088:	csel	x5, x5, x11, cc  // cc = lo, ul, last
   3108c:	b	3115c <__gmpn_div_q@@Base+0x8e0>
   31090:	mov	x0, x28
   31094:	bl	d410 <__gmpn_invert_limb@plt>
   31098:	ldur	x8, [x29, #-24]
   3109c:	mul	x9, x0, x28
   310a0:	add	x8, x8, x20, lsl #3
   310a4:	ldur	x8, [x8, #-16]
   310a8:	adds	x9, x9, x8
   310ac:	b.cc	310c8 <__gmpn_div_q@@Base+0x84c>  // b.lo, b.ul, b.last
   310b0:	subs	x9, x9, x28
   310b4:	cset	w10, cs  // cs = hs, nlast
   310b8:	csel	x11, x28, xzr, cs  // cs = hs, nlast
   310bc:	mvn	x10, x10
   310c0:	add	x0, x10, x0
   310c4:	sub	x9, x9, x11
   310c8:	umulh	x10, x8, x0
   310cc:	adds	x9, x10, x9
   310d0:	b.cc	31190 <__gmpn_div_q@@Base+0x914>  // b.lo, b.ul, b.last
   310d4:	cmp	x9, x28
   310d8:	sub	x5, x0, #0x1
   310dc:	b.cc	31194 <__gmpn_div_q@@Base+0x918>  // b.lo, b.ul, b.last
   310e0:	mul	x10, x0, x8
   310e4:	cmp	x9, x28
   310e8:	sub	x11, x0, #0x2
   310ec:	ccmp	x10, x8, #0x2, ls  // ls = plast
   310f0:	csel	x5, x5, x11, cc  // cc = lo, ul, last
   310f4:	b	31194 <__gmpn_div_q@@Base+0x918>
   310f8:	mov	x0, x28
   310fc:	bl	d410 <__gmpn_invert_limb@plt>
   31100:	ldr	x8, [x25, x22, lsl #3]
   31104:	mul	x9, x0, x28
   31108:	adds	x9, x9, x8
   3110c:	b.cc	31128 <__gmpn_div_q@@Base+0x8ac>  // b.lo, b.ul, b.last
   31110:	subs	x9, x9, x28
   31114:	cset	w10, cs  // cs = hs, nlast
   31118:	csel	x11, x28, xzr, cs  // cs = hs, nlast
   3111c:	mvn	x10, x10
   31120:	add	x0, x10, x0
   31124:	sub	x9, x9, x11
   31128:	umulh	x10, x8, x0
   3112c:	adds	x10, x10, x9
   31130:	b.cc	311dc <__gmpn_div_q@@Base+0x960>  // b.lo, b.ul, b.last
   31134:	cmp	x10, x28
   31138:	sub	x9, x0, #0x1
   3113c:	b.cc	311e0 <__gmpn_div_q@@Base+0x964>  // b.lo, b.ul, b.last
   31140:	mul	x11, x0, x8
   31144:	cmp	x10, x28
   31148:	sub	x12, x0, #0x2
   3114c:	ccmp	x11, x8, #0x2, ls  // ls = plast
   31150:	csel	x9, x9, x12, cc  // cc = lo, ul, last
   31154:	b	311e0 <__gmpn_div_q@@Base+0x964>
   31158:	mov	x5, x0
   3115c:	ldur	x28, [x29, #-56]
   31160:	ldur	x4, [x29, #-32]
   31164:	mov	x1, x23
   31168:	mov	x2, x27
   3116c:	mov	x0, x28
   31170:	mov	x3, x25
   31174:	stur	x5, [x29, #-8]
   31178:	bl	c710 <__gmpn_sbpi1_divappr_q@plt>
   3117c:	b	31204 <__gmpn_div_q@@Base+0x988>
   31180:	sub	x0, x29, #0x10
   31184:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31188:	mov	x5, x0
   3118c:	b	30aec <__gmpn_div_q@@Base+0x270>
   31190:	mov	x5, x0
   31194:	ldur	x3, [x29, #-24]
   31198:	mov	x0, x19
   3119c:	mov	x1, x23
   311a0:	mov	x2, x21
   311a4:	mov	x4, x20
   311a8:	stur	x5, [x29, #-8]
   311ac:	bl	cf00 <__gmpn_sbpi1_div_q@plt>
   311b0:	b	30e58 <__gmpn_div_q@@Base+0x5dc>
   311b4:	mov	x9, x0
   311b8:	ldur	x3, [x29, #-24]
   311bc:	sub	x5, x29, #0x8
   311c0:	mov	x0, x19
   311c4:	mov	x1, x23
   311c8:	mov	x2, x21
   311cc:	mov	x4, x20
   311d0:	stur	x9, [x29, #-8]
   311d4:	bl	cac0 <__gmpn_dcpi1_div_q@plt>
   311d8:	b	30e58 <__gmpn_div_q@@Base+0x5dc>
   311dc:	mov	x9, x0
   311e0:	ldur	x28, [x29, #-56]
   311e4:	ldur	x4, [x29, #-32]
   311e8:	sub	x5, x29, #0x8
   311ec:	mov	x1, x23
   311f0:	mov	x0, x28
   311f4:	mov	x2, x27
   311f8:	mov	x3, x25
   311fc:	stur	x9, [x29, #-8]
   31200:	bl	c4f0 <__gmpn_dcpi1_divappr_q@plt>
   31204:	ldur	x26, [x29, #-24]
   31208:	ldur	x22, [x29, #-40]
   3120c:	str	x0, [x28, x22, lsl #3]
   31210:	add	x23, x28, #0x8
   31214:	mov	x0, x19
   31218:	mov	x1, x23
   3121c:	mov	x2, x22
   31220:	bl	ca70 <__gmpn_copyi@plt>
   31224:	ldr	x8, [x28]
   31228:	cmp	x8, #0x4
   3122c:	b.hi	31298 <__gmpn_div_q@@Base+0xa1c>  // b.pmore
   31230:	add	x22, x21, #0x1
   31234:	lsl	x1, x22, #3
   31238:	mov	w8, #0x7f00                	// #32512
   3123c:	cmp	x1, x8
   31240:	b.hi	312f4 <__gmpn_div_q@@Base+0xa78>  // b.pmore
   31244:	add	x9, x1, #0xf
   31248:	mov	x8, sp
   3124c:	and	x9, x9, #0xfffffffffffffff0
   31250:	sub	x25, x8, x9
   31254:	mov	sp, x25
   31258:	ldur	x4, [x29, #-40]
   3125c:	mov	x0, x25
   31260:	mov	x1, x26
   31264:	mov	x2, x20
   31268:	mov	x3, x23
   3126c:	bl	ccf0 <__gmpn_mul@plt>
   31270:	ldr	x8, [x25, x21, lsl #3]
   31274:	cmp	x8, #0x0
   31278:	cset	w8, eq  // eq = none
   3127c:	sub	x8, x22, x8
   31280:	cmp	x8, x21
   31284:	b.le	312c0 <__gmpn_div_q@@Base+0xa44>
   31288:	ldr	x8, [x19]
   3128c:	sub	x9, x8, #0x1
   31290:	str	x9, [x19], #8
   31294:	cbz	x8, 31288 <__gmpn_div_q@@Base+0xa0c>
   31298:	ldur	x0, [x29, #-16]
   3129c:	cbnz	x0, 312ec <__gmpn_div_q@@Base+0xa70>
   312a0:	mov	sp, x29
   312a4:	ldp	x20, x19, [sp, #80]
   312a8:	ldp	x22, x21, [sp, #64]
   312ac:	ldp	x24, x23, [sp, #48]
   312b0:	ldp	x26, x25, [sp, #32]
   312b4:	ldp	x28, x27, [sp, #16]
   312b8:	ldp	x29, x30, [sp], #96
   312bc:	ret
   312c0:	sub	x8, x25, #0x8
   312c4:	sub	x9, x24, #0x8
   312c8:	subs	x10, x21, #0x1
   312cc:	b.lt	31298 <__gmpn_div_q@@Base+0xa1c>  // b.tstop
   312d0:	ldr	x11, [x9, x21, lsl #3]
   312d4:	ldr	x12, [x8, x21, lsl #3]
   312d8:	mov	x21, x10
   312dc:	cmp	x11, x12
   312e0:	b.eq	312c8 <__gmpn_div_q@@Base+0xa4c>  // b.none
   312e4:	b.ls	31288 <__gmpn_div_q@@Base+0xa0c>  // b.plast
   312e8:	b	31298 <__gmpn_div_q@@Base+0xa1c>
   312ec:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   312f0:	b	312a0 <__gmpn_div_q@@Base+0xa24>
   312f4:	sub	x0, x29, #0x10
   312f8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   312fc:	mov	x25, x0
   31300:	b	31258 <__gmpn_div_q@@Base+0x9dc>
   31304:	mov	x0, x21
   31308:	mov	x1, x20
   3130c:	mov	w2, wzr
   31310:	bl	cff0 <__gmpn_mu_div_q_itch@plt>
   31314:	lsl	x1, x0, #3
   31318:	mov	w8, #0x7f00                	// #32512
   3131c:	cmp	x1, x8
   31320:	b.hi	31374 <__gmpn_div_q@@Base+0xaf8>  // b.pmore
   31324:	add	x9, x1, #0xf
   31328:	mov	x8, sp
   3132c:	and	x9, x9, #0xfffffffffffffff0
   31330:	sub	x5, x8, x9
   31334:	mov	sp, x5
   31338:	ldur	x3, [x29, #-24]
   3133c:	mov	x0, x19
   31340:	mov	x1, x24
   31344:	mov	x2, x21
   31348:	mov	x4, x20
   3134c:	bl	c2f0 <__gmpn_mu_div_q@plt>
   31350:	b	30e58 <__gmpn_div_q@@Base+0x5dc>
   31354:	sub	x0, x29, #0x10
   31358:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   3135c:	mov	x5, x0
   31360:	b	30e3c <__gmpn_div_q@@Base+0x5c0>
   31364:	sub	x0, x29, #0x10
   31368:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   3136c:	mov	x5, x0
   31370:	b	30ee4 <__gmpn_div_q@@Base+0x668>
   31374:	sub	x0, x29, #0x10
   31378:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   3137c:	mov	x5, x0
   31380:	b	31338 <__gmpn_div_q@@Base+0xabc>

0000000000031384 <__gmpn_tdiv_qr@@Base>:
   31384:	stp	x29, x30, [sp, #-96]!
   31388:	stp	x28, x27, [sp, #16]
   3138c:	stp	x26, x25, [sp, #32]
   31390:	stp	x24, x23, [sp, #48]
   31394:	stp	x22, x21, [sp, #64]
   31398:	stp	x20, x19, [sp, #80]
   3139c:	mov	x29, sp
   313a0:	sub	sp, sp, #0x50
   313a4:	cbnz	x2, 31ee4 <__gmpn_tdiv_qr@@Base+0xb60>
   313a8:	mov	x21, x6
   313ac:	mov	x22, x5
   313b0:	mov	x25, x4
   313b4:	mov	x26, x1
   313b8:	mov	x20, x0
   313bc:	subs	x19, x6, #0x1
   313c0:	b.eq	31598 <__gmpn_tdiv_qr@@Base+0x214>  // b.none
   313c4:	cmp	x21, #0x2
   313c8:	b.eq	314dc <__gmpn_tdiv_qr@@Base+0x158>  // b.none
   313cc:	cbz	x21, 31efc <__gmpn_tdiv_qr@@Base+0xb78>
   313d0:	stur	xzr, [x29, #-8]
   313d4:	add	x8, x3, x25, lsl #3
   313d8:	ldur	x28, [x8, #-8]
   313dc:	ldr	x23, [x22, x19, lsl #3]
   313e0:	sub	x9, x25, x21
   313e4:	str	xzr, [x20, x9, lsl #3]
   313e8:	stur	x26, [x29, #-32]
   313ec:	cmp	x28, x23
   313f0:	cinc	x24, x25, cs  // cs = hs, nlast
   313f4:	cset	w8, cs  // cs = hs, nlast
   313f8:	cmp	x24, x21, lsl #1
   313fc:	b.ge	315b8 <__gmpn_tdiv_qr@@Base+0x234>  // b.tcont
   31400:	adds	x24, x9, x8
   31404:	b.eq	316a4 <__gmpn_tdiv_qr@@Base+0x320>  // b.none
   31408:	ldr	x8, [x22, x19, lsl #3]
   3140c:	sub	x10, x21, x24
   31410:	lsl	x11, x24, #3
   31414:	stur	x22, [x29, #-40]
   31418:	stp	x11, x10, [x29, #-64]
   3141c:	tbnz	x8, #63, 3181c <__gmpn_tdiv_qr@@Base+0x498>
   31420:	mov	w9, #0x7f00                	// #32512
   31424:	cmp	x11, x9
   31428:	clz	x8, x8
   3142c:	mov	x19, x3
   31430:	stur	x8, [x29, #-80]
   31434:	b.hi	31e68 <__gmpn_tdiv_qr@@Base+0xae4>  // b.pmore
   31438:	add	x9, x11, #0xf
   3143c:	mov	x8, sp
   31440:	and	x9, x9, #0xfffffffffffffff0
   31444:	sub	x27, x8, x9
   31448:	mov	sp, x27
   3144c:	add	x26, x22, x10, lsl #3
   31450:	ldur	x22, [x29, #-80]
   31454:	mov	x0, x27
   31458:	mov	x1, x26
   3145c:	mov	x2, x24
   31460:	mov	w3, w22
   31464:	bl	c190 <__gmpn_lshift@plt>
   31468:	ldur	x8, [x26, #-8]
   3146c:	ldr	x10, [x27]
   31470:	neg	x9, x22
   31474:	mov	w1, #0x8                   	// #8
   31478:	lsr	x8, x8, x9
   3147c:	mov	w11, #0x7f00                	// #32512
   31480:	bfi	x1, x24, #4, #60
   31484:	orr	x8, x10, x8
   31488:	cmp	x1, x11
   3148c:	stur	x27, [x29, #-72]
   31490:	str	x8, [x27]
   31494:	lsl	x27, x24, #1
   31498:	b.hi	31e84 <__gmpn_tdiv_qr@@Base+0xb00>  // b.pmore
   3149c:	add	x9, x1, #0xf
   314a0:	mov	x8, sp
   314a4:	and	x9, x9, #0xfffffffffffffff0
   314a8:	sub	x26, x8, x9
   314ac:	mov	sp, x26
   314b0:	ldur	x22, [x29, #-80]
   314b4:	add	x8, x19, x25, lsl #3
   314b8:	sub	x1, x8, x27, lsl #3
   314bc:	mov	x0, x26
   314c0:	mov	x2, x27
   314c4:	mov	w3, w22
   314c8:	bl	c190 <__gmpn_lshift@plt>
   314cc:	cmp	x28, x23
   314d0:	b.cc	31880 <__gmpn_tdiv_qr@@Base+0x4fc>  // b.lo, b.ul, b.last
   314d4:	str	x0, [x26, x27, lsl #3]
   314d8:	b	31878 <__gmpn_tdiv_qr@@Base+0x4f4>
   314dc:	stur	xzr, [x29, #-8]
   314e0:	ldr	x8, [x22, #8]
   314e4:	tbnz	x8, #63, 31644 <__gmpn_tdiv_qr@@Base+0x2c0>
   314e8:	ldr	x9, [x22]
   314ec:	clz	x21, x8
   314f0:	lsl	x10, x25, #3
   314f4:	neg	x12, x21
   314f8:	mov	w11, #0x7f00                	// #32512
   314fc:	lsl	x8, x8, x21
   31500:	add	x1, x10, #0x8
   31504:	lsr	x10, x9, x12
   31508:	mov	w19, #0x40                  	// #64
   3150c:	cmp	x1, x11
   31510:	lsl	x9, x9, x21
   31514:	orr	x8, x10, x8
   31518:	stp	x9, x8, [x29, #-24]
   3151c:	b.hi	31e08 <__gmpn_tdiv_qr@@Base+0xa84>  // b.pmore
   31520:	add	x9, x1, #0xf
   31524:	mov	x8, sp
   31528:	and	x9, x9, #0xfffffffffffffff0
   3152c:	sub	x22, x8, x9
   31530:	mov	sp, x22
   31534:	mov	x0, x22
   31538:	mov	x1, x3
   3153c:	mov	x2, x25
   31540:	mov	w3, w21
   31544:	sub	x19, x19, x21
   31548:	bl	c190 <__gmpn_lshift@plt>
   3154c:	cmp	x0, #0x0
   31550:	mov	x23, x0
   31554:	str	x0, [x22, x25, lsl #3]
   31558:	cinc	x3, x25, ne  // ne = any
   3155c:	sub	x4, x29, #0x18
   31560:	mov	x0, x20
   31564:	mov	x1, xzr
   31568:	mov	x2, x22
   3156c:	bl	c210 <__gmpn_divrem_2@plt>
   31570:	cbnz	x23, 3157c <__gmpn_tdiv_qr@@Base+0x1f8>
   31574:	add	x8, x20, x25, lsl #3
   31578:	stur	x0, [x8, #-16]
   3157c:	ldp	x8, x9, [x22]
   31580:	lsr	x8, x8, x21
   31584:	lsl	x10, x9, x19
   31588:	lsr	x9, x9, x21
   3158c:	orr	x8, x10, x8
   31590:	stp	x8, x9, [x26]
   31594:	b	31da8 <__gmpn_tdiv_qr@@Base+0xa24>
   31598:	ldr	x4, [x22]
   3159c:	mov	x0, x20
   315a0:	mov	x1, xzr
   315a4:	mov	x2, x3
   315a8:	mov	x3, x25
   315ac:	bl	cd20 <__gmpn_divrem_1@plt>
   315b0:	str	x0, [x26]
   315b4:	b	31db0 <__gmpn_tdiv_qr@@Base+0xa2c>
   315b8:	ldr	x8, [x22, x19, lsl #3]
   315bc:	tbnz	x8, #63, 316b8 <__gmpn_tdiv_qr@@Base+0x334>
   315c0:	lsl	x1, x21, #3
   315c4:	mov	w9, #0x7f00                	// #32512
   315c8:	cmp	x1, x9
   315cc:	clz	x26, x8
   315d0:	mov	x23, x3
   315d4:	b.hi	31e38 <__gmpn_tdiv_qr@@Base+0xab4>  // b.pmore
   315d8:	add	x9, x1, #0xf
   315dc:	mov	x8, sp
   315e0:	and	x9, x9, #0xfffffffffffffff0
   315e4:	sub	x28, x8, x9
   315e8:	mov	sp, x28
   315ec:	mov	x0, x28
   315f0:	mov	x1, x22
   315f4:	mov	x2, x21
   315f8:	mov	w3, w26
   315fc:	bl	c190 <__gmpn_lshift@plt>
   31600:	lsl	x8, x25, #3
   31604:	add	x1, x8, #0x8
   31608:	mov	w8, #0x7f00                	// #32512
   3160c:	cmp	x1, x8
   31610:	b.hi	31e48 <__gmpn_tdiv_qr@@Base+0xac4>  // b.pmore
   31614:	add	x9, x1, #0xf
   31618:	mov	x8, sp
   3161c:	and	x9, x9, #0xfffffffffffffff0
   31620:	sub	x27, x8, x9
   31624:	mov	sp, x27
   31628:	mov	x1, x23
   3162c:	mov	x0, x27
   31630:	mov	x2, x25
   31634:	mov	w3, w26
   31638:	bl	c190 <__gmpn_lshift@plt>
   3163c:	mov	x22, x28
   31640:	b	316f8 <__gmpn_tdiv_qr@@Base+0x374>
   31644:	lsl	x1, x25, #3
   31648:	mov	w8, #0x7f00                	// #32512
   3164c:	cmp	x1, x8
   31650:	b.hi	31e20 <__gmpn_tdiv_qr@@Base+0xa9c>  // b.pmore
   31654:	add	x9, x1, #0xf
   31658:	mov	x8, sp
   3165c:	and	x9, x9, #0xfffffffffffffff0
   31660:	sub	x21, x8, x9
   31664:	mov	sp, x21
   31668:	mov	x0, x21
   3166c:	mov	x1, x3
   31670:	mov	x2, x25
   31674:	bl	ca70 <__gmpn_copyi@plt>
   31678:	mov	x0, x20
   3167c:	mov	x1, xzr
   31680:	mov	x2, x21
   31684:	mov	x3, x25
   31688:	mov	x4, x22
   3168c:	bl	c210 <__gmpn_divrem_2@plt>
   31690:	add	x8, x20, x25, lsl #3
   31694:	stur	x0, [x8, #-16]
   31698:	ldr	q0, [x21]
   3169c:	str	q0, [x26]
   316a0:	b	31da8 <__gmpn_tdiv_qr@@Base+0xa24>
   316a4:	mov	x0, x26
   316a8:	mov	x1, x3
   316ac:	mov	x2, x21
   316b0:	bl	ca70 <__gmpn_copyi@plt>
   316b4:	b	31db0 <__gmpn_tdiv_qr@@Base+0xa2c>
   316b8:	lsl	x8, x25, #3
   316bc:	add	x1, x8, #0x8
   316c0:	mov	w8, #0x7f00                	// #32512
   316c4:	cmp	x1, x8
   316c8:	b.hi	31e94 <__gmpn_tdiv_qr@@Base+0xb10>  // b.pmore
   316cc:	add	x9, x1, #0xf
   316d0:	mov	x8, sp
   316d4:	and	x9, x9, #0xfffffffffffffff0
   316d8:	sub	x27, x8, x9
   316dc:	mov	sp, x27
   316e0:	mov	x0, x27
   316e4:	mov	x1, x3
   316e8:	mov	x2, x25
   316ec:	bl	ca70 <__gmpn_copyi@plt>
   316f0:	mov	x0, xzr
   316f4:	mov	w26, wzr
   316f8:	str	x0, [x27, x25, lsl #3]
   316fc:	ldr	x23, [x22, x19, lsl #3]
   31700:	mov	x0, x23
   31704:	bl	d410 <__gmpn_invert_limb@plt>
   31708:	add	x8, x22, x21, lsl #3
   3170c:	ldur	x8, [x8, #-16]
   31710:	mul	x9, x0, x23
   31714:	adds	x9, x9, x8
   31718:	b.cc	31734 <__gmpn_tdiv_qr@@Base+0x3b0>  // b.lo, b.ul, b.last
   3171c:	subs	x9, x9, x23
   31720:	cset	w10, cs  // cs = hs, nlast
   31724:	csel	x11, x23, xzr, cs  // cs = hs, nlast
   31728:	mvn	x10, x10
   3172c:	add	x0, x10, x0
   31730:	sub	x9, x9, x11
   31734:	umulh	x10, x8, x0
   31738:	adds	x9, x10, x9
   3173c:	b.cc	31764 <__gmpn_tdiv_qr@@Base+0x3e0>  // b.lo, b.ul, b.last
   31740:	cmp	x9, x23
   31744:	sub	x5, x0, #0x1
   31748:	b.cc	31768 <__gmpn_tdiv_qr@@Base+0x3e4>  // b.lo, b.ul, b.last
   3174c:	mul	x10, x0, x8
   31750:	cmp	x9, x23
   31754:	sub	x11, x0, #0x2
   31758:	ccmp	x10, x8, #0x2, ls  // ls = plast
   3175c:	csel	x5, x5, x11, cc  // cc = lo, ul, last
   31760:	b	31768 <__gmpn_tdiv_qr@@Base+0x3e4>
   31764:	mov	x5, x0
   31768:	cmp	x21, #0x29
   3176c:	stur	x5, [x29, #-24]
   31770:	b.le	317e8 <__gmpn_tdiv_qr@@Base+0x464>
   31774:	cmp	x21, #0x62
   31778:	b.lt	317b4 <__gmpn_tdiv_qr@@Base+0x430>  // b.tstop
   3177c:	cmp	x24, #0x7cc
   31780:	b.lt	317b4 <__gmpn_tdiv_qr@@Base+0x430>  // b.tstop
   31784:	adrp	x8, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   31788:	adrp	x9, 51000 <__gmp_binvert_limb_table@@Base+0x308>
   3178c:	ldr	d0, [x8, #840]
   31790:	ldr	d1, [x9, #848]
   31794:	scvtf	d2, x21
   31798:	scvtf	d3, x24
   3179c:	fmul	d0, d2, d0
   317a0:	fmul	d1, d3, d1
   317a4:	fadd	d0, d0, d1
   317a8:	fmul	d1, d2, d3
   317ac:	fcmp	d0, d1
   317b0:	b.le	318a8 <__gmpn_tdiv_qr@@Base+0x524>
   317b4:	sub	x5, x29, #0x18
   317b8:	mov	x0, x20
   317bc:	mov	x1, x27
   317c0:	mov	x2, x24
   317c4:	mov	x3, x22
   317c8:	mov	x4, x21
   317cc:	bl	c3d0 <__gmpn_dcpi1_div_qr@plt>
   317d0:	cbnz	w26, 31804 <__gmpn_tdiv_qr@@Base+0x480>
   317d4:	ldur	x0, [x29, #-32]
   317d8:	mov	x1, x27
   317dc:	mov	x2, x21
   317e0:	bl	ca70 <__gmpn_copyi@plt>
   317e4:	b	31da8 <__gmpn_tdiv_qr@@Base+0xa24>
   317e8:	mov	x0, x20
   317ec:	mov	x1, x27
   317f0:	mov	x2, x24
   317f4:	mov	x3, x22
   317f8:	mov	x4, x21
   317fc:	bl	c660 <__gmpn_sbpi1_div_qr@plt>
   31800:	cbz	w26, 317d4 <__gmpn_tdiv_qr@@Base+0x450>
   31804:	ldur	x0, [x29, #-32]
   31808:	mov	x1, x27
   3180c:	mov	x2, x21
   31810:	mov	w3, w26
   31814:	bl	c1b0 <__gmpn_rshift@plt>
   31818:	b	31da8 <__gmpn_tdiv_qr@@Base+0xa24>
   3181c:	add	x8, x22, x10, lsl #3
   31820:	mov	w1, #0x8                   	// #8
   31824:	stur	x8, [x29, #-72]
   31828:	bfi	x1, x24, #4, #60
   3182c:	mov	w8, #0x7f00                	// #32512
   31830:	cmp	x1, x8
   31834:	lsl	x27, x24, #1
   31838:	b.hi	31eac <__gmpn_tdiv_qr@@Base+0xb28>  // b.pmore
   3183c:	add	x9, x1, #0xf
   31840:	mov	x8, sp
   31844:	and	x9, x9, #0xfffffffffffffff0
   31848:	sub	x26, x8, x9
   3184c:	mov	sp, x26
   31850:	add	x8, x3, x25, lsl #3
   31854:	sub	x1, x8, x27, lsl #3
   31858:	mov	x0, x26
   3185c:	mov	x2, x27
   31860:	mov	x19, x3
   31864:	bl	ca70 <__gmpn_copyi@plt>
   31868:	cmp	x28, x23
   3186c:	b.cc	31908 <__gmpn_tdiv_qr@@Base+0x584>  // b.lo, b.ul, b.last
   31870:	mov	w22, wzr
   31874:	str	xzr, [x26, x27, lsl #3]
   31878:	add	x26, x26, #0x8
   3187c:	b	3190c <__gmpn_tdiv_qr@@Base+0x588>
   31880:	mvn	x8, x27
   31884:	add	x8, x8, x25
   31888:	ldr	x8, [x19, x8, lsl #3]
   3188c:	ldr	x9, [x26]
   31890:	mov	w10, #0x40                  	// #64
   31894:	sub	x10, x10, x22
   31898:	lsr	x8, x8, x10
   3189c:	orr	x8, x9, x8
   318a0:	str	x8, [x26]
   318a4:	b	3190c <__gmpn_tdiv_qr@@Base+0x588>
   318a8:	mov	x0, x24
   318ac:	mov	x1, x21
   318b0:	mov	w2, wzr
   318b4:	bl	d030 <__gmpn_mu_div_qr_itch@plt>
   318b8:	lsl	x1, x0, #3
   318bc:	mov	w8, #0x7f00                	// #32512
   318c0:	cmp	x1, x8
   318c4:	b.hi	31ec4 <__gmpn_tdiv_qr@@Base+0xb40>  // b.pmore
   318c8:	add	x9, x1, #0xf
   318cc:	mov	x8, sp
   318d0:	and	x9, x9, #0xfffffffffffffff0
   318d4:	sub	x6, x8, x9
   318d8:	mov	sp, x6
   318dc:	ldur	x19, [x29, #-32]
   318e0:	mov	x0, x20
   318e4:	mov	x2, x27
   318e8:	mov	x3, x24
   318ec:	mov	x1, x19
   318f0:	mov	x4, x22
   318f4:	mov	x5, x21
   318f8:	bl	c980 <__gmpn_mu_div_qr@plt>
   318fc:	mov	x27, x19
   31900:	cbnz	w26, 31804 <__gmpn_tdiv_qr@@Base+0x480>
   31904:	b	317d4 <__gmpn_tdiv_qr@@Base+0x450>
   31908:	mov	w22, wzr
   3190c:	ldur	x28, [x29, #-72]
   31910:	cmp	x24, #0x2
   31914:	stur	x19, [x29, #-48]
   31918:	b.eq	31970 <__gmpn_tdiv_qr@@Base+0x5ec>  // b.none
   3191c:	cmp	x24, #0x1
   31920:	b.ne	3198c <__gmpn_tdiv_qr@@Base+0x608>  // b.any
   31924:	ldr	x9, [x28]
   31928:	ldp	x8, x10, [x26]
   3192c:	lsr	x12, x9, #32
   31930:	udiv	x15, x10, x12
   31934:	and	x11, x9, #0xffffffff
   31938:	msub	w10, w15, w12, w10
   3193c:	mul	x13, x15, x11
   31940:	extr	x14, x10, x8, #32
   31944:	cmp	x14, x13
   31948:	b.cs	319f4 <__gmpn_tdiv_qr@@Base+0x670>  // b.hs, b.nlast
   3194c:	add	x14, x14, x9
   31950:	cmp	x14, x9
   31954:	sub	x10, x15, #0x1
   31958:	b.cc	319f8 <__gmpn_tdiv_qr@@Base+0x674>  // b.lo, b.ul, b.last
   3195c:	cmp	x14, x13
   31960:	b.cs	319f8 <__gmpn_tdiv_qr@@Base+0x674>  // b.hs, b.nlast
   31964:	sub	x10, x15, #0x2
   31968:	add	x14, x14, x9
   3196c:	b	319f8 <__gmpn_tdiv_qr@@Base+0x674>
   31970:	mov	w3, #0x4                   	// #4
   31974:	mov	x0, x20
   31978:	mov	x1, xzr
   3197c:	mov	x2, x26
   31980:	mov	x4, x28
   31984:	bl	c210 <__gmpn_divrem_2@plt>
   31988:	b	31b28 <__gmpn_tdiv_qr@@Base+0x7a4>
   3198c:	add	x23, x28, x24, lsl #3
   31990:	ldur	x27, [x23, #-8]
   31994:	mov	x0, x27
   31998:	bl	d410 <__gmpn_invert_limb@plt>
   3199c:	ldur	x8, [x23, #-16]
   319a0:	mul	x9, x0, x27
   319a4:	adds	x9, x9, x8
   319a8:	b.cc	319c4 <__gmpn_tdiv_qr@@Base+0x640>  // b.lo, b.ul, b.last
   319ac:	subs	x9, x9, x27
   319b0:	cset	w10, cs  // cs = hs, nlast
   319b4:	csel	x11, x27, xzr, cs  // cs = hs, nlast
   319b8:	mvn	x10, x10
   319bc:	add	x0, x10, x0
   319c0:	sub	x9, x9, x11
   319c4:	umulh	x10, x8, x0
   319c8:	adds	x9, x10, x9
   319cc:	b.cc	31a58 <__gmpn_tdiv_qr@@Base+0x6d4>  // b.lo, b.ul, b.last
   319d0:	cmp	x9, x27
   319d4:	sub	x5, x0, #0x1
   319d8:	b.cc	31a5c <__gmpn_tdiv_qr@@Base+0x6d8>  // b.lo, b.ul, b.last
   319dc:	mul	x10, x0, x8
   319e0:	cmp	x9, x27
   319e4:	sub	x11, x0, #0x2
   319e8:	ccmp	x10, x8, #0x2, ls  // ls = plast
   319ec:	csel	x5, x5, x11, cc  // cc = lo, ul, last
   319f0:	b	31a5c <__gmpn_tdiv_qr@@Base+0x6d8>
   319f4:	mov	x10, x15
   319f8:	sub	x14, x14, x13
   319fc:	udiv	x13, x14, x12
   31a00:	msub	w12, w13, w12, w14
   31a04:	mul	x11, x13, x11
   31a08:	bfi	x8, x12, #32, #32
   31a0c:	cmp	x8, x11
   31a10:	b.cs	31a3c <__gmpn_tdiv_qr@@Base+0x6b8>  // b.hs, b.nlast
   31a14:	ldp	x15, x14, [x29, #-64]
   31a18:	add	x8, x8, x9
   31a1c:	cmp	x8, x9
   31a20:	sub	x12, x13, #0x1
   31a24:	b.cc	31a44 <__gmpn_tdiv_qr@@Base+0x6c0>  // b.lo, b.ul, b.last
   31a28:	cmp	x8, x11
   31a2c:	b.cs	31a44 <__gmpn_tdiv_qr@@Base+0x6c0>  // b.hs, b.nlast
   31a30:	sub	x12, x13, #0x2
   31a34:	add	x8, x8, x9
   31a38:	b	31a44 <__gmpn_tdiv_qr@@Base+0x6c0>
   31a3c:	ldp	x15, x14, [x29, #-64]
   31a40:	mov	x12, x13
   31a44:	sub	x8, x8, x11
   31a48:	orr	x9, x12, x10, lsl #32
   31a4c:	str	x8, [x26]
   31a50:	str	x9, [x20]
   31a54:	b	31b2c <__gmpn_tdiv_qr@@Base+0x7a8>
   31a58:	mov	x5, x0
   31a5c:	cmp	x24, #0x29
   31a60:	stur	x5, [x29, #-24]
   31a64:	b.le	31af0 <__gmpn_tdiv_qr@@Base+0x76c>
   31a68:	cmp	x24, #0x3e5
   31a6c:	lsl	x27, x24, #1
   31a70:	b.le	31b0c <__gmpn_tdiv_qr@@Base+0x788>
   31a74:	mov	x0, x27
   31a78:	mov	x1, x24
   31a7c:	mov	w2, wzr
   31a80:	bl	d030 <__gmpn_mu_div_qr_itch@plt>
   31a84:	lsl	x1, x0, #3
   31a88:	mov	w8, #0x7f00                	// #32512
   31a8c:	cmp	x1, x8
   31a90:	b.hi	31ed4 <__gmpn_tdiv_qr@@Base+0xb50>  // b.pmore
   31a94:	add	x9, x1, #0xf
   31a98:	mov	x8, sp
   31a9c:	and	x9, x9, #0xfffffffffffffff0
   31aa0:	sub	x6, x8, x9
   31aa4:	mov	sp, x6
   31aa8:	ldur	x10, [x29, #-48]
   31aac:	ldur	x9, [x29, #-32]
   31ab0:	sub	x8, x25, x24
   31ab4:	mov	x0, x20
   31ab8:	mov	x2, x26
   31abc:	add	x8, x9, x8, lsl #3
   31ac0:	cmp	x10, x9
   31ac4:	csel	x25, x8, x9, eq  // eq = none
   31ac8:	mov	x1, x25
   31acc:	mov	x3, x27
   31ad0:	mov	x4, x28
   31ad4:	mov	x5, x24
   31ad8:	bl	c980 <__gmpn_mu_div_qr@plt>
   31adc:	mov	x0, x26
   31ae0:	mov	x1, x25
   31ae4:	mov	x2, x24
   31ae8:	bl	ca70 <__gmpn_copyi@plt>
   31aec:	b	31b28 <__gmpn_tdiv_qr@@Base+0x7a4>
   31af0:	lsl	x2, x24, #1
   31af4:	mov	x0, x20
   31af8:	mov	x1, x26
   31afc:	mov	x3, x28
   31b00:	mov	x4, x24
   31b04:	bl	c660 <__gmpn_sbpi1_div_qr@plt>
   31b08:	b	31b28 <__gmpn_tdiv_qr@@Base+0x7a4>
   31b0c:	sub	x5, x29, #0x18
   31b10:	mov	x0, x20
   31b14:	mov	x1, x26
   31b18:	mov	x2, x27
   31b1c:	mov	x3, x28
   31b20:	mov	x4, x24
   31b24:	bl	c3d0 <__gmpn_dcpi1_div_qr@plt>
   31b28:	ldp	x15, x14, [x29, #-64]
   31b2c:	cmp	x14, #0x2
   31b30:	b.ge	31b40 <__gmpn_tdiv_qr@@Base+0x7bc>  // b.tcont
   31b34:	ldur	x10, [x29, #-40]
   31b38:	mov	x8, xzr
   31b3c:	b	31b50 <__gmpn_tdiv_qr@@Base+0x7cc>
   31b40:	ldur	x10, [x29, #-40]
   31b44:	add	x8, x10, x14, lsl #3
   31b48:	ldur	x8, [x8, #-16]
   31b4c:	lsr	x8, x8, #1
   31b50:	sub	x25, x14, #0x1
   31b54:	ldr	x10, [x10, x25, lsl #3]
   31b58:	sub	x11, x15, #0x8
   31b5c:	ldr	x12, [x20, x11]
   31b60:	ldr	x11, [x26, x11]
   31b64:	mvn	w9, w22
   31b68:	lsl	x10, x10, x22
   31b6c:	lsr	x8, x8, x9
   31b70:	orr	x8, x10, x8
   31b74:	umulh	x8, x8, x12
   31b78:	cmp	x11, x8
   31b7c:	mov	x27, x24
   31b80:	b.cs	31bc4 <__gmpn_tdiv_qr@@Base+0x840>  // b.hs, b.nlast
   31b84:	mov	x19, x14
   31b88:	mov	x8, x20
   31b8c:	ldr	x9, [x8]
   31b90:	sub	x10, x9, #0x1
   31b94:	str	x10, [x8], #8
   31b98:	cbz	x9, 31b8c <__gmpn_tdiv_qr@@Base+0x808>
   31b9c:	mov	x0, x26
   31ba0:	mov	x1, x26
   31ba4:	mov	x2, x28
   31ba8:	mov	x3, x24
   31bac:	bl	ca90 <__gmpn_add_n@plt>
   31bb0:	mov	x27, x24
   31bb4:	mov	x14, x19
   31bb8:	cbz	x0, 31bc4 <__gmpn_tdiv_qr@@Base+0x840>
   31bbc:	add	x27, x24, #0x1
   31bc0:	str	x0, [x26, x24, lsl #3]
   31bc4:	cbz	w22, 31c38 <__gmpn_tdiv_qr@@Base+0x8b4>
   31bc8:	mov	w8, #0x40                  	// #64
   31bcc:	sub	w3, w8, w22
   31bd0:	mov	x0, x26
   31bd4:	mov	x1, x26
   31bd8:	mov	x2, x27
   31bdc:	bl	c190 <__gmpn_lshift@plt>
   31be0:	ldur	x8, [x29, #-48]
   31be4:	ldr	x9, [x26]
   31be8:	mov	x10, #0xffffffffffffffff    	// #-1
   31bec:	lsr	x10, x10, x22
   31bf0:	ldr	x8, [x8, x25, lsl #3]
   31bf4:	ldur	x22, [x29, #-40]
   31bf8:	mov	x28, x0
   31bfc:	mov	x0, x26
   31c00:	and	x8, x8, x10
   31c04:	orr	x8, x9, x8
   31c08:	str	x8, [x26]
   31c0c:	ldr	x8, [x22, x25, lsl #3]
   31c10:	mov	x1, x20
   31c14:	mov	x2, x24
   31c18:	and	x3, x8, x10
   31c1c:	bl	ca00 <__gmpn_submul_1@plt>
   31c20:	cmp	x24, x27
   31c24:	b.ne	31c48 <__gmpn_tdiv_qr@@Base+0x8c4>  // b.any
   31c28:	subs	x8, x28, x0
   31c2c:	cset	w23, cc  // cc = lo, ul, last
   31c30:	add	x27, x24, #0x1
   31c34:	b	31c58 <__gmpn_tdiv_qr@@Base+0x8d4>
   31c38:	ldur	x22, [x29, #-40]
   31c3c:	mov	x23, xzr
   31c40:	mov	x25, x14
   31c44:	b	31c5c <__gmpn_tdiv_qr@@Base+0x8d8>
   31c48:	ldr	x8, [x26, x24, lsl #3]
   31c4c:	subs	x8, x8, x0
   31c50:	b.cc	31f00 <__gmpn_tdiv_qr@@Base+0xb7c>  // b.lo, b.ul, b.last
   31c54:	mov	x23, xzr
   31c58:	str	x8, [x26, x24, lsl #3]
   31c5c:	lsl	x1, x21, #3
   31c60:	mov	w8, #0x7f00                	// #32512
   31c64:	cmp	x1, x8
   31c68:	b.hi	31e58 <__gmpn_tdiv_qr@@Base+0xad4>  // b.pmore
   31c6c:	add	x9, x1, #0xf
   31c70:	mov	x8, sp
   31c74:	and	x9, x9, #0xfffffffffffffff0
   31c78:	sub	x28, x8, x9
   31c7c:	mov	sp, x28
   31c80:	cmp	x25, x24
   31c84:	b.ge	31ca4 <__gmpn_tdiv_qr@@Base+0x920>  // b.tcont
   31c88:	cbz	x25, 31dd0 <__gmpn_tdiv_qr@@Base+0xa4c>
   31c8c:	mov	x0, x28
   31c90:	mov	x1, x20
   31c94:	mov	x2, x24
   31c98:	mov	x3, x22
   31c9c:	mov	x4, x25
   31ca0:	b	31cb8 <__gmpn_tdiv_qr@@Base+0x934>
   31ca4:	mov	x0, x28
   31ca8:	mov	x1, x22
   31cac:	mov	x2, x25
   31cb0:	mov	x3, x20
   31cb4:	mov	x4, x24
   31cb8:	bl	ccf0 <__gmpn_mul@plt>
   31cbc:	add	x2, x28, x25, lsl #3
   31cc0:	mov	x0, x26
   31cc4:	mov	x1, x26
   31cc8:	mov	x3, x24
   31ccc:	bl	c2e0 <__gmpn_sub_n@plt>
   31cd0:	cbz	x0, 31cf8 <__gmpn_tdiv_qr@@Base+0x974>
   31cd4:	mov	w19, #0x1                   	// #1
   31cd8:	cmp	x24, x27
   31cdc:	b.ge	31d04 <__gmpn_tdiv_qr@@Base+0x980>  // b.tcont
   31ce0:	ldr	x8, [x26, x24, lsl #3]
   31ce4:	add	x10, x24, #0x1
   31ce8:	sub	x9, x8, #0x1
   31cec:	str	x9, [x26, x24, lsl #3]
   31cf0:	mov	x24, x10
   31cf4:	cbz	x8, 31cd8 <__gmpn_tdiv_qr@@Base+0x954>
   31cf8:	mov	x22, x23
   31cfc:	mov	x19, xzr
   31d00:	b	31d08 <__gmpn_tdiv_qr@@Base+0x984>
   31d04:	mov	x22, x23
   31d08:	ldur	x23, [x29, #-32]
   31d0c:	sub	x2, x21, x25
   31d10:	mov	x1, x26
   31d14:	add	x24, x23, x25, lsl #3
   31d18:	mov	x0, x24
   31d1c:	bl	ca70 <__gmpn_copyi@plt>
   31d20:	ldur	x1, [x29, #-48]
   31d24:	mov	x0, x23
   31d28:	mov	x2, x28
   31d2c:	mov	x3, x25
   31d30:	orr	x19, x19, x22
   31d34:	bl	c2e0 <__gmpn_sub_n@plt>
   31d38:	ldr	x8, [x24]
   31d3c:	subs	x8, x8, x0
   31d40:	str	x8, [x24]
   31d44:	b.cs	31d74 <__gmpn_tdiv_qr@@Base+0x9f0>  // b.hs, b.nlast
   31d48:	ldur	x22, [x29, #-40]
   31d4c:	mov	w8, #0x1                   	// #1
   31d50:	mov	w9, #0x1                   	// #1
   31d54:	cmp	x9, x27
   31d58:	b.ge	31d7c <__gmpn_tdiv_qr@@Base+0x9f8>  // b.tcont
   31d5c:	ldr	x10, [x24, x9, lsl #3]
   31d60:	sub	x11, x10, #0x1
   31d64:	str	x11, [x24, x9, lsl #3]
   31d68:	add	x9, x9, #0x1
   31d6c:	cbz	x10, 31d54 <__gmpn_tdiv_qr@@Base+0x9d0>
   31d70:	b	31d78 <__gmpn_tdiv_qr@@Base+0x9f4>
   31d74:	ldur	x22, [x29, #-40]
   31d78:	mov	x8, xzr
   31d7c:	orr	x23, x19, x8
   31d80:	cbz	x23, 31da8 <__gmpn_tdiv_qr@@Base+0xa24>
   31d84:	ldr	x8, [x20]
   31d88:	sub	x9, x8, #0x1
   31d8c:	str	x9, [x20], #8
   31d90:	cbz	x8, 31d84 <__gmpn_tdiv_qr@@Base+0xa00>
   31d94:	ldur	x0, [x29, #-32]
   31d98:	mov	x2, x22
   31d9c:	mov	x3, x21
   31da0:	mov	x1, x0
   31da4:	bl	ca90 <__gmpn_add_n@plt>
   31da8:	ldur	x0, [x29, #-8]
   31dac:	cbnz	x0, 31e00 <__gmpn_tdiv_qr@@Base+0xa7c>
   31db0:	mov	sp, x29
   31db4:	ldp	x20, x19, [sp, #80]
   31db8:	ldp	x22, x21, [sp, #64]
   31dbc:	ldp	x24, x23, [sp, #48]
   31dc0:	ldp	x26, x25, [sp, #32]
   31dc4:	ldp	x28, x27, [sp, #16]
   31dc8:	ldp	x29, x30, [sp], #96
   31dcc:	ret
   31dd0:	ldur	x0, [x29, #-32]
   31dd4:	mov	x1, x26
   31dd8:	mov	x2, x27
   31ddc:	bl	ca70 <__gmpn_copyi@plt>
   31de0:	cmp	x27, x21
   31de4:	b.eq	31d80 <__gmpn_tdiv_qr@@Base+0x9fc>  // b.none
   31de8:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   31dec:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   31df0:	add	x0, x0, #0x75c
   31df4:	add	x2, x2, #0x77e
   31df8:	mov	w1, #0x169                 	// #361
   31dfc:	bl	c6e0 <__gmp_assert_fail@plt>
   31e00:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   31e04:	b	31db0 <__gmpn_tdiv_qr@@Base+0xa2c>
   31e08:	sub	x0, x29, #0x8
   31e0c:	mov	x22, x3
   31e10:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31e14:	mov	x3, x22
   31e18:	mov	x22, x0
   31e1c:	b	31534 <__gmpn_tdiv_qr@@Base+0x1b0>
   31e20:	sub	x0, x29, #0x8
   31e24:	mov	x19, x3
   31e28:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31e2c:	mov	x3, x19
   31e30:	mov	x21, x0
   31e34:	b	31668 <__gmpn_tdiv_qr@@Base+0x2e4>
   31e38:	sub	x0, x29, #0x8
   31e3c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31e40:	mov	x28, x0
   31e44:	b	315ec <__gmpn_tdiv_qr@@Base+0x268>
   31e48:	sub	x0, x29, #0x8
   31e4c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31e50:	mov	x27, x0
   31e54:	b	31628 <__gmpn_tdiv_qr@@Base+0x2a4>
   31e58:	sub	x0, x29, #0x8
   31e5c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31e60:	mov	x28, x0
   31e64:	b	31c80 <__gmpn_tdiv_qr@@Base+0x8fc>
   31e68:	sub	x0, x29, #0x8
   31e6c:	mov	x1, x11
   31e70:	mov	x26, x10
   31e74:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31e78:	mov	x10, x26
   31e7c:	mov	x27, x0
   31e80:	b	3144c <__gmpn_tdiv_qr@@Base+0xc8>
   31e84:	sub	x0, x29, #0x8
   31e88:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31e8c:	mov	x26, x0
   31e90:	b	314b0 <__gmpn_tdiv_qr@@Base+0x12c>
   31e94:	sub	x0, x29, #0x8
   31e98:	mov	x23, x3
   31e9c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31ea0:	mov	x3, x23
   31ea4:	mov	x27, x0
   31ea8:	b	316e0 <__gmpn_tdiv_qr@@Base+0x35c>
   31eac:	sub	x0, x29, #0x8
   31eb0:	mov	x19, x3
   31eb4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31eb8:	mov	x3, x19
   31ebc:	mov	x26, x0
   31ec0:	b	31850 <__gmpn_tdiv_qr@@Base+0x4cc>
   31ec4:	sub	x0, x29, #0x8
   31ec8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31ecc:	mov	x6, x0
   31ed0:	b	318dc <__gmpn_tdiv_qr@@Base+0x558>
   31ed4:	sub	x0, x29, #0x8
   31ed8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   31edc:	mov	x6, x0
   31ee0:	b	31aa8 <__gmpn_tdiv_qr@@Base+0x724>
   31ee4:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   31ee8:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   31eec:	add	x0, x0, #0x75c
   31ef0:	add	x2, x2, #0x766
   31ef4:	mov	w1, #0x32                  	// #50
   31ef8:	bl	c6e0 <__gmp_assert_fail@plt>
   31efc:	bl	bfe0 <__gmp_divide_by_zero@plt>
   31f00:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   31f04:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   31f08:	add	x0, x0, #0x75c
   31f0c:	add	x2, x2, #0x76f
   31f10:	mov	w1, #0x154                 	// #340
   31f14:	bl	c6e0 <__gmp_assert_fail@plt>

0000000000031f18 <__gmpn_jacobi_base@@Base>:
   31f18:	cbz	x0, 31f94 <__gmpn_jacobi_base@@Base+0x7c>
   31f1c:	lsr	x8, x1, #1
   31f20:	rbit	x9, x0
   31f24:	clz	x9, x9
   31f28:	eor	w10, w8, w1, lsr #2
   31f2c:	and	w10, w10, w9
   31f30:	lsr	x11, x0, x9
   31f34:	eor	w9, w10, w2, asr #1
   31f38:	lsr	x10, x11, #1
   31f3c:	subs	x11, x10, x8
   31f40:	b.eq	31f98 <__gmpn_jacobi_base@@Base+0x80>  // b.none
   31f44:	asr	x12, x11, #63
   31f48:	and	w10, w10, w8
   31f4c:	and	w10, w10, w12
   31f50:	eor	w9, w9, w10
   31f54:	and	x10, x12, x11
   31f58:	add	x8, x10, x8
   31f5c:	rbit	x10, x11
   31f60:	eor	x11, x12, x11
   31f64:	clz	x10, x10
   31f68:	sub	x11, x11, x12
   31f6c:	lsr	x12, x8, #1
   31f70:	add	w10, w10, #0x1
   31f74:	eor	w12, w12, w8
   31f78:	and	w12, w10, w12
   31f7c:	eor	w9, w9, w12
   31f80:	lsr	x10, x11, x10
   31f84:	cbnz	x8, 31f3c <__gmpn_jacobi_base@@Base+0x24>
   31f88:	ubfiz	w8, w9, #1, #1
   31f8c:	mov	w9, #0x1                   	// #1
   31f90:	sub	w0, w9, w8
   31f94:	ret
   31f98:	mov	w0, wzr
   31f9c:	ret

0000000000031fa0 <__gmpn_jacobi_2@@Base>:
   31fa0:	mov	x8, x0
   31fa4:	ldr	x10, [x8, #8]
   31fa8:	ldp	x9, x8, [x1]
   31fac:	ldr	x0, [x0]
   31fb0:	lsl	w2, w2, #1
   31fb4:	cmp	x9, #0x1
   31fb8:	b.ne	31fc0 <__gmpn_jacobi_2@@Base+0x20>  // b.any
   31fbc:	cbz	x8, 32150 <__gmpn_jacobi_2@@Base+0x1b0>
   31fc0:	cbz	x0, 320a8 <__gmpn_jacobi_2@@Base+0x108>
   31fc4:	tbnz	w0, #0, 31ff0 <__gmpn_jacobi_2@@Base+0x50>
   31fc8:	rbit	x11, x0
   31fcc:	clz	x11, x11
   31fd0:	eor	w12, w9, w9, lsr #1
   31fd4:	neg	x13, x11
   31fd8:	lsr	x14, x0, x11
   31fdc:	and	w12, w12, w11, lsl #1
   31fe0:	lsl	x13, x10, x13
   31fe4:	lsr	x10, x10, x11
   31fe8:	orr	x0, x13, x14
   31fec:	eor	w2, w2, w12
   31ff0:	cbz	x10, 320e0 <__gmpn_jacobi_2@@Base+0x140>
   31ff4:	cbz	x8, 321dc <__gmpn_jacobi_2@@Base+0x23c>
   31ff8:	cmp	x10, x8
   31ffc:	b.ls	3203c <__gmpn_jacobi_2@@Base+0x9c>  // b.plast
   32000:	eor	x11, x9, x9, lsr #1
   32004:	subs	x13, x0, x9
   32008:	sbc	x12, x10, x8
   3200c:	cbz	x13, 320f4 <__gmpn_jacobi_2@@Base+0x154>
   32010:	rbit	x10, x13
   32014:	clz	x10, x10
   32018:	neg	x15, x10
   3201c:	and	w14, w11, w10, lsl #1
   32020:	lsr	x13, x13, x10
   32024:	lsr	x10, x12, x10
   32028:	lsl	x12, x12, x15
   3202c:	eor	w2, w2, w14
   32030:	cmp	x10, x8
   32034:	orr	x0, x12, x13
   32038:	b.hi	32004 <__gmpn_jacobi_2@@Base+0x64>  // b.pmore
   3203c:	cmp	x10, x8
   32040:	b.eq	321e4 <__gmpn_jacobi_2@@Base+0x244>  // b.none
   32044:	and	w11, w0, w9
   32048:	eor	w2, w2, w11
   3204c:	cbz	x10, 320ec <__gmpn_jacobi_2@@Base+0x14c>
   32050:	cmp	x8, x10
   32054:	b.ls	32098 <__gmpn_jacobi_2@@Base+0xf8>  // b.plast
   32058:	eor	x11, x0, x0, lsr #1
   3205c:	subs	x12, x9, x0
   32060:	sbc	x9, x8, x10
   32064:	cbz	x12, 3211c <__gmpn_jacobi_2@@Base+0x17c>
   32068:	rbit	x8, x12
   3206c:	clz	x8, x8
   32070:	neg	x14, x8
   32074:	and	w13, w11, w8, lsl #1
   32078:	lsr	x12, x12, x8
   3207c:	lsr	x8, x9, x8
   32080:	lsl	x9, x9, x14
   32084:	eor	w2, w2, w13
   32088:	cmp	x8, x10
   3208c:	orr	x9, x9, x12
   32090:	b.hi	3205c <__gmpn_jacobi_2@@Base+0xbc>  // b.pmore
   32094:	and	w11, w9, w0
   32098:	cmp	x10, x8
   3209c:	eor	w2, w2, w11
   320a0:	b.ne	31ff4 <__gmpn_jacobi_2@@Base+0x54>  // b.any
   320a4:	b	321e8 <__gmpn_jacobi_2@@Base+0x248>
   320a8:	cbz	x10, 32238 <__gmpn_jacobi_2@@Base+0x298>
   320ac:	rbit	x11, x10
   320b0:	clz	x11, x11
   320b4:	lsr	x12, x9, #1
   320b8:	lsl	w13, w11, #1
   320bc:	eor	w12, w12, w9
   320c0:	lsr	x1, x10, x11
   320c4:	orr	w10, w13, #0x80
   320c8:	and	w10, w10, w12
   320cc:	cmp	x1, #0x1
   320d0:	eor	w10, w2, w10
   320d4:	b.ne	32160 <__gmpn_jacobi_2@@Base+0x1c0>  // b.any
   320d8:	and	w8, w10, #0x2
   320dc:	b	32154 <__gmpn_jacobi_2@@Base+0x1b4>
   320e0:	cbz	x8, 321d4 <__gmpn_jacobi_2@@Base+0x234>
   320e4:	and	w10, w0, w9
   320e8:	eor	w2, w2, w10
   320ec:	mov	x1, x0
   320f0:	b	32148 <__gmpn_jacobi_2@@Base+0x1a8>
   320f4:	rbit	x10, x12
   320f8:	clz	x10, x10
   320fc:	lsl	w13, w10, #1
   32100:	lsr	x1, x12, x10
   32104:	add	w10, w13, #0x80
   32108:	and	w12, w1, w9
   3210c:	and	w10, w10, w11
   32110:	eor	w11, w2, w12
   32114:	eor	w2, w11, w10
   32118:	b	32148 <__gmpn_jacobi_2@@Base+0x1a8>
   3211c:	rbit	x8, x9
   32120:	clz	x8, x8
   32124:	lsl	w12, w8, #1
   32128:	lsr	x1, x9, x8
   3212c:	add	w8, w12, #0x80
   32130:	and	w9, w1, w0
   32134:	and	w8, w8, w11
   32138:	eor	w9, w2, w9
   3213c:	eor	w2, w9, w8
   32140:	mov	x9, x0
   32144:	mov	x8, x10
   32148:	cmp	x1, #0x1
   3214c:	b.ne	32168 <__gmpn_jacobi_2@@Base+0x1c8>  // b.any
   32150:	and	w8, w2, #0x2
   32154:	mov	w9, #0x1                   	// #1
   32158:	sub	w0, w9, w8
   3215c:	ret
   32160:	and	w11, w1, w9
   32164:	eor	w2, w10, w11
   32168:	cbz	x8, 321a8 <__gmpn_jacobi_2@@Base+0x208>
   3216c:	eor	x10, x1, x1, lsr #1
   32170:	subs	x11, x9, x1
   32174:	cset	w9, cc  // cc = lo, ul, last
   32178:	sub	x9, x8, x9
   3217c:	cbz	x11, 321b0 <__gmpn_jacobi_2@@Base+0x210>
   32180:	rbit	x8, x11
   32184:	clz	x12, x8
   32188:	neg	x13, x12
   3218c:	lsr	x11, x11, x12
   32190:	lsr	x8, x9, x12
   32194:	and	w12, w10, w12, lsl #1
   32198:	lsl	x9, x9, x13
   3219c:	orr	x9, x9, x11
   321a0:	eor	w2, w2, w12
   321a4:	cbnz	x8, 32170 <__gmpn_jacobi_2@@Base+0x1d0>
   321a8:	mov	x0, x9
   321ac:	b	c750 <__gmpn_jacobi_base@plt>
   321b0:	cbz	x9, 32238 <__gmpn_jacobi_2@@Base+0x298>
   321b4:	rbit	x8, x9
   321b8:	clz	x8, x8
   321bc:	lsl	w11, w8, #1
   321c0:	orr	w11, w11, #0x80
   321c4:	and	w10, w11, w10
   321c8:	eor	w2, w2, w10
   321cc:	lsr	x0, x9, x8
   321d0:	b	c750 <__gmpn_jacobi_base@plt>
   321d4:	mov	x1, x9
   321d8:	b	c750 <__gmpn_jacobi_base@plt>
   321dc:	mov	x1, x9
   321e0:	b	32140 <__gmpn_jacobi_2@@Base+0x1a0>
   321e4:	mov	x10, x8
   321e8:	cmp	x0, x9
   321ec:	csel	x11, x0, x9, cc  // cc = lo, ul, last
   321f0:	csel	x8, x9, x0, cc  // cc = lo, ul, last
   321f4:	subs	x8, x8, x11
   321f8:	b.eq	32238 <__gmpn_jacobi_2@@Base+0x298>  // b.none
   321fc:	and	w12, w9, w0
   32200:	cmp	x0, x9
   32204:	rbit	x9, x8
   32208:	lsr	x13, x11, #1
   3220c:	csel	w12, w12, wzr, cc  // cc = lo, ul, last
   32210:	clz	x9, x9
   32214:	eor	w13, w13, w11
   32218:	eor	w12, w12, w2
   3221c:	and	w13, w13, w9, lsl #1
   32220:	lsr	x1, x8, x9
   32224:	cmp	x1, #0x1
   32228:	eor	w8, w12, w13
   3222c:	b.ne	32240 <__gmpn_jacobi_2@@Base+0x2a0>  // b.any
   32230:	and	w8, w8, #0x2
   32234:	b	32154 <__gmpn_jacobi_2@@Base+0x1b4>
   32238:	mov	w0, wzr
   3223c:	ret
   32240:	and	w9, w1, w11
   32244:	eor	w2, w8, w9
   32248:	mov	x8, x10
   3224c:	mov	x9, x11
   32250:	cbnz	x8, 3216c <__gmpn_jacobi_2@@Base+0x1cc>
   32254:	b	321a8 <__gmpn_jacobi_2@@Base+0x208>

0000000000032258 <__gmpn_jacobi_n@@Base>:
   32258:	stp	x29, x30, [sp, #-96]!
   3225c:	str	x27, [sp, #16]
   32260:	stp	x26, x25, [sp, #32]
   32264:	stp	x24, x23, [sp, #48]
   32268:	stp	x22, x21, [sp, #64]
   3226c:	stp	x20, x19, [sp, #80]
   32270:	mov	x29, sp
   32274:	sub	sp, sp, #0x40
   32278:	mov	x21, x2
   3227c:	mov	x19, x1
   32280:	mov	x20, x0
   32284:	cmp	x2, #0x14a
   32288:	mov	x8, x2
   3228c:	str	w3, [x29, #28]
   32290:	b.lt	322e8 <__gmpn_jacobi_n@@Base+0x90>  // b.tstop
   32294:	mov	x9, #0x5555555555555555    	// #6148914691236517205
   32298:	lsl	x8, x21, #1
   3229c:	movk	x9, #0x5556
   322a0:	smulh	x8, x8, x9
   322a4:	add	x22, x8, x8, lsr #63
   322a8:	sub	x0, x21, x22
   322ac:	add	x8, x0, #0x1
   322b0:	add	x9, x0, #0x2
   322b4:	cmp	x8, #0x0
   322b8:	csinc	x8, x9, x0, lt  // lt = tstop
   322bc:	lsl	x8, x8, #1
   322c0:	and	x23, x8, #0xfffffffffffffffc
   322c4:	bl	c5b0 <__gmpn_hgcd_itch@plt>
   322c8:	add	x8, x22, x21
   322cc:	sub	x9, x8, #0x1
   322d0:	cmp	x0, x8
   322d4:	csel	x8, x9, x0, lt  // lt = tstop
   322d8:	add	x8, x23, x8
   322dc:	add	x8, x8, #0x4
   322e0:	cmp	x8, x21
   322e4:	csel	x8, x8, x21, gt
   322e8:	lsl	x1, x8, #3
   322ec:	mov	w8, #0x7f00                	// #32512
   322f0:	cmp	x1, x8
   322f4:	stur	xzr, [x29, #-8]
   322f8:	b.hi	32590 <__gmpn_jacobi_n@@Base+0x338>  // b.pmore
   322fc:	add	x9, x1, #0xf
   32300:	mov	x8, sp
   32304:	and	x9, x9, #0xfffffffffffffff0
   32308:	sub	x22, x8, x9
   3230c:	mov	sp, x22
   32310:	cmp	x21, #0x14a
   32314:	b.lt	323e0 <__gmpn_jacobi_n@@Base+0x188>  // b.tstop
   32318:	mov	x27, #0x5555555555555555    	// #6148914691236517205
   3231c:	adrp	x23, 32000 <__gmpn_jacobi_2@@Base+0x60>
   32320:	movk	x27, #0x5556
   32324:	add	x23, x23, #0x5b4
   32328:	lsl	x8, x21, #1
   3232c:	smulh	x8, x8, x27
   32330:	add	x24, x8, x8, lsr #63
   32334:	sub	x26, x21, x24
   32338:	add	x8, x26, #0x1
   3233c:	add	x9, x26, #0x2
   32340:	cmp	x8, #0x0
   32344:	csinc	x8, x9, x26, lt  // lt = tstop
   32348:	lsl	x8, x8, #4
   3234c:	sub	x0, x29, #0x38
   32350:	mov	x1, x26
   32354:	mov	x2, x22
   32358:	and	x25, x8, #0xffffffffffffffe0
   3235c:	bl	c850 <__gmpn_hgcd_matrix_init@plt>
   32360:	add	x8, x25, x22
   32364:	add	x25, x8, #0x20
   32368:	add	x0, x20, x24, lsl #3
   3236c:	add	x1, x19, x24, lsl #3
   32370:	sub	x3, x29, #0x38
   32374:	add	x4, x29, #0x1c
   32378:	mov	x2, x26
   3237c:	mov	x5, x25
   32380:	bl	d3b0 <__gmpn_hgcd_jacobi@plt>
   32384:	cmp	x0, #0x1
   32388:	b.lt	323b0 <__gmpn_jacobi_n@@Base+0x158>  // b.tstop
   3238c:	add	x1, x0, x24
   32390:	sub	x0, x29, #0x38
   32394:	mov	x2, x20
   32398:	mov	x3, x19
   3239c:	mov	x4, x24
   323a0:	mov	x5, x25
   323a4:	bl	c8c0 <__gmpn_hgcd_matrix_adjust@plt>
   323a8:	mov	x21, x0
   323ac:	b	323d8 <__gmpn_jacobi_n@@Base+0x180>
   323b0:	add	x5, x29, #0x1c
   323b4:	mov	x0, x20
   323b8:	mov	x1, x19
   323bc:	mov	x2, x21
   323c0:	mov	x3, xzr
   323c4:	mov	x4, x23
   323c8:	mov	x6, x22
   323cc:	bl	d2d0 <__gmpn_gcd_subdiv_step@plt>
   323d0:	mov	x21, x0
   323d4:	cbz	x0, 32538 <__gmpn_jacobi_n@@Base+0x2e0>
   323d8:	cmp	x21, #0x149
   323dc:	b.gt	32328 <__gmpn_jacobi_n@@Base+0xd0>
   323e0:	cmp	x21, #0x3
   323e4:	b.lt	324d4 <__gmpn_jacobi_n@@Base+0x27c>  // b.tstop
   323e8:	adrp	x23, 32000 <__gmpn_jacobi_2@@Base+0x60>
   323ec:	add	x23, x23, #0x5b4
   323f0:	lsl	x8, x21, #3
   323f4:	sub	x9, x8, #0x8
   323f8:	ldr	x0, [x20, x9]
   323fc:	ldr	x2, [x19, x9]
   32400:	orr	x9, x2, x0
   32404:	tbnz	x9, #63, 3245c <__gmpn_jacobi_n@@Base+0x204>
   32408:	sub	x10, x8, #0x10
   3240c:	sub	x8, x8, #0x18
   32410:	ldr	x12, [x20, x10]
   32414:	ldr	x14, [x20, x8]
   32418:	ldr	x10, [x19, x10]
   3241c:	ldr	x8, [x19, x8]
   32420:	clz	x9, x9
   32424:	neg	x13, x9
   32428:	lsl	x11, x0, x9
   3242c:	lsl	x15, x2, x9
   32430:	lsr	x16, x12, x13
   32434:	lsl	x12, x12, x9
   32438:	lsr	x14, x14, x13
   3243c:	lsl	x9, x10, x9
   32440:	lsr	x10, x10, x13
   32444:	lsr	x8, x8, x13
   32448:	orr	x0, x16, x11
   3244c:	orr	x1, x14, x12
   32450:	orr	x2, x10, x15
   32454:	orr	x3, x8, x9
   32458:	b	32468 <__gmpn_jacobi_n@@Base+0x210>
   3245c:	sub	x8, x8, #0x10
   32460:	ldr	x1, [x20, x8]
   32464:	ldr	x3, [x19, x8]
   32468:	sub	x4, x29, #0x38
   3246c:	add	x5, x29, #0x1c
   32470:	bl	cb10 <__gmpn_hgcd2_jacobi@plt>
   32474:	cbz	w0, 324a4 <__gmpn_jacobi_n@@Base+0x24c>
   32478:	sub	x0, x29, #0x38
   3247c:	mov	x1, x22
   32480:	mov	x2, x20
   32484:	mov	x3, x19
   32488:	mov	x4, x21
   3248c:	bl	c510 <__gmpn_matrix22_mul1_inverse_vector@plt>
   32490:	mov	x21, x0
   32494:	mov	x0, x20
   32498:	mov	x20, x22
   3249c:	mov	x22, x0
   324a0:	b	324cc <__gmpn_jacobi_n@@Base+0x274>
   324a4:	add	x5, x29, #0x1c
   324a8:	mov	x0, x20
   324ac:	mov	x1, x19
   324b0:	mov	x2, x21
   324b4:	mov	x3, xzr
   324b8:	mov	x4, x23
   324bc:	mov	x6, x22
   324c0:	bl	d2d0 <__gmpn_gcd_subdiv_step@plt>
   324c4:	mov	x21, x0
   324c8:	cbz	x0, 32538 <__gmpn_jacobi_n@@Base+0x2e0>
   324cc:	cmp	x21, #0x2
   324d0:	b.gt	323f0 <__gmpn_jacobi_n@@Base+0x198>
   324d4:	ldr	w8, [x29, #28]
   324d8:	cmp	w8, #0xf
   324dc:	csel	x1, x20, x19, hi  // hi = pmore
   324e0:	csel	x0, x19, x20, hi  // hi = pmore
   324e4:	cmp	x21, #0x1
   324e8:	b.ne	32518 <__gmpn_jacobi_n@@Base+0x2c0>  // b.any
   324ec:	ldr	x19, [x0]
   324f0:	ldur	x0, [x29, #-8]
   324f4:	ldr	x20, [x1]
   324f8:	cbnz	x0, 325a0 <__gmpn_jacobi_n@@Base+0x348>
   324fc:	cmp	x20, #0x1
   32500:	lsl	w2, w8, #1
   32504:	b.ne	3255c <__gmpn_jacobi_n@@Base+0x304>  // b.any
   32508:	and	w8, w2, #0x2
   3250c:	mov	w9, #0x1                   	// #1
   32510:	sub	w19, w9, w8
   32514:	b	3256c <__gmpn_jacobi_n@@Base+0x314>
   32518:	and	w2, w8, #0x1
   3251c:	bl	cad0 <__gmpn_jacobi_2@plt>
   32520:	ldur	x8, [x29, #-8]
   32524:	mov	w19, w0
   32528:	cbz	x8, 3256c <__gmpn_jacobi_n@@Base+0x314>
   3252c:	mov	x0, x8
   32530:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   32534:	b	3256c <__gmpn_jacobi_n@@Base+0x314>
   32538:	ldur	x0, [x29, #-8]
   3253c:	cbnz	x0, 325ac <__gmpn_jacobi_n@@Base+0x354>
   32540:	ldr	w8, [x29, #28]
   32544:	mov	w9, #0x1                   	// #1
   32548:	ubfiz	w10, w8, #1, #1
   3254c:	sub	w9, w9, w10
   32550:	cmp	w8, #0x1f
   32554:	csel	w19, wzr, w9, eq  // eq = none
   32558:	b	3256c <__gmpn_jacobi_n@@Base+0x314>
   3255c:	mov	x0, x19
   32560:	mov	x1, x20
   32564:	bl	c750 <__gmpn_jacobi_base@plt>
   32568:	mov	w19, w0
   3256c:	mov	w0, w19
   32570:	mov	sp, x29
   32574:	ldp	x20, x19, [sp, #80]
   32578:	ldp	x22, x21, [sp, #64]
   3257c:	ldp	x24, x23, [sp, #48]
   32580:	ldp	x26, x25, [sp, #32]
   32584:	ldr	x27, [sp, #16]
   32588:	ldp	x29, x30, [sp], #96
   3258c:	ret
   32590:	sub	x0, x29, #0x8
   32594:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   32598:	mov	x22, x0
   3259c:	b	32310 <__gmpn_jacobi_n@@Base+0xb8>
   325a0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   325a4:	ldr	w8, [x29, #28]
   325a8:	b	324fc <__gmpn_jacobi_n@@Base+0x2a4>
   325ac:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   325b0:	b	32540 <__gmpn_jacobi_n@@Base+0x2e8>
   325b4:	cbz	x1, 325cc <__gmpn_jacobi_n@@Base+0x374>
   325b8:	cmp	x2, #0x1
   325bc:	b.ne	325f4 <__gmpn_jacobi_n@@Base+0x39c>  // b.any
   325c0:	ldr	x8, [x1]
   325c4:	cmp	x8, #0x1
   325c8:	b.ne	325f4 <__gmpn_jacobi_n@@Base+0x39c>  // b.any
   325cc:	cbz	x3, 325fc <__gmpn_jacobi_n@@Base+0x3a4>
   325d0:	ldr	w8, [x0]
   325d4:	ldr	w9, [x3]
   325d8:	lsl	w8, w8, #3
   325dc:	add	w8, w8, w5, lsl #2
   325e0:	bfxil	w8, w9, #0, #2
   325e4:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   325e8:	ldr	x9, [x9, #3872]
   325ec:	ldrb	w8, [x9, w8, uxtw]
   325f0:	b	325f8 <__gmpn_jacobi_n@@Base+0x3a0>
   325f4:	mov	w8, #0x1f                  	// #31
   325f8:	str	w8, [x0]
   325fc:	ret

0000000000032600 <__gmpn_get_d@@Base>:
   32600:	fmov	d0, xzr
   32604:	cbz	x1, 32690 <__gmpn_get_d@@Base+0x90>
   32608:	mov	x9, #0x7fffffffffffffff    	// #9223372036854775807
   3260c:	lsl	x8, x1, #6
   32610:	sub	x9, x9, x3
   32614:	cmp	x8, x9
   32618:	b.hi	32694 <__gmpn_get_d@@Base+0x94>  // b.pmore
   3261c:	add	x9, x0, x1, lsl #3
   32620:	ldur	x10, [x9, #-8]
   32624:	add	x8, x8, x3
   32628:	cmp	x1, #0x2
   3262c:	clz	x11, x10
   32630:	mvn	x12, x11
   32634:	add	x8, x8, x12
   32638:	lsl	x10, x10, x11
   3263c:	b.lt	32658 <__gmpn_get_d@@Base+0x58>  // b.tstop
   32640:	cmp	w11, #0xc
   32644:	b.cc	32658 <__gmpn_get_d@@Base+0x58>  // b.lo, b.ul, b.last
   32648:	ldur	x9, [x9, #-16]
   3264c:	neg	x11, x11
   32650:	lsr	x9, x9, x11
   32654:	orr	x10, x9, x10
   32658:	cmp	x8, #0x3ff
   3265c:	b.gt	32694 <__gmpn_get_d@@Base+0x94>
   32660:	cmn	x8, #0x3ff
   32664:	lsr	x9, x10, #11
   32668:	b.le	326a4 <__gmpn_get_d@@Base+0xa4>
   3266c:	lsr	x10, x10, #43
   32670:	mov	x11, #0x3ff0000000000000    	// #4607182418800017408
   32674:	and	x12, x2, #0x8000000000000000
   32678:	add	x8, x11, x8, lsl #52
   3267c:	bfxil	x12, x9, #0, #32
   32680:	and	x8, x8, #0x7ff0000000000000
   32684:	bfi	x12, x10, #32, #20
   32688:	orr	x8, x12, x8
   3268c:	fmov	d0, x8
   32690:	ret
   32694:	mov	x10, xzr
   32698:	mov	x9, xzr
   3269c:	mov	w8, #0x400                 	// #1024
   326a0:	b	32670 <__gmpn_get_d@@Base+0x70>
   326a4:	cmn	x8, #0x432
   326a8:	b.lt	32690 <__gmpn_get_d@@Base+0x90>  // b.tstop
   326ac:	mov	w10, #0xfffffc02            	// #-1022
   326b0:	sub	w8, w10, w8
   326b4:	lsr	x9, x9, x8
   326b8:	lsr	x10, x9, #32
   326bc:	mov	x8, #0xfffffffffffffc01    	// #-1023
   326c0:	b	32670 <__gmpn_get_d@@Base+0x70>

00000000000326c4 <__gmpn_matrix22_mul_itch@@Base>:
   326c4:	cmp	x0, #0xa
   326c8:	b.lt	326e4 <__gmpn_matrix22_mul_itch@@Base+0x20>  // b.tstop
   326cc:	cmp	x1, #0x9
   326d0:	b.le	326e4 <__gmpn_matrix22_mul_itch@@Base+0x20>
   326d4:	add	x8, x1, x0
   326d8:	add	x8, x8, x8, lsl #1
   326dc:	add	x0, x8, #0x5
   326e0:	ret
   326e4:	add	x8, x0, x0, lsl #1
   326e8:	add	x0, x8, x1, lsl #1
   326ec:	ret

00000000000326f0 <__gmpn_matrix22_mul@@Base>:
   326f0:	sub	sp, sp, #0xe0
   326f4:	stp	x29, x30, [sp, #128]
   326f8:	stp	x28, x27, [sp, #144]
   326fc:	stp	x26, x25, [sp, #160]
   32700:	stp	x24, x23, [sp, #176]
   32704:	stp	x22, x21, [sp, #192]
   32708:	stp	x20, x19, [sp, #208]
   3270c:	add	x29, sp, #0x80
   32710:	ldp	x24, x27, [x29, #104]
   32714:	ldr	x8, [x29, #96]
   32718:	mov	x22, x4
   3271c:	mov	x28, x2
   32720:	mov	x21, x1
   32724:	cmp	x4, #0xa
   32728:	mov	x19, x0
   3272c:	stp	x5, x7, [x29, #-32]
   32730:	stp	x3, x8, [x29, #-16]
   32734:	stp	x6, x27, [x29, #-48]
   32738:	b.lt	32790 <__gmpn_matrix22_mul@@Base+0xa0>  // b.tstop
   3273c:	cmp	x24, #0x9
   32740:	b.le	32790 <__gmpn_matrix22_mul@@Base+0xa0>
   32744:	add	x8, x22, #0x1
   32748:	add	x9, x24, #0x1
   3274c:	stp	x9, x8, [sp, #56]
   32750:	add	x8, x27, x8, lsl #3
   32754:	add	x10, x24, x22
   32758:	add	x20, x8, x9, lsl #3
   3275c:	mov	x25, x6
   32760:	mov	x23, x3
   32764:	cmp	x22, x24
   32768:	add	x26, x10, #0x1
   3276c:	mov	x0, x20
   32770:	stur	x8, [x29, #-56]
   32774:	str	x10, [sp, #40]
   32778:	b.lt	328e0 <__gmpn_matrix22_mul@@Base+0x1f0>  // b.tstop
   3277c:	ldur	x3, [x29, #-24]
   32780:	mov	x1, x21
   32784:	mov	x2, x22
   32788:	mov	x4, x24
   3278c:	b	328f0 <__gmpn_matrix22_mul@@Base+0x200>
   32790:	ldur	x26, [x29, #-40]
   32794:	add	x25, x27, x22, lsl #3
   32798:	add	x9, x25, x22, lsl #3
   3279c:	mov	w8, wzr
   327a0:	add	x23, x9, x24, lsl #3
   327a4:	add	x20, x24, x22
   327a8:	mov	x0, x26
   327ac:	mov	x1, x19
   327b0:	mov	x2, x22
   327b4:	mov	w27, w8
   327b8:	bl	ca70 <__gmpn_copyi@plt>
   327bc:	mov	x0, x25
   327c0:	cmp	x22, x24
   327c4:	b.ge	32824 <__gmpn_matrix22_mul@@Base+0x134>  // b.tcont
   327c8:	ldur	x1, [x29, #-32]
   327cc:	mov	x2, x24
   327d0:	mov	x3, x19
   327d4:	mov	x4, x22
   327d8:	bl	ccf0 <__gmpn_mul@plt>
   327dc:	ldur	x1, [x29, #-8]
   327e0:	mov	x0, x23
   327e4:	mov	x2, x24
   327e8:	mov	x3, x21
   327ec:	mov	x4, x22
   327f0:	bl	ccf0 <__gmpn_mul@plt>
   327f4:	ldur	x1, [x29, #-24]
   327f8:	mov	x0, x19
   327fc:	mov	x2, x24
   32800:	mov	x3, x21
   32804:	mov	x4, x22
   32808:	bl	ccf0 <__gmpn_mul@plt>
   3280c:	ldur	x1, [x29, #-48]
   32810:	mov	x0, x21
   32814:	mov	x2, x24
   32818:	mov	x3, x26
   3281c:	mov	x4, x22
   32820:	b	3287c <__gmpn_matrix22_mul@@Base+0x18c>
   32824:	ldur	x3, [x29, #-32]
   32828:	mov	x1, x19
   3282c:	mov	x2, x22
   32830:	mov	x4, x24
   32834:	bl	ccf0 <__gmpn_mul@plt>
   32838:	ldur	x3, [x29, #-8]
   3283c:	mov	x0, x23
   32840:	mov	x1, x21
   32844:	mov	x2, x22
   32848:	mov	x4, x24
   3284c:	bl	ccf0 <__gmpn_mul@plt>
   32850:	ldur	x3, [x29, #-24]
   32854:	mov	x0, x19
   32858:	mov	x1, x21
   3285c:	mov	x2, x22
   32860:	mov	x4, x24
   32864:	bl	ccf0 <__gmpn_mul@plt>
   32868:	ldur	x3, [x29, #-48]
   3286c:	mov	x0, x21
   32870:	mov	x1, x26
   32874:	mov	x2, x22
   32878:	mov	x4, x24
   3287c:	bl	ccf0 <__gmpn_mul@plt>
   32880:	mov	x0, x19
   32884:	mov	x1, x19
   32888:	mov	x2, x25
   3288c:	mov	x3, x20
   32890:	bl	ca90 <__gmpn_add_n@plt>
   32894:	str	x0, [x19, x20, lsl #3]
   32898:	mov	x0, x21
   3289c:	mov	x1, x21
   328a0:	mov	x2, x23
   328a4:	mov	x3, x20
   328a8:	bl	ca90 <__gmpn_add_n@plt>
   328ac:	str	x0, [x21, x20, lsl #3]
   328b0:	ldur	x21, [x29, #-16]
   328b4:	mov	w8, #0x1                   	// #1
   328b8:	mov	x19, x28
   328bc:	cbz	w27, 327a8 <__gmpn_matrix22_mul@@Base+0xb8>
   328c0:	ldp	x20, x19, [sp, #208]
   328c4:	ldp	x22, x21, [sp, #192]
   328c8:	ldp	x24, x23, [sp, #176]
   328cc:	ldp	x26, x25, [sp, #160]
   328d0:	ldp	x28, x27, [sp, #144]
   328d4:	ldp	x29, x30, [sp, #128]
   328d8:	add	sp, sp, #0xe0
   328dc:	ret
   328e0:	ldur	x1, [x29, #-24]
   328e4:	mov	x2, x24
   328e8:	mov	x3, x21
   328ec:	mov	x4, x22
   328f0:	bl	ccf0 <__gmpn_mul@plt>
   328f4:	mov	x0, x23
   328f8:	mov	x1, x23
   328fc:	mov	x2, x28
   32900:	mov	x3, x22
   32904:	str	x20, [sp, #48]
   32908:	str	x26, [sp]
   3290c:	add	x26, x20, x26, lsl #3
   32910:	bl	32e08 <__gmpn_matrix22_mul@@Base+0x718>
   32914:	str	x28, [sp, #24]
   32918:	str	w0, [sp, #16]
   3291c:	cbz	w0, 32964 <__gmpn_matrix22_mul@@Base+0x274>
   32920:	mov	x0, x21
   32924:	mov	x1, x21
   32928:	mov	x2, x23
   3292c:	mov	x3, x22
   32930:	bl	32e08 <__gmpn_matrix22_mul@@Base+0x718>
   32934:	str	xzr, [x21, x22, lsl #3]
   32938:	cbz	w0, 329a8 <__gmpn_matrix22_mul@@Base+0x2b8>
   3293c:	str	w0, [sp, #8]
   32940:	mov	x0, x27
   32944:	mov	x1, x21
   32948:	mov	x2, x19
   3294c:	mov	x3, x22
   32950:	bl	ca90 <__gmpn_add_n@plt>
   32954:	mov	w9, #0x1                   	// #1
   32958:	mov	w8, wzr
   3295c:	str	w9, [sp, #12]
   32960:	b	329c8 <__gmpn_matrix22_mul@@Base+0x2d8>
   32964:	mov	x0, x21
   32968:	mov	x1, x21
   3296c:	mov	x2, x23
   32970:	mov	x3, x22
   32974:	bl	ca90 <__gmpn_add_n@plt>
   32978:	str	x0, [x21, x22, lsl #3]
   3297c:	cbz	x0, 329a8 <__gmpn_matrix22_mul@@Base+0x2b8>
   32980:	mov	x20, x0
   32984:	mov	x0, x27
   32988:	mov	x1, x21
   3298c:	mov	x2, x19
   32990:	mov	x3, x22
   32994:	bl	c2e0 <__gmpn_sub_n@plt>
   32998:	str	xzr, [sp, #8]
   3299c:	sub	x0, x20, x0
   329a0:	mov	w8, #0x1                   	// #1
   329a4:	b	329c8 <__gmpn_matrix22_mul@@Base+0x2d8>
   329a8:	mov	x0, x27
   329ac:	mov	x1, x19
   329b0:	mov	x2, x21
   329b4:	mov	x3, x22
   329b8:	bl	32e08 <__gmpn_matrix22_mul@@Base+0x718>
   329bc:	mov	w8, w0
   329c0:	mov	x0, xzr
   329c4:	str	xzr, [sp, #8]
   329c8:	ldur	x20, [x29, #-56]
   329cc:	ldr	x28, [sp, #40]
   329d0:	cmp	x22, x24
   329d4:	str	x0, [x27, x22, lsl #3]
   329d8:	mov	x0, x26
   329dc:	str	w8, [sp, #20]
   329e0:	b.lt	329f8 <__gmpn_matrix22_mul@@Base+0x308>  // b.tstop
   329e4:	ldur	x3, [x29, #-32]
   329e8:	mov	x1, x19
   329ec:	mov	x2, x22
   329f0:	mov	x4, x24
   329f4:	b	32a08 <__gmpn_matrix22_mul@@Base+0x318>
   329f8:	ldur	x1, [x29, #-32]
   329fc:	mov	x2, x24
   32a00:	mov	x3, x19
   32a04:	mov	x4, x22
   32a08:	bl	ccf0 <__gmpn_mul@plt>
   32a0c:	ldr	x27, [sp, #48]
   32a10:	mov	x0, x19
   32a14:	mov	x2, x26
   32a18:	mov	x3, x28
   32a1c:	mov	x1, x27
   32a20:	bl	ca90 <__gmpn_add_n@plt>
   32a24:	ldur	x1, [x29, #-8]
   32a28:	ldur	x2, [x29, #-24]
   32a2c:	str	x0, [x19, x28, lsl #3]
   32a30:	mov	x0, x20
   32a34:	mov	x3, x24
   32a38:	bl	32e08 <__gmpn_matrix22_mul@@Base+0x718>
   32a3c:	cmp	x22, x24
   32a40:	mov	w19, w0
   32a44:	mov	x0, x26
   32a48:	b.lt	32a60 <__gmpn_matrix22_mul@@Base+0x370>  // b.tstop
   32a4c:	mov	x1, x23
   32a50:	mov	x2, x22
   32a54:	mov	x3, x20
   32a58:	mov	x4, x24
   32a5c:	b	32a70 <__gmpn_matrix22_mul@@Base+0x380>
   32a60:	mov	x1, x20
   32a64:	mov	x2, x24
   32a68:	mov	x3, x23
   32a6c:	mov	x4, x22
   32a70:	bl	ccf0 <__gmpn_mul@plt>
   32a74:	mov	x0, x20
   32a78:	str	xzr, [x26, x28, lsl #3]
   32a7c:	str	x26, [sp, #32]
   32a80:	cbz	w19, 32ae0 <__gmpn_matrix22_mul@@Base+0x3f0>
   32a84:	mov	x1, x25
   32a88:	mov	x2, x20
   32a8c:	mov	x3, x24
   32a90:	bl	32e08 <__gmpn_matrix22_mul@@Base+0x718>
   32a94:	add	x20, x20, x24, lsl #3
   32a98:	mov	w28, w0
   32a9c:	str	xzr, [x20]
   32aa0:	ldr	x4, [sp, #64]
   32aa4:	ldr	x26, [sp]
   32aa8:	ldr	w25, [sp, #12]
   32aac:	mov	x0, x23
   32ab0:	cmp	x4, x24
   32ab4:	b.ge	32ac8 <__gmpn_matrix22_mul@@Base+0x3d8>  // b.tcont
   32ab8:	ldur	x1, [x29, #-56]
   32abc:	mov	x2, x24
   32ac0:	mov	x3, x21
   32ac4:	b	32ad8 <__gmpn_matrix22_mul@@Base+0x3e8>
   32ac8:	ldur	x3, [x29, #-56]
   32acc:	mov	x1, x21
   32ad0:	mov	x2, x4
   32ad4:	mov	x4, x24
   32ad8:	bl	ccf0 <__gmpn_mul@plt>
   32adc:	b	32b60 <__gmpn_matrix22_mul@@Base+0x470>
   32ae0:	mov	x1, x20
   32ae4:	mov	x2, x25
   32ae8:	mov	x3, x24
   32aec:	bl	ca90 <__gmpn_add_n@plt>
   32af0:	add	x20, x20, x24, lsl #3
   32af4:	str	x0, [x20]
   32af8:	cbz	x0, 32b1c <__gmpn_matrix22_mul@@Base+0x42c>
   32afc:	mov	x0, x23
   32b00:	cmp	x24, x22
   32b04:	b.ge	32b24 <__gmpn_matrix22_mul@@Base+0x434>  // b.tcont
   32b08:	ldur	x3, [x29, #-56]
   32b0c:	ldr	x4, [sp, #56]
   32b10:	mov	x1, x21
   32b14:	mov	x2, x22
   32b18:	b	32b34 <__gmpn_matrix22_mul@@Base+0x444>
   32b1c:	mov	w28, wzr
   32b20:	b	32aa0 <__gmpn_matrix22_mul@@Base+0x3b0>
   32b24:	ldur	x1, [x29, #-56]
   32b28:	ldr	x2, [sp, #56]
   32b2c:	mov	x3, x21
   32b30:	mov	x4, x22
   32b34:	bl	ccf0 <__gmpn_mul@plt>
   32b38:	ldr	x26, [sp]
   32b3c:	ldr	x8, [x21, x22, lsl #3]
   32b40:	cbz	x8, 32b58 <__gmpn_matrix22_mul@@Base+0x468>
   32b44:	ldur	x2, [x29, #-56]
   32b48:	ldr	x3, [sp, #56]
   32b4c:	add	x0, x23, x22, lsl #3
   32b50:	mov	x1, x0
   32b54:	bl	ca90 <__gmpn_add_n@plt>
   32b58:	ldr	w25, [sp, #12]
   32b5c:	mov	w28, wzr
   32b60:	ldr	w8, [sp, #8]
   32b64:	mov	x0, x23
   32b68:	cmp	w8, w28
   32b6c:	ldr	x8, [sp, #40]
   32b70:	str	xzr, [x27, x8, lsl #3]
   32b74:	b.ne	32b90 <__gmpn_matrix22_mul@@Base+0x4a0>  // b.any
   32b78:	mov	x1, x23
   32b7c:	mov	x2, x27
   32b80:	mov	x3, x26
   32b84:	bl	ca90 <__gmpn_add_n@plt>
   32b88:	mov	w26, wzr
   32b8c:	b	32ba4 <__gmpn_matrix22_mul@@Base+0x4b4>
   32b90:	mov	x1, x27
   32b94:	mov	x2, x23
   32b98:	mov	x3, x26
   32b9c:	bl	32e08 <__gmpn_matrix22_mul@@Base+0x718>
   32ba0:	mov	w26, w0
   32ba4:	ldr	w8, [sp, #16]
   32ba8:	eor	w19, w8, w19
   32bac:	cbz	w28, 32bd0 <__gmpn_matrix22_mul@@Base+0x4e0>
   32bb0:	ldur	x20, [x29, #-56]
   32bb4:	ldur	x2, [x29, #-32]
   32bb8:	mov	x3, x24
   32bbc:	mov	x0, x20
   32bc0:	mov	x1, x20
   32bc4:	bl	ca90 <__gmpn_add_n@plt>
   32bc8:	str	x0, [x20, x24, lsl #3]
   32bcc:	b	32c1c <__gmpn_matrix22_mul@@Base+0x52c>
   32bd0:	ldr	x8, [x20]
   32bd4:	cbz	x8, 32c04 <__gmpn_matrix22_mul@@Base+0x514>
   32bd8:	ldur	x20, [x29, #-56]
   32bdc:	ldur	x2, [x29, #-32]
   32be0:	mov	x3, x24
   32be4:	mov	x0, x20
   32be8:	mov	x1, x20
   32bec:	bl	c2e0 <__gmpn_sub_n@plt>
   32bf0:	ldr	x8, [x20, x24, lsl #3]
   32bf4:	mov	w28, wzr
   32bf8:	sub	x8, x8, x0
   32bfc:	str	x8, [x20, x24, lsl #3]
   32c00:	b	32c1c <__gmpn_matrix22_mul@@Base+0x52c>
   32c04:	ldur	x0, [x29, #-56]
   32c08:	ldur	x2, [x29, #-32]
   32c0c:	mov	x3, x24
   32c10:	mov	x1, x0
   32c14:	bl	32e08 <__gmpn_matrix22_mul@@Base+0x718>
   32c18:	mov	w28, w0
   32c1c:	ldr	x20, [sp, #24]
   32c20:	cmp	x24, x22
   32c24:	eor	w23, w19, #0x1
   32c28:	mov	x0, x27
   32c2c:	b.ge	32c44 <__gmpn_matrix22_mul@@Base+0x554>  // b.tcont
   32c30:	ldur	x3, [x29, #-56]
   32c34:	ldr	x4, [sp, #56]
   32c38:	mov	x1, x20
   32c3c:	mov	x2, x22
   32c40:	b	32c54 <__gmpn_matrix22_mul@@Base+0x564>
   32c44:	ldur	x1, [x29, #-56]
   32c48:	ldr	x2, [sp, #56]
   32c4c:	mov	x3, x20
   32c50:	mov	x4, x22
   32c54:	bl	ccf0 <__gmpn_mul@plt>
   32c58:	mov	x0, x21
   32c5c:	cbz	w25, 32c74 <__gmpn_matrix22_mul@@Base+0x584>
   32c60:	mov	x1, x20
   32c64:	mov	x2, x21
   32c68:	mov	x3, x22
   32c6c:	bl	c2e0 <__gmpn_sub_n@plt>
   32c70:	b	32c90 <__gmpn_matrix22_mul@@Base+0x5a0>
   32c74:	mov	x1, x21
   32c78:	mov	x2, x20
   32c7c:	mov	x3, x22
   32c80:	bl	ca90 <__gmpn_add_n@plt>
   32c84:	ldr	x8, [x21, x22, lsl #3]
   32c88:	add	x8, x8, x0
   32c8c:	str	x8, [x21, x22, lsl #3]
   32c90:	ldr	x25, [sp, #64]
   32c94:	mov	x0, x20
   32c98:	ldur	x27, [x29, #-16]
   32c9c:	ldr	x20, [sp, #48]
   32ca0:	add	x19, x25, x24
   32ca4:	mov	w2, w26
   32ca8:	mov	x1, x27
   32cac:	mov	x3, x20
   32cb0:	mov	w4, w28
   32cb4:	mov	x5, x19
   32cb8:	bl	32e64 <__gmpn_matrix22_mul@@Base+0x774>
   32cbc:	ldr	x3, [sp, #32]
   32cc0:	mov	w28, w0
   32cc4:	mov	x0, x27
   32cc8:	mov	x1, x27
   32ccc:	mov	w2, w26
   32cd0:	mov	w4, w23
   32cd4:	mov	x5, x19
   32cd8:	bl	32e64 <__gmpn_matrix22_mul@@Base+0x774>
   32cdc:	cmp	x25, x24
   32ce0:	mov	w23, w0
   32ce4:	mov	x0, x20
   32ce8:	b.ge	32d00 <__gmpn_matrix22_mul@@Base+0x610>  // b.tcont
   32cec:	ldp	x26, x3, [x29, #-48]
   32cf0:	mov	x2, x24
   32cf4:	mov	x4, x25
   32cf8:	mov	x1, x26
   32cfc:	b	32d10 <__gmpn_matrix22_mul@@Base+0x620>
   32d00:	ldp	x26, x1, [x29, #-48]
   32d04:	mov	x2, x25
   32d08:	mov	x4, x24
   32d0c:	mov	x3, x26
   32d10:	bl	ccf0 <__gmpn_mul@plt>
   32d14:	mov	x27, x20
   32d18:	ldur	x20, [x29, #-56]
   32d1c:	ldp	x25, x1, [x29, #-16]
   32d20:	mov	x2, x26
   32d24:	mov	x3, x24
   32d28:	mov	x0, x20
   32d2c:	bl	ca90 <__gmpn_add_n@plt>
   32d30:	cmp	x22, x24
   32d34:	str	x0, [x20, x24, lsl #3]
   32d38:	b.ge	32d50 <__gmpn_matrix22_mul@@Base+0x660>  // b.tcont
   32d3c:	ldr	x22, [sp, #32]
   32d40:	ldp	x2, x4, [sp, #56]
   32d44:	mov	x1, x20
   32d48:	mov	x3, x21
   32d4c:	b	32d60 <__gmpn_matrix22_mul@@Base+0x670>
   32d50:	ldr	x22, [sp, #32]
   32d54:	ldp	x4, x2, [sp, #56]
   32d58:	mov	x1, x21
   32d5c:	mov	x3, x20
   32d60:	mov	x0, x22
   32d64:	bl	ccf0 <__gmpn_mul@plt>
   32d68:	ldr	w4, [sp, #20]
   32d6c:	mov	x0, x21
   32d70:	mov	x1, x25
   32d74:	mov	w2, w23
   32d78:	mov	x3, x27
   32d7c:	mov	x5, x19
   32d80:	bl	32e64 <__gmpn_matrix22_mul@@Base+0x774>
   32d84:	mov	x0, x25
   32d88:	mov	x1, x22
   32d8c:	mov	x2, x25
   32d90:	mov	x3, x19
   32d94:	cbz	w23, 32dd0 <__gmpn_matrix22_mul@@Base+0x6e0>
   32d98:	bl	ca90 <__gmpn_add_n@plt>
   32d9c:	cbz	w28, 32dd8 <__gmpn_matrix22_mul@@Base+0x6e8>
   32da0:	ldr	x0, [sp, #24]
   32da4:	mov	x1, x22
   32da8:	mov	x3, x19
   32dac:	ldp	x20, x19, [sp, #208]
   32db0:	ldp	x22, x21, [sp, #192]
   32db4:	ldp	x24, x23, [sp, #176]
   32db8:	ldp	x26, x25, [sp, #160]
   32dbc:	ldp	x28, x27, [sp, #144]
   32dc0:	ldp	x29, x30, [sp, #128]
   32dc4:	mov	x2, x0
   32dc8:	add	sp, sp, #0xe0
   32dcc:	b	ca90 <__gmpn_add_n@plt>
   32dd0:	bl	c2e0 <__gmpn_sub_n@plt>
   32dd4:	cbnz	w28, 32da0 <__gmpn_matrix22_mul@@Base+0x6b0>
   32dd8:	ldr	x0, [sp, #24]
   32ddc:	mov	x1, x22
   32de0:	mov	x3, x19
   32de4:	ldp	x20, x19, [sp, #208]
   32de8:	ldp	x22, x21, [sp, #192]
   32dec:	ldp	x24, x23, [sp, #176]
   32df0:	ldp	x26, x25, [sp, #160]
   32df4:	ldp	x28, x27, [sp, #144]
   32df8:	ldp	x29, x30, [sp, #128]
   32dfc:	mov	x2, x0
   32e00:	add	sp, sp, #0xe0
   32e04:	b	c2e0 <__gmpn_sub_n@plt>
   32e08:	stp	x29, x30, [sp, #-16]!
   32e0c:	mov	x8, x1
   32e10:	sub	x9, x3, #0x1
   32e14:	mov	x29, sp
   32e18:	add	x10, x9, #0x1
   32e1c:	cmp	x10, #0x1
   32e20:	b.lt	32e3c <__gmpn_matrix22_mul@@Base+0x74c>  // b.tstop
   32e24:	ldr	x10, [x8, x9, lsl #3]
   32e28:	ldr	x11, [x2, x9, lsl #3]
   32e2c:	sub	x9, x9, #0x1
   32e30:	cmp	x10, x11
   32e34:	b.eq	32e18 <__gmpn_matrix22_mul@@Base+0x728>  // b.none
   32e38:	b.ls	32e4c <__gmpn_matrix22_mul@@Base+0x75c>  // b.plast
   32e3c:	mov	x1, x8
   32e40:	bl	c2e0 <__gmpn_sub_n@plt>
   32e44:	mov	w0, wzr
   32e48:	b	32e5c <__gmpn_matrix22_mul@@Base+0x76c>
   32e4c:	mov	x1, x2
   32e50:	mov	x2, x8
   32e54:	bl	c2e0 <__gmpn_sub_n@plt>
   32e58:	mov	w0, #0x1                   	// #1
   32e5c:	ldp	x29, x30, [sp], #16
   32e60:	ret
   32e64:	stp	x29, x30, [sp, #-32]!
   32e68:	str	x19, [sp, #16]
   32e6c:	mov	w19, w2
   32e70:	cmp	w2, w4
   32e74:	mov	x29, sp
   32e78:	b.ne	32e8c <__gmpn_matrix22_mul@@Base+0x79c>  // b.any
   32e7c:	mov	x2, x3
   32e80:	mov	x3, x5
   32e84:	bl	ca90 <__gmpn_add_n@plt>
   32e88:	b	32e9c <__gmpn_matrix22_mul@@Base+0x7ac>
   32e8c:	mov	x2, x3
   32e90:	mov	x3, x5
   32e94:	bl	32e08 <__gmpn_matrix22_mul@@Base+0x718>
   32e98:	eor	w19, w0, w19
   32e9c:	mov	w0, w19
   32ea0:	ldr	x19, [sp, #16]
   32ea4:	ldp	x29, x30, [sp], #32
   32ea8:	ret

0000000000032eac <__gmpn_matrix22_mul1_inverse_vector@@Base>:
   32eac:	stp	x29, x30, [sp, #-64]!
   32eb0:	stp	x22, x21, [sp, #32]
   32eb4:	stp	x20, x19, [sp, #48]
   32eb8:	mov	x20, x3
   32ebc:	ldr	x3, [x0, #24]
   32ec0:	str	x23, [sp, #16]
   32ec4:	mov	x21, x2
   32ec8:	mov	x22, x0
   32ecc:	mov	x23, x1
   32ed0:	mov	x0, x1
   32ed4:	mov	x1, x2
   32ed8:	mov	x2, x4
   32edc:	mov	x29, sp
   32ee0:	mov	x19, x4
   32ee4:	bl	d4b0 <__gmpn_mul_1@plt>
   32ee8:	ldr	x3, [x22, #8]
   32eec:	mov	x0, x23
   32ef0:	mov	x1, x20
   32ef4:	mov	x2, x19
   32ef8:	bl	ca00 <__gmpn_submul_1@plt>
   32efc:	ldr	x3, [x22]
   32f00:	mov	x0, x20
   32f04:	mov	x1, x20
   32f08:	mov	x2, x19
   32f0c:	bl	d4b0 <__gmpn_mul_1@plt>
   32f10:	ldr	x3, [x22, #16]
   32f14:	mov	x0, x20
   32f18:	mov	x1, x21
   32f1c:	mov	x2, x19
   32f20:	bl	ca00 <__gmpn_submul_1@plt>
   32f24:	lsl	x8, x19, #3
   32f28:	sub	x8, x8, #0x8
   32f2c:	ldr	x9, [x23, x8]
   32f30:	ldr	x8, [x20, x8]
   32f34:	ldp	x22, x21, [sp, #32]
   32f38:	ldr	x23, [sp, #16]
   32f3c:	orr	x8, x8, x9
   32f40:	cmp	x8, #0x0
   32f44:	cset	w8, eq  // eq = none
   32f48:	sub	x0, x19, x8
   32f4c:	ldp	x20, x19, [sp, #48]
   32f50:	ldp	x29, x30, [sp], #64
   32f54:	ret

0000000000032f58 <__gmpn_hgcd_matrix_init@@Base>:
   32f58:	stp	x29, x30, [sp, #-48]!
   32f5c:	add	x8, x1, #0x1
   32f60:	add	x9, x1, #0x2
   32f64:	cmp	x8, #0x0
   32f68:	csinc	x8, x9, x1, lt  // lt = tstop
   32f6c:	asr	x8, x8, #1
   32f70:	str	x21, [sp, #16]
   32f74:	stp	x20, x19, [sp, #32]
   32f78:	mov	x19, x2
   32f7c:	mov	x20, x0
   32f80:	mov	w10, #0x1                   	// #1
   32f84:	adds	x21, x8, #0x1
   32f88:	mov	x29, sp
   32f8c:	stp	x21, x10, [x0]
   32f90:	b.cs	32fa8 <__gmpn_hgcd_matrix_init@@Base+0x50>  // b.hs, b.nlast
   32f94:	lsl	x8, x8, #5
   32f98:	add	x2, x8, #0x20
   32f9c:	mov	x0, x19
   32fa0:	mov	w1, wzr
   32fa4:	bl	c610 <memset@plt>
   32fa8:	add	x8, x19, x21, lsl #3
   32fac:	mov	w10, #0x18                  	// #24
   32fb0:	stp	x19, x8, [x20, #16]
   32fb4:	mul	x8, x21, x10
   32fb8:	add	x9, x19, x21, lsl #4
   32fbc:	mov	w11, #0x1                   	// #1
   32fc0:	add	x10, x19, x8
   32fc4:	stp	x9, x10, [x20, #32]
   32fc8:	str	x11, [x19, x8]
   32fcc:	str	x11, [x19]
   32fd0:	ldp	x20, x19, [sp, #32]
   32fd4:	ldr	x21, [sp, #16]
   32fd8:	ldp	x29, x30, [sp], #48
   32fdc:	ret

0000000000032fe0 <__gmpn_hgcd_matrix_update_q@@Base>:
   32fe0:	sub	sp, sp, #0x90
   32fe4:	stp	x24, x23, [sp, #96]
   32fe8:	stp	x20, x19, [sp, #128]
   32fec:	mov	w24, w3
   32ff0:	mov	x14, x1
   32ff4:	cmp	x2, #0x1
   32ff8:	mov	x19, x0
   32ffc:	stp	x29, x30, [sp, #48]
   33000:	stp	x28, x27, [sp, #64]
   33004:	stp	x26, x25, [sp, #80]
   33008:	stp	x22, x21, [sp, #112]
   3300c:	add	x29, sp, #0x30
   33010:	b.ne	33084 <__gmpn_hgcd_matrix_update_q@@Base+0xa4>  // b.any
   33014:	mov	w8, #0x1                   	// #1
   33018:	ldr	x20, [x14]
   3301c:	add	x22, x19, #0x10
   33020:	sub	w21, w8, w24
   33024:	ldr	x0, [x22, w24, uxtw #3]
   33028:	ldr	x1, [x22, w21, uxtw #3]
   3302c:	ldr	x2, [x19, #8]
   33030:	mov	x3, x20
   33034:	bl	d420 <__gmpn_addmul_1@plt>
   33038:	add	x23, x19, #0x20
   3303c:	ldr	x8, [x23, w24, uxtw #3]
   33040:	ldr	x1, [x23, w21, uxtw #3]
   33044:	ldr	x2, [x19, #8]
   33048:	mov	x21, x0
   3304c:	mov	x0, x8
   33050:	mov	x3, x20
   33054:	bl	d420 <__gmpn_addmul_1@plt>
   33058:	ldr	x8, [x22, w24, uxtw #3]
   3305c:	ldr	x9, [x19, #8]
   33060:	str	x21, [x8, x9, lsl #3]
   33064:	ldr	x8, [x23, w24, uxtw #3]
   33068:	ldr	x9, [x19, #8]
   3306c:	str	x0, [x8, x9, lsl #3]
   33070:	ldr	x8, [x19, #8]
   33074:	orr	x9, x0, x21
   33078:	cmp	x9, #0x0
   3307c:	cinc	x8, x8, ne  // ne = any
   33080:	b	33268 <__gmpn_hgcd_matrix_update_q@@Base+0x288>
   33084:	ldr	x8, [x19, #8]
   33088:	mov	w9, #0x1                   	// #1
   3308c:	sub	w9, w9, w24
   33090:	add	x10, x19, w9, uxtw #3
   33094:	add	x11, x8, x2
   33098:	lsl	x11, x11, #3
   3309c:	mov	x22, x4
   330a0:	mov	x20, x2
   330a4:	str	x9, [sp, #16]
   330a8:	add	x9, x10, #0x10
   330ac:	add	x10, x10, #0x20
   330b0:	sub	x11, x11, #0x8
   330b4:	mov	x12, x8
   330b8:	add	x28, x20, x12
   330bc:	mov	x21, x12
   330c0:	cmp	x28, x8
   330c4:	mov	x27, x11
   330c8:	b.le	330f4 <__gmpn_hgcd_matrix_update_q@@Base+0x114>
   330cc:	ldr	x11, [x9]
   330d0:	add	x11, x11, x21, lsl #3
   330d4:	ldur	x11, [x11, #-8]
   330d8:	cbnz	x11, 330f4 <__gmpn_hgcd_matrix_update_q@@Base+0x114>
   330dc:	ldr	x11, [x10]
   330e0:	sub	x12, x21, #0x1
   330e4:	add	x11, x11, x21, lsl #3
   330e8:	ldur	x13, [x11, #-8]
   330ec:	sub	x11, x27, #0x8
   330f0:	cbz	x13, 330b8 <__gmpn_hgcd_matrix_update_q@@Base+0xd8>
   330f4:	mov	w8, w24
   330f8:	mov	x26, xzr
   330fc:	str	x8, [sp, #24]
   33100:	neg	x8, x20
   33104:	mov	x23, x14
   33108:	str	x8, [sp, #8]
   3310c:	ldr	x9, [sp, #16]
   33110:	add	x8, x19, x26, lsl #4
   33114:	mov	x0, x22
   33118:	cmp	x21, x20
   3311c:	add	x8, x8, x9, lsl #3
   33120:	ldr	x3, [x8, #16]
   33124:	b.ge	33138 <__gmpn_hgcd_matrix_update_q@@Base+0x158>  // b.tcont
   33128:	mov	x1, x14
   3312c:	mov	x2, x20
   33130:	mov	x4, x21
   33134:	b	33148 <__gmpn_hgcd_matrix_update_q@@Base+0x168>
   33138:	mov	x1, x3
   3313c:	mov	x2, x21
   33140:	mov	x3, x14
   33144:	mov	x4, x20
   33148:	bl	ccf0 <__gmpn_mul@plt>
   3314c:	ldr	x9, [sp, #24]
   33150:	add	x8, x19, x26, lsl #4
   33154:	ldr	x25, [x19, #8]
   33158:	add	x8, x8, x9, lsl #3
   3315c:	ldr	x24, [x8, #16]
   33160:	cbz	x25, 331a4 <__gmpn_hgcd_matrix_update_q@@Base+0x1c4>
   33164:	mov	x0, x24
   33168:	mov	x1, x22
   3316c:	mov	x2, x24
   33170:	mov	x3, x25
   33174:	bl	ca90 <__gmpn_add_n@plt>
   33178:	cbz	x0, 331ac <__gmpn_hgcd_matrix_update_q@@Base+0x1cc>
   3317c:	mov	x14, x23
   33180:	cmp	x25, x28
   33184:	b.ge	331f4 <__gmpn_hgcd_matrix_update_q@@Base+0x214>  // b.tcont
   33188:	ldr	x8, [x22, x25, lsl #3]
   3318c:	adds	x9, x8, #0x1
   33190:	add	x8, x25, #0x1
   33194:	str	x9, [x24, x25, lsl #3]
   33198:	mov	x25, x8
   3319c:	b.cs	33180 <__gmpn_hgcd_matrix_update_q@@Base+0x1a0>  // b.hs, b.nlast
   331a0:	b	331b4 <__gmpn_hgcd_matrix_update_q@@Base+0x1d4>
   331a4:	mov	x8, xzr
   331a8:	b	331b0 <__gmpn_hgcd_matrix_update_q@@Base+0x1d0>
   331ac:	mov	x8, x25
   331b0:	mov	x14, x23
   331b4:	cmp	x24, x22
   331b8:	mov	x9, xzr
   331bc:	b.eq	331f8 <__gmpn_hgcd_matrix_update_q@@Base+0x218>  // b.none
   331c0:	cmp	x8, x28
   331c4:	b.ge	331f8 <__gmpn_hgcd_matrix_update_q@@Base+0x218>  // b.tcont
   331c8:	ldr	x9, [sp, #8]
   331cc:	add	x10, x24, x8, lsl #3
   331d0:	add	x9, x9, x8
   331d4:	add	x8, x22, x8, lsl #3
   331d8:	ldr	x11, [x8], #8
   331dc:	add	x9, x9, #0x1
   331e0:	cmp	x21, x9
   331e4:	str	x11, [x10], #8
   331e8:	b.ne	331d8 <__gmpn_hgcd_matrix_update_q@@Base+0x1f8>  // b.any
   331ec:	mov	x9, xzr
   331f0:	b	331f8 <__gmpn_hgcd_matrix_update_q@@Base+0x218>
   331f4:	mov	w9, #0x1                   	// #1
   331f8:	sub	x8, x29, #0x10
   331fc:	str	x9, [x8, x26, lsl #3]
   33200:	add	x26, x26, #0x1
   33204:	cmp	x26, #0x2
   33208:	b.ne	3310c <__gmpn_hgcd_matrix_update_q@@Base+0x12c>  // b.any
   3320c:	ldr	x9, [sp, #24]
   33210:	ldp	x10, x8, [x29, #-16]
   33214:	add	x9, x19, x9, lsl #3
   33218:	ldr	x11, [x9, #16]
   3321c:	orr	x12, x8, x10
   33220:	cbz	x12, 33240 <__gmpn_hgcd_matrix_update_q@@Base+0x260>
   33224:	add	x11, x11, x27
   33228:	str	x10, [x11, #8]
   3322c:	ldr	x9, [x9, #32]
   33230:	add	x9, x9, x20, lsl #3
   33234:	str	x8, [x9, x21, lsl #3]
   33238:	mov	w8, #0x1                   	// #1
   3323c:	b	33260 <__gmpn_hgcd_matrix_update_q@@Base+0x280>
   33240:	ldr	x8, [x9, #32]
   33244:	ldr	x9, [x11, x27]
   33248:	add	x8, x8, x20, lsl #3
   3324c:	add	x8, x8, x21, lsl #3
   33250:	ldur	x8, [x8, #-8]
   33254:	orr	x8, x8, x9
   33258:	cmp	x8, #0x0
   3325c:	csetm	x8, eq  // eq = none
   33260:	add	x8, x8, x20
   33264:	add	x8, x8, x21
   33268:	str	x8, [x19, #8]
   3326c:	ldp	x20, x19, [sp, #128]
   33270:	ldp	x22, x21, [sp, #112]
   33274:	ldp	x24, x23, [sp, #96]
   33278:	ldp	x26, x25, [sp, #80]
   3327c:	ldp	x28, x27, [sp, #64]
   33280:	ldp	x29, x30, [sp, #48]
   33284:	add	sp, sp, #0x90
   33288:	ret

000000000003328c <__gmpn_hgcd_matrix_mul_1@@Base>:
   3328c:	stp	x29, x30, [sp, #-48]!
   33290:	stp	x22, x21, [sp, #16]
   33294:	stp	x20, x19, [sp, #32]
   33298:	mov	x19, x2
   3329c:	ldp	x2, x8, [x0, #8]
   332a0:	mov	x20, x0
   332a4:	mov	x21, x1
   332a8:	mov	x0, x19
   332ac:	mov	x1, x8
   332b0:	mov	x29, sp
   332b4:	bl	ca70 <__gmpn_copyi@plt>
   332b8:	ldp	x1, x3, [x20, #16]
   332bc:	ldr	x4, [x20, #8]
   332c0:	mov	x0, x21
   332c4:	mov	x2, x19
   332c8:	bl	d460 <__gmpn_hgcd_mul_matrix1_vector@plt>
   332cc:	ldr	x1, [x20, #32]
   332d0:	ldr	x2, [x20, #8]
   332d4:	mov	x22, x0
   332d8:	mov	x0, x19
   332dc:	bl	ca70 <__gmpn_copyi@plt>
   332e0:	ldp	x1, x3, [x20, #32]
   332e4:	ldr	x4, [x20, #8]
   332e8:	mov	x0, x21
   332ec:	mov	x2, x19
   332f0:	bl	d460 <__gmpn_hgcd_mul_matrix1_vector@plt>
   332f4:	cmp	x22, x0
   332f8:	csel	x8, x22, x0, gt
   332fc:	str	x8, [x20, #8]
   33300:	ldp	x20, x19, [sp, #32]
   33304:	ldp	x22, x21, [sp, #16]
   33308:	ldp	x29, x30, [sp], #48
   3330c:	ret

0000000000033310 <__gmpn_hgcd_matrix_mul@@Base>:
   33310:	sub	sp, sp, #0x40
   33314:	stp	x29, x30, [sp, #32]
   33318:	stp	x20, x19, [sp, #48]
   3331c:	mov	x20, x1
   33320:	mov	x19, x0
   33324:	ldp	x1, x8, [x0, #24]
   33328:	ldp	x10, x5, [x20, #8]
   3332c:	ldr	x3, [x0, #40]
   33330:	ldr	x0, [x0, #16]
   33334:	ldr	x4, [x19, #8]
   33338:	ldp	x6, x7, [x20, #24]
   3333c:	ldr	x9, [x20, #40]
   33340:	stp	x10, x2, [sp, #8]
   33344:	mov	x2, x8
   33348:	add	x29, sp, #0x20
   3334c:	str	x9, [sp]
   33350:	bl	c020 <__gmpn_matrix22_mul@plt>
   33354:	ldr	x8, [x20, #8]
   33358:	ldp	x9, x10, [x19, #8]
   3335c:	ldp	x11, x12, [x19, #24]
   33360:	ldr	x13, [x19, #40]
   33364:	add	x8, x8, x9
   33368:	ldr	x9, [x10, x8, lsl #3]
   3336c:	ldr	x14, [x11, x8, lsl #3]
   33370:	ldr	x15, [x12, x8, lsl #3]
   33374:	ldr	x16, [x13, x8, lsl #3]
   33378:	orr	x9, x14, x9
   3337c:	orr	x9, x9, x15
   33380:	orr	x9, x9, x16
   33384:	cmp	x9, #0x0
   33388:	cset	w9, eq  // eq = none
   3338c:	sub	x8, x8, x9
   33390:	ldr	x9, [x10, x8, lsl #3]
   33394:	ldr	x14, [x11, x8, lsl #3]
   33398:	ldr	x15, [x12, x8, lsl #3]
   3339c:	ldr	x16, [x13, x8, lsl #3]
   333a0:	orr	x9, x14, x9
   333a4:	orr	x9, x9, x15
   333a8:	orr	x9, x9, x16
   333ac:	cmp	x9, #0x0
   333b0:	cset	w9, eq  // eq = none
   333b4:	sub	x8, x8, x9
   333b8:	ldr	x9, [x10, x8, lsl #3]
   333bc:	ldr	x10, [x11, x8, lsl #3]
   333c0:	ldr	x11, [x12, x8, lsl #3]
   333c4:	ldr	x12, [x13, x8, lsl #3]
   333c8:	orr	x9, x10, x9
   333cc:	orr	x9, x9, x11
   333d0:	orr	x9, x9, x12
   333d4:	cmp	x9, #0x0
   333d8:	cset	w9, eq  // eq = none
   333dc:	sub	x8, x8, x9
   333e0:	add	x8, x8, #0x1
   333e4:	str	x8, [x19, #8]
   333e8:	ldp	x20, x19, [sp, #48]
   333ec:	ldp	x29, x30, [sp, #32]
   333f0:	add	sp, sp, #0x40
   333f4:	ret

00000000000333f8 <__gmpn_hgcd_matrix_adjust@@Base>:
   333f8:	sub	sp, sp, #0x70
   333fc:	stp	x29, x30, [sp, #16]
   33400:	stp	x28, x27, [sp, #32]
   33404:	stp	x26, x25, [sp, #48]
   33408:	stp	x24, x23, [sp, #64]
   3340c:	stp	x22, x21, [sp, #80]
   33410:	stp	x20, x19, [sp, #96]
   33414:	mov	x22, x4
   33418:	ldr	x4, [x0, #8]
   3341c:	mov	x20, x3
   33420:	ldr	x3, [x0, #40]
   33424:	add	x25, x5, x22, lsl #3
   33428:	mov	x26, x5
   3342c:	mov	x21, x2
   33430:	mov	x19, x1
   33434:	mov	x23, x0
   33438:	cmp	x4, x22
   3343c:	add	x24, x25, x4, lsl #3
   33440:	mov	x0, x5
   33444:	add	x29, sp, #0x10
   33448:	str	x24, [sp]
   3344c:	b.ge	33474 <__gmpn_hgcd_matrix_adjust@@Base+0x7c>  // b.tcont
   33450:	mov	x1, x21
   33454:	mov	x2, x22
   33458:	bl	ccf0 <__gmpn_mul@plt>
   3345c:	ldr	x3, [x23, #32]
   33460:	ldr	x4, [x23, #8]
   33464:	mov	x0, x24
   33468:	mov	x1, x21
   3346c:	mov	x2, x22
   33470:	b	3349c <__gmpn_hgcd_matrix_adjust@@Base+0xa4>
   33474:	mov	x1, x3
   33478:	mov	x2, x4
   3347c:	mov	x3, x21
   33480:	mov	x4, x22
   33484:	bl	ccf0 <__gmpn_mul@plt>
   33488:	ldr	x1, [x23, #32]
   3348c:	ldr	x2, [x23, #8]
   33490:	mov	x0, x24
   33494:	mov	x3, x21
   33498:	mov	x4, x22
   3349c:	bl	ccf0 <__gmpn_mul@plt>
   334a0:	mov	x0, x21
   334a4:	mov	x1, x26
   334a8:	mov	x2, x22
   334ac:	bl	ca70 <__gmpn_copyi@plt>
   334b0:	ldr	x27, [x23, #8]
   334b4:	sub	x24, x19, x22
   334b8:	cbz	x27, 334f8 <__gmpn_hgcd_matrix_adjust@@Base+0x100>
   334bc:	add	x28, x21, x22, lsl #3
   334c0:	mov	x0, x28
   334c4:	mov	x1, x28
   334c8:	mov	x2, x25
   334cc:	mov	x3, x27
   334d0:	bl	ca90 <__gmpn_add_n@plt>
   334d4:	cbz	x0, 334f8 <__gmpn_hgcd_matrix_adjust@@Base+0x100>
   334d8:	cmp	x27, x24
   334dc:	b.ge	336b4 <__gmpn_hgcd_matrix_adjust@@Base+0x2bc>  // b.tcont
   334e0:	ldr	x8, [x28, x27, lsl #3]
   334e4:	add	x9, x27, #0x1
   334e8:	adds	x8, x8, #0x1
   334ec:	str	x8, [x28, x27, lsl #3]
   334f0:	mov	x27, x9
   334f4:	b.cs	334d8 <__gmpn_hgcd_matrix_adjust@@Base+0xe0>  // b.hs, b.nlast
   334f8:	str	xzr, [sp, #8]
   334fc:	ldr	x4, [x23, #8]
   33500:	ldr	x3, [x23, #24]
   33504:	mov	x0, x26
   33508:	cmp	x4, x22
   3350c:	b.ge	3351c <__gmpn_hgcd_matrix_adjust@@Base+0x124>  // b.tcont
   33510:	mov	x1, x20
   33514:	mov	x2, x22
   33518:	b	3352c <__gmpn_hgcd_matrix_adjust@@Base+0x134>
   3351c:	mov	x1, x3
   33520:	mov	x2, x4
   33524:	mov	x3, x20
   33528:	mov	x4, x22
   3352c:	bl	ccf0 <__gmpn_mul@plt>
   33530:	ldr	x8, [x23, #8]
   33534:	adds	x27, x8, x22
   33538:	b.eq	33578 <__gmpn_hgcd_matrix_adjust@@Base+0x180>  // b.none
   3353c:	mov	x0, x21
   33540:	mov	x1, x21
   33544:	mov	x2, x26
   33548:	mov	x3, x27
   3354c:	bl	c2e0 <__gmpn_sub_n@plt>
   33550:	cbz	x0, 33578 <__gmpn_hgcd_matrix_adjust@@Base+0x180>
   33554:	mov	w28, #0x1                   	// #1
   33558:	cmp	x27, x19
   3355c:	b.ge	3357c <__gmpn_hgcd_matrix_adjust@@Base+0x184>  // b.tcont
   33560:	ldr	x8, [x21, x27, lsl #3]
   33564:	add	x10, x27, #0x1
   33568:	sub	x9, x8, #0x1
   3356c:	str	x9, [x21, x27, lsl #3]
   33570:	mov	x27, x10
   33574:	cbz	x8, 33558 <__gmpn_hgcd_matrix_adjust@@Base+0x160>
   33578:	mov	x28, xzr
   3357c:	ldp	x4, x3, [x23, #8]
   33580:	mov	x0, x26
   33584:	cmp	x4, x22
   33588:	b.ge	33598 <__gmpn_hgcd_matrix_adjust@@Base+0x1a0>  // b.tcont
   3358c:	mov	x1, x20
   33590:	mov	x2, x22
   33594:	b	335a8 <__gmpn_hgcd_matrix_adjust@@Base+0x1b0>
   33598:	mov	x1, x3
   3359c:	mov	x2, x4
   335a0:	mov	x3, x20
   335a4:	mov	x4, x22
   335a8:	bl	ccf0 <__gmpn_mul@plt>
   335ac:	mov	x0, x20
   335b0:	mov	x1, x26
   335b4:	mov	x2, x22
   335b8:	bl	ca70 <__gmpn_copyi@plt>
   335bc:	ldr	x26, [x23, #8]
   335c0:	cbz	x26, 33614 <__gmpn_hgcd_matrix_adjust@@Base+0x21c>
   335c4:	add	x27, x20, x22, lsl #3
   335c8:	mov	x0, x27
   335cc:	mov	x1, x27
   335d0:	mov	x2, x25
   335d4:	mov	x3, x26
   335d8:	bl	ca90 <__gmpn_add_n@plt>
   335dc:	cbz	x0, 33614 <__gmpn_hgcd_matrix_adjust@@Base+0x21c>
   335e0:	ldr	x10, [sp, #8]
   335e4:	mov	w25, #0x1                   	// #1
   335e8:	cmp	x26, x24
   335ec:	b.ge	3360c <__gmpn_hgcd_matrix_adjust@@Base+0x214>  // b.tcont
   335f0:	ldr	x8, [x27, x26, lsl #3]
   335f4:	add	x9, x26, #0x1
   335f8:	adds	x8, x8, #0x1
   335fc:	str	x8, [x27, x26, lsl #3]
   33600:	mov	x26, x9
   33604:	b.cs	335e8 <__gmpn_hgcd_matrix_adjust@@Base+0x1f0>  // b.hs, b.nlast
   33608:	mov	x25, xzr
   3360c:	ldr	x2, [sp]
   33610:	b	3361c <__gmpn_hgcd_matrix_adjust@@Base+0x224>
   33614:	ldp	x2, x10, [sp]
   33618:	mov	x25, xzr
   3361c:	ldr	x8, [x23, #8]
   33620:	sub	x23, x10, x28
   33624:	adds	x22, x8, x22
   33628:	b.eq	33664 <__gmpn_hgcd_matrix_adjust@@Base+0x26c>  // b.none
   3362c:	mov	x0, x20
   33630:	mov	x1, x20
   33634:	mov	x3, x22
   33638:	bl	c2e0 <__gmpn_sub_n@plt>
   3363c:	cbz	x0, 33664 <__gmpn_hgcd_matrix_adjust@@Base+0x26c>
   33640:	mov	w8, #0x1                   	// #1
   33644:	cmp	x22, x19
   33648:	b.ge	33668 <__gmpn_hgcd_matrix_adjust@@Base+0x270>  // b.tcont
   3364c:	ldr	x9, [x20, x22, lsl #3]
   33650:	add	x11, x22, #0x1
   33654:	sub	x10, x9, #0x1
   33658:	str	x10, [x20, x22, lsl #3]
   3365c:	mov	x22, x11
   33660:	cbz	x9, 33644 <__gmpn_hgcd_matrix_adjust@@Base+0x24c>
   33664:	mov	x8, xzr
   33668:	sub	x8, x25, x8
   3366c:	orr	x9, x8, x23
   33670:	cbz	x9, 33684 <__gmpn_hgcd_matrix_adjust@@Base+0x28c>
   33674:	str	x23, [x21, x19, lsl #3]
   33678:	str	x8, [x20, x19, lsl #3]
   3367c:	add	x19, x19, #0x1
   33680:	b	33690 <__gmpn_hgcd_matrix_adjust@@Base+0x298>
   33684:	sub	x8, x19, #0x1
   33688:	ldr	x9, [x21, x8, lsl #3]
   3368c:	cbz	x9, 336c0 <__gmpn_hgcd_matrix_adjust@@Base+0x2c8>
   33690:	mov	x0, x19
   33694:	ldp	x20, x19, [sp, #96]
   33698:	ldp	x22, x21, [sp, #80]
   3369c:	ldp	x24, x23, [sp, #64]
   336a0:	ldp	x26, x25, [sp, #48]
   336a4:	ldp	x28, x27, [sp, #32]
   336a8:	ldp	x29, x30, [sp, #16]
   336ac:	add	sp, sp, #0x70
   336b0:	ret
   336b4:	mov	w8, #0x1                   	// #1
   336b8:	str	x8, [sp, #8]
   336bc:	b	334fc <__gmpn_hgcd_matrix_adjust@@Base+0x104>
   336c0:	ldr	x9, [x20, x8, lsl #3]
   336c4:	cmp	x9, #0x0
   336c8:	csel	x0, x8, x19, eq  // eq = none
   336cc:	b	33694 <__gmpn_hgcd_matrix_adjust@@Base+0x29c>

00000000000336d0 <__gmpn_hgcd2@@Base>:
   336d0:	sub	sp, sp, #0x70
   336d4:	stp	x22, x21, [sp, #80]
   336d8:	mov	x21, x0
   336dc:	cmp	x0, #0x2
   336e0:	mov	w0, wzr
   336e4:	stp	x29, x30, [sp, #16]
   336e8:	str	x27, [sp, #32]
   336ec:	stp	x26, x25, [sp, #48]
   336f0:	stp	x24, x23, [sp, #64]
   336f4:	stp	x20, x19, [sp, #96]
   336f8:	add	x29, sp, #0x10
   336fc:	b.cc	338fc <__gmpn_hgcd2@@Base+0x22c>  // b.lo, b.ul, b.last
   33700:	mov	x20, x2
   33704:	cmp	x2, #0x2
   33708:	b.cc	338fc <__gmpn_hgcd2@@Base+0x22c>  // b.lo, b.ul, b.last
   3370c:	mov	x19, x4
   33710:	mov	x22, x3
   33714:	mov	x23, x1
   33718:	cmp	x21, x20
   3371c:	b.hi	3372c <__gmpn_hgcd2@@Base+0x5c>  // b.pmore
   33720:	b.ne	3374c <__gmpn_hgcd2@@Base+0x7c>  // b.any
   33724:	cmp	x23, x22
   33728:	b.ls	3374c <__gmpn_hgcd2@@Base+0x7c>  // b.plast
   3372c:	subs	x8, x23, x22
   33730:	sbc	x21, x21, x20
   33734:	cmp	x21, #0x2
   33738:	b.cc	3375c <__gmpn_hgcd2@@Base+0x8c>  // b.lo, b.ul, b.last
   3373c:	mov	x24, xzr
   33740:	mov	w25, #0x1                   	// #1
   33744:	mov	x23, x8
   33748:	b	33770 <__gmpn_hgcd2@@Base+0xa0>
   3374c:	subs	x8, x22, x23
   33750:	sbc	x20, x20, x21
   33754:	cmp	x20, #0x2
   33758:	b.cs	33764 <__gmpn_hgcd2@@Base+0x94>  // b.hs, b.nlast
   3375c:	mov	w0, wzr
   33760:	b	338fc <__gmpn_hgcd2@@Base+0x22c>
   33764:	mov	x25, xzr
   33768:	mov	w24, #0x1                   	// #1
   3376c:	mov	x22, x8
   33770:	mov	w26, #0x1                   	// #1
   33774:	cmp	x21, x20
   33778:	mov	w27, #0x1                   	// #1
   3377c:	b.cc	337f0 <__gmpn_hgcd2@@Base+0x120>  // b.lo, b.ul, b.last
   33780:	cmp	x21, x20
   33784:	b.eq	338f0 <__gmpn_hgcd2@@Base+0x220>  // b.none
   33788:	lsr	x8, x21, #32
   3378c:	cbz	x8, 33864 <__gmpn_hgcd2@@Base+0x194>
   33790:	mov	x8, x23
   33794:	subs	x23, x8, x22
   33798:	sbc	x21, x21, x20
   3379c:	cmp	x21, #0x2
   337a0:	b.cc	338f0 <__gmpn_hgcd2@@Base+0x220>  // b.lo, b.ul, b.last
   337a4:	cmp	x21, x20
   337a8:	b.ls	337e8 <__gmpn_hgcd2@@Base+0x118>  // b.plast
   337ac:	mov	x0, sp
   337b0:	mov	x1, x21
   337b4:	mov	x2, x23
   337b8:	mov	x3, x20
   337bc:	mov	x4, x22
   337c0:	bl	33928 <__gmpn_hgcd2@@Base+0x258>
   337c4:	ldr	x21, [sp, #8]
   337c8:	cmp	x21, #0x1
   337cc:	cinc	x8, x0, hi  // hi = pmore
   337d0:	cmp	x21, #0x2
   337d4:	madd	x27, x8, x24, x27
   337d8:	madd	x25, x8, x26, x25
   337dc:	b.cc	338f0 <__gmpn_hgcd2@@Base+0x220>  // b.lo, b.ul, b.last
   337e0:	ldr	x23, [sp]
   337e4:	b	337f0 <__gmpn_hgcd2@@Base+0x120>
   337e8:	add	x25, x25, x26
   337ec:	add	x27, x27, x24
   337f0:	cmp	x21, x20
   337f4:	b.eq	338f0 <__gmpn_hgcd2@@Base+0x220>  // b.none
   337f8:	lsr	x8, x20, #32
   337fc:	cbz	x8, 33870 <__gmpn_hgcd2@@Base+0x1a0>
   33800:	mov	x8, x22
   33804:	subs	x22, x8, x23
   33808:	sbc	x20, x20, x21
   3380c:	cmp	x20, #0x2
   33810:	b.cc	338f0 <__gmpn_hgcd2@@Base+0x220>  // b.lo, b.ul, b.last
   33814:	cmp	x20, x21
   33818:	b.ls	33858 <__gmpn_hgcd2@@Base+0x188>  // b.plast
   3381c:	mov	x0, sp
   33820:	mov	x1, x20
   33824:	mov	x2, x22
   33828:	mov	x3, x21
   3382c:	mov	x4, x23
   33830:	bl	33928 <__gmpn_hgcd2@@Base+0x258>
   33834:	ldr	x20, [sp, #8]
   33838:	cmp	x20, #0x1
   3383c:	cinc	x8, x0, hi  // hi = pmore
   33840:	cmp	x20, #0x2
   33844:	madd	x24, x8, x27, x24
   33848:	madd	x26, x8, x25, x26
   3384c:	b.cc	338f0 <__gmpn_hgcd2@@Base+0x220>  // b.lo, b.ul, b.last
   33850:	ldr	x22, [sp]
   33854:	b	33780 <__gmpn_hgcd2@@Base+0xb0>
   33858:	add	x26, x25, x26
   3385c:	add	x24, x27, x24
   33860:	b	33780 <__gmpn_hgcd2@@Base+0xb0>
   33864:	extr	x8, x21, x23, #32
   33868:	extr	x9, x20, x22, #32
   3386c:	b	3387c <__gmpn_hgcd2@@Base+0x1ac>
   33870:	extr	x8, x21, x23, #32
   33874:	extr	x9, x20, x22, #32
   33878:	b	338bc <__gmpn_hgcd2@@Base+0x1ec>
   3387c:	sub	x8, x8, x9
   33880:	lsr	x10, x8, #33
   33884:	cbz	x10, 338f0 <__gmpn_hgcd2@@Base+0x220>
   33888:	cmp	x8, x9
   3388c:	b.ls	338b4 <__gmpn_hgcd2@@Base+0x1e4>  // b.plast
   33890:	udiv	x10, x8, x9
   33894:	msub	x8, x10, x9, x8
   33898:	lsr	x11, x8, #33
   3389c:	cmp	x11, #0x0
   338a0:	cinc	x10, x10, ne  // ne = any
   338a4:	madd	x27, x10, x24, x27
   338a8:	madd	x25, x10, x26, x25
   338ac:	cbnz	x11, 338bc <__gmpn_hgcd2@@Base+0x1ec>
   338b0:	b	338f0 <__gmpn_hgcd2@@Base+0x220>
   338b4:	add	x25, x25, x26
   338b8:	add	x27, x27, x24
   338bc:	sub	x9, x9, x8
   338c0:	lsr	x10, x9, #33
   338c4:	cbz	x10, 338f0 <__gmpn_hgcd2@@Base+0x220>
   338c8:	cmp	x9, x8
   338cc:	b.ls	3391c <__gmpn_hgcd2@@Base+0x24c>  // b.plast
   338d0:	udiv	x10, x9, x8
   338d4:	msub	x9, x10, x8, x9
   338d8:	lsr	x11, x9, #33
   338dc:	cmp	x11, #0x0
   338e0:	cinc	x10, x10, ne  // ne = any
   338e4:	madd	x24, x10, x27, x24
   338e8:	madd	x26, x10, x25, x26
   338ec:	cbnz	x11, 3387c <__gmpn_hgcd2@@Base+0x1ac>
   338f0:	mov	w0, #0x1                   	// #1
   338f4:	stp	x26, x25, [x19]
   338f8:	stp	x24, x27, [x19, #16]
   338fc:	ldp	x20, x19, [sp, #96]
   33900:	ldp	x22, x21, [sp, #80]
   33904:	ldp	x24, x23, [sp, #64]
   33908:	ldp	x26, x25, [sp, #48]
   3390c:	ldr	x27, [sp, #32]
   33910:	ldp	x29, x30, [sp, #16]
   33914:	add	sp, sp, #0x70
   33918:	ret
   3391c:	add	x26, x25, x26
   33920:	add	x24, x27, x24
   33924:	b	3387c <__gmpn_hgcd2@@Base+0x1ac>
   33928:	clz	x11, x1
   3392c:	clz	x10, x3
   33930:	mov	w9, #0x3f                  	// #63
   33934:	sub	w12, w10, w11
   33938:	lsl	x13, x3, x12
   3393c:	sub	w14, w9, w12
   33940:	lsl	x9, x4, x12
   33944:	lsr	x12, x4, #1
   33948:	mvn	w15, w10
   3394c:	lsr	x10, x12, x14
   33950:	mov	x8, xzr
   33954:	add	x10, x10, x13
   33958:	add	w11, w15, w11
   3395c:	cmp	x2, x9
   33960:	cset	w12, cs  // cs = hs, nlast
   33964:	cmp	x1, x10
   33968:	cset	w13, hi  // hi = pmore
   3396c:	csel	w12, w12, w13, eq  // eq = none
   33970:	sbfx	x13, x12, #0, #1
   33974:	bfi	x12, x8, #1, #63
   33978:	mov	x8, x12
   3397c:	and	x14, x9, x13
   33980:	and	x13, x10, x13
   33984:	subs	x12, x2, x14
   33988:	sbc	x1, x1, x13
   3398c:	extr	x9, x10, x9, #1
   33990:	adds	w11, w11, #0x1
   33994:	lsr	x10, x10, #1
   33998:	mov	x2, x12
   3399c:	b.cc	3395c <__gmpn_hgcd2@@Base+0x28c>  // b.lo, b.ul, b.last
   339a0:	stp	x12, x1, [x0]
   339a4:	mov	x0, x8
   339a8:	ret

00000000000339ac <__gmpn_hgcd_mul_matrix1_vector@@Base>:
   339ac:	stp	x29, x30, [sp, #-64]!
   339b0:	stp	x24, x23, [sp, #16]
   339b4:	stp	x22, x21, [sp, #32]
   339b8:	stp	x20, x19, [sp, #48]
   339bc:	mov	x20, x3
   339c0:	ldr	x3, [x0]
   339c4:	mov	x21, x2
   339c8:	mov	x22, x0
   339cc:	mov	x23, x1
   339d0:	mov	x0, x1
   339d4:	mov	x1, x2
   339d8:	mov	x2, x4
   339dc:	mov	x29, sp
   339e0:	mov	x19, x4
   339e4:	bl	d4b0 <__gmpn_mul_1@plt>
   339e8:	ldr	x3, [x22, #16]
   339ec:	mov	x24, x0
   339f0:	mov	x0, x23
   339f4:	mov	x1, x20
   339f8:	mov	x2, x19
   339fc:	bl	d420 <__gmpn_addmul_1@plt>
   33a00:	ldr	x3, [x22, #24]
   33a04:	add	x24, x0, x24
   33a08:	mov	x0, x20
   33a0c:	mov	x1, x20
   33a10:	mov	x2, x19
   33a14:	bl	d4b0 <__gmpn_mul_1@plt>
   33a18:	ldr	x3, [x22, #8]
   33a1c:	mov	x22, x0
   33a20:	mov	x0, x20
   33a24:	mov	x1, x21
   33a28:	mov	x2, x19
   33a2c:	bl	d420 <__gmpn_addmul_1@plt>
   33a30:	add	x8, x0, x22
   33a34:	orr	x9, x8, x24
   33a38:	str	x24, [x23, x19, lsl #3]
   33a3c:	cmp	x9, #0x0
   33a40:	str	x8, [x20, x19, lsl #3]
   33a44:	cinc	x0, x19, ne  // ne = any
   33a48:	ldp	x20, x19, [sp, #48]
   33a4c:	ldp	x22, x21, [sp, #32]
   33a50:	ldp	x24, x23, [sp, #16]
   33a54:	ldp	x29, x30, [sp], #64
   33a58:	ret

0000000000033a5c <__gmpn_hgcd_step@@Base>:
   33a5c:	sub	sp, sp, #0x60
   33a60:	lsl	x8, x0, #3
   33a64:	stp	x29, x30, [sp, #32]
   33a68:	stp	x24, x23, [sp, #48]
   33a6c:	stp	x22, x21, [sp, #64]
   33a70:	stp	x20, x19, [sp, #80]
   33a74:	sub	x9, x8, #0x8
   33a78:	mov	x21, x2
   33a7c:	mov	x20, x0
   33a80:	ldr	x0, [x1, x9]
   33a84:	ldr	x2, [x2, x9]
   33a88:	add	x9, x3, #0x1
   33a8c:	mov	x19, x5
   33a90:	mov	x23, x4
   33a94:	mov	x22, x1
   33a98:	mov	x24, x3
   33a9c:	cmp	x9, x20
   33aa0:	orr	x9, x2, x0
   33aa4:	add	x29, sp, #0x20
   33aa8:	b.ne	33ab8 <__gmpn_hgcd_step@@Base+0x5c>  // b.any
   33aac:	cmp	x9, #0x4
   33ab0:	b.cs	33b10 <__gmpn_hgcd_step@@Base+0xb4>  // b.hs, b.nlast
   33ab4:	b	33b64 <__gmpn_hgcd_step@@Base+0x108>
   33ab8:	tbnz	x9, #63, 33b10 <__gmpn_hgcd_step@@Base+0xb4>
   33abc:	sub	x10, x8, #0x10
   33ac0:	sub	x8, x8, #0x18
   33ac4:	ldr	x12, [x22, x10]
   33ac8:	ldr	x14, [x22, x8]
   33acc:	ldr	x10, [x21, x10]
   33ad0:	ldr	x8, [x21, x8]
   33ad4:	clz	x9, x9
   33ad8:	neg	x13, x9
   33adc:	lsl	x11, x0, x9
   33ae0:	lsl	x15, x2, x9
   33ae4:	lsr	x16, x12, x13
   33ae8:	lsl	x12, x12, x9
   33aec:	lsr	x14, x14, x13
   33af0:	lsl	x9, x10, x9
   33af4:	lsr	x10, x10, x13
   33af8:	lsr	x8, x8, x13
   33afc:	orr	x0, x16, x11
   33b00:	orr	x1, x14, x12
   33b04:	orr	x2, x10, x15
   33b08:	orr	x3, x8, x9
   33b0c:	b	33b1c <__gmpn_hgcd_step@@Base+0xc0>
   33b10:	sub	x8, x8, #0x10
   33b14:	ldr	x1, [x22, x8]
   33b18:	ldr	x3, [x21, x8]
   33b1c:	mov	x4, sp
   33b20:	bl	c5c0 <__gmpn_hgcd2@plt>
   33b24:	cbz	w0, 33b64 <__gmpn_hgcd_step@@Base+0x108>
   33b28:	mov	x1, sp
   33b2c:	mov	x0, x23
   33b30:	mov	x2, x19
   33b34:	bl	c7a0 <__gmpn_hgcd_matrix_mul_1@plt>
   33b38:	mov	x0, x19
   33b3c:	mov	x1, x22
   33b40:	mov	x2, x20
   33b44:	bl	ca70 <__gmpn_copyi@plt>
   33b48:	mov	x0, sp
   33b4c:	mov	x1, x22
   33b50:	mov	x2, x19
   33b54:	mov	x3, x21
   33b58:	mov	x4, x20
   33b5c:	bl	c510 <__gmpn_matrix22_mul1_inverse_vector@plt>
   33b60:	b	33b88 <__gmpn_hgcd_step@@Base+0x12c>
   33b64:	adrp	x4, 33000 <__gmpn_hgcd_matrix_update_q@@Base+0x20>
   33b68:	add	x4, x4, #0xba0
   33b6c:	mov	x0, x22
   33b70:	mov	x1, x21
   33b74:	mov	x2, x20
   33b78:	mov	x3, x24
   33b7c:	mov	x5, x23
   33b80:	mov	x6, x19
   33b84:	bl	d2d0 <__gmpn_gcd_subdiv_step@plt>
   33b88:	ldp	x20, x19, [sp, #80]
   33b8c:	ldp	x22, x21, [sp, #64]
   33b90:	ldp	x24, x23, [sp, #48]
   33b94:	ldp	x29, x30, [sp, #32]
   33b98:	add	sp, sp, #0x60
   33b9c:	ret
   33ba0:	add	x9, x3, x4, lsl #3
   33ba4:	mov	x8, x4
   33ba8:	add	x4, x9, #0x8
   33bac:	subs	x8, x8, #0x1
   33bb0:	b.lt	33bd0 <__gmpn_hgcd_step@@Base+0x174>  // b.tstop
   33bb4:	ldur	x9, [x4, #-16]
   33bb8:	sub	x4, x4, #0x8
   33bbc:	cbz	x9, 33bac <__gmpn_hgcd_step@@Base+0x150>
   33bc0:	add	x2, x8, #0x1
   33bc4:	mov	x1, x3
   33bc8:	mov	w3, w5
   33bcc:	b	d040 <__gmpn_hgcd_matrix_update_q@plt>
   33bd0:	ret

0000000000033bd4 <__gmpn_hgcd_reduce_itch@@Base>:
   33bd4:	stp	x29, x30, [sp, #-48]!
   33bd8:	str	x21, [sp, #16]
   33bdc:	cmp	x0, #0x68e
   33be0:	sub	x21, x0, x1
   33be4:	stp	x20, x19, [sp, #32]
   33be8:	mov	x29, sp
   33bec:	b.le	33c00 <__gmpn_hgcd_reduce_itch@@Base+0x2c>
   33bf0:	mov	x0, x21
   33bf4:	bl	c5b0 <__gmpn_hgcd_itch@plt>
   33bf8:	add	x0, x0, x21, lsl #1
   33bfc:	b	33c20 <__gmpn_hgcd_reduce_itch@@Base+0x4c>
   33c00:	mov	x20, x0
   33c04:	mov	x0, x21
   33c08:	mov	x19, x1
   33c0c:	bl	c5b0 <__gmpn_hgcd_itch@plt>
   33c10:	add	x8, x20, x19
   33c14:	sub	x8, x8, #0x1
   33c18:	cmp	x0, x8
   33c1c:	csel	x0, x8, x0, lt  // lt = tstop
   33c20:	ldp	x20, x19, [sp, #32]
   33c24:	ldr	x21, [sp, #16]
   33c28:	ldp	x29, x30, [sp], #48
   33c2c:	ret

0000000000033c30 <__gmpn_hgcd_reduce@@Base>:
   33c30:	stp	x29, x30, [sp, #-80]!
   33c34:	stp	x24, x23, [sp, #32]
   33c38:	stp	x22, x21, [sp, #48]
   33c3c:	stp	x20, x19, [sp, #64]
   33c40:	mov	x22, x5
   33c44:	mov	x24, x4
   33c48:	mov	x23, x3
   33c4c:	mov	x19, x2
   33c50:	mov	x20, x1
   33c54:	mov	x21, x0
   33c58:	cmp	x3, #0x68e
   33c5c:	add	x8, x1, x4, lsl #3
   33c60:	stp	x26, x25, [sp, #16]
   33c64:	mov	x29, sp
   33c68:	b.le	33cdc <__gmpn_hgcd_reduce@@Base+0xac>
   33c6c:	sub	x25, x23, x24
   33c70:	mov	x0, x22
   33c74:	mov	x1, x8
   33c78:	mov	x2, x25
   33c7c:	bl	ca70 <__gmpn_copyi@plt>
   33c80:	add	x8, x22, x23, lsl #3
   33c84:	sub	x26, x8, x24, lsl #3
   33c88:	add	x1, x19, x24, lsl #3
   33c8c:	mov	x0, x26
   33c90:	mov	x2, x25
   33c94:	bl	ca70 <__gmpn_copyi@plt>
   33c98:	add	x4, x22, x25, lsl #4
   33c9c:	mov	x0, x22
   33ca0:	mov	x1, x26
   33ca4:	mov	x2, x25
   33ca8:	mov	x3, x21
   33cac:	bl	cd70 <__gmpn_hgcd_appr@plt>
   33cb0:	cbz	w0, 33d2c <__gmpn_hgcd_reduce@@Base+0xfc>
   33cb4:	mov	x0, x21
   33cb8:	mov	x1, x20
   33cbc:	mov	x2, x19
   33cc0:	mov	x3, x23
   33cc4:	ldp	x20, x19, [sp, #64]
   33cc8:	ldp	x22, x21, [sp, #48]
   33ccc:	ldp	x24, x23, [sp, #32]
   33cd0:	ldp	x26, x25, [sp, #16]
   33cd4:	ldp	x29, x30, [sp], #80
   33cd8:	b	33d48 <__gmpn_hgcd_reduce@@Base+0x118>
   33cdc:	add	x1, x19, x24, lsl #3
   33ce0:	sub	x2, x23, x24
   33ce4:	mov	x0, x8
   33ce8:	mov	x3, x21
   33cec:	mov	x4, x22
   33cf0:	bl	ce00 <__gmpn_hgcd@plt>
   33cf4:	cmp	x0, #0x1
   33cf8:	b.lt	33d2c <__gmpn_hgcd_reduce@@Base+0xfc>  // b.tstop
   33cfc:	add	x1, x0, x24
   33d00:	mov	x0, x21
   33d04:	mov	x2, x20
   33d08:	mov	x3, x19
   33d0c:	mov	x4, x24
   33d10:	mov	x5, x22
   33d14:	ldp	x20, x19, [sp, #64]
   33d18:	ldp	x22, x21, [sp, #48]
   33d1c:	ldp	x24, x23, [sp, #32]
   33d20:	ldp	x26, x25, [sp, #16]
   33d24:	ldp	x29, x30, [sp], #80
   33d28:	b	c8c0 <__gmpn_hgcd_matrix_adjust@plt>
   33d2c:	ldp	x20, x19, [sp, #64]
   33d30:	ldp	x22, x21, [sp, #48]
   33d34:	ldp	x24, x23, [sp, #32]
   33d38:	ldp	x26, x25, [sp, #16]
   33d3c:	mov	x0, xzr
   33d40:	ldp	x29, x30, [sp], #80
   33d44:	ret
   33d48:	stp	x29, x30, [sp, #-96]!
   33d4c:	stp	x28, x27, [sp, #16]
   33d50:	stp	x26, x25, [sp, #32]
   33d54:	stp	x24, x23, [sp, #48]
   33d58:	stp	x22, x21, [sp, #64]
   33d5c:	stp	x20, x19, [sp, #80]
   33d60:	mov	x29, sp
   33d64:	sub	sp, sp, #0x60
   33d68:	mov	x22, x3
   33d6c:	mov	x19, x2
   33d70:	mov	x20, x1
   33d74:	mov	x21, x0
   33d78:	mov	x8, x3
   33d7c:	mov	x3, x8
   33d80:	subs	x8, x8, #0x1
   33d84:	b.lt	33d94 <__gmpn_hgcd_reduce@@Base+0x164>  // b.tstop
   33d88:	add	x9, x20, x3, lsl #3
   33d8c:	ldur	x9, [x9, #-8]
   33d90:	cbz	x9, 33d7c <__gmpn_hgcd_reduce@@Base+0x14c>
   33d94:	mov	x9, x22
   33d98:	mov	x8, x9
   33d9c:	subs	x9, x9, #0x1
   33da0:	b.lt	33db0 <__gmpn_hgcd_reduce@@Base+0x180>  // b.tstop
   33da4:	add	x10, x19, x8, lsl #3
   33da8:	ldur	x10, [x10, #-8]
   33dac:	cbz	x10, 33d98 <__gmpn_hgcd_reduce@@Base+0x168>
   33db0:	ldr	x23, [x21, #8]
   33db4:	mov	x9, xzr
   33db8:	sub	x10, x29, #0x20
   33dbc:	mov	x11, xzr
   33dc0:	add	x12, x21, x9, lsl #4
   33dc4:	add	x12, x12, x11, lsl #3
   33dc8:	add	x12, x12, #0x10
   33dcc:	mov	x14, x23
   33dd0:	mov	x13, x14
   33dd4:	subs	x14, x14, #0x1
   33dd8:	b.lt	33dec <__gmpn_hgcd_reduce@@Base+0x1bc>  // b.tstop
   33ddc:	ldr	x15, [x12]
   33de0:	add	x15, x15, x13, lsl #3
   33de4:	ldur	x15, [x15, #-8]
   33de8:	cbz	x15, 33dd0 <__gmpn_hgcd_reduce@@Base+0x1a0>
   33dec:	add	x12, x10, x9, lsl #4
   33df0:	str	x13, [x12, x11, lsl #3]
   33df4:	add	x11, x11, #0x1
   33df8:	cmp	x11, #0x2
   33dfc:	b.ne	33dc0 <__gmpn_hgcd_reduce@@Base+0x190>  // b.any
   33e00:	add	x9, x9, #0x1
   33e04:	cmp	x9, #0x2
   33e08:	b.ne	33dbc <__gmpn_hgcd_reduce@@Base+0x18c>  // b.any
   33e0c:	ldur	x27, [x29, #-24]
   33e10:	stur	xzr, [x29, #-40]
   33e14:	cbz	x27, 33f0c <__gmpn_hgcd_reduce@@Base+0x2dc>
   33e18:	ldur	x9, [x29, #-16]
   33e1c:	cbz	x9, 33f24 <__gmpn_hgcd_reduce@@Base+0x2f4>
   33e20:	ldur	x11, [x29, #-32]
   33e24:	ldur	x10, [x29, #-8]
   33e28:	sub	x9, x8, x9
   33e2c:	sub	x12, x3, x27
   33e30:	stur	x11, [x29, #-80]
   33e34:	sub	x11, x3, x11
   33e38:	sub	x10, x8, x10
   33e3c:	cmp	x11, x9
   33e40:	csel	x8, x11, x9, lt  // lt = tstop
   33e44:	cmp	x12, x10
   33e48:	stp	x11, x9, [x29, #-56]
   33e4c:	csel	x9, x12, x10, lt  // lt = tstop
   33e50:	cmp	x8, x9
   33e54:	csel	x8, x8, x9, gt
   33e58:	add	x0, x8, #0x2
   33e5c:	stp	x10, x12, [x29, #-72]
   33e60:	stur	x8, [x29, #-88]
   33e64:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   33e68:	asr	x8, x0, #1
   33e6c:	cmp	x8, x23
   33e70:	csel	x10, x0, x8, lt  // lt = tstop
   33e74:	cmp	x8, x0
   33e78:	add	x9, x0, x0, lsl #1
   33e7c:	csel	x8, x10, xzr, lt  // lt = tstop
   33e80:	add	x8, x9, x8
   33e84:	lsl	x8, x8, #3
   33e88:	add	x1, x8, #0x20
   33e8c:	mov	w8, #0x7f00                	// #32512
   33e90:	mov	x24, x0
   33e94:	cmp	x1, x8
   33e98:	b.hi	341f4 <__gmpn_hgcd_reduce@@Base+0x5c4>  // b.pmore
   33e9c:	add	x9, x1, #0xf
   33ea0:	mov	x8, sp
   33ea4:	and	x9, x9, #0xfffffffffffffff0
   33ea8:	sub	x25, x8, x9
   33eac:	mov	sp, x25
   33eb0:	add	x26, x25, x24, lsl #3
   33eb4:	cmp	x24, x22
   33eb8:	add	x28, x26, x24, lsl #3
   33ebc:	b.ge	33fb4 <__gmpn_hgcd_reduce@@Base+0x384>  // b.tcont
   33ec0:	subs	x23, x22, x24
   33ec4:	mov	x22, x24
   33ec8:	b.eq	33fb4 <__gmpn_hgcd_reduce@@Base+0x384>  // b.none
   33ecc:	add	x2, x20, x24, lsl #3
   33ed0:	mov	x0, x20
   33ed4:	mov	x1, x20
   33ed8:	mov	x3, x23
   33edc:	bl	ca90 <__gmpn_add_n@plt>
   33ee0:	cbz	x0, 33f5c <__gmpn_hgcd_reduce@@Base+0x32c>
   33ee4:	mov	x8, x23
   33ee8:	cmp	x8, x24
   33eec:	b.ge	33f48 <__gmpn_hgcd_reduce@@Base+0x318>  // b.tcont
   33ef0:	ldr	x9, [x20, x8, lsl #3]
   33ef4:	add	x10, x8, #0x1
   33ef8:	adds	x9, x9, #0x1
   33efc:	str	x9, [x20, x8, lsl #3]
   33f00:	mov	x8, x10
   33f04:	b.cs	33ee8 <__gmpn_hgcd_reduce@@Base+0x2b8>  // b.hs, b.nlast
   33f08:	b	33f5c <__gmpn_hgcd_reduce@@Base+0x32c>
   33f0c:	ldr	x4, [x21, #32]
   33f10:	ldur	x5, [x29, #-16]
   33f14:	mov	x0, x19
   33f18:	mov	x1, x8
   33f1c:	mov	x2, x20
   33f20:	b	33f3c <__gmpn_hgcd_reduce@@Base+0x30c>
   33f24:	ldr	x4, [x21, #24]
   33f28:	mov	x0, x20
   33f2c:	mov	x1, x3
   33f30:	mov	x2, x19
   33f34:	mov	x3, x8
   33f38:	mov	x5, x27
   33f3c:	bl	3420c <__gmpn_hgcd_reduce@@Base+0x5dc>
   33f40:	mov	x19, x0
   33f44:	b	341d0 <__gmpn_hgcd_reduce@@Base+0x5a0>
   33f48:	mov	x8, x20
   33f4c:	ldr	x9, [x8]
   33f50:	adds	x9, x9, #0x1
   33f54:	str	x9, [x8], #8
   33f58:	b.cs	33f4c <__gmpn_hgcd_reduce@@Base+0x31c>  // b.hs, b.nlast
   33f5c:	add	x2, x19, x24, lsl #3
   33f60:	mov	x0, x19
   33f64:	mov	x1, x19
   33f68:	mov	x3, x23
   33f6c:	bl	ca90 <__gmpn_add_n@plt>
   33f70:	mov	x22, x24
   33f74:	cbz	x0, 33fb4 <__gmpn_hgcd_reduce@@Base+0x384>
   33f78:	cmp	x23, x24
   33f7c:	b.ge	33f9c <__gmpn_hgcd_reduce@@Base+0x36c>  // b.tcont
   33f80:	ldr	x8, [x19, x23, lsl #3]
   33f84:	add	x9, x23, #0x1
   33f88:	adds	x8, x8, #0x1
   33f8c:	str	x8, [x19, x23, lsl #3]
   33f90:	mov	x23, x9
   33f94:	b.cs	33f78 <__gmpn_hgcd_reduce@@Base+0x348>  // b.hs, b.nlast
   33f98:	b	33fb0 <__gmpn_hgcd_reduce@@Base+0x380>
   33f9c:	mov	x8, x19
   33fa0:	ldr	x9, [x8]
   33fa4:	adds	x9, x9, #0x1
   33fa8:	str	x9, [x8], #8
   33fac:	b.cs	33fa0 <__gmpn_hgcd_reduce@@Base+0x370>  // b.hs, b.nlast
   33fb0:	mov	x22, x24
   33fb4:	ldur	x23, [x29, #-8]
   33fb8:	ldr	x4, [x21, #40]
   33fbc:	mov	x0, x25
   33fc0:	mov	x1, x24
   33fc4:	mov	x2, x20
   33fc8:	mov	x3, x22
   33fcc:	mov	x5, x23
   33fd0:	mov	x6, x28
   33fd4:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   33fd8:	ldr	x4, [x21, #24]
   33fdc:	mov	x0, x26
   33fe0:	mov	x1, x24
   33fe4:	mov	x2, x19
   33fe8:	mov	x3, x22
   33fec:	mov	x5, x27
   33ff0:	mov	x6, x28
   33ff4:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   33ff8:	add	x8, x23, x22
   33ffc:	cmp	x8, x24
   34000:	b.ge	34024 <__gmpn_hgcd_reduce@@Base+0x3f4>  // b.tcont
   34004:	sub	x8, x24, x22
   34008:	subs	x8, x8, x23
   3400c:	b.eq	34024 <__gmpn_hgcd_reduce@@Base+0x3f4>  // b.none
   34010:	add	x9, x22, x23
   34014:	add	x0, x25, x9, lsl #3
   34018:	lsl	x2, x8, #3
   3401c:	mov	w1, wzr
   34020:	bl	c610 <memset@plt>
   34024:	add	x8, x22, x27
   34028:	cmp	x8, x24
   3402c:	ldur	x8, [x29, #-88]
   34030:	add	x23, x8, #0x1
   34034:	b.ge	3405c <__gmpn_hgcd_reduce@@Base+0x42c>  // b.tcont
   34038:	sub	x8, x24, x22
   3403c:	subs	x8, x8, x27
   34040:	b.eq	3405c <__gmpn_hgcd_reduce@@Base+0x42c>  // b.none
   34044:	add	x9, x24, x22
   34048:	add	x9, x9, x27
   3404c:	add	x0, x25, x9, lsl #3
   34050:	lsl	x2, x8, #3
   34054:	mov	w1, wzr
   34058:	bl	c610 <memset@plt>
   3405c:	mov	x0, x25
   34060:	mov	x1, x25
   34064:	mov	x2, x26
   34068:	mov	x3, x24
   3406c:	bl	c2e0 <__gmpn_sub_n@plt>
   34070:	ldr	x8, [x25]
   34074:	subs	x8, x8, x0
   34078:	str	x8, [x25]
   3407c:	b.cs	34094 <__gmpn_hgcd_reduce@@Base+0x464>  // b.hs, b.nlast
   34080:	add	x8, x25, #0x8
   34084:	ldr	x9, [x8]
   34088:	sub	x10, x9, #0x1
   3408c:	str	x10, [x8], #8
   34090:	cbz	x9, 34084 <__gmpn_hgcd_reduce@@Base+0x454>
   34094:	ldur	x27, [x29, #-16]
   34098:	ldr	x4, [x21, #32]
   3409c:	mov	x0, x26
   340a0:	mov	x1, x24
   340a4:	mov	x2, x20
   340a8:	mov	x3, x22
   340ac:	mov	x5, x27
   340b0:	mov	x6, x28
   340b4:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   340b8:	mov	x0, x20
   340bc:	mov	x1, x25
   340c0:	mov	x2, x23
   340c4:	bl	ca70 <__gmpn_copyi@plt>
   340c8:	ldr	x4, [x21, #16]
   340cc:	ldur	x21, [x29, #-80]
   340d0:	mov	x0, x25
   340d4:	mov	x1, x24
   340d8:	mov	x2, x19
   340dc:	mov	x3, x22
   340e0:	mov	x5, x21
   340e4:	mov	x6, x28
   340e8:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   340ec:	add	x8, x27, x22
   340f0:	cmp	x8, x24
   340f4:	b.ge	3411c <__gmpn_hgcd_reduce@@Base+0x4ec>  // b.tcont
   340f8:	sub	x8, x24, x22
   340fc:	subs	x8, x8, x27
   34100:	b.eq	3411c <__gmpn_hgcd_reduce@@Base+0x4ec>  // b.none
   34104:	add	x9, x24, x22
   34108:	add	x9, x9, x27
   3410c:	add	x0, x25, x9, lsl #3
   34110:	lsl	x2, x8, #3
   34114:	mov	w1, wzr
   34118:	bl	c610 <memset@plt>
   3411c:	add	x8, x22, x21
   34120:	cmp	x8, x24
   34124:	b.ge	34148 <__gmpn_hgcd_reduce@@Base+0x518>  // b.tcont
   34128:	sub	x8, x24, x22
   3412c:	subs	x8, x8, x21
   34130:	b.eq	34148 <__gmpn_hgcd_reduce@@Base+0x518>  // b.none
   34134:	add	x9, x22, x21
   34138:	add	x0, x25, x9, lsl #3
   3413c:	lsl	x2, x8, #3
   34140:	mov	w1, wzr
   34144:	bl	c610 <memset@plt>
   34148:	mov	x0, x25
   3414c:	mov	x1, x25
   34150:	mov	x2, x26
   34154:	mov	x3, x24
   34158:	bl	c2e0 <__gmpn_sub_n@plt>
   3415c:	ldr	x8, [x25]
   34160:	subs	x8, x8, x0
   34164:	str	x8, [x25]
   34168:	b.cs	34180 <__gmpn_hgcd_reduce@@Base+0x550>  // b.hs, b.nlast
   3416c:	add	x8, x25, #0x8
   34170:	ldr	x9, [x8]
   34174:	sub	x10, x9, #0x1
   34178:	str	x10, [x8], #8
   3417c:	cbz	x9, 34170 <__gmpn_hgcd_reduce@@Base+0x540>
   34180:	mov	x0, x19
   34184:	mov	x1, x25
   34188:	mov	x2, x23
   3418c:	bl	ca70 <__gmpn_copyi@plt>
   34190:	ldp	x9, x8, [x29, #-72]
   34194:	cmp	x8, x9
   34198:	csel	x8, x8, x9, lt  // lt = tstop
   3419c:	ldp	x10, x9, [x29, #-56]
   341a0:	cmp	x10, x9
   341a4:	csel	x9, x10, x9, lt  // lt = tstop
   341a8:	cmp	x8, x9
   341ac:	csel	x8, x8, x9, gt
   341b0:	ldr	x9, [x20, x8, lsl #3]
   341b4:	ldr	x10, [x19, x8, lsl #3]
   341b8:	sub	x8, x8, #0x1
   341bc:	orr	x9, x10, x9
   341c0:	cbz	x9, 341b0 <__gmpn_hgcd_reduce@@Base+0x580>
   341c4:	ldur	x0, [x29, #-40]
   341c8:	add	x19, x8, #0x2
   341cc:	cbnz	x0, 34204 <__gmpn_hgcd_reduce@@Base+0x5d4>
   341d0:	mov	x0, x19
   341d4:	mov	sp, x29
   341d8:	ldp	x20, x19, [sp, #80]
   341dc:	ldp	x22, x21, [sp, #64]
   341e0:	ldp	x24, x23, [sp, #48]
   341e4:	ldp	x26, x25, [sp, #32]
   341e8:	ldp	x28, x27, [sp, #16]
   341ec:	ldp	x29, x30, [sp], #96
   341f0:	ret
   341f4:	sub	x0, x29, #0x28
   341f8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   341fc:	mov	x25, x0
   34200:	b	33eb0 <__gmpn_hgcd_reduce@@Base+0x280>
   34204:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   34208:	b	341d0 <__gmpn_hgcd_reduce@@Base+0x5a0>
   3420c:	stp	x29, x30, [sp, #-80]!
   34210:	stp	x26, x25, [sp, #16]
   34214:	stp	x24, x23, [sp, #32]
   34218:	stp	x22, x21, [sp, #48]
   3421c:	stp	x20, x19, [sp, #64]
   34220:	mov	x29, sp
   34224:	sub	sp, sp, #0x10
   34228:	add	x26, x5, x3
   3422c:	mov	x20, x1
   34230:	lsl	x1, x26, #3
   34234:	mov	w8, #0x7f00                	// #32512
   34238:	mov	x22, x5
   3423c:	mov	x23, x4
   34240:	mov	x19, x3
   34244:	mov	x24, x2
   34248:	mov	x21, x0
   3424c:	cmp	x1, x8
   34250:	stur	xzr, [x29, #-8]
   34254:	b.hi	3430c <__gmpn_hgcd_reduce@@Base+0x6dc>  // b.pmore
   34258:	add	x9, x1, #0xf
   3425c:	mov	x8, sp
   34260:	and	x9, x9, #0xfffffffffffffff0
   34264:	sub	x25, x8, x9
   34268:	mov	sp, x25
   3426c:	mov	x0, x25
   34270:	mov	x1, x24
   34274:	mov	x2, x19
   34278:	mov	x3, x23
   3427c:	mov	x4, x22
   34280:	bl	ccf0 <__gmpn_mul@plt>
   34284:	cmp	x26, x20
   34288:	cset	w8, gt
   3428c:	subs	x22, x26, x8
   34290:	b.eq	342cc <__gmpn_hgcd_reduce@@Base+0x69c>  // b.none
   34294:	mov	x0, x21
   34298:	mov	x1, x21
   3429c:	mov	x2, x25
   342a0:	mov	x3, x22
   342a4:	bl	c2e0 <__gmpn_sub_n@plt>
   342a8:	cbz	x0, 342cc <__gmpn_hgcd_reduce@@Base+0x69c>
   342ac:	cmp	x22, x20
   342b0:	b.ge	342cc <__gmpn_hgcd_reduce@@Base+0x69c>  // b.tcont
   342b4:	ldr	x8, [x21, x22, lsl #3]
   342b8:	add	x10, x22, #0x1
   342bc:	sub	x9, x8, #0x1
   342c0:	str	x9, [x21, x22, lsl #3]
   342c4:	mov	x22, x10
   342c8:	cbz	x8, 342ac <__gmpn_hgcd_reduce@@Base+0x67c>
   342cc:	ldur	x0, [x29, #-8]
   342d0:	cbnz	x0, 3431c <__gmpn_hgcd_reduce@@Base+0x6ec>
   342d4:	sub	x8, x21, #0x8
   342d8:	mov	x0, x20
   342dc:	cmp	x20, x19
   342e0:	b.le	342f0 <__gmpn_hgcd_reduce@@Base+0x6c0>
   342e4:	ldr	x9, [x8, x0, lsl #3]
   342e8:	sub	x20, x0, #0x1
   342ec:	cbz	x9, 342d8 <__gmpn_hgcd_reduce@@Base+0x6a8>
   342f0:	mov	sp, x29
   342f4:	ldp	x20, x19, [sp, #64]
   342f8:	ldp	x22, x21, [sp, #48]
   342fc:	ldp	x24, x23, [sp, #32]
   34300:	ldp	x26, x25, [sp, #16]
   34304:	ldp	x29, x30, [sp], #80
   34308:	ret
   3430c:	sub	x0, x29, #0x8
   34310:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   34314:	mov	x25, x0
   34318:	b	3426c <__gmpn_hgcd_reduce@@Base+0x63c>
   3431c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   34320:	b	342d4 <__gmpn_hgcd_reduce@@Base+0x6a4>

0000000000034324 <__gmpn_hgcd_itch@@Base>:
   34324:	cmp	x0, #0x65
   34328:	b.lt	34384 <__gmpn_hgcd_itch@@Base+0x60>  // b.tstop
   3432c:	mov	x9, #0xd70b                	// #55051
   34330:	movk	x9, #0x70a3, lsl #16
   34334:	movk	x9, #0xa3d, lsl #32
   34338:	sub	x8, x0, #0x1
   3433c:	movk	x9, #0xa3d7, lsl #48
   34340:	smulh	x9, x8, x9
   34344:	add	x8, x9, x8
   34348:	add	x9, x0, #0x3
   3434c:	add	x11, x0, #0x6
   34350:	cmp	x9, #0x0
   34354:	csel	x9, x11, x9, lt  // lt = tstop
   34358:	asr	x11, x8, #6
   3435c:	add	x8, x11, x8, lsr #63
   34360:	mov	w10, #0x40                  	// #64
   34364:	clz	x8, x8
   34368:	sub	w8, w10, w8
   3436c:	mov	w10, #0x16                  	// #22
   34370:	mov	w11, #0x14                  	// #20
   34374:	asr	x9, x9, #2
   34378:	mul	w8, w8, w10
   3437c:	madd	x8, x9, x11, x8
   34380:	add	x0, x8, #0x65
   34384:	ret

0000000000034388 <__gmpn_hgcd@@Base>:
   34388:	sub	sp, sp, #0x90
   3438c:	cmp	x2, #0x0
   34390:	cinc	x8, x2, lt  // lt = tstop
   34394:	stp	x26, x25, [sp, #80]
   34398:	asr	x25, x8, #1
   3439c:	stp	x22, x21, [sp, #112]
   343a0:	add	x22, x25, #0x1
   343a4:	cmp	x22, x2
   343a8:	stp	x29, x30, [sp, #48]
   343ac:	stp	x28, x27, [sp, #64]
   343b0:	stp	x24, x23, [sp, #96]
   343b4:	stp	x20, x19, [sp, #128]
   343b8:	add	x29, sp, #0x30
   343bc:	b.ge	3445c <__gmpn_hgcd@@Base+0xd4>  // b.tcont
   343c0:	mov	x19, x4
   343c4:	mov	x20, x3
   343c8:	mov	x24, x2
   343cc:	mov	x21, x1
   343d0:	mov	x23, x0
   343d4:	cmp	x2, #0x64
   343d8:	b.le	34464 <__gmpn_hgcd@@Base+0xdc>
   343dc:	add	x8, x24, x24, lsl #1
   343e0:	add	x9, x8, #0x3
   343e4:	cmp	x8, #0x0
   343e8:	csel	x8, x9, x8, lt  // lt = tstop
   343ec:	asr	x8, x8, #2
   343f0:	mov	x0, x20
   343f4:	mov	x1, x23
   343f8:	mov	x2, x21
   343fc:	mov	x3, x24
   34400:	mov	x4, x25
   34404:	mov	x5, x19
   34408:	add	x26, x8, #0x1
   3440c:	bl	d310 <__gmpn_hgcd_reduce@plt>
   34410:	cmp	x0, #0x0
   34414:	cset	w8, ne  // ne = any
   34418:	csel	x0, x24, x0, eq  // eq = none
   3441c:	mov	x24, x0
   34420:	cmp	x0, x26
   34424:	mov	w28, w8
   34428:	b.le	344c0 <__gmpn_hgcd@@Base+0x138>
   3442c:	mov	x0, x24
   34430:	mov	x1, x23
   34434:	mov	x2, x21
   34438:	mov	x3, x22
   3443c:	mov	x4, x20
   34440:	mov	x5, x19
   34444:	bl	c2c0 <__gmpn_hgcd_step@plt>
   34448:	mov	w8, #0x1                   	// #1
   3444c:	cbnz	x0, 3441c <__gmpn_hgcd@@Base+0x94>
   34450:	cmp	w28, #0x0
   34454:	csel	x0, xzr, x24, eq  // eq = none
   34458:	b	344a0 <__gmpn_hgcd@@Base+0x118>
   3445c:	mov	x0, xzr
   34460:	b	344a0 <__gmpn_hgcd@@Base+0x118>
   34464:	mov	w28, wzr
   34468:	mov	x0, x24
   3446c:	mov	x1, x23
   34470:	mov	x2, x21
   34474:	mov	x3, x22
   34478:	mov	x4, x20
   3447c:	mov	x5, x19
   34480:	mov	x25, x24
   34484:	mov	w26, w28
   34488:	bl	c2c0 <__gmpn_hgcd_step@plt>
   3448c:	mov	x24, x0
   34490:	mov	w28, #0x1                   	// #1
   34494:	cbnz	x0, 34468 <__gmpn_hgcd@@Base+0xe0>
   34498:	cmp	w26, #0x0
   3449c:	csel	x0, xzr, x25, eq  // eq = none
   344a0:	ldp	x20, x19, [sp, #128]
   344a4:	ldp	x22, x21, [sp, #112]
   344a8:	ldp	x24, x23, [sp, #96]
   344ac:	ldp	x26, x25, [sp, #80]
   344b0:	ldp	x28, x27, [sp, #64]
   344b4:	ldp	x29, x30, [sp, #48]
   344b8:	add	sp, sp, #0x90
   344bc:	ret
   344c0:	add	x8, x25, #0x3
   344c4:	cmp	x24, x8
   344c8:	b.le	34468 <__gmpn_hgcd@@Base+0xe0>
   344cc:	lsl	x8, x22, #1
   344d0:	sub	x8, x8, x24
   344d4:	add	x25, x8, #0x1
   344d8:	sub	x27, x24, x25
   344dc:	add	x8, x27, #0x1
   344e0:	add	x9, x27, #0x2
   344e4:	cmp	x8, #0x0
   344e8:	csinc	x8, x9, x27, lt  // lt = tstop
   344ec:	lsl	x8, x8, #4
   344f0:	mov	x0, sp
   344f4:	mov	x1, x27
   344f8:	mov	x2, x19
   344fc:	and	x26, x8, #0xffffffffffffffe0
   34500:	bl	c850 <__gmpn_hgcd_matrix_init@plt>
   34504:	add	x8, x26, x19
   34508:	add	x26, x8, #0x20
   3450c:	add	x0, x23, x25, lsl #3
   34510:	add	x1, x21, x25, lsl #3
   34514:	mov	x3, sp
   34518:	mov	x2, x27
   3451c:	mov	x4, x26
   34520:	bl	ce00 <__gmpn_hgcd@plt>
   34524:	cmp	x0, #0x1
   34528:	b.lt	34468 <__gmpn_hgcd@@Base+0xe0>  // b.tstop
   3452c:	add	x1, x0, x25
   34530:	mov	x0, sp
   34534:	mov	x2, x23
   34538:	mov	x3, x21
   3453c:	mov	x4, x25
   34540:	mov	x5, x26
   34544:	bl	c8c0 <__gmpn_hgcd_matrix_adjust@plt>
   34548:	mov	x24, x0
   3454c:	mov	x1, sp
   34550:	mov	x0, x20
   34554:	mov	x2, x26
   34558:	bl	cfc0 <__gmpn_hgcd_matrix_mul@plt>
   3455c:	mov	w28, #0x1                   	// #1
   34560:	b	34468 <__gmpn_hgcd@@Base+0xe0>

0000000000034564 <__gmpn_hgcd_appr_itch@@Base>:
   34564:	cmp	x0, #0x68
   34568:	b.lt	345c4 <__gmpn_hgcd_appr_itch@@Base+0x60>  // b.tstop
   3456c:	mov	x9, #0x13e3                	// #5091
   34570:	movk	x9, #0x2548, lsl #16
   34574:	movk	x9, #0x65e7, lsl #32
   34578:	sub	x8, x0, #0x1
   3457c:	movk	x9, #0x9f11, lsl #48
   34580:	smulh	x9, x8, x9
   34584:	add	x8, x9, x8
   34588:	add	x9, x0, #0x3
   3458c:	add	x11, x0, #0x6
   34590:	cmp	x9, #0x0
   34594:	csel	x9, x11, x9, lt  // lt = tstop
   34598:	asr	x11, x8, #6
   3459c:	add	x8, x11, x8, lsr #63
   345a0:	mov	w10, #0x40                  	// #64
   345a4:	clz	x8, x8
   345a8:	sub	w8, w10, w8
   345ac:	mov	w10, #0x16                  	// #22
   345b0:	mov	w11, #0x14                  	// #20
   345b4:	asr	x9, x9, #2
   345b8:	mul	w8, w8, w10
   345bc:	madd	x8, x9, x11, x8
   345c0:	add	x0, x8, #0x65
   345c4:	ret

00000000000345c8 <__gmpn_hgcd_appr@@Base>:
   345c8:	sub	sp, sp, #0x90
   345cc:	cmp	x2, #0x3
   345d0:	stp	x29, x30, [sp, #48]
   345d4:	stp	x28, x27, [sp, #64]
   345d8:	stp	x26, x25, [sp, #80]
   345dc:	stp	x24, x23, [sp, #96]
   345e0:	stp	x22, x21, [sp, #112]
   345e4:	stp	x20, x19, [sp, #128]
   345e8:	add	x29, sp, #0x30
   345ec:	b.ge	345f8 <__gmpn_hgcd_appr@@Base+0x30>  // b.tcont
   345f0:	mov	w24, wzr
   345f4:	b	348f8 <__gmpn_hgcd_appr@@Base+0x330>
   345f8:	lsr	x26, x2, #1
   345fc:	mov	x20, x4
   34600:	mov	x19, x3
   34604:	mov	x25, x2
   34608:	mov	x21, x1
   3460c:	mov	x22, x0
   34610:	cmp	x2, #0x67
   34614:	add	x23, x26, #0x1
   34618:	b.le	34694 <__gmpn_hgcd_appr@@Base+0xcc>
   3461c:	add	x8, x25, x25, lsl #1
   34620:	add	x9, x8, #0x3
   34624:	cmp	x8, #0x0
   34628:	csel	x8, x9, x8, lt  // lt = tstop
   3462c:	asr	x8, x8, #2
   34630:	mov	x0, x19
   34634:	mov	x1, x22
   34638:	mov	x2, x21
   3463c:	mov	x3, x25
   34640:	mov	x4, x26
   34644:	mov	x5, x20
   34648:	add	x27, x8, #0x1
   3464c:	bl	d310 <__gmpn_hgcd_reduce@plt>
   34650:	cmp	x0, #0x0
   34654:	cset	w8, ne  // ne = any
   34658:	csel	x25, x25, x0, eq  // eq = none
   3465c:	cmp	x25, x27
   34660:	mov	w24, w8
   34664:	b.le	34794 <__gmpn_hgcd_appr@@Base+0x1cc>
   34668:	mov	x0, x25
   3466c:	mov	x1, x22
   34670:	mov	x2, x21
   34674:	mov	x3, x23
   34678:	mov	x4, x19
   3467c:	mov	x5, x20
   34680:	bl	c2c0 <__gmpn_hgcd_step@plt>
   34684:	mov	x25, x0
   34688:	mov	w8, #0x1                   	// #1
   3468c:	cbnz	x0, 3465c <__gmpn_hgcd_appr@@Base+0x94>
   34690:	b	348f8 <__gmpn_hgcd_appr@@Base+0x330>
   34694:	mov	x0, x25
   34698:	mov	x1, x22
   3469c:	mov	x2, x21
   346a0:	mov	x3, x23
   346a4:	mov	x4, x19
   346a8:	mov	x5, x20
   346ac:	bl	c2c0 <__gmpn_hgcd_step@plt>
   346b0:	mov	w26, wzr
   346b4:	cbz	x0, 34810 <__gmpn_hgcd_appr@@Base+0x248>
   346b8:	lsl	w8, w26, #1
   346bc:	add	x9, x8, x0, lsl #6
   346c0:	add	x9, x9, #0x40
   346c4:	cmp	x9, x23, lsl #7
   346c8:	b.gt	34750 <__gmpn_hgcd_appr@@Base+0x188>
   346cc:	lsl	x9, x23, #1
   346d0:	sub	x9, x9, x0
   346d4:	lsl	x9, x9, #6
   346d8:	sub	x8, x9, x8
   346dc:	add	x9, x8, #0x3f
   346e0:	cmp	x8, #0x0
   346e4:	csel	x8, x9, x8, lt  // lt = tstop
   346e8:	cbz	w26, 3470c <__gmpn_hgcd_appr@@Base+0x144>
   346ec:	sub	w26, w26, #0x1
   346f0:	mov	x9, x23
   346f4:	asr	x8, x8, #6
   346f8:	add	x22, x22, x8, lsl #3
   346fc:	add	x21, x21, x8, lsl #3
   34700:	sub	x25, x0, x8
   34704:	sub	x23, x9, x8
   34708:	b	34754 <__gmpn_hgcd_appr@@Base+0x18c>
   3470c:	add	x9, x23, #0x1
   34710:	cmp	x9, x0
   34714:	b.eq	3474c <__gmpn_hgcd_appr@@Base+0x184>  // b.none
   34718:	sub	x10, x0, #0x1
   3471c:	mov	x11, x10
   34720:	ldr	x12, [x22, x11, lsl #3]
   34724:	cbnz	x12, 34738 <__gmpn_hgcd_appr@@Base+0x170>
   34728:	sub	x11, x11, #0x1
   3472c:	cmp	x23, x11
   34730:	b.ne	34720 <__gmpn_hgcd_appr@@Base+0x158>  // b.any
   34734:	b	3474c <__gmpn_hgcd_appr@@Base+0x184>
   34738:	ldr	x11, [x21, x10, lsl #3]
   3473c:	cbnz	x11, 34780 <__gmpn_hgcd_appr@@Base+0x1b8>
   34740:	sub	x10, x10, #0x1
   34744:	cmp	x23, x10
   34748:	b.ne	34738 <__gmpn_hgcd_appr@@Base+0x170>  // b.any
   3474c:	mov	w26, wzr
   34750:	mov	x25, x0
   34754:	cmp	x25, #0x2
   34758:	b.le	34788 <__gmpn_hgcd_appr@@Base+0x1c0>
   3475c:	mov	x0, x25
   34760:	mov	x1, x22
   34764:	mov	x2, x21
   34768:	mov	x3, x23
   3476c:	mov	x4, x19
   34770:	mov	x5, x20
   34774:	bl	c2c0 <__gmpn_hgcd_step@plt>
   34778:	cbnz	x0, 346b8 <__gmpn_hgcd_appr@@Base+0xf0>
   3477c:	b	34788 <__gmpn_hgcd_appr@@Base+0x1c0>
   34780:	mov	w26, #0x3f                  	// #63
   34784:	b	346f4 <__gmpn_hgcd_appr@@Base+0x12c>
   34788:	mov	w24, #0x1                   	// #1
   3478c:	cbnz	w26, 34818 <__gmpn_hgcd_appr@@Base+0x250>
   34790:	b	34894 <__gmpn_hgcd_appr@@Base+0x2cc>
   34794:	add	x8, x26, #0x3
   34798:	cmp	x25, x8
   3479c:	b.le	348c8 <__gmpn_hgcd_appr@@Base+0x300>
   347a0:	lsl	x8, x23, #1
   347a4:	sub	x8, x8, x25
   347a8:	add	x26, x8, #0x1
   347ac:	sub	x27, x25, x26
   347b0:	add	x8, x27, #0x1
   347b4:	add	x9, x27, #0x2
   347b8:	cmp	x8, #0x0
   347bc:	csinc	x8, x9, x27, lt  // lt = tstop
   347c0:	lsl	x8, x8, #4
   347c4:	mov	x0, sp
   347c8:	mov	x1, x27
   347cc:	mov	x2, x20
   347d0:	and	x28, x8, #0xffffffffffffffe0
   347d4:	bl	c850 <__gmpn_hgcd_matrix_init@plt>
   347d8:	add	x8, x28, x20
   347dc:	add	x0, x22, x26, lsl #3
   347e0:	add	x1, x21, x26, lsl #3
   347e4:	add	x26, x8, #0x20
   347e8:	mov	x3, sp
   347ec:	mov	x2, x27
   347f0:	mov	x4, x26
   347f4:	bl	cd70 <__gmpn_hgcd_appr@plt>
   347f8:	cbz	w0, 348c8 <__gmpn_hgcd_appr@@Base+0x300>
   347fc:	mov	x1, sp
   34800:	mov	x0, x19
   34804:	mov	x2, x26
   34808:	bl	cfc0 <__gmpn_hgcd_matrix_mul@plt>
   3480c:	b	348c0 <__gmpn_hgcd_appr@@Base+0x2f8>
   34810:	mov	w24, wzr
   34814:	cbz	w26, 34894 <__gmpn_hgcd_appr@@Base+0x2cc>
   34818:	mov	w8, #0x40                  	// #64
   3481c:	sub	w26, w8, w26
   34820:	mov	x0, x22
   34824:	mov	x1, x22
   34828:	mov	x2, x25
   3482c:	mov	w3, w26
   34830:	bl	c1b0 <__gmpn_rshift@plt>
   34834:	str	x0, [x22, #-8]!
   34838:	mov	x0, x21
   3483c:	mov	x1, x21
   34840:	mov	x2, x25
   34844:	mov	w3, w26
   34848:	bl	c1b0 <__gmpn_rshift@plt>
   3484c:	str	x0, [x21, #-8]!
   34850:	ldr	x8, [x22, x25, lsl #3]
   34854:	ldr	x9, [x21, x25, lsl #3]
   34858:	orr	x8, x9, x8
   3485c:	cmp	x8, #0x0
   34860:	cinc	x25, x25, ne  // ne = any
   34864:	cmp	x25, #0x3
   34868:	b.lt	34894 <__gmpn_hgcd_appr@@Base+0x2cc>  // b.tstop
   3486c:	mov	x0, x25
   34870:	mov	x1, x22
   34874:	mov	x2, x21
   34878:	mov	x3, x23
   3487c:	mov	x4, x19
   34880:	mov	x5, x20
   34884:	bl	c2c0 <__gmpn_hgcd_step@plt>
   34888:	mov	x25, x0
   3488c:	cbnz	x0, 34864 <__gmpn_hgcd_appr@@Base+0x29c>
   34890:	b	348c0 <__gmpn_hgcd_appr@@Base+0x2f8>
   34894:	cmp	x25, #0x2
   34898:	b.ne	348f8 <__gmpn_hgcd_appr@@Base+0x330>  // b.any
   3489c:	ldp	x1, x0, [x22]
   348a0:	ldp	x3, x2, [x21]
   348a4:	mov	x4, sp
   348a8:	bl	c5c0 <__gmpn_hgcd2@plt>
   348ac:	cbz	w0, 348f8 <__gmpn_hgcd_appr@@Base+0x330>
   348b0:	mov	x1, sp
   348b4:	mov	x0, x19
   348b8:	mov	x2, x20
   348bc:	bl	c7a0 <__gmpn_hgcd_matrix_mul_1@plt>
   348c0:	mov	w24, #0x1                   	// #1
   348c4:	b	348f8 <__gmpn_hgcd_appr@@Base+0x330>
   348c8:	mov	w8, w24
   348cc:	mov	x0, x25
   348d0:	mov	x1, x22
   348d4:	mov	x2, x21
   348d8:	mov	x3, x23
   348dc:	mov	x4, x19
   348e0:	mov	x5, x20
   348e4:	mov	w24, w8
   348e8:	bl	c2c0 <__gmpn_hgcd_step@plt>
   348ec:	mov	x25, x0
   348f0:	mov	w8, #0x1                   	// #1
   348f4:	cbnz	x0, 348cc <__gmpn_hgcd_appr@@Base+0x304>
   348f8:	mov	w0, w24
   348fc:	ldp	x20, x19, [sp, #128]
   34900:	ldp	x22, x21, [sp, #112]
   34904:	ldp	x24, x23, [sp, #96]
   34908:	ldp	x26, x25, [sp, #80]
   3490c:	ldp	x28, x27, [sp, #64]
   34910:	ldp	x29, x30, [sp, #48]
   34914:	add	sp, sp, #0x90
   34918:	ret

000000000003491c <__gmpn_hgcd2_jacobi@@Base>:
   3491c:	sub	sp, sp, #0x80
   34920:	stp	x22, x21, [sp, #96]
   34924:	mov	x22, x0
   34928:	cmp	x0, #0x2
   3492c:	mov	w0, wzr
   34930:	stp	x29, x30, [sp, #32]
   34934:	stp	x28, x27, [sp, #48]
   34938:	stp	x26, x25, [sp, #64]
   3493c:	stp	x24, x23, [sp, #80]
   34940:	stp	x20, x19, [sp, #112]
   34944:	add	x29, sp, #0x20
   34948:	b.cc	34d50 <__gmpn_hgcd2_jacobi@@Base+0x434>  // b.lo, b.ul, b.last
   3494c:	mov	x21, x2
   34950:	cmp	x2, #0x2
   34954:	b.cc	34d50 <__gmpn_hgcd2_jacobi@@Base+0x434>  // b.lo, b.ul, b.last
   34958:	ldr	w8, [x5]
   3495c:	mov	x23, x3
   34960:	mov	x24, x1
   34964:	cmp	x22, x21
   34968:	b.hi	34978 <__gmpn_hgcd2_jacobi@@Base+0x5c>  // b.pmore
   3496c:	b.ne	349a0 <__gmpn_hgcd2_jacobi@@Base+0x84>  // b.any
   34970:	cmp	x24, x23
   34974:	b.ls	349a0 <__gmpn_hgcd2_jacobi@@Base+0x84>  // b.plast
   34978:	subs	x10, x24, x23
   3497c:	sbc	x22, x22, x21
   34980:	cmp	x22, #0x2
   34984:	b.cc	349b0 <__gmpn_hgcd2_jacobi@@Base+0x94>  // b.lo, b.ul, b.last
   34988:	stp	x4, x5, [sp]
   3498c:	mov	x26, xzr
   34990:	mov	w9, #0x5                   	// #5
   34994:	mov	w25, #0x1                   	// #1
   34998:	mov	x24, x10
   3499c:	b	349cc <__gmpn_hgcd2_jacobi@@Base+0xb0>
   349a0:	subs	x10, x23, x24
   349a4:	sbc	x21, x21, x22
   349a8:	cmp	x21, #0x2
   349ac:	b.cs	349b8 <__gmpn_hgcd2_jacobi@@Base+0x9c>  // b.hs, b.nlast
   349b0:	mov	w0, wzr
   349b4:	b	34d50 <__gmpn_hgcd2_jacobi@@Base+0x434>
   349b8:	mov	x25, xzr
   349bc:	mov	w9, #0x1                   	// #1
   349c0:	mov	x23, x10
   349c4:	mov	w26, #0x1                   	// #1
   349c8:	stp	x4, x5, [sp]
   349cc:	adrp	x20, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   349d0:	ldr	x20, [x20, #3872]
   349d4:	bfi	w9, w8, #3, #29
   349d8:	mov	w27, #0x1                   	// #1
   349dc:	cmp	x22, x21
   349e0:	ldrb	w19, [x20, w9, uxtw]
   349e4:	mov	w28, #0x1                   	// #1
   349e8:	b.cc	34a7c <__gmpn_hgcd2_jacobi@@Base+0x160>  // b.lo, b.ul, b.last
   349ec:	cmp	x22, x21
   349f0:	b.eq	34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>  // b.none
   349f4:	lsr	x8, x22, #32
   349f8:	cbz	x8, 34b04 <__gmpn_hgcd2_jacobi@@Base+0x1e8>
   349fc:	subs	x2, x24, x23
   34a00:	sbc	x22, x22, x21
   34a04:	cmp	x22, #0x2
   34a08:	b.cc	34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>  // b.lo, b.ul, b.last
   34a0c:	cmp	x22, x21
   34a10:	b.ls	34a58 <__gmpn_hgcd2_jacobi@@Base+0x13c>  // b.plast
   34a14:	add	x0, sp, #0x10
   34a18:	mov	x1, x22
   34a1c:	mov	x3, x21
   34a20:	mov	x4, x23
   34a24:	bl	34d70 <__gmpn_hgcd2_jacobi@@Base+0x454>
   34a28:	ldr	x22, [sp, #24]
   34a2c:	cmp	x22, #0x2
   34a30:	b.cc	34b1c <__gmpn_hgcd2_jacobi@@Base+0x200>  // b.lo, b.ul, b.last
   34a34:	add	x8, x0, #0x1
   34a38:	and	w9, w8, #0x3
   34a3c:	bfi	w9, w19, #3, #8
   34a40:	orr	x9, x9, #0x4
   34a44:	ldr	x2, [sp, #16]
   34a48:	ldrb	w19, [x20, x9]
   34a4c:	mul	x9, x8, x26
   34a50:	mul	x8, x8, x27
   34a54:	b	34a70 <__gmpn_hgcd2_jacobi@@Base+0x154>
   34a58:	lsl	w8, w19, #3
   34a5c:	mov	w9, #0x5                   	// #5
   34a60:	orr	x8, x8, x9
   34a64:	ldrb	w19, [x20, x8]
   34a68:	mov	x8, x27
   34a6c:	mov	x9, x26
   34a70:	add	x28, x9, x28
   34a74:	add	x25, x8, x25
   34a78:	mov	x24, x2
   34a7c:	cmp	x22, x21
   34a80:	b.eq	34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>  // b.none
   34a84:	lsr	x8, x21, #32
   34a88:	cbz	x8, 34b10 <__gmpn_hgcd2_jacobi@@Base+0x1f4>
   34a8c:	mov	x8, x23
   34a90:	subs	x23, x8, x24
   34a94:	sbc	x21, x21, x22
   34a98:	cmp	x21, #0x2
   34a9c:	b.cc	34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>  // b.lo, b.ul, b.last
   34aa0:	cmp	x21, x22
   34aa4:	b.ls	34aec <__gmpn_hgcd2_jacobi@@Base+0x1d0>  // b.plast
   34aa8:	add	x0, sp, #0x10
   34aac:	mov	x1, x21
   34ab0:	mov	x2, x23
   34ab4:	mov	x3, x22
   34ab8:	mov	x4, x24
   34abc:	bl	34d70 <__gmpn_hgcd2_jacobi@@Base+0x454>
   34ac0:	ldr	x21, [sp, #24]
   34ac4:	cmp	x21, #0x2
   34ac8:	b.cc	34b38 <__gmpn_hgcd2_jacobi@@Base+0x21c>  // b.lo, b.ul, b.last
   34acc:	add	x8, x0, #0x1
   34ad0:	and	w9, w8, #0x3
   34ad4:	bfi	w9, w19, #3, #29
   34ad8:	ldr	x23, [sp, #16]
   34adc:	ldrb	w19, [x20, w9, uxtw]
   34ae0:	madd	x26, x8, x28, x26
   34ae4:	madd	x27, x8, x25, x27
   34ae8:	b	349ec <__gmpn_hgcd2_jacobi@@Base+0xd0>
   34aec:	lsl	w8, w19, #3
   34af0:	orr	x8, x8, #0x1
   34af4:	ldrb	w19, [x20, x8]
   34af8:	add	x27, x25, x27
   34afc:	add	x26, x28, x26
   34b00:	b	349ec <__gmpn_hgcd2_jacobi@@Base+0xd0>
   34b04:	extr	x8, x22, x24, #32
   34b08:	extr	x9, x21, x23, #32
   34b0c:	b	34b50 <__gmpn_hgcd2_jacobi@@Base+0x234>
   34b10:	extr	x8, x22, x24, #32
   34b14:	extr	x9, x21, x23, #32
   34b18:	b	34c30 <__gmpn_hgcd2_jacobi@@Base+0x314>
   34b1c:	and	w8, w0, #0x3
   34b20:	bfi	w8, w19, #3, #8
   34b24:	orr	x8, x8, #0x4
   34b28:	ldrb	w19, [x20, x8]
   34b2c:	madd	x28, x0, x26, x28
   34b30:	madd	x25, x0, x27, x25
   34b34:	b	34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>
   34b38:	and	w8, w0, #0x3
   34b3c:	bfi	w8, w19, #3, #29
   34b40:	ldrb	w19, [x20, w8, uxtw]
   34b44:	madd	x26, x0, x28, x26
   34b48:	madd	x27, x0, x25, x27
   34b4c:	b	34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>
   34b50:	subs	x8, x8, x9
   34b54:	b.eq	34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>  // b.none
   34b58:	lsr	x10, x8, #33
   34b5c:	cbz	x10, 34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>
   34b60:	cmp	x8, x9
   34b64:	b.ls	34bb0 <__gmpn_hgcd2_jacobi@@Base+0x294>  // b.plast
   34b68:	tbnz	x8, #63, 34bc4 <__gmpn_hgcd2_jacobi@@Base+0x2a8>
   34b6c:	mov	w11, wzr
   34b70:	mov	x12, x9
   34b74:	lsl	x12, x12, #1
   34b78:	cmp	x12, x8
   34b7c:	sub	w11, w11, #0x1
   34b80:	b.ls	34b74 <__gmpn_hgcd2_jacobi@@Base+0x258>  // b.plast
   34b84:	mov	x13, xzr
   34b88:	cmp	x8, x12, lsr #1
   34b8c:	lsr	x12, x12, #1
   34b90:	cset	w10, cs  // cs = hs, nlast
   34b94:	csel	x14, xzr, x12, cc  // cc = lo, ul, last
   34b98:	bfi	x10, x13, #1, #63
   34b9c:	adds	w11, w11, #0x1
   34ba0:	sub	x8, x8, x14
   34ba4:	mov	x13, x10
   34ba8:	b.cc	34b88 <__gmpn_hgcd2_jacobi@@Base+0x26c>  // b.lo, b.ul, b.last
   34bac:	b	34c04 <__gmpn_hgcd2_jacobi@@Base+0x2e8>
   34bb0:	mov	w10, #0x5                   	// #5
   34bb4:	bfi	w10, w19, #3, #8
   34bb8:	mov	x11, x27
   34bbc:	mov	x12, x26
   34bc0:	b	34c24 <__gmpn_hgcd2_jacobi@@Base+0x308>
   34bc4:	mov	w11, #0x1                   	// #1
   34bc8:	mov	x12, x9
   34bcc:	tbnz	x9, #63, 34bdc <__gmpn_hgcd2_jacobi@@Base+0x2c0>
   34bd0:	lsl	x12, x12, #1
   34bd4:	add	w11, w11, #0x1
   34bd8:	tbz	x12, #63, 34bd0 <__gmpn_hgcd2_jacobi@@Base+0x2b4>
   34bdc:	mov	x13, xzr
   34be0:	cmp	x8, x12
   34be4:	cset	w10, cs  // cs = hs, nlast
   34be8:	csel	x14, xzr, x12, cc  // cc = lo, ul, last
   34bec:	bfi	x10, x13, #1, #63
   34bf0:	sub	x8, x8, x14
   34bf4:	subs	w11, w11, #0x1
   34bf8:	lsr	x12, x12, #1
   34bfc:	mov	x13, x10
   34c00:	b.ne	34be0 <__gmpn_hgcd2_jacobi@@Base+0x2c4>  // b.any
   34c04:	lsr	x11, x8, #33
   34c08:	cbz	x11, 34d0c <__gmpn_hgcd2_jacobi@@Base+0x3f0>
   34c0c:	add	x11, x10, #0x1
   34c10:	and	w10, w11, #0x3
   34c14:	bfi	w10, w19, #3, #8
   34c18:	mul	x12, x11, x26
   34c1c:	orr	w10, w10, #0x4
   34c20:	mul	x11, x11, x27
   34c24:	ldrb	w19, [x20, w10, uxtw]
   34c28:	add	x28, x12, x28
   34c2c:	add	x25, x11, x25
   34c30:	subs	x9, x9, x8
   34c34:	b.eq	34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>  // b.none
   34c38:	lsr	x10, x9, #33
   34c3c:	cbz	x10, 34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>
   34c40:	cmp	x9, x8
   34c44:	b.ls	34c90 <__gmpn_hgcd2_jacobi@@Base+0x374>  // b.plast
   34c48:	tbnz	x9, #63, 34ca8 <__gmpn_hgcd2_jacobi@@Base+0x38c>
   34c4c:	mov	w10, wzr
   34c50:	mov	x12, x8
   34c54:	lsl	x12, x12, #1
   34c58:	cmp	x12, x9
   34c5c:	sub	w10, w10, #0x1
   34c60:	b.ls	34c54 <__gmpn_hgcd2_jacobi@@Base+0x338>  // b.plast
   34c64:	mov	x13, xzr
   34c68:	cmp	x9, x12, lsr #1
   34c6c:	lsr	x12, x12, #1
   34c70:	cset	w11, cs  // cs = hs, nlast
   34c74:	csel	x14, xzr, x12, cc  // cc = lo, ul, last
   34c78:	bfi	x11, x13, #1, #63
   34c7c:	adds	w10, w10, #0x1
   34c80:	sub	x9, x9, x14
   34c84:	mov	x13, x11
   34c88:	b.cc	34c68 <__gmpn_hgcd2_jacobi@@Base+0x34c>  // b.lo, b.ul, b.last
   34c8c:	b	34ce8 <__gmpn_hgcd2_jacobi@@Base+0x3cc>
   34c90:	lsl	w10, w19, #3
   34c94:	orr	x10, x10, #0x1
   34c98:	ldrb	w19, [x20, x10]
   34c9c:	add	x27, x25, x27
   34ca0:	add	x26, x28, x26
   34ca4:	b	34b50 <__gmpn_hgcd2_jacobi@@Base+0x234>
   34ca8:	mov	w10, #0x1                   	// #1
   34cac:	mov	x12, x8
   34cb0:	tbnz	x8, #63, 34cc0 <__gmpn_hgcd2_jacobi@@Base+0x3a4>
   34cb4:	lsl	x12, x12, #1
   34cb8:	add	w10, w10, #0x1
   34cbc:	tbz	x12, #63, 34cb4 <__gmpn_hgcd2_jacobi@@Base+0x398>
   34cc0:	mov	x13, xzr
   34cc4:	cmp	x9, x12
   34cc8:	cset	w11, cs  // cs = hs, nlast
   34ccc:	csel	x14, xzr, x12, cc  // cc = lo, ul, last
   34cd0:	bfi	x11, x13, #1, #63
   34cd4:	sub	x9, x9, x14
   34cd8:	subs	w10, w10, #0x1
   34cdc:	lsr	x12, x12, #1
   34ce0:	mov	x13, x11
   34ce4:	b.ne	34cc4 <__gmpn_hgcd2_jacobi@@Base+0x3a8>  // b.any
   34ce8:	lsr	x10, x9, #33
   34cec:	cbz	x10, 34d28 <__gmpn_hgcd2_jacobi@@Base+0x40c>
   34cf0:	add	x10, x11, #0x1
   34cf4:	and	w11, w10, #0x3
   34cf8:	bfi	w11, w19, #3, #29
   34cfc:	ldrb	w19, [x20, w11, uxtw]
   34d00:	madd	x26, x10, x28, x26
   34d04:	madd	x27, x10, x25, x27
   34d08:	b	34b50 <__gmpn_hgcd2_jacobi@@Base+0x234>
   34d0c:	and	w8, w10, #0x3
   34d10:	bfi	w8, w19, #3, #8
   34d14:	orr	x8, x8, #0x4
   34d18:	ldrb	w19, [x20, x8]
   34d1c:	madd	x28, x10, x26, x28
   34d20:	madd	x25, x10, x27, x25
   34d24:	b	34d3c <__gmpn_hgcd2_jacobi@@Base+0x420>
   34d28:	and	w8, w11, #0x3
   34d2c:	bfi	w8, w19, #3, #29
   34d30:	ldrb	w19, [x20, w8, uxtw]
   34d34:	madd	x26, x11, x28, x26
   34d38:	madd	x27, x11, x25, x27
   34d3c:	ldp	x9, x8, [sp]
   34d40:	mov	w0, #0x1                   	// #1
   34d44:	stp	x27, x25, [x9]
   34d48:	stp	x26, x28, [x9, #16]
   34d4c:	str	w19, [x8]
   34d50:	ldp	x20, x19, [sp, #112]
   34d54:	ldp	x22, x21, [sp, #96]
   34d58:	ldp	x24, x23, [sp, #80]
   34d5c:	ldp	x26, x25, [sp, #64]
   34d60:	ldp	x28, x27, [sp, #48]
   34d64:	ldp	x29, x30, [sp, #32]
   34d68:	add	sp, sp, #0x80
   34d6c:	ret
   34d70:	tbnz	x1, #63, 34de4 <__gmpn_hgcd2_jacobi@@Base+0x4c8>
   34d74:	mov	w9, wzr
   34d78:	cmp	x3, x1
   34d7c:	b.cc	34d8c <__gmpn_hgcd2_jacobi@@Base+0x470>  // b.lo, b.ul, b.last
   34d80:	b.ne	34d9c <__gmpn_hgcd2_jacobi@@Base+0x480>  // b.any
   34d84:	cmp	x4, x2
   34d88:	b.hi	34d9c <__gmpn_hgcd2_jacobi@@Base+0x480>  // b.pmore
   34d8c:	extr	x3, x3, x4, #63
   34d90:	lsl	x4, x4, #1
   34d94:	sub	w9, w9, #0x1
   34d98:	b	34d78 <__gmpn_hgcd2_jacobi@@Base+0x45c>
   34d9c:	mov	x8, xzr
   34da0:	cbz	w9, 34e38 <__gmpn_hgcd2_jacobi@@Base+0x51c>
   34da4:	extr	x4, x3, x4, #1
   34da8:	cmp	x1, x3, lsr #1
   34dac:	lsr	x3, x3, #1
   34db0:	lsl	x8, x8, #1
   34db4:	b.hi	34dc8 <__gmpn_hgcd2_jacobi@@Base+0x4ac>  // b.pmore
   34db8:	cmp	x1, x3
   34dbc:	b.ne	34dd8 <__gmpn_hgcd2_jacobi@@Base+0x4bc>  // b.any
   34dc0:	cmp	x2, x4
   34dc4:	b.cc	34dd8 <__gmpn_hgcd2_jacobi@@Base+0x4bc>  // b.lo, b.ul, b.last
   34dc8:	subs	x10, x2, x4
   34dcc:	sbc	x1, x1, x3
   34dd0:	orr	x8, x8, #0x1
   34dd4:	mov	x2, x10
   34dd8:	adds	w9, w9, #0x1
   34ddc:	b.cc	34da4 <__gmpn_hgcd2_jacobi@@Base+0x488>  // b.lo, b.ul, b.last
   34de0:	b	34e38 <__gmpn_hgcd2_jacobi@@Base+0x51c>
   34de4:	mov	w9, #0x1                   	// #1
   34de8:	tbnz	x3, #63, 34dfc <__gmpn_hgcd2_jacobi@@Base+0x4e0>
   34dec:	extr	x3, x3, x4, #63
   34df0:	lsl	x4, x4, #1
   34df4:	add	w9, w9, #0x1
   34df8:	tbz	x3, #63, 34dec <__gmpn_hgcd2_jacobi@@Base+0x4d0>
   34dfc:	mov	x8, xzr
   34e00:	cmp	x1, x3
   34e04:	lsl	x8, x8, #1
   34e08:	b.hi	34e18 <__gmpn_hgcd2_jacobi@@Base+0x4fc>  // b.pmore
   34e0c:	b.ne	34e28 <__gmpn_hgcd2_jacobi@@Base+0x50c>  // b.any
   34e10:	cmp	x2, x4
   34e14:	b.cc	34e28 <__gmpn_hgcd2_jacobi@@Base+0x50c>  // b.lo, b.ul, b.last
   34e18:	subs	x10, x2, x4
   34e1c:	sbc	x1, x1, x3
   34e20:	orr	x8, x8, #0x1
   34e24:	mov	x2, x10
   34e28:	extr	x4, x3, x4, #1
   34e2c:	subs	w9, w9, #0x1
   34e30:	lsr	x3, x3, #1
   34e34:	b.ne	34e00 <__gmpn_hgcd2_jacobi@@Base+0x4e4>  // b.any
   34e38:	stp	x2, x1, [x0]
   34e3c:	mov	x0, x8
   34e40:	ret

0000000000034e44 <__gmpn_hgcd_jacobi@@Base>:
   34e44:	sub	sp, sp, #0xa0
   34e48:	cmp	x2, #0x0
   34e4c:	cinc	x8, x2, lt  // lt = tstop
   34e50:	stp	x26, x25, [sp, #96]
   34e54:	asr	x26, x8, #1
   34e58:	stp	x24, x23, [sp, #112]
   34e5c:	add	x23, x26, #0x1
   34e60:	cmp	x23, x2
   34e64:	stp	x29, x30, [sp, #64]
   34e68:	stp	x28, x27, [sp, #80]
   34e6c:	stp	x22, x21, [sp, #128]
   34e70:	stp	x20, x19, [sp, #144]
   34e74:	add	x29, sp, #0x40
   34e78:	b.ge	34efc <__gmpn_hgcd_jacobi@@Base+0xb8>  // b.tcont
   34e7c:	mov	x19, x5
   34e80:	mov	x20, x4
   34e84:	mov	x21, x3
   34e88:	mov	x25, x2
   34e8c:	mov	x22, x1
   34e90:	mov	x24, x0
   34e94:	cmp	x2, #0x64
   34e98:	b.le	34f04 <__gmpn_hgcd_jacobi@@Base+0xc0>
   34e9c:	add	x8, x25, x25, lsl #1
   34ea0:	add	x9, x8, #0x3
   34ea4:	cmp	x8, #0x0
   34ea8:	add	x0, x24, x26, lsl #3
   34eac:	add	x1, x22, x26, lsl #3
   34eb0:	csel	x8, x9, x8, lt  // lt = tstop
   34eb4:	sub	x2, x25, x26
   34eb8:	mov	x3, x21
   34ebc:	mov	x4, x20
   34ec0:	mov	x5, x19
   34ec4:	asr	x27, x8, #2
   34ec8:	bl	d3b0 <__gmpn_hgcd_jacobi@plt>
   34ecc:	cmp	x0, #0x1
   34ed0:	b.lt	34f48 <__gmpn_hgcd_jacobi@@Base+0x104>  // b.tstop
   34ed4:	add	x1, x0, x26
   34ed8:	mov	x0, x21
   34edc:	mov	x2, x24
   34ee0:	mov	x3, x22
   34ee4:	mov	x4, x26
   34ee8:	mov	x5, x19
   34eec:	bl	c8c0 <__gmpn_hgcd_matrix_adjust@plt>
   34ef0:	mov	x25, x0
   34ef4:	mov	w8, #0x1                   	// #1
   34ef8:	b	34f4c <__gmpn_hgcd_jacobi@@Base+0x108>
   34efc:	mov	x0, xzr
   34f00:	b	34f94 <__gmpn_hgcd_jacobi@@Base+0x150>
   34f04:	mov	w27, wzr
   34f08:	mov	x0, x25
   34f0c:	mov	x1, x24
   34f10:	mov	x2, x22
   34f14:	mov	x3, x23
   34f18:	mov	x4, x21
   34f1c:	mov	x5, x20
   34f20:	mov	x6, x19
   34f24:	mov	x26, x25
   34f28:	mov	w28, w27
   34f2c:	bl	35068 <__gmpn_hgcd_jacobi@@Base+0x224>
   34f30:	mov	x25, x0
   34f34:	mov	w27, #0x1                   	// #1
   34f38:	cbnz	x0, 34f08 <__gmpn_hgcd_jacobi@@Base+0xc4>
   34f3c:	cmp	w28, #0x0
   34f40:	csel	x0, xzr, x26, eq  // eq = none
   34f44:	b	34f94 <__gmpn_hgcd_jacobi@@Base+0x150>
   34f48:	mov	w8, wzr
   34f4c:	add	x28, x27, #0x1
   34f50:	mov	x0, x25
   34f54:	mov	x25, x0
   34f58:	cmp	x0, x28
   34f5c:	mov	w27, w8
   34f60:	b.le	34fb4 <__gmpn_hgcd_jacobi@@Base+0x170>
   34f64:	mov	x0, x25
   34f68:	mov	x1, x24
   34f6c:	mov	x2, x22
   34f70:	mov	x3, x23
   34f74:	mov	x4, x21
   34f78:	mov	x5, x20
   34f7c:	mov	x6, x19
   34f80:	bl	35068 <__gmpn_hgcd_jacobi@@Base+0x224>
   34f84:	mov	w8, #0x1                   	// #1
   34f88:	cbnz	x0, 34f54 <__gmpn_hgcd_jacobi@@Base+0x110>
   34f8c:	cmp	w27, #0x0
   34f90:	csel	x0, xzr, x25, eq  // eq = none
   34f94:	ldp	x20, x19, [sp, #144]
   34f98:	ldp	x22, x21, [sp, #128]
   34f9c:	ldp	x24, x23, [sp, #112]
   34fa0:	ldp	x26, x25, [sp, #96]
   34fa4:	ldp	x28, x27, [sp, #80]
   34fa8:	ldp	x29, x30, [sp, #64]
   34fac:	add	sp, sp, #0xa0
   34fb0:	ret
   34fb4:	add	x8, x26, #0x3
   34fb8:	cmp	x25, x8
   34fbc:	b.le	34f08 <__gmpn_hgcd_jacobi@@Base+0xc4>
   34fc0:	lsl	x8, x23, #1
   34fc4:	sub	x8, x8, x25
   34fc8:	add	x26, x8, #0x1
   34fcc:	sub	x28, x25, x26
   34fd0:	add	x8, x28, #0x1
   34fd4:	add	x9, x28, #0x2
   34fd8:	cmp	x8, #0x0
   34fdc:	csinc	x8, x9, x28, lt  // lt = tstop
   34fe0:	lsl	x8, x8, #4
   34fe4:	and	x8, x8, #0xffffffffffffffe0
   34fe8:	add	x0, sp, #0x10
   34fec:	mov	x1, x28
   34ff0:	mov	x2, x19
   34ff4:	str	x8, [sp, #8]
   34ff8:	bl	c850 <__gmpn_hgcd_matrix_init@plt>
   34ffc:	ldr	x8, [sp, #8]
   35000:	add	x0, x24, x26, lsl #3
   35004:	add	x1, x22, x26, lsl #3
   35008:	add	x3, sp, #0x10
   3500c:	add	x8, x8, x19
   35010:	add	x8, x8, #0x20
   35014:	mov	x2, x28
   35018:	mov	x4, x20
   3501c:	mov	x5, x8
   35020:	mov	x28, x8
   35024:	bl	d3b0 <__gmpn_hgcd_jacobi@plt>
   35028:	cmp	x0, #0x1
   3502c:	b.lt	34f08 <__gmpn_hgcd_jacobi@@Base+0xc4>  // b.tstop
   35030:	add	x1, x0, x26
   35034:	add	x0, sp, #0x10
   35038:	mov	x2, x24
   3503c:	mov	x3, x22
   35040:	mov	x4, x26
   35044:	mov	x5, x28
   35048:	bl	c8c0 <__gmpn_hgcd_matrix_adjust@plt>
   3504c:	mov	x25, x0
   35050:	add	x1, sp, #0x10
   35054:	mov	x0, x21
   35058:	mov	x2, x28
   3505c:	bl	cfc0 <__gmpn_hgcd_matrix_mul@plt>
   35060:	mov	w27, #0x1                   	// #1
   35064:	b	34f08 <__gmpn_hgcd_jacobi@@Base+0xc4>
   35068:	sub	sp, sp, #0x80
   3506c:	lsl	x8, x0, #3
   35070:	stp	x29, x30, [sp, #48]
   35074:	stp	x24, x23, [sp, #80]
   35078:	stp	x22, x21, [sp, #96]
   3507c:	stp	x20, x19, [sp, #112]
   35080:	sub	x9, x8, #0x8
   35084:	mov	x20, x2
   35088:	mov	x21, x0
   3508c:	ldr	x0, [x1, x9]
   35090:	ldr	x2, [x2, x9]
   35094:	add	x9, x3, #0x1
   35098:	str	x25, [sp, #64]
   3509c:	mov	x19, x6
   350a0:	mov	x25, x5
   350a4:	mov	x23, x4
   350a8:	mov	x22, x1
   350ac:	mov	x24, x3
   350b0:	cmp	x9, x21
   350b4:	orr	x9, x2, x0
   350b8:	add	x29, sp, #0x30
   350bc:	b.ne	350cc <__gmpn_hgcd_jacobi@@Base+0x288>  // b.any
   350c0:	cmp	x9, #0x4
   350c4:	b.cs	35124 <__gmpn_hgcd_jacobi@@Base+0x2e0>  // b.hs, b.nlast
   350c8:	b	3517c <__gmpn_hgcd_jacobi@@Base+0x338>
   350cc:	tbnz	x9, #63, 35124 <__gmpn_hgcd_jacobi@@Base+0x2e0>
   350d0:	sub	x10, x8, #0x10
   350d4:	sub	x8, x8, #0x18
   350d8:	ldr	x12, [x22, x10]
   350dc:	ldr	x14, [x22, x8]
   350e0:	ldr	x10, [x20, x10]
   350e4:	ldr	x8, [x20, x8]
   350e8:	clz	x9, x9
   350ec:	neg	x13, x9
   350f0:	lsl	x11, x0, x9
   350f4:	lsl	x15, x2, x9
   350f8:	lsr	x16, x12, x13
   350fc:	lsl	x12, x12, x9
   35100:	lsr	x14, x14, x13
   35104:	lsl	x9, x10, x9
   35108:	lsr	x10, x10, x13
   3510c:	lsr	x8, x8, x13
   35110:	orr	x0, x16, x11
   35114:	orr	x1, x14, x12
   35118:	orr	x2, x10, x15
   3511c:	orr	x3, x8, x9
   35120:	b	35130 <__gmpn_hgcd_jacobi@@Base+0x2ec>
   35124:	sub	x8, x8, #0x10
   35128:	ldr	x1, [x22, x8]
   3512c:	ldr	x3, [x20, x8]
   35130:	add	x4, sp, #0x10
   35134:	mov	x5, x25
   35138:	bl	cb10 <__gmpn_hgcd2_jacobi@plt>
   3513c:	cbz	w0, 3517c <__gmpn_hgcd_jacobi@@Base+0x338>
   35140:	add	x1, sp, #0x10
   35144:	mov	x0, x23
   35148:	mov	x2, x19
   3514c:	bl	c7a0 <__gmpn_hgcd_matrix_mul_1@plt>
   35150:	mov	x0, x19
   35154:	mov	x1, x22
   35158:	mov	x2, x21
   3515c:	bl	ca70 <__gmpn_copyi@plt>
   35160:	add	x0, sp, #0x10
   35164:	mov	x1, x22
   35168:	mov	x2, x19
   3516c:	mov	x3, x20
   35170:	mov	x4, x21
   35174:	bl	c510 <__gmpn_matrix22_mul1_inverse_vector@plt>
   35178:	b	351a4 <__gmpn_hgcd_jacobi@@Base+0x360>
   3517c:	adrp	x4, 35000 <__gmpn_hgcd_jacobi@@Base+0x1bc>
   35180:	add	x4, x4, #0x1c0
   35184:	mov	x5, sp
   35188:	mov	x0, x22
   3518c:	mov	x1, x20
   35190:	mov	x2, x21
   35194:	mov	x3, x24
   35198:	mov	x6, x19
   3519c:	stp	x23, x25, [sp]
   351a0:	bl	d2d0 <__gmpn_gcd_subdiv_step@plt>
   351a4:	ldp	x20, x19, [sp, #112]
   351a8:	ldp	x22, x21, [sp, #96]
   351ac:	ldp	x24, x23, [sp, #80]
   351b0:	ldr	x25, [sp, #64]
   351b4:	ldp	x29, x30, [sp, #48]
   351b8:	add	sp, sp, #0x80
   351bc:	ret
   351c0:	stp	x29, x30, [sp, #-48]!
   351c4:	add	x9, x3, x4, lsl #3
   351c8:	str	x21, [sp, #16]
   351cc:	stp	x20, x19, [sp, #32]
   351d0:	mov	w19, w5
   351d4:	mov	x8, x4
   351d8:	mov	x20, x3
   351dc:	mov	x21, x0
   351e0:	add	x4, x9, #0x8
   351e4:	mov	x29, sp
   351e8:	subs	x8, x8, #0x1
   351ec:	b.lt	35238 <__gmpn_hgcd_jacobi@@Base+0x3f4>  // b.tstop
   351f0:	ldur	x9, [x4, #-16]
   351f4:	sub	x4, x4, #0x8
   351f8:	cbz	x9, 351e8 <__gmpn_hgcd_jacobi@@Base+0x3a4>
   351fc:	ldr	x0, [x21]
   35200:	add	x2, x8, #0x1
   35204:	mov	x1, x20
   35208:	mov	w3, w19
   3520c:	bl	d040 <__gmpn_hgcd_matrix_update_q@plt>
   35210:	ldr	x8, [x21, #8]
   35214:	ldr	w10, [x20]
   35218:	ldr	w9, [x8]
   3521c:	lsl	w9, w9, #3
   35220:	add	w9, w9, w19, lsl #2
   35224:	bfxil	w9, w10, #0, #2
   35228:	adrp	x10, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   3522c:	ldr	x10, [x10, #3872]
   35230:	ldrb	w9, [x10, w9, uxtw]
   35234:	str	w9, [x8]
   35238:	ldp	x20, x19, [sp, #32]
   3523c:	ldr	x21, [sp, #16]
   35240:	ldp	x29, x30, [sp], #48
   35244:	ret

0000000000035248 <__gmpn_mullo_n@@Base>:
   35248:	stp	x29, x30, [sp, #-64]!
   3524c:	stp	x22, x21, [sp, #32]
   35250:	stp	x20, x19, [sp, #48]
   35254:	mov	x19, x3
   35258:	mov	x20, x2
   3525c:	mov	x22, x1
   35260:	cmp	x3, #0x25
   35264:	mov	x21, x0
   35268:	str	x23, [sp, #16]
   3526c:	mov	x29, sp
   35270:	b.le	352d4 <__gmpn_mullo_n@@Base+0x8c>
   35274:	lsl	x1, x19, #4
   35278:	mov	w8, #0x7f00                	// #32512
   3527c:	cmp	x1, x8
   35280:	str	xzr, [x29, #24]
   35284:	b.hi	35334 <__gmpn_mullo_n@@Base+0xec>  // b.pmore
   35288:	add	x9, x1, #0xf
   3528c:	mov	x8, sp
   35290:	and	x9, x9, #0xfffffffffffffff0
   35294:	sub	x23, x8, x9
   35298:	mov	sp, x23
   3529c:	mov	w8, #0x186c                	// #6252
   352a0:	cmp	x19, x8
   352a4:	b.le	352fc <__gmpn_mullo_n@@Base+0xb4>
   352a8:	mov	x0, x23
   352ac:	mov	x1, x22
   352b0:	mov	x2, x19
   352b4:	mov	x3, x20
   352b8:	mov	x4, x19
   352bc:	bl	ccc0 <__gmpn_nussbaumer_mul@plt>
   352c0:	mov	x0, x21
   352c4:	mov	x1, x23
   352c8:	mov	x2, x19
   352cc:	bl	ca70 <__gmpn_copyi@plt>
   352d0:	b	35314 <__gmpn_mullo_n@@Base+0xcc>
   352d4:	mov	x0, x21
   352d8:	mov	x1, x22
   352dc:	mov	x2, x20
   352e0:	mov	x3, x19
   352e4:	mov	sp, x29
   352e8:	ldp	x20, x19, [sp, #48]
   352ec:	ldp	x22, x21, [sp, #32]
   352f0:	ldr	x23, [sp, #16]
   352f4:	ldp	x29, x30, [sp], #64
   352f8:	b	d2b0 <__gmpn_mullo_basecase@plt>
   352fc:	mov	x0, x21
   35300:	mov	x1, x22
   35304:	mov	x2, x20
   35308:	mov	x3, x19
   3530c:	mov	x4, x23
   35310:	bl	3534c <__gmpn_mullo_n@@Base+0x104>
   35314:	ldr	x0, [x29, #24]
   35318:	cbnz	x0, 35344 <__gmpn_mullo_n@@Base+0xfc>
   3531c:	mov	sp, x29
   35320:	ldp	x20, x19, [sp, #48]
   35324:	ldp	x22, x21, [sp, #32]
   35328:	ldr	x23, [sp, #16]
   3532c:	ldp	x29, x30, [sp], #64
   35330:	ret
   35334:	add	x0, x29, #0x18
   35338:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   3533c:	mov	x23, x0
   35340:	b	3529c <__gmpn_mullo_n@@Base+0x54>
   35344:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   35348:	b	3531c <__gmpn_mullo_n@@Base+0xd4>
   3534c:	stp	x29, x30, [sp, #-80]!
   35350:	stp	x24, x23, [sp, #32]
   35354:	stp	x22, x21, [sp, #48]
   35358:	stp	x20, x19, [sp, #64]
   3535c:	mov	x21, x4
   35360:	mov	x24, x3
   35364:	mov	x20, x2
   35368:	mov	x19, x1
   3536c:	cmp	x3, #0x45
   35370:	mov	x23, x0
   35374:	str	x25, [sp, #16]
   35378:	mov	x29, sp
   3537c:	b.le	353a4 <__gmpn_mullo_n@@Base+0x15c>
   35380:	cmp	x24, #0x68
   35384:	b.le	353c8 <__gmpn_mullo_n@@Base+0x180>
   35388:	cmp	x24, #0x105
   3538c:	b.le	353e4 <__gmpn_mullo_n@@Base+0x19c>
   35390:	mov	x8, #0xcccccccccccccccc    	// #-3689348814741910324
   35394:	movk	x8, #0xcccd
   35398:	umulh	x8, x24, x8
   3539c:	lsr	x22, x8, #3
   353a0:	b	3540c <__gmpn_mullo_n@@Base+0x1c4>
   353a4:	mov	x9, #0xe38f                	// #58255
   353a8:	movk	x9, #0x8e38, lsl #16
   353ac:	mov	w8, #0xb                   	// #11
   353b0:	movk	x9, #0x38e3, lsl #32
   353b4:	mul	x8, x24, x8
   353b8:	movk	x9, #0xe38e, lsl #48
   353bc:	umulh	x8, x8, x9
   353c0:	lsr	x22, x8, #5
   353c4:	b	3540c <__gmpn_mullo_n@@Base+0x1c4>
   353c8:	add	w8, w24, w24, lsl #3
   353cc:	mov	w9, #0xcccd                	// #52429
   353d0:	and	w8, w8, #0xffff
   353d4:	movk	w9, #0xcccc, lsl #16
   353d8:	umull	x8, w8, w9
   353dc:	lsr	x22, x8, #37
   353e0:	b	3540c <__gmpn_mullo_n@@Base+0x1c4>
   353e4:	lsl	w8, w24, #3
   353e8:	sub	w8, w8, w24
   353ec:	mov	w9, #0x41a5                	// #16805
   353f0:	and	w8, w8, #0xffff
   353f4:	movk	w9, #0xa41a, lsl #16
   353f8:	umull	x9, w8, w9
   353fc:	lsr	x9, x9, #32
   35400:	sub	w8, w8, w9
   35404:	add	w8, w9, w8, lsr #1
   35408:	lsr	w22, w8, #5
   3540c:	sub	x25, x24, x22
   35410:	mov	x0, x21
   35414:	mov	x1, x19
   35418:	mov	x2, x20
   3541c:	mov	x3, x25
   35420:	bl	c9b0 <__gmpn_mul_n@plt>
   35424:	mov	x0, x23
   35428:	mov	x1, x21
   3542c:	mov	x2, x25
   35430:	bl	ca70 <__gmpn_copyi@plt>
   35434:	add	x24, x21, x24, lsl #3
   35438:	cmp	x22, #0x25
   3543c:	add	x1, x19, x25, lsl #3
   35440:	mov	x0, x24
   35444:	mov	x2, x20
   35448:	mov	x3, x22
   3544c:	b.ls	3545c <__gmpn_mullo_n@@Base+0x214>  // b.plast
   35450:	mov	x4, x24
   35454:	bl	3534c <__gmpn_mullo_n@@Base+0x104>
   35458:	b	35460 <__gmpn_mullo_n@@Base+0x218>
   3545c:	bl	d2b0 <__gmpn_mullo_basecase@plt>
   35460:	add	x23, x23, x25, lsl #3
   35464:	add	x1, x21, x25, lsl #3
   35468:	mov	x0, x23
   3546c:	mov	x2, x24
   35470:	mov	x3, x22
   35474:	bl	ca90 <__gmpn_add_n@plt>
   35478:	cmp	x22, #0x25
   3547c:	add	x2, x20, x25, lsl #3
   35480:	mov	x0, x24
   35484:	mov	x1, x19
   35488:	mov	x3, x22
   3548c:	b.ls	3549c <__gmpn_mullo_n@@Base+0x254>  // b.plast
   35490:	mov	x4, x24
   35494:	bl	3534c <__gmpn_mullo_n@@Base+0x104>
   35498:	b	354a0 <__gmpn_mullo_n@@Base+0x258>
   3549c:	bl	d2b0 <__gmpn_mullo_basecase@plt>
   354a0:	mov	x0, x23
   354a4:	mov	x1, x23
   354a8:	mov	x2, x24
   354ac:	mov	x3, x22
   354b0:	ldp	x20, x19, [sp, #64]
   354b4:	ldp	x22, x21, [sp, #48]
   354b8:	ldp	x24, x23, [sp, #32]
   354bc:	ldr	x25, [sp, #16]
   354c0:	ldp	x29, x30, [sp], #80
   354c4:	b	ca90 <__gmpn_add_n@plt>

00000000000354c8 <__gmpn_mullo_basecase@@Base>:
   354c8:	stp	x29, x30, [sp, #-80]!
   354cc:	stp	x24, x23, [sp, #32]
   354d0:	stp	x22, x21, [sp, #48]
   354d4:	stp	x20, x19, [sp, #64]
   354d8:	mov	x22, x2
   354dc:	subs	x2, x3, #0x1
   354e0:	ldr	x8, [x1]
   354e4:	ldr	x9, [x22, x2, lsl #3]
   354e8:	mov	x19, x0
   354ec:	str	x25, [sp, #16]
   354f0:	mov	x29, sp
   354f4:	mul	x24, x9, x8
   354f8:	b.eq	35564 <__gmpn_mullo_basecase@@Base+0x9c>  // b.none
   354fc:	ldr	x23, [x22]
   35500:	ldr	x25, [x1, x2, lsl #3]
   35504:	mov	x21, x3
   35508:	mov	x0, x19
   3550c:	mov	x3, x23
   35510:	mov	x20, x1
   35514:	bl	d4b0 <__gmpn_mul_1@plt>
   35518:	add	x8, x0, x24
   3551c:	cmp	x21, #0x3
   35520:	madd	x24, x25, x23, x8
   35524:	add	x19, x19, #0x8
   35528:	b.lt	35564 <__gmpn_mullo_basecase@@Base+0x9c>  // b.tstop
   3552c:	sub	x21, x21, #0x2
   35530:	add	x23, x22, #0x8
   35534:	ldr	x22, [x23], #8
   35538:	ldr	x25, [x20, x21, lsl #3]
   3553c:	mov	x0, x19
   35540:	mov	x1, x20
   35544:	mov	x2, x21
   35548:	mov	x3, x22
   3554c:	bl	d420 <__gmpn_addmul_1@plt>
   35550:	add	x8, x0, x24
   35554:	subs	x21, x21, #0x1
   35558:	madd	x24, x25, x22, x8
   3555c:	add	x19, x19, #0x8
   35560:	b.gt	35534 <__gmpn_mullo_basecase@@Base+0x6c>
   35564:	str	x24, [x19]
   35568:	ldp	x20, x19, [sp, #64]
   3556c:	ldp	x22, x21, [sp, #48]
   35570:	ldp	x24, x23, [sp, #32]
   35574:	ldr	x25, [sp, #16]
   35578:	ldp	x29, x30, [sp], #80
   3557c:	ret

0000000000035580 <__gmpn_sqrlo@@Base>:
   35580:	stp	x29, x30, [sp, #-80]!
   35584:	stp	x22, x21, [sp, #48]
   35588:	stp	x20, x19, [sp, #64]
   3558c:	mov	x21, x2
   35590:	mov	x20, x1
   35594:	cmp	x2, #0x3
   35598:	mov	x19, x0
   3559c:	str	x25, [sp, #16]
   355a0:	stp	x24, x23, [sp, #32]
   355a4:	mov	x29, sp
   355a8:	b.le	35614 <__gmpn_sqrlo@@Base+0x94>
   355ac:	cmp	x21, #0x42
   355b0:	b.le	35640 <__gmpn_sqrlo@@Base+0xc0>
   355b4:	lsl	x1, x21, #4
   355b8:	mov	w8, #0x7f00                	// #32512
   355bc:	cmp	x1, x8
   355c0:	str	xzr, [x29, #24]
   355c4:	b.hi	35780 <__gmpn_sqrlo@@Base+0x200>  // b.pmore
   355c8:	add	x9, x1, #0xf
   355cc:	mov	x8, sp
   355d0:	and	x9, x9, #0xfffffffffffffff0
   355d4:	sub	x22, x8, x9
   355d8:	mov	sp, x22
   355dc:	mov	w8, #0x1477                	// #5239
   355e0:	cmp	x21, x8
   355e4:	b.le	35668 <__gmpn_sqrlo@@Base+0xe8>
   355e8:	mov	x0, x22
   355ec:	mov	x1, x20
   355f0:	mov	x2, x21
   355f4:	mov	x3, x20
   355f8:	mov	x4, x21
   355fc:	bl	ccc0 <__gmpn_nussbaumer_mul@plt>
   35600:	mov	x0, x19
   35604:	mov	x1, x22
   35608:	mov	x2, x21
   3560c:	bl	ca70 <__gmpn_copyi@plt>
   35610:	b	3575c <__gmpn_sqrlo@@Base+0x1dc>
   35614:	mov	x0, x19
   35618:	mov	x1, x20
   3561c:	mov	x2, x20
   35620:	mov	x3, x21
   35624:	mov	sp, x29
   35628:	ldp	x20, x19, [sp, #64]
   3562c:	ldp	x22, x21, [sp, #48]
   35630:	ldp	x24, x23, [sp, #32]
   35634:	ldr	x25, [sp, #16]
   35638:	ldp	x29, x30, [sp], #80
   3563c:	b	d2b0 <__gmpn_mullo_basecase@plt>
   35640:	mov	x0, x19
   35644:	mov	x1, x20
   35648:	mov	x2, x21
   3564c:	mov	sp, x29
   35650:	ldp	x20, x19, [sp, #64]
   35654:	ldp	x22, x21, [sp, #48]
   35658:	ldp	x24, x23, [sp, #32]
   3565c:	ldr	x25, [sp, #16]
   35660:	ldp	x29, x30, [sp], #80
   35664:	b	c0c0 <__gmpn_sqrlo_basecase@plt>
   35668:	cmp	x21, #0x5f
   3566c:	b.le	35690 <__gmpn_sqrlo@@Base+0x110>
   35670:	cmp	x21, #0xd5
   35674:	b.le	356b0 <__gmpn_sqrlo@@Base+0x130>
   35678:	cmp	x21, #0x171
   3567c:	b.le	356cc <__gmpn_sqrlo@@Base+0x14c>
   35680:	mov	w9, #0xcccd                	// #52429
   35684:	and	w8, w21, #0xffff
   35688:	movk	w9, #0xcccc, lsl #16
   3568c:	b	356a4 <__gmpn_sqrlo@@Base+0x124>
   35690:	mov	w8, #0xb                   	// #11
   35694:	mul	w8, w21, w8
   35698:	mov	w9, #0x8e39                	// #36409
   3569c:	and	w8, w8, #0xffff
   356a0:	movk	w9, #0x38e3, lsl #16
   356a4:	umull	x8, w8, w9
   356a8:	lsr	x8, x8, #35
   356ac:	b	356f4 <__gmpn_sqrlo@@Base+0x174>
   356b0:	add	w8, w21, w21, lsl #3
   356b4:	mov	w9, #0xcccd                	// #52429
   356b8:	and	w8, w8, #0xffff
   356bc:	movk	w9, #0xcccc, lsl #16
   356c0:	umull	x8, w8, w9
   356c4:	lsr	x8, x8, #37
   356c8:	b	356f4 <__gmpn_sqrlo@@Base+0x174>
   356cc:	lsl	w8, w21, #3
   356d0:	sub	w8, w8, w21
   356d4:	mov	w9, #0x41a5                	// #16805
   356d8:	and	w8, w8, #0xffff
   356dc:	movk	w9, #0xa41a, lsl #16
   356e0:	umull	x9, w8, w9
   356e4:	lsr	x9, x9, #32
   356e8:	sub	w8, w8, w9
   356ec:	add	w8, w9, w8, lsr #1
   356f0:	lsr	w8, w8, #5
   356f4:	sub	x24, x21, w8, uxth
   356f8:	mov	x0, x22
   356fc:	mov	x1, x20
   35700:	mov	x2, x24
   35704:	and	x23, x8, #0xffff
   35708:	and	w25, w8, #0xffff
   3570c:	bl	c900 <__gmpn_sqr@plt>
   35710:	mov	x0, x19
   35714:	mov	x1, x22
   35718:	mov	x2, x24
   3571c:	bl	ca70 <__gmpn_copyi@plt>
   35720:	add	x21, x22, x21, lsl #3
   35724:	cmp	w25, #0x25
   35728:	add	x1, x20, x24, lsl #3
   3572c:	mov	x0, x21
   35730:	mov	x2, x20
   35734:	mov	x3, x23
   35738:	b.ls	35744 <__gmpn_sqrlo@@Base+0x1c4>  // b.plast
   3573c:	bl	cee0 <__gmpn_mullo_n@plt>
   35740:	b	35748 <__gmpn_sqrlo@@Base+0x1c8>
   35744:	bl	d2b0 <__gmpn_mullo_basecase@plt>
   35748:	add	x0, x19, x24, lsl #3
   3574c:	add	x1, x22, x24, lsl #3
   35750:	mov	x2, x21
   35754:	mov	x3, x23
   35758:	bl	cc60 <__gmpn_addlsh1_n@plt>
   3575c:	ldr	x0, [x29, #24]
   35760:	cbnz	x0, 35790 <__gmpn_sqrlo@@Base+0x210>
   35764:	mov	sp, x29
   35768:	ldp	x20, x19, [sp, #64]
   3576c:	ldp	x22, x21, [sp, #48]
   35770:	ldp	x24, x23, [sp, #32]
   35774:	ldr	x25, [sp, #16]
   35778:	ldp	x29, x30, [sp], #80
   3577c:	ret
   35780:	add	x0, x29, #0x18
   35784:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   35788:	mov	x22, x0
   3578c:	b	355dc <__gmpn_sqrlo@@Base+0x5c>
   35790:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   35794:	b	35764 <__gmpn_sqrlo@@Base+0x1e4>

0000000000035798 <__gmpn_sqrlo_basecase@@Base>:
   35798:	stp	x29, x30, [sp, #-96]!
   3579c:	stp	x28, x27, [sp, #16]
   357a0:	stp	x26, x25, [sp, #32]
   357a4:	stp	x24, x23, [sp, #48]
   357a8:	stp	x22, x21, [sp, #64]
   357ac:	stp	x20, x19, [sp, #80]
   357b0:	mov	x29, sp
   357b4:	sub	sp, sp, #0x240
   357b8:	ldr	x24, [x1]
   357bc:	sub	x19, x2, #0x1
   357c0:	ldr	x20, [x1, x19, lsl #3]
   357c4:	sub	x25, x2, #0x2
   357c8:	mov	x27, x2
   357cc:	mov	x23, x1
   357d0:	mov	x21, x0
   357d4:	add	x1, x1, #0x8
   357d8:	add	x0, sp, #0x28
   357dc:	mov	x2, x25
   357e0:	mov	x3, x24
   357e4:	add	x22, sp, #0x28
   357e8:	bl	d4b0 <__gmpn_mul_1@plt>
   357ec:	cmp	x27, #0x5
   357f0:	madd	x28, x20, x24, x0
   357f4:	b.lt	35888 <__gmpn_sqrlo_basecase@@Base+0xf0>  // b.tstop
   357f8:	add	x8, x23, x27, lsl #3
   357fc:	stp	x25, x27, [sp, #8]
   35800:	stp	x23, x21, [sp, #24]
   35804:	mov	x20, xzr
   35808:	add	x24, x22, #0x10
   3580c:	sub	x25, x27, #0x4
   35810:	add	x26, x23, #0x10
   35814:	sub	x23, x8, #0x10
   35818:	mov	w22, #0x3                   	// #3
   3581c:	ldur	x27, [x26, #-8]
   35820:	mov	x21, x19
   35824:	ldr	x19, [x23, x20, lsl #3]
   35828:	mov	x0, x24
   3582c:	mov	x1, x26
   35830:	mov	x2, x25
   35834:	mov	x3, x27
   35838:	bl	d420 <__gmpn_addmul_1@plt>
   3583c:	add	x8, x0, x28
   35840:	add	x22, x22, #0x2
   35844:	add	x24, x24, #0x10
   35848:	sub	x25, x25, #0x2
   3584c:	add	x26, x26, #0x8
   35850:	madd	x28, x19, x27, x8
   35854:	mov	x19, x21
   35858:	cmp	x22, x21
   3585c:	sub	x20, x20, #0x1
   35860:	b.lt	3581c <__gmpn_sqrlo_basecase@@Base+0x84>  // b.tstop
   35864:	ldp	x23, x21, [sp, #24]
   35868:	ldp	x25, x27, [sp, #8]
   3586c:	mov	w8, #0x1                   	// #1
   35870:	sub	x8, x8, x20
   35874:	tbz	w19, #0, 35890 <__gmpn_sqrlo_basecase@@Base+0xf8>
   35878:	add	x8, x23, x8, lsl #3
   3587c:	ldp	x9, x8, [x8]
   35880:	mul	x8, x8, x9
   35884:	b	35894 <__gmpn_sqrlo_basecase@@Base+0xfc>
   35888:	mov	w8, #0x1                   	// #1
   3588c:	tbnz	w19, #0, 35878 <__gmpn_sqrlo_basecase@@Base+0xe0>
   35890:	mov	x8, xzr
   35894:	add	x8, x8, x28
   35898:	add	x9, sp, #0x28
   3589c:	cmp	x27, #0x2
   358a0:	str	x8, [x9, x25, lsl #3]
   358a4:	asr	x8, x27, #1
   358a8:	b.lt	358d4 <__gmpn_sqrlo_basecase@@Base+0x13c>  // b.tstop
   358ac:	mov	x9, xzr
   358b0:	add	x10, x21, #0x8
   358b4:	ldr	x11, [x23, x9, lsl #3]
   358b8:	add	x9, x9, #0x1
   358bc:	umulh	x12, x11, x11
   358c0:	cmp	x9, x8
   358c4:	mul	x11, x11, x11
   358c8:	stp	x11, x12, [x10, #-8]
   358cc:	add	x10, x10, #0x10
   358d0:	b.lt	358b4 <__gmpn_sqrlo_basecase@@Base+0x11c>  // b.tstop
   358d4:	tbz	w27, #0, 358e4 <__gmpn_sqrlo_basecase@@Base+0x14c>
   358d8:	ldr	x8, [x23, x8, lsl #3]
   358dc:	mul	x8, x8, x8
   358e0:	str	x8, [x21, x19, lsl #3]
   358e4:	add	x0, x21, #0x8
   358e8:	add	x2, sp, #0x28
   358ec:	mov	x1, x0
   358f0:	mov	x3, x19
   358f4:	bl	cc60 <__gmpn_addlsh1_n@plt>
   358f8:	add	sp, sp, #0x240
   358fc:	ldp	x20, x19, [sp, #80]
   35900:	ldp	x22, x21, [sp, #64]
   35904:	ldp	x24, x23, [sp, #48]
   35908:	ldp	x26, x25, [sp, #32]
   3590c:	ldp	x28, x27, [sp, #16]
   35910:	ldp	x29, x30, [sp], #96
   35914:	ret

0000000000035918 <__gmpn_toom22_mul@@Base>:
   35918:	sub	sp, sp, #0x80
   3591c:	stp	x22, x21, [sp, #96]
   35920:	asr	x21, x2, #1
   35924:	sub	x22, x2, x2, asr #1
   35928:	stp	x29, x30, [sp, #32]
   3592c:	stp	x28, x27, [sp, #48]
   35930:	stp	x26, x25, [sp, #64]
   35934:	stp	x24, x23, [sp, #80]
   35938:	stp	x20, x19, [sp, #112]
   3593c:	add	x29, sp, #0x20
   35940:	mov	x28, x4
   35944:	mov	x26, x3
   35948:	mov	x19, x2
   3594c:	mov	x27, x1
   35950:	mov	x20, x0
   35954:	sub	x25, x4, x22
   35958:	add	x24, x0, x22, lsl #3
   3595c:	subs	x12, x21, x22
   35960:	add	x2, x1, x21, lsl #3
   35964:	stur	x5, [x29, #-8]
   35968:	str	x12, [sp, #8]
   3596c:	b.ne	359bc <__gmpn_toom22_mul@@Base+0xa4>  // b.any
   35970:	lsl	x8, x21, #4
   35974:	sub	x8, x8, #0x8
   35978:	mov	x10, x21
   3597c:	subs	x9, x10, #0x1
   35980:	b.lt	359a4 <__gmpn_toom22_mul@@Base+0x8c>  // b.tstop
   35984:	add	x10, x27, x10, lsl #3
   35988:	ldur	x10, [x10, #-8]
   3598c:	ldr	x11, [x27, x8]
   35990:	sub	x8, x8, #0x8
   35994:	cmp	x10, x11
   35998:	mov	x10, x9
   3599c:	b.eq	3597c <__gmpn_toom22_mul@@Base+0x64>  // b.none
   359a0:	b.ls	35a38 <__gmpn_toom22_mul@@Base+0x120>  // b.plast
   359a4:	mov	x0, x20
   359a8:	mov	x1, x27
   359ac:	mov	x3, x21
   359b0:	bl	c2e0 <__gmpn_sub_n@plt>
   359b4:	stur	wzr, [x29, #-12]
   359b8:	b	35a54 <__gmpn_toom22_mul@@Base+0x13c>
   359bc:	ldr	x23, [x2]
   359c0:	cbz	x23, 359e8 <__gmpn_toom22_mul@@Base+0xd0>
   359c4:	add	x2, x27, x22, lsl #3
   359c8:	mov	x0, x20
   359cc:	mov	x1, x27
   359d0:	mov	x3, x21
   359d4:	bl	c2e0 <__gmpn_sub_n@plt>
   359d8:	sub	x8, x23, x0
   359dc:	stur	wzr, [x29, #-12]
   359e0:	str	x8, [x20, x21, lsl #3]
   359e4:	b	35a54 <__gmpn_toom22_mul@@Base+0x13c>
   359e8:	lsl	x8, x19, #3
   359ec:	add	x1, x27, x22, lsl #3
   359f0:	sub	x8, x8, #0x8
   359f4:	mov	x10, x21
   359f8:	subs	x9, x10, #0x1
   359fc:	b.lt	359c4 <__gmpn_toom22_mul@@Base+0xac>  // b.tstop
   35a00:	add	x10, x27, x10, lsl #3
   35a04:	ldur	x10, [x10, #-8]
   35a08:	ldr	x11, [x27, x8]
   35a0c:	sub	x8, x8, #0x8
   35a10:	cmp	x10, x11
   35a14:	mov	x10, x9
   35a18:	b.eq	359f8 <__gmpn_toom22_mul@@Base+0xe0>  // b.none
   35a1c:	b.hi	359c4 <__gmpn_toom22_mul@@Base+0xac>  // b.pmore
   35a20:	mov	x0, x20
   35a24:	mov	x2, x27
   35a28:	mov	x3, x21
   35a2c:	bl	c2e0 <__gmpn_sub_n@plt>
   35a30:	str	xzr, [x20, x21, lsl #3]
   35a34:	b	35a4c <__gmpn_toom22_mul@@Base+0x134>
   35a38:	mov	x0, x20
   35a3c:	mov	x1, x2
   35a40:	mov	x2, x27
   35a44:	mov	x3, x21
   35a48:	bl	c2e0 <__gmpn_sub_n@plt>
   35a4c:	mov	w8, #0x1                   	// #1
   35a50:	stur	w8, [x29, #-12]
   35a54:	subs	x23, x22, x25
   35a58:	b.ne	35aac <__gmpn_toom22_mul@@Base+0x194>  // b.any
   35a5c:	ldur	x23, [x29, #-8]
   35a60:	lsl	x9, x19, #4
   35a64:	add	x2, x26, x22, lsl #3
   35a68:	sub	x8, x26, #0x8
   35a6c:	sub	x9, x9, x21, lsl #4
   35a70:	mov	x10, x22
   35a74:	subs	x11, x10, #0x1
   35a78:	b.lt	35a98 <__gmpn_toom22_mul@@Base+0x180>  // b.tstop
   35a7c:	ldr	x10, [x8, x10, lsl #3]
   35a80:	ldr	x12, [x8, x9]
   35a84:	sub	x9, x9, #0x8
   35a88:	cmp	x10, x12
   35a8c:	mov	x10, x11
   35a90:	b.eq	35a74 <__gmpn_toom22_mul@@Base+0x15c>  // b.none
   35a94:	b.ls	35b9c <__gmpn_toom22_mul@@Base+0x284>  // b.plast
   35a98:	mov	x0, x24
   35a9c:	mov	x1, x26
   35aa0:	mov	x3, x22
   35aa4:	bl	c2e0 <__gmpn_sub_n@plt>
   35aa8:	b	35bfc <__gmpn_toom22_mul@@Base+0x2e4>
   35aac:	lsl	x9, x19, #3
   35ab0:	add	x8, x28, x21, lsl #1
   35ab4:	sub	x9, x9, x21, lsl #3
   35ab8:	sub	x8, x8, x19, lsl #1
   35abc:	sub	x9, x9, #0x8
   35ac0:	ldr	x10, [x26, x9]
   35ac4:	cbnz	x10, 35b0c <__gmpn_toom22_mul@@Base+0x1f4>
   35ac8:	adds	x8, x8, #0x1
   35acc:	sub	x9, x9, #0x8
   35ad0:	b.cc	35ac0 <__gmpn_toom22_mul@@Base+0x1a8>  // b.lo, b.ul, b.last
   35ad4:	lsl	x8, x28, #3
   35ad8:	add	x1, x26, x22, lsl #3
   35adc:	sub	x8, x8, #0x8
   35ae0:	mov	x10, x25
   35ae4:	subs	x9, x10, #0x1
   35ae8:	b.lt	35b0c <__gmpn_toom22_mul@@Base+0x1f4>  // b.tstop
   35aec:	add	x10, x26, x10, lsl #3
   35af0:	ldur	x10, [x10, #-8]
   35af4:	ldr	x11, [x26, x8]
   35af8:	sub	x8, x8, #0x8
   35afc:	cmp	x10, x11
   35b00:	mov	x10, x9
   35b04:	b.eq	35ae4 <__gmpn_toom22_mul@@Base+0x1cc>  // b.none
   35b08:	b.ls	35bb8 <__gmpn_toom22_mul@@Base+0x2a0>  // b.plast
   35b0c:	cbz	x25, 35b58 <__gmpn_toom22_mul@@Base+0x240>
   35b10:	add	x2, x26, x22, lsl #3
   35b14:	mov	x0, x24
   35b18:	mov	x1, x26
   35b1c:	mov	x3, x25
   35b20:	bl	c2e0 <__gmpn_sub_n@plt>
   35b24:	ldur	x23, [x29, #-8]
   35b28:	mov	x8, x25
   35b2c:	cbz	x0, 35b60 <__gmpn_toom22_mul@@Base+0x248>
   35b30:	add	x9, x20, x28, lsl #3
   35b34:	mov	x8, x25
   35b38:	cmp	x8, x22
   35b3c:	b.ge	35bfc <__gmpn_toom22_mul@@Base+0x2e4>  // b.tcont
   35b40:	ldr	x10, [x26, x8, lsl #3]
   35b44:	add	x8, x8, #0x1
   35b48:	sub	x11, x10, #0x1
   35b4c:	str	x11, [x9], #8
   35b50:	cbz	x10, 35b38 <__gmpn_toom22_mul@@Base+0x220>
   35b54:	b	35b60 <__gmpn_toom22_mul@@Base+0x248>
   35b58:	ldur	x23, [x29, #-8]
   35b5c:	mov	x8, xzr
   35b60:	cmp	x24, x26
   35b64:	b.eq	35bfc <__gmpn_toom22_mul@@Base+0x2e4>  // b.none
   35b68:	cmp	x8, x22
   35b6c:	b.ge	35bfc <__gmpn_toom22_mul@@Base+0x2e4>  // b.tcont
   35b70:	add	x10, x8, x19
   35b74:	add	x9, x8, x21
   35b78:	sub	x10, x10, x21
   35b7c:	sub	x9, x9, x19
   35b80:	add	x10, x20, x10, lsl #3
   35b84:	add	x8, x26, x8, lsl #3
   35b88:	ldr	x11, [x8], #8
   35b8c:	adds	x9, x9, #0x1
   35b90:	str	x11, [x10], #8
   35b94:	b.cc	35b88 <__gmpn_toom22_mul@@Base+0x270>  // b.lo, b.ul, b.last
   35b98:	b	35bfc <__gmpn_toom22_mul@@Base+0x2e4>
   35b9c:	mov	x0, x24
   35ba0:	mov	x1, x2
   35ba4:	mov	x2, x26
   35ba8:	mov	x3, x22
   35bac:	bl	c2e0 <__gmpn_sub_n@plt>
   35bb0:	ldur	w8, [x29, #-12]
   35bb4:	b	35bf4 <__gmpn_toom22_mul@@Base+0x2dc>
   35bb8:	mov	x0, x24
   35bbc:	mov	x2, x26
   35bc0:	mov	x3, x25
   35bc4:	bl	c2e0 <__gmpn_sub_n@plt>
   35bc8:	cbz	x23, 35bec <__gmpn_toom22_mul@@Base+0x2d4>
   35bcc:	lsl	x8, x19, #1
   35bd0:	sub	x8, x8, x28
   35bd4:	and	x9, x19, #0x1ffffffffffffffe
   35bd8:	sub	x8, x8, x9
   35bdc:	add	x0, x20, x28, lsl #3
   35be0:	lsl	x2, x8, #3
   35be4:	mov	w1, wzr
   35be8:	bl	c610 <memset@plt>
   35bec:	ldur	w8, [x29, #-12]
   35bf0:	ldur	x23, [x29, #-8]
   35bf4:	eor	w8, w8, #0x1
   35bf8:	stur	w8, [x29, #-12]
   35bfc:	cmp	x22, #0xd
   35c00:	b.le	35c24 <__gmpn_toom22_mul@@Base+0x30c>
   35c04:	add	x5, x23, x22, lsl #4
   35c08:	mov	x0, x23
   35c0c:	mov	x1, x20
   35c10:	mov	x2, x22
   35c14:	mov	x3, x24
   35c18:	mov	x4, x22
   35c1c:	bl	d470 <__gmpn_toom22_mul@plt>
   35c20:	b	35c3c <__gmpn_toom22_mul@@Base+0x324>
   35c24:	mov	x0, x23
   35c28:	mov	x1, x20
   35c2c:	mov	x2, x22
   35c30:	mov	x3, x24
   35c34:	mov	x4, x22
   35c38:	bl	c570 <__gmpn_mul_basecase@plt>
   35c3c:	cmp	x21, x25
   35c40:	lsl	x28, x22, #1
   35c44:	b.le	35c7c <__gmpn_toom22_mul@@Base+0x364>
   35c48:	cmp	x25, #0xd
   35c4c:	b.le	35ca4 <__gmpn_toom22_mul@@Base+0x38c>
   35c50:	add	x8, x25, x25, lsl #2
   35c54:	add	x0, x20, x22, lsl #4
   35c58:	add	x1, x27, x22, lsl #3
   35c5c:	add	x3, x26, x22, lsl #3
   35c60:	cmp	x8, x21, lsl #2
   35c64:	add	x5, x23, x22, lsl #4
   35c68:	mov	x2, x21
   35c6c:	mov	x4, x25
   35c70:	b.gt	35c9c <__gmpn_toom22_mul@@Base+0x384>
   35c74:	bl	c870 <__gmpn_toom32_mul@plt>
   35c78:	b	35cc8 <__gmpn_toom22_mul@@Base+0x3b0>
   35c7c:	add	x0, x20, x22, lsl #4
   35c80:	add	x1, x27, x22, lsl #3
   35c84:	cmp	x19, #0x1b
   35c88:	add	x3, x26, x22, lsl #3
   35c8c:	b.le	35cbc <__gmpn_toom22_mul@@Base+0x3a4>
   35c90:	add	x5, x23, x28, lsl #3
   35c94:	mov	x2, x21
   35c98:	mov	x4, x21
   35c9c:	bl	d470 <__gmpn_toom22_mul@plt>
   35ca0:	b	35cc8 <__gmpn_toom22_mul@@Base+0x3b0>
   35ca4:	add	x0, x20, x22, lsl #4
   35ca8:	add	x1, x27, x22, lsl #3
   35cac:	add	x3, x26, x22, lsl #3
   35cb0:	mov	x2, x21
   35cb4:	mov	x4, x25
   35cb8:	b	35cc4 <__gmpn_toom22_mul@@Base+0x3ac>
   35cbc:	mov	x2, x21
   35cc0:	mov	x4, x21
   35cc4:	bl	c570 <__gmpn_mul_basecase@plt>
   35cc8:	cmp	x22, #0xd
   35ccc:	b.le	35cf0 <__gmpn_toom22_mul@@Base+0x3d8>
   35cd0:	add	x5, x23, x22, lsl #4
   35cd4:	mov	x0, x20
   35cd8:	mov	x1, x27
   35cdc:	mov	x2, x22
   35ce0:	mov	x3, x26
   35ce4:	mov	x4, x22
   35ce8:	bl	d470 <__gmpn_toom22_mul@plt>
   35cec:	b	35d08 <__gmpn_toom22_mul@@Base+0x3f0>
   35cf0:	mov	x0, x20
   35cf4:	mov	x1, x27
   35cf8:	mov	x2, x22
   35cfc:	mov	x3, x26
   35d00:	mov	x4, x22
   35d04:	bl	c570 <__gmpn_mul_basecase@plt>
   35d08:	add	x26, x20, x28, lsl #3
   35d0c:	mov	x0, x26
   35d10:	mov	x1, x24
   35d14:	mov	x2, x26
   35d18:	mov	x3, x22
   35d1c:	bl	ca90 <__gmpn_add_n@plt>
   35d20:	mov	x27, x0
   35d24:	mov	x0, x24
   35d28:	mov	x1, x26
   35d2c:	mov	x2, x20
   35d30:	mov	x3, x22
   35d34:	bl	ca90 <__gmpn_add_n@plt>
   35d38:	ldr	x8, [sp, #8]
   35d3c:	adds	x23, x8, x25
   35d40:	mov	x25, x0
   35d44:	b.eq	35d84 <__gmpn_toom22_mul@@Base+0x46c>  // b.none
   35d48:	add	x2, x26, x22, lsl #3
   35d4c:	mov	x0, x26
   35d50:	mov	x1, x26
   35d54:	mov	x3, x23
   35d58:	bl	ca90 <__gmpn_add_n@plt>
   35d5c:	cbz	x0, 35d84 <__gmpn_toom22_mul@@Base+0x46c>
   35d60:	mov	w8, #0x1                   	// #1
   35d64:	cmp	x23, x22
   35d68:	b.ge	35d88 <__gmpn_toom22_mul@@Base+0x470>  // b.tcont
   35d6c:	ldr	x9, [x26, x23, lsl #3]
   35d70:	add	x10, x23, #0x1
   35d74:	adds	x9, x9, #0x1
   35d78:	str	x9, [x26, x23, lsl #3]
   35d7c:	mov	x23, x10
   35d80:	b.cs	35d64 <__gmpn_toom22_mul@@Base+0x44c>  // b.hs, b.nlast
   35d84:	mov	x8, xzr
   35d88:	add	x23, x8, x27
   35d8c:	ldur	w8, [x29, #-12]
   35d90:	cbz	w8, 35db0 <__gmpn_toom22_mul@@Base+0x498>
   35d94:	ldur	x2, [x29, #-8]
   35d98:	mov	x0, x24
   35d9c:	mov	x1, x24
   35da0:	mov	x3, x28
   35da4:	bl	ca90 <__gmpn_add_n@plt>
   35da8:	add	x8, x0, x23
   35dac:	b	35dd0 <__gmpn_toom22_mul@@Base+0x4b8>
   35db0:	ldur	x2, [x29, #-8]
   35db4:	mov	x0, x24
   35db8:	mov	x1, x24
   35dbc:	mov	x3, x28
   35dc0:	bl	c2e0 <__gmpn_sub_n@plt>
   35dc4:	sub	x8, x23, x0
   35dc8:	cmn	x8, #0x1
   35dcc:	b.eq	35e58 <__gmpn_toom22_mul@@Base+0x540>  // b.none
   35dd0:	ldr	x9, [x26]
   35dd4:	add	x10, x25, x27
   35dd8:	adds	x9, x9, x10
   35ddc:	str	x9, [x26]
   35de0:	b.cc	35dfc <__gmpn_toom22_mul@@Base+0x4e4>  // b.lo, b.ul, b.last
   35de4:	add	x9, x20, x28, lsl #3
   35de8:	add	x9, x9, #0x8
   35dec:	ldr	x10, [x9]
   35df0:	adds	x10, x10, #0x1
   35df4:	str	x10, [x9], #8
   35df8:	b.cs	35dec <__gmpn_toom22_mul@@Base+0x4d4>  // b.hs, b.nlast
   35dfc:	mov	w9, #0x18                  	// #24
   35e00:	mul	x9, x22, x9
   35e04:	ldr	x10, [x20, x9]
   35e08:	adds	x8, x10, x8
   35e0c:	str	x8, [x20, x9]
   35e10:	b.cc	35e38 <__gmpn_toom22_mul@@Base+0x520>  // b.lo, b.ul, b.last
   35e14:	add	x8, x19, x19, lsl #1
   35e18:	add	x9, x21, x21, lsl #1
   35e1c:	sub	x8, x8, x9
   35e20:	add	x8, x20, x8, lsl #3
   35e24:	add	x8, x8, #0x8
   35e28:	ldr	x9, [x8]
   35e2c:	adds	x9, x9, #0x1
   35e30:	str	x9, [x8], #8
   35e34:	b.cs	35e28 <__gmpn_toom22_mul@@Base+0x510>  // b.hs, b.nlast
   35e38:	ldp	x20, x19, [sp, #112]
   35e3c:	ldp	x22, x21, [sp, #96]
   35e40:	ldp	x24, x23, [sp, #80]
   35e44:	ldp	x26, x25, [sp, #64]
   35e48:	ldp	x28, x27, [sp, #48]
   35e4c:	ldp	x29, x30, [sp, #32]
   35e50:	add	sp, sp, #0x80
   35e54:	ret
   35e58:	sub	x8, x19, x21
   35e5c:	lsl	x2, x8, #3
   35e60:	mov	x0, x26
   35e64:	mov	w1, wzr
   35e68:	bl	c610 <memset@plt>
   35e6c:	b	35e38 <__gmpn_toom22_mul@@Base+0x520>

0000000000035e70 <__gmpn_toom32_mul@@Base>:
   35e70:	sub	sp, sp, #0xc0
   35e74:	add	x8, x4, x4, lsl #1
   35e78:	stp	x28, x27, [sp, #112]
   35e7c:	stp	x26, x25, [sp, #128]
   35e80:	stp	x22, x21, [sp, #160]
   35e84:	stp	x20, x19, [sp, #176]
   35e88:	mov	x25, x5
   35e8c:	mov	x27, x4
   35e90:	mov	x26, x3
   35e94:	mov	x21, x2
   35e98:	mov	x28, x1
   35e9c:	cmp	x8, x2, lsl #1
   35ea0:	mov	x19, x0
   35ea4:	stp	x29, x30, [sp, #96]
   35ea8:	stp	x24, x23, [sp, #144]
   35eac:	add	x29, sp, #0x60
   35eb0:	b.le	35ec0 <__gmpn_toom32_mul@@Base+0x50>
   35eb4:	sub	x8, x27, #0x1
   35eb8:	asr	x24, x8, #1
   35ebc:	b	35ed4 <__gmpn_toom32_mul@@Base+0x64>
   35ec0:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   35ec4:	sub	x8, x21, #0x1
   35ec8:	movk	x9, #0xaaab
   35ecc:	umulh	x8, x8, x9
   35ed0:	lsr	x24, x8, #1
   35ed4:	add	x22, x24, #0x1
   35ed8:	lsl	x23, x22, #1
   35edc:	sub	x3, x21, x22, lsl #1
   35ee0:	sub	x8, x27, x22
   35ee4:	add	x2, x28, x22, lsl #4
   35ee8:	stp	x8, x23, [x29, #-16]
   35eec:	stur	x3, [x29, #-32]
   35ef0:	str	x21, [sp, #8]
   35ef4:	str	x2, [sp, #32]
   35ef8:	cbz	x3, 35f3c <__gmpn_toom32_mul@@Base+0xcc>
   35efc:	mov	x0, x19
   35f00:	mov	x1, x28
   35f04:	bl	ca90 <__gmpn_add_n@plt>
   35f08:	ldur	x9, [x29, #-32]
   35f0c:	mov	x8, x9
   35f10:	cbz	x0, 35f40 <__gmpn_toom32_mul@@Base+0xd0>
   35f14:	mov	w20, #0x1                   	// #1
   35f18:	cmp	x9, x24
   35f1c:	b.gt	35fa8 <__gmpn_toom32_mul@@Base+0x138>
   35f20:	ldr	x8, [x28, x9, lsl #3]
   35f24:	adds	x10, x8, #0x1
   35f28:	add	x8, x9, #0x1
   35f2c:	str	x10, [x19, x9, lsl #3]
   35f30:	mov	x9, x8
   35f34:	b.cs	35f18 <__gmpn_toom32_mul@@Base+0xa8>  // b.hs, b.nlast
   35f38:	b	35f40 <__gmpn_toom32_mul@@Base+0xd0>
   35f3c:	mov	x8, xzr
   35f40:	cmp	x19, x28
   35f44:	b.eq	35f70 <__gmpn_toom32_mul@@Base+0x100>  // b.none
   35f48:	cmp	x8, x24
   35f4c:	b.gt	35f70 <__gmpn_toom32_mul@@Base+0x100>
   35f50:	sub	x10, x24, x8
   35f54:	add	x9, x19, x8, lsl #3
   35f58:	add	x10, x10, #0x1
   35f5c:	add	x8, x28, x8, lsl #3
   35f60:	ldr	x11, [x8], #8
   35f64:	subs	x10, x10, #0x1
   35f68:	str	x11, [x9], #8
   35f6c:	b.ne	35f60 <__gmpn_toom32_mul@@Base+0xf0>  // b.any
   35f70:	add	x8, x28, x24, lsl #4
   35f74:	add	x1, x28, x22, lsl #3
   35f78:	add	x8, x8, #0x8
   35f7c:	mov	x9, x24
   35f80:	add	x10, x9, #0x1
   35f84:	cmp	x10, #0x1
   35f88:	b.lt	35fa4 <__gmpn_toom32_mul@@Base+0x134>  // b.tstop
   35f8c:	ldr	x10, [x19, x9, lsl #3]
   35f90:	ldr	x11, [x8], #-8
   35f94:	sub	x9, x9, #0x1
   35f98:	cmp	x10, x11
   35f9c:	b.eq	35f80 <__gmpn_toom32_mul@@Base+0x110>  // b.none
   35fa0:	b.ls	360b0 <__gmpn_toom32_mul@@Base+0x240>  // b.plast
   35fa4:	mov	x20, xzr
   35fa8:	add	x0, x19, x23, lsl #3
   35fac:	add	x2, x28, x22, lsl #3
   35fb0:	mov	x1, x19
   35fb4:	mov	x3, x22
   35fb8:	bl	c2e0 <__gmpn_sub_n@plt>
   35fbc:	sub	x8, x20, x0
   35fc0:	stur	wzr, [x29, #-40]
   35fc4:	str	x8, [sp, #24]
   35fc8:	add	x2, x28, x22, lsl #3
   35fcc:	mov	x0, x19
   35fd0:	mov	x1, x19
   35fd4:	mov	x3, x22
   35fd8:	str	x28, [sp, #40]
   35fdc:	bl	ca90 <__gmpn_add_n@plt>
   35fe0:	ldur	x3, [x29, #-16]
   35fe4:	add	x23, x0, x20
   35fe8:	add	x21, x19, x22, lsl #3
   35fec:	add	x2, x26, x22, lsl #3
   35ff0:	subs	x28, x22, x3
   35ff4:	stur	x21, [x29, #-24]
   35ff8:	str	x2, [sp, #48]
   35ffc:	b.ne	36068 <__gmpn_toom32_mul@@Base+0x1f8>  // b.any
   36000:	mov	x0, x21
   36004:	mov	x1, x26
   36008:	mov	x3, x22
   3600c:	bl	ca90 <__gmpn_add_n@plt>
   36010:	ldur	x28, [x29, #-8]
   36014:	mov	w8, #0x8                   	// #8
   36018:	mov	x20, x0
   3601c:	bfi	x8, x24, #4, #60
   36020:	mov	x9, x24
   36024:	add	x10, x9, #0x1
   36028:	cmp	x10, #0x1
   3602c:	b.lt	3604c <__gmpn_toom32_mul@@Base+0x1dc>  // b.tstop
   36030:	ldr	x10, [x26, x9, lsl #3]
   36034:	ldr	x11, [x26, x8]
   36038:	sub	x9, x9, #0x1
   3603c:	sub	x8, x8, #0x8
   36040:	cmp	x10, x11
   36044:	b.eq	36024 <__gmpn_toom32_mul@@Base+0x1b4>  // b.none
   36048:	b.ls	36214 <__gmpn_toom32_mul@@Base+0x3a4>  // b.plast
   3604c:	ldr	x2, [sp, #48]
   36050:	mov	w8, #0x18                  	// #24
   36054:	madd	x0, x22, x8, x19
   36058:	mov	x1, x26
   3605c:	mov	x3, x22
   36060:	bl	c2e0 <__gmpn_sub_n@plt>
   36064:	b	3628c <__gmpn_toom32_mul@@Base+0x41c>
   36068:	cbz	x3, 360d4 <__gmpn_toom32_mul@@Base+0x264>
   3606c:	mov	x0, x21
   36070:	mov	x1, x26
   36074:	bl	ca90 <__gmpn_add_n@plt>
   36078:	ldur	x3, [x29, #-16]
   3607c:	mov	x8, x3
   36080:	cbz	x0, 360d8 <__gmpn_toom32_mul@@Base+0x268>
   36084:	add	x9, x19, x27, lsl #3
   36088:	mov	w20, #0x1                   	// #1
   3608c:	mov	x8, x3
   36090:	cmp	x8, x24
   36094:	b.gt	36118 <__gmpn_toom32_mul@@Base+0x2a8>
   36098:	ldr	x10, [x26, x8, lsl #3]
   3609c:	add	x8, x8, #0x1
   360a0:	adds	x10, x10, #0x1
   360a4:	str	x10, [x9], #8
   360a8:	b.cs	36090 <__gmpn_toom32_mul@@Base+0x220>  // b.hs, b.nlast
   360ac:	b	360d8 <__gmpn_toom32_mul@@Base+0x268>
   360b0:	add	x0, x19, x23, lsl #3
   360b4:	mov	x2, x19
   360b8:	mov	x3, x22
   360bc:	bl	c2e0 <__gmpn_sub_n@plt>
   360c0:	mov	x20, xzr
   360c4:	mov	w8, #0x1                   	// #1
   360c8:	str	xzr, [sp, #24]
   360cc:	stur	w8, [x29, #-40]
   360d0:	b	35fc8 <__gmpn_toom32_mul@@Base+0x158>
   360d4:	mov	x8, xzr
   360d8:	cmp	x21, x26
   360dc:	mov	x20, xzr
   360e0:	b.eq	36118 <__gmpn_toom32_mul@@Base+0x2a8>  // b.none
   360e4:	cmp	x8, x24
   360e8:	b.gt	36118 <__gmpn_toom32_mul@@Base+0x2a8>
   360ec:	add	x10, x8, x24
   360f0:	sub	x9, x24, x8
   360f4:	add	x10, x19, x10, lsl #3
   360f8:	add	x9, x9, #0x1
   360fc:	add	x10, x10, #0x8
   36100:	add	x8, x26, x8, lsl #3
   36104:	ldr	x11, [x8], #8
   36108:	subs	x9, x9, #0x1
   3610c:	str	x11, [x10], #8
   36110:	b.ne	36104 <__gmpn_toom32_mul@@Base+0x294>  // b.any
   36114:	mov	x20, xzr
   36118:	sub	x8, x27, x24, lsl #1
   3611c:	sub	x8, x8, #0x2
   36120:	lsl	x9, x24, #3
   36124:	ldr	x10, [x26, x9]
   36128:	cbnz	x10, 36170 <__gmpn_toom32_mul@@Base+0x300>
   3612c:	adds	x8, x8, #0x1
   36130:	sub	x9, x9, #0x8
   36134:	b.cc	36124 <__gmpn_toom32_mul@@Base+0x2b4>  // b.lo, b.ul, b.last
   36138:	sub	x8, x27, x24
   3613c:	lsl	x9, x27, #3
   36140:	sub	x8, x8, #0x2
   36144:	sub	x9, x9, #0x8
   36148:	add	x10, x8, #0x1
   3614c:	cmp	x10, #0x1
   36150:	b.lt	36170 <__gmpn_toom32_mul@@Base+0x300>  // b.tstop
   36154:	ldr	x10, [x26, x8, lsl #3]
   36158:	ldr	x11, [x26, x9]
   3615c:	sub	x8, x8, #0x1
   36160:	sub	x9, x9, #0x8
   36164:	cmp	x10, x11
   36168:	b.eq	36148 <__gmpn_toom32_mul@@Base+0x2d8>  // b.none
   3616c:	b.ls	3623c <__gmpn_toom32_mul@@Base+0x3cc>  // b.plast
   36170:	mov	w8, #0x18                  	// #24
   36174:	madd	x21, x22, x8, x19
   36178:	cbz	x3, 361c8 <__gmpn_toom32_mul@@Base+0x358>
   3617c:	ldr	x2, [sp, #48]
   36180:	mov	x0, x21
   36184:	mov	x1, x26
   36188:	bl	c2e0 <__gmpn_sub_n@plt>
   3618c:	ldp	x10, x28, [x29, #-16]
   36190:	mov	x8, x10
   36194:	cbz	x0, 361d0 <__gmpn_toom32_mul@@Base+0x360>
   36198:	add	x8, x27, x24, lsl #1
   3619c:	add	x8, x19, x8, lsl #3
   361a0:	add	x9, x8, #0x10
   361a4:	mov	x8, x10
   361a8:	cmp	x8, x24
   361ac:	b.gt	36288 <__gmpn_toom32_mul@@Base+0x418>
   361b0:	ldr	x10, [x26, x8, lsl #3]
   361b4:	add	x8, x8, #0x1
   361b8:	sub	x11, x10, #0x1
   361bc:	str	x11, [x9], #8
   361c0:	cbz	x10, 361a8 <__gmpn_toom32_mul@@Base+0x338>
   361c4:	b	361d0 <__gmpn_toom32_mul@@Base+0x360>
   361c8:	ldur	x28, [x29, #-8]
   361cc:	mov	x8, xzr
   361d0:	cmp	x21, x26
   361d4:	b.eq	36288 <__gmpn_toom32_mul@@Base+0x418>  // b.none
   361d8:	cmp	x8, x24
   361dc:	b.gt	36288 <__gmpn_toom32_mul@@Base+0x418>
   361e0:	add	x10, x24, x24, lsl #1
   361e4:	ldur	x21, [x29, #-24]
   361e8:	add	x10, x8, x10
   361ec:	sub	x9, x24, x8
   361f0:	add	x10, x19, x10, lsl #3
   361f4:	add	x9, x9, #0x1
   361f8:	add	x10, x10, #0x18
   361fc:	add	x8, x26, x8, lsl #3
   36200:	ldr	x11, [x8], #8
   36204:	subs	x9, x9, #0x1
   36208:	str	x11, [x10], #8
   3620c:	b.ne	36200 <__gmpn_toom32_mul@@Base+0x390>  // b.any
   36210:	b	3628c <__gmpn_toom32_mul@@Base+0x41c>
   36214:	ldr	x1, [sp, #48]
   36218:	mov	w8, #0x18                  	// #24
   3621c:	madd	x0, x22, x8, x19
   36220:	mov	x2, x26
   36224:	mov	x3, x22
   36228:	bl	c2e0 <__gmpn_sub_n@plt>
   3622c:	ldur	w8, [x29, #-40]
   36230:	eor	w8, w8, #0x1
   36234:	stur	w8, [x29, #-40]
   36238:	b	3628c <__gmpn_toom32_mul@@Base+0x41c>
   3623c:	ldr	x1, [sp, #48]
   36240:	mov	w8, #0x18                  	// #24
   36244:	madd	x21, x22, x8, x19
   36248:	mov	x0, x21
   3624c:	mov	x2, x26
   36250:	bl	c2e0 <__gmpn_sub_n@plt>
   36254:	cbz	x28, 36278 <__gmpn_toom32_mul@@Base+0x408>
   36258:	ldur	x8, [x29, #-16]
   3625c:	mov	w1, wzr
   36260:	add	x0, x21, x8, lsl #3
   36264:	lsl	x8, x24, #1
   36268:	sub	x8, x8, x27
   3626c:	lsl	x8, x8, #3
   36270:	add	x2, x8, #0x10
   36274:	bl	c610 <memset@plt>
   36278:	ldur	w8, [x29, #-40]
   3627c:	ldur	x28, [x29, #-8]
   36280:	eor	w8, w8, #0x1
   36284:	stur	w8, [x29, #-40]
   36288:	ldur	x21, [x29, #-24]
   3628c:	mov	x0, x25
   36290:	mov	x1, x19
   36294:	mov	x2, x21
   36298:	mov	x3, x22
   3629c:	bl	c9b0 <__gmpn_mul_n@plt>
   362a0:	cmp	x23, #0x2
   362a4:	b.eq	362cc <__gmpn_toom32_mul@@Base+0x45c>  // b.none
   362a8:	cmp	x23, #0x1
   362ac:	b.ne	362e8 <__gmpn_toom32_mul@@Base+0x478>  // b.any
   362b0:	add	x0, x25, x22, lsl #3
   362b4:	mov	x1, x0
   362b8:	mov	x2, x21
   362bc:	mov	x3, x22
   362c0:	bl	ca90 <__gmpn_add_n@plt>
   362c4:	add	x21, x0, x20
   362c8:	b	362ec <__gmpn_toom32_mul@@Base+0x47c>
   362cc:	add	x0, x25, x22, lsl #3
   362d0:	mov	x1, x0
   362d4:	mov	x2, x21
   362d8:	mov	x3, x22
   362dc:	bl	cc60 <__gmpn_addlsh1_n@plt>
   362e0:	add	x21, x0, x20, lsl #1
   362e4:	b	362ec <__gmpn_toom32_mul@@Base+0x47c>
   362e8:	mov	x21, xzr
   362ec:	ldr	x23, [sp, #24]
   362f0:	cbz	x20, 3630c <__gmpn_toom32_mul@@Base+0x49c>
   362f4:	add	x0, x25, x22, lsl #3
   362f8:	mov	x1, x0
   362fc:	mov	x2, x19
   36300:	mov	x3, x22
   36304:	bl	ca90 <__gmpn_add_n@plt>
   36308:	add	x21, x0, x21
   3630c:	str	x21, [x25, x28, lsl #3]
   36310:	add	x20, x19, x28, lsl #3
   36314:	add	x28, x22, x22, lsl #1
   36318:	add	x21, x19, x28, lsl #3
   3631c:	mov	x0, x19
   36320:	mov	x1, x20
   36324:	mov	x2, x21
   36328:	mov	x3, x22
   3632c:	bl	c9b0 <__gmpn_mul_n@plt>
   36330:	cbz	x23, 3634c <__gmpn_toom32_mul@@Base+0x4dc>
   36334:	ldur	x0, [x29, #-24]
   36338:	mov	x2, x21
   3633c:	mov	x3, x22
   36340:	mov	x1, x0
   36344:	bl	ca90 <__gmpn_add_n@plt>
   36348:	b	36350 <__gmpn_toom32_mul@@Base+0x4e0>
   3634c:	mov	x0, xzr
   36350:	ldur	x8, [x29, #-8]
   36354:	str	x0, [x20]
   36358:	mov	x0, x25
   3635c:	mov	x1, x25
   36360:	orr	x3, x8, #0x1
   36364:	ldur	w8, [x29, #-40]
   36368:	mov	x2, x19
   3636c:	str	x27, [sp, #16]
   36370:	cbz	w8, 3637c <__gmpn_toom32_mul@@Base+0x50c>
   36374:	bl	c860 <__gmpn_rsh1sub_n@plt>
   36378:	b	36380 <__gmpn_toom32_mul@@Base+0x510>
   3637c:	bl	c970 <__gmpn_rsh1add_n@plt>
   36380:	ldr	x27, [x20]
   36384:	add	x23, x25, x22, lsl #3
   36388:	mov	x0, x20
   3638c:	mov	x1, x25
   36390:	mov	x2, x23
   36394:	mov	x3, x22
   36398:	bl	ca90 <__gmpn_add_n@plt>
   3639c:	ldur	x10, [x29, #-8]
   363a0:	ldr	x9, [x23]
   363a4:	ldr	x8, [x25, x10, lsl #3]
   363a8:	add	x8, x8, x0
   363ac:	add	x8, x9, x8
   363b0:	str	x8, [x23]
   363b4:	ldr	x9, [x25, x10, lsl #3]
   363b8:	add	x9, x9, x0
   363bc:	cmp	x8, x9
   363c0:	b.cs	363dc <__gmpn_toom32_mul@@Base+0x56c>  // b.hs, b.nlast
   363c4:	add	x8, x25, x24, lsl #3
   363c8:	add	x8, x8, #0x10
   363cc:	ldr	x9, [x8]
   363d0:	adds	x9, x9, #0x1
   363d4:	str	x9, [x8], #8
   363d8:	b.cs	363cc <__gmpn_toom32_mul@@Base+0x55c>  // b.hs, b.nlast
   363dc:	ldur	w8, [x29, #-40]
   363e0:	cbz	w8, 36440 <__gmpn_toom32_mul@@Base+0x5d0>
   363e4:	mov	x0, x25
   363e8:	mov	x1, x25
   363ec:	mov	x2, x19
   363f0:	mov	x3, x22
   363f4:	bl	ca90 <__gmpn_add_n@plt>
   363f8:	ldur	x2, [x29, #-24]
   363fc:	mov	x4, x0
   36400:	mov	x0, x20
   36404:	mov	x1, x20
   36408:	mov	x3, x22
   3640c:	bl	ceb0 <__gmpn_add_nc@plt>
   36410:	ldr	x8, [x25, x22, lsl #3]
   36414:	add	x9, x0, x27
   36418:	adds	x8, x8, x9
   3641c:	str	x8, [x25, x22, lsl #3]
   36420:	b.cc	36498 <__gmpn_toom32_mul@@Base+0x628>  // b.lo, b.ul, b.last
   36424:	add	x8, x25, x24, lsl #3
   36428:	add	x8, x8, #0x10
   3642c:	ldr	x9, [x8]
   36430:	adds	x9, x9, #0x1
   36434:	str	x9, [x8], #8
   36438:	b.cs	3642c <__gmpn_toom32_mul@@Base+0x5bc>  // b.hs, b.nlast
   3643c:	b	36498 <__gmpn_toom32_mul@@Base+0x628>
   36440:	mov	x0, x25
   36444:	mov	x1, x25
   36448:	mov	x2, x19
   3644c:	mov	x3, x22
   36450:	bl	c2e0 <__gmpn_sub_n@plt>
   36454:	ldur	x2, [x29, #-24]
   36458:	mov	x4, x0
   3645c:	mov	x0, x20
   36460:	mov	x1, x20
   36464:	mov	x3, x22
   36468:	bl	c780 <__gmpn_sub_nc@plt>
   3646c:	ldr	x8, [x25, x22, lsl #3]
   36470:	add	x9, x0, x27
   36474:	subs	x8, x8, x9
   36478:	str	x8, [x25, x22, lsl #3]
   3647c:	b.cs	36498 <__gmpn_toom32_mul@@Base+0x628>  // b.hs, b.nlast
   36480:	add	x8, x25, x24, lsl #3
   36484:	add	x8, x8, #0x10
   36488:	ldr	x9, [x8]
   3648c:	sub	x10, x9, #0x1
   36490:	str	x10, [x8], #8
   36494:	cbz	x9, 36488 <__gmpn_toom32_mul@@Base+0x618>
   36498:	ldr	x1, [sp, #40]
   3649c:	mov	x0, x19
   364a0:	mov	x2, x26
   364a4:	mov	x3, x22
   364a8:	bl	c9b0 <__gmpn_mul_n@plt>
   364ac:	ldur	x8, [x29, #-32]
   364b0:	ldur	x9, [x29, #-16]
   364b4:	mov	x27, x25
   364b8:	mov	x0, x21
   364bc:	cmp	x8, x9
   364c0:	b.le	364d8 <__gmpn_toom32_mul@@Base+0x668>
   364c4:	ldr	x1, [sp, #32]
   364c8:	ldr	x3, [sp, #48]
   364cc:	mov	x2, x8
   364d0:	mov	x4, x9
   364d4:	b	364e8 <__gmpn_toom32_mul@@Base+0x678>
   364d8:	ldr	x1, [sp, #48]
   364dc:	ldr	x3, [sp, #32]
   364e0:	mov	x2, x9
   364e4:	mov	x4, x8
   364e8:	bl	ccf0 <__gmpn_mul@plt>
   364ec:	ldur	x25, [x29, #-24]
   364f0:	mov	x2, x21
   364f4:	mov	x3, x22
   364f8:	mov	x0, x25
   364fc:	mov	x1, x25
   36500:	bl	c2e0 <__gmpn_sub_n@plt>
   36504:	ldur	x8, [x29, #-8]
   36508:	mov	x26, x0
   3650c:	mov	x0, x20
   36510:	mov	x1, x20
   36514:	ldr	x8, [x27, x8, lsl #3]
   36518:	mov	x2, x19
   3651c:	mov	x3, x22
   36520:	mov	x4, x26
   36524:	stur	x8, [x29, #-40]
   36528:	bl	c780 <__gmpn_sub_nc@plt>
   3652c:	mov	x4, x0
   36530:	mov	x0, x21
   36534:	mov	x1, x23
   36538:	mov	x2, x25
   3653c:	mov	x3, x22
   36540:	bl	c780 <__gmpn_sub_nc@plt>
   36544:	mov	x21, x0
   36548:	cbz	x22, 365a0 <__gmpn_toom32_mul@@Base+0x730>
   3654c:	mov	x0, x25
   36550:	mov	x1, x25
   36554:	mov	x2, x27
   36558:	mov	x3, x22
   3655c:	bl	ca90 <__gmpn_add_n@plt>
   36560:	cbz	x0, 365a0 <__gmpn_toom32_mul@@Base+0x730>
   36564:	ldur	x12, [x29, #-32]
   36568:	ldur	x13, [x29, #-16]
   3656c:	mov	w8, #0x1                   	// #1
   36570:	mov	x9, x20
   36574:	mov	x10, x22
   36578:	cmp	x10, x28
   3657c:	b.ge	36598 <__gmpn_toom32_mul@@Base+0x728>  // b.tcont
   36580:	ldr	x11, [x9]
   36584:	add	x10, x10, #0x1
   36588:	adds	x11, x11, #0x1
   3658c:	str	x11, [x9], #8
   36590:	b.cs	36578 <__gmpn_toom32_mul@@Base+0x708>  // b.hs, b.nlast
   36594:	mov	x8, xzr
   36598:	ldur	x28, [x29, #-8]
   3659c:	b	365ac <__gmpn_toom32_mul@@Base+0x73c>
   365a0:	ldp	x13, x28, [x29, #-16]
   365a4:	ldur	x12, [x29, #-32]
   365a8:	mov	x8, xzr
   365ac:	ldur	x10, [x29, #-40]
   365b0:	add	x9, x12, x13
   365b4:	cmp	x9, x22
   365b8:	b.le	36684 <__gmpn_toom32_mul@@Base+0x814>
   365bc:	add	x10, x10, x26
   365c0:	subs	x23, x9, x22
   365c4:	sub	x9, x10, x21
   365c8:	add	x25, x9, x8
   365cc:	add	x21, x19, x22, lsl #5
   365d0:	b.eq	3661c <__gmpn_toom32_mul@@Base+0x7ac>  // b.none
   365d4:	mov	x0, x20
   365d8:	mov	x1, x20
   365dc:	mov	x2, x21
   365e0:	mov	x3, x23
   365e4:	bl	c2e0 <__gmpn_sub_n@plt>
   365e8:	cbz	x0, 3661c <__gmpn_toom32_mul@@Base+0x7ac>
   365ec:	ldp	x9, x8, [sp, #8]
   365f0:	add	x8, x8, x9
   365f4:	sub	x8, x8, x24, lsl #1
   365f8:	add	x8, x19, x8, lsl #3
   365fc:	sub	x8, x8, #0x10
   36600:	cmp	x23, x28
   36604:	b.ge	366a4 <__gmpn_toom32_mul@@Base+0x834>  // b.tcont
   36608:	ldr	x9, [x8]
   3660c:	add	x23, x23, #0x1
   36610:	sub	x10, x9, #0x1
   36614:	str	x10, [x8], #8
   36618:	cbz	x9, 36600 <__gmpn_toom32_mul@@Base+0x790>
   3661c:	mov	x8, xzr
   36620:	adds	x8, x25, x8
   36624:	b.mi	36654 <__gmpn_toom32_mul@@Base+0x7e4>  // b.first
   36628:	ldr	x9, [x21]
   3662c:	adds	x8, x9, x8
   36630:	str	x8, [x21]
   36634:	b.cc	36684 <__gmpn_toom32_mul@@Base+0x814>  // b.lo, b.ul, b.last
   36638:	add	x8, x19, x24, lsl #5
   3663c:	add	x8, x8, #0x28
   36640:	ldr	x9, [x8]
   36644:	adds	x9, x9, #0x1
   36648:	str	x9, [x8], #8
   3664c:	b.cs	36640 <__gmpn_toom32_mul@@Base+0x7d0>  // b.hs, b.nlast
   36650:	b	36684 <__gmpn_toom32_mul@@Base+0x814>
   36654:	ldr	x9, [x21]
   36658:	neg	x10, x8
   3665c:	add	x8, x9, x8
   36660:	cmp	x9, x10
   36664:	str	x8, [x21]
   36668:	b.cs	36684 <__gmpn_toom32_mul@@Base+0x814>  // b.hs, b.nlast
   3666c:	add	x8, x19, x24, lsl #5
   36670:	add	x8, x8, #0x28
   36674:	ldr	x9, [x8]
   36678:	sub	x10, x9, #0x1
   3667c:	str	x10, [x8], #8
   36680:	cbz	x9, 36674 <__gmpn_toom32_mul@@Base+0x804>
   36684:	ldp	x20, x19, [sp, #176]
   36688:	ldp	x22, x21, [sp, #160]
   3668c:	ldp	x24, x23, [sp, #144]
   36690:	ldp	x26, x25, [sp, #128]
   36694:	ldp	x28, x27, [sp, #112]
   36698:	ldp	x29, x30, [sp, #96]
   3669c:	add	sp, sp, #0xc0
   366a0:	ret
   366a4:	mov	x8, #0xffffffffffffffff    	// #-1
   366a8:	b	36620 <__gmpn_toom32_mul@@Base+0x7b0>

00000000000366ac <__gmpn_toom42_mul@@Base>:
   366ac:	stp	x29, x30, [sp, #-96]!
   366b0:	stp	x28, x27, [sp, #16]
   366b4:	stp	x26, x25, [sp, #32]
   366b8:	stp	x24, x23, [sp, #48]
   366bc:	stp	x22, x21, [sp, #64]
   366c0:	stp	x20, x19, [sp, #80]
   366c4:	mov	x29, sp
   366c8:	sub	sp, sp, #0x70
   366cc:	add	x8, x2, #0x3
   366d0:	add	x9, x4, #0x1
   366d4:	cmp	x2, x4, lsl #1
   366d8:	asr	x8, x8, #2
   366dc:	asr	x9, x9, #1
   366e0:	mov	w10, #0x30                  	// #48
   366e4:	csel	x23, x9, x8, lt  // lt = tstop
   366e8:	mul	x8, x23, x10
   366ec:	mov	x20, x1
   366f0:	add	x26, x23, x23, lsl #1
   366f4:	add	x1, x8, #0x28
   366f8:	mov	w8, #0x7f00                	// #32512
   366fc:	mov	x21, x3
   36700:	mov	x22, x2
   36704:	sub	x9, x2, x26
   36708:	cmp	x1, x8
   3670c:	stur	x5, [x29, #-48]
   36710:	stp	x4, x0, [x29, #-32]
   36714:	stp	x9, xzr, [x29, #-16]
   36718:	b.hi	36dc4 <__gmpn_toom42_mul@@Base+0x718>  // b.pmore
   3671c:	add	x9, x1, #0xf
   36720:	mov	x8, sp
   36724:	and	x9, x9, #0xfffffffffffffff0
   36728:	sub	x0, x8, x9
   3672c:	mov	sp, x0
   36730:	ldp	x8, x5, [x29, #-32]
   36734:	ldur	x4, [x29, #-16]
   36738:	mov	x2, x20
   3673c:	mov	x3, x23
   36740:	sub	x25, x8, x23
   36744:	add	x8, x23, #0x1
   36748:	add	x1, x0, x8, lsl #3
   3674c:	add	x19, x1, x8, lsl #3
   36750:	add	x28, x19, x8, lsl #3
   36754:	stur	x8, [x29, #-80]
   36758:	add	x27, x28, x8, lsl #3
   3675c:	stur	x0, [x29, #-56]
   36760:	stur	x1, [x29, #-96]
   36764:	bl	c290 <__gmpn_toom_eval_dgr3_pm1@plt>
   36768:	ldur	x3, [x29, #-16]
   3676c:	add	x24, x20, x23, lsl #4
   36770:	and	w8, w0, #0x1
   36774:	add	x2, x20, x26, lsl #3
   36778:	mov	x0, x19
   3677c:	mov	x1, x24
   36780:	stur	w8, [x29, #-60]
   36784:	stur	x2, [x29, #-88]
   36788:	bl	cc60 <__gmpn_addlsh1_n@plt>
   3678c:	ldur	x10, [x29, #-16]
   36790:	mov	x26, x0
   36794:	subs	x8, x23, x10
   36798:	b.eq	36860 <__gmpn_toom42_mul@@Base+0x1b4>  // b.none
   3679c:	ldr	x9, [x24, x10, lsl #3]
   367a0:	adds	x9, x9, x26
   367a4:	str	x9, [x19, x10, lsl #3]
   367a8:	b.cc	36818 <__gmpn_toom42_mul@@Base+0x16c>  // b.lo, b.ul, b.last
   367ac:	ldur	x11, [x29, #-56]
   367b0:	lsl	x9, x22, #3
   367b4:	sub	x10, x22, x23
   367b8:	sub	x9, x9, x23, lsl #3
   367bc:	add	x10, x20, x10, lsl #3
   367c0:	add	x9, x9, x11
   367c4:	mov	w26, #0x1                   	// #1
   367c8:	add	x1, x10, #0x8
   367cc:	add	x0, x9, #0x18
   367d0:	mov	w9, #0x1                   	// #1
   367d4:	cmp	x9, x8
   367d8:	b.ge	36860 <__gmpn_toom42_mul@@Base+0x1b4>  // b.tcont
   367dc:	ldr	x10, [x1], #8
   367e0:	add	x9, x9, #0x1
   367e4:	adds	x10, x10, #0x1
   367e8:	str	x10, [x0], #8
   367ec:	b.cs	367d4 <__gmpn_toom42_mul@@Base+0x128>  // b.hs, b.nlast
   367f0:	cmp	x24, x19
   367f4:	mov	x26, xzr
   367f8:	b.eq	36860 <__gmpn_toom42_mul@@Base+0x1b4>  // b.none
   367fc:	cmp	x9, x8
   36800:	b.ge	36860 <__gmpn_toom42_mul@@Base+0x1b4>  // b.tcont
   36804:	lsl	x8, x23, #2
   36808:	sub	x8, x8, x22
   3680c:	sub	x8, x8, x9
   36810:	lsl	x2, x8, #3
   36814:	b	36858 <__gmpn_toom42_mul@@Base+0x1ac>
   36818:	cmp	x8, #0x2
   3681c:	mov	x26, xzr
   36820:	b.lt	36860 <__gmpn_toom42_mul@@Base+0x1b4>  // b.tstop
   36824:	cmp	x24, x19
   36828:	b.eq	36860 <__gmpn_toom42_mul@@Base+0x1b4>  // b.none
   3682c:	ldur	x11, [x29, #-56]
   36830:	lsl	x8, x22, #3
   36834:	sub	x9, x22, x23
   36838:	mvn	x10, x22
   3683c:	sub	x8, x8, x23, lsl #3
   36840:	add	x9, x20, x9, lsl #3
   36844:	add	x10, x10, x23, lsl #2
   36848:	add	x8, x8, x11
   3684c:	add	x1, x9, #0x8
   36850:	add	x0, x8, #0x18
   36854:	lsl	x2, x10, #3
   36858:	bl	bee0 <memcpy@plt>
   3685c:	mov	x26, xzr
   36860:	add	x8, x27, x23, lsl #3
   36864:	add	x1, x20, x23, lsl #3
   36868:	mov	x0, x19
   3686c:	mov	x2, x19
   36870:	mov	x3, x23
   36874:	stur	x8, [x29, #-40]
   36878:	bl	cc60 <__gmpn_addlsh1_n@plt>
   3687c:	add	x22, x0, x26, lsl #1
   36880:	mov	x0, x19
   36884:	mov	x1, x20
   36888:	mov	x2, x19
   3688c:	mov	x3, x23
   36890:	stur	x20, [x29, #-72]
   36894:	bl	cc60 <__gmpn_addlsh1_n@plt>
   36898:	add	x8, x0, x22, lsl #1
   3689c:	subs	x24, x23, x25
   368a0:	add	x26, x21, x23, lsl #3
   368a4:	str	x8, [x19, x23, lsl #3]
   368a8:	stur	x19, [x29, #-104]
   368ac:	b.ne	3691c <__gmpn_toom42_mul@@Base+0x270>  // b.any
   368b0:	mov	x0, x28
   368b4:	mov	x1, x21
   368b8:	mov	x2, x26
   368bc:	mov	x3, x23
   368c0:	bl	ca90 <__gmpn_add_n@plt>
   368c4:	mov	x20, x27
   368c8:	ldp	x27, x19, [x29, #-56]
   368cc:	lsl	x8, x23, #4
   368d0:	sub	x8, x8, #0x8
   368d4:	mov	x10, x23
   368d8:	str	x0, [x28, x23, lsl #3]
   368dc:	subs	x9, x10, #0x1
   368e0:	b.lt	36904 <__gmpn_toom42_mul@@Base+0x258>  // b.tstop
   368e4:	add	x10, x21, x10, lsl #3
   368e8:	ldur	x10, [x10, #-8]
   368ec:	ldr	x11, [x21, x8]
   368f0:	sub	x8, x8, #0x8
   368f4:	cmp	x10, x11
   368f8:	mov	x10, x9
   368fc:	b.eq	368dc <__gmpn_toom42_mul@@Base+0x230>  // b.none
   36900:	b.ls	36ab4 <__gmpn_toom42_mul@@Base+0x408>  // b.plast
   36904:	mov	x0, x20
   36908:	mov	x1, x21
   3690c:	mov	x2, x26
   36910:	mov	x3, x23
   36914:	bl	c2e0 <__gmpn_sub_n@plt>
   36918:	b	36b28 <__gmpn_toom42_mul@@Base+0x47c>
   3691c:	lsl	x22, x23, #3
   36920:	cbz	x25, 36984 <__gmpn_toom42_mul@@Base+0x2d8>
   36924:	mov	x0, x28
   36928:	mov	x1, x21
   3692c:	mov	x2, x26
   36930:	mov	x3, x25
   36934:	bl	ca90 <__gmpn_add_n@plt>
   36938:	mov	x20, x27
   3693c:	ldur	x27, [x29, #-56]
   36940:	mov	x8, x25
   36944:	cbz	x0, 36990 <__gmpn_toom42_mul@@Base+0x2e4>
   36948:	ldur	x9, [x29, #-32]
   3694c:	lsl	x8, x23, #4
   36950:	add	x8, x8, x9, lsl #3
   36954:	add	x8, x8, x27
   36958:	add	x10, x8, #0x18
   3695c:	mov	w9, #0x1                   	// #1
   36960:	mov	x8, x25
   36964:	cmp	x8, x23
   36968:	b.ge	369c8 <__gmpn_toom42_mul@@Base+0x31c>  // b.tcont
   3696c:	ldr	x11, [x21, x8, lsl #3]
   36970:	add	x8, x8, #0x1
   36974:	adds	x11, x11, #0x1
   36978:	str	x11, [x10], #8
   3697c:	b.cs	36964 <__gmpn_toom42_mul@@Base+0x2b8>  // b.hs, b.nlast
   36980:	b	36990 <__gmpn_toom42_mul@@Base+0x2e4>
   36984:	mov	x20, x27
   36988:	ldur	x27, [x29, #-56]
   3698c:	mov	x8, xzr
   36990:	cmp	x28, x21
   36994:	mov	x9, xzr
   36998:	b.eq	369c8 <__gmpn_toom42_mul@@Base+0x31c>  // b.none
   3699c:	cmp	x8, x23
   369a0:	b.ge	369c8 <__gmpn_toom42_mul@@Base+0x31c>  // b.tcont
   369a4:	mov	w9, #0x18                  	// #24
   369a8:	mul	x9, x23, x9
   369ac:	add	x9, x9, x8, lsl #3
   369b0:	add	x9, x9, x27
   369b4:	add	x1, x21, x8, lsl #3
   369b8:	add	x0, x9, #0x18
   369bc:	sub	x2, x22, x8, lsl #3
   369c0:	bl	bee0 <memcpy@plt>
   369c4:	mov	x9, xzr
   369c8:	ldur	x8, [x29, #-32]
   369cc:	str	x9, [x28, x23, lsl #3]
   369d0:	sub	x9, x22, #0x8
   369d4:	sub	x8, x8, x23, lsl #1
   369d8:	ldr	x10, [x21, x9]
   369dc:	cbnz	x10, 36a24 <__gmpn_toom42_mul@@Base+0x378>
   369e0:	adds	x8, x8, #0x1
   369e4:	sub	x9, x9, #0x8
   369e8:	b.cc	369d8 <__gmpn_toom42_mul@@Base+0x32c>  // b.lo, b.ul, b.last
   369ec:	ldur	x8, [x29, #-32]
   369f0:	mov	x10, x25
   369f4:	lsl	x8, x8, #3
   369f8:	sub	x8, x8, #0x8
   369fc:	subs	x9, x10, #0x1
   36a00:	b.lt	36a24 <__gmpn_toom42_mul@@Base+0x378>  // b.tstop
   36a04:	add	x10, x21, x10, lsl #3
   36a08:	ldur	x10, [x10, #-8]
   36a0c:	ldr	x11, [x21, x8]
   36a10:	sub	x8, x8, #0x8
   36a14:	cmp	x10, x11
   36a18:	mov	x10, x9
   36a1c:	b.eq	369fc <__gmpn_toom42_mul@@Base+0x350>  // b.none
   36a20:	b.ls	36ad8 <__gmpn_toom42_mul@@Base+0x42c>  // b.plast
   36a24:	cbz	x25, 36a80 <__gmpn_toom42_mul@@Base+0x3d4>
   36a28:	mov	x0, x20
   36a2c:	mov	x1, x21
   36a30:	mov	x2, x26
   36a34:	mov	x3, x25
   36a38:	bl	c2e0 <__gmpn_sub_n@plt>
   36a3c:	mov	x8, x25
   36a40:	cbz	x0, 36a84 <__gmpn_toom42_mul@@Base+0x3d8>
   36a44:	ldur	x9, [x29, #-32]
   36a48:	mov	w8, #0x18                  	// #24
   36a4c:	mul	x8, x23, x8
   36a50:	add	x8, x8, x9, lsl #3
   36a54:	add	x8, x8, x27
   36a58:	add	x9, x8, #0x20
   36a5c:	mov	x8, x25
   36a60:	cmp	x8, x23
   36a64:	b.ge	36b24 <__gmpn_toom42_mul@@Base+0x478>  // b.tcont
   36a68:	ldr	x10, [x21, x8, lsl #3]
   36a6c:	add	x8, x8, #0x1
   36a70:	sub	x11, x10, #0x1
   36a74:	str	x11, [x9], #8
   36a78:	cbz	x10, 36a60 <__gmpn_toom42_mul@@Base+0x3b4>
   36a7c:	b	36a84 <__gmpn_toom42_mul@@Base+0x3d8>
   36a80:	mov	x8, xzr
   36a84:	cmp	x20, x21
   36a88:	b.eq	36b24 <__gmpn_toom42_mul@@Base+0x478>  // b.none
   36a8c:	cmp	x8, x23
   36a90:	b.ge	36b24 <__gmpn_toom42_mul@@Base+0x478>  // b.tcont
   36a94:	lsl	x9, x23, #5
   36a98:	add	x9, x9, x8, lsl #3
   36a9c:	add	x9, x9, x27
   36aa0:	add	x1, x21, x8, lsl #3
   36aa4:	add	x0, x9, #0x20
   36aa8:	sub	x2, x22, x8, lsl #3
   36aac:	bl	bee0 <memcpy@plt>
   36ab0:	b	36b24 <__gmpn_toom42_mul@@Base+0x478>
   36ab4:	mov	x0, x20
   36ab8:	mov	x1, x26
   36abc:	mov	x2, x21
   36ac0:	mov	x3, x23
   36ac4:	bl	c2e0 <__gmpn_sub_n@plt>
   36ac8:	ldur	w8, [x29, #-60]
   36acc:	eor	w8, w8, #0x1
   36ad0:	stur	w8, [x29, #-60]
   36ad4:	b	36b28 <__gmpn_toom42_mul@@Base+0x47c>
   36ad8:	mov	x0, x20
   36adc:	mov	x1, x26
   36ae0:	mov	x2, x21
   36ae4:	mov	x3, x25
   36ae8:	bl	c2e0 <__gmpn_sub_n@plt>
   36aec:	cbz	x24, 36b18 <__gmpn_toom42_mul@@Base+0x46c>
   36af0:	ldur	x10, [x29, #-32]
   36af4:	mov	w8, #0x18                  	// #24
   36af8:	mul	x8, x23, x8
   36afc:	lsl	x9, x23, #4
   36b00:	add	x8, x8, x10, lsl #3
   36b04:	add	x8, x8, x27
   36b08:	add	x0, x8, #0x20
   36b0c:	sub	x2, x9, x10, lsl #3
   36b10:	mov	w1, wzr
   36b14:	bl	c610 <memset@plt>
   36b18:	ldur	w8, [x29, #-60]
   36b1c:	eor	w8, w8, #0x1
   36b20:	stur	w8, [x29, #-60]
   36b24:	ldur	x19, [x29, #-48]
   36b28:	cbz	x25, 36b90 <__gmpn_toom42_mul@@Base+0x4e4>
   36b2c:	ldur	x0, [x29, #-40]
   36b30:	mov	x1, x28
   36b34:	mov	x2, x26
   36b38:	mov	x3, x25
   36b3c:	bl	ca90 <__gmpn_add_n@plt>
   36b40:	mov	x8, x25
   36b44:	cbz	x0, 36b94 <__gmpn_toom42_mul@@Base+0x4e8>
   36b48:	ldur	x10, [x29, #-32]
   36b4c:	lsl	x8, x23, #5
   36b50:	lsl	x9, x23, #4
   36b54:	add	x8, x8, x10, lsl #3
   36b58:	add	x9, x9, x10, lsl #3
   36b5c:	add	x8, x8, x27
   36b60:	add	x10, x9, x27
   36b64:	add	x9, x8, #0x20
   36b68:	add	x10, x10, #0x18
   36b6c:	mov	x8, x25
   36b70:	cmp	x8, x23
   36b74:	b.gt	36be8 <__gmpn_toom42_mul@@Base+0x53c>
   36b78:	ldr	x11, [x10], #8
   36b7c:	add	x8, x8, #0x1
   36b80:	adds	x11, x11, #0x1
   36b84:	str	x11, [x9], #8
   36b88:	b.cs	36b70 <__gmpn_toom42_mul@@Base+0x4c4>  // b.hs, b.nlast
   36b8c:	b	36b94 <__gmpn_toom42_mul@@Base+0x4e8>
   36b90:	mov	x8, xzr
   36b94:	ldur	x9, [x29, #-40]
   36b98:	cmp	x9, x28
   36b9c:	b.eq	36be8 <__gmpn_toom42_mul@@Base+0x53c>  // b.none
   36ba0:	cmp	x8, x23
   36ba4:	b.gt	36be8 <__gmpn_toom42_mul@@Base+0x53c>
   36ba8:	mov	w10, #0x28                  	// #40
   36bac:	mov	w11, #0x18                  	// #24
   36bb0:	mul	x10, x23, x10
   36bb4:	mul	x11, x23, x11
   36bb8:	sub	x9, x23, x8
   36bbc:	add	x10, x10, x8, lsl #3
   36bc0:	add	x8, x11, x8, lsl #3
   36bc4:	add	x10, x10, x27
   36bc8:	add	x11, x8, x27
   36bcc:	add	x9, x9, #0x1
   36bd0:	add	x8, x10, #0x20
   36bd4:	add	x10, x11, #0x18
   36bd8:	ldr	x11, [x10], #8
   36bdc:	subs	x9, x9, #0x1
   36be0:	str	x11, [x8], #8
   36be4:	b.ne	36bd8 <__gmpn_toom42_mul@@Base+0x52c>  // b.any
   36be8:	mov	x22, x28
   36bec:	mov	x28, x27
   36bf0:	mov	x27, x26
   36bf4:	ldur	x26, [x29, #-96]
   36bf8:	mov	x0, x19
   36bfc:	mov	x2, x20
   36c00:	mov	x3, x23
   36c04:	mov	x1, x26
   36c08:	lsl	x24, x23, #1
   36c0c:	bl	c9b0 <__gmpn_mul_n@plt>
   36c10:	ldr	x8, [x26, x23, lsl #3]
   36c14:	cbz	x8, 36c30 <__gmpn_toom42_mul@@Base+0x584>
   36c18:	add	x0, x19, x23, lsl #3
   36c1c:	mov	x1, x0
   36c20:	mov	x2, x20
   36c24:	mov	x3, x23
   36c28:	bl	ca90 <__gmpn_add_n@plt>
   36c2c:	b	36c34 <__gmpn_toom42_mul@@Base+0x588>
   36c30:	mov	x0, xzr
   36c34:	ldur	x1, [x29, #-104]
   36c38:	ldur	x2, [x29, #-40]
   36c3c:	ldur	x3, [x29, #-80]
   36c40:	add	x20, x19, x24, lsl #3
   36c44:	str	x0, [x20], #8
   36c48:	mov	x0, x20
   36c4c:	mov	x26, x27
   36c50:	bl	c9b0 <__gmpn_mul_n@plt>
   36c54:	ldp	x8, x9, [x29, #-24]
   36c58:	mov	x4, x25
   36c5c:	mov	x27, x28
   36c60:	add	x19, x8, x23, lsl #5
   36c64:	cmp	x9, x25
   36c68:	mov	x0, x19
   36c6c:	b.le	36c80 <__gmpn_toom42_mul@@Base+0x5d4>
   36c70:	ldur	x1, [x29, #-88]
   36c74:	mov	x2, x9
   36c78:	mov	x3, x26
   36c7c:	b	36c90 <__gmpn_toom42_mul@@Base+0x5e4>
   36c80:	ldur	x3, [x29, #-88]
   36c84:	mov	x1, x26
   36c88:	mov	x2, x4
   36c8c:	mov	x4, x9
   36c90:	bl	ccf0 <__gmpn_mul@plt>
   36c94:	ldur	x8, [x29, #-24]
   36c98:	ldr	x19, [x19]
   36c9c:	mov	x28, x22
   36ca0:	mov	x1, x27
   36ca4:	add	x22, x8, x24, lsl #3
   36ca8:	mov	x0, x22
   36cac:	mov	x2, x28
   36cb0:	mov	x3, x23
   36cb4:	bl	c9b0 <__gmpn_mul_n@plt>
   36cb8:	ldr	x8, [x27, x23, lsl #3]
   36cbc:	cmp	x8, #0x3
   36cc0:	b.eq	36cf4 <__gmpn_toom42_mul@@Base+0x648>  // b.none
   36cc4:	cmp	x8, #0x2
   36cc8:	b.eq	36d18 <__gmpn_toom42_mul@@Base+0x66c>  // b.none
   36ccc:	cmp	x8, #0x1
   36cd0:	b.ne	36d38 <__gmpn_toom42_mul@@Base+0x68c>  // b.any
   36cd4:	ldr	x26, [x28, x23, lsl #3]
   36cd8:	add	x0, x22, x23, lsl #3
   36cdc:	mov	x1, x0
   36ce0:	mov	x2, x28
   36ce4:	mov	x3, x23
   36ce8:	bl	ca90 <__gmpn_add_n@plt>
   36cec:	add	x26, x0, x26
   36cf0:	b	36d3c <__gmpn_toom42_mul@@Base+0x690>
   36cf4:	ldr	x8, [x28, x23, lsl #3]
   36cf8:	add	x0, x22, x23, lsl #3
   36cfc:	mov	w3, #0x3                   	// #3
   36d00:	mov	x1, x28
   36d04:	mov	x2, x23
   36d08:	add	x26, x8, x8, lsl #1
   36d0c:	bl	d420 <__gmpn_addmul_1@plt>
   36d10:	add	x26, x26, x0
   36d14:	b	36d3c <__gmpn_toom42_mul@@Base+0x690>
   36d18:	ldr	x26, [x28, x23, lsl #3]
   36d1c:	add	x0, x22, x23, lsl #3
   36d20:	mov	x1, x0
   36d24:	mov	x2, x28
   36d28:	mov	x3, x23
   36d2c:	bl	cc60 <__gmpn_addlsh1_n@plt>
   36d30:	add	x26, x0, x26, lsl #1
   36d34:	b	36d3c <__gmpn_toom42_mul@@Base+0x690>
   36d38:	mov	x26, xzr
   36d3c:	ldr	x8, [x28, x23, lsl #3]
   36d40:	cbz	x8, 36d5c <__gmpn_toom42_mul@@Base+0x6b0>
   36d44:	add	x0, x22, x23, lsl #3
   36d48:	mov	x1, x0
   36d4c:	mov	x2, x27
   36d50:	mov	x3, x23
   36d54:	bl	ca90 <__gmpn_add_n@plt>
   36d58:	add	x26, x0, x26
   36d5c:	str	x26, [x22, x24, lsl #3]
   36d60:	ldur	x22, [x29, #-24]
   36d64:	ldur	x1, [x29, #-72]
   36d68:	mov	x2, x21
   36d6c:	mov	x3, x23
   36d70:	mov	x0, x22
   36d74:	bl	c9b0 <__gmpn_mul_n@plt>
   36d78:	ldur	x8, [x29, #-16]
   36d7c:	ldur	x2, [x29, #-48]
   36d80:	ldur	w5, [x29, #-60]
   36d84:	mov	x0, x22
   36d88:	add	x4, x8, x25
   36d8c:	mov	x1, x20
   36d90:	mov	x3, x23
   36d94:	mov	x6, x19
   36d98:	bl	ca40 <__gmpn_toom_interpolate_5pts@plt>
   36d9c:	ldur	x0, [x29, #-8]
   36da0:	cbnz	x0, 36dd0 <__gmpn_toom42_mul@@Base+0x724>
   36da4:	mov	sp, x29
   36da8:	ldp	x20, x19, [sp, #80]
   36dac:	ldp	x22, x21, [sp, #64]
   36db0:	ldp	x24, x23, [sp, #48]
   36db4:	ldp	x26, x25, [sp, #32]
   36db8:	ldp	x28, x27, [sp, #16]
   36dbc:	ldp	x29, x30, [sp], #96
   36dc0:	ret
   36dc4:	sub	x0, x29, #0x8
   36dc8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   36dcc:	b	36730 <__gmpn_toom42_mul@@Base+0x84>
   36dd0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   36dd4:	b	36da4 <__gmpn_toom42_mul@@Base+0x6f8>

0000000000036dd8 <__gmpn_toom52_mul@@Base>:
   36dd8:	sub	sp, sp, #0xe0
   36ddc:	add	x8, x4, x4, lsl #2
   36de0:	stp	x28, x27, [sp, #144]
   36de4:	stp	x22, x21, [sp, #192]
   36de8:	stp	x20, x19, [sp, #208]
   36dec:	mov	x19, x5
   36df0:	mov	x27, x4
   36df4:	mov	x20, x3
   36df8:	mov	x22, x1
   36dfc:	cmp	x8, x2, lsl #1
   36e00:	mov	x21, x0
   36e04:	stp	x29, x30, [sp, #128]
   36e08:	stp	x26, x25, [sp, #160]
   36e0c:	stp	x24, x23, [sp, #176]
   36e10:	add	x29, sp, #0x80
   36e14:	b.le	36e24 <__gmpn_toom52_mul@@Base+0x4c>
   36e18:	sub	x8, x27, #0x1
   36e1c:	asr	x26, x8, #1
   36e20:	b	36e38 <__gmpn_toom52_mul@@Base+0x60>
   36e24:	mov	x9, #0xcccccccccccccccc    	// #-3689348814741910324
   36e28:	sub	x8, x2, #0x1
   36e2c:	movk	x9, #0xcccd
   36e30:	umulh	x8, x8, x9
   36e34:	lsr	x26, x8, #2
   36e38:	add	x23, x26, #0x1
   36e3c:	add	x8, x23, x23, lsl #1
   36e40:	add	x10, x19, x23, lsl #5
   36e44:	add	x9, x21, x8, lsl #3
   36e48:	add	x8, x19, x8, lsl #3
   36e4c:	sub	x5, x2, x23, lsl #2
   36e50:	add	x1, x10, #0x20
   36e54:	add	x0, x9, #0x18
   36e58:	add	x6, x8, #0x18
   36e5c:	mov	w2, #0x4                   	// #4
   36e60:	mov	x3, x22
   36e64:	mov	x4, x23
   36e68:	sub	x24, x27, x23
   36e6c:	str	x10, [sp, #64]
   36e70:	stur	x0, [x29, #-56]
   36e74:	stp	x5, x1, [sp, #48]
   36e78:	str	x6, [sp, #40]
   36e7c:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   36e80:	mov	x3, x24
   36e84:	and	w28, w0, #0x2
   36e88:	subs	x24, x23, x24
   36e8c:	add	x25, x20, x23, lsl #3
   36e90:	stp	x3, x19, [x29, #-16]
   36e94:	stur	x22, [x29, #-48]
   36e98:	stur	x25, [x29, #-24]
   36e9c:	b.ne	36f18 <__gmpn_toom52_mul@@Base+0x140>  // b.any
   36ea0:	mov	x0, x21
   36ea4:	mov	x1, x20
   36ea8:	mov	x2, x25
   36eac:	mov	x3, x23
   36eb0:	bl	ca90 <__gmpn_add_n@plt>
   36eb4:	mov	w8, #0x8                   	// #8
   36eb8:	bfi	x8, x26, #4, #60
   36ebc:	mov	x9, x26
   36ec0:	str	x0, [x21, x23, lsl #3]
   36ec4:	add	x10, x9, #0x1
   36ec8:	cmp	x10, #0x1
   36ecc:	b.lt	36eec <__gmpn_toom52_mul@@Base+0x114>  // b.tstop
   36ed0:	ldr	x10, [x20, x9, lsl #3]
   36ed4:	ldr	x11, [x20, x8]
   36ed8:	sub	x9, x9, #0x1
   36edc:	sub	x8, x8, #0x8
   36ee0:	cmp	x10, x11
   36ee4:	b.eq	36ec4 <__gmpn_toom52_mul@@Base+0xec>  // b.none
   36ee8:	b.ls	370a8 <__gmpn_toom52_mul@@Base+0x2d0>  // b.plast
   36eec:	add	x8, x19, x23, lsl #4
   36ef0:	lsl	x9, x23, #1
   36ef4:	add	x0, x8, #0x10
   36ef8:	mov	x1, x20
   36efc:	mov	x2, x25
   36f00:	mov	x3, x23
   36f04:	mov	x19, x9
   36f08:	bl	c2e0 <__gmpn_sub_n@plt>
   36f0c:	ldur	x3, [x29, #-16]
   36f10:	mov	w22, w28
   36f14:	b	37124 <__gmpn_toom52_mul@@Base+0x34c>
   36f18:	cbz	x3, 36f64 <__gmpn_toom52_mul@@Base+0x18c>
   36f1c:	mov	x0, x21
   36f20:	mov	x1, x20
   36f24:	mov	x2, x25
   36f28:	bl	ca90 <__gmpn_add_n@plt>
   36f2c:	ldur	x3, [x29, #-16]
   36f30:	mov	x9, x3
   36f34:	cbz	x0, 36f68 <__gmpn_toom52_mul@@Base+0x190>
   36f38:	mov	w8, #0x1                   	// #1
   36f3c:	mov	x10, x3
   36f40:	cmp	x10, x26
   36f44:	b.gt	36fa0 <__gmpn_toom52_mul@@Base+0x1c8>
   36f48:	ldr	x9, [x20, x10, lsl #3]
   36f4c:	adds	x11, x9, #0x1
   36f50:	add	x9, x10, #0x1
   36f54:	str	x11, [x21, x10, lsl #3]
   36f58:	mov	x10, x9
   36f5c:	b.cs	36f40 <__gmpn_toom52_mul@@Base+0x168>  // b.hs, b.nlast
   36f60:	b	36f68 <__gmpn_toom52_mul@@Base+0x190>
   36f64:	mov	x9, xzr
   36f68:	cmp	x21, x20
   36f6c:	mov	x8, xzr
   36f70:	b.eq	36fa0 <__gmpn_toom52_mul@@Base+0x1c8>  // b.none
   36f74:	cmp	x9, x26
   36f78:	b.gt	36fa0 <__gmpn_toom52_mul@@Base+0x1c8>
   36f7c:	sub	x10, x26, x9
   36f80:	add	x8, x21, x9, lsl #3
   36f84:	add	x10, x10, #0x1
   36f88:	add	x9, x20, x9, lsl #3
   36f8c:	ldr	x11, [x9], #8
   36f90:	subs	x10, x10, #0x1
   36f94:	str	x11, [x8], #8
   36f98:	b.ne	36f8c <__gmpn_toom52_mul@@Base+0x1b4>  // b.any
   36f9c:	mov	x8, xzr
   36fa0:	str	x8, [x21, x23, lsl #3]
   36fa4:	sub	x8, x27, x26, lsl #1
   36fa8:	sub	x8, x8, #0x2
   36fac:	lsl	x9, x26, #3
   36fb0:	ldr	x10, [x20, x9]
   36fb4:	cbnz	x10, 36ffc <__gmpn_toom52_mul@@Base+0x224>
   36fb8:	adds	x8, x8, #0x1
   36fbc:	sub	x9, x9, #0x8
   36fc0:	b.cc	36fb0 <__gmpn_toom52_mul@@Base+0x1d8>  // b.lo, b.ul, b.last
   36fc4:	sub	x8, x27, x26
   36fc8:	lsl	x9, x27, #3
   36fcc:	sub	x8, x8, #0x2
   36fd0:	sub	x9, x9, #0x8
   36fd4:	add	x10, x8, #0x1
   36fd8:	cmp	x10, #0x1
   36fdc:	b.lt	36ffc <__gmpn_toom52_mul@@Base+0x224>  // b.tstop
   36fe0:	ldr	x10, [x20, x8, lsl #3]
   36fe4:	ldr	x11, [x20, x9]
   36fe8:	sub	x8, x8, #0x1
   36fec:	sub	x9, x9, #0x8
   36ff0:	cmp	x10, x11
   36ff4:	b.eq	36fd4 <__gmpn_toom52_mul@@Base+0x1fc>  // b.none
   36ff8:	b.ls	370d0 <__gmpn_toom52_mul@@Base+0x2f8>  // b.plast
   36ffc:	add	x8, x19, x23, lsl #4
   37000:	lsl	x24, x23, #1
   37004:	add	x22, x8, #0x10
   37008:	cbz	x3, 37058 <__gmpn_toom52_mul@@Base+0x280>
   3700c:	mov	x0, x22
   37010:	mov	x1, x20
   37014:	mov	x2, x25
   37018:	bl	c2e0 <__gmpn_sub_n@plt>
   3701c:	ldur	x3, [x29, #-16]
   37020:	mov	x8, x3
   37024:	cbz	x0, 3705c <__gmpn_toom52_mul@@Base+0x284>
   37028:	add	x8, x26, x27
   3702c:	add	x8, x19, x8, lsl #3
   37030:	add	x9, x8, #0x18
   37034:	mov	x8, x3
   37038:	cmp	x8, x26
   3703c:	b.gt	3709c <__gmpn_toom52_mul@@Base+0x2c4>
   37040:	ldr	x10, [x20, x8, lsl #3]
   37044:	add	x8, x8, #0x1
   37048:	sub	x11, x10, #0x1
   3704c:	str	x11, [x9], #8
   37050:	cbz	x10, 37038 <__gmpn_toom52_mul@@Base+0x260>
   37054:	b	3705c <__gmpn_toom52_mul@@Base+0x284>
   37058:	mov	x8, xzr
   3705c:	cmp	x22, x20
   37060:	b.eq	3709c <__gmpn_toom52_mul@@Base+0x2c4>  // b.none
   37064:	cmp	x8, x26
   37068:	mov	w22, w28
   3706c:	b.gt	370a0 <__gmpn_toom52_mul@@Base+0x2c8>
   37070:	add	x10, x8, x26, lsl #1
   37074:	sub	x9, x26, x8
   37078:	add	x10, x19, x10, lsl #3
   3707c:	add	x9, x9, #0x1
   37080:	add	x10, x10, #0x20
   37084:	add	x8, x20, x8, lsl #3
   37088:	ldr	x11, [x8], #8
   3708c:	subs	x9, x9, #0x1
   37090:	str	x11, [x10], #8
   37094:	b.ne	37088 <__gmpn_toom52_mul@@Base+0x2b0>  // b.any
   37098:	b	370a0 <__gmpn_toom52_mul@@Base+0x2c8>
   3709c:	mov	w22, w28
   370a0:	mov	x19, x24
   370a4:	b	37124 <__gmpn_toom52_mul@@Base+0x34c>
   370a8:	add	x8, x19, x23, lsl #4
   370ac:	lsl	x9, x23, #1
   370b0:	add	x0, x8, #0x10
   370b4:	mov	x1, x25
   370b8:	mov	x2, x20
   370bc:	mov	x3, x23
   370c0:	mov	x19, x9
   370c4:	bl	c2e0 <__gmpn_sub_n@plt>
   370c8:	ldur	x3, [x29, #-16]
   370cc:	b	3711c <__gmpn_toom52_mul@@Base+0x344>
   370d0:	lsl	x8, x23, #1
   370d4:	str	x8, [sp, #8]
   370d8:	add	x8, x19, x23, lsl #4
   370dc:	add	x22, x8, #0x10
   370e0:	mov	x0, x22
   370e4:	mov	x1, x25
   370e8:	mov	x2, x20
   370ec:	mov	x19, x3
   370f0:	bl	c2e0 <__gmpn_sub_n@plt>
   370f4:	cbz	x24, 37114 <__gmpn_toom52_mul@@Base+0x33c>
   370f8:	lsl	x8, x26, #1
   370fc:	sub	x8, x8, x27
   37100:	lsl	x8, x8, #3
   37104:	add	x0, x22, x19, lsl #3
   37108:	add	x2, x8, #0x10
   3710c:	mov	w1, wzr
   37110:	bl	c610 <memset@plt>
   37114:	mov	x3, x19
   37118:	ldr	x19, [sp, #8]
   3711c:	mov	w22, w28
   37120:	orr	w22, w28, #0x1
   37124:	add	x25, x21, x19, lsl #3
   37128:	add	x24, x25, #0x10
   3712c:	add	x28, x26, #0x2
   37130:	cbz	x3, 37188 <__gmpn_toom52_mul@@Base+0x3b0>
   37134:	ldur	x2, [x29, #-24]
   37138:	mov	x0, x24
   3713c:	mov	x1, x21
   37140:	bl	ca90 <__gmpn_add_n@plt>
   37144:	ldur	x3, [x29, #-16]
   37148:	mov	x8, x3
   3714c:	cbz	x0, 3718c <__gmpn_toom52_mul@@Base+0x3b4>
   37150:	add	x8, x19, x27
   37154:	lsl	x8, x8, #3
   37158:	sub	x8, x8, x26, lsl #3
   3715c:	add	x9, x8, #0x8
   37160:	mov	x8, x3
   37164:	cmp	x8, x28
   37168:	b.ge	371c4 <__gmpn_toom52_mul@@Base+0x3ec>  // b.tcont
   3716c:	ldr	x10, [x21, x8, lsl #3]
   37170:	add	x8, x8, #0x1
   37174:	adds	x10, x10, #0x1
   37178:	str	x10, [x21, x9]
   3717c:	add	x9, x9, #0x8
   37180:	b.cs	37164 <__gmpn_toom52_mul@@Base+0x38c>  // b.hs, b.nlast
   37184:	b	3718c <__gmpn_toom52_mul@@Base+0x3b4>
   37188:	mov	x8, xzr
   3718c:	cmp	x24, x21
   37190:	b.eq	371c4 <__gmpn_toom52_mul@@Base+0x3ec>  // b.none
   37194:	cmp	x8, x28
   37198:	b.ge	371c4 <__gmpn_toom52_mul@@Base+0x3ec>  // b.tcont
   3719c:	sub	x9, x26, x8
   371a0:	lsl	x10, x19, #3
   371a4:	add	x9, x9, #0x2
   371a8:	add	x10, x10, #0x10
   371ac:	add	x8, x21, x8, lsl #3
   371b0:	ldr	x11, [x8]
   371b4:	subs	x9, x9, #0x1
   371b8:	str	x11, [x8, x10]
   371bc:	add	x8, x8, #0x8
   371c0:	b.ne	371b0 <__gmpn_toom52_mul@@Base+0x3d8>  // b.any
   371c4:	lsl	x8, x23, #2
   371c8:	str	x24, [sp, #16]
   371cc:	stp	x21, x8, [x29, #-40]
   371d0:	add	x8, x21, x23, lsl #3
   371d4:	add	x13, x8, #0x8
   371d8:	stp	x28, x25, [sp, #24]
   371dc:	str	x13, [sp]
   371e0:	tbnz	w22, #0, 37244 <__gmpn_toom52_mul@@Base+0x46c>
   371e4:	ldur	x10, [x29, #-8]
   371e8:	subs	x14, x23, x3
   371ec:	str	xzr, [x13, x23, lsl #3]
   371f0:	add	x8, x10, x19, lsl #3
   371f4:	add	x24, x8, #0x10
   371f8:	b.ne	372cc <__gmpn_toom52_mul@@Base+0x4f4>  // b.any
   371fc:	add	x8, x20, x26, lsl #4
   37200:	add	x8, x8, #0x8
   37204:	add	x9, x26, #0x1
   37208:	cmp	x9, #0x1
   3720c:	b.lt	37228 <__gmpn_toom52_mul@@Base+0x450>  // b.tstop
   37210:	ldr	x9, [x24, x26, lsl #3]
   37214:	ldr	x10, [x8], #-8
   37218:	sub	x26, x26, #0x1
   3721c:	cmp	x9, x10
   37220:	b.eq	37204 <__gmpn_toom52_mul@@Base+0x42c>  // b.none
   37224:	b.ls	375b0 <__gmpn_toom52_mul@@Base+0x7d8>  // b.plast
   37228:	ldur	x2, [x29, #-24]
   3722c:	mov	x0, x13
   37230:	mov	x1, x24
   37234:	mov	x3, x23
   37238:	mov	x28, x19
   3723c:	bl	c2e0 <__gmpn_sub_n@plt>
   37240:	b	3746c <__gmpn_toom52_mul@@Base+0x694>
   37244:	ldur	x8, [x29, #-8]
   37248:	str	x19, [sp, #8]
   3724c:	add	x8, x8, x19, lsl #3
   37250:	add	x24, x8, #0x10
   37254:	cbz	x3, 373a4 <__gmpn_toom52_mul@@Base+0x5cc>
   37258:	ldur	x2, [x29, #-24]
   3725c:	mov	x0, x13
   37260:	mov	x1, x24
   37264:	mov	x19, x27
   37268:	mov	w27, w22
   3726c:	mov	x25, x13
   37270:	bl	ca90 <__gmpn_add_n@plt>
   37274:	ldur	x12, [x29, #-16]
   37278:	mov	x13, x25
   3727c:	mov	x8, x12
   37280:	cbz	x0, 373a8 <__gmpn_toom52_mul@@Base+0x5d0>
   37284:	ldr	x9, [sp, #8]
   37288:	add	x8, x21, x19, lsl #3
   3728c:	add	x10, x8, #0x8
   37290:	add	x9, x9, x19
   37294:	sub	x8, x9, x26
   37298:	ldur	x9, [x29, #-8]
   3729c:	add	x8, x9, x8, lsl #3
   372a0:	add	x11, x8, #0x8
   372a4:	mov	w9, #0x1                   	// #1
   372a8:	mov	x8, x12
   372ac:	cmp	x8, x26
   372b0:	b.gt	373fc <__gmpn_toom52_mul@@Base+0x624>
   372b4:	ldr	x12, [x11], #8
   372b8:	add	x8, x8, #0x1
   372bc:	adds	x12, x12, #0x1
   372c0:	str	x12, [x10], #8
   372c4:	b.cs	372ac <__gmpn_toom52_mul@@Base+0x4d4>  // b.hs, b.nlast
   372c8:	b	373a8 <__gmpn_toom52_mul@@Base+0x5d0>
   372cc:	add	x9, x19, x26
   372d0:	sub	x8, x27, x26, lsl #1
   372d4:	add	x9, x10, x9, lsl #3
   372d8:	sub	x8, x8, #0x2
   372dc:	add	x9, x9, #0x10
   372e0:	ldr	x10, [x9]
   372e4:	cbnz	x10, 3732c <__gmpn_toom52_mul@@Base+0x554>
   372e8:	adds	x8, x8, #0x1
   372ec:	sub	x9, x9, #0x8
   372f0:	b.cc	372e0 <__gmpn_toom52_mul@@Base+0x508>  // b.lo, b.ul, b.last
   372f4:	ldur	x10, [x29, #-8]
   372f8:	add	x9, x19, x27
   372fc:	add	x8, x20, x27, lsl #3
   37300:	sub	x9, x9, x26
   37304:	sub	x8, x8, #0x8
   37308:	add	x9, x10, x9, lsl #3
   3730c:	mov	x10, x3
   37310:	subs	x10, x10, #0x1
   37314:	b.lt	3732c <__gmpn_toom52_mul@@Base+0x554>  // b.tstop
   37318:	ldr	x11, [x9], #-8
   3731c:	ldr	x12, [x8], #-8
   37320:	cmp	x11, x12
   37324:	b.eq	37310 <__gmpn_toom52_mul@@Base+0x538>  // b.none
   37328:	b.ls	375cc <__gmpn_toom52_mul@@Base+0x7f4>  // b.plast
   3732c:	str	x19, [sp, #8]
   37330:	cbz	x3, 37410 <__gmpn_toom52_mul@@Base+0x638>
   37334:	ldur	x2, [x29, #-24]
   37338:	mov	x0, x13
   3733c:	mov	x1, x24
   37340:	mov	x19, x27
   37344:	mov	w27, w22
   37348:	mov	x25, x13
   3734c:	bl	c2e0 <__gmpn_sub_n@plt>
   37350:	ldur	x11, [x29, #-16]
   37354:	mov	x13, x25
   37358:	mov	x8, x11
   3735c:	cbz	x0, 37414 <__gmpn_toom52_mul@@Base+0x63c>
   37360:	ldr	x9, [sp, #8]
   37364:	add	x8, x21, x19, lsl #3
   37368:	add	x10, x9, x19
   3736c:	add	x9, x8, #0x8
   37370:	sub	x8, x10, x26
   37374:	ldur	x10, [x29, #-8]
   37378:	add	x8, x10, x8, lsl #3
   3737c:	add	x10, x8, #0x8
   37380:	mov	x8, x11
   37384:	cmp	x8, x26
   37388:	b.gt	37468 <__gmpn_toom52_mul@@Base+0x690>
   3738c:	ldr	x11, [x10], #8
   37390:	add	x8, x8, #0x1
   37394:	sub	x12, x11, #0x1
   37398:	str	x12, [x9], #8
   3739c:	cbz	x11, 37384 <__gmpn_toom52_mul@@Base+0x5ac>
   373a0:	b	37414 <__gmpn_toom52_mul@@Base+0x63c>
   373a4:	mov	x8, xzr
   373a8:	cmp	x13, x24
   373ac:	mov	x9, xzr
   373b0:	b.eq	373fc <__gmpn_toom52_mul@@Base+0x624>  // b.none
   373b4:	ldr	x12, [sp, #8]
   373b8:	cmp	x8, x26
   373bc:	b.gt	37400 <__gmpn_toom52_mul@@Base+0x628>
   373c0:	sub	x9, x26, x8
   373c4:	add	x10, x8, x26
   373c8:	add	x11, x12, x8
   373cc:	add	x8, x9, #0x1
   373d0:	add	x9, x21, x10, lsl #3
   373d4:	ldur	x10, [x29, #-8]
   373d8:	add	x9, x9, #0x10
   373dc:	add	x10, x10, x11, lsl #3
   373e0:	add	x10, x10, #0x10
   373e4:	ldr	x11, [x10], #8
   373e8:	subs	x8, x8, #0x1
   373ec:	str	x11, [x9], #8
   373f0:	b.ne	373e4 <__gmpn_toom52_mul@@Base+0x60c>  // b.any
   373f4:	mov	x9, xzr
   373f8:	b	37400 <__gmpn_toom52_mul@@Base+0x628>
   373fc:	ldr	x12, [sp, #8]
   37400:	mov	x28, x12
   37404:	str	x9, [x13, x23, lsl #3]
   37408:	eor	w25, w22, #0x2
   3740c:	b	37470 <__gmpn_toom52_mul@@Base+0x698>
   37410:	mov	x8, xzr
   37414:	cmp	x13, x24
   37418:	b.eq	37468 <__gmpn_toom52_mul@@Base+0x690>  // b.none
   3741c:	cmp	x8, x26
   37420:	b.gt	37468 <__gmpn_toom52_mul@@Base+0x690>
   37424:	ldr	x11, [sp, #8]
   37428:	sub	x9, x26, x8
   3742c:	add	x10, x8, x26
   37430:	mov	w25, w22
   37434:	mov	x28, x11
   37438:	add	x11, x11, x8
   3743c:	add	x8, x9, #0x1
   37440:	add	x9, x21, x10, lsl #3
   37444:	ldur	x10, [x29, #-8]
   37448:	add	x9, x9, #0x10
   3744c:	add	x10, x10, x11, lsl #3
   37450:	add	x10, x10, #0x10
   37454:	ldr	x11, [x10], #8
   37458:	subs	x8, x8, #0x1
   3745c:	str	x11, [x9], #8
   37460:	b.ne	37454 <__gmpn_toom52_mul@@Base+0x67c>  // b.any
   37464:	b	37470 <__gmpn_toom52_mul@@Base+0x698>
   37468:	ldr	x28, [sp, #8]
   3746c:	mov	w25, w22
   37470:	ldp	x21, x8, [x29, #-40]
   37474:	ldp	x24, x19, [sp, #40]
   37478:	ldur	x22, [x29, #-48]
   3747c:	ldur	x27, [x29, #-8]
   37480:	add	x8, x21, x8, lsl #3
   37484:	add	x26, x8, #0x20
   37488:	mov	w2, #0x4                   	// #4
   3748c:	mov	x0, x26
   37490:	mov	x1, x24
   37494:	mov	x3, x22
   37498:	mov	x4, x23
   3749c:	mov	x5, x19
   374a0:	mov	x6, x27
   374a4:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   374a8:	mov	x1, x24
   374ac:	ldr	x24, [sp, #24]
   374b0:	and	w8, w0, #0x1
   374b4:	add	x28, x27, x28, lsl #3
   374b8:	eor	w8, w8, w25
   374bc:	add	x3, x28, #0x10
   374c0:	mov	x0, x27
   374c4:	mov	x2, x24
   374c8:	mov	x4, x23
   374cc:	str	w8, [sp, #8]
   374d0:	bl	ccf0 <__gmpn_mul@plt>
   374d4:	ldr	x1, [sp, #56]
   374d8:	ldr	x2, [sp]
   374dc:	add	x28, x28, #0x8
   374e0:	mov	x0, x28
   374e4:	mov	x3, x24
   374e8:	bl	c9b0 <__gmpn_mul_n@plt>
   374ec:	ldr	x8, [sp, #64]
   374f0:	ldur	x1, [x29, #-56]
   374f4:	ldr	x2, [sp, #16]
   374f8:	mov	x3, x24
   374fc:	add	x27, x8, #0x10
   37500:	mov	x0, x27
   37504:	bl	c9b0 <__gmpn_mul_n@plt>
   37508:	ldr	x0, [sp, #32]
   3750c:	mov	x1, x26
   37510:	mov	x2, x21
   37514:	mov	x3, x24
   37518:	bl	c9b0 <__gmpn_mul_n@plt>
   3751c:	mov	w8, #0x28                  	// #40
   37520:	ldur	x25, [x29, #-16]
   37524:	madd	x0, x23, x8, x21
   37528:	ldur	x8, [x29, #-32]
   3752c:	cmp	x19, x25
   37530:	add	x3, x22, x8, lsl #3
   37534:	b.le	3754c <__gmpn_toom52_mul@@Base+0x774>
   37538:	mov	x1, x3
   3753c:	ldur	x3, [x29, #-24]
   37540:	mov	x2, x19
   37544:	mov	x4, x25
   37548:	b	37558 <__gmpn_toom52_mul@@Base+0x780>
   3754c:	ldur	x1, [x29, #-24]
   37550:	mov	x2, x25
   37554:	mov	x4, x19
   37558:	bl	ccf0 <__gmpn_mul@plt>
   3755c:	ldur	x21, [x29, #-40]
   37560:	mov	x1, x22
   37564:	mov	x2, x20
   37568:	mov	x3, x23
   3756c:	mov	x0, x21
   37570:	bl	c9b0 <__gmpn_mul_n@plt>
   37574:	add	x6, x19, x25
   37578:	mov	x0, x21
   3757c:	mov	x1, x23
   37580:	ldr	w2, [sp, #8]
   37584:	ldur	x3, [x29, #-8]
   37588:	mov	x4, x28
   3758c:	mov	x5, x27
   37590:	ldp	x20, x19, [sp, #208]
   37594:	ldp	x22, x21, [sp, #192]
   37598:	ldp	x24, x23, [sp, #176]
   3759c:	ldp	x26, x25, [sp, #160]
   375a0:	ldp	x28, x27, [sp, #144]
   375a4:	ldp	x29, x30, [sp, #128]
   375a8:	add	sp, sp, #0xe0
   375ac:	b	c930 <__gmpn_toom_interpolate_6pts@plt>
   375b0:	ldur	x1, [x29, #-24]
   375b4:	mov	x0, x13
   375b8:	mov	x2, x24
   375bc:	mov	x3, x23
   375c0:	mov	x28, x19
   375c4:	bl	c2e0 <__gmpn_sub_n@plt>
   375c8:	b	37408 <__gmpn_toom52_mul@@Base+0x630>
   375cc:	ldur	x1, [x29, #-24]
   375d0:	mov	x0, x13
   375d4:	mov	x2, x24
   375d8:	mov	x28, x19
   375dc:	mov	x21, x13
   375e0:	mov	x19, x3
   375e4:	mov	x24, x14
   375e8:	bl	c2e0 <__gmpn_sub_n@plt>
   375ec:	cbz	x24, 37408 <__gmpn_toom52_mul@@Base+0x630>
   375f0:	lsl	x8, x26, #1
   375f4:	sub	x8, x8, x27
   375f8:	lsl	x8, x8, #3
   375fc:	add	x0, x21, x19, lsl #3
   37600:	add	x2, x8, #0x10
   37604:	mov	w1, wzr
   37608:	bl	c610 <memset@plt>
   3760c:	b	37408 <__gmpn_toom52_mul@@Base+0x630>

0000000000037610 <__gmpn_toom62_mul@@Base>:
   37610:	stp	x29, x30, [sp, #-96]!
   37614:	stp	x28, x27, [sp, #16]
   37618:	stp	x26, x25, [sp, #32]
   3761c:	stp	x24, x23, [sp, #48]
   37620:	stp	x22, x21, [sp, #64]
   37624:	stp	x20, x19, [sp, #80]
   37628:	mov	x29, sp
   3762c:	sub	sp, sp, #0xc0
   37630:	add	x8, x4, x4, lsl #1
   37634:	mov	x25, x3
   37638:	mov	x23, x1
   3763c:	cmp	x8, x2
   37640:	mov	x20, x0
   37644:	stur	x5, [x29, #-40]
   37648:	b.le	37658 <__gmpn_toom62_mul@@Base+0x48>
   3764c:	sub	x8, x4, #0x1
   37650:	asr	x24, x8, #1
   37654:	b	3766c <__gmpn_toom62_mul@@Base+0x5c>
   37658:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   3765c:	sub	x8, x2, #0x1
   37660:	movk	x9, #0xaaab
   37664:	umulh	x8, x8, x9
   37668:	lsr	x24, x8, #2
   3766c:	add	x21, x24, #0x1
   37670:	add	x9, x24, #0x2
   37674:	sub	x8, x4, x21
   37678:	stur	x8, [x29, #-48]
   3767c:	lsl	x8, x9, #3
   37680:	add	x8, x8, #0xf
   37684:	add	x22, x21, x21, lsl #2
   37688:	stur	x9, [x29, #-120]
   3768c:	mov	x9, sp
   37690:	and	x8, x8, #0xfffffffffffffff0
   37694:	sub	x19, x2, x22
   37698:	sub	x0, x9, x8
   3769c:	stur	x4, [x29, #-80]
   376a0:	stur	x2, [x29, #-24]
   376a4:	mov	sp, x0
   376a8:	mov	x9, sp
   376ac:	sub	x1, x9, x8
   376b0:	mov	sp, x1
   376b4:	mov	x9, sp
   376b8:	sub	x27, x9, x8
   376bc:	mov	sp, x27
   376c0:	mov	x9, sp
   376c4:	sub	x26, x9, x8
   376c8:	mov	sp, x26
   376cc:	mov	x9, sp
   376d0:	sub	x28, x9, x8
   376d4:	mov	sp, x28
   376d8:	mov	x9, sp
   376dc:	sub	x9, x9, x8
   376e0:	stur	x9, [x29, #-144]
   376e4:	mov	sp, x9
   376e8:	lsl	x10, x21, #3
   376ec:	stur	x10, [x29, #-96]
   376f0:	add	x10, x10, #0xf
   376f4:	mov	x9, sp
   376f8:	and	x10, x10, #0xfffffffffffffff0
   376fc:	sub	x9, x9, x10
   37700:	stur	x9, [x29, #-128]
   37704:	mov	sp, x9
   37708:	mov	x9, sp
   3770c:	sub	x9, x9, x8
   37710:	stur	x9, [x29, #-56]
   37714:	mov	sp, x9
   37718:	mov	x9, sp
   3771c:	sub	x9, x9, x8
   37720:	stur	x9, [x29, #-168]
   37724:	mov	sp, x9
   37728:	mov	x9, sp
   3772c:	sub	x8, x9, x8
   37730:	stur	x8, [x29, #-160]
   37734:	mov	sp, x8
   37738:	mov	w2, #0x5                   	// #5
   3773c:	mov	x3, x23
   37740:	mov	x4, x21
   37744:	mov	x5, x19
   37748:	mov	x6, x20
   3774c:	stur	x0, [x29, #-72]
   37750:	stur	x1, [x29, #-112]
   37754:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   37758:	stur	w0, [x29, #-104]
   3775c:	mov	w2, #0x5                   	// #5
   37760:	mov	x0, x27
   37764:	mov	x1, x26
   37768:	mov	x3, x23
   3776c:	mov	x4, x21
   37770:	mov	x5, x19
   37774:	mov	x6, x20
   37778:	stur	x27, [x29, #-136]
   3777c:	stur	x26, [x29, #-192]
   37780:	stur	x20, [x29, #-64]
   37784:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   37788:	stur	w0, [x29, #-100]
   3778c:	add	x1, x23, x21, lsl #3
   37790:	mov	x0, x28
   37794:	mov	x2, x23
   37798:	mov	x3, x21
   3779c:	bl	cc60 <__gmpn_addlsh1_n@plt>
   377a0:	stur	x23, [x29, #-16]
   377a4:	ldur	x8, [x29, #-16]
   377a8:	mov	x23, x0
   377ac:	mov	x0, x28
   377b0:	mov	x2, x28
   377b4:	add	x1, x8, x21, lsl #4
   377b8:	mov	x3, x21
   377bc:	bl	cc60 <__gmpn_addlsh1_n@plt>
   377c0:	add	x20, x0, x23, lsl #1
   377c4:	ldur	x23, [x29, #-16]
   377c8:	mov	w8, #0x18                  	// #24
   377cc:	mov	x0, x28
   377d0:	mov	x2, x28
   377d4:	madd	x1, x21, x8, x23
   377d8:	mov	x3, x21
   377dc:	bl	cc60 <__gmpn_addlsh1_n@plt>
   377e0:	add	x20, x0, x20, lsl #1
   377e4:	add	x1, x23, x21, lsl #5
   377e8:	mov	x0, x28
   377ec:	mov	x2, x28
   377f0:	mov	x3, x21
   377f4:	bl	cc60 <__gmpn_addlsh1_n@plt>
   377f8:	cmp	x24, x19
   377fc:	add	x26, x0, x20, lsl #1
   37800:	add	x1, x23, x22, lsl #3
   37804:	mov	x0, x28
   37808:	mov	x2, x28
   3780c:	stur	x19, [x29, #-88]
   37810:	stur	x22, [x29, #-184]
   37814:	b.ge	3782c <__gmpn_toom62_mul@@Base+0x21c>  // b.tcont
   37818:	mov	x3, x21
   3781c:	bl	cc60 <__gmpn_addlsh1_n@plt>
   37820:	add	x8, x0, x26, lsl #1
   37824:	str	x8, [x28, x21, lsl #3]
   37828:	b	37890 <__gmpn_toom62_mul@@Base+0x280>
   3782c:	mov	x3, x19
   37830:	bl	cc60 <__gmpn_addlsh1_n@plt>
   37834:	add	x20, x28, x19, lsl #3
   37838:	mov	x23, x0
   3783c:	sub	x2, x21, x19
   37840:	mov	w3, #0x1                   	// #1
   37844:	mov	x0, x20
   37848:	mov	x1, x20
   3784c:	bl	c190 <__gmpn_lshift@plt>
   37850:	add	x8, x0, x26, lsl #1
   37854:	str	x8, [x28, x21, lsl #3]
   37858:	ldr	x8, [x20]
   3785c:	adds	x8, x8, x23
   37860:	str	x8, [x20]
   37864:	b.cc	37890 <__gmpn_toom62_mul@@Base+0x280>  // b.lo, b.ul, b.last
   37868:	ldur	x8, [x29, #-24]
   3786c:	mov	w9, #0x28                  	// #40
   37870:	lsl	x8, x8, #3
   37874:	msub	x8, x24, x9, x8
   37878:	add	x8, x8, x28
   3787c:	sub	x8, x8, #0x20
   37880:	ldr	x9, [x8]
   37884:	adds	x9, x9, #0x1
   37888:	str	x9, [x8], #8
   3788c:	b.cs	37880 <__gmpn_toom62_mul@@Base+0x270>  // b.hs, b.nlast
   37890:	ldur	x23, [x29, #-48]
   37894:	stur	x28, [x29, #-152]
   37898:	ldp	x28, x19, [x29, #-128]
   3789c:	ldur	x27, [x29, #-144]
   378a0:	ldur	x26, [x29, #-168]
   378a4:	subs	x20, x21, x23
   378a8:	add	x22, x25, x21, lsl #3
   378ac:	stur	x22, [x29, #-32]
   378b0:	b.ne	3791c <__gmpn_toom62_mul@@Base+0x30c>  // b.any
   378b4:	mov	x0, x27
   378b8:	mov	x1, x25
   378bc:	mov	x2, x22
   378c0:	mov	x3, x21
   378c4:	bl	ca90 <__gmpn_add_n@plt>
   378c8:	ldur	x20, [x29, #-56]
   378cc:	mov	w8, #0x8                   	// #8
   378d0:	bfi	x8, x24, #4, #60
   378d4:	mov	x9, x24
   378d8:	str	x0, [x27, x21, lsl #3]
   378dc:	add	x10, x9, #0x1
   378e0:	cmp	x10, #0x1
   378e4:	b.lt	37904 <__gmpn_toom62_mul@@Base+0x2f4>  // b.tstop
   378e8:	ldr	x10, [x25, x9, lsl #3]
   378ec:	ldr	x11, [x25, x8]
   378f0:	sub	x9, x9, #0x1
   378f4:	sub	x8, x8, #0x8
   378f8:	cmp	x10, x11
   378fc:	b.eq	378dc <__gmpn_toom62_mul@@Base+0x2cc>  // b.none
   37900:	b.ls	37ac4 <__gmpn_toom62_mul@@Base+0x4b4>  // b.plast
   37904:	mov	x0, x28
   37908:	mov	x1, x25
   3790c:	mov	x2, x22
   37910:	mov	x3, x21
   37914:	bl	c2e0 <__gmpn_sub_n@plt>
   37918:	b	37a78 <__gmpn_toom62_mul@@Base+0x468>
   3791c:	cbz	x23, 37968 <__gmpn_toom62_mul@@Base+0x358>
   37920:	mov	x0, x27
   37924:	mov	x1, x25
   37928:	mov	x2, x22
   3792c:	mov	x3, x23
   37930:	bl	ca90 <__gmpn_add_n@plt>
   37934:	mov	x9, x23
   37938:	cbz	x0, 3796c <__gmpn_toom62_mul@@Base+0x35c>
   3793c:	mov	w8, #0x1                   	// #1
   37940:	mov	x10, x23
   37944:	cmp	x10, x24
   37948:	b.gt	37998 <__gmpn_toom62_mul@@Base+0x388>
   3794c:	ldr	x9, [x25, x10, lsl #3]
   37950:	adds	x11, x9, #0x1
   37954:	add	x9, x10, #0x1
   37958:	str	x11, [x27, x10, lsl #3]
   3795c:	mov	x10, x9
   37960:	b.cs	37944 <__gmpn_toom62_mul@@Base+0x334>  // b.hs, b.nlast
   37964:	b	3796c <__gmpn_toom62_mul@@Base+0x35c>
   37968:	mov	x9, xzr
   3796c:	cmp	x27, x25
   37970:	mov	x8, xzr
   37974:	b.eq	37998 <__gmpn_toom62_mul@@Base+0x388>  // b.none
   37978:	cmp	x9, x24
   3797c:	b.gt	37998 <__gmpn_toom62_mul@@Base+0x388>
   37980:	sub	x8, x21, x9
   37984:	add	x0, x27, x9, lsl #3
   37988:	add	x1, x25, x9, lsl #3
   3798c:	lsl	x2, x8, #3
   37990:	bl	bee0 <memcpy@plt>
   37994:	mov	x8, xzr
   37998:	str	x8, [x27, x21, lsl #3]
   3799c:	ldur	x8, [x29, #-80]
   379a0:	lsl	x9, x24, #3
   379a4:	sub	x8, x8, x24, lsl #1
   379a8:	sub	x8, x8, #0x2
   379ac:	ldr	x10, [x25, x9]
   379b0:	cbnz	x10, 379fc <__gmpn_toom62_mul@@Base+0x3ec>
   379b4:	adds	x8, x8, #0x1
   379b8:	sub	x9, x9, #0x8
   379bc:	b.cc	379ac <__gmpn_toom62_mul@@Base+0x39c>  // b.lo, b.ul, b.last
   379c0:	ldur	x9, [x29, #-80]
   379c4:	sub	x8, x9, x24
   379c8:	lsl	x22, x9, #3
   379cc:	sub	x8, x8, #0x2
   379d0:	sub	x9, x22, #0x8
   379d4:	add	x10, x8, #0x1
   379d8:	cmp	x10, #0x1
   379dc:	b.lt	379fc <__gmpn_toom62_mul@@Base+0x3ec>  // b.tstop
   379e0:	ldr	x10, [x25, x8, lsl #3]
   379e4:	ldr	x11, [x25, x9]
   379e8:	sub	x8, x8, #0x1
   379ec:	sub	x9, x9, #0x8
   379f0:	cmp	x10, x11
   379f4:	b.eq	379d4 <__gmpn_toom62_mul@@Base+0x3c4>  // b.none
   379f8:	b.ls	37adc <__gmpn_toom62_mul@@Base+0x4cc>  // b.plast
   379fc:	cbz	x23, 37a48 <__gmpn_toom62_mul@@Base+0x438>
   37a00:	ldur	x2, [x29, #-32]
   37a04:	mov	x0, x28
   37a08:	mov	x1, x25
   37a0c:	mov	x3, x23
   37a10:	bl	c2e0 <__gmpn_sub_n@plt>
   37a14:	ldur	x20, [x29, #-56]
   37a18:	mov	x8, x23
   37a1c:	cbz	x0, 37a50 <__gmpn_toom62_mul@@Base+0x440>
   37a20:	mov	x9, x23
   37a24:	cmp	x9, x24
   37a28:	b.gt	37a78 <__gmpn_toom62_mul@@Base+0x468>
   37a2c:	ldr	x10, [x25, x9, lsl #3]
   37a30:	add	x8, x9, #0x1
   37a34:	sub	x11, x10, #0x1
   37a38:	str	x11, [x28, x9, lsl #3]
   37a3c:	mov	x9, x8
   37a40:	cbz	x10, 37a24 <__gmpn_toom62_mul@@Base+0x414>
   37a44:	b	37a50 <__gmpn_toom62_mul@@Base+0x440>
   37a48:	ldur	x20, [x29, #-56]
   37a4c:	mov	x8, xzr
   37a50:	cmp	x28, x25
   37a54:	mov	w22, wzr
   37a58:	b.eq	37a7c <__gmpn_toom62_mul@@Base+0x46c>  // b.none
   37a5c:	cmp	x8, x24
   37a60:	b.gt	37a7c <__gmpn_toom62_mul@@Base+0x46c>
   37a64:	add	x0, x28, x8, lsl #3
   37a68:	add	x1, x25, x8, lsl #3
   37a6c:	sub	x8, x21, x8
   37a70:	lsl	x2, x8, #3
   37a74:	bl	bee0 <memcpy@plt>
   37a78:	mov	w22, wzr
   37a7c:	cbz	x23, 37b28 <__gmpn_toom62_mul@@Base+0x518>
   37a80:	ldur	x2, [x29, #-32]
   37a84:	mov	x0, x20
   37a88:	mov	x1, x27
   37a8c:	mov	x3, x23
   37a90:	bl	ca90 <__gmpn_add_n@plt>
   37a94:	mov	x8, x23
   37a98:	cbz	x0, 37b2c <__gmpn_toom62_mul@@Base+0x51c>
   37a9c:	mov	x9, x23
   37aa0:	cmp	x9, x19
   37aa4:	b.ge	37b44 <__gmpn_toom62_mul@@Base+0x534>  // b.tcont
   37aa8:	ldr	x8, [x27, x9, lsl #3]
   37aac:	adds	x10, x8, #0x1
   37ab0:	add	x8, x9, #0x1
   37ab4:	str	x10, [x20, x9, lsl #3]
   37ab8:	mov	x9, x8
   37abc:	b.cs	37aa0 <__gmpn_toom62_mul@@Base+0x490>  // b.hs, b.nlast
   37ac0:	b	37b2c <__gmpn_toom62_mul@@Base+0x51c>
   37ac4:	mov	x0, x28
   37ac8:	mov	x1, x22
   37acc:	mov	x2, x25
   37ad0:	mov	x3, x21
   37ad4:	bl	c2e0 <__gmpn_sub_n@plt>
   37ad8:	b	37b20 <__gmpn_toom62_mul@@Base+0x510>
   37adc:	ldur	x1, [x29, #-32]
   37ae0:	mov	x0, x28
   37ae4:	mov	x2, x25
   37ae8:	mov	x3, x23
   37aec:	bl	c2e0 <__gmpn_sub_n@plt>
   37af0:	cbz	x20, 37b1c <__gmpn_toom62_mul@@Base+0x50c>
   37af4:	ldur	x10, [x29, #-80]
   37af8:	sub	x8, x22, x24, lsl #3
   37afc:	lsl	x9, x24, #1
   37b00:	add	x8, x8, x28
   37b04:	sub	x9, x9, x10
   37b08:	sub	x0, x8, #0x8
   37b0c:	lsl	x8, x9, #3
   37b10:	add	x2, x8, #0x10
   37b14:	mov	w1, wzr
   37b18:	bl	c610 <memset@plt>
   37b1c:	ldur	x20, [x29, #-56]
   37b20:	mov	w22, #0x2                   	// #2
   37b24:	cbnz	x23, 37a80 <__gmpn_toom62_mul@@Base+0x470>
   37b28:	mov	x8, xzr
   37b2c:	subs	x9, x19, x8
   37b30:	b.le	37b44 <__gmpn_toom62_mul@@Base+0x534>
   37b34:	add	x0, x20, x8, lsl #3
   37b38:	add	x1, x27, x8, lsl #3
   37b3c:	lsl	x2, x9, #3
   37b40:	bl	bee0 <memcpy@plt>
   37b44:	lsl	x8, x21, #1
   37b48:	lsl	x13, x21, #2
   37b4c:	stur	x8, [x29, #-24]
   37b50:	stur	x13, [x29, #-176]
   37b54:	cbz	w22, 37ba0 <__gmpn_toom62_mul@@Base+0x590>
   37b58:	cbz	x23, 37bf4 <__gmpn_toom62_mul@@Base+0x5e4>
   37b5c:	ldur	x2, [x29, #-32]
   37b60:	mov	x0, x26
   37b64:	mov	x1, x28
   37b68:	mov	x3, x23
   37b6c:	bl	ca90 <__gmpn_add_n@plt>
   37b70:	mov	x9, x23
   37b74:	cbz	x0, 37bf8 <__gmpn_toom62_mul@@Base+0x5e8>
   37b78:	mov	w8, #0x1                   	// #1
   37b7c:	cmp	x23, x24
   37b80:	b.gt	37c18 <__gmpn_toom62_mul@@Base+0x608>
   37b84:	ldr	x9, [x28, x23, lsl #3]
   37b88:	adds	x11, x9, #0x1
   37b8c:	add	x9, x23, #0x1
   37b90:	str	x11, [x26, x23, lsl #3]
   37b94:	mov	x23, x9
   37b98:	b.cs	37b7c <__gmpn_toom62_mul@@Base+0x56c>  // b.hs, b.nlast
   37b9c:	b	37bf8 <__gmpn_toom62_mul@@Base+0x5e8>
   37ba0:	cmp	x24, x23
   37ba4:	b.ge	37c30 <__gmpn_toom62_mul@@Base+0x620>  // b.tcont
   37ba8:	ldur	x2, [x29, #-32]
   37bac:	ldur	x23, [x29, #-192]
   37bb0:	add	x8, x25, x24, lsl #4
   37bb4:	add	x8, x8, #0x8
   37bb8:	add	x9, x24, #0x1
   37bbc:	cmp	x9, #0x1
   37bc0:	b.lt	37bdc <__gmpn_toom62_mul@@Base+0x5cc>  // b.tstop
   37bc4:	ldr	x9, [x28, x24, lsl #3]
   37bc8:	ldr	x10, [x8], #-8
   37bcc:	sub	x24, x24, #0x1
   37bd0:	cmp	x9, x10
   37bd4:	b.eq	37bb8 <__gmpn_toom62_mul@@Base+0x5a8>  // b.none
   37bd8:	b.ls	37d00 <__gmpn_toom62_mul@@Base+0x6f0>  // b.plast
   37bdc:	mov	x0, x26
   37be0:	mov	x1, x28
   37be4:	mov	x3, x21
   37be8:	bl	c2e0 <__gmpn_sub_n@plt>
   37bec:	stur	wzr, [x29, #-80]
   37bf0:	b	37d1c <__gmpn_toom62_mul@@Base+0x70c>
   37bf4:	mov	x9, xzr
   37bf8:	cmp	x9, x24
   37bfc:	b.gt	37c14 <__gmpn_toom62_mul@@Base+0x604>
   37c00:	sub	x8, x21, x9
   37c04:	add	x0, x26, x9, lsl #3
   37c08:	add	x1, x28, x9, lsl #3
   37c0c:	lsl	x2, x8, #3
   37c10:	bl	bee0 <memcpy@plt>
   37c14:	mov	x8, xzr
   37c18:	ldur	x24, [x29, #-72]
   37c1c:	ldur	x23, [x29, #-192]
   37c20:	str	x8, [x26, x21, lsl #3]
   37c24:	orr	w8, w22, #0x1
   37c28:	stur	w8, [x29, #-80]
   37c2c:	b	37d24 <__gmpn_toom62_mul@@Base+0x714>
   37c30:	ldur	x8, [x29, #-80]
   37c34:	ldur	x2, [x29, #-32]
   37c38:	add	x9, x28, x24, lsl #3
   37c3c:	sub	x8, x8, x24, lsl #1
   37c40:	sub	x8, x8, #0x2
   37c44:	ldr	x10, [x9]
   37c48:	cbnz	x10, 37c90 <__gmpn_toom62_mul@@Base+0x680>
   37c4c:	adds	x8, x8, #0x1
   37c50:	sub	x9, x9, #0x8
   37c54:	b.cc	37c44 <__gmpn_toom62_mul@@Base+0x634>  // b.lo, b.ul, b.last
   37c58:	ldur	x8, [x29, #-80]
   37c5c:	sub	x9, x28, #0x10
   37c60:	sub	x10, x8, x24
   37c64:	add	x8, x25, x8, lsl #3
   37c68:	sub	x8, x8, #0x8
   37c6c:	sub	x11, x10, #0x1
   37c70:	cmp	x11, #0x1
   37c74:	b.lt	37c90 <__gmpn_toom62_mul@@Base+0x680>  // b.tstop
   37c78:	ldr	x10, [x9, x10, lsl #3]
   37c7c:	ldr	x12, [x8], #-8
   37c80:	cmp	x10, x12
   37c84:	mov	x10, x11
   37c88:	b.eq	37c6c <__gmpn_toom62_mul@@Base+0x65c>  // b.none
   37c8c:	b.ls	37fa8 <__gmpn_toom62_mul@@Base+0x998>  // b.plast
   37c90:	cbz	x23, 37cd0 <__gmpn_toom62_mul@@Base+0x6c0>
   37c94:	mov	x0, x26
   37c98:	mov	x1, x28
   37c9c:	mov	x3, x23
   37ca0:	bl	c2e0 <__gmpn_sub_n@plt>
   37ca4:	mov	x8, x23
   37ca8:	cbz	x0, 37cd4 <__gmpn_toom62_mul@@Base+0x6c4>
   37cac:	cmp	x23, x24
   37cb0:	b.gt	37cf0 <__gmpn_toom62_mul@@Base+0x6e0>
   37cb4:	ldr	x10, [x28, x23, lsl #3]
   37cb8:	add	x8, x23, #0x1
   37cbc:	sub	x11, x10, #0x1
   37cc0:	str	x11, [x26, x23, lsl #3]
   37cc4:	mov	x23, x8
   37cc8:	cbz	x10, 37cac <__gmpn_toom62_mul@@Base+0x69c>
   37ccc:	b	37cd4 <__gmpn_toom62_mul@@Base+0x6c4>
   37cd0:	mov	x8, xzr
   37cd4:	cmp	x8, x24
   37cd8:	b.gt	37cf0 <__gmpn_toom62_mul@@Base+0x6e0>
   37cdc:	add	x0, x26, x8, lsl #3
   37ce0:	add	x1, x28, x8, lsl #3
   37ce4:	sub	x8, x21, x8
   37ce8:	lsl	x2, x8, #3
   37cec:	bl	bee0 <memcpy@plt>
   37cf0:	ldur	x24, [x29, #-72]
   37cf4:	ldur	x23, [x29, #-192]
   37cf8:	stur	wzr, [x29, #-80]
   37cfc:	b	37d20 <__gmpn_toom62_mul@@Base+0x710>
   37d00:	mov	x0, x26
   37d04:	mov	x1, x2
   37d08:	mov	x2, x28
   37d0c:	mov	x3, x21
   37d10:	bl	c2e0 <__gmpn_sub_n@plt>
   37d14:	mov	w8, #0x1                   	// #1
   37d18:	stur	w8, [x29, #-80]
   37d1c:	ldur	x24, [x29, #-72]
   37d20:	str	xzr, [x26, x21, lsl #3]
   37d24:	mov	x20, x26
   37d28:	ldur	x26, [x29, #-160]
   37d2c:	ldr	x22, [x27, x21, lsl #3]
   37d30:	mov	x1, x27
   37d34:	mov	x2, x25
   37d38:	mov	x0, x26
   37d3c:	mov	x3, x21
   37d40:	bl	ca90 <__gmpn_add_n@plt>
   37d44:	add	x8, x0, x22
   37d48:	ldur	x22, [x29, #-40]
   37d4c:	ldur	x1, [x29, #-136]
   37d50:	ldur	x2, [x29, #-56]
   37d54:	mov	x3, x19
   37d58:	mov	x0, x22
   37d5c:	str	x8, [x26, x21, lsl #3]
   37d60:	bl	c9b0 <__gmpn_mul_n@plt>
   37d64:	ldur	x8, [x29, #-24]
   37d68:	mov	x1, x23
   37d6c:	mov	x2, x20
   37d70:	mov	x3, x19
   37d74:	add	x8, x22, x8, lsl #3
   37d78:	add	x0, x8, #0x8
   37d7c:	stur	x0, [x29, #-56]
   37d80:	bl	c9b0 <__gmpn_mul_n@plt>
   37d84:	ldur	x8, [x29, #-176]
   37d88:	ldur	x1, [x29, #-152]
   37d8c:	mov	x2, x26
   37d90:	mov	x3, x19
   37d94:	add	x8, x22, x8, lsl #3
   37d98:	add	x20, x8, #0x10
   37d9c:	mov	x0, x20
   37da0:	bl	c9b0 <__gmpn_mul_n@plt>
   37da4:	add	x23, x21, x21, lsl #1
   37da8:	add	x8, x22, x23, lsl #4
   37dac:	ldur	x22, [x29, #-112]
   37db0:	add	x19, x8, #0x18
   37db4:	mov	x0, x19
   37db8:	mov	x2, x28
   37dbc:	mov	x1, x22
   37dc0:	mov	x3, x21
   37dc4:	bl	c9b0 <__gmpn_mul_n@plt>
   37dc8:	ldr	x8, [x22, x21, lsl #3]
   37dcc:	cmp	x8, #0x2
   37dd0:	b.eq	37df4 <__gmpn_toom62_mul@@Base+0x7e4>  // b.none
   37dd4:	cmp	x8, #0x1
   37dd8:	b.ne	37e0c <__gmpn_toom62_mul@@Base+0x7fc>  // b.any
   37ddc:	add	x0, x19, x21, lsl #3
   37de0:	mov	x1, x0
   37de4:	mov	x2, x28
   37de8:	mov	x3, x21
   37dec:	bl	ca90 <__gmpn_add_n@plt>
   37df0:	b	37e10 <__gmpn_toom62_mul@@Base+0x800>
   37df4:	add	x0, x19, x21, lsl #3
   37df8:	mov	x1, x0
   37dfc:	mov	x2, x28
   37e00:	mov	x3, x21
   37e04:	bl	cc60 <__gmpn_addlsh1_n@plt>
   37e08:	b	37e10 <__gmpn_toom62_mul@@Base+0x800>
   37e0c:	mov	x0, xzr
   37e10:	ldur	x8, [x29, #-64]
   37e14:	ldur	x9, [x29, #-24]
   37e18:	ldur	x28, [x29, #-184]
   37e1c:	mov	x1, x24
   37e20:	mov	x2, x27
   37e24:	add	x22, x8, x9, lsl #3
   37e28:	str	x0, [x19, x9, lsl #3]
   37e2c:	mov	x0, x22
   37e30:	mov	x3, x21
   37e34:	bl	c9b0 <__gmpn_mul_n@plt>
   37e38:	ldr	x26, [x24, x21, lsl #3]
   37e3c:	cbz	x26, 37eb8 <__gmpn_toom62_mul@@Base+0x8a8>
   37e40:	cmp	x26, #0x2
   37e44:	b.eq	37e70 <__gmpn_toom62_mul@@Base+0x860>  // b.none
   37e48:	cmp	x26, #0x1
   37e4c:	b.ne	37e90 <__gmpn_toom62_mul@@Base+0x880>  // b.any
   37e50:	ldr	x26, [x27, x21, lsl #3]
   37e54:	add	x0, x22, x21, lsl #3
   37e58:	mov	x1, x0
   37e5c:	mov	x2, x27
   37e60:	mov	x3, x21
   37e64:	bl	ca90 <__gmpn_add_n@plt>
   37e68:	add	x26, x0, x26
   37e6c:	b	37eb8 <__gmpn_toom62_mul@@Base+0x8a8>
   37e70:	ldr	x26, [x27, x21, lsl #3]
   37e74:	add	x0, x22, x21, lsl #3
   37e78:	mov	x1, x0
   37e7c:	mov	x2, x27
   37e80:	mov	x3, x21
   37e84:	bl	cc60 <__gmpn_addlsh1_n@plt>
   37e88:	add	x26, x0, x26, lsl #1
   37e8c:	b	37eb8 <__gmpn_toom62_mul@@Base+0x8a8>
   37e90:	mov	x24, x28
   37e94:	ldr	x28, [x27, x21, lsl #3]
   37e98:	add	x0, x22, x21, lsl #3
   37e9c:	mov	x1, x27
   37ea0:	mov	x2, x21
   37ea4:	mov	x3, x26
   37ea8:	bl	d420 <__gmpn_addmul_1@plt>
   37eac:	madd	x26, x28, x26, x0
   37eb0:	mov	x28, x24
   37eb4:	ldur	x24, [x29, #-72]
   37eb8:	ldur	w9, [x29, #-104]
   37ebc:	ldr	x8, [x27, x21, lsl #3]
   37ec0:	lsl	x23, x23, #1
   37ec4:	and	w27, w9, #0x2
   37ec8:	cbz	x8, 37ee4 <__gmpn_toom62_mul@@Base+0x8d4>
   37ecc:	add	x0, x22, x21, lsl #3
   37ed0:	mov	x1, x0
   37ed4:	mov	x2, x24
   37ed8:	mov	x3, x21
   37edc:	bl	ca90 <__gmpn_add_n@plt>
   37ee0:	add	x26, x0, x26
   37ee4:	ldur	w8, [x29, #-100]
   37ee8:	mov	x2, x25
   37eec:	mov	x3, x21
   37ef0:	bfxil	w27, w8, #0, #1
   37ef4:	ldur	x8, [x29, #-24]
   37ef8:	str	x26, [x22, x8, lsl #3]
   37efc:	ldur	x22, [x29, #-64]
   37f00:	ldur	x26, [x29, #-16]
   37f04:	mov	x0, x22
   37f08:	mov	x1, x26
   37f0c:	bl	c9b0 <__gmpn_mul_n@plt>
   37f10:	add	x0, x22, x23, lsl #3
   37f14:	ldur	x23, [x29, #-48]
   37f18:	ldur	x25, [x29, #-88]
   37f1c:	add	x3, x26, x28, lsl #3
   37f20:	cmp	x25, x23
   37f24:	b.le	37f3c <__gmpn_toom62_mul@@Base+0x92c>
   37f28:	mov	x1, x3
   37f2c:	ldur	x3, [x29, #-32]
   37f30:	mov	x2, x25
   37f34:	mov	x4, x23
   37f38:	b	37f48 <__gmpn_toom62_mul@@Base+0x938>
   37f3c:	ldur	x1, [x29, #-32]
   37f40:	mov	x2, x23
   37f44:	mov	x4, x25
   37f48:	bl	ccf0 <__gmpn_mul@plt>
   37f4c:	ldur	w8, [x29, #-80]
   37f50:	ldur	x5, [x29, #-40]
   37f54:	add	x7, x25, x23
   37f58:	eor	w2, w8, w27
   37f5c:	ldur	x8, [x29, #-96]
   37f60:	add	x8, x5, x8, lsl #3
   37f64:	add	x8, x8, #0x20
   37f68:	str	x8, [sp, #-16]!
   37f6c:	ldur	x3, [x29, #-56]
   37f70:	mov	x0, x22
   37f74:	mov	x1, x21
   37f78:	mov	x4, x19
   37f7c:	mov	x6, x20
   37f80:	bl	c830 <__gmpn_toom_interpolate_7pts@plt>
   37f84:	add	sp, sp, #0x10
   37f88:	mov	sp, x29
   37f8c:	ldp	x20, x19, [sp, #80]
   37f90:	ldp	x22, x21, [sp, #64]
   37f94:	ldp	x24, x23, [sp, #48]
   37f98:	ldp	x26, x25, [sp, #32]
   37f9c:	ldp	x28, x27, [sp, #16]
   37fa0:	ldp	x29, x30, [sp], #96
   37fa4:	ret
   37fa8:	mov	x0, x26
   37fac:	mov	x1, x2
   37fb0:	mov	x2, x28
   37fb4:	mov	x3, x23
   37fb8:	bl	c2e0 <__gmpn_sub_n@plt>
   37fbc:	cmp	x19, x23
   37fc0:	ldur	x23, [x29, #-192]
   37fc4:	b.eq	37ff4 <__gmpn_toom62_mul@@Base+0x9e4>  // b.none
   37fc8:	ldur	x10, [x29, #-80]
   37fcc:	lsl	x9, x24, #1
   37fd0:	mov	w1, wzr
   37fd4:	lsl	x8, x10, #3
   37fd8:	sub	x8, x8, x24, lsl #3
   37fdc:	sub	x9, x9, x10
   37fe0:	add	x8, x8, x26
   37fe4:	lsl	x9, x9, #3
   37fe8:	sub	x0, x8, #0x8
   37fec:	add	x2, x9, #0x18
   37ff0:	bl	c610 <memset@plt>
   37ff4:	ldur	x24, [x29, #-72]
   37ff8:	mov	w8, #0x1                   	// #1
   37ffc:	b	37c28 <__gmpn_toom62_mul@@Base+0x618>

0000000000038000 <__gmpn_toom33_mul@@Base>:
   38000:	sub	sp, sp, #0xd0
   38004:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   38008:	add	x8, x2, #0x2
   3800c:	movk	x9, #0xaaab
   38010:	umulh	x8, x8, x9
   38014:	stp	x22, x21, [sp, #176]
   38018:	lsr	x21, x8, #1
   3801c:	stp	x29, x30, [sp, #112]
   38020:	add	x29, sp, #0x70
   38024:	add	x9, x5, x21, lsl #4
   38028:	stp	x28, x27, [sp, #128]
   3802c:	stp	x26, x25, [sp, #144]
   38030:	stp	x24, x23, [sp, #160]
   38034:	stp	x20, x19, [sp, #192]
   38038:	add	x8, x5, x21, lsl #5
   3803c:	stur	x9, [x29, #-40]
   38040:	add	x9, x0, x21, lsl #3
   38044:	mov	x19, x5
   38048:	mov	x23, x4
   3804c:	mov	x22, x3
   38050:	mov	x27, x2
   38054:	mov	x28, x1
   38058:	mov	x25, x0
   3805c:	sub	x24, x2, x21, lsl #1
   38060:	add	x8, x8, #0x20
   38064:	add	x20, x9, #0x8
   38068:	add	x2, x1, x21, lsl #4
   3806c:	stur	x8, [x29, #-8]
   38070:	stur	x2, [x29, #-48]
   38074:	cbz	x24, 380bc <__gmpn_toom33_mul@@Base+0xbc>
   38078:	mov	x0, x19
   3807c:	mov	x1, x28
   38080:	mov	x3, x24
   38084:	bl	ca90 <__gmpn_add_n@plt>
   38088:	mov	x8, x24
   3808c:	cbz	x0, 380c0 <__gmpn_toom33_mul@@Base+0xc0>
   38090:	mov	w26, #0x1                   	// #1
   38094:	mov	x9, x24
   38098:	cmp	x9, x21
   3809c:	b.ge	380f4 <__gmpn_toom33_mul@@Base+0xf4>  // b.tcont
   380a0:	ldr	x8, [x28, x9, lsl #3]
   380a4:	adds	x10, x8, #0x1
   380a8:	add	x8, x9, #0x1
   380ac:	str	x10, [x19, x9, lsl #3]
   380b0:	mov	x9, x8
   380b4:	b.cs	38098 <__gmpn_toom33_mul@@Base+0x98>  // b.hs, b.nlast
   380b8:	b	380c0 <__gmpn_toom33_mul@@Base+0xc0>
   380bc:	mov	x8, xzr
   380c0:	cmp	x19, x28
   380c4:	mov	x26, xzr
   380c8:	b.eq	380f4 <__gmpn_toom33_mul@@Base+0xf4>  // b.none
   380cc:	cmp	x8, x21
   380d0:	b.ge	380f4 <__gmpn_toom33_mul@@Base+0xf4>  // b.tcont
   380d4:	sub	x9, x21, x8
   380d8:	add	x10, x19, x8, lsl #3
   380dc:	add	x8, x28, x8, lsl #3
   380e0:	ldr	x11, [x8], #8
   380e4:	subs	x9, x9, #0x1
   380e8:	str	x11, [x10], #8
   380ec:	b.ne	380e0 <__gmpn_toom33_mul@@Base+0xe0>  // b.any
   380f0:	mov	x26, xzr
   380f4:	stur	x25, [x29, #-24]
   380f8:	str	x23, [sp, #40]
   380fc:	sub	x8, x23, x21, lsl #1
   38100:	stur	x8, [x29, #-16]
   38104:	ldur	x8, [x29, #-40]
   38108:	add	x23, x28, x21, lsl #3
   3810c:	mov	x1, x19
   38110:	mov	x2, x23
   38114:	add	x8, x8, #0x10
   38118:	str	x8, [sp, #56]
   3811c:	ldur	x25, [x29, #-8]
   38120:	mov	x3, x21
   38124:	mov	x0, x25
   38128:	bl	ca90 <__gmpn_add_n@plt>
   3812c:	add	x8, x0, x26
   38130:	str	x8, [x25, x21, lsl #3]
   38134:	mov	x25, x20
   38138:	cbz	x26, 38220 <__gmpn_toom33_mul@@Base+0x220>
   3813c:	ldr	x20, [sp, #56]
   38140:	mov	x1, x19
   38144:	mov	x2, x23
   38148:	mov	x3, x21
   3814c:	mov	x0, x20
   38150:	bl	c2e0 <__gmpn_sub_n@plt>
   38154:	sub	x8, x26, x0
   38158:	str	wzr, [sp, #36]
   3815c:	ldur	x26, [x29, #-8]
   38160:	ldur	x1, [x29, #-48]
   38164:	ldur	x9, [x29, #-24]
   38168:	mov	x0, x25
   3816c:	mov	x2, x26
   38170:	mov	x3, x24
   38174:	stur	x28, [x29, #-32]
   38178:	add	x28, x9, x21, lsl #4
   3817c:	lsl	x23, x21, #1
   38180:	str	x8, [x20, x21, lsl #3]
   38184:	bl	ca90 <__gmpn_add_n@plt>
   38188:	subs	x9, x21, x24
   3818c:	b.eq	382c8 <__gmpn_toom33_mul@@Base+0x2c8>  // b.none
   38190:	ldr	x8, [x26, x24, lsl #3]
   38194:	adds	x8, x8, x0
   38198:	str	x8, [x25, x24, lsl #3]
   3819c:	b.cc	38278 <__gmpn_toom33_mul@@Base+0x278>  // b.lo, b.ul, b.last
   381a0:	add	x8, x19, x21, lsl #4
   381a4:	mov	w10, #0x2                   	// #2
   381a8:	add	x11, x8, #0x28
   381ac:	sub	x8, x10, x21
   381b0:	ldur	x10, [x29, #-24]
   381b4:	mov	w0, #0x1                   	// #1
   381b8:	add	x10, x10, x8, lsl #3
   381bc:	mov	w8, #0x1                   	// #1
   381c0:	cmp	x8, x9
   381c4:	b.ge	382c8 <__gmpn_toom33_mul@@Base+0x2c8>  // b.tcont
   381c8:	ldr	x12, [x11, x27, lsl #3]
   381cc:	add	x8, x8, #0x1
   381d0:	add	x11, x11, #0x8
   381d4:	adds	x12, x12, #0x1
   381d8:	str	x12, [x10, x27, lsl #3]
   381dc:	add	x10, x10, #0x8
   381e0:	b.cs	381c0 <__gmpn_toom33_mul@@Base+0x1c0>  // b.hs, b.nlast
   381e4:	cmp	x26, x25
   381e8:	mov	x0, xzr
   381ec:	b.eq	382c8 <__gmpn_toom33_mul@@Base+0x2c8>  // b.none
   381f0:	cmp	x8, x9
   381f4:	b.ge	382c8 <__gmpn_toom33_mul@@Base+0x2c8>  // b.tcont
   381f8:	add	x9, x11, x27, lsl #3
   381fc:	add	x11, x21, x21, lsl #1
   38200:	add	x10, x10, x27, lsl #3
   38204:	sub	x11, x11, x27
   38208:	ldr	x12, [x9], #8
   3820c:	sub	x11, x11, #0x1
   38210:	cmp	x8, x11
   38214:	str	x12, [x10], #8
   38218:	b.ne	38208 <__gmpn_toom33_mul@@Base+0x208>  // b.any
   3821c:	b	382c4 <__gmpn_toom33_mul@@Base+0x2c4>
   38220:	add	x8, x28, x21, lsl #4
   38224:	sub	x8, x8, #0x8
   38228:	mov	x10, x21
   3822c:	subs	x9, x10, #0x1
   38230:	b.lt	3813c <__gmpn_toom33_mul@@Base+0x13c>  // b.tstop
   38234:	add	x10, x19, x10, lsl #3
   38238:	ldur	x10, [x10, #-8]
   3823c:	ldr	x11, [x8], #-8
   38240:	cmp	x10, x11
   38244:	mov	x10, x9
   38248:	b.eq	3822c <__gmpn_toom33_mul@@Base+0x22c>  // b.none
   3824c:	b.hi	3813c <__gmpn_toom33_mul@@Base+0x13c>  // b.pmore
   38250:	ldr	x20, [sp, #56]
   38254:	mov	x1, x23
   38258:	mov	x2, x19
   3825c:	mov	x3, x21
   38260:	mov	x0, x20
   38264:	bl	c2e0 <__gmpn_sub_n@plt>
   38268:	mov	w9, #0x1                   	// #1
   3826c:	mov	x8, xzr
   38270:	str	w9, [sp, #36]
   38274:	b	3815c <__gmpn_toom33_mul@@Base+0x15c>
   38278:	cmp	x26, x25
   3827c:	mov	x0, xzr
   38280:	b.eq	382c8 <__gmpn_toom33_mul@@Base+0x2c8>  // b.none
   38284:	cmp	x9, #0x2
   38288:	b.lt	382c8 <__gmpn_toom33_mul@@Base+0x2c8>  // b.tstop
   3828c:	ldur	x11, [x29, #-24]
   38290:	add	x8, x21, x21, lsl #1
   38294:	sub	x9, x27, x21
   38298:	add	x10, x27, x21, lsl #1
   3829c:	sub	x8, x27, x8
   382a0:	add	x9, x11, x9, lsl #3
   382a4:	add	x10, x19, x10, lsl #3
   382a8:	add	x8, x8, #0x1
   382ac:	add	x9, x9, #0x10
   382b0:	add	x10, x10, #0x28
   382b4:	ldr	x11, [x10], #8
   382b8:	adds	x8, x8, #0x1
   382bc:	str	x11, [x9], #8
   382c0:	b.cc	382b4 <__gmpn_toom33_mul@@Base+0x2b4>  // b.lo, b.ul, b.last
   382c4:	mov	x0, xzr
   382c8:	ldr	x8, [x26, x21, lsl #3]
   382cc:	str	x28, [sp, #16]
   382d0:	ldur	x1, [x29, #-32]
   382d4:	mov	w9, #0x18                  	// #24
   382d8:	add	x20, x28, #0x10
   382dc:	add	x28, x8, x0
   382e0:	mov	x0, x25
   382e4:	mov	x2, x25
   382e8:	mov	x3, x21
   382ec:	madd	x26, x21, x9, x19
   382f0:	bl	d0b0 <__gmpn_rsblsh1_n@plt>
   382f4:	str	x25, [sp, #24]
   382f8:	add	x2, x22, x23, lsl #3
   382fc:	ldur	x23, [x29, #-16]
   38300:	add	x8, x0, x28, lsl #1
   38304:	str	x8, [x25, x21, lsl #3]
   38308:	str	x2, [sp, #48]
   3830c:	cbz	x23, 38354 <__gmpn_toom33_mul@@Base+0x354>
   38310:	mov	x0, x19
   38314:	mov	x1, x22
   38318:	mov	x3, x23
   3831c:	bl	ca90 <__gmpn_add_n@plt>
   38320:	ldur	x25, [x29, #-24]
   38324:	mov	x8, x23
   38328:	cbz	x0, 3835c <__gmpn_toom33_mul@@Base+0x35c>
   3832c:	mov	w28, #0x1                   	// #1
   38330:	cmp	x23, x21
   38334:	b.ge	38390 <__gmpn_toom33_mul@@Base+0x390>  // b.tcont
   38338:	ldr	x8, [x22, x23, lsl #3]
   3833c:	adds	x10, x8, #0x1
   38340:	add	x8, x23, #0x1
   38344:	str	x10, [x19, x23, lsl #3]
   38348:	mov	x23, x8
   3834c:	b.cs	38330 <__gmpn_toom33_mul@@Base+0x330>  // b.hs, b.nlast
   38350:	b	3835c <__gmpn_toom33_mul@@Base+0x35c>
   38354:	ldur	x25, [x29, #-24]
   38358:	mov	x8, xzr
   3835c:	cmp	x19, x22
   38360:	mov	x28, xzr
   38364:	b.eq	38390 <__gmpn_toom33_mul@@Base+0x390>  // b.none
   38368:	cmp	x8, x21
   3836c:	b.ge	38390 <__gmpn_toom33_mul@@Base+0x390>  // b.tcont
   38370:	sub	x9, x21, x8
   38374:	add	x10, x19, x8, lsl #3
   38378:	add	x8, x22, x8, lsl #3
   3837c:	ldr	x11, [x8], #8
   38380:	subs	x9, x9, #0x1
   38384:	str	x11, [x10], #8
   38388:	b.ne	3837c <__gmpn_toom33_mul@@Base+0x37c>  // b.any
   3838c:	mov	x28, xzr
   38390:	add	x23, x22, x21, lsl #3
   38394:	mov	x0, x25
   38398:	mov	x1, x19
   3839c:	mov	x2, x23
   383a0:	mov	x3, x21
   383a4:	add	x26, x26, #0x18
   383a8:	bl	ca90 <__gmpn_add_n@plt>
   383ac:	add	x8, x0, x28
   383b0:	str	x8, [x25, x21, lsl #3]
   383b4:	cbz	x28, 38490 <__gmpn_toom33_mul@@Base+0x490>
   383b8:	mov	x0, x26
   383bc:	mov	x1, x19
   383c0:	mov	x2, x23
   383c4:	mov	x3, x21
   383c8:	bl	c2e0 <__gmpn_sub_n@plt>
   383cc:	sub	x8, x28, x0
   383d0:	str	x8, [x26, x21, lsl #3]
   383d4:	ldur	x23, [x29, #-16]
   383d8:	ldr	x1, [sp, #48]
   383dc:	lsl	x8, x21, #2
   383e0:	mov	x0, x20
   383e4:	mov	x2, x25
   383e8:	mov	x3, x23
   383ec:	str	x8, [sp, #8]
   383f0:	bl	ca90 <__gmpn_add_n@plt>
   383f4:	subs	x9, x21, x23
   383f8:	b.eq	38530 <__gmpn_toom33_mul@@Base+0x530>  // b.none
   383fc:	ldr	x8, [x25, x23, lsl #3]
   38400:	adds	x8, x8, x0
   38404:	str	x8, [x20, x23, lsl #3]
   38408:	b.cc	384e8 <__gmpn_toom33_mul@@Base+0x4e8>  // b.lo, b.ul, b.last
   3840c:	ldr	x8, [sp, #40]
   38410:	mov	w11, #0x8                   	// #8
   38414:	mov	w10, #0x3                   	// #3
   38418:	sub	x11, x11, x21, lsl #4
   3841c:	add	x8, x25, x8, lsl #3
   38420:	mov	w0, #0x1                   	// #1
   38424:	sub	x12, x10, #0x2
   38428:	cmp	x12, x9
   3842c:	b.ge	38530 <__gmpn_toom33_mul@@Base+0x530>  // b.tcont
   38430:	ldr	x12, [x8, x11]
   38434:	add	x10, x10, #0x1
   38438:	adds	x12, x12, #0x1
   3843c:	str	x12, [x8, #24]
   38440:	add	x8, x8, #0x8
   38444:	b.cs	38424 <__gmpn_toom33_mul@@Base+0x424>  // b.hs, b.nlast
   38448:	cmp	x20, x25
   3844c:	mov	x0, xzr
   38450:	b.eq	38530 <__gmpn_toom33_mul@@Base+0x530>  // b.none
   38454:	sub	x10, x10, #0x2
   38458:	cmp	x10, x9
   3845c:	b.ge	38530 <__gmpn_toom33_mul@@Base+0x530>  // b.tcont
   38460:	ldr	x12, [sp, #40]
   38464:	add	x9, x21, x21, lsl #1
   38468:	mov	w11, #0x8                   	// #8
   3846c:	sub	x11, x11, x21, lsl #4
   38470:	sub	x9, x9, x12
   38474:	ldr	x12, [x8, x11]
   38478:	sub	x9, x9, #0x1
   3847c:	cmp	x10, x9
   38480:	str	x12, [x8, #24]
   38484:	add	x8, x8, #0x8
   38488:	b.ne	38474 <__gmpn_toom33_mul@@Base+0x474>  // b.any
   3848c:	b	3852c <__gmpn_toom33_mul@@Base+0x52c>
   38490:	add	x8, x22, x21, lsl #4
   38494:	sub	x8, x8, #0x8
   38498:	mov	x10, x21
   3849c:	subs	x9, x10, #0x1
   384a0:	b.lt	383b8 <__gmpn_toom33_mul@@Base+0x3b8>  // b.tstop
   384a4:	add	x10, x19, x10, lsl #3
   384a8:	ldur	x10, [x10, #-8]
   384ac:	ldr	x11, [x8], #-8
   384b0:	cmp	x10, x11
   384b4:	mov	x10, x9
   384b8:	b.eq	3849c <__gmpn_toom33_mul@@Base+0x49c>  // b.none
   384bc:	b.hi	383b8 <__gmpn_toom33_mul@@Base+0x3b8>  // b.pmore
   384c0:	mov	x0, x26
   384c4:	mov	x1, x23
   384c8:	mov	x2, x19
   384cc:	mov	x3, x21
   384d0:	bl	c2e0 <__gmpn_sub_n@plt>
   384d4:	ldr	w8, [sp, #36]
   384d8:	str	xzr, [x26, x21, lsl #3]
   384dc:	eor	w8, w8, #0x1
   384e0:	str	w8, [sp, #36]
   384e4:	b	383d4 <__gmpn_toom33_mul@@Base+0x3d4>
   384e8:	cmp	x20, x25
   384ec:	mov	x0, xzr
   384f0:	b.eq	38530 <__gmpn_toom33_mul@@Base+0x530>  // b.none
   384f4:	cmp	x9, #0x2
   384f8:	b.lt	38530 <__gmpn_toom33_mul@@Base+0x530>  // b.tstop
   384fc:	ldr	x11, [sp, #40]
   38500:	add	x9, x21, x21, lsl #1
   38504:	mov	w10, #0x8                   	// #8
   38508:	sub	x10, x10, x21, lsl #4
   3850c:	sub	x9, x11, x9
   38510:	add	x8, x25, x11, lsl #3
   38514:	add	x9, x9, #0x1
   38518:	ldr	x11, [x8, x10]
   3851c:	adds	x9, x9, #0x1
   38520:	str	x11, [x8, #24]
   38524:	add	x8, x8, #0x8
   38528:	b.cc	38518 <__gmpn_toom33_mul@@Base+0x518>  // b.lo, b.ul, b.last
   3852c:	mov	x0, xzr
   38530:	ldr	x8, [x25, x21, lsl #3]
   38534:	mov	x1, x22
   38538:	mov	x2, x20
   3853c:	mov	x3, x21
   38540:	add	x23, x8, x0
   38544:	mov	x0, x20
   38548:	stur	x22, [x29, #-24]
   3854c:	bl	d0b0 <__gmpn_rsblsh1_n@plt>
   38550:	add	x8, x0, x23, lsl #1
   38554:	mov	w9, #0x28                  	// #40
   38558:	ldr	x1, [sp, #56]
   3855c:	str	x8, [x20, x21, lsl #3]
   38560:	madd	x8, x21, x9, x19
   38564:	add	x28, x21, #0x1
   38568:	add	x23, x8, #0x28
   3856c:	mov	x0, x19
   38570:	mov	x2, x28
   38574:	mov	x3, x26
   38578:	mov	x4, x28
   3857c:	mov	x5, x23
   38580:	bl	d470 <__gmpn_toom22_mul@plt>
   38584:	ldur	x8, [x29, #-40]
   38588:	mov	x2, x28
   3858c:	mov	x3, x20
   38590:	mov	x4, x28
   38594:	add	x0, x8, #0x8
   38598:	stur	x0, [x29, #-40]
   3859c:	ldr	x1, [sp, #24]
   385a0:	mov	x5, x23
   385a4:	bl	d470 <__gmpn_toom22_mul@plt>
   385a8:	ldr	x8, [sp, #40]
   385ac:	mov	x22, x25
   385b0:	cmp	x27, x8
   385b4:	ldr	x8, [sp, #8]
   385b8:	add	x25, x25, x8, lsl #3
   385bc:	mov	x0, x25
   385c0:	b.le	385e0 <__gmpn_toom33_mul@@Base+0x5e0>
   385c4:	ldur	x26, [x29, #-16]
   385c8:	ldur	x1, [x29, #-48]
   385cc:	ldr	x3, [sp, #48]
   385d0:	mov	x2, x24
   385d4:	mov	x4, x26
   385d8:	bl	ccf0 <__gmpn_mul@plt>
   385dc:	b	385fc <__gmpn_toom33_mul@@Base+0x5fc>
   385e0:	ldur	x1, [x29, #-48]
   385e4:	ldr	x3, [sp, #48]
   385e8:	mov	x2, x24
   385ec:	mov	x4, x24
   385f0:	mov	x5, x23
   385f4:	bl	d470 <__gmpn_toom22_mul@plt>
   385f8:	ldur	x26, [x29, #-16]
   385fc:	ldr	x0, [sp, #16]
   38600:	ldur	x1, [x29, #-8]
   38604:	ldp	x27, x20, [x25]
   38608:	mov	x2, x28
   3860c:	mov	x3, x22
   38610:	mov	x4, x28
   38614:	mov	x5, x23
   38618:	bl	d470 <__gmpn_toom22_mul@plt>
   3861c:	str	x20, [x25, #8]
   38620:	ldp	x1, x3, [x29, #-32]
   38624:	mov	x0, x22
   38628:	mov	x2, x21
   3862c:	mov	x4, x21
   38630:	mov	x5, x23
   38634:	bl	d470 <__gmpn_toom22_mul@plt>
   38638:	add	x4, x24, x26
   3863c:	mov	x0, x22
   38640:	ldur	x1, [x29, #-40]
   38644:	mov	x2, x19
   38648:	mov	x3, x21
   3864c:	ldr	w5, [sp, #36]
   38650:	mov	x6, x27
   38654:	ldp	x20, x19, [sp, #192]
   38658:	ldp	x22, x21, [sp, #176]
   3865c:	ldp	x24, x23, [sp, #160]
   38660:	ldp	x26, x25, [sp, #144]
   38664:	ldp	x28, x27, [sp, #128]
   38668:	ldp	x29, x30, [sp, #112]
   3866c:	add	sp, sp, #0xd0
   38670:	b	ca40 <__gmpn_toom_interpolate_5pts@plt>

0000000000038674 <__gmpn_toom43_mul@@Base>:
   38674:	sub	sp, sp, #0xe0
   38678:	add	x8, x2, x2, lsl #1
   3867c:	stp	x29, x30, [sp, #128]
   38680:	stp	x28, x27, [sp, #144]
   38684:	stp	x22, x21, [sp, #192]
   38688:	stp	x20, x19, [sp, #208]
   3868c:	add	x29, sp, #0x80
   38690:	mov	x19, x5
   38694:	mov	x27, x4
   38698:	mov	x20, x3
   3869c:	cmp	x8, x4, lsl #2
   386a0:	mov	x21, x0
   386a4:	stp	x26, x25, [sp, #160]
   386a8:	stp	x24, x23, [sp, #176]
   386ac:	stur	x1, [x29, #-8]
   386b0:	b.ge	386cc <__gmpn_toom43_mul@@Base+0x58>  // b.tcont
   386b4:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   386b8:	sub	x8, x27, #0x1
   386bc:	movk	x9, #0xaaab
   386c0:	umulh	x8, x8, x9
   386c4:	lsr	x25, x8, #1
   386c8:	b	386d4 <__gmpn_toom43_mul@@Base+0x60>
   386cc:	sub	x8, x2, #0x1
   386d0:	asr	x25, x8, #2
   386d4:	add	x23, x25, #0x1
   386d8:	add	x9, x23, x23, lsl #1
   386dc:	add	x10, x19, x23, lsl #5
   386e0:	add	x8, x21, x9, lsl #3
   386e4:	add	x1, x10, #0x20
   386e8:	add	x0, x8, #0x18
   386ec:	str	x10, [sp, #64]
   386f0:	stur	x9, [x29, #-48]
   386f4:	stur	x0, [x29, #-56]
   386f8:	str	x1, [sp, #56]
   386fc:	sub	x4, x2, x9
   38700:	ldur	x2, [x29, #-8]
   38704:	add	x9, x19, x9, lsl #3
   38708:	add	x5, x9, #0x18
   3870c:	mov	x3, x23
   38710:	lsl	x26, x23, #1
   38714:	sub	x24, x27, x23, lsl #1
   38718:	stp	x4, x5, [x29, #-24]
   3871c:	bl	cd80 <__gmpn_toom_eval_dgr3_pm2@plt>
   38720:	and	w8, w0, #0x2
   38724:	stur	w8, [x29, #-36]
   38728:	add	x8, x19, x23, lsl #4
   3872c:	add	x28, x8, #0x10
   38730:	add	x1, x20, x23, lsl #3
   38734:	mov	w3, #0x1                   	// #1
   38738:	mov	x0, x28
   3873c:	mov	x2, x23
   38740:	stp	x1, x8, [sp, #40]
   38744:	bl	c190 <__gmpn_lshift@plt>
   38748:	str	x0, [x28, x23, lsl #3]
   3874c:	add	x1, x20, x23, lsl #4
   38750:	mov	w3, #0x2                   	// #2
   38754:	mov	x0, x19
   38758:	mov	x2, x24
   3875c:	stur	x1, [x29, #-32]
   38760:	bl	c190 <__gmpn_lshift@plt>
   38764:	mov	x22, x0
   38768:	mov	x0, x19
   3876c:	mov	x1, x19
   38770:	mov	x2, x20
   38774:	mov	x3, x24
   38778:	bl	ca90 <__gmpn_add_n@plt>
   3877c:	subs	x9, x23, x24
   38780:	add	x8, x0, x22
   38784:	b.eq	3885c <__gmpn_toom43_mul@@Base+0x1e8>  // b.none
   38788:	ldr	x10, [x20, x24, lsl #3]
   3878c:	adds	x8, x10, x8
   38790:	str	x8, [x19, x24, lsl #3]
   38794:	b.cc	38814 <__gmpn_toom43_mul@@Base+0x1a0>  // b.lo, b.ul, b.last
   38798:	mov	x11, #0xffffffffffffffff    	// #-1
   3879c:	eor	x11, x11, x25, lsl #1
   387a0:	add	x10, x25, x25, lsl #1
   387a4:	mov	w8, #0x1                   	// #1
   387a8:	add	x13, x20, x11, lsl #3
   387ac:	add	x11, x19, x11, lsl #3
   387b0:	mov	w12, #0x1                   	// #1
   387b4:	cmp	x12, x9
   387b8:	b.ge	3885c <__gmpn_toom43_mul@@Base+0x1e8>  // b.tcont
   387bc:	ldr	x14, [x13, x27, lsl #3]
   387c0:	add	x12, x12, #0x1
   387c4:	add	x13, x13, #0x8
   387c8:	adds	x14, x14, #0x1
   387cc:	str	x14, [x11, x27, lsl #3]
   387d0:	add	x11, x11, #0x8
   387d4:	b.cs	387b4 <__gmpn_toom43_mul@@Base+0x140>  // b.hs, b.nlast
   387d8:	cmp	x20, x19
   387dc:	mov	x8, xzr
   387e0:	b.eq	3885c <__gmpn_toom43_mul@@Base+0x1e8>  // b.none
   387e4:	cmp	x12, x9
   387e8:	b.ge	3885c <__gmpn_toom43_mul@@Base+0x1e8>  // b.tcont
   387ec:	sub	x10, x27, x10
   387f0:	add	x10, x10, x12
   387f4:	add	x8, x13, x27, lsl #3
   387f8:	add	x9, x11, x27, lsl #3
   387fc:	sub	x10, x10, #0x3
   38800:	ldr	x11, [x8], #8
   38804:	adds	x10, x10, #0x1
   38808:	str	x11, [x9], #8
   3880c:	b.cc	38800 <__gmpn_toom43_mul@@Base+0x18c>  // b.lo, b.ul, b.last
   38810:	b	38858 <__gmpn_toom43_mul@@Base+0x1e4>
   38814:	cmp	x20, x19
   38818:	mov	x8, xzr
   3881c:	b.eq	3885c <__gmpn_toom43_mul@@Base+0x1e8>  // b.none
   38820:	cmp	x9, #0x2
   38824:	b.lt	3885c <__gmpn_toom43_mul@@Base+0x1e8>  // b.tstop
   38828:	sub	x9, x27, x25, lsl #1
   3882c:	add	x8, x25, x25, lsl #1
   38830:	lsl	x9, x9, #3
   38834:	sub	x8, x27, x8
   38838:	sub	x10, x9, #0x8
   3883c:	sub	x8, x8, #0x2
   38840:	add	x9, x19, x10
   38844:	add	x10, x20, x10
   38848:	ldr	x11, [x10], #8
   3884c:	adds	x8, x8, #0x1
   38850:	str	x11, [x9], #8
   38854:	b.cc	38848 <__gmpn_toom43_mul@@Base+0x1d4>  // b.lo, b.ul, b.last
   38858:	mov	x8, xzr
   3885c:	str	x8, [x19, x23, lsl #3]
   38860:	add	x8, x21, x26, lsl #3
   38864:	add	x26, x25, #0x2
   38868:	add	x0, x8, #0x10
   3886c:	mov	x1, x19
   38870:	mov	x2, x28
   38874:	mov	x3, x26
   38878:	lsl	x22, x23, #2
   3887c:	stp	x0, x8, [sp, #24]
   38880:	bl	ca90 <__gmpn_add_n@plt>
   38884:	mov	w8, #0x18                  	// #24
   38888:	mul	x8, x25, x8
   3888c:	add	x8, x8, #0x28
   38890:	mov	x9, x23
   38894:	add	x10, x9, #0x1
   38898:	cmp	x10, #0x1
   3889c:	b.lt	388bc <__gmpn_toom43_mul@@Base+0x248>  // b.tstop
   388a0:	ldr	x10, [x19, x9, lsl #3]
   388a4:	ldr	x11, [x19, x8]
   388a8:	sub	x9, x9, #0x1
   388ac:	sub	x8, x8, #0x8
   388b0:	cmp	x10, x11
   388b4:	b.eq	38894 <__gmpn_toom43_mul@@Base+0x220>  // b.none
   388b8:	b.ls	388dc <__gmpn_toom43_mul@@Base+0x268>  // b.plast
   388bc:	add	x8, x21, x23, lsl #3
   388c0:	add	x0, x8, #0x8
   388c4:	mov	x1, x19
   388c8:	mov	x2, x28
   388cc:	mov	x3, x26
   388d0:	str	x0, [sp, #8]
   388d4:	bl	c2e0 <__gmpn_sub_n@plt>
   388d8:	b	38904 <__gmpn_toom43_mul@@Base+0x290>
   388dc:	add	x8, x21, x23, lsl #3
   388e0:	add	x0, x8, #0x8
   388e4:	mov	x1, x28
   388e8:	mov	x2, x19
   388ec:	mov	x3, x26
   388f0:	str	x0, [sp, #8]
   388f4:	bl	c2e0 <__gmpn_sub_n@plt>
   388f8:	ldur	w8, [x29, #-36]
   388fc:	eor	w8, w8, #0x2
   38900:	stur	w8, [x29, #-36]
   38904:	add	x8, x21, x22, lsl #3
   38908:	add	x0, x8, #0x20
   3890c:	str	x0, [sp, #16]
   38910:	ldp	x1, x2, [x29, #-16]
   38914:	ldur	x4, [x29, #-24]
   38918:	mov	x3, x23
   3891c:	mov	x5, x19
   38920:	bl	c290 <__gmpn_toom_eval_dgr3_pm1@plt>
   38924:	and	w22, w0, #0x1
   38928:	cbz	x24, 3897c <__gmpn_toom43_mul@@Base+0x308>
   3892c:	ldur	x2, [x29, #-32]
   38930:	mov	x0, x28
   38934:	mov	x1, x20
   38938:	mov	x3, x24
   3893c:	bl	ca90 <__gmpn_add_n@plt>
   38940:	ldur	w12, [x29, #-36]
   38944:	mov	x8, x24
   38948:	cbz	x0, 38984 <__gmpn_toom43_mul@@Base+0x310>
   3894c:	add	x8, x19, x27, lsl #3
   38950:	add	x9, x8, #0x10
   38954:	mov	w27, #0x1                   	// #1
   38958:	mov	x8, x24
   3895c:	cmp	x8, x25
   38960:	b.gt	389d4 <__gmpn_toom43_mul@@Base+0x360>
   38964:	ldr	x10, [x20, x8, lsl #3]
   38968:	add	x8, x8, #0x1
   3896c:	adds	x10, x10, #0x1
   38970:	str	x10, [x9], #8
   38974:	b.cs	3895c <__gmpn_toom43_mul@@Base+0x2e8>  // b.hs, b.nlast
   38978:	b	38984 <__gmpn_toom43_mul@@Base+0x310>
   3897c:	ldur	w12, [x29, #-36]
   38980:	mov	x8, xzr
   38984:	mov	x9, x21
   38988:	mov	x21, x24
   3898c:	mov	x24, x9
   38990:	cmp	x28, x20
   38994:	mov	x27, xzr
   38998:	b.eq	389e0 <__gmpn_toom43_mul@@Base+0x36c>  // b.none
   3899c:	cmp	x8, x25
   389a0:	b.gt	389e0 <__gmpn_toom43_mul@@Base+0x36c>
   389a4:	add	x10, x8, x25, lsl #1
   389a8:	sub	x9, x25, x8
   389ac:	add	x10, x19, x10, lsl #3
   389b0:	add	x9, x9, #0x1
   389b4:	add	x10, x10, #0x20
   389b8:	add	x8, x20, x8, lsl #3
   389bc:	ldr	x11, [x8], #8
   389c0:	subs	x9, x9, #0x1
   389c4:	str	x11, [x10], #8
   389c8:	b.ne	389bc <__gmpn_toom43_mul@@Base+0x348>  // b.any
   389cc:	mov	x27, xzr
   389d0:	b	389e0 <__gmpn_toom43_mul@@Base+0x36c>
   389d4:	mov	x8, x21
   389d8:	mov	x21, x24
   389dc:	mov	x24, x8
   389e0:	eor	w8, w22, w12
   389e4:	stur	w8, [x29, #-36]
   389e8:	ldr	x22, [sp, #40]
   389ec:	mov	x0, x24
   389f0:	mov	x1, x28
   389f4:	mov	x3, x23
   389f8:	mov	x2, x22
   389fc:	str	x27, [x28, x23, lsl #3]
   38a00:	bl	ca90 <__gmpn_add_n@plt>
   38a04:	add	x8, x0, x27
   38a08:	str	x8, [x24, x23, lsl #3]
   38a0c:	ldr	x8, [x28, x23, lsl #3]
   38a10:	mov	x27, x24
   38a14:	cbz	x8, 38b28 <__gmpn_toom43_mul@@Base+0x4b4>
   38a18:	mov	x0, x28
   38a1c:	mov	x1, x28
   38a20:	mov	x2, x22
   38a24:	mov	x3, x23
   38a28:	bl	c2e0 <__gmpn_sub_n@plt>
   38a2c:	ldr	x8, [x28, x23, lsl #3]
   38a30:	sub	x8, x8, x0
   38a34:	str	x8, [x28, x23, lsl #3]
   38a38:	ldp	x25, x1, [x29, #-24]
   38a3c:	ldr	x22, [sp, #8]
   38a40:	mov	x0, x19
   38a44:	mov	x2, x28
   38a48:	mov	x3, x26
   38a4c:	bl	c9b0 <__gmpn_mul_n@plt>
   38a50:	ldp	x8, x1, [sp, #48]
   38a54:	mov	x2, x22
   38a58:	mov	x3, x26
   38a5c:	add	x28, x8, #0x8
   38a60:	mov	x0, x28
   38a64:	bl	c9b0 <__gmpn_mul_n@plt>
   38a68:	ldr	x8, [sp, #64]
   38a6c:	ldur	x1, [x29, #-56]
   38a70:	ldr	x2, [sp, #24]
   38a74:	mov	x3, x26
   38a78:	add	x22, x8, #0x10
   38a7c:	mov	x0, x22
   38a80:	bl	c9b0 <__gmpn_mul_n@plt>
   38a84:	ldr	x0, [sp, #32]
   38a88:	ldr	x1, [sp, #16]
   38a8c:	mov	x2, x27
   38a90:	mov	x3, x26
   38a94:	bl	c9b0 <__gmpn_mul_n@plt>
   38a98:	mov	w8, #0x28                  	// #40
   38a9c:	madd	x0, x23, x8, x27
   38aa0:	ldur	x8, [x29, #-8]
   38aa4:	ldur	x9, [x29, #-48]
   38aa8:	cmp	x25, x21
   38aac:	add	x3, x8, x9, lsl #3
   38ab0:	b.le	38ac8 <__gmpn_toom43_mul@@Base+0x454>
   38ab4:	mov	x1, x3
   38ab8:	ldur	x3, [x29, #-32]
   38abc:	mov	x2, x25
   38ac0:	mov	x4, x21
   38ac4:	b	38ad4 <__gmpn_toom43_mul@@Base+0x460>
   38ac8:	ldur	x1, [x29, #-32]
   38acc:	mov	x2, x21
   38ad0:	mov	x4, x25
   38ad4:	bl	ccf0 <__gmpn_mul@plt>
   38ad8:	ldur	x1, [x29, #-8]
   38adc:	mov	x0, x27
   38ae0:	mov	x2, x20
   38ae4:	mov	x3, x23
   38ae8:	bl	c9b0 <__gmpn_mul_n@plt>
   38aec:	add	x6, x21, x25
   38af0:	mov	x0, x27
   38af4:	mov	x1, x23
   38af8:	ldur	w2, [x29, #-36]
   38afc:	mov	x3, x19
   38b00:	mov	x4, x28
   38b04:	mov	x5, x22
   38b08:	ldp	x20, x19, [sp, #208]
   38b0c:	ldp	x22, x21, [sp, #192]
   38b10:	ldp	x24, x23, [sp, #176]
   38b14:	ldp	x26, x25, [sp, #160]
   38b18:	ldp	x28, x27, [sp, #144]
   38b1c:	ldp	x29, x30, [sp, #128]
   38b20:	add	sp, sp, #0xe0
   38b24:	b	c930 <__gmpn_toom_interpolate_6pts@plt>
   38b28:	mov	w9, #0x18                  	// #24
   38b2c:	add	x8, x20, x25, lsl #4
   38b30:	madd	x9, x25, x9, x19
   38b34:	add	x8, x8, #0x8
   38b38:	add	x9, x9, #0x20
   38b3c:	mov	x10, x23
   38b40:	subs	x10, x10, #0x1
   38b44:	b.lt	38a18 <__gmpn_toom43_mul@@Base+0x3a4>  // b.tstop
   38b48:	ldr	x11, [x9], #-8
   38b4c:	ldr	x12, [x8], #-8
   38b50:	cmp	x11, x12
   38b54:	b.eq	38b40 <__gmpn_toom43_mul@@Base+0x4cc>  // b.none
   38b58:	b.hi	38a18 <__gmpn_toom43_mul@@Base+0x3a4>  // b.pmore
   38b5c:	mov	x0, x28
   38b60:	mov	x1, x22
   38b64:	mov	x2, x28
   38b68:	mov	x3, x23
   38b6c:	bl	c2e0 <__gmpn_sub_n@plt>
   38b70:	ldur	w8, [x29, #-36]
   38b74:	eor	w8, w8, #0x1
   38b78:	stur	w8, [x29, #-36]
   38b7c:	b	38a38 <__gmpn_toom43_mul@@Base+0x3c4>

0000000000038b80 <__gmpn_toom53_mul@@Base>:
   38b80:	stp	x29, x30, [sp, #-96]!
   38b84:	stp	x28, x27, [sp, #16]
   38b88:	stp	x26, x25, [sp, #32]
   38b8c:	stp	x24, x23, [sp, #48]
   38b90:	stp	x22, x21, [sp, #64]
   38b94:	stp	x20, x19, [sp, #80]
   38b98:	mov	x29, sp
   38b9c:	sub	sp, sp, #0xa0
   38ba0:	add	x8, x2, x2, lsl #1
   38ba4:	add	x9, x4, x4, lsl #2
   38ba8:	cmp	x8, x9
   38bac:	mov	w10, #0x5                   	// #5
   38bb0:	mov	w11, #0x3                   	// #3
   38bb4:	csel	x8, x4, x2, lt  // lt = tstop
   38bb8:	csel	x9, x11, x10, lt  // lt = tstop
   38bbc:	sub	x8, x8, #0x1
   38bc0:	udiv	x8, x8, x9
   38bc4:	add	x21, x8, #0x1
   38bc8:	stur	x8, [x29, #-72]
   38bcc:	add	x23, x8, #0x2
   38bd0:	lsl	x8, x21, #1
   38bd4:	stur	x8, [x29, #-32]
   38bd8:	add	x8, x23, x23, lsl #2
   38bdc:	mov	x24, x1
   38be0:	lsl	x1, x8, #4
   38be4:	mov	w8, #0x7f00                	// #32512
   38be8:	mov	x20, x0
   38bec:	sub	x22, x2, x21, lsl #2
   38bf0:	sub	x9, x4, x21, lsl #1
   38bf4:	cmp	x1, x8
   38bf8:	stp	x3, x2, [x29, #-56]
   38bfc:	stur	x4, [x29, #-160]
   38c00:	stp	x9, xzr, [x29, #-16]
   38c04:	stur	x5, [x29, #-96]
   38c08:	b.hi	3928c <__gmpn_toom53_mul@@Base+0x70c>  // b.pmore
   38c0c:	add	x9, x1, #0xf
   38c10:	mov	x8, sp
   38c14:	and	x9, x9, #0xfffffffffffffff0
   38c18:	sub	x0, x8, x9
   38c1c:	mov	sp, x0
   38c20:	add	x1, x0, x23, lsl #3
   38c24:	add	x19, x1, x23, lsl #3
   38c28:	add	x25, x19, x23, lsl #3
   38c2c:	add	x28, x25, x23, lsl #3
   38c30:	lsl	x8, x21, #2
   38c34:	add	x26, x28, x23, lsl #3
   38c38:	stur	x8, [x29, #-64]
   38c3c:	add	x8, x26, x23, lsl #3
   38c40:	mov	w2, #0x4                   	// #4
   38c44:	mov	x3, x24
   38c48:	mov	x4, x21
   38c4c:	mov	x5, x22
   38c50:	mov	x6, x20
   38c54:	stp	x0, x8, [x29, #-88]
   38c58:	stur	x23, [x29, #-136]
   38c5c:	add	x27, x8, x23, lsl #3
   38c60:	stur	x1, [x29, #-120]
   38c64:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   38c68:	and	w8, w0, #0x2
   38c6c:	mov	w2, #0x4                   	// #4
   38c70:	mov	x0, x19
   38c74:	mov	x1, x25
   38c78:	mov	x3, x24
   38c7c:	mov	x4, x21
   38c80:	mov	x5, x22
   38c84:	mov	x6, x20
   38c88:	stur	w8, [x29, #-20]
   38c8c:	stp	x19, x25, [x29, #-152]
   38c90:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   38c94:	stur	w0, [x29, #-40]
   38c98:	add	x1, x24, x21, lsl #3
   38c9c:	mov	x0, x28
   38ca0:	mov	x2, x24
   38ca4:	mov	x3, x21
   38ca8:	bl	cc60 <__gmpn_addlsh1_n@plt>
   38cac:	ldur	x8, [x29, #-32]
   38cb0:	mov	x23, x0
   38cb4:	mov	x0, x28
   38cb8:	mov	x2, x28
   38cbc:	add	x1, x24, x8, lsl #3
   38cc0:	mov	x3, x21
   38cc4:	bl	cc60 <__gmpn_addlsh1_n@plt>
   38cc8:	mov	w8, #0x18                  	// #24
   38ccc:	add	x23, x0, x23, lsl #1
   38cd0:	madd	x1, x21, x8, x24
   38cd4:	mov	x0, x28
   38cd8:	mov	x2, x28
   38cdc:	mov	x3, x21
   38ce0:	bl	cc60 <__gmpn_addlsh1_n@plt>
   38ce4:	ldur	x19, [x29, #-72]
   38ce8:	add	x25, x0, x23, lsl #1
   38cec:	stp	x24, x22, [x29, #-112]
   38cf0:	cmp	x19, x22
   38cf4:	b.ge	38d20 <__gmpn_toom53_mul@@Base+0x1a0>  // b.tcont
   38cf8:	ldur	x8, [x29, #-64]
   38cfc:	mov	x0, x28
   38d00:	mov	x2, x28
   38d04:	mov	x3, x21
   38d08:	add	x1, x24, x8, lsl #3
   38d0c:	bl	cc60 <__gmpn_addlsh1_n@plt>
   38d10:	ldur	x23, [x29, #-56]
   38d14:	add	x8, x0, x25, lsl #1
   38d18:	str	x8, [x28, x21, lsl #3]
   38d1c:	b	38d90 <__gmpn_toom53_mul@@Base+0x210>
   38d20:	ldur	x8, [x29, #-64]
   38d24:	mov	x0, x28
   38d28:	mov	x2, x28
   38d2c:	mov	x3, x22
   38d30:	add	x1, x24, x8, lsl #3
   38d34:	bl	cc60 <__gmpn_addlsh1_n@plt>
   38d38:	add	x24, x28, x22, lsl #3
   38d3c:	mov	x23, x0
   38d40:	sub	x2, x21, x22
   38d44:	mov	w3, #0x1                   	// #1
   38d48:	mov	x0, x24
   38d4c:	mov	x1, x24
   38d50:	bl	c190 <__gmpn_lshift@plt>
   38d54:	add	x8, x0, x25, lsl #1
   38d58:	str	x8, [x28, x21, lsl #3]
   38d5c:	ldr	x8, [x24]
   38d60:	adds	x8, x8, x23
   38d64:	ldur	x23, [x29, #-56]
   38d68:	str	x8, [x24]
   38d6c:	b.cc	38d90 <__gmpn_toom53_mul@@Base+0x210>  // b.lo, b.ul, b.last
   38d70:	ldur	x8, [x29, #-88]
   38d74:	ldur	x9, [x29, #-48]
   38d78:	add	x8, x8, x9, lsl #3
   38d7c:	add	x8, x8, #0x28
   38d80:	ldr	x9, [x8]
   38d84:	adds	x9, x9, #0x1
   38d88:	str	x9, [x8], #8
   38d8c:	b.cs	38d80 <__gmpn_toom53_mul@@Base+0x200>  // b.hs, b.nlast
   38d90:	ldur	x25, [x29, #-136]
   38d94:	ldur	w22, [x29, #-20]
   38d98:	ldur	x24, [x29, #-16]
   38d9c:	stur	x28, [x29, #-128]
   38da0:	add	x8, x27, x25, lsl #3
   38da4:	stur	x8, [x29, #-48]
   38da8:	ldur	w8, [x29, #-40]
   38dac:	bfxil	w22, w8, #0, #1
   38db0:	ldur	x8, [x29, #-32]
   38db4:	add	x2, x23, x8, lsl #3
   38db8:	stur	x2, [x29, #-40]
   38dbc:	cbz	x24, 38df8 <__gmpn_toom53_mul@@Base+0x278>
   38dc0:	mov	x0, x26
   38dc4:	mov	x1, x23
   38dc8:	mov	x3, x24
   38dcc:	bl	ca90 <__gmpn_add_n@plt>
   38dd0:	cbz	x0, 38df8 <__gmpn_toom53_mul@@Base+0x278>
   38dd4:	ldur	x9, [x29, #-16]
   38dd8:	cmp	x9, x19
   38ddc:	b.gt	38e64 <__gmpn_toom53_mul@@Base+0x2e4>
   38de0:	ldr	x8, [x23, x9, lsl #3]
   38de4:	add	x24, x9, #0x1
   38de8:	adds	x10, x8, #0x1
   38dec:	str	x10, [x26, x9, lsl #3]
   38df0:	mov	x9, x24
   38df4:	b.cs	38dd8 <__gmpn_toom53_mul@@Base+0x258>  // b.hs, b.nlast
   38df8:	cmp	x26, x23
   38dfc:	b.eq	38e30 <__gmpn_toom53_mul@@Base+0x2b0>  // b.none
   38e00:	cmp	x24, x19
   38e04:	b.gt	38e30 <__gmpn_toom53_mul@@Base+0x2b0>
   38e08:	mov	w9, #0x28                  	// #40
   38e0c:	mul	x9, x19, x9
   38e10:	add	x8, x9, x24, lsl #3
   38e14:	ldur	x9, [x29, #-88]
   38e18:	sub	x10, x21, x24
   38e1c:	add	x1, x23, x24, lsl #3
   38e20:	lsl	x2, x10, #3
   38e24:	add	x8, x8, x9
   38e28:	add	x0, x8, #0x50
   38e2c:	bl	bee0 <memcpy@plt>
   38e30:	add	x1, x23, x21, lsl #3
   38e34:	mov	x8, x21
   38e38:	str	xzr, [x26, x21, lsl #3]
   38e3c:	subs	x8, x8, #0x1
   38e40:	b.lt	38e58 <__gmpn_toom53_mul@@Base+0x2d8>  // b.tstop
   38e44:	ldr	x9, [x26, x8, lsl #3]
   38e48:	ldr	x10, [x1, x8, lsl #3]
   38e4c:	cmp	x9, x10
   38e50:	b.eq	38e3c <__gmpn_toom53_mul@@Base+0x2bc>  // b.none
   38e54:	b.ls	39268 <__gmpn_toom53_mul@@Base+0x6e8>  // b.plast
   38e58:	stur	w22, [x29, #-20]
   38e5c:	mov	x22, xzr
   38e60:	b	38e70 <__gmpn_toom53_mul@@Base+0x2f0>
   38e64:	stur	w22, [x29, #-20]
   38e68:	mov	w22, #0x1                   	// #1
   38e6c:	str	x22, [x26, x21, lsl #3]
   38e70:	ldur	x19, [x29, #-80]
   38e74:	add	x2, x23, x21, lsl #3
   38e78:	mov	x1, x26
   38e7c:	mov	x3, x21
   38e80:	mov	x0, x19
   38e84:	bl	c2e0 <__gmpn_sub_n@plt>
   38e88:	sub	x8, x22, x0
   38e8c:	str	x8, [x19, x21, lsl #3]
   38e90:	ldur	x8, [x29, #-48]
   38e94:	add	x24, x23, x21, lsl #3
   38e98:	mov	x0, x26
   38e9c:	mov	x1, x26
   38ea0:	mov	x2, x24
   38ea4:	mov	x3, x21
   38ea8:	add	x22, x8, x25, lsl #3
   38eac:	bl	ca90 <__gmpn_add_n@plt>
   38eb0:	ldr	x8, [x26, x21, lsl #3]
   38eb4:	ldur	x28, [x29, #-16]
   38eb8:	ldur	x2, [x29, #-40]
   38ebc:	mov	x1, x23
   38ec0:	add	x8, x8, x0
   38ec4:	mov	x0, x27
   38ec8:	mov	x3, x28
   38ecc:	str	x8, [x26, x21, lsl #3]
   38ed0:	bl	cbc0 <__gmpn_addlsh2_n@plt>
   38ed4:	ldur	x19, [x29, #-72]
   38ed8:	cmp	x19, x28
   38edc:	b.lt	38fd8 <__gmpn_toom53_mul@@Base+0x458>  // b.tstop
   38ee0:	ldur	x9, [x29, #-16]
   38ee4:	add	x10, x23, x9, lsl #3
   38ee8:	ldr	x8, [x10]
   38eec:	add	x11, x27, x9, lsl #3
   38ef0:	sub	x9, x21, x9
   38ef4:	adds	x8, x8, x0
   38ef8:	str	x8, [x11]
   38efc:	b.cc	38f80 <__gmpn_toom53_mul@@Base+0x400>  // b.lo, b.ul, b.last
   38f00:	mov	w0, #0x1                   	// #1
   38f04:	mov	w8, #0x1                   	// #1
   38f08:	cmp	x8, x9
   38f0c:	b.ge	38fd8 <__gmpn_toom53_mul@@Base+0x458>  // b.tcont
   38f10:	ldr	x12, [x10, x8, lsl #3]
   38f14:	adds	x12, x12, #0x1
   38f18:	str	x12, [x11, x8, lsl #3]
   38f1c:	add	x8, x8, #0x1
   38f20:	b.cs	38f08 <__gmpn_toom53_mul@@Base+0x388>  // b.hs, b.nlast
   38f24:	cmp	x27, x23
   38f28:	mov	x0, xzr
   38f2c:	b.eq	38fd8 <__gmpn_toom53_mul@@Base+0x458>  // b.none
   38f30:	cmp	x8, x9
   38f34:	b.ge	38fd8 <__gmpn_toom53_mul@@Base+0x458>  // b.tcont
   38f38:	ldur	x12, [x29, #-160]
   38f3c:	mov	w9, #0x28                  	// #40
   38f40:	add	x11, x19, x19, lsl #1
   38f44:	mul	x9, x19, x9
   38f48:	add	x10, x8, x12
   38f4c:	sub	x10, x10, x19, lsl #1
   38f50:	sub	x11, x11, x8
   38f54:	add	x8, x9, x8, lsl #3
   38f58:	add	x9, x23, x10, lsl #3
   38f5c:	sub	x10, x11, x12
   38f60:	sub	x1, x9, #0x10
   38f64:	lsl	x9, x10, #3
   38f68:	ldur	x10, [x29, #-88]
   38f6c:	add	x8, x8, x12, lsl #3
   38f70:	add	x2, x9, #0x18
   38f74:	add	x8, x8, x10
   38f78:	add	x0, x8, #0x60
   38f7c:	b	38fd0 <__gmpn_toom53_mul@@Base+0x450>
   38f80:	cmp	x9, #0x2
   38f84:	mov	x0, xzr
   38f88:	b.lt	38fd8 <__gmpn_toom53_mul@@Base+0x458>  // b.tstop
   38f8c:	cmp	x27, x23
   38f90:	b.eq	38fd8 <__gmpn_toom53_mul@@Base+0x458>  // b.none
   38f94:	ldur	x11, [x29, #-160]
   38f98:	mov	w8, #0x28                  	// #40
   38f9c:	mov	x9, #0xffffffffffffffff    	// #-1
   38fa0:	add	x10, x19, x19, lsl #1
   38fa4:	mul	x8, x19, x8
   38fa8:	eor	x9, x9, x19, lsl #1
   38fac:	sub	x10, x10, x11
   38fb0:	add	x8, x8, x11, lsl #3
   38fb4:	add	x9, x9, x11
   38fb8:	ldur	x11, [x29, #-88]
   38fbc:	lsl	x10, x10, #3
   38fc0:	add	x1, x23, x9, lsl #3
   38fc4:	add	x2, x10, #0x10
   38fc8:	add	x8, x8, x11
   38fcc:	add	x0, x8, #0x68
   38fd0:	bl	bee0 <memcpy@plt>
   38fd4:	mov	x0, xzr
   38fd8:	str	x0, [x27, x21, lsl #3]
   38fdc:	mov	w3, #0x1                   	// #1
   38fe0:	mov	x0, x20
   38fe4:	mov	x1, x24
   38fe8:	mov	x2, x21
   38fec:	bl	c190 <__gmpn_lshift@plt>
   38ff0:	mov	x8, x25
   38ff4:	str	x0, [x20, x21, lsl #3]
   38ff8:	subs	x8, x8, #0x1
   38ffc:	b.lt	39014 <__gmpn_toom53_mul@@Base+0x494>  // b.tstop
   39000:	ldr	x9, [x27, x8, lsl #3]
   39004:	ldr	x10, [x20, x8, lsl #3]
   39008:	cmp	x9, x10
   3900c:	b.eq	38ff8 <__gmpn_toom53_mul@@Base+0x478>  // b.none
   39010:	b.ls	3902c <__gmpn_toom53_mul@@Base+0x4ac>  // b.plast
   39014:	ldur	x0, [x29, #-48]
   39018:	mov	x1, x27
   3901c:	mov	x2, x20
   39020:	mov	x3, x25
   39024:	bl	c2e0 <__gmpn_sub_n@plt>
   39028:	b	3904c <__gmpn_toom53_mul@@Base+0x4cc>
   3902c:	ldur	x0, [x29, #-48]
   39030:	mov	x1, x20
   39034:	mov	x2, x27
   39038:	mov	x3, x25
   3903c:	bl	c2e0 <__gmpn_sub_n@plt>
   39040:	ldur	w8, [x29, #-20]
   39044:	eor	w8, w8, #0x1
   39048:	stur	w8, [x29, #-20]
   3904c:	mov	x0, x27
   39050:	mov	x1, x27
   39054:	mov	x2, x20
   39058:	mov	x3, x25
   3905c:	bl	ca90 <__gmpn_add_n@plt>
   39060:	mov	x0, x22
   39064:	mov	x1, x24
   39068:	mov	x2, x23
   3906c:	mov	x3, x21
   39070:	bl	cc60 <__gmpn_addlsh1_n@plt>
   39074:	ldur	x28, [x29, #-16]
   39078:	mov	x24, x0
   3907c:	mov	x0, x22
   39080:	cmp	x19, x28
   39084:	b.lt	390e4 <__gmpn_toom53_mul@@Base+0x564>  // b.tstop
   39088:	ldur	x1, [x29, #-40]
   3908c:	mov	x2, x22
   39090:	mov	x3, x28
   39094:	bl	cc60 <__gmpn_addlsh1_n@plt>
   39098:	add	x23, x22, x28, lsl #3
   3909c:	mov	x19, x0
   390a0:	sub	x2, x21, x28
   390a4:	mov	w3, #0x1                   	// #1
   390a8:	mov	x0, x23
   390ac:	mov	x1, x23
   390b0:	bl	c190 <__gmpn_lshift@plt>
   390b4:	add	x8, x0, x24, lsl #1
   390b8:	str	x8, [x22, x21, lsl #3]
   390bc:	ldr	x8, [x23]
   390c0:	adds	x8, x8, x19
   390c4:	ldur	x19, [x29, #-64]
   390c8:	str	x8, [x23]
   390cc:	b.cc	39100 <__gmpn_toom53_mul@@Base+0x580>  // b.lo, b.ul, b.last
   390d0:	ldr	x8, [x23, #8]!
   390d4:	adds	x8, x8, #0x1
   390d8:	str	x8, [x23]
   390dc:	b.cs	390d0 <__gmpn_toom53_mul@@Base+0x550>  // b.hs, b.nlast
   390e0:	b	39100 <__gmpn_toom53_mul@@Base+0x580>
   390e4:	ldur	x1, [x29, #-40]
   390e8:	mov	x2, x22
   390ec:	mov	x3, x21
   390f0:	bl	cc60 <__gmpn_addlsh1_n@plt>
   390f4:	ldur	x19, [x29, #-64]
   390f8:	add	x8, x0, x24, lsl #1
   390fc:	str	x8, [x22, x21, lsl #3]
   39100:	ldur	x23, [x29, #-96]
   39104:	ldur	x1, [x29, #-152]
   39108:	mov	x2, x27
   3910c:	mov	x3, x25
   39110:	mov	x0, x23
   39114:	bl	c9b0 <__gmpn_mul_n@plt>
   39118:	mov	x28, x25
   3911c:	ldur	x25, [x29, #-32]
   39120:	ldur	x1, [x29, #-144]
   39124:	ldur	x2, [x29, #-48]
   39128:	mov	x3, x28
   3912c:	add	x8, x23, x25, lsl #3
   39130:	add	x24, x8, #0x8
   39134:	mov	x0, x24
   39138:	bl	c9b0 <__gmpn_mul_n@plt>
   3913c:	ldur	x1, [x29, #-128]
   39140:	add	x8, x23, x19, lsl #3
   39144:	add	x27, x8, #0x10
   39148:	mov	x0, x27
   3914c:	mov	x2, x22
   39150:	mov	x3, x28
   39154:	bl	c9b0 <__gmpn_mul_n@plt>
   39158:	add	x22, x21, x21, lsl #1
   3915c:	ldur	x1, [x29, #-120]
   39160:	ldur	x2, [x29, #-80]
   39164:	add	x8, x23, x22, lsl #4
   39168:	mov	x28, x19
   3916c:	add	x19, x8, #0x18
   39170:	str	xzr, [x19, x25, lsl #3]
   39174:	ldr	x8, [x1, x21, lsl #3]
   39178:	ldr	x9, [x2, x21, lsl #3]
   3917c:	mov	x0, x19
   39180:	orr	x8, x9, x8
   39184:	cmp	x8, #0x0
   39188:	cinc	x3, x21, ne  // ne = any
   3918c:	bl	c9b0 <__gmpn_mul_n@plt>
   39190:	ldur	x1, [x29, #-88]
   39194:	add	x0, x20, x25, lsl #3
   39198:	str	xzr, [x0, x25, lsl #3]
   3919c:	ldr	x9, [x26, x21, lsl #3]
   391a0:	ldr	x8, [x1, x21, lsl #3]
   391a4:	mov	x2, x26
   391a8:	orr	x8, x9, x8
   391ac:	cmp	x8, #0x0
   391b0:	cinc	x3, x21, ne  // ne = any
   391b4:	bl	c9b0 <__gmpn_mul_n@plt>
   391b8:	ldur	x26, [x29, #-112]
   391bc:	ldur	x2, [x29, #-56]
   391c0:	mov	x0, x20
   391c4:	mov	x3, x21
   391c8:	mov	x1, x26
   391cc:	bl	c9b0 <__gmpn_mul_n@plt>
   391d0:	add	x0, x20, x22, lsl #4
   391d4:	ldur	x22, [x29, #-104]
   391d8:	ldur	x25, [x29, #-16]
   391dc:	add	x3, x26, x28, lsl #3
   391e0:	cmp	x22, x25
   391e4:	b.le	391fc <__gmpn_toom53_mul@@Base+0x67c>
   391e8:	mov	x1, x3
   391ec:	ldur	x3, [x29, #-40]
   391f0:	mov	x2, x22
   391f4:	mov	x4, x25
   391f8:	b	39208 <__gmpn_toom53_mul@@Base+0x688>
   391fc:	ldur	x1, [x29, #-40]
   39200:	mov	x2, x25
   39204:	mov	x4, x22
   39208:	bl	ccf0 <__gmpn_mul@plt>
   3920c:	add	x8, x23, x21, lsl #6
   39210:	add	x8, x8, #0x20
   39214:	add	x7, x22, x25
   39218:	str	x8, [sp, #-16]!
   3921c:	ldur	w2, [x29, #-20]
   39220:	mov	x0, x20
   39224:	mov	x1, x21
   39228:	mov	x3, x24
   3922c:	mov	x4, x19
   39230:	mov	x5, x23
   39234:	mov	x6, x27
   39238:	bl	c830 <__gmpn_toom_interpolate_7pts@plt>
   3923c:	add	sp, sp, #0x10
   39240:	ldur	x0, [x29, #-8]
   39244:	cbnz	x0, 39298 <__gmpn_toom53_mul@@Base+0x718>
   39248:	mov	sp, x29
   3924c:	ldp	x20, x19, [sp, #80]
   39250:	ldp	x22, x21, [sp, #64]
   39254:	ldp	x24, x23, [sp, #48]
   39258:	ldp	x26, x25, [sp, #32]
   3925c:	ldp	x28, x27, [sp, #16]
   39260:	ldp	x29, x30, [sp], #96
   39264:	ret
   39268:	ldur	x19, [x29, #-80]
   3926c:	mov	x2, x26
   39270:	mov	x3, x21
   39274:	mov	x0, x19
   39278:	bl	c2e0 <__gmpn_sub_n@plt>
   3927c:	eor	w22, w22, #0x2
   39280:	str	xzr, [x19, x21, lsl #3]
   39284:	stur	w22, [x29, #-20]
   39288:	b	38e90 <__gmpn_toom53_mul@@Base+0x310>
   3928c:	sub	x0, x29, #0x8
   39290:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   39294:	b	38c20 <__gmpn_toom53_mul@@Base+0xa0>
   39298:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   3929c:	b	39248 <__gmpn_toom53_mul@@Base+0x6c8>

00000000000392a0 <__gmpn_toom54_mul@@Base>:
   392a0:	sub	sp, sp, #0xc0
   392a4:	add	x8, x4, x4, lsl #2
   392a8:	stp	x29, x30, [sp, #96]
   392ac:	stp	x20, x19, [sp, #176]
   392b0:	add	x29, sp, #0x60
   392b4:	mov	x19, x1
   392b8:	cmp	x8, x2, lsl #2
   392bc:	mov	x20, x0
   392c0:	stp	x28, x27, [sp, #112]
   392c4:	stp	x26, x25, [sp, #128]
   392c8:	stp	x24, x23, [sp, #144]
   392cc:	stp	x22, x21, [sp, #160]
   392d0:	stur	x5, [x29, #-24]
   392d4:	stur	x3, [x29, #-8]
   392d8:	b.le	392e4 <__gmpn_toom54_mul@@Base+0x44>
   392dc:	sub	x8, x4, #0x1
   392e0:	b	392f4 <__gmpn_toom54_mul@@Base+0x54>
   392e4:	mov	x9, #0xcccccccccccccccc    	// #-3689348814741910324
   392e8:	sub	x8, x2, #0x1
   392ec:	movk	x9, #0xcccd
   392f0:	umulh	x8, x8, x9
   392f4:	lsr	x23, x8, #2
   392f8:	add	x21, x23, #0x1
   392fc:	mov	w8, #0x28                  	// #40
   39300:	add	x24, x21, x21, lsl #1
   39304:	madd	x8, x21, x8, x20
   39308:	add	x28, x8, #0x10
   3930c:	add	x27, x20, x24, lsl #3
   39310:	lsl	x9, x21, #2
   39314:	sub	x5, x2, x21, lsl #2
   39318:	sub	x25, x4, x24
   3931c:	mov	w2, #0x4                   	// #4
   39320:	mov	w6, #0x2                   	// #2
   39324:	mov	x0, x28
   39328:	mov	x1, x27
   3932c:	mov	x3, x19
   39330:	mov	x4, x21
   39334:	mov	x7, x20
   39338:	str	x9, [sp, #40]
   3933c:	str	x5, [sp, #16]
   39340:	stur	x25, [x29, #-32]
   39344:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   39348:	lsl	x8, x24, #1
   3934c:	stur	x19, [x29, #-16]
   39350:	str	x8, [sp, #48]
   39354:	ldur	x3, [x29, #-8]
   39358:	add	x8, x20, x24, lsl #4
   3935c:	add	x9, x20, x21, lsl #5
   39360:	add	x26, x8, #0x18
   39364:	add	x19, x9, #0x8
   39368:	mov	w22, w0
   3936c:	mov	w2, #0x3                   	// #3
   39370:	mov	w6, #0x2                   	// #2
   39374:	mov	x0, x26
   39378:	mov	x1, x19
   3937c:	mov	x4, x21
   39380:	mov	x5, x25
   39384:	mov	x7, x20
   39388:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   3938c:	eor	w8, w0, w22
   39390:	add	x22, x23, #0x2
   39394:	mov	x0, x20
   39398:	mov	x1, x27
   3939c:	mov	x2, x19
   393a0:	mov	x3, x22
   393a4:	str	w8, [sp, #12]
   393a8:	bl	c9b0 <__gmpn_mul_n@plt>
   393ac:	ldur	x25, [x29, #-24]
   393b0:	str	x24, [sp, #32]
   393b4:	mov	x1, x28
   393b8:	mov	x2, x26
   393bc:	add	x8, x25, x24, lsl #3
   393c0:	add	x24, x8, #0x8
   393c4:	mov	x0, x24
   393c8:	mov	x3, x22
   393cc:	stur	x28, [x29, #-40]
   393d0:	bl	c9b0 <__gmpn_mul_n@plt>
   393d4:	ldr	w3, [sp, #12]
   393d8:	mov	w23, #0x1                   	// #1
   393dc:	bfi	x23, x21, #1, #63
   393e0:	mov	w5, #0x2                   	// #2
   393e4:	mov	w6, #0x4                   	// #4
   393e8:	mov	x0, x24
   393ec:	mov	x1, x23
   393f0:	mov	x2, x20
   393f4:	mov	x4, x21
   393f8:	str	x24, [sp, #24]
   393fc:	bl	c990 <__gmpn_toom_couple_handling@plt>
   39400:	mov	x0, x28
   39404:	ldr	x28, [sp, #16]
   39408:	ldur	x3, [x29, #-16]
   3940c:	mov	w2, #0x4                   	// #4
   39410:	mov	x1, x27
   39414:	mov	x4, x21
   39418:	mov	x5, x28
   3941c:	mov	x6, x20
   39420:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   39424:	ldur	x2, [x29, #-8]
   39428:	ldur	x4, [x29, #-32]
   3942c:	mov	w24, w0
   39430:	mov	x0, x26
   39434:	mov	x1, x19
   39438:	mov	x3, x21
   3943c:	mov	x5, x20
   39440:	bl	c290 <__gmpn_toom_eval_dgr3_pm1@plt>
   39444:	eor	w8, w0, w24
   39448:	mov	x0, x20
   3944c:	mov	x1, x27
   39450:	mov	x2, x19
   39454:	mov	x3, x22
   39458:	str	w8, [sp, #12]
   3945c:	bl	c9b0 <__gmpn_mul_n@plt>
   39460:	ldur	x24, [x29, #-40]
   39464:	mov	x0, x25
   39468:	mov	x2, x26
   3946c:	mov	x3, x22
   39470:	mov	x1, x24
   39474:	bl	c9b0 <__gmpn_mul_n@plt>
   39478:	ldr	w3, [sp, #12]
   3947c:	mov	x0, x25
   39480:	mov	x1, x23
   39484:	mov	x2, x20
   39488:	mov	x4, x21
   3948c:	mov	w5, wzr
   39490:	mov	w6, wzr
   39494:	bl	c990 <__gmpn_toom_couple_handling@plt>
   39498:	ldur	x3, [x29, #-16]
   3949c:	mov	w2, #0x4                   	// #4
   394a0:	mov	x0, x24
   394a4:	mov	x1, x27
   394a8:	mov	x4, x21
   394ac:	mov	x5, x28
   394b0:	mov	x6, x20
   394b4:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   394b8:	ldur	x25, [x29, #-32]
   394bc:	ldur	x2, [x29, #-8]
   394c0:	mov	w24, w0
   394c4:	mov	x0, x26
   394c8:	mov	x1, x19
   394cc:	mov	x3, x21
   394d0:	mov	x4, x25
   394d4:	mov	x5, x20
   394d8:	bl	cd80 <__gmpn_toom_eval_dgr3_pm2@plt>
   394dc:	eor	w24, w0, w24
   394e0:	mov	x0, x20
   394e4:	mov	x1, x27
   394e8:	mov	x2, x19
   394ec:	mov	x3, x22
   394f0:	bl	c9b0 <__gmpn_mul_n@plt>
   394f4:	ldur	x1, [x29, #-40]
   394f8:	mov	x3, x22
   394fc:	ldur	x22, [x29, #-16]
   39500:	mov	x0, x27
   39504:	mov	x2, x26
   39508:	bl	c9b0 <__gmpn_mul_n@plt>
   3950c:	ldur	x19, [x29, #-8]
   39510:	mov	w5, #0x1                   	// #1
   39514:	mov	w6, #0x2                   	// #2
   39518:	mov	x0, x27
   3951c:	mov	x1, x23
   39520:	mov	x2, x20
   39524:	mov	w3, w24
   39528:	mov	x4, x21
   3952c:	bl	c990 <__gmpn_toom_couple_handling@plt>
   39530:	mov	x0, x20
   39534:	mov	x1, x22
   39538:	mov	x2, x19
   3953c:	mov	x3, x21
   39540:	bl	c9b0 <__gmpn_mul_n@plt>
   39544:	mov	w8, #0x38                  	// #56
   39548:	cmp	x28, x25
   3954c:	madd	x0, x21, x8, x20
   39550:	b.le	39570 <__gmpn_toom54_mul@@Base+0x2d0>
   39554:	ldr	x8, [sp, #40]
   39558:	mov	x2, x28
   3955c:	mov	x4, x25
   39560:	add	x1, x22, x8, lsl #3
   39564:	ldr	x8, [sp, #32]
   39568:	add	x3, x19, x8, lsl #3
   3956c:	b	39588 <__gmpn_toom54_mul@@Base+0x2e8>
   39570:	ldr	x8, [sp, #32]
   39574:	mov	x2, x25
   39578:	mov	x4, x28
   3957c:	add	x1, x19, x8, lsl #3
   39580:	ldr	x8, [sp, #40]
   39584:	add	x3, x22, x8, lsl #3
   39588:	bl	ccf0 <__gmpn_mul@plt>
   3958c:	ldur	x3, [x29, #-24]
   39590:	ldr	x8, [sp, #48]
   39594:	add	x4, x28, x25
   39598:	mov	x0, x20
   3959c:	mov	x1, x21
   395a0:	ldr	x2, [sp, #24]
   395a4:	ldp	x20, x19, [sp, #176]
   395a8:	ldp	x22, x21, [sp, #160]
   395ac:	ldp	x24, x23, [sp, #144]
   395b0:	ldp	x26, x25, [sp, #128]
   395b4:	ldp	x28, x27, [sp, #112]
   395b8:	ldp	x29, x30, [sp, #96]
   395bc:	add	x8, x3, x8, lsl #3
   395c0:	add	x5, x8, #0x10
   395c4:	add	sp, sp, #0xc0
   395c8:	b	c7d0 <__gmpn_toom_interpolate_8pts@plt>

00000000000395cc <__gmpn_toom63_mul@@Base>:
   395cc:	sub	sp, sp, #0xe0
   395d0:	lsl	x8, x4, #1
   395d4:	cmp	x8, x2
   395d8:	mov	w9, #0x6                   	// #6
   395dc:	mov	w10, #0x3                   	// #3
   395e0:	csel	x8, x4, x2, gt
   395e4:	csel	x9, x10, x9, gt
   395e8:	sub	x8, x8, #0x1
   395ec:	stp	x26, x25, [sp, #160]
   395f0:	udiv	x26, x8, x9
   395f4:	stp	x22, x21, [sp, #192]
   395f8:	add	x21, x26, #0x1
   395fc:	stp	x29, x30, [sp, #128]
   39600:	add	x29, sp, #0x80
   39604:	add	x8, x21, x21, lsl #2
   39608:	lsl	x9, x21, #1
   3960c:	stp	x28, x27, [sp, #144]
   39610:	stp	x24, x23, [sp, #176]
   39614:	stp	x20, x19, [sp, #208]
   39618:	stur	x5, [x29, #-8]
   3961c:	mov	x20, x0
   39620:	stp	x8, x9, [sp, #32]
   39624:	add	x28, x21, x21, lsl #1
   39628:	sub	x5, x2, x8
   3962c:	add	x8, x0, x8, lsl #3
   39630:	mov	x25, x3
   39634:	mov	x3, x1
   39638:	sub	x22, x4, x21, lsl #1
   3963c:	add	x0, x8, #0x10
   39640:	add	x1, x20, x28, lsl #3
   39644:	mov	w2, #0x5                   	// #5
   39648:	mov	w6, #0x2                   	// #2
   3964c:	mov	x4, x21
   39650:	mov	x7, x20
   39654:	stur	x0, [x29, #-40]
   39658:	stp	x1, x3, [x29, #-24]
   3965c:	stur	x5, [x29, #-56]
   39660:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   39664:	mov	w24, w0
   39668:	add	x1, x25, x21, lsl #3
   3966c:	mov	w3, #0x2                   	// #2
   39670:	mov	x0, x20
   39674:	mov	x2, x21
   39678:	str	x1, [sp, #56]
   3967c:	bl	c190 <__gmpn_lshift@plt>
   39680:	lsl	x8, x28, #1
   39684:	str	x8, [sp, #16]
   39688:	add	x8, x20, x28, lsl #4
   3968c:	add	x27, x8, #0x18
   39690:	str	x0, [x20, x21, lsl #3]
   39694:	add	x1, x25, x21, lsl #4
   39698:	mov	w3, #0x4                   	// #4
   3969c:	mov	x0, x27
   396a0:	mov	x2, x22
   396a4:	stur	x1, [x29, #-48]
   396a8:	bl	c190 <__gmpn_lshift@plt>
   396ac:	cmp	x21, x22
   396b0:	str	x0, [x27, x22, lsl #3]
   396b4:	stur	x22, [x29, #-32]
   396b8:	b.ne	396dc <__gmpn_toom63_mul@@Base+0x110>  // b.any
   396bc:	mov	x0, x27
   396c0:	mov	x1, x27
   396c4:	mov	x2, x25
   396c8:	mov	x3, x21
   396cc:	bl	ca90 <__gmpn_add_n@plt>
   396d0:	ldr	x8, [x27, x21, lsl #3]
   396d4:	add	x8, x8, x0
   396d8:	b	39760 <__gmpn_toom63_mul@@Base+0x194>
   396dc:	adds	x23, x22, #0x1
   396e0:	b.cc	396ec <__gmpn_toom63_mul@@Base+0x120>  // b.lo, b.ul, b.last
   396e4:	mov	x9, xzr
   396e8:	b	39730 <__gmpn_toom63_mul@@Base+0x164>
   396ec:	mov	x0, x27
   396f0:	mov	x1, x25
   396f4:	mov	x2, x27
   396f8:	mov	x3, x23
   396fc:	bl	ca90 <__gmpn_add_n@plt>
   39700:	cbz	x0, 3972c <__gmpn_toom63_mul@@Base+0x160>
   39704:	mov	w8, #0x1                   	// #1
   39708:	cmp	x23, x26
   3970c:	b.gt	39760 <__gmpn_toom63_mul@@Base+0x194>
   39710:	ldr	x9, [x25, x23, lsl #3]
   39714:	adds	x10, x9, #0x1
   39718:	add	x9, x23, #0x1
   3971c:	str	x10, [x27, x23, lsl #3]
   39720:	mov	x23, x9
   39724:	b.cs	39708 <__gmpn_toom63_mul@@Base+0x13c>  // b.hs, b.nlast
   39728:	b	39730 <__gmpn_toom63_mul@@Base+0x164>
   3972c:	mov	x9, x23
   39730:	cmp	x27, x25
   39734:	mov	x8, xzr
   39738:	b.eq	39760 <__gmpn_toom63_mul@@Base+0x194>  // b.none
   3973c:	cmp	x9, x26
   39740:	b.gt	39760 <__gmpn_toom63_mul@@Base+0x194>
   39744:	ldr	x8, [x25, x9, lsl #3]
   39748:	add	x10, x9, #0x1
   3974c:	cmp	x9, x26
   39750:	str	x8, [x27, x9, lsl #3]
   39754:	mov	x9, x10
   39758:	b.ne	39744 <__gmpn_toom63_mul@@Base+0x178>  // b.any
   3975c:	mov	x8, xzr
   39760:	str	x8, [x27, x21, lsl #3]
   39764:	add	x8, x20, x21, lsl #5
   39768:	add	x23, x8, #0x8
   3976c:	add	x19, x26, #0x2
   39770:	mov	x0, x23
   39774:	mov	x1, x27
   39778:	mov	x2, x20
   3977c:	mov	x3, x19
   39780:	bl	39bb4 <__gmpn_toom63_mul@@Base+0x5e8>
   39784:	eor	w8, w0, w24
   39788:	str	w8, [sp, #12]
   3978c:	ldur	x22, [x29, #-24]
   39790:	mov	x0, x20
   39794:	mov	x2, x23
   39798:	mov	x3, x19
   3979c:	mov	x1, x22
   397a0:	str	x23, [sp, #48]
   397a4:	bl	c9b0 <__gmpn_mul_n@plt>
   397a8:	ldur	x23, [x29, #-8]
   397ac:	mov	x2, x27
   397b0:	mov	x3, x19
   397b4:	add	x8, x23, x28, lsl #3
   397b8:	ldur	x28, [x29, #-40]
   397bc:	add	x24, x8, #0x8
   397c0:	mov	x0, x24
   397c4:	str	x19, [sp, #64]
   397c8:	mov	x1, x28
   397cc:	bl	c9b0 <__gmpn_mul_n@plt>
   397d0:	ldr	x8, [sp, #40]
   397d4:	ldr	w3, [sp, #12]
   397d8:	mov	w5, #0x2                   	// #2
   397dc:	mov	w6, #0x4                   	// #4
   397e0:	orr	x1, x8, #0x1
   397e4:	mov	x0, x24
   397e8:	mov	x2, x20
   397ec:	mov	x4, x21
   397f0:	str	x24, [sp, #24]
   397f4:	str	x1, [sp, #40]
   397f8:	bl	c990 <__gmpn_toom_couple_handling@plt>
   397fc:	ldur	x3, [x29, #-16]
   39800:	ldur	x5, [x29, #-56]
   39804:	mov	w2, #0x5                   	// #5
   39808:	mov	x0, x28
   3980c:	mov	x1, x22
   39810:	mov	x4, x21
   39814:	mov	x6, x20
   39818:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   3981c:	ldr	x8, [sp, #16]
   39820:	ldur	x22, [x29, #-32]
   39824:	mov	w24, w0
   39828:	add	x8, x23, x8, lsl #3
   3982c:	add	x19, x8, #0x10
   39830:	cbz	x22, 39878 <__gmpn_toom63_mul@@Base+0x2ac>
   39834:	ldur	x2, [x29, #-48]
   39838:	mov	x0, x19
   3983c:	mov	x1, x25
   39840:	mov	x3, x22
   39844:	bl	ca90 <__gmpn_add_n@plt>
   39848:	mov	x8, x22
   3984c:	cbz	x0, 3987c <__gmpn_toom63_mul@@Base+0x2b0>
   39850:	mov	w28, #0x1                   	// #1
   39854:	cmp	x22, x26
   39858:	b.gt	398b4 <__gmpn_toom63_mul@@Base+0x2e8>
   3985c:	ldr	x8, [x25, x22, lsl #3]
   39860:	adds	x10, x8, #0x1
   39864:	add	x8, x22, #0x1
   39868:	str	x10, [x19, x22, lsl #3]
   3986c:	mov	x22, x8
   39870:	b.cs	39854 <__gmpn_toom63_mul@@Base+0x288>  // b.hs, b.nlast
   39874:	b	3987c <__gmpn_toom63_mul@@Base+0x2b0>
   39878:	mov	x8, xzr
   3987c:	cmp	x19, x25
   39880:	mov	x28, xzr
   39884:	b.eq	398b4 <__gmpn_toom63_mul@@Base+0x2e8>  // b.none
   39888:	ldr	x22, [sp, #56]
   3988c:	cmp	x8, x26
   39890:	b.gt	398b8 <__gmpn_toom63_mul@@Base+0x2ec>
   39894:	ldr	x9, [x25, x8, lsl #3]
   39898:	add	x10, x8, #0x1
   3989c:	cmp	x8, x26
   398a0:	str	x9, [x19, x8, lsl #3]
   398a4:	mov	x8, x10
   398a8:	b.ne	39894 <__gmpn_toom63_mul@@Base+0x2c8>  // b.any
   398ac:	mov	x28, xzr
   398b0:	b	398b8 <__gmpn_toom63_mul@@Base+0x2ec>
   398b4:	ldr	x22, [sp, #56]
   398b8:	mov	x0, x27
   398bc:	mov	x1, x19
   398c0:	mov	x2, x22
   398c4:	mov	x3, x21
   398c8:	bl	ca90 <__gmpn_add_n@plt>
   398cc:	add	x8, x0, x28
   398d0:	str	x8, [x27, x21, lsl #3]
   398d4:	cbz	x28, 399ec <__gmpn_toom63_mul@@Base+0x420>
   398d8:	ldr	x23, [sp, #48]
   398dc:	mov	x1, x19
   398e0:	mov	x2, x22
   398e4:	mov	x3, x21
   398e8:	mov	x0, x23
   398ec:	str	w24, [sp, #16]
   398f0:	bl	c2e0 <__gmpn_sub_n@plt>
   398f4:	sub	x8, x28, x0
   398f8:	str	x8, [x23, x21, lsl #3]
   398fc:	ldur	x22, [x29, #-24]
   39900:	ldr	x24, [sp, #64]
   39904:	mov	x0, x20
   39908:	mov	x2, x23
   3990c:	mov	x1, x22
   39910:	mov	x3, x24
   39914:	bl	c9b0 <__gmpn_mul_n@plt>
   39918:	ldur	x28, [x29, #-8]
   3991c:	ldur	x23, [x29, #-40]
   39920:	mov	x2, x27
   39924:	mov	x3, x24
   39928:	mov	x0, x28
   3992c:	mov	x1, x23
   39930:	bl	c9b0 <__gmpn_mul_n@plt>
   39934:	ldr	x1, [sp, #40]
   39938:	ldr	w3, [sp, #16]
   3993c:	mov	x0, x28
   39940:	mov	x2, x20
   39944:	mov	x4, x21
   39948:	mov	w5, wzr
   3994c:	mov	w6, wzr
   39950:	bl	c990 <__gmpn_toom_couple_handling@plt>
   39954:	ldur	x28, [x29, #-56]
   39958:	ldur	x3, [x29, #-16]
   3995c:	mov	w2, #0x5                   	// #5
   39960:	mov	x0, x23
   39964:	mov	x1, x22
   39968:	mov	x4, x21
   3996c:	mov	x5, x28
   39970:	mov	x6, x20
   39974:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   39978:	ldr	x1, [sp, #56]
   3997c:	mov	w24, w0
   39980:	mov	w3, #0x1                   	// #1
   39984:	mov	x0, x20
   39988:	mov	x2, x21
   3998c:	bl	c190 <__gmpn_lshift@plt>
   39990:	ldur	x22, [x29, #-32]
   39994:	ldur	x1, [x29, #-48]
   39998:	str	x0, [x20, x21, lsl #3]
   3999c:	mov	w3, #0x2                   	// #2
   399a0:	mov	x0, x27
   399a4:	mov	x2, x22
   399a8:	bl	c190 <__gmpn_lshift@plt>
   399ac:	cmp	x21, x22
   399b0:	str	x0, [x27, x22, lsl #3]
   399b4:	b.ne	399d8 <__gmpn_toom63_mul@@Base+0x40c>  // b.any
   399b8:	mov	x0, x27
   399bc:	mov	x1, x27
   399c0:	mov	x2, x25
   399c4:	mov	x3, x21
   399c8:	bl	ca90 <__gmpn_add_n@plt>
   399cc:	ldr	x8, [x27, x21, lsl #3]
   399d0:	add	x8, x8, x0
   399d4:	b	39ab4 <__gmpn_toom63_mul@@Base+0x4e8>
   399d8:	mov	w23, w24
   399dc:	adds	x24, x22, #0x1
   399e0:	b.cc	39a34 <__gmpn_toom63_mul@@Base+0x468>  // b.lo, b.ul, b.last
   399e4:	mov	x9, xzr
   399e8:	b	39a78 <__gmpn_toom63_mul@@Base+0x4ac>
   399ec:	mov	x8, x21
   399f0:	subs	x8, x8, #0x1
   399f4:	b.lt	398d8 <__gmpn_toom63_mul@@Base+0x30c>  // b.tstop
   399f8:	ldr	x9, [x19, x8, lsl #3]
   399fc:	ldr	x10, [x22, x8, lsl #3]
   39a00:	cmp	x9, x10
   39a04:	b.eq	399f0 <__gmpn_toom63_mul@@Base+0x424>  // b.none
   39a08:	b.hi	398d8 <__gmpn_toom63_mul@@Base+0x30c>  // b.pmore
   39a0c:	ldr	x23, [sp, #48]
   39a10:	mov	x1, x22
   39a14:	mov	x2, x19
   39a18:	mov	x3, x21
   39a1c:	mov	x0, x23
   39a20:	bl	c2e0 <__gmpn_sub_n@plt>
   39a24:	mvn	w24, w24
   39a28:	str	xzr, [x23, x21, lsl #3]
   39a2c:	str	w24, [sp, #16]
   39a30:	b	398fc <__gmpn_toom63_mul@@Base+0x330>
   39a34:	mov	x0, x27
   39a38:	mov	x1, x25
   39a3c:	mov	x2, x27
   39a40:	mov	x3, x24
   39a44:	bl	ca90 <__gmpn_add_n@plt>
   39a48:	cbz	x0, 39a74 <__gmpn_toom63_mul@@Base+0x4a8>
   39a4c:	mov	w8, #0x1                   	// #1
   39a50:	cmp	x24, x26
   39a54:	b.gt	39ab0 <__gmpn_toom63_mul@@Base+0x4e4>
   39a58:	ldr	x9, [x25, x24, lsl #3]
   39a5c:	adds	x10, x9, #0x1
   39a60:	add	x9, x24, #0x1
   39a64:	str	x10, [x27, x24, lsl #3]
   39a68:	mov	x24, x9
   39a6c:	b.cs	39a50 <__gmpn_toom63_mul@@Base+0x484>  // b.hs, b.nlast
   39a70:	b	39a78 <__gmpn_toom63_mul@@Base+0x4ac>
   39a74:	mov	x9, x24
   39a78:	cmp	x27, x25
   39a7c:	mov	x8, xzr
   39a80:	mov	w24, w23
   39a84:	b.eq	39ab4 <__gmpn_toom63_mul@@Base+0x4e8>  // b.none
   39a88:	cmp	x9, x26
   39a8c:	b.gt	39ab4 <__gmpn_toom63_mul@@Base+0x4e8>
   39a90:	ldr	x8, [x25, x9, lsl #3]
   39a94:	add	x10, x9, #0x1
   39a98:	cmp	x9, x26
   39a9c:	str	x8, [x27, x9, lsl #3]
   39aa0:	mov	x9, x10
   39aa4:	b.ne	39a90 <__gmpn_toom63_mul@@Base+0x4c4>  // b.any
   39aa8:	mov	x8, xzr
   39aac:	b	39ab4 <__gmpn_toom63_mul@@Base+0x4e8>
   39ab0:	mov	w24, w23
   39ab4:	ldr	x26, [sp, #48]
   39ab8:	ldr	x23, [sp, #64]
   39abc:	mov	x1, x27
   39ac0:	mov	x2, x20
   39ac4:	mov	x0, x26
   39ac8:	mov	x3, x23
   39acc:	str	x8, [x27, x21, lsl #3]
   39ad0:	bl	39bb4 <__gmpn_toom63_mul@@Base+0x5e8>
   39ad4:	ldur	x22, [x29, #-24]
   39ad8:	eor	w24, w0, w24
   39adc:	mov	x0, x20
   39ae0:	mov	x2, x26
   39ae4:	mov	x1, x22
   39ae8:	mov	x3, x23
   39aec:	bl	c9b0 <__gmpn_mul_n@plt>
   39af0:	ldur	x1, [x29, #-40]
   39af4:	mov	x0, x22
   39af8:	mov	x2, x27
   39afc:	mov	x3, x23
   39b00:	bl	c9b0 <__gmpn_mul_n@plt>
   39b04:	ldr	x1, [sp, #40]
   39b08:	mov	w5, #0x1                   	// #1
   39b0c:	mov	w6, #0x2                   	// #2
   39b10:	mov	x0, x22
   39b14:	mov	x2, x20
   39b18:	mov	w3, w24
   39b1c:	mov	x4, x21
   39b20:	bl	c990 <__gmpn_toom_couple_handling@plt>
   39b24:	ldur	x23, [x29, #-16]
   39b28:	mov	x0, x20
   39b2c:	mov	x2, x25
   39b30:	mov	x3, x21
   39b34:	mov	x1, x23
   39b38:	bl	c9b0 <__gmpn_mul_n@plt>
   39b3c:	mov	w8, #0x38                  	// #56
   39b40:	ldur	x22, [x29, #-32]
   39b44:	madd	x0, x21, x8, x20
   39b48:	ldr	x8, [sp, #32]
   39b4c:	cmp	x28, x22
   39b50:	add	x3, x23, x8, lsl #3
   39b54:	b.le	39b6c <__gmpn_toom63_mul@@Base+0x5a0>
   39b58:	mov	x1, x3
   39b5c:	ldur	x3, [x29, #-48]
   39b60:	mov	x2, x28
   39b64:	mov	x4, x22
   39b68:	b	39b78 <__gmpn_toom63_mul@@Base+0x5ac>
   39b6c:	ldur	x1, [x29, #-48]
   39b70:	mov	x2, x22
   39b74:	mov	x4, x28
   39b78:	bl	ccf0 <__gmpn_mul@plt>
   39b7c:	add	x4, x28, x22
   39b80:	mov	x0, x20
   39b84:	mov	x1, x21
   39b88:	ldr	x2, [sp, #24]
   39b8c:	ldur	x3, [x29, #-8]
   39b90:	mov	x5, x19
   39b94:	ldp	x20, x19, [sp, #208]
   39b98:	ldp	x22, x21, [sp, #192]
   39b9c:	ldp	x24, x23, [sp, #176]
   39ba0:	ldp	x26, x25, [sp, #160]
   39ba4:	ldp	x28, x27, [sp, #144]
   39ba8:	ldp	x29, x30, [sp, #128]
   39bac:	add	sp, sp, #0xe0
   39bb0:	b	c7d0 <__gmpn_toom_interpolate_8pts@plt>
   39bb4:	stp	x29, x30, [sp, #-48]!
   39bb8:	stp	x22, x21, [sp, #16]
   39bbc:	stp	x20, x19, [sp, #32]
   39bc0:	mov	x19, x3
   39bc4:	mov	x20, x2
   39bc8:	mov	x21, x1
   39bcc:	cmp	x3, #0x1
   39bd0:	mov	x29, sp
   39bd4:	b.lt	39c24 <__gmpn_toom63_mul@@Base+0x658>  // b.tstop
   39bd8:	sub	x8, x0, #0x8
   39bdc:	sub	x9, x20, #0x8
   39be0:	sub	x10, x21, #0x8
   39be4:	mov	x3, x19
   39be8:	ldr	x11, [x10, x3, lsl #3]
   39bec:	ldr	x12, [x9, x3, lsl #3]
   39bf0:	cmp	x11, x12
   39bf4:	b.ne	39c14 <__gmpn_toom63_mul@@Base+0x648>  // b.any
   39bf8:	sub	x11, x3, #0x1
   39bfc:	add	x12, x11, #0x1
   39c00:	cmp	x12, #0x1
   39c04:	str	xzr, [x8, x3, lsl #3]
   39c08:	mov	x3, x11
   39c0c:	b.gt	39be8 <__gmpn_toom63_mul@@Base+0x61c>
   39c10:	b	39c24 <__gmpn_toom63_mul@@Base+0x658>
   39c14:	b.ls	39c50 <__gmpn_toom63_mul@@Base+0x684>  // b.plast
   39c18:	mov	x1, x21
   39c1c:	mov	x2, x20
   39c20:	bl	c2e0 <__gmpn_sub_n@plt>
   39c24:	mov	w22, wzr
   39c28:	mov	x0, x21
   39c2c:	mov	x1, x21
   39c30:	mov	x2, x20
   39c34:	mov	x3, x19
   39c38:	bl	ca90 <__gmpn_add_n@plt>
   39c3c:	mov	w0, w22
   39c40:	ldp	x20, x19, [sp, #32]
   39c44:	ldp	x22, x21, [sp, #16]
   39c48:	ldp	x29, x30, [sp], #48
   39c4c:	ret
   39c50:	mov	x1, x20
   39c54:	mov	x2, x21
   39c58:	bl	c2e0 <__gmpn_sub_n@plt>
   39c5c:	mov	w22, #0xffffffff            	// #-1
   39c60:	b	39c28 <__gmpn_toom63_mul@@Base+0x65c>

0000000000039c64 <__gmpn_toom44_mul@@Base>:
   39c64:	sub	sp, sp, #0xe0
   39c68:	stp	x26, x25, [sp, #160]
   39c6c:	mov	x25, x2
   39c70:	stp	x20, x19, [sp, #208]
   39c74:	add	x19, x25, #0x3
   39c78:	stp	x22, x21, [sp, #192]
   39c7c:	asr	x21, x19, #2
   39c80:	lsl	x10, x21, #1
   39c84:	add	x8, x0, x21, lsl #3
   39c88:	add	x9, x5, x21, lsl #6
   39c8c:	stp	x4, x10, [sp, #56]
   39c90:	add	x10, x10, x19, asr #2
   39c94:	stp	x28, x27, [sp, #144]
   39c98:	add	x28, x8, #0x8
   39c9c:	sub	x8, x25, x10
   39ca0:	add	x22, x9, #0x28
   39ca4:	stp	x29, x30, [sp, #128]
   39ca8:	stp	x24, x23, [sp, #176]
   39cac:	add	x29, sp, #0x80
   39cb0:	mov	x23, x5
   39cb4:	mov	x26, x3
   39cb8:	mov	x2, x1
   39cbc:	sub	x24, x4, x10
   39cc0:	mov	x1, x28
   39cc4:	mov	x3, x21
   39cc8:	mov	x4, x8
   39ccc:	mov	x5, x22
   39cd0:	mov	x20, x0
   39cd4:	stur	x10, [x29, #-8]
   39cd8:	stur	x2, [x29, #-48]
   39cdc:	stur	x8, [x29, #-24]
   39ce0:	bl	cd80 <__gmpn_toom_eval_dgr3_pm2@plt>
   39ce4:	and	x8, x19, #0xfffffffffffffffc
   39ce8:	add	x9, x20, x21, lsl #4
   39cec:	str	x8, [sp, #16]
   39cf0:	add	x8, x20, x8, lsl #3
   39cf4:	add	x27, x8, #0x10
   39cf8:	add	x19, x9, #0x10
   39cfc:	str	w0, [sp, #12]
   39d00:	mov	x0, x27
   39d04:	mov	x1, x19
   39d08:	mov	x2, x26
   39d0c:	mov	x3, x21
   39d10:	mov	x4, x24
   39d14:	mov	x5, x22
   39d18:	str	x9, [sp, #32]
   39d1c:	stp	x24, x26, [x29, #-40]
   39d20:	bl	cd80 <__gmpn_toom_eval_dgr3_pm2@plt>
   39d24:	add	x24, x21, #0x1
   39d28:	str	w0, [sp, #8]
   39d2c:	cmp	x25, #0xbc
   39d30:	mov	x0, x23
   39d34:	mov	x1, x20
   39d38:	mov	x2, x24
   39d3c:	mov	x3, x27
   39d40:	mov	x4, x24
   39d44:	mov	x5, x22
   39d48:	stur	x25, [x29, #-56]
   39d4c:	stur	x23, [x29, #-16]
   39d50:	str	x28, [sp, #40]
   39d54:	str	x19, [sp, #24]
   39d58:	b.le	39d8c <__gmpn_toom44_mul@@Base+0x128>
   39d5c:	bl	c0b0 <__gmpn_toom33_mul@plt>
   39d60:	ldr	x25, [sp, #64]
   39d64:	mov	x1, x28
   39d68:	mov	x2, x24
   39d6c:	mov	x3, x19
   39d70:	add	x8, x23, x25, lsl #3
   39d74:	add	x0, x8, #0x8
   39d78:	mov	x4, x24
   39d7c:	mov	x5, x22
   39d80:	str	x0, [sp, #48]
   39d84:	bl	c0b0 <__gmpn_toom33_mul@plt>
   39d88:	b	39db8 <__gmpn_toom44_mul@@Base+0x154>
   39d8c:	bl	d470 <__gmpn_toom22_mul@plt>
   39d90:	ldr	x25, [sp, #64]
   39d94:	mov	x1, x28
   39d98:	mov	x2, x24
   39d9c:	mov	x3, x19
   39da0:	add	x8, x23, x25, lsl #3
   39da4:	add	x0, x8, #0x8
   39da8:	mov	x4, x24
   39dac:	mov	x5, x22
   39db0:	str	x0, [sp, #48]
   39db4:	bl	d470 <__gmpn_toom22_mul@plt>
   39db8:	mov	x19, x25
   39dbc:	ldur	x25, [x29, #-48]
   39dc0:	mov	x0, x20
   39dc4:	mov	x3, x21
   39dc8:	add	x1, x25, x21, lsl #3
   39dcc:	mov	x2, x25
   39dd0:	bl	cc60 <__gmpn_addlsh1_n@plt>
   39dd4:	mov	x23, x0
   39dd8:	add	x1, x25, x19, lsl #3
   39ddc:	mov	x0, x20
   39de0:	mov	x2, x20
   39de4:	mov	x3, x21
   39de8:	bl	cc60 <__gmpn_addlsh1_n@plt>
   39dec:	ldur	x28, [x29, #-24]
   39df0:	add	x26, x0, x23, lsl #1
   39df4:	subs	x19, x21, x28
   39df8:	b.le	39e64 <__gmpn_toom44_mul@@Base+0x200>
   39dfc:	ldur	x8, [x29, #-8]
   39e00:	mov	x0, x20
   39e04:	mov	x2, x20
   39e08:	mov	x3, x28
   39e0c:	add	x1, x25, x8, lsl #3
   39e10:	bl	cc60 <__gmpn_addlsh1_n@plt>
   39e14:	mov	x8, x28
   39e18:	add	x23, x20, x8, lsl #3
   39e1c:	mov	x28, x0
   39e20:	mov	w3, #0x1                   	// #1
   39e24:	mov	x0, x23
   39e28:	mov	x1, x23
   39e2c:	mov	x2, x19
   39e30:	bl	c190 <__gmpn_lshift@plt>
   39e34:	add	x8, x0, x26, lsl #1
   39e38:	str	x8, [x20, x21, lsl #3]
   39e3c:	ldr	x8, [x23]
   39e40:	adds	x8, x8, x28
   39e44:	str	x8, [x23]
   39e48:	b.cc	39e84 <__gmpn_toom44_mul@@Base+0x220>  // b.lo, b.ul, b.last
   39e4c:	add	x8, x23, #0x8
   39e50:	ldr	x9, [x8]
   39e54:	adds	x9, x9, #0x1
   39e58:	str	x9, [x8], #8
   39e5c:	b.cs	39e50 <__gmpn_toom44_mul@@Base+0x1ec>  // b.hs, b.nlast
   39e60:	b	39e84 <__gmpn_toom44_mul@@Base+0x220>
   39e64:	ldur	x8, [x29, #-8]
   39e68:	mov	x0, x20
   39e6c:	mov	x2, x20
   39e70:	mov	x3, x21
   39e74:	add	x1, x25, x8, lsl #3
   39e78:	bl	cc60 <__gmpn_addlsh1_n@plt>
   39e7c:	add	x8, x0, x26, lsl #1
   39e80:	str	x8, [x20, x21, lsl #3]
   39e84:	ldp	w9, w8, [sp, #8]
   39e88:	ldur	x26, [x29, #-32]
   39e8c:	mov	x0, x27
   39e90:	mov	x3, x21
   39e94:	eor	w8, w9, w8
   39e98:	add	x1, x26, x21, lsl #3
   39e9c:	mov	x2, x26
   39ea0:	str	w8, [sp, #12]
   39ea4:	bl	cc60 <__gmpn_addlsh1_n@plt>
   39ea8:	ldr	x8, [sp, #64]
   39eac:	mov	x23, x0
   39eb0:	mov	x0, x27
   39eb4:	mov	x2, x27
   39eb8:	add	x1, x26, x8, lsl #3
   39ebc:	mov	x3, x21
   39ec0:	bl	cc60 <__gmpn_addlsh1_n@plt>
   39ec4:	ldur	x28, [x29, #-40]
   39ec8:	add	x25, x0, x23, lsl #1
   39ecc:	subs	x19, x21, x28
   39ed0:	b.le	39f60 <__gmpn_toom44_mul@@Base+0x2fc>
   39ed4:	ldur	x8, [x29, #-8]
   39ed8:	mov	x0, x27
   39edc:	mov	x2, x27
   39ee0:	mov	x3, x28
   39ee4:	add	x1, x26, x8, lsl #3
   39ee8:	bl	cc60 <__gmpn_addlsh1_n@plt>
   39eec:	ldur	x8, [x29, #-40]
   39ef0:	mov	x23, x0
   39ef4:	mov	w3, #0x1                   	// #1
   39ef8:	mov	x2, x19
   39efc:	add	x28, x27, x8, lsl #3
   39f00:	mov	x0, x28
   39f04:	mov	x1, x28
   39f08:	bl	c190 <__gmpn_lshift@plt>
   39f0c:	add	x8, x0, x25, lsl #1
   39f10:	str	x8, [x27, x21, lsl #3]
   39f14:	ldr	x8, [x28]
   39f18:	ldur	x25, [x29, #-24]
   39f1c:	ldr	x10, [sp, #16]
   39f20:	adds	x8, x8, x23
   39f24:	str	x8, [x28]
   39f28:	ldur	x28, [x29, #-40]
   39f2c:	ldr	x23, [sp, #40]
   39f30:	b.cc	39f8c <__gmpn_toom44_mul@@Base+0x328>  // b.lo, b.ul, b.last
   39f34:	ldr	x8, [sp, #56]
   39f38:	ldur	x9, [x29, #-8]
   39f3c:	add	x8, x8, x10
   39f40:	sub	x8, x8, x9
   39f44:	add	x8, x20, x8, lsl #3
   39f48:	add	x8, x8, #0x18
   39f4c:	ldr	x9, [x8]
   39f50:	adds	x9, x9, #0x1
   39f54:	str	x9, [x8], #8
   39f58:	b.cs	39f4c <__gmpn_toom44_mul@@Base+0x2e8>  // b.hs, b.nlast
   39f5c:	b	39f8c <__gmpn_toom44_mul@@Base+0x328>
   39f60:	ldur	x8, [x29, #-8]
   39f64:	mov	x0, x27
   39f68:	mov	x2, x27
   39f6c:	mov	x3, x21
   39f70:	add	x1, x26, x8, lsl #3
   39f74:	bl	cc60 <__gmpn_addlsh1_n@plt>
   39f78:	add	x8, x0, x25, lsl #1
   39f7c:	ldur	x25, [x29, #-24]
   39f80:	ldr	x23, [sp, #40]
   39f84:	ldr	x10, [sp, #16]
   39f88:	str	x8, [x27, x21, lsl #3]
   39f8c:	ldr	w8, [sp, #12]
   39f90:	ldp	x9, x26, [x29, #-56]
   39f94:	mov	x1, x20
   39f98:	mov	x2, x24
   39f9c:	and	w19, w8, #0x1
   39fa0:	ldur	x8, [x29, #-16]
   39fa4:	cmp	x9, #0xbc
   39fa8:	mov	x3, x27
   39fac:	mov	x4, x24
   39fb0:	add	x8, x8, x10, lsl #3
   39fb4:	add	x0, x8, #0x10
   39fb8:	mov	x5, x22
   39fbc:	stur	x0, [x29, #-40]
   39fc0:	b.le	39fcc <__gmpn_toom44_mul@@Base+0x368>
   39fc4:	bl	c0b0 <__gmpn_toom33_mul@plt>
   39fc8:	b	39fd0 <__gmpn_toom44_mul@@Base+0x36c>
   39fcc:	bl	d470 <__gmpn_toom22_mul@plt>
   39fd0:	mov	x0, x20
   39fd4:	mov	x1, x23
   39fd8:	mov	x2, x26
   39fdc:	mov	x3, x21
   39fe0:	mov	x4, x25
   39fe4:	mov	x5, x22
   39fe8:	bl	c290 <__gmpn_toom_eval_dgr3_pm1@plt>
   39fec:	ldr	x25, [sp, #24]
   39ff0:	ldur	x2, [x29, #-32]
   39ff4:	and	w8, w0, #0x2
   39ff8:	mov	x0, x27
   39ffc:	mov	x1, x25
   3a000:	mov	x3, x21
   3a004:	mov	x4, x28
   3a008:	mov	x5, x22
   3a00c:	orr	w19, w8, w19
   3a010:	bl	c290 <__gmpn_toom_eval_dgr3_pm1@plt>
   3a014:	and	w8, w0, #0x2
   3a018:	eor	w8, w19, w8
   3a01c:	str	w8, [sp, #64]
   3a020:	ldur	x8, [x29, #-16]
   3a024:	ldur	x19, [x29, #-56]
   3a028:	mov	x1, x23
   3a02c:	add	x23, x21, x21, lsl #1
   3a030:	add	x8, x8, x23, lsl #4
   3a034:	cmp	x19, #0xbc
   3a038:	add	x0, x8, #0x18
   3a03c:	mov	x2, x24
   3a040:	mov	x3, x25
   3a044:	mov	x4, x24
   3a048:	mov	x5, x22
   3a04c:	str	x0, [sp, #16]
   3a050:	b.le	3a0a0 <__gmpn_toom44_mul@@Base+0x43c>
   3a054:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a058:	ldr	x0, [sp, #32]
   3a05c:	mov	x1, x20
   3a060:	mov	x2, x24
   3a064:	mov	x3, x27
   3a068:	mov	x4, x24
   3a06c:	mov	x5, x22
   3a070:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a074:	cmp	x19, #0xc0
   3a078:	b.le	3a0c0 <__gmpn_toom44_mul@@Base+0x45c>
   3a07c:	ldur	x24, [x29, #-32]
   3a080:	mov	x0, x20
   3a084:	mov	x1, x26
   3a088:	mov	x2, x21
   3a08c:	mov	x3, x24
   3a090:	mov	x4, x21
   3a094:	mov	x5, x22
   3a098:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a09c:	b	3a0e0 <__gmpn_toom44_mul@@Base+0x47c>
   3a0a0:	bl	d470 <__gmpn_toom22_mul@plt>
   3a0a4:	ldr	x0, [sp, #32]
   3a0a8:	mov	x1, x20
   3a0ac:	mov	x2, x24
   3a0b0:	mov	x3, x27
   3a0b4:	mov	x4, x24
   3a0b8:	mov	x5, x22
   3a0bc:	bl	d470 <__gmpn_toom22_mul@plt>
   3a0c0:	ldur	x24, [x29, #-32]
   3a0c4:	mov	x0, x20
   3a0c8:	mov	x1, x26
   3a0cc:	mov	x2, x21
   3a0d0:	mov	x3, x24
   3a0d4:	mov	x4, x21
   3a0d8:	mov	x5, x22
   3a0dc:	bl	d470 <__gmpn_toom22_mul@plt>
   3a0e0:	ldr	x8, [sp, #56]
   3a0e4:	ldur	x25, [x29, #-24]
   3a0e8:	cmp	x19, x8
   3a0ec:	lsl	x8, x23, #1
   3a0f0:	add	x0, x20, x8, lsl #3
   3a0f4:	b.le	3a114 <__gmpn_toom44_mul@@Base+0x4b0>
   3a0f8:	ldur	x8, [x29, #-8]
   3a0fc:	mov	x2, x25
   3a100:	mov	x4, x28
   3a104:	add	x1, x26, x8, lsl #3
   3a108:	add	x3, x24, x8, lsl #3
   3a10c:	bl	ccf0 <__gmpn_mul@plt>
   3a110:	b	3a140 <__gmpn_toom44_mul@@Base+0x4dc>
   3a114:	ldur	x8, [x29, #-8]
   3a118:	cmp	x25, #0x30
   3a11c:	mov	x2, x25
   3a120:	mov	x4, x25
   3a124:	add	x1, x26, x8, lsl #3
   3a128:	add	x3, x24, x8, lsl #3
   3a12c:	mov	x5, x22
   3a130:	b.le	3a13c <__gmpn_toom44_mul@@Base+0x4d8>
   3a134:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a138:	b	3a140 <__gmpn_toom44_mul@@Base+0x4dc>
   3a13c:	bl	d470 <__gmpn_toom22_mul@plt>
   3a140:	ldr	w2, [sp, #64]
   3a144:	ldr	x3, [sp, #48]
   3a148:	ldr	x4, [sp, #16]
   3a14c:	ldur	x5, [x29, #-16]
   3a150:	ldur	x6, [x29, #-40]
   3a154:	add	x7, x25, x28
   3a158:	mov	x0, x20
   3a15c:	mov	x1, x21
   3a160:	str	x22, [sp]
   3a164:	bl	c830 <__gmpn_toom_interpolate_7pts@plt>
   3a168:	ldp	x20, x19, [sp, #208]
   3a16c:	ldp	x22, x21, [sp, #192]
   3a170:	ldp	x24, x23, [sp, #176]
   3a174:	ldp	x26, x25, [sp, #160]
   3a178:	ldp	x28, x27, [sp, #144]
   3a17c:	ldp	x29, x30, [sp, #128]
   3a180:	add	sp, sp, #0xe0
   3a184:	ret

000000000003a188 <__gmpn_toom6h_mul@@Base>:
   3a188:	sub	sp, sp, #0xd0
   3a18c:	add	x8, x2, x2, lsl #4
   3a190:	add	x9, x4, x4, lsl #3
   3a194:	stp	x29, x30, [sp, #112]
   3a198:	stp	x20, x19, [sp, #192]
   3a19c:	add	x29, sp, #0x70
   3a1a0:	cmp	x8, x9, lsl #1
   3a1a4:	mov	x20, x0
   3a1a8:	stp	x28, x27, [sp, #128]
   3a1ac:	stp	x26, x25, [sp, #144]
   3a1b0:	stp	x24, x23, [sp, #160]
   3a1b4:	stp	x22, x21, [sp, #176]
   3a1b8:	str	x5, [sp, #56]
   3a1bc:	stp	x3, x1, [x29, #-16]
   3a1c0:	b.ge	3abac <__gmpn_toom6h_mul@@Base+0xa24>  // b.tcont
   3a1c4:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   3a1c8:	sub	x8, x2, #0x1
   3a1cc:	movk	x9, #0xaaab
   3a1d0:	umulh	x8, x8, x9
   3a1d4:	lsr	x8, x8, #2
   3a1d8:	add	x23, x8, #0x1
   3a1dc:	add	x8, x23, x23, lsl #2
   3a1e0:	sub	x5, x2, x8
   3a1e4:	sub	x8, x4, x8
   3a1e8:	str	wzr, [sp, #44]
   3a1ec:	mov	w15, #0x5                   	// #5
   3a1f0:	stur	x8, [x29, #-24]
   3a1f4:	mov	w26, #0x5                   	// #5
   3a1f8:	add	x19, x23, x23, lsl #3
   3a1fc:	ldur	x3, [x29, #-8]
   3a200:	mov	w8, #0x38                  	// #56
   3a204:	add	x9, x20, x19, lsl #3
   3a208:	add	x28, x9, #0x10
   3a20c:	madd	x27, x23, x8, x20
   3a210:	mov	w6, #0x1                   	// #1
   3a214:	mov	x0, x28
   3a218:	mov	x1, x27
   3a21c:	mov	w2, w15
   3a220:	mov	x4, x23
   3a224:	mov	x7, x20
   3a228:	stur	x5, [x29, #-32]
   3a22c:	stur	x15, [x29, #-48]
   3a230:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3a234:	ldr	x21, [sp, #56]
   3a238:	ldp	x5, x3, [x29, #-24]
   3a23c:	add	x9, x20, x23, lsl #6
   3a240:	add	x25, x9, #0x8
   3a244:	add	x8, x21, x19, lsl #3
   3a248:	add	x24, x8, #0x18
   3a24c:	mov	w22, w0
   3a250:	mov	w6, #0x1                   	// #1
   3a254:	mov	x0, x24
   3a258:	mov	x1, x25
   3a25c:	mov	w2, w26
   3a260:	mov	x4, x23
   3a264:	mov	x7, x20
   3a268:	stur	x26, [x29, #-40]
   3a26c:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3a270:	eor	w8, w0, w22
   3a274:	str	w8, [sp, #32]
   3a278:	mov	w8, #0x50                  	// #80
   3a27c:	cmp	x23, #0x2f
   3a280:	add	x19, x23, #0x1
   3a284:	madd	x8, x23, x8, x21
   3a288:	b.le	3a2e0 <__gmpn_toom6h_mul@@Base+0x158>
   3a28c:	cmp	x23, #0x50
   3a290:	b.le	3a324 <__gmpn_toom6h_mul@@Base+0x19c>
   3a294:	add	x26, x8, #0x20
   3a298:	cmp	x23, #0xab
   3a29c:	mov	x22, x28
   3a2a0:	mov	x0, x20
   3a2a4:	mov	x1, x27
   3a2a8:	mov	x2, x19
   3a2ac:	mov	x3, x25
   3a2b0:	mov	x4, x19
   3a2b4:	mov	x5, x26
   3a2b8:	b.le	3a368 <__gmpn_toom6h_mul@@Base+0x1e0>
   3a2bc:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a2c0:	mov	x0, x21
   3a2c4:	mov	x1, x22
   3a2c8:	mov	x2, x19
   3a2cc:	mov	x3, x24
   3a2d0:	mov	x4, x19
   3a2d4:	mov	x5, x26
   3a2d8:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a2dc:	b	3a388 <__gmpn_toom6h_mul@@Base+0x200>
   3a2e0:	add	x26, x8, #0x20
   3a2e4:	mov	x0, x20
   3a2e8:	mov	x1, x27
   3a2ec:	mov	x2, x19
   3a2f0:	mov	x3, x25
   3a2f4:	mov	x4, x19
   3a2f8:	mov	x5, x26
   3a2fc:	bl	d470 <__gmpn_toom22_mul@plt>
   3a300:	mov	x0, x21
   3a304:	mov	x1, x28
   3a308:	mov	x2, x19
   3a30c:	mov	x3, x24
   3a310:	mov	x4, x19
   3a314:	mov	x5, x26
   3a318:	bl	d470 <__gmpn_toom22_mul@plt>
   3a31c:	mov	x22, x28
   3a320:	b	3a388 <__gmpn_toom6h_mul@@Base+0x200>
   3a324:	add	x26, x8, #0x20
   3a328:	mov	x0, x20
   3a32c:	mov	x1, x27
   3a330:	mov	x2, x19
   3a334:	mov	x3, x25
   3a338:	mov	x4, x19
   3a33c:	mov	x5, x26
   3a340:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a344:	mov	x0, x21
   3a348:	mov	x1, x28
   3a34c:	mov	x2, x19
   3a350:	mov	x3, x24
   3a354:	mov	x4, x19
   3a358:	mov	x5, x26
   3a35c:	mov	x22, x28
   3a360:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a364:	b	3a388 <__gmpn_toom6h_mul@@Base+0x200>
   3a368:	bl	c740 <__gmpn_toom44_mul@plt>
   3a36c:	mov	x0, x21
   3a370:	mov	x1, x22
   3a374:	mov	x2, x19
   3a378:	mov	x3, x24
   3a37c:	mov	x4, x19
   3a380:	mov	x5, x26
   3a384:	bl	c740 <__gmpn_toom44_mul@plt>
   3a388:	ldr	w6, [sp, #44]
   3a38c:	ldr	w3, [sp, #32]
   3a390:	mov	w1, #0x1                   	// #1
   3a394:	bfi	x1, x23, #1, #63
   3a398:	add	w5, w6, #0x1
   3a39c:	mov	x0, x21
   3a3a0:	mov	x2, x20
   3a3a4:	mov	x4, x23
   3a3a8:	str	x1, [sp, #48]
   3a3ac:	str	w5, [sp, #28]
   3a3b0:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3a3b4:	ldur	x3, [x29, #-8]
   3a3b8:	ldur	x5, [x29, #-32]
   3a3bc:	mov	x0, x22
   3a3c0:	mov	x1, x27
   3a3c4:	ldur	x2, [x29, #-48]
   3a3c8:	mov	x4, x23
   3a3cc:	mov	x6, x20
   3a3d0:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   3a3d4:	ldur	x2, [x29, #-40]
   3a3d8:	mov	w26, w0
   3a3dc:	mov	x0, x24
   3a3e0:	mov	x1, x25
   3a3e4:	cmp	w2, #0x3
   3a3e8:	b.eq	3abcc <__gmpn_toom6h_mul@@Base+0xa44>  // b.none
   3a3ec:	ldp	x5, x3, [x29, #-24]
   3a3f0:	mov	x4, x23
   3a3f4:	mov	x6, x20
   3a3f8:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   3a3fc:	eor	w8, w0, w26
   3a400:	str	w8, [sp, #16]
   3a404:	mov	w8, #0x50                  	// #80
   3a408:	cmp	x23, #0x2f
   3a40c:	madd	x8, x23, x8, x21
   3a410:	b.le	3a46c <__gmpn_toom6h_mul@@Base+0x2e4>
   3a414:	cmp	x23, #0x50
   3a418:	b.le	3a4b4 <__gmpn_toom6h_mul@@Base+0x32c>
   3a41c:	add	x26, x8, #0x20
   3a420:	cmp	x23, #0xab
   3a424:	mov	x0, x20
   3a428:	mov	x1, x27
   3a42c:	mov	x2, x19
   3a430:	mov	x3, x25
   3a434:	mov	x4, x19
   3a438:	mov	x5, x26
   3a43c:	b.le	3a4fc <__gmpn_toom6h_mul@@Base+0x374>
   3a440:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a444:	add	x28, x23, x23, lsl #1
   3a448:	add	x8, x21, x28, lsl #3
   3a44c:	add	x0, x8, #0x8
   3a450:	mov	x1, x22
   3a454:	mov	x2, x19
   3a458:	mov	x3, x24
   3a45c:	mov	x4, x19
   3a460:	mov	x5, x26
   3a464:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a468:	b	3a524 <__gmpn_toom6h_mul@@Base+0x39c>
   3a46c:	add	x26, x8, #0x20
   3a470:	mov	x0, x20
   3a474:	mov	x1, x27
   3a478:	mov	x2, x19
   3a47c:	mov	x3, x25
   3a480:	mov	x4, x19
   3a484:	mov	x5, x26
   3a488:	bl	d470 <__gmpn_toom22_mul@plt>
   3a48c:	add	x28, x23, x23, lsl #1
   3a490:	add	x8, x21, x28, lsl #3
   3a494:	add	x0, x8, #0x8
   3a498:	mov	x1, x22
   3a49c:	mov	x2, x19
   3a4a0:	mov	x3, x24
   3a4a4:	mov	x4, x19
   3a4a8:	mov	x5, x26
   3a4ac:	bl	d470 <__gmpn_toom22_mul@plt>
   3a4b0:	b	3a524 <__gmpn_toom6h_mul@@Base+0x39c>
   3a4b4:	add	x26, x8, #0x20
   3a4b8:	mov	x0, x20
   3a4bc:	mov	x1, x27
   3a4c0:	mov	x2, x19
   3a4c4:	mov	x3, x25
   3a4c8:	mov	x4, x19
   3a4cc:	mov	x5, x26
   3a4d0:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a4d4:	add	x28, x23, x23, lsl #1
   3a4d8:	add	x8, x21, x28, lsl #3
   3a4dc:	add	x0, x8, #0x8
   3a4e0:	mov	x1, x22
   3a4e4:	mov	x2, x19
   3a4e8:	mov	x3, x24
   3a4ec:	mov	x4, x19
   3a4f0:	mov	x5, x26
   3a4f4:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a4f8:	b	3a524 <__gmpn_toom6h_mul@@Base+0x39c>
   3a4fc:	bl	c740 <__gmpn_toom44_mul@plt>
   3a500:	add	x28, x23, x23, lsl #1
   3a504:	add	x8, x21, x28, lsl #3
   3a508:	add	x0, x8, #0x8
   3a50c:	mov	x1, x22
   3a510:	mov	x2, x19
   3a514:	mov	x3, x24
   3a518:	mov	x4, x19
   3a51c:	mov	x5, x26
   3a520:	bl	c740 <__gmpn_toom44_mul@plt>
   3a524:	ldr	x1, [sp, #48]
   3a528:	ldr	w3, [sp, #16]
   3a52c:	ldur	x26, [x29, #-32]
   3a530:	add	x8, x21, x28, lsl #3
   3a534:	add	x0, x8, #0x8
   3a538:	mov	x2, x20
   3a53c:	mov	x4, x23
   3a540:	mov	w5, wzr
   3a544:	mov	w6, wzr
   3a548:	str	x28, [sp, #8]
   3a54c:	str	x0, [sp, #32]
   3a550:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3a554:	ldur	x3, [x29, #-8]
   3a558:	mov	w6, #0x2                   	// #2
   3a55c:	mov	x0, x22
   3a560:	mov	x1, x27
   3a564:	ldur	x2, [x29, #-48]
   3a568:	mov	x4, x23
   3a56c:	mov	x5, x26
   3a570:	mov	x7, x20
   3a574:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   3a578:	ldp	x5, x3, [x29, #-24]
   3a57c:	mov	w26, w0
   3a580:	mov	w6, #0x2                   	// #2
   3a584:	mov	x0, x24
   3a588:	mov	x1, x25
   3a58c:	ldur	x2, [x29, #-40]
   3a590:	mov	x4, x23
   3a594:	mov	x7, x20
   3a598:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   3a59c:	eor	w8, w0, w26
   3a5a0:	cmp	x23, #0x2f
   3a5a4:	str	w8, [sp, #4]
   3a5a8:	mov	w8, #0x50                  	// #80
   3a5ac:	b.le	3a614 <__gmpn_toom6h_mul@@Base+0x48c>
   3a5b0:	cmp	x23, #0x50
   3a5b4:	b.le	3a664 <__gmpn_toom6h_mul@@Base+0x4dc>
   3a5b8:	ldr	x21, [sp, #56]
   3a5bc:	cmp	x23, #0xab
   3a5c0:	mov	x0, x20
   3a5c4:	mov	x1, x27
   3a5c8:	madd	x8, x23, x8, x21
   3a5cc:	add	x26, x8, #0x20
   3a5d0:	mov	x2, x19
   3a5d4:	mov	x3, x25
   3a5d8:	mov	x4, x19
   3a5dc:	mov	x5, x26
   3a5e0:	b.le	3a6b8 <__gmpn_toom6h_mul@@Base+0x530>
   3a5e4:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a5e8:	add	x8, x23, x23, lsl #1
   3a5ec:	lsl	x28, x8, #1
   3a5f0:	add	x8, x21, x8, lsl #4
   3a5f4:	add	x0, x8, #0x10
   3a5f8:	mov	x1, x22
   3a5fc:	mov	x2, x19
   3a600:	mov	x3, x24
   3a604:	mov	x4, x19
   3a608:	mov	x5, x26
   3a60c:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a610:	b	3a6e4 <__gmpn_toom6h_mul@@Base+0x55c>
   3a614:	madd	x8, x23, x8, x21
   3a618:	add	x26, x8, #0x20
   3a61c:	mov	x0, x20
   3a620:	mov	x1, x27
   3a624:	mov	x2, x19
   3a628:	mov	x3, x25
   3a62c:	mov	x4, x19
   3a630:	mov	x5, x26
   3a634:	bl	d470 <__gmpn_toom22_mul@plt>
   3a638:	add	x8, x23, x23, lsl #1
   3a63c:	lsl	x28, x8, #1
   3a640:	add	x8, x21, x8, lsl #4
   3a644:	add	x0, x8, #0x10
   3a648:	mov	x1, x22
   3a64c:	mov	x2, x19
   3a650:	mov	x3, x24
   3a654:	mov	x4, x19
   3a658:	mov	x5, x26
   3a65c:	bl	d470 <__gmpn_toom22_mul@plt>
   3a660:	b	3a6e4 <__gmpn_toom6h_mul@@Base+0x55c>
   3a664:	ldr	x21, [sp, #56]
   3a668:	mov	x0, x20
   3a66c:	mov	x1, x27
   3a670:	mov	x2, x19
   3a674:	madd	x8, x23, x8, x21
   3a678:	add	x26, x8, #0x20
   3a67c:	mov	x3, x25
   3a680:	mov	x4, x19
   3a684:	mov	x5, x26
   3a688:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a68c:	add	x8, x23, x23, lsl #1
   3a690:	lsl	x28, x8, #1
   3a694:	add	x8, x21, x8, lsl #4
   3a698:	add	x0, x8, #0x10
   3a69c:	mov	x1, x22
   3a6a0:	mov	x2, x19
   3a6a4:	mov	x3, x24
   3a6a8:	mov	x4, x19
   3a6ac:	mov	x5, x26
   3a6b0:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a6b4:	b	3a6e4 <__gmpn_toom6h_mul@@Base+0x55c>
   3a6b8:	bl	c740 <__gmpn_toom44_mul@plt>
   3a6bc:	add	x8, x23, x23, lsl #1
   3a6c0:	lsl	x28, x8, #1
   3a6c4:	add	x8, x21, x8, lsl #4
   3a6c8:	add	x0, x8, #0x10
   3a6cc:	mov	x1, x22
   3a6d0:	mov	x2, x19
   3a6d4:	mov	x3, x24
   3a6d8:	mov	x4, x19
   3a6dc:	mov	x5, x26
   3a6e0:	bl	c740 <__gmpn_toom44_mul@plt>
   3a6e4:	ldr	x1, [sp, #48]
   3a6e8:	ldr	w3, [sp, #4]
   3a6ec:	ldur	x26, [x29, #-32]
   3a6f0:	add	x8, x21, x28, lsl #3
   3a6f4:	add	x0, x8, #0x10
   3a6f8:	mov	w5, #0x2                   	// #2
   3a6fc:	mov	w6, #0x4                   	// #4
   3a700:	mov	x2, x20
   3a704:	mov	x4, x23
   3a708:	str	x0, [sp, #16]
   3a70c:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3a710:	ldur	x3, [x29, #-8]
   3a714:	mov	w6, #0x2                   	// #2
   3a718:	mov	x0, x22
   3a71c:	mov	x1, x27
   3a720:	ldur	x2, [x29, #-48]
   3a724:	mov	x4, x23
   3a728:	mov	x5, x26
   3a72c:	mov	x7, x20
   3a730:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3a734:	ldp	x5, x3, [x29, #-24]
   3a738:	mov	w26, w0
   3a73c:	mov	w6, #0x2                   	// #2
   3a740:	mov	x0, x24
   3a744:	mov	x1, x25
   3a748:	ldur	x2, [x29, #-40]
   3a74c:	mov	x4, x23
   3a750:	mov	x7, x20
   3a754:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3a758:	cmp	x23, #0x2f
   3a75c:	mov	x28, x22
   3a760:	mov	x22, x27
   3a764:	mov	x27, x25
   3a768:	eor	w25, w0, w26
   3a76c:	str	w25, [sp, #4]
   3a770:	b.le	3a7d8 <__gmpn_toom6h_mul@@Base+0x650>
   3a774:	cmp	x23, #0x50
   3a778:	b.le	3a828 <__gmpn_toom6h_mul@@Base+0x6a0>
   3a77c:	ldp	x25, x9, [sp, #48]
   3a780:	mov	w8, #0x50                  	// #80
   3a784:	mov	x21, x24
   3a788:	cmp	x23, #0xab
   3a78c:	madd	x8, x23, x8, x9
   3a790:	add	x26, x8, #0x20
   3a794:	mov	x0, x20
   3a798:	mov	x1, x22
   3a79c:	mov	x2, x19
   3a7a0:	mov	x3, x27
   3a7a4:	mov	x4, x19
   3a7a8:	mov	x5, x26
   3a7ac:	b.le	3aaac <__gmpn_toom6h_mul@@Base+0x924>
   3a7b0:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a7b4:	ldr	x24, [sp, #8]
   3a7b8:	mov	x1, x28
   3a7bc:	mov	x2, x19
   3a7c0:	mov	x3, x21
   3a7c4:	add	x0, x20, x24, lsl #3
   3a7c8:	mov	x4, x19
   3a7cc:	mov	x5, x26
   3a7d0:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a7d4:	b	3a87c <__gmpn_toom6h_mul@@Base+0x6f4>
   3a7d8:	mov	w8, #0x50                  	// #80
   3a7dc:	madd	x8, x23, x8, x21
   3a7e0:	add	x26, x8, #0x20
   3a7e4:	mov	x0, x20
   3a7e8:	mov	x1, x22
   3a7ec:	mov	x2, x19
   3a7f0:	mov	x3, x27
   3a7f4:	mov	x4, x19
   3a7f8:	mov	x5, x26
   3a7fc:	bl	d470 <__gmpn_toom22_mul@plt>
   3a800:	mov	x21, x24
   3a804:	ldr	x24, [sp, #8]
   3a808:	mov	x1, x28
   3a80c:	mov	x2, x19
   3a810:	mov	x3, x21
   3a814:	add	x0, x20, x24, lsl #3
   3a818:	mov	x4, x19
   3a81c:	mov	x5, x26
   3a820:	bl	d470 <__gmpn_toom22_mul@plt>
   3a824:	b	3a878 <__gmpn_toom6h_mul@@Base+0x6f0>
   3a828:	ldr	x9, [sp, #56]
   3a82c:	mov	w8, #0x50                  	// #80
   3a830:	mov	x0, x20
   3a834:	mov	x1, x22
   3a838:	madd	x8, x23, x8, x9
   3a83c:	add	x26, x8, #0x20
   3a840:	mov	x2, x19
   3a844:	mov	x3, x27
   3a848:	mov	x4, x19
   3a84c:	mov	x5, x26
   3a850:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a854:	mov	x21, x24
   3a858:	ldr	x24, [sp, #8]
   3a85c:	mov	x1, x28
   3a860:	mov	x2, x19
   3a864:	mov	x3, x21
   3a868:	add	x0, x20, x24, lsl #3
   3a86c:	mov	x4, x19
   3a870:	mov	x5, x26
   3a874:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3a878:	ldr	x25, [sp, #48]
   3a87c:	ldr	w8, [sp, #28]
   3a880:	ldr	w3, [sp, #4]
   3a884:	add	x0, x20, x24, lsl #3
   3a888:	mov	x1, x25
   3a88c:	lsl	w5, w8, #1
   3a890:	ldr	w8, [sp, #44]
   3a894:	mov	x2, x20
   3a898:	mov	x4, x23
   3a89c:	lsl	w6, w8, #1
   3a8a0:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3a8a4:	ldur	x3, [x29, #-8]
   3a8a8:	ldur	x5, [x29, #-32]
   3a8ac:	mov	x0, x28
   3a8b0:	mov	x1, x22
   3a8b4:	ldur	x2, [x29, #-48]
   3a8b8:	mov	x4, x23
   3a8bc:	mov	x6, x20
   3a8c0:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   3a8c4:	ldp	x5, x3, [x29, #-24]
   3a8c8:	mov	w26, w0
   3a8cc:	mov	x0, x21
   3a8d0:	mov	x1, x27
   3a8d4:	ldur	x2, [x29, #-40]
   3a8d8:	mov	x4, x23
   3a8dc:	mov	x6, x20
   3a8e0:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   3a8e4:	cmp	x23, #0x2f
   3a8e8:	eor	w10, w0, w26
   3a8ec:	mov	x24, x21
   3a8f0:	b.le	3a9a4 <__gmpn_toom6h_mul@@Base+0x81c>
   3a8f4:	ldr	x9, [sp, #56]
   3a8f8:	mov	x11, x20
   3a8fc:	cmp	x23, #0x51
   3a900:	b.lt	3aa14 <__gmpn_toom6h_mul@@Base+0x88c>  // b.tstop
   3a904:	mov	w8, #0x50                  	// #80
   3a908:	madd	x8, x23, x8, x9
   3a90c:	add	x26, x8, #0x20
   3a910:	mov	x20, x22
   3a914:	mov	w21, w10
   3a918:	cmp	x23, #0xab
   3a91c:	mov	x22, x11
   3a920:	mov	x0, x11
   3a924:	mov	x1, x20
   3a928:	mov	x2, x19
   3a92c:	mov	x3, x27
   3a930:	mov	x4, x19
   3a934:	mov	x5, x26
   3a938:	b.le	3aad4 <__gmpn_toom6h_mul@@Base+0x94c>
   3a93c:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a940:	mov	x0, x20
   3a944:	mov	x1, x28
   3a948:	mov	x2, x19
   3a94c:	mov	x3, x24
   3a950:	mov	x4, x19
   3a954:	mov	x5, x26
   3a958:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a95c:	ldr	x1, [sp, #48]
   3a960:	mov	w5, #0x1                   	// #1
   3a964:	mov	w6, #0x2                   	// #2
   3a968:	mov	x0, x20
   3a96c:	mov	x2, x22
   3a970:	mov	w3, w21
   3a974:	mov	x4, x23
   3a978:	mov	x20, x22
   3a97c:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3a980:	cmp	x23, #0xac
   3a984:	b.eq	3ab20 <__gmpn_toom6h_mul@@Base+0x998>  // b.none
   3a988:	ldp	x3, x1, [x29, #-16]
   3a98c:	mov	x0, x20
   3a990:	mov	x2, x23
   3a994:	mov	x4, x23
   3a998:	mov	x5, x24
   3a99c:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3a9a0:	b	3ab54 <__gmpn_toom6h_mul@@Base+0x9cc>
   3a9a4:	ldr	x9, [sp, #56]
   3a9a8:	mov	w8, #0x50                  	// #80
   3a9ac:	mov	x0, x20
   3a9b0:	mov	x1, x22
   3a9b4:	madd	x8, x23, x8, x9
   3a9b8:	add	x26, x8, #0x20
   3a9bc:	mov	x2, x19
   3a9c0:	mov	x3, x27
   3a9c4:	mov	x4, x19
   3a9c8:	mov	x5, x26
   3a9cc:	mov	w21, w10
   3a9d0:	bl	d470 <__gmpn_toom22_mul@plt>
   3a9d4:	mov	x0, x22
   3a9d8:	mov	x1, x28
   3a9dc:	mov	x2, x19
   3a9e0:	mov	x3, x24
   3a9e4:	mov	x4, x19
   3a9e8:	mov	x5, x26
   3a9ec:	bl	d470 <__gmpn_toom22_mul@plt>
   3a9f0:	mov	w5, #0x1                   	// #1
   3a9f4:	mov	w6, #0x2                   	// #2
   3a9f8:	mov	x0, x22
   3a9fc:	mov	x1, x25
   3aa00:	mov	x2, x20
   3aa04:	mov	w3, w21
   3aa08:	mov	x4, x23
   3aa0c:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3aa10:	b	3aa90 <__gmpn_toom6h_mul@@Base+0x908>
   3aa14:	mov	w8, #0x50                  	// #80
   3aa18:	madd	x8, x23, x8, x9
   3aa1c:	add	x26, x8, #0x20
   3aa20:	mov	x0, x11
   3aa24:	mov	x1, x22
   3aa28:	mov	x2, x19
   3aa2c:	mov	x3, x27
   3aa30:	mov	x4, x19
   3aa34:	mov	x5, x26
   3aa38:	mov	x21, x11
   3aa3c:	mov	x20, x22
   3aa40:	mov	w22, w10
   3aa44:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3aa48:	mov	x0, x20
   3aa4c:	mov	x1, x28
   3aa50:	mov	x2, x19
   3aa54:	mov	x3, x24
   3aa58:	mov	x4, x19
   3aa5c:	mov	x5, x26
   3aa60:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3aa64:	ldr	x1, [sp, #48]
   3aa68:	mov	w5, #0x1                   	// #1
   3aa6c:	mov	w6, #0x2                   	// #2
   3aa70:	mov	x0, x20
   3aa74:	mov	x2, x21
   3aa78:	mov	w3, w22
   3aa7c:	mov	x4, x23
   3aa80:	mov	x20, x21
   3aa84:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3aa88:	cmp	x23, #0x30
   3aa8c:	b.gt	3ab3c <__gmpn_toom6h_mul@@Base+0x9b4>
   3aa90:	ldp	x3, x1, [x29, #-16]
   3aa94:	mov	x0, x20
   3aa98:	mov	x2, x23
   3aa9c:	mov	x4, x23
   3aaa0:	mov	x5, x24
   3aaa4:	bl	d470 <__gmpn_toom22_mul@plt>
   3aaa8:	b	3ab54 <__gmpn_toom6h_mul@@Base+0x9cc>
   3aaac:	bl	c740 <__gmpn_toom44_mul@plt>
   3aab0:	ldr	x24, [sp, #8]
   3aab4:	mov	x1, x28
   3aab8:	mov	x2, x19
   3aabc:	mov	x3, x21
   3aac0:	add	x0, x20, x24, lsl #3
   3aac4:	mov	x4, x19
   3aac8:	mov	x5, x26
   3aacc:	bl	c740 <__gmpn_toom44_mul@plt>
   3aad0:	b	3a87c <__gmpn_toom6h_mul@@Base+0x6f4>
   3aad4:	bl	c740 <__gmpn_toom44_mul@plt>
   3aad8:	mov	x0, x20
   3aadc:	mov	x1, x28
   3aae0:	mov	x2, x19
   3aae4:	mov	x3, x24
   3aae8:	mov	x4, x19
   3aaec:	mov	x5, x26
   3aaf0:	bl	c740 <__gmpn_toom44_mul@plt>
   3aaf4:	ldr	x1, [sp, #48]
   3aaf8:	mov	w5, #0x1                   	// #1
   3aafc:	mov	w6, #0x2                   	// #2
   3ab00:	mov	x0, x20
   3ab04:	mov	x2, x22
   3ab08:	mov	w3, w21
   3ab0c:	mov	x4, x23
   3ab10:	mov	x20, x22
   3ab14:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3ab18:	cmp	x23, #0x51
   3ab1c:	b.le	3ab3c <__gmpn_toom6h_mul@@Base+0x9b4>
   3ab20:	ldp	x3, x1, [x29, #-16]
   3ab24:	mov	x0, x20
   3ab28:	mov	x2, x23
   3ab2c:	mov	x4, x23
   3ab30:	mov	x5, x24
   3ab34:	bl	c740 <__gmpn_toom44_mul@plt>
   3ab38:	b	3ab54 <__gmpn_toom6h_mul@@Base+0x9cc>
   3ab3c:	ldp	x3, x1, [x29, #-16]
   3ab40:	mov	x0, x20
   3ab44:	mov	x2, x23
   3ab48:	mov	x4, x23
   3ab4c:	mov	x5, x24
   3ab50:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3ab54:	ldr	w21, [sp, #44]
   3ab58:	ldp	x22, x25, [x29, #-32]
   3ab5c:	ldur	x9, [x29, #-40]
   3ab60:	ldr	x19, [sp, #32]
   3ab64:	ldr	x26, [sp, #16]
   3ab68:	cbnz	w21, 3abe0 <__gmpn_toom6h_mul@@Base+0xa58>
   3ab6c:	add	x5, x25, x22
   3ab70:	mov	x0, x20
   3ab74:	mov	x1, x26
   3ab78:	mov	x2, x19
   3ab7c:	ldr	x3, [sp, #56]
   3ab80:	mov	x4, x23
   3ab84:	mov	w6, w21
   3ab88:	mov	x7, x24
   3ab8c:	ldp	x20, x19, [sp, #192]
   3ab90:	ldp	x22, x21, [sp, #176]
   3ab94:	ldp	x24, x23, [sp, #160]
   3ab98:	ldp	x26, x25, [sp, #144]
   3ab9c:	ldp	x28, x27, [sp, #128]
   3aba0:	ldp	x29, x30, [sp, #112]
   3aba4:	add	sp, sp, #0xd0
   3aba8:	b	bfc0 <__gmpn_toom_interpolate_12pts@plt>
   3abac:	mov	w9, #0x5a                  	// #90
   3abb0:	mov	w10, #0x77                  	// #119
   3abb4:	mul	x9, x2, x9
   3abb8:	mul	x10, x4, x10
   3abbc:	cmp	x9, x10
   3abc0:	b.ge	3ac1c <__gmpn_toom6h_mul@@Base+0xa94>  // b.tcont
   3abc4:	mov	w8, #0x6                   	// #6
   3abc8:	b	3ac38 <__gmpn_toom6h_mul@@Base+0xab0>
   3abcc:	ldp	x4, x2, [x29, #-24]
   3abd0:	mov	x3, x23
   3abd4:	mov	x5, x20
   3abd8:	bl	c290 <__gmpn_toom_eval_dgr3_pm1@plt>
   3abdc:	b	3a3fc <__gmpn_toom6h_mul@@Base+0x274>
   3abe0:	mov	w8, #0x58                  	// #88
   3abe4:	cmp	x22, x25
   3abe8:	madd	x0, x23, x8, x20
   3abec:	b.le	3ac88 <__gmpn_toom6h_mul@@Base+0xb00>
   3abf0:	ldur	x8, [x29, #-48]
   3abf4:	ldur	x10, [x29, #-8]
   3abf8:	mul	x9, x23, x9
   3abfc:	mov	x2, x22
   3ac00:	mov	w8, w8
   3ac04:	mul	x8, x23, x8
   3ac08:	add	x1, x10, x8, lsl #3
   3ac0c:	ldur	x8, [x29, #-16]
   3ac10:	mov	x4, x25
   3ac14:	add	x3, x8, x9, lsl #3
   3ac18:	b	3acb0 <__gmpn_toom6h_mul@@Base+0xb28>
   3ac1c:	mov	w9, #0x55                  	// #85
   3ac20:	mov	w10, #0x7e                  	// #126
   3ac24:	mul	x9, x2, x9
   3ac28:	mul	x10, x4, x10
   3ac2c:	cmp	x9, x10
   3ac30:	b.ge	3acd4 <__gmpn_toom6h_mul@@Base+0xb4c>  // b.tcont
   3ac34:	mov	w8, #0x5                   	// #5
   3ac38:	mov	w9, #0x7                   	// #7
   3ac3c:	mov	w12, w9
   3ac40:	mul	x11, x8, x2
   3ac44:	mul	x13, x12, x4
   3ac48:	cmp	x11, x13
   3ac4c:	csel	x11, x4, x2, lt  // lt = tstop
   3ac50:	csel	x12, x8, x12, lt  // lt = tstop
   3ac54:	sub	x11, x11, #0x1
   3ac58:	sub	w15, w9, #0x1
   3ac5c:	udiv	x11, x11, x12
   3ac60:	sub	w26, w8, #0x1
   3ac64:	sxtw	x14, w15
   3ac68:	add	x23, x11, #0x1
   3ac6c:	eor	w10, w8, w9
   3ac70:	msub	x5, x23, x14, x2
   3ac74:	msub	x21, x23, x26, x4
   3ac78:	stur	x21, [x29, #-24]
   3ac7c:	tbnz	w10, #0, 3acb8 <__gmpn_toom6h_mul@@Base+0xb30>
   3ac80:	str	wzr, [sp, #44]
   3ac84:	b	3a1f8 <__gmpn_toom6h_mul@@Base+0x70>
   3ac88:	mul	x8, x23, x9
   3ac8c:	ldur	x9, [x29, #-48]
   3ac90:	ldur	x10, [x29, #-16]
   3ac94:	mov	x2, x25
   3ac98:	mov	x4, x22
   3ac9c:	mov	w9, w9
   3aca0:	add	x1, x10, x8, lsl #3
   3aca4:	mul	x8, x23, x9
   3aca8:	ldur	x9, [x29, #-8]
   3acac:	add	x3, x9, x8, lsl #3
   3acb0:	bl	ccf0 <__gmpn_mul@plt>
   3acb4:	b	3ab6c <__gmpn_toom6h_mul@@Base+0x9e4>
   3acb8:	cmp	x5, #0x0
   3acbc:	b.le	3ad08 <__gmpn_toom6h_mul@@Base+0xb80>
   3acc0:	cmp	x21, #0x0
   3acc4:	b.le	3ad18 <__gmpn_toom6h_mul@@Base+0xb90>
   3acc8:	mov	w8, #0x1                   	// #1
   3accc:	str	w8, [sp, #44]
   3acd0:	b	3a1f8 <__gmpn_toom6h_mul@@Base+0x70>
   3acd4:	add	x9, x2, x2, lsl #3
   3acd8:	lsl	x9, x9, #1
   3acdc:	add	x10, x4, x4, lsl #4
   3ace0:	cmp	x9, x10, lsl #1
   3ace4:	mov	w9, #0x8                   	// #8
   3ace8:	b.ge	3acf4 <__gmpn_toom6h_mul@@Base+0xb6c>  // b.tcont
   3acec:	mov	w8, #0x5                   	// #5
   3acf0:	b	3ac3c <__gmpn_toom6h_mul@@Base+0xab4>
   3acf4:	add	x10, x4, x4, lsl #3
   3acf8:	cmp	x8, x10, lsl #2
   3acfc:	cinc	w9, w9, ge  // ge = tcont
   3ad00:	mov	w8, #0x4                   	// #4
   3ad04:	b	3ac3c <__gmpn_toom6h_mul@@Base+0xab4>
   3ad08:	str	wzr, [sp, #44]
   3ad0c:	sub	w15, w9, #0x2
   3ad10:	add	x5, x5, x23
   3ad14:	b	3a1f8 <__gmpn_toom6h_mul@@Base+0x70>
   3ad18:	mov	x9, x21
   3ad1c:	sub	w26, w8, #0x2
   3ad20:	add	x9, x21, x23
   3ad24:	str	wzr, [sp, #44]
   3ad28:	stur	x9, [x29, #-24]
   3ad2c:	b	3a1f8 <__gmpn_toom6h_mul@@Base+0x70>

000000000003ad30 <__gmpn_toom6_sqr@@Base>:
   3ad30:	sub	sp, sp, #0x90
   3ad34:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   3ad38:	sub	x8, x2, #0x1
   3ad3c:	movk	x9, #0xaaab
   3ad40:	umulh	x8, x8, x9
   3ad44:	stp	x20, x19, [sp, #128]
   3ad48:	lsr	x19, x8, #2
   3ad4c:	stp	x22, x21, [sp, #112]
   3ad50:	add	x22, x19, #0x1
   3ad54:	add	x8, x22, x22, lsl #2
   3ad58:	add	x21, x22, x22, lsl #3
   3ad5c:	mov	w10, #0x38                  	// #56
   3ad60:	sub	x5, x2, x8
   3ad64:	add	x8, x0, x21, lsl #3
   3ad68:	stp	x28, x27, [sp, #64]
   3ad6c:	stp	x26, x25, [sp, #80]
   3ad70:	mov	x20, x0
   3ad74:	add	x27, x8, #0x10
   3ad78:	madd	x25, x22, x10, x0
   3ad7c:	stp	x24, x23, [sp, #96]
   3ad80:	mov	x24, x3
   3ad84:	mov	x3, x1
   3ad88:	mov	w2, #0x5                   	// #5
   3ad8c:	mov	w6, #0x1                   	// #1
   3ad90:	mov	x0, x27
   3ad94:	mov	x1, x25
   3ad98:	mov	x4, x22
   3ad9c:	mov	x7, x20
   3ada0:	stp	x29, x30, [sp, #48]
   3ada4:	add	x29, sp, #0x30
   3ada8:	mov	x23, x3
   3adac:	mov	x26, x5
   3adb0:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3adb4:	add	x8, x24, x21, lsl #3
   3adb8:	add	x28, x19, #0x2
   3adbc:	mov	x19, x24
   3adc0:	add	x24, x8, #0x18
   3adc4:	mov	x0, x20
   3adc8:	mov	x1, x25
   3adcc:	mov	x2, x28
   3add0:	mov	x3, x24
   3add4:	bl	c060 <__gmpn_toom2_sqr@plt>
   3add8:	mov	x0, x19
   3addc:	mov	x1, x27
   3ade0:	mov	x2, x28
   3ade4:	mov	x3, x24
   3ade8:	bl	c060 <__gmpn_toom2_sqr@plt>
   3adec:	mov	w1, #0x1                   	// #1
   3adf0:	bfi	x1, x22, #1, #63
   3adf4:	mov	w5, #0x1                   	// #1
   3adf8:	mov	x0, x19
   3adfc:	mov	x2, x20
   3ae00:	mov	w3, wzr
   3ae04:	mov	x4, x22
   3ae08:	mov	w6, wzr
   3ae0c:	str	x1, [sp, #8]
   3ae10:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3ae14:	mov	w2, #0x5                   	// #5
   3ae18:	mov	x0, x27
   3ae1c:	mov	x1, x25
   3ae20:	mov	x3, x23
   3ae24:	mov	x4, x22
   3ae28:	mov	x5, x26
   3ae2c:	mov	x6, x20
   3ae30:	mov	x21, x26
   3ae34:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   3ae38:	mov	x0, x20
   3ae3c:	mov	x1, x25
   3ae40:	mov	x2, x28
   3ae44:	mov	x3, x24
   3ae48:	bl	c060 <__gmpn_toom2_sqr@plt>
   3ae4c:	add	x8, x22, x22, lsl #1
   3ae50:	str	x8, [sp, #24]
   3ae54:	add	x8, x19, x8, lsl #3
   3ae58:	add	x26, x8, #0x8
   3ae5c:	mov	x0, x26
   3ae60:	mov	x1, x27
   3ae64:	mov	x2, x28
   3ae68:	mov	x3, x24
   3ae6c:	stp	x19, x26, [x29, #-16]
   3ae70:	bl	c060 <__gmpn_toom2_sqr@plt>
   3ae74:	mov	x0, x26
   3ae78:	ldr	x26, [sp, #8]
   3ae7c:	mov	x2, x20
   3ae80:	mov	w3, wzr
   3ae84:	mov	x4, x22
   3ae88:	mov	x1, x26
   3ae8c:	mov	w5, wzr
   3ae90:	mov	w6, wzr
   3ae94:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3ae98:	mov	w2, #0x5                   	// #5
   3ae9c:	mov	w6, #0x2                   	// #2
   3aea0:	mov	x0, x27
   3aea4:	mov	x1, x25
   3aea8:	mov	x3, x23
   3aeac:	mov	x4, x22
   3aeb0:	mov	x5, x21
   3aeb4:	mov	x7, x20
   3aeb8:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   3aebc:	mov	x0, x20
   3aec0:	mov	x1, x25
   3aec4:	mov	x2, x28
   3aec8:	mov	x3, x24
   3aecc:	bl	c060 <__gmpn_toom2_sqr@plt>
   3aed0:	mov	w8, #0x30                  	// #48
   3aed4:	madd	x8, x22, x8, x19
   3aed8:	add	x19, x8, #0x10
   3aedc:	mov	x0, x19
   3aee0:	mov	x1, x27
   3aee4:	mov	x2, x28
   3aee8:	mov	x3, x24
   3aeec:	str	x19, [sp, #16]
   3aef0:	bl	c060 <__gmpn_toom2_sqr@plt>
   3aef4:	mov	w5, #0x2                   	// #2
   3aef8:	mov	w6, #0x4                   	// #4
   3aefc:	mov	x0, x19
   3af00:	mov	x1, x26
   3af04:	mov	x2, x20
   3af08:	mov	w3, wzr
   3af0c:	mov	x4, x22
   3af10:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3af14:	mov	w2, #0x5                   	// #5
   3af18:	mov	w6, #0x2                   	// #2
   3af1c:	mov	x0, x27
   3af20:	mov	x1, x25
   3af24:	mov	x3, x23
   3af28:	mov	x4, x22
   3af2c:	mov	x5, x21
   3af30:	mov	x7, x20
   3af34:	mov	x19, x23
   3af38:	mov	x23, x21
   3af3c:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3af40:	mov	x0, x20
   3af44:	mov	x1, x25
   3af48:	mov	x2, x28
   3af4c:	mov	x3, x24
   3af50:	bl	c060 <__gmpn_toom2_sqr@plt>
   3af54:	ldr	x8, [sp, #24]
   3af58:	mov	x1, x27
   3af5c:	mov	x2, x28
   3af60:	mov	x3, x24
   3af64:	add	x21, x20, x8, lsl #3
   3af68:	mov	x0, x21
   3af6c:	bl	c060 <__gmpn_toom2_sqr@plt>
   3af70:	mov	w5, #0x2                   	// #2
   3af74:	mov	x0, x21
   3af78:	mov	x1, x26
   3af7c:	mov	x2, x20
   3af80:	mov	w3, wzr
   3af84:	mov	x4, x22
   3af88:	mov	w6, wzr
   3af8c:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3af90:	mov	w2, #0x5                   	// #5
   3af94:	mov	x0, x27
   3af98:	mov	x1, x25
   3af9c:	mov	x3, x19
   3afa0:	mov	x4, x22
   3afa4:	mov	x5, x23
   3afa8:	mov	x6, x20
   3afac:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   3afb0:	mov	x0, x20
   3afb4:	mov	x1, x25
   3afb8:	mov	x2, x28
   3afbc:	mov	x3, x24
   3afc0:	bl	c060 <__gmpn_toom2_sqr@plt>
   3afc4:	mov	x0, x25
   3afc8:	mov	x1, x27
   3afcc:	mov	x2, x28
   3afd0:	mov	x3, x24
   3afd4:	bl	c060 <__gmpn_toom2_sqr@plt>
   3afd8:	mov	w5, #0x1                   	// #1
   3afdc:	mov	w6, #0x2                   	// #2
   3afe0:	mov	x0, x25
   3afe4:	mov	x1, x26
   3afe8:	mov	x2, x20
   3afec:	mov	w3, wzr
   3aff0:	mov	x4, x22
   3aff4:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3aff8:	mov	x0, x20
   3affc:	mov	x1, x19
   3b000:	mov	x2, x22
   3b004:	mov	x3, x24
   3b008:	bl	c060 <__gmpn_toom2_sqr@plt>
   3b00c:	lsl	x5, x23, #1
   3b010:	mov	x0, x20
   3b014:	ldr	x1, [sp, #16]
   3b018:	ldp	x3, x2, [x29, #-16]
   3b01c:	mov	x4, x22
   3b020:	mov	x7, x24
   3b024:	ldp	x20, x19, [sp, #128]
   3b028:	ldp	x22, x21, [sp, #112]
   3b02c:	ldp	x24, x23, [sp, #96]
   3b030:	ldp	x26, x25, [sp, #80]
   3b034:	ldp	x28, x27, [sp, #64]
   3b038:	ldp	x29, x30, [sp, #48]
   3b03c:	mov	w6, wzr
   3b040:	add	sp, sp, #0x90
   3b044:	b	bfc0 <__gmpn_toom_interpolate_12pts@plt>

000000000003b048 <__gmpn_toom8h_mul@@Base>:
   3b048:	sub	sp, sp, #0x100
   3b04c:	stp	x29, x30, [sp, #160]
   3b050:	stp	x28, x27, [sp, #176]
   3b054:	stp	x20, x19, [sp, #240]
   3b058:	add	x29, sp, #0xa0
   3b05c:	mov	x27, x5
   3b060:	mov	x16, x1
   3b064:	cmp	x2, x4
   3b068:	mov	x20, x0
   3b06c:	stp	x26, x25, [sp, #192]
   3b070:	stp	x24, x23, [sp, #208]
   3b074:	stp	x22, x21, [sp, #224]
   3b078:	stp	x1, x3, [x29, #-16]
   3b07c:	str	x0, [sp, #32]
   3b080:	b.ne	3c1d8 <__gmpn_toom8h_mul@@Base+0x1190>  // b.any
   3b084:	sub	x8, x2, #0x1
   3b088:	asr	x8, x8, #3
   3b08c:	add	x23, x8, #0x1
   3b090:	lsl	x8, x23, #3
   3b094:	sub	x8, x8, x23
   3b098:	mov	w10, wzr
   3b09c:	mov	w15, #0x7                   	// #7
   3b0a0:	sub	x5, x2, x8
   3b0a4:	sub	x26, x4, x8
   3b0a8:	mov	w28, #0x7                   	// #7
   3b0ac:	mov	w8, #0xd                   	// #13
   3b0b0:	mul	x19, x23, x8
   3b0b4:	add	x8, x20, x19, lsl #3
   3b0b8:	mov	w9, #0x58                  	// #88
   3b0bc:	add	x25, x8, #0x10
   3b0c0:	madd	x1, x23, x9, x20
   3b0c4:	mov	w6, #0x3                   	// #3
   3b0c8:	mov	x0, x25
   3b0cc:	mov	w2, w15
   3b0d0:	mov	x3, x16
   3b0d4:	mov	x4, x23
   3b0d8:	mov	x7, x20
   3b0dc:	stp	x5, x26, [x29, #-32]
   3b0e0:	stur	w10, [x29, #-76]
   3b0e4:	str	x1, [sp, #72]
   3b0e8:	stur	x15, [x29, #-48]
   3b0ec:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3b0f0:	add	x8, x23, x23, lsl #1
   3b0f4:	ldur	x3, [x29, #-8]
   3b0f8:	add	x9, x27, x8, lsl #5
   3b0fc:	add	x8, x20, x8, lsl #5
   3b100:	add	x21, x9, #0x20
   3b104:	add	x24, x8, #0x8
   3b108:	mov	w22, w0
   3b10c:	mov	w6, #0x3                   	// #3
   3b110:	mov	x0, x21
   3b114:	mov	x1, x24
   3b118:	mov	w2, w28
   3b11c:	mov	x4, x23
   3b120:	mov	x5, x26
   3b124:	mov	x7, x20
   3b128:	stur	x28, [x29, #-56]
   3b12c:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3b130:	eor	w28, w0, w22
   3b134:	cmp	x23, #0x2f
   3b138:	add	x22, x23, #0x1
   3b13c:	stur	x21, [x29, #-64]
   3b140:	stp	x24, x25, [sp, #48]
   3b144:	stur	x19, [x29, #-40]
   3b148:	str	x27, [sp, #64]
   3b14c:	b.le	3b1c4 <__gmpn_toom8h_mul@@Base+0x17c>
   3b150:	ldr	x9, [sp, #72]
   3b154:	cmp	x23, #0x50
   3b158:	b.le	3b208 <__gmpn_toom8h_mul@@Base+0x1c0>
   3b15c:	ldp	x25, x27, [sp, #56]
   3b160:	ldur	x8, [x29, #-40]
   3b164:	cmp	x23, #0xab
   3b168:	add	x8, x27, x8, lsl #3
   3b16c:	b.le	3b264 <__gmpn_toom8h_mul@@Base+0x21c>
   3b170:	cmp	x23, #0xea
   3b174:	add	x26, x8, #0x28
   3b178:	b.le	3b2b0 <__gmpn_toom8h_mul@@Base+0x268>
   3b17c:	ldr	x20, [sp, #32]
   3b180:	ldr	x24, [sp, #48]
   3b184:	mov	x1, x9
   3b188:	mov	x2, x22
   3b18c:	mov	x0, x20
   3b190:	mov	x3, x24
   3b194:	mov	x4, x22
   3b198:	mov	x5, x26
   3b19c:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3b1a0:	ldur	x21, [x29, #-64]
   3b1a4:	mov	x0, x27
   3b1a8:	mov	x1, x25
   3b1ac:	mov	x2, x22
   3b1b0:	mov	x3, x21
   3b1b4:	mov	x4, x22
   3b1b8:	mov	x5, x26
   3b1bc:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3b1c0:	b	3b2f4 <__gmpn_toom8h_mul@@Base+0x2ac>
   3b1c4:	ldr	x1, [sp, #72]
   3b1c8:	add	x8, x27, x19, lsl #3
   3b1cc:	add	x26, x8, #0x28
   3b1d0:	mov	x0, x20
   3b1d4:	mov	x2, x22
   3b1d8:	mov	x3, x24
   3b1dc:	mov	x4, x22
   3b1e0:	mov	x5, x26
   3b1e4:	bl	d470 <__gmpn_toom22_mul@plt>
   3b1e8:	mov	x0, x27
   3b1ec:	mov	x1, x25
   3b1f0:	mov	x2, x22
   3b1f4:	mov	x3, x21
   3b1f8:	mov	x4, x22
   3b1fc:	mov	x5, x26
   3b200:	bl	d470 <__gmpn_toom22_mul@plt>
   3b204:	b	3b2f4 <__gmpn_toom8h_mul@@Base+0x2ac>
   3b208:	ldur	x8, [x29, #-40]
   3b20c:	ldr	x27, [sp, #64]
   3b210:	ldr	x20, [sp, #32]
   3b214:	ldr	x24, [sp, #48]
   3b218:	mov	x1, x9
   3b21c:	add	x8, x27, x8, lsl #3
   3b220:	add	x26, x8, #0x28
   3b224:	mov	x0, x20
   3b228:	mov	x2, x22
   3b22c:	mov	x3, x24
   3b230:	mov	x4, x22
   3b234:	mov	x5, x26
   3b238:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3b23c:	ldr	x25, [sp, #56]
   3b240:	ldur	x21, [x29, #-64]
   3b244:	mov	x0, x27
   3b248:	mov	x2, x22
   3b24c:	mov	x1, x25
   3b250:	mov	x3, x21
   3b254:	mov	x4, x22
   3b258:	mov	x5, x26
   3b25c:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3b260:	b	3b2f4 <__gmpn_toom8h_mul@@Base+0x2ac>
   3b264:	ldr	x20, [sp, #32]
   3b268:	ldr	x24, [sp, #48]
   3b26c:	add	x26, x8, #0x28
   3b270:	mov	x1, x9
   3b274:	mov	x0, x20
   3b278:	mov	x2, x22
   3b27c:	mov	x3, x24
   3b280:	mov	x4, x22
   3b284:	mov	x5, x26
   3b288:	bl	c740 <__gmpn_toom44_mul@plt>
   3b28c:	ldur	x21, [x29, #-64]
   3b290:	mov	x0, x27
   3b294:	mov	x1, x25
   3b298:	mov	x2, x22
   3b29c:	mov	x3, x21
   3b2a0:	mov	x4, x22
   3b2a4:	mov	x5, x26
   3b2a8:	bl	c740 <__gmpn_toom44_mul@plt>
   3b2ac:	b	3b2f4 <__gmpn_toom8h_mul@@Base+0x2ac>
   3b2b0:	ldr	x20, [sp, #32]
   3b2b4:	ldr	x24, [sp, #48]
   3b2b8:	mov	x1, x9
   3b2bc:	mov	x2, x22
   3b2c0:	mov	x0, x20
   3b2c4:	mov	x3, x24
   3b2c8:	mov	x4, x22
   3b2cc:	mov	x5, x26
   3b2d0:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3b2d4:	ldur	x21, [x29, #-64]
   3b2d8:	mov	x0, x27
   3b2dc:	mov	x1, x25
   3b2e0:	mov	x2, x22
   3b2e4:	mov	x3, x21
   3b2e8:	mov	x4, x22
   3b2ec:	mov	x5, x26
   3b2f0:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3b2f4:	ldur	w6, [x29, #-76]
   3b2f8:	mov	w19, #0x1                   	// #1
   3b2fc:	bfi	x19, x23, #1, #63
   3b300:	mov	x0, x27
   3b304:	add	w8, w6, #0x1
   3b308:	bfi	w6, w6, #1, #1
   3b30c:	add	w5, w6, #0x3
   3b310:	mov	x1, x19
   3b314:	mov	x2, x20
   3b318:	mov	w3, w28
   3b31c:	mov	x4, x23
   3b320:	str	w8, [sp, #44]
   3b324:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3b328:	ldr	x1, [sp, #72]
   3b32c:	ldur	x3, [x29, #-16]
   3b330:	ldur	x5, [x29, #-32]
   3b334:	mov	w6, #0x2                   	// #2
   3b338:	mov	x0, x25
   3b33c:	ldur	x2, [x29, #-48]
   3b340:	mov	x4, x23
   3b344:	mov	x7, x20
   3b348:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3b34c:	ldur	x3, [x29, #-8]
   3b350:	ldur	x5, [x29, #-24]
   3b354:	mov	w28, w0
   3b358:	mov	w6, #0x2                   	// #2
   3b35c:	mov	x0, x21
   3b360:	mov	x1, x24
   3b364:	ldur	x2, [x29, #-56]
   3b368:	mov	x4, x23
   3b36c:	mov	x7, x20
   3b370:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3b374:	cmp	x23, #0x2f
   3b378:	eor	w9, w0, w28
   3b37c:	stur	w9, [x29, #-72]
   3b380:	b.le	3b3fc <__gmpn_toom8h_mul@@Base+0x3b4>
   3b384:	ldr	x1, [sp, #72]
   3b388:	cmp	x23, #0x50
   3b38c:	b.le	3b450 <__gmpn_toom8h_mul@@Base+0x408>
   3b390:	ldur	x8, [x29, #-40]
   3b394:	cmp	x23, #0xab
   3b398:	b.le	3b4ac <__gmpn_toom8h_mul@@Base+0x464>
   3b39c:	ldr	x27, [sp, #64]
   3b3a0:	cmp	x23, #0xea
   3b3a4:	add	x8, x27, x8, lsl #3
   3b3a8:	add	x26, x8, #0x28
   3b3ac:	b.le	3b504 <__gmpn_toom8h_mul@@Base+0x4bc>
   3b3b0:	ldr	x20, [sp, #32]
   3b3b4:	ldr	x24, [sp, #48]
   3b3b8:	mov	x2, x22
   3b3bc:	mov	x4, x22
   3b3c0:	mov	x0, x20
   3b3c4:	mov	x3, x24
   3b3c8:	mov	x5, x26
   3b3cc:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3b3d0:	ldr	x25, [sp, #56]
   3b3d4:	add	x28, x23, x23, lsl #1
   3b3d8:	add	x8, x27, x28, lsl #3
   3b3dc:	add	x0, x8, #0x8
   3b3e0:	mov	x1, x25
   3b3e4:	mov	x2, x22
   3b3e8:	mov	x3, x21
   3b3ec:	mov	x4, x22
   3b3f0:	mov	x5, x26
   3b3f4:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3b3f8:	b	3b54c <__gmpn_toom8h_mul@@Base+0x504>
   3b3fc:	ldur	x8, [x29, #-40]
   3b400:	ldr	x1, [sp, #72]
   3b404:	mov	x0, x20
   3b408:	mov	x2, x22
   3b40c:	add	x8, x27, x8, lsl #3
   3b410:	add	x26, x8, #0x28
   3b414:	mov	x3, x24
   3b418:	mov	x4, x22
   3b41c:	mov	x5, x26
   3b420:	bl	d470 <__gmpn_toom22_mul@plt>
   3b424:	add	x28, x23, x23, lsl #1
   3b428:	mov	x5, x26
   3b42c:	ldur	w26, [x29, #-76]
   3b430:	add	x8, x27, x28, lsl #3
   3b434:	add	x0, x8, #0x8
   3b438:	mov	x1, x25
   3b43c:	mov	x2, x22
   3b440:	mov	x3, x21
   3b444:	mov	x4, x22
   3b448:	bl	d470 <__gmpn_toom22_mul@plt>
   3b44c:	b	3b550 <__gmpn_toom8h_mul@@Base+0x508>
   3b450:	ldur	x8, [x29, #-40]
   3b454:	ldr	x27, [sp, #64]
   3b458:	ldr	x20, [sp, #32]
   3b45c:	ldr	x24, [sp, #48]
   3b460:	mov	x2, x22
   3b464:	add	x8, x27, x8, lsl #3
   3b468:	add	x26, x8, #0x28
   3b46c:	mov	x0, x20
   3b470:	mov	x3, x24
   3b474:	mov	x4, x22
   3b478:	mov	x5, x26
   3b47c:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3b480:	ldr	x25, [sp, #56]
   3b484:	add	x28, x23, x23, lsl #1
   3b488:	add	x8, x27, x28, lsl #3
   3b48c:	add	x0, x8, #0x8
   3b490:	mov	x1, x25
   3b494:	mov	x2, x22
   3b498:	mov	x3, x21
   3b49c:	mov	x4, x22
   3b4a0:	mov	x5, x26
   3b4a4:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3b4a8:	b	3b54c <__gmpn_toom8h_mul@@Base+0x504>
   3b4ac:	ldr	x27, [sp, #64]
   3b4b0:	ldr	x20, [sp, #32]
   3b4b4:	ldr	x24, [sp, #48]
   3b4b8:	mov	x2, x22
   3b4bc:	add	x8, x27, x8, lsl #3
   3b4c0:	add	x26, x8, #0x28
   3b4c4:	mov	x0, x20
   3b4c8:	mov	x3, x24
   3b4cc:	mov	x4, x22
   3b4d0:	mov	x5, x26
   3b4d4:	bl	c740 <__gmpn_toom44_mul@plt>
   3b4d8:	ldr	x25, [sp, #56]
   3b4dc:	add	x28, x23, x23, lsl #1
   3b4e0:	add	x8, x27, x28, lsl #3
   3b4e4:	add	x0, x8, #0x8
   3b4e8:	mov	x1, x25
   3b4ec:	mov	x2, x22
   3b4f0:	mov	x3, x21
   3b4f4:	mov	x4, x22
   3b4f8:	mov	x5, x26
   3b4fc:	bl	c740 <__gmpn_toom44_mul@plt>
   3b500:	b	3b54c <__gmpn_toom8h_mul@@Base+0x504>
   3b504:	ldr	x20, [sp, #32]
   3b508:	ldr	x24, [sp, #48]
   3b50c:	mov	x2, x22
   3b510:	mov	x4, x22
   3b514:	mov	x0, x20
   3b518:	mov	x3, x24
   3b51c:	mov	x5, x26
   3b520:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3b524:	ldr	x25, [sp, #56]
   3b528:	add	x28, x23, x23, lsl #1
   3b52c:	add	x8, x27, x28, lsl #3
   3b530:	add	x0, x8, #0x8
   3b534:	mov	x1, x25
   3b538:	mov	x2, x22
   3b53c:	mov	x3, x21
   3b540:	mov	x4, x22
   3b544:	mov	x5, x26
   3b548:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3b54c:	ldur	w26, [x29, #-76]
   3b550:	ldr	w9, [sp, #44]
   3b554:	ldur	w3, [x29, #-72]
   3b558:	add	x8, x27, x28, lsl #3
   3b55c:	add	x0, x8, #0x8
   3b560:	lsl	w5, w9, #1
   3b564:	lsl	w6, w26, #1
   3b568:	mov	x1, x19
   3b56c:	mov	x2, x20
   3b570:	mov	x4, x23
   3b574:	stp	x28, x0, [sp, #16]
   3b578:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3b57c:	ldr	x28, [sp, #72]
   3b580:	ldur	x3, [x29, #-16]
   3b584:	ldur	x5, [x29, #-32]
   3b588:	mov	x0, x25
   3b58c:	mov	x1, x28
   3b590:	ldur	x2, [x29, #-48]
   3b594:	mov	x4, x23
   3b598:	mov	x6, x20
   3b59c:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   3b5a0:	ldur	x3, [x29, #-8]
   3b5a4:	ldur	x5, [x29, #-24]
   3b5a8:	mov	w26, w0
   3b5ac:	mov	x0, x21
   3b5b0:	mov	x1, x24
   3b5b4:	ldur	x2, [x29, #-56]
   3b5b8:	mov	x4, x23
   3b5bc:	mov	x6, x20
   3b5c0:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   3b5c4:	cmp	x23, #0x2f
   3b5c8:	eor	w8, w0, w26
   3b5cc:	stur	x19, [x29, #-72]
   3b5d0:	str	w8, [sp, #12]
   3b5d4:	b.le	3b654 <__gmpn_toom8h_mul@@Base+0x60c>
   3b5d8:	cmp	x23, #0x50
   3b5dc:	b.le	3b6b0 <__gmpn_toom8h_mul@@Base+0x668>
   3b5e0:	ldp	x25, x19, [sp, #56]
   3b5e4:	cmp	x23, #0xab
   3b5e8:	b.le	3b718 <__gmpn_toom8h_mul@@Base+0x6d0>
   3b5ec:	ldur	x8, [x29, #-40]
   3b5f0:	cmp	x23, #0xea
   3b5f4:	add	x8, x19, x8, lsl #3
   3b5f8:	add	x26, x8, #0x28
   3b5fc:	b.le	3b778 <__gmpn_toom8h_mul@@Base+0x730>
   3b600:	ldr	x20, [sp, #32]
   3b604:	mov	x1, x28
   3b608:	mov	x2, x22
   3b60c:	mov	x3, x24
   3b610:	mov	x0, x20
   3b614:	mov	x4, x22
   3b618:	mov	x5, x26
   3b61c:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3b620:	ldur	x21, [x29, #-64]
   3b624:	add	x8, x23, x23, lsl #1
   3b628:	mov	x27, x24
   3b62c:	lsl	x24, x8, #1
   3b630:	add	x8, x19, x8, lsl #4
   3b634:	add	x0, x8, #0x10
   3b638:	mov	x1, x25
   3b63c:	mov	x2, x22
   3b640:	mov	x3, x21
   3b644:	mov	x4, x22
   3b648:	mov	x5, x26
   3b64c:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3b650:	b	3b7c8 <__gmpn_toom8h_mul@@Base+0x780>
   3b654:	ldur	x8, [x29, #-40]
   3b658:	mov	x0, x20
   3b65c:	mov	x1, x28
   3b660:	mov	x2, x22
   3b664:	add	x8, x27, x8, lsl #3
   3b668:	add	x26, x8, #0x28
   3b66c:	mov	x3, x24
   3b670:	mov	x4, x22
   3b674:	mov	x5, x26
   3b678:	bl	d470 <__gmpn_toom22_mul@plt>
   3b67c:	add	x8, x23, x23, lsl #1
   3b680:	mov	x19, x27
   3b684:	mov	x27, x24
   3b688:	lsl	x24, x8, #1
   3b68c:	add	x8, x19, x8, lsl #4
   3b690:	add	x0, x8, #0x10
   3b694:	mov	x1, x25
   3b698:	mov	x2, x22
   3b69c:	mov	x3, x21
   3b6a0:	mov	x4, x22
   3b6a4:	mov	x5, x26
   3b6a8:	bl	d470 <__gmpn_toom22_mul@plt>
   3b6ac:	b	3b7c8 <__gmpn_toom8h_mul@@Base+0x780>
   3b6b0:	ldur	x8, [x29, #-40]
   3b6b4:	ldr	x19, [sp, #64]
   3b6b8:	ldr	x20, [sp, #32]
   3b6bc:	mov	x1, x28
   3b6c0:	mov	x2, x22
   3b6c4:	add	x8, x19, x8, lsl #3
   3b6c8:	add	x26, x8, #0x28
   3b6cc:	mov	x0, x20
   3b6d0:	mov	x3, x24
   3b6d4:	mov	x4, x22
   3b6d8:	mov	x5, x26
   3b6dc:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3b6e0:	ldr	x25, [sp, #56]
   3b6e4:	ldur	x21, [x29, #-64]
   3b6e8:	add	x8, x23, x23, lsl #1
   3b6ec:	mov	x27, x24
   3b6f0:	lsl	x24, x8, #1
   3b6f4:	add	x8, x19, x8, lsl #4
   3b6f8:	add	x0, x8, #0x10
   3b6fc:	mov	x1, x25
   3b700:	mov	x2, x22
   3b704:	mov	x3, x21
   3b708:	mov	x4, x22
   3b70c:	mov	x5, x26
   3b710:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3b714:	b	3b7c8 <__gmpn_toom8h_mul@@Base+0x780>
   3b718:	ldur	x8, [x29, #-40]
   3b71c:	ldr	x20, [sp, #32]
   3b720:	mov	x1, x28
   3b724:	mov	x2, x22
   3b728:	add	x8, x19, x8, lsl #3
   3b72c:	add	x26, x8, #0x28
   3b730:	mov	x0, x20
   3b734:	mov	x3, x24
   3b738:	mov	x4, x22
   3b73c:	mov	x5, x26
   3b740:	bl	c740 <__gmpn_toom44_mul@plt>
   3b744:	ldur	x21, [x29, #-64]
   3b748:	add	x8, x23, x23, lsl #1
   3b74c:	mov	x27, x24
   3b750:	lsl	x24, x8, #1
   3b754:	add	x8, x19, x8, lsl #4
   3b758:	add	x0, x8, #0x10
   3b75c:	mov	x1, x25
   3b760:	mov	x2, x22
   3b764:	mov	x3, x21
   3b768:	mov	x4, x22
   3b76c:	mov	x5, x26
   3b770:	bl	c740 <__gmpn_toom44_mul@plt>
   3b774:	b	3b7c8 <__gmpn_toom8h_mul@@Base+0x780>
   3b778:	ldr	x20, [sp, #32]
   3b77c:	mov	x1, x28
   3b780:	mov	x2, x22
   3b784:	mov	x3, x24
   3b788:	mov	x0, x20
   3b78c:	mov	x4, x22
   3b790:	mov	x5, x26
   3b794:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3b798:	ldur	x21, [x29, #-64]
   3b79c:	add	x8, x23, x23, lsl #1
   3b7a0:	mov	x27, x24
   3b7a4:	lsl	x24, x8, #1
   3b7a8:	add	x8, x19, x8, lsl #4
   3b7ac:	add	x0, x8, #0x10
   3b7b0:	mov	x1, x25
   3b7b4:	mov	x2, x22
   3b7b8:	mov	x3, x21
   3b7bc:	mov	x4, x22
   3b7c0:	mov	x5, x26
   3b7c4:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3b7c8:	ldur	x1, [x29, #-72]
   3b7cc:	ldr	w3, [sp, #12]
   3b7d0:	ldur	x26, [x29, #-32]
   3b7d4:	add	x8, x19, x24, lsl #3
   3b7d8:	add	x0, x8, #0x10
   3b7dc:	mov	w5, #0x1                   	// #1
   3b7e0:	mov	w6, #0x2                   	// #2
   3b7e4:	mov	x2, x20
   3b7e8:	mov	x4, x23
   3b7ec:	str	x0, [sp, #72]
   3b7f0:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3b7f4:	ldur	x3, [x29, #-16]
   3b7f8:	mov	w6, #0x3                   	// #3
   3b7fc:	mov	x0, x25
   3b800:	mov	x1, x28
   3b804:	ldur	x2, [x29, #-48]
   3b808:	mov	x4, x23
   3b80c:	mov	x5, x26
   3b810:	mov	x7, x20
   3b814:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   3b818:	ldur	x3, [x29, #-8]
   3b81c:	ldur	x5, [x29, #-24]
   3b820:	mov	w26, w0
   3b824:	mov	w6, #0x3                   	// #3
   3b828:	mov	x0, x21
   3b82c:	mov	x1, x27
   3b830:	ldur	x2, [x29, #-56]
   3b834:	mov	x4, x23
   3b838:	mov	x7, x20
   3b83c:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   3b840:	cmp	x23, #0x2f
   3b844:	eor	w9, w0, w26
   3b848:	str	w9, [sp, #12]
   3b84c:	b.le	3b8c8 <__gmpn_toom8h_mul@@Base+0x880>
   3b850:	ldur	x8, [x29, #-40]
   3b854:	cmp	x23, #0x50
   3b858:	b.le	3b91c <__gmpn_toom8h_mul@@Base+0x8d4>
   3b85c:	ldr	x25, [sp, #56]
   3b860:	cmp	x23, #0xab
   3b864:	add	x8, x19, x8, lsl #3
   3b868:	b.le	3b974 <__gmpn_toom8h_mul@@Base+0x92c>
   3b86c:	cmp	x23, #0xea
   3b870:	add	x26, x8, #0x28
   3b874:	mov	x24, x19
   3b878:	mov	x0, x20
   3b87c:	mov	x1, x28
   3b880:	mov	x2, x22
   3b884:	b.le	3b9c4 <__gmpn_toom8h_mul@@Base+0x97c>
   3b888:	ldr	x27, [sp, #48]
   3b88c:	mov	x4, x22
   3b890:	mov	x5, x26
   3b894:	mov	x3, x27
   3b898:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3b89c:	ldur	x21, [x29, #-64]
   3b8a0:	add	x19, x23, x23, lsl #3
   3b8a4:	add	x8, x24, x19, lsl #3
   3b8a8:	add	x0, x8, #0x18
   3b8ac:	mov	x1, x25
   3b8b0:	mov	x2, x22
   3b8b4:	mov	x3, x21
   3b8b8:	mov	x4, x22
   3b8bc:	mov	x5, x26
   3b8c0:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3b8c4:	b	3ba00 <__gmpn_toom8h_mul@@Base+0x9b8>
   3b8c8:	ldur	x8, [x29, #-40]
   3b8cc:	mov	x0, x20
   3b8d0:	mov	x1, x28
   3b8d4:	mov	x2, x22
   3b8d8:	add	x8, x19, x8, lsl #3
   3b8dc:	add	x26, x8, #0x28
   3b8e0:	mov	x3, x27
   3b8e4:	mov	x4, x22
   3b8e8:	mov	x5, x26
   3b8ec:	bl	d470 <__gmpn_toom22_mul@plt>
   3b8f0:	mov	x24, x19
   3b8f4:	add	x19, x23, x23, lsl #3
   3b8f8:	add	x8, x24, x19, lsl #3
   3b8fc:	add	x0, x8, #0x18
   3b900:	mov	x1, x25
   3b904:	mov	x2, x22
   3b908:	mov	x3, x21
   3b90c:	mov	x4, x22
   3b910:	mov	x5, x26
   3b914:	bl	d470 <__gmpn_toom22_mul@plt>
   3b918:	b	3ba00 <__gmpn_toom8h_mul@@Base+0x9b8>
   3b91c:	add	x8, x19, x8, lsl #3
   3b920:	add	x26, x8, #0x28
   3b924:	mov	x0, x20
   3b928:	mov	x1, x28
   3b92c:	mov	x2, x22
   3b930:	mov	x3, x27
   3b934:	mov	x4, x22
   3b938:	mov	x5, x26
   3b93c:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3b940:	ldr	x25, [sp, #56]
   3b944:	ldur	x21, [x29, #-64]
   3b948:	mov	x24, x19
   3b94c:	add	x19, x23, x23, lsl #3
   3b950:	add	x8, x24, x19, lsl #3
   3b954:	add	x0, x8, #0x18
   3b958:	mov	x1, x25
   3b95c:	mov	x2, x22
   3b960:	mov	x3, x21
   3b964:	mov	x4, x22
   3b968:	mov	x5, x26
   3b96c:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3b970:	b	3ba00 <__gmpn_toom8h_mul@@Base+0x9b8>
   3b974:	add	x26, x8, #0x28
   3b978:	mov	x0, x20
   3b97c:	mov	x1, x28
   3b980:	mov	x2, x22
   3b984:	mov	x3, x27
   3b988:	mov	x4, x22
   3b98c:	mov	x5, x26
   3b990:	bl	c740 <__gmpn_toom44_mul@plt>
   3b994:	ldur	x21, [x29, #-64]
   3b998:	mov	x24, x19
   3b99c:	add	x19, x23, x23, lsl #3
   3b9a0:	add	x8, x24, x19, lsl #3
   3b9a4:	add	x0, x8, #0x18
   3b9a8:	mov	x1, x25
   3b9ac:	mov	x2, x22
   3b9b0:	mov	x3, x21
   3b9b4:	mov	x4, x22
   3b9b8:	mov	x5, x26
   3b9bc:	bl	c740 <__gmpn_toom44_mul@plt>
   3b9c0:	b	3ba00 <__gmpn_toom8h_mul@@Base+0x9b8>
   3b9c4:	ldr	x27, [sp, #48]
   3b9c8:	mov	x4, x22
   3b9cc:	mov	x5, x26
   3b9d0:	mov	x3, x27
   3b9d4:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3b9d8:	ldur	x21, [x29, #-64]
   3b9dc:	add	x19, x23, x23, lsl #3
   3b9e0:	add	x8, x24, x19, lsl #3
   3b9e4:	add	x0, x8, #0x18
   3b9e8:	mov	x1, x25
   3b9ec:	mov	x2, x22
   3b9f0:	mov	x3, x21
   3b9f4:	mov	x4, x22
   3b9f8:	mov	x5, x26
   3b9fc:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3ba00:	ldur	x1, [x29, #-72]
   3ba04:	ldr	w3, [sp, #12]
   3ba08:	ldur	x26, [x29, #-32]
   3ba0c:	add	x8, x24, x19, lsl #3
   3ba10:	add	x0, x8, #0x18
   3ba14:	mov	w5, #0x3                   	// #3
   3ba18:	mov	w6, #0x6                   	// #6
   3ba1c:	mov	x2, x20
   3ba20:	mov	x4, x23
   3ba24:	str	x0, [sp, #32]
   3ba28:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3ba2c:	ldur	x3, [x29, #-16]
   3ba30:	mov	w6, #0x1                   	// #1
   3ba34:	mov	x0, x25
   3ba38:	mov	x1, x28
   3ba3c:	ldur	x2, [x29, #-48]
   3ba40:	mov	x4, x23
   3ba44:	mov	x5, x26
   3ba48:	mov	x7, x20
   3ba4c:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3ba50:	ldur	x3, [x29, #-8]
   3ba54:	ldur	x5, [x29, #-24]
   3ba58:	mov	w26, w0
   3ba5c:	mov	w6, #0x1                   	// #1
   3ba60:	mov	x0, x21
   3ba64:	mov	x1, x27
   3ba68:	ldur	x2, [x29, #-56]
   3ba6c:	mov	x4, x23
   3ba70:	mov	x7, x20
   3ba74:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3ba78:	cmp	x23, #0x2f
   3ba7c:	eor	w9, w0, w26
   3ba80:	mov	x19, x24
   3ba84:	str	w9, [sp, #12]
   3ba88:	b.le	3bafc <__gmpn_toom8h_mul@@Base+0xab4>
   3ba8c:	ldur	x24, [x29, #-16]
   3ba90:	ldur	x8, [x29, #-40]
   3ba94:	mov	x27, x28
   3ba98:	cmp	x23, #0x50
   3ba9c:	b.le	3bb54 <__gmpn_toom8h_mul@@Base+0xb0c>
   3baa0:	ldp	x21, x25, [sp, #48]
   3baa4:	cmp	x23, #0xab
   3baa8:	add	x8, x19, x8, lsl #3
   3baac:	b.le	3bba4 <__gmpn_toom8h_mul@@Base+0xb5c>
   3bab0:	ldr	x28, [sp, #16]
   3bab4:	add	x26, x8, #0x28
   3bab8:	cmp	x23, #0xea
   3babc:	mov	x0, x20
   3bac0:	mov	x1, x27
   3bac4:	mov	x2, x22
   3bac8:	mov	x3, x21
   3bacc:	mov	x4, x22
   3bad0:	mov	x5, x26
   3bad4:	b.le	3bbe8 <__gmpn_toom8h_mul@@Base+0xba0>
   3bad8:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3badc:	ldur	x3, [x29, #-64]
   3bae0:	add	x0, x20, x28, lsl #3
   3bae4:	mov	x1, x25
   3bae8:	mov	x2, x22
   3baec:	mov	x4, x22
   3baf0:	mov	x5, x26
   3baf4:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3baf8:	b	3bc08 <__gmpn_toom8h_mul@@Base+0xbc0>
   3bafc:	ldur	x8, [x29, #-40]
   3bb00:	mov	x0, x20
   3bb04:	mov	x1, x28
   3bb08:	mov	x2, x22
   3bb0c:	add	x8, x19, x8, lsl #3
   3bb10:	add	x26, x8, #0x28
   3bb14:	mov	x3, x27
   3bb18:	mov	x4, x22
   3bb1c:	mov	x5, x26
   3bb20:	bl	d470 <__gmpn_toom22_mul@plt>
   3bb24:	mov	x3, x21
   3bb28:	mov	x21, x27
   3bb2c:	mov	x27, x28
   3bb30:	ldr	x28, [sp, #16]
   3bb34:	mov	x1, x25
   3bb38:	mov	x2, x22
   3bb3c:	mov	x4, x22
   3bb40:	add	x0, x20, x28, lsl #3
   3bb44:	mov	x5, x26
   3bb48:	bl	d470 <__gmpn_toom22_mul@plt>
   3bb4c:	ldur	x24, [x29, #-16]
   3bb50:	b	3bc08 <__gmpn_toom8h_mul@@Base+0xbc0>
   3bb54:	ldr	x21, [sp, #48]
   3bb58:	add	x8, x19, x8, lsl #3
   3bb5c:	add	x26, x8, #0x28
   3bb60:	mov	x0, x20
   3bb64:	mov	x1, x27
   3bb68:	mov	x2, x22
   3bb6c:	mov	x3, x21
   3bb70:	mov	x4, x22
   3bb74:	mov	x5, x26
   3bb78:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3bb7c:	ldr	x28, [sp, #16]
   3bb80:	ldr	x25, [sp, #56]
   3bb84:	ldur	x3, [x29, #-64]
   3bb88:	mov	x2, x22
   3bb8c:	add	x0, x20, x28, lsl #3
   3bb90:	mov	x1, x25
   3bb94:	mov	x4, x22
   3bb98:	mov	x5, x26
   3bb9c:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3bba0:	b	3bc08 <__gmpn_toom8h_mul@@Base+0xbc0>
   3bba4:	add	x26, x8, #0x28
   3bba8:	mov	x0, x20
   3bbac:	mov	x1, x27
   3bbb0:	mov	x2, x22
   3bbb4:	mov	x3, x21
   3bbb8:	mov	x4, x22
   3bbbc:	mov	x5, x26
   3bbc0:	bl	c740 <__gmpn_toom44_mul@plt>
   3bbc4:	ldr	x28, [sp, #16]
   3bbc8:	ldur	x3, [x29, #-64]
   3bbcc:	mov	x1, x25
   3bbd0:	mov	x2, x22
   3bbd4:	add	x0, x20, x28, lsl #3
   3bbd8:	mov	x4, x22
   3bbdc:	mov	x5, x26
   3bbe0:	bl	c740 <__gmpn_toom44_mul@plt>
   3bbe4:	b	3bc08 <__gmpn_toom8h_mul@@Base+0xbc0>
   3bbe8:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3bbec:	ldur	x3, [x29, #-64]
   3bbf0:	add	x0, x20, x28, lsl #3
   3bbf4:	mov	x1, x25
   3bbf8:	mov	x2, x22
   3bbfc:	mov	x4, x22
   3bc00:	mov	x5, x26
   3bc04:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3bc08:	ldur	w6, [x29, #-76]
   3bc0c:	ldur	x1, [x29, #-72]
   3bc10:	ldr	w3, [sp, #12]
   3bc14:	ldr	w5, [sp, #44]
   3bc18:	ldur	x26, [x29, #-32]
   3bc1c:	add	x0, x20, x28, lsl #3
   3bc20:	mov	x2, x20
   3bc24:	mov	x4, x23
   3bc28:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3bc2c:	mov	x0, x25
   3bc30:	mov	x1, x27
   3bc34:	ldur	x2, [x29, #-48]
   3bc38:	mov	x3, x24
   3bc3c:	mov	x4, x23
   3bc40:	mov	x5, x26
   3bc44:	mov	x6, x20
   3bc48:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   3bc4c:	ldur	x2, [x29, #-56]
   3bc50:	mov	w28, w0
   3bc54:	cmp	w2, #0x3
   3bc58:	b.eq	3c20c <__gmpn_toom8h_mul@@Base+0x11c4>  // b.none
   3bc5c:	ldur	x0, [x29, #-64]
   3bc60:	ldur	x3, [x29, #-8]
   3bc64:	ldur	x5, [x29, #-24]
   3bc68:	mov	x1, x21
   3bc6c:	mov	x4, x23
   3bc70:	mov	x6, x20
   3bc74:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   3bc78:	cmp	x23, #0x2f
   3bc7c:	eor	w28, w0, w28
   3bc80:	b.le	3bcf4 <__gmpn_toom8h_mul@@Base+0xcac>
   3bc84:	cmp	x23, #0x50
   3bc88:	b.le	3bd4c <__gmpn_toom8h_mul@@Base+0xd04>
   3bc8c:	cmp	x23, #0xab
   3bc90:	b.le	3bda4 <__gmpn_toom8h_mul@@Base+0xd5c>
   3bc94:	ldur	x8, [x29, #-40]
   3bc98:	cmp	x23, #0xea
   3bc9c:	mov	x0, x20
   3bca0:	mov	x1, x27
   3bca4:	add	x8, x19, x8, lsl #3
   3bca8:	add	x8, x8, #0x28
   3bcac:	mov	x2, x22
   3bcb0:	mov	x3, x21
   3bcb4:	mov	x4, x22
   3bcb8:	mov	x5, x8
   3bcbc:	str	x8, [sp, #56]
   3bcc0:	b.le	3bdfc <__gmpn_toom8h_mul@@Base+0xdb4>
   3bcc4:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3bcc8:	ldur	x24, [x29, #-64]
   3bccc:	ldr	x5, [sp, #56]
   3bcd0:	lsl	x8, x23, #3
   3bcd4:	sub	x19, x8, x23
   3bcd8:	add	x0, x20, x19, lsl #3
   3bcdc:	mov	x1, x25
   3bce0:	mov	x2, x22
   3bce4:	mov	x3, x24
   3bce8:	mov	x4, x22
   3bcec:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3bcf0:	b	3be28 <__gmpn_toom8h_mul@@Base+0xde0>
   3bcf4:	ldur	x8, [x29, #-40]
   3bcf8:	mov	x0, x20
   3bcfc:	mov	x1, x27
   3bd00:	mov	x2, x22
   3bd04:	add	x8, x19, x8, lsl #3
   3bd08:	add	x26, x8, #0x28
   3bd0c:	mov	x3, x21
   3bd10:	mov	x4, x22
   3bd14:	mov	x5, x26
   3bd18:	bl	d470 <__gmpn_toom22_mul@plt>
   3bd1c:	ldur	x24, [x29, #-64]
   3bd20:	lsl	x8, x23, #3
   3bd24:	mov	x5, x26
   3bd28:	ldur	x26, [x29, #-32]
   3bd2c:	sub	x19, x8, x23
   3bd30:	add	x0, x20, x19, lsl #3
   3bd34:	mov	x1, x25
   3bd38:	mov	x2, x22
   3bd3c:	mov	x3, x24
   3bd40:	mov	x4, x22
   3bd44:	bl	d470 <__gmpn_toom22_mul@plt>
   3bd48:	b	3be28 <__gmpn_toom8h_mul@@Base+0xde0>
   3bd4c:	ldur	x8, [x29, #-40]
   3bd50:	mov	x0, x20
   3bd54:	mov	x1, x27
   3bd58:	mov	x2, x22
   3bd5c:	add	x8, x19, x8, lsl #3
   3bd60:	add	x26, x8, #0x28
   3bd64:	mov	x3, x21
   3bd68:	mov	x4, x22
   3bd6c:	mov	x5, x26
   3bd70:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3bd74:	ldur	x24, [x29, #-64]
   3bd78:	lsl	x8, x23, #3
   3bd7c:	mov	x5, x26
   3bd80:	ldur	x26, [x29, #-32]
   3bd84:	sub	x19, x8, x23
   3bd88:	add	x0, x20, x19, lsl #3
   3bd8c:	mov	x1, x25
   3bd90:	mov	x2, x22
   3bd94:	mov	x3, x24
   3bd98:	mov	x4, x22
   3bd9c:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3bda0:	b	3be28 <__gmpn_toom8h_mul@@Base+0xde0>
   3bda4:	ldur	x8, [x29, #-40]
   3bda8:	mov	x0, x20
   3bdac:	mov	x1, x27
   3bdb0:	mov	x2, x22
   3bdb4:	add	x8, x19, x8, lsl #3
   3bdb8:	add	x26, x8, #0x28
   3bdbc:	mov	x3, x21
   3bdc0:	mov	x4, x22
   3bdc4:	mov	x5, x26
   3bdc8:	bl	c740 <__gmpn_toom44_mul@plt>
   3bdcc:	ldur	x24, [x29, #-64]
   3bdd0:	lsl	x8, x23, #3
   3bdd4:	mov	x5, x26
   3bdd8:	ldur	x26, [x29, #-32]
   3bddc:	sub	x19, x8, x23
   3bde0:	add	x0, x20, x19, lsl #3
   3bde4:	mov	x1, x25
   3bde8:	mov	x2, x22
   3bdec:	mov	x3, x24
   3bdf0:	mov	x4, x22
   3bdf4:	bl	c740 <__gmpn_toom44_mul@plt>
   3bdf8:	b	3be28 <__gmpn_toom8h_mul@@Base+0xde0>
   3bdfc:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3be00:	ldur	x24, [x29, #-64]
   3be04:	ldr	x5, [sp, #56]
   3be08:	lsl	x8, x23, #3
   3be0c:	sub	x19, x8, x23
   3be10:	add	x0, x20, x19, lsl #3
   3be14:	mov	x1, x25
   3be18:	mov	x2, x22
   3be1c:	mov	x3, x24
   3be20:	mov	x4, x22
   3be24:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3be28:	add	x0, x20, x19, lsl #3
   3be2c:	ldur	x19, [x29, #-72]
   3be30:	mov	x2, x20
   3be34:	mov	w3, w28
   3be38:	mov	x4, x23
   3be3c:	mov	x1, x19
   3be40:	mov	w5, wzr
   3be44:	mov	w6, wzr
   3be48:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3be4c:	ldur	x3, [x29, #-16]
   3be50:	mov	w6, #0x2                   	// #2
   3be54:	mov	x0, x25
   3be58:	mov	x1, x27
   3be5c:	ldur	x2, [x29, #-48]
   3be60:	mov	x4, x23
   3be64:	mov	x5, x26
   3be68:	mov	x7, x20
   3be6c:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   3be70:	ldur	x3, [x29, #-8]
   3be74:	ldur	x5, [x29, #-24]
   3be78:	mov	w26, w0
   3be7c:	mov	w6, #0x2                   	// #2
   3be80:	mov	x0, x24
   3be84:	mov	x1, x21
   3be88:	ldur	x2, [x29, #-56]
   3be8c:	mov	x4, x23
   3be90:	mov	x7, x20
   3be94:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   3be98:	cmp	x23, #0x2f
   3be9c:	eor	w28, w0, w26
   3bea0:	b.le	3bf58 <__gmpn_toom8h_mul@@Base+0xf10>
   3bea4:	ldr	x9, [sp, #64]
   3bea8:	cmp	x23, #0x51
   3beac:	b.lt	3bfd0 <__gmpn_toom8h_mul@@Base+0xf88>  // b.tstop
   3beb0:	ldur	x8, [x29, #-40]
   3beb4:	ldr	x3, [sp, #48]
   3beb8:	cmp	x23, #0xac
   3bebc:	add	x8, x9, x8, lsl #3
   3bec0:	b.lt	3c068 <__gmpn_toom8h_mul@@Base+0x1020>  // b.tstop
   3bec4:	add	x19, x8, #0x28
   3bec8:	cmp	x23, #0xea
   3becc:	mov	x0, x20
   3bed0:	mov	x1, x27
   3bed4:	mov	x2, x22
   3bed8:	mov	x4, x22
   3bedc:	mov	x5, x19
   3bee0:	b.le	3c0f4 <__gmpn_toom8h_mul@@Base+0x10ac>
   3bee4:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3bee8:	ldur	x26, [x29, #-64]
   3beec:	mov	x0, x27
   3bef0:	mov	x1, x25
   3bef4:	mov	x2, x22
   3bef8:	mov	x3, x26
   3befc:	mov	x4, x22
   3bf00:	mov	x5, x19
   3bf04:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3bf08:	ldur	x1, [x29, #-72]
   3bf0c:	mov	w5, #0x2                   	// #2
   3bf10:	mov	w6, #0x4                   	// #4
   3bf14:	mov	x0, x27
   3bf18:	mov	x2, x20
   3bf1c:	mov	w3, w28
   3bf20:	mov	x4, x23
   3bf24:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3bf28:	ldur	w21, [x29, #-76]
   3bf2c:	ldp	x22, x25, [x29, #-32]
   3bf30:	cmp	x23, #0xeb
   3bf34:	b.eq	3c148 <__gmpn_toom8h_mul@@Base+0x1100>  // b.none
   3bf38:	ldp	x28, x3, [x29, #-16]
   3bf3c:	mov	x0, x20
   3bf40:	mov	x2, x23
   3bf44:	mov	x4, x23
   3bf48:	mov	x1, x28
   3bf4c:	mov	x5, x26
   3bf50:	bl	cb40 <__gmpn_toom8h_mul@plt>
   3bf54:	b	3c184 <__gmpn_toom8h_mul@@Base+0x113c>
   3bf58:	ldur	x8, [x29, #-40]
   3bf5c:	ldr	x9, [sp, #64]
   3bf60:	mov	x0, x20
   3bf64:	mov	x1, x27
   3bf68:	mov	x2, x22
   3bf6c:	add	x8, x9, x8, lsl #3
   3bf70:	add	x26, x8, #0x28
   3bf74:	mov	x3, x21
   3bf78:	mov	x4, x22
   3bf7c:	mov	x5, x26
   3bf80:	bl	d470 <__gmpn_toom22_mul@plt>
   3bf84:	mov	x0, x27
   3bf88:	mov	x1, x25
   3bf8c:	mov	x2, x22
   3bf90:	mov	x3, x24
   3bf94:	mov	x4, x22
   3bf98:	mov	x5, x26
   3bf9c:	bl	d470 <__gmpn_toom22_mul@plt>
   3bfa0:	mov	w5, #0x2                   	// #2
   3bfa4:	mov	w6, #0x4                   	// #4
   3bfa8:	mov	x0, x27
   3bfac:	mov	x1, x19
   3bfb0:	mov	x2, x20
   3bfb4:	mov	w3, w28
   3bfb8:	mov	x4, x23
   3bfbc:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3bfc0:	ldur	w21, [x29, #-76]
   3bfc4:	ldp	x22, x25, [x29, #-32]
   3bfc8:	mov	x26, x24
   3bfcc:	b	3c048 <__gmpn_toom8h_mul@@Base+0x1000>
   3bfd0:	ldur	x8, [x29, #-40]
   3bfd4:	ldr	x3, [sp, #48]
   3bfd8:	mov	x0, x20
   3bfdc:	mov	x1, x27
   3bfe0:	add	x8, x9, x8, lsl #3
   3bfe4:	add	x26, x8, #0x28
   3bfe8:	mov	x2, x22
   3bfec:	mov	x4, x22
   3bff0:	mov	x5, x26
   3bff4:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3bff8:	ldur	x3, [x29, #-64]
   3bffc:	mov	x0, x27
   3c000:	mov	x1, x25
   3c004:	mov	x2, x22
   3c008:	mov	x4, x22
   3c00c:	mov	x5, x26
   3c010:	mov	x26, x3
   3c014:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3c018:	ldur	x1, [x29, #-72]
   3c01c:	mov	w5, #0x2                   	// #2
   3c020:	mov	w6, #0x4                   	// #4
   3c024:	mov	x0, x27
   3c028:	mov	x2, x20
   3c02c:	mov	w3, w28
   3c030:	mov	x4, x23
   3c034:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3c038:	ldur	w21, [x29, #-76]
   3c03c:	ldp	x22, x25, [x29, #-32]
   3c040:	cmp	x23, #0x30
   3c044:	b.gt	3c0d4 <__gmpn_toom8h_mul@@Base+0x108c>
   3c048:	ldp	x28, x3, [x29, #-16]
   3c04c:	mov	x0, x20
   3c050:	mov	x2, x23
   3c054:	mov	x4, x23
   3c058:	mov	x1, x28
   3c05c:	mov	x5, x26
   3c060:	bl	d470 <__gmpn_toom22_mul@plt>
   3c064:	b	3c184 <__gmpn_toom8h_mul@@Base+0x113c>
   3c068:	add	x26, x8, #0x28
   3c06c:	mov	x0, x20
   3c070:	mov	x1, x27
   3c074:	mov	x2, x22
   3c078:	mov	x4, x22
   3c07c:	mov	x5, x26
   3c080:	bl	c740 <__gmpn_toom44_mul@plt>
   3c084:	ldur	x3, [x29, #-64]
   3c088:	mov	x0, x27
   3c08c:	mov	x1, x25
   3c090:	mov	x2, x22
   3c094:	mov	x4, x22
   3c098:	mov	x5, x26
   3c09c:	mov	x26, x3
   3c0a0:	bl	c740 <__gmpn_toom44_mul@plt>
   3c0a4:	ldur	x1, [x29, #-72]
   3c0a8:	mov	w5, #0x2                   	// #2
   3c0ac:	mov	w6, #0x4                   	// #4
   3c0b0:	mov	x0, x27
   3c0b4:	mov	x2, x20
   3c0b8:	mov	w3, w28
   3c0bc:	mov	x4, x23
   3c0c0:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3c0c4:	ldur	w21, [x29, #-76]
   3c0c8:	ldp	x22, x25, [x29, #-32]
   3c0cc:	cmp	x23, #0x51
   3c0d0:	b.gt	3c168 <__gmpn_toom8h_mul@@Base+0x1120>
   3c0d4:	ldp	x28, x3, [x29, #-16]
   3c0d8:	mov	x0, x20
   3c0dc:	mov	x2, x23
   3c0e0:	mov	x4, x23
   3c0e4:	mov	x1, x28
   3c0e8:	mov	x5, x26
   3c0ec:	bl	c0b0 <__gmpn_toom33_mul@plt>
   3c0f0:	b	3c184 <__gmpn_toom8h_mul@@Base+0x113c>
   3c0f4:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3c0f8:	ldur	x26, [x29, #-64]
   3c0fc:	mov	x0, x27
   3c100:	mov	x1, x25
   3c104:	mov	x2, x22
   3c108:	mov	x3, x26
   3c10c:	mov	x4, x22
   3c110:	mov	x5, x19
   3c114:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3c118:	ldur	x1, [x29, #-72]
   3c11c:	mov	w5, #0x2                   	// #2
   3c120:	mov	w6, #0x4                   	// #4
   3c124:	mov	x0, x27
   3c128:	mov	x2, x20
   3c12c:	mov	w3, w28
   3c130:	mov	x4, x23
   3c134:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3c138:	ldur	w21, [x29, #-76]
   3c13c:	ldp	x22, x25, [x29, #-32]
   3c140:	cmp	x23, #0xac
   3c144:	b.le	3c168 <__gmpn_toom8h_mul@@Base+0x1120>
   3c148:	ldp	x28, x3, [x29, #-16]
   3c14c:	mov	x0, x20
   3c150:	mov	x2, x23
   3c154:	mov	x4, x23
   3c158:	mov	x1, x28
   3c15c:	mov	x5, x26
   3c160:	bl	cc40 <__gmpn_toom6h_mul@plt>
   3c164:	b	3c184 <__gmpn_toom8h_mul@@Base+0x113c>
   3c168:	ldp	x28, x3, [x29, #-16]
   3c16c:	mov	x0, x20
   3c170:	mov	x2, x23
   3c174:	mov	x4, x23
   3c178:	mov	x1, x28
   3c17c:	mov	x5, x26
   3c180:	bl	c740 <__gmpn_toom44_mul@plt>
   3c184:	ldp	x19, x27, [sp, #24]
   3c188:	ldr	x24, [sp, #72]
   3c18c:	cbnz	w21, 3c22c <__gmpn_toom8h_mul@@Base+0x11e4>
   3c190:	ldr	x4, [sp, #64]
   3c194:	add	x6, x25, x22
   3c198:	mov	x0, x20
   3c19c:	mov	x1, x27
   3c1a0:	mov	x2, x24
   3c1a4:	mov	x3, x19
   3c1a8:	mov	x5, x23
   3c1ac:	mov	w7, w21
   3c1b0:	str	x26, [sp]
   3c1b4:	bl	d370 <__gmpn_toom_interpolate_16pts@plt>
   3c1b8:	ldp	x20, x19, [sp, #240]
   3c1bc:	ldp	x22, x21, [sp, #224]
   3c1c0:	ldp	x24, x23, [sp, #208]
   3c1c4:	ldp	x26, x25, [sp, #192]
   3c1c8:	ldp	x28, x27, [sp, #176]
   3c1cc:	ldp	x29, x30, [sp, #160]
   3c1d0:	add	sp, sp, #0x100
   3c1d4:	ret
   3c1d8:	add	x9, x2, x2, lsl #2
   3c1dc:	asr	x8, x4, #1
   3c1e0:	mov	w10, #0x15                  	// #21
   3c1e4:	lsl	x9, x9, #1
   3c1e8:	mul	x10, x8, x10
   3c1ec:	cmp	x9, x10
   3c1f0:	b.lt	3b084 <__gmpn_toom8h_mul@@Base+0x3c>  // b.tstop
   3c1f4:	mov	w10, #0xd                   	// #13
   3c1f8:	mul	x10, x2, x10
   3c1fc:	cmp	x10, x4, lsl #4
   3c200:	b.ge	3c290 <__gmpn_toom8h_mul@@Base+0x1248>  // b.tcont
   3c204:	mov	w8, #0x8                   	// #8
   3c208:	b	3c2a4 <__gmpn_toom8h_mul@@Base+0x125c>
   3c20c:	ldur	x0, [x29, #-64]
   3c210:	ldur	x2, [x29, #-8]
   3c214:	ldur	x4, [x29, #-24]
   3c218:	mov	x1, x21
   3c21c:	mov	x3, x23
   3c220:	mov	x5, x20
   3c224:	bl	c290 <__gmpn_toom_eval_dgr3_pm1@plt>
   3c228:	b	3bc78 <__gmpn_toom8h_mul@@Base+0xc30>
   3c22c:	mov	w8, #0x78                  	// #120
   3c230:	cmp	x22, x25
   3c234:	madd	x0, x23, x8, x20
   3c238:	b.le	3c264 <__gmpn_toom8h_mul@@Base+0x121c>
   3c23c:	ldp	x9, x8, [x29, #-56]
   3c240:	mov	x2, x22
   3c244:	mov	x4, x25
   3c248:	mov	w8, w8
   3c24c:	mul	x8, x23, x8
   3c250:	add	x1, x28, x8, lsl #3
   3c254:	ldur	x8, [x29, #-8]
   3c258:	mul	x9, x23, x9
   3c25c:	add	x3, x8, x9, lsl #3
   3c260:	b	3c288 <__gmpn_toom8h_mul@@Base+0x1240>
   3c264:	ldp	x8, x9, [x29, #-56]
   3c268:	ldur	x10, [x29, #-8]
   3c26c:	mov	x2, x25
   3c270:	mov	x4, x22
   3c274:	mul	x8, x23, x8
   3c278:	mov	w9, w9
   3c27c:	add	x1, x10, x8, lsl #3
   3c280:	mul	x8, x23, x9
   3c284:	add	x3, x28, x8, lsl #3
   3c288:	bl	ccf0 <__gmpn_mul@plt>
   3c28c:	b	3c190 <__gmpn_toom8h_mul@@Base+0x1148>
   3c290:	mov	w10, #0x1b                  	// #27
   3c294:	mul	x10, x8, x10
   3c298:	cmp	x9, x10
   3c29c:	b.ge	3c2ac <__gmpn_toom8h_mul@@Base+0x1264>  // b.tcont
   3c2a0:	mov	w8, #0x7                   	// #7
   3c2a4:	mov	w9, #0x9                   	// #9
   3c2a8:	b	3c2e4 <__gmpn_toom8h_mul@@Base+0x129c>
   3c2ac:	add	x8, x8, x8, lsl #5
   3c2b0:	cmp	x9, x8
   3c2b4:	b.ge	3c2c0 <__gmpn_toom8h_mul@@Base+0x1278>  // b.tcont
   3c2b8:	mov	w8, #0x7                   	// #7
   3c2bc:	b	3c2d8 <__gmpn_toom8h_mul@@Base+0x1290>
   3c2c0:	lsl	x9, x4, #3
   3c2c4:	lsl	x8, x2, #2
   3c2c8:	sub	x9, x9, x4
   3c2cc:	cmp	x8, x9
   3c2d0:	b.ge	3c348 <__gmpn_toom8h_mul@@Base+0x1300>  // b.tcont
   3c2d4:	mov	w8, #0x6                   	// #6
   3c2d8:	mov	w9, #0xa                   	// #10
   3c2dc:	ldur	x16, [x29, #-16]
   3c2e0:	ldr	x20, [sp, #32]
   3c2e4:	mov	w12, w9
   3c2e8:	mul	x11, x8, x2
   3c2ec:	mul	x13, x12, x4
   3c2f0:	cmp	x11, x13
   3c2f4:	csel	x11, x4, x2, lt  // lt = tstop
   3c2f8:	csel	x12, x8, x12, lt  // lt = tstop
   3c2fc:	sub	x11, x11, #0x1
   3c300:	sub	w14, w8, #0x1
   3c304:	udiv	x11, x11, x12
   3c308:	sub	w15, w9, #0x1
   3c30c:	mov	x28, x14
   3c310:	sxtw	x14, w14
   3c314:	add	x23, x11, #0x1
   3c318:	add	w10, w8, w9
   3c31c:	msub	x5, x23, x15, x2
   3c320:	msub	x26, x23, x14, x4
   3c324:	tbnz	w10, #0, 3c330 <__gmpn_toom8h_mul@@Base+0x12e8>
   3c328:	mov	w10, wzr
   3c32c:	b	3b0ac <__gmpn_toom8h_mul@@Base+0x64>
   3c330:	cmp	x5, #0x0
   3c334:	b.le	3c3bc <__gmpn_toom8h_mul@@Base+0x1374>
   3c338:	cmp	x26, #0x0
   3c33c:	b.le	3c3cc <__gmpn_toom8h_mul@@Base+0x1384>
   3c340:	mov	w10, #0x1                   	// #1
   3c344:	b	3b0ac <__gmpn_toom8h_mul@@Base+0x64>
   3c348:	add	x9, x2, x2, lsl #1
   3c34c:	mov	w10, #0xd                   	// #13
   3c350:	lsl	x9, x9, #1
   3c354:	mul	x10, x4, x10
   3c358:	cmp	x9, x10
   3c35c:	b.ge	3c368 <__gmpn_toom8h_mul@@Base+0x1320>  // b.tcont
   3c360:	mov	w8, #0x6                   	// #6
   3c364:	b	3c378 <__gmpn_toom8h_mul@@Base+0x1330>
   3c368:	add	x9, x4, x4, lsl #3
   3c36c:	cmp	x8, x9
   3c370:	b.ge	3c380 <__gmpn_toom8h_mul@@Base+0x1338>  // b.tcont
   3c374:	mov	w8, #0x5                   	// #5
   3c378:	mov	w9, #0xb                   	// #11
   3c37c:	b	3c2dc <__gmpn_toom8h_mul@@Base+0x1294>
   3c380:	lsl	x8, x2, #3
   3c384:	sub	x8, x8, x2
   3c388:	add	x9, x4, x4, lsl #2
   3c38c:	cmp	x8, x9, lsl #2
   3c390:	mov	w9, #0xc                   	// #12
   3c394:	b.ge	3c3a0 <__gmpn_toom8h_mul@@Base+0x1358>  // b.tcont
   3c398:	mov	w8, #0x5                   	// #5
   3c39c:	b	3c2dc <__gmpn_toom8h_mul@@Base+0x1294>
   3c3a0:	mov	w10, #0x1c                  	// #28
   3c3a4:	add	x8, x2, x2, lsl #3
   3c3a8:	mul	x10, x4, x10
   3c3ac:	cmp	x8, x10
   3c3b0:	cinc	w9, w9, ge  // ge = tcont
   3c3b4:	mov	w8, #0x4                   	// #4
   3c3b8:	b	3c2dc <__gmpn_toom8h_mul@@Base+0x1294>
   3c3bc:	mov	w10, wzr
   3c3c0:	sub	w15, w9, #0x2
   3c3c4:	add	x5, x5, x23
   3c3c8:	b	3b0ac <__gmpn_toom8h_mul@@Base+0x64>
   3c3cc:	mov	w10, wzr
   3c3d0:	sub	w28, w8, #0x2
   3c3d4:	add	x26, x26, x23
   3c3d8:	b	3b0ac <__gmpn_toom8h_mul@@Base+0x64>

000000000003c3dc <__gmpn_toom8_sqr@@Base>:
   3c3dc:	sub	sp, sp, #0xb0
   3c3e0:	sub	x8, x2, #0x1
   3c3e4:	stp	x22, x21, [sp, #144]
   3c3e8:	asr	x22, x8, #3
   3c3ec:	add	x21, x22, #0x1
   3c3f0:	mov	w9, #0x68                  	// #104
   3c3f4:	lsl	x8, x21, #3
   3c3f8:	mov	w10, #0x58                  	// #88
   3c3fc:	madd	x9, x21, x9, x0
   3c400:	sub	x8, x8, x21
   3c404:	stp	x26, x25, [sp, #112]
   3c408:	stp	x24, x23, [sp, #128]
   3c40c:	stp	x20, x19, [sp, #160]
   3c410:	mov	x20, x0
   3c414:	add	x26, x9, #0x10
   3c418:	sub	x23, x2, x8
   3c41c:	madd	x25, x21, x10, x0
   3c420:	stp	x29, x30, [sp, #80]
   3c424:	add	x29, sp, #0x50
   3c428:	mov	x19, x3
   3c42c:	mov	x24, x2
   3c430:	mov	x3, x1
   3c434:	mov	w2, #0x7                   	// #7
   3c438:	mov	w6, #0x3                   	// #3
   3c43c:	mov	x0, x26
   3c440:	mov	x1, x25
   3c444:	mov	x4, x21
   3c448:	mov	x5, x23
   3c44c:	mov	x7, x20
   3c450:	stp	x28, x27, [sp, #96]
   3c454:	str	x8, [sp, #40]
   3c458:	stur	x3, [x29, #-8]
   3c45c:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3c460:	mov	w8, #0x60                  	// #96
   3c464:	cmp	x24, #0x208
   3c468:	add	x27, x22, #0x2
   3c46c:	madd	x8, x21, x8, x19
   3c470:	b.le	3c4bc <__gmpn_toom8_sqr@@Base+0xe0>
   3c474:	cmp	x24, #0x520
   3c478:	b.le	3c4ec <__gmpn_toom8_sqr@@Base+0x110>
   3c47c:	cmp	x24, #0x6e0
   3c480:	b.le	3c51c <__gmpn_toom8_sqr@@Base+0x140>
   3c484:	add	x28, x8, #0x20
   3c488:	cmp	x24, #0xa58
   3c48c:	mov	x0, x20
   3c490:	mov	x1, x25
   3c494:	mov	x2, x27
   3c498:	mov	x3, x28
   3c49c:	b.le	3c54c <__gmpn_toom8_sqr@@Base+0x170>
   3c4a0:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3c4a4:	mov	x0, x19
   3c4a8:	mov	x1, x26
   3c4ac:	mov	x2, x27
   3c4b0:	mov	x3, x28
   3c4b4:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3c4b8:	b	3c564 <__gmpn_toom8_sqr@@Base+0x188>
   3c4bc:	add	x28, x8, #0x20
   3c4c0:	mov	x0, x20
   3c4c4:	mov	x1, x25
   3c4c8:	mov	x2, x27
   3c4cc:	mov	x3, x28
   3c4d0:	bl	c060 <__gmpn_toom2_sqr@plt>
   3c4d4:	mov	x0, x19
   3c4d8:	mov	x1, x26
   3c4dc:	mov	x2, x27
   3c4e0:	mov	x3, x28
   3c4e4:	bl	c060 <__gmpn_toom2_sqr@plt>
   3c4e8:	b	3c564 <__gmpn_toom8_sqr@@Base+0x188>
   3c4ec:	add	x28, x8, #0x20
   3c4f0:	mov	x0, x20
   3c4f4:	mov	x1, x25
   3c4f8:	mov	x2, x27
   3c4fc:	mov	x3, x28
   3c500:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3c504:	mov	x0, x19
   3c508:	mov	x1, x26
   3c50c:	mov	x2, x27
   3c510:	mov	x3, x28
   3c514:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3c518:	b	3c564 <__gmpn_toom8_sqr@@Base+0x188>
   3c51c:	add	x28, x8, #0x20
   3c520:	mov	x0, x20
   3c524:	mov	x1, x25
   3c528:	mov	x2, x27
   3c52c:	mov	x3, x28
   3c530:	bl	c230 <__gmpn_toom4_sqr@plt>
   3c534:	mov	x0, x19
   3c538:	mov	x1, x26
   3c53c:	mov	x2, x27
   3c540:	mov	x3, x28
   3c544:	bl	c230 <__gmpn_toom4_sqr@plt>
   3c548:	b	3c564 <__gmpn_toom8_sqr@@Base+0x188>
   3c54c:	bl	d490 <__gmpn_toom6_sqr@plt>
   3c550:	mov	x0, x19
   3c554:	mov	x1, x26
   3c558:	mov	x2, x27
   3c55c:	mov	x3, x28
   3c560:	bl	d490 <__gmpn_toom6_sqr@plt>
   3c564:	mov	w28, #0x1                   	// #1
   3c568:	bfi	x28, x21, #1, #63
   3c56c:	mov	w5, #0x3                   	// #3
   3c570:	mov	x0, x19
   3c574:	mov	x1, x28
   3c578:	mov	x2, x20
   3c57c:	mov	w3, wzr
   3c580:	mov	x4, x21
   3c584:	mov	w6, wzr
   3c588:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3c58c:	ldur	x3, [x29, #-8]
   3c590:	mov	w2, #0x7                   	// #7
   3c594:	mov	w6, #0x2                   	// #2
   3c598:	mov	x0, x26
   3c59c:	mov	x1, x25
   3c5a0:	mov	x4, x21
   3c5a4:	mov	x5, x23
   3c5a8:	mov	x7, x20
   3c5ac:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3c5b0:	mov	w8, #0x60                  	// #96
   3c5b4:	madd	x8, x21, x8, x19
   3c5b8:	cmp	x24, #0x208
   3c5bc:	b.le	3c614 <__gmpn_toom8_sqr@@Base+0x238>
   3c5c0:	cmp	x24, #0x520
   3c5c4:	b.le	3c650 <__gmpn_toom8_sqr@@Base+0x274>
   3c5c8:	cmp	x24, #0x6e0
   3c5cc:	b.le	3c68c <__gmpn_toom8_sqr@@Base+0x2b0>
   3c5d0:	add	x8, x8, #0x20
   3c5d4:	cmp	x24, #0xa58
   3c5d8:	mov	x0, x20
   3c5dc:	mov	x1, x25
   3c5e0:	mov	x2, x27
   3c5e4:	mov	x3, x8
   3c5e8:	stur	x8, [x29, #-16]
   3c5ec:	b.le	3c6c8 <__gmpn_toom8_sqr@@Base+0x2ec>
   3c5f0:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3c5f4:	ldur	x3, [x29, #-16]
   3c5f8:	add	x22, x21, x21, lsl #1
   3c5fc:	add	x8, x19, x22, lsl #3
   3c600:	add	x0, x8, #0x8
   3c604:	mov	x1, x26
   3c608:	mov	x2, x27
   3c60c:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3c610:	b	3c6e8 <__gmpn_toom8_sqr@@Base+0x30c>
   3c614:	add	x22, x8, #0x20
   3c618:	mov	x0, x20
   3c61c:	mov	x1, x25
   3c620:	mov	x2, x27
   3c624:	mov	x3, x22
   3c628:	bl	c060 <__gmpn_toom2_sqr@plt>
   3c62c:	add	x9, x21, x21, lsl #1
   3c630:	add	x8, x19, x9, lsl #3
   3c634:	add	x0, x8, #0x8
   3c638:	mov	x1, x26
   3c63c:	mov	x2, x27
   3c640:	mov	x3, x22
   3c644:	mov	x22, x9
   3c648:	bl	c060 <__gmpn_toom2_sqr@plt>
   3c64c:	b	3c6e8 <__gmpn_toom8_sqr@@Base+0x30c>
   3c650:	add	x22, x8, #0x20
   3c654:	mov	x0, x20
   3c658:	mov	x1, x25
   3c65c:	mov	x2, x27
   3c660:	mov	x3, x22
   3c664:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3c668:	add	x9, x21, x21, lsl #1
   3c66c:	add	x8, x19, x9, lsl #3
   3c670:	add	x0, x8, #0x8
   3c674:	mov	x1, x26
   3c678:	mov	x2, x27
   3c67c:	mov	x3, x22
   3c680:	mov	x22, x9
   3c684:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3c688:	b	3c6e8 <__gmpn_toom8_sqr@@Base+0x30c>
   3c68c:	add	x22, x8, #0x20
   3c690:	mov	x0, x20
   3c694:	mov	x1, x25
   3c698:	mov	x2, x27
   3c69c:	mov	x3, x22
   3c6a0:	bl	c230 <__gmpn_toom4_sqr@plt>
   3c6a4:	add	x9, x21, x21, lsl #1
   3c6a8:	add	x8, x19, x9, lsl #3
   3c6ac:	add	x0, x8, #0x8
   3c6b0:	mov	x1, x26
   3c6b4:	mov	x2, x27
   3c6b8:	mov	x3, x22
   3c6bc:	mov	x22, x9
   3c6c0:	bl	c230 <__gmpn_toom4_sqr@plt>
   3c6c4:	b	3c6e8 <__gmpn_toom8_sqr@@Base+0x30c>
   3c6c8:	bl	d490 <__gmpn_toom6_sqr@plt>
   3c6cc:	ldur	x3, [x29, #-16]
   3c6d0:	add	x22, x21, x21, lsl #1
   3c6d4:	add	x8, x19, x22, lsl #3
   3c6d8:	add	x0, x8, #0x8
   3c6dc:	mov	x1, x26
   3c6e0:	mov	x2, x27
   3c6e4:	bl	d490 <__gmpn_toom6_sqr@plt>
   3c6e8:	add	x8, x19, x22, lsl #3
   3c6ec:	str	x22, [sp, #24]
   3c6f0:	add	x22, x8, #0x8
   3c6f4:	mov	w5, #0x2                   	// #2
   3c6f8:	mov	x0, x22
   3c6fc:	mov	x1, x28
   3c700:	mov	x2, x20
   3c704:	mov	w3, wzr
   3c708:	mov	x4, x21
   3c70c:	mov	w6, wzr
   3c710:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3c714:	ldur	x3, [x29, #-8]
   3c718:	mov	w2, #0x7                   	// #7
   3c71c:	mov	x0, x26
   3c720:	mov	x1, x25
   3c724:	mov	x4, x21
   3c728:	mov	x5, x23
   3c72c:	mov	x6, x20
   3c730:	bl	c550 <__gmpn_toom_eval_pm2@plt>
   3c734:	mov	w8, #0x60                  	// #96
   3c738:	cmp	x24, #0x208
   3c73c:	madd	x8, x21, x8, x19
   3c740:	stur	x23, [x29, #-16]
   3c744:	str	x22, [sp, #32]
   3c748:	b.le	3c7a4 <__gmpn_toom8_sqr@@Base+0x3c8>
   3c74c:	cmp	x24, #0x520
   3c750:	b.le	3c7e0 <__gmpn_toom8_sqr@@Base+0x404>
   3c754:	cmp	x24, #0x6e0
   3c758:	b.le	3c81c <__gmpn_toom8_sqr@@Base+0x440>
   3c75c:	add	x8, x8, #0x20
   3c760:	cmp	x24, #0xa58
   3c764:	mov	x0, x20
   3c768:	mov	x1, x25
   3c76c:	mov	x2, x27
   3c770:	mov	x22, x8
   3c774:	mov	x3, x8
   3c778:	b.le	3c858 <__gmpn_toom8_sqr@@Base+0x47c>
   3c77c:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3c780:	add	x8, x21, x21, lsl #1
   3c784:	lsl	x23, x8, #1
   3c788:	add	x8, x19, x8, lsl #4
   3c78c:	add	x0, x8, #0x10
   3c790:	mov	x1, x26
   3c794:	mov	x2, x27
   3c798:	mov	x3, x22
   3c79c:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3c7a0:	b	3c87c <__gmpn_toom8_sqr@@Base+0x4a0>
   3c7a4:	add	x22, x8, #0x20
   3c7a8:	mov	x0, x20
   3c7ac:	mov	x1, x25
   3c7b0:	mov	x2, x27
   3c7b4:	mov	x3, x22
   3c7b8:	bl	c060 <__gmpn_toom2_sqr@plt>
   3c7bc:	add	x8, x21, x21, lsl #1
   3c7c0:	lsl	x23, x8, #1
   3c7c4:	add	x8, x19, x8, lsl #4
   3c7c8:	add	x0, x8, #0x10
   3c7cc:	mov	x1, x26
   3c7d0:	mov	x2, x27
   3c7d4:	mov	x3, x22
   3c7d8:	bl	c060 <__gmpn_toom2_sqr@plt>
   3c7dc:	b	3c87c <__gmpn_toom8_sqr@@Base+0x4a0>
   3c7e0:	add	x22, x8, #0x20
   3c7e4:	mov	x0, x20
   3c7e8:	mov	x1, x25
   3c7ec:	mov	x2, x27
   3c7f0:	mov	x3, x22
   3c7f4:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3c7f8:	add	x8, x21, x21, lsl #1
   3c7fc:	lsl	x23, x8, #1
   3c800:	add	x8, x19, x8, lsl #4
   3c804:	add	x0, x8, #0x10
   3c808:	mov	x1, x26
   3c80c:	mov	x2, x27
   3c810:	mov	x3, x22
   3c814:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3c818:	b	3c87c <__gmpn_toom8_sqr@@Base+0x4a0>
   3c81c:	add	x22, x8, #0x20
   3c820:	mov	x0, x20
   3c824:	mov	x1, x25
   3c828:	mov	x2, x27
   3c82c:	mov	x3, x22
   3c830:	bl	c230 <__gmpn_toom4_sqr@plt>
   3c834:	add	x8, x21, x21, lsl #1
   3c838:	lsl	x23, x8, #1
   3c83c:	add	x8, x19, x8, lsl #4
   3c840:	add	x0, x8, #0x10
   3c844:	mov	x1, x26
   3c848:	mov	x2, x27
   3c84c:	mov	x3, x22
   3c850:	bl	c230 <__gmpn_toom4_sqr@plt>
   3c854:	b	3c87c <__gmpn_toom8_sqr@@Base+0x4a0>
   3c858:	bl	d490 <__gmpn_toom6_sqr@plt>
   3c85c:	add	x8, x21, x21, lsl #1
   3c860:	lsl	x23, x8, #1
   3c864:	add	x8, x19, x8, lsl #4
   3c868:	add	x0, x8, #0x10
   3c86c:	mov	x1, x26
   3c870:	mov	x2, x27
   3c874:	mov	x3, x22
   3c878:	bl	d490 <__gmpn_toom6_sqr@plt>
   3c87c:	add	x8, x19, x23, lsl #3
   3c880:	add	x22, x8, #0x10
   3c884:	mov	w5, #0x1                   	// #1
   3c888:	mov	w6, #0x2                   	// #2
   3c88c:	mov	x0, x22
   3c890:	mov	x1, x28
   3c894:	mov	x2, x20
   3c898:	mov	w3, wzr
   3c89c:	mov	x4, x21
   3c8a0:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3c8a4:	ldp	x5, x3, [x29, #-16]
   3c8a8:	mov	w2, #0x7                   	// #7
   3c8ac:	mov	w6, #0x3                   	// #3
   3c8b0:	mov	x0, x26
   3c8b4:	mov	x1, x25
   3c8b8:	mov	x4, x21
   3c8bc:	mov	x7, x20
   3c8c0:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   3c8c4:	mov	w8, #0x60                  	// #96
   3c8c8:	cmp	x24, #0x208
   3c8cc:	madd	x8, x21, x8, x19
   3c8d0:	stur	x22, [x29, #-24]
   3c8d4:	b.le	3c92c <__gmpn_toom8_sqr@@Base+0x550>
   3c8d8:	cmp	x24, #0x520
   3c8dc:	b.le	3c964 <__gmpn_toom8_sqr@@Base+0x588>
   3c8e0:	cmp	x24, #0x6e0
   3c8e4:	b.le	3c99c <__gmpn_toom8_sqr@@Base+0x5c0>
   3c8e8:	add	x8, x8, #0x20
   3c8ec:	cmp	x24, #0xa58
   3c8f0:	mov	x0, x20
   3c8f4:	mov	x1, x25
   3c8f8:	mov	x2, x27
   3c8fc:	mov	x22, x8
   3c900:	mov	x3, x8
   3c904:	b.le	3c9d4 <__gmpn_toom8_sqr@@Base+0x5f8>
   3c908:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3c90c:	add	x23, x21, x21, lsl #3
   3c910:	add	x8, x19, x23, lsl #3
   3c914:	add	x0, x8, #0x18
   3c918:	mov	x1, x26
   3c91c:	mov	x2, x27
   3c920:	mov	x3, x22
   3c924:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3c928:	b	3c9f4 <__gmpn_toom8_sqr@@Base+0x618>
   3c92c:	add	x22, x8, #0x20
   3c930:	mov	x0, x20
   3c934:	mov	x1, x25
   3c938:	mov	x2, x27
   3c93c:	mov	x3, x22
   3c940:	bl	c060 <__gmpn_toom2_sqr@plt>
   3c944:	add	x23, x21, x21, lsl #3
   3c948:	add	x8, x19, x23, lsl #3
   3c94c:	add	x0, x8, #0x18
   3c950:	mov	x1, x26
   3c954:	mov	x2, x27
   3c958:	mov	x3, x22
   3c95c:	bl	c060 <__gmpn_toom2_sqr@plt>
   3c960:	b	3c9f4 <__gmpn_toom8_sqr@@Base+0x618>
   3c964:	add	x22, x8, #0x20
   3c968:	mov	x0, x20
   3c96c:	mov	x1, x25
   3c970:	mov	x2, x27
   3c974:	mov	x3, x22
   3c978:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3c97c:	add	x23, x21, x21, lsl #3
   3c980:	add	x8, x19, x23, lsl #3
   3c984:	add	x0, x8, #0x18
   3c988:	mov	x1, x26
   3c98c:	mov	x2, x27
   3c990:	mov	x3, x22
   3c994:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3c998:	b	3c9f4 <__gmpn_toom8_sqr@@Base+0x618>
   3c99c:	add	x22, x8, #0x20
   3c9a0:	mov	x0, x20
   3c9a4:	mov	x1, x25
   3c9a8:	mov	x2, x27
   3c9ac:	mov	x3, x22
   3c9b0:	bl	c230 <__gmpn_toom4_sqr@plt>
   3c9b4:	add	x23, x21, x21, lsl #3
   3c9b8:	add	x8, x19, x23, lsl #3
   3c9bc:	add	x0, x8, #0x18
   3c9c0:	mov	x1, x26
   3c9c4:	mov	x2, x27
   3c9c8:	mov	x3, x22
   3c9cc:	bl	c230 <__gmpn_toom4_sqr@plt>
   3c9d0:	b	3c9f4 <__gmpn_toom8_sqr@@Base+0x618>
   3c9d4:	bl	d490 <__gmpn_toom6_sqr@plt>
   3c9d8:	add	x23, x21, x21, lsl #3
   3c9dc:	add	x8, x19, x23, lsl #3
   3c9e0:	add	x0, x8, #0x18
   3c9e4:	mov	x1, x26
   3c9e8:	mov	x2, x27
   3c9ec:	mov	x3, x22
   3c9f0:	bl	d490 <__gmpn_toom6_sqr@plt>
   3c9f4:	add	x8, x19, x23, lsl #3
   3c9f8:	add	x22, x8, #0x18
   3c9fc:	mov	w5, #0x3                   	// #3
   3ca00:	mov	w6, #0x6                   	// #6
   3ca04:	mov	x0, x22
   3ca08:	mov	x1, x28
   3ca0c:	mov	x2, x20
   3ca10:	mov	w3, wzr
   3ca14:	mov	x4, x21
   3ca18:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3ca1c:	ldp	x23, x3, [x29, #-16]
   3ca20:	mov	w2, #0x7                   	// #7
   3ca24:	mov	w6, #0x1                   	// #1
   3ca28:	mov	x0, x26
   3ca2c:	mov	x1, x25
   3ca30:	mov	x4, x21
   3ca34:	mov	x5, x23
   3ca38:	mov	x7, x20
   3ca3c:	bl	d100 <__gmpn_toom_eval_pm2rexp@plt>
   3ca40:	mov	w8, #0x60                  	// #96
   3ca44:	cmp	x24, #0x208
   3ca48:	madd	x8, x21, x8, x19
   3ca4c:	stur	x22, [x29, #-32]
   3ca50:	b.le	3caa0 <__gmpn_toom8_sqr@@Base+0x6c4>
   3ca54:	cmp	x24, #0x520
   3ca58:	b.le	3cad8 <__gmpn_toom8_sqr@@Base+0x6fc>
   3ca5c:	cmp	x24, #0x6e0
   3ca60:	b.le	3cb10 <__gmpn_toom8_sqr@@Base+0x734>
   3ca64:	add	x8, x8, #0x20
   3ca68:	cmp	x24, #0xa58
   3ca6c:	mov	x0, x20
   3ca70:	mov	x1, x25
   3ca74:	mov	x2, x27
   3ca78:	mov	x3, x8
   3ca7c:	str	x8, [sp, #16]
   3ca80:	b.le	3cb48 <__gmpn_toom8_sqr@@Base+0x76c>
   3ca84:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3ca88:	ldp	x3, x22, [sp, #16]
   3ca8c:	mov	x1, x26
   3ca90:	mov	x2, x27
   3ca94:	add	x0, x20, x22, lsl #3
   3ca98:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3ca9c:	b	3cb60 <__gmpn_toom8_sqr@@Base+0x784>
   3caa0:	add	x22, x8, #0x20
   3caa4:	mov	x0, x20
   3caa8:	mov	x1, x25
   3caac:	mov	x2, x27
   3cab0:	mov	x3, x22
   3cab4:	bl	c060 <__gmpn_toom2_sqr@plt>
   3cab8:	ldr	x8, [sp, #24]
   3cabc:	mov	x1, x26
   3cac0:	mov	x2, x27
   3cac4:	mov	x3, x22
   3cac8:	add	x0, x20, x8, lsl #3
   3cacc:	mov	x22, x8
   3cad0:	bl	c060 <__gmpn_toom2_sqr@plt>
   3cad4:	b	3cb60 <__gmpn_toom8_sqr@@Base+0x784>
   3cad8:	add	x22, x8, #0x20
   3cadc:	mov	x0, x20
   3cae0:	mov	x1, x25
   3cae4:	mov	x2, x27
   3cae8:	mov	x3, x22
   3caec:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3caf0:	ldr	x8, [sp, #24]
   3caf4:	mov	x1, x26
   3caf8:	mov	x2, x27
   3cafc:	mov	x3, x22
   3cb00:	add	x0, x20, x8, lsl #3
   3cb04:	mov	x22, x8
   3cb08:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3cb0c:	b	3cb60 <__gmpn_toom8_sqr@@Base+0x784>
   3cb10:	add	x22, x8, #0x20
   3cb14:	mov	x0, x20
   3cb18:	mov	x1, x25
   3cb1c:	mov	x2, x27
   3cb20:	mov	x3, x22
   3cb24:	bl	c230 <__gmpn_toom4_sqr@plt>
   3cb28:	ldr	x8, [sp, #24]
   3cb2c:	mov	x1, x26
   3cb30:	mov	x2, x27
   3cb34:	mov	x3, x22
   3cb38:	add	x0, x20, x8, lsl #3
   3cb3c:	mov	x22, x8
   3cb40:	bl	c230 <__gmpn_toom4_sqr@plt>
   3cb44:	b	3cb60 <__gmpn_toom8_sqr@@Base+0x784>
   3cb48:	bl	d490 <__gmpn_toom6_sqr@plt>
   3cb4c:	ldp	x3, x22, [sp, #16]
   3cb50:	mov	x1, x26
   3cb54:	mov	x2, x27
   3cb58:	add	x0, x20, x22, lsl #3
   3cb5c:	bl	d490 <__gmpn_toom6_sqr@plt>
   3cb60:	add	x0, x20, x22, lsl #3
   3cb64:	mov	w5, #0x1                   	// #1
   3cb68:	mov	x1, x28
   3cb6c:	mov	x2, x20
   3cb70:	mov	w3, wzr
   3cb74:	mov	x4, x21
   3cb78:	mov	w6, wzr
   3cb7c:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3cb80:	ldur	x3, [x29, #-8]
   3cb84:	mov	w2, #0x7                   	// #7
   3cb88:	mov	x0, x26
   3cb8c:	mov	x1, x25
   3cb90:	mov	x4, x21
   3cb94:	mov	x5, x23
   3cb98:	mov	x6, x20
   3cb9c:	bl	cfe0 <__gmpn_toom_eval_pm1@plt>
   3cba0:	mov	w8, #0x60                  	// #96
   3cba4:	madd	x8, x21, x8, x19
   3cba8:	cmp	x24, #0x208
   3cbac:	b.le	3cc00 <__gmpn_toom8_sqr@@Base+0x824>
   3cbb0:	cmp	x24, #0x520
   3cbb4:	b.le	3cc38 <__gmpn_toom8_sqr@@Base+0x85c>
   3cbb8:	cmp	x24, #0x6e0
   3cbbc:	b.le	3cc70 <__gmpn_toom8_sqr@@Base+0x894>
   3cbc0:	add	x8, x8, #0x20
   3cbc4:	cmp	x24, #0xa58
   3cbc8:	mov	x0, x20
   3cbcc:	mov	x1, x25
   3cbd0:	mov	x2, x27
   3cbd4:	mov	x3, x8
   3cbd8:	str	x8, [sp, #24]
   3cbdc:	b.le	3cca8 <__gmpn_toom8_sqr@@Base+0x8cc>
   3cbe0:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3cbe4:	ldr	x22, [sp, #40]
   3cbe8:	ldr	x3, [sp, #24]
   3cbec:	mov	x1, x26
   3cbf0:	mov	x2, x27
   3cbf4:	add	x0, x20, x22, lsl #3
   3cbf8:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3cbfc:	b	3ccc4 <__gmpn_toom8_sqr@@Base+0x8e8>
   3cc00:	add	x22, x8, #0x20
   3cc04:	mov	x0, x20
   3cc08:	mov	x1, x25
   3cc0c:	mov	x2, x27
   3cc10:	mov	x3, x22
   3cc14:	bl	c060 <__gmpn_toom2_sqr@plt>
   3cc18:	ldr	x8, [sp, #40]
   3cc1c:	mov	x1, x26
   3cc20:	mov	x2, x27
   3cc24:	mov	x3, x22
   3cc28:	add	x0, x20, x8, lsl #3
   3cc2c:	mov	x22, x8
   3cc30:	bl	c060 <__gmpn_toom2_sqr@plt>
   3cc34:	b	3ccc4 <__gmpn_toom8_sqr@@Base+0x8e8>
   3cc38:	add	x22, x8, #0x20
   3cc3c:	mov	x0, x20
   3cc40:	mov	x1, x25
   3cc44:	mov	x2, x27
   3cc48:	mov	x3, x22
   3cc4c:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3cc50:	ldr	x8, [sp, #40]
   3cc54:	mov	x1, x26
   3cc58:	mov	x2, x27
   3cc5c:	mov	x3, x22
   3cc60:	add	x0, x20, x8, lsl #3
   3cc64:	mov	x22, x8
   3cc68:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3cc6c:	b	3ccc4 <__gmpn_toom8_sqr@@Base+0x8e8>
   3cc70:	add	x22, x8, #0x20
   3cc74:	mov	x0, x20
   3cc78:	mov	x1, x25
   3cc7c:	mov	x2, x27
   3cc80:	mov	x3, x22
   3cc84:	bl	c230 <__gmpn_toom4_sqr@plt>
   3cc88:	ldr	x8, [sp, #40]
   3cc8c:	mov	x1, x26
   3cc90:	mov	x2, x27
   3cc94:	mov	x3, x22
   3cc98:	add	x0, x20, x8, lsl #3
   3cc9c:	mov	x22, x8
   3cca0:	bl	c230 <__gmpn_toom4_sqr@plt>
   3cca4:	b	3ccc4 <__gmpn_toom8_sqr@@Base+0x8e8>
   3cca8:	bl	d490 <__gmpn_toom6_sqr@plt>
   3ccac:	ldr	x22, [sp, #40]
   3ccb0:	ldr	x3, [sp, #24]
   3ccb4:	mov	x1, x26
   3ccb8:	mov	x2, x27
   3ccbc:	add	x0, x20, x22, lsl #3
   3ccc0:	bl	d490 <__gmpn_toom6_sqr@plt>
   3ccc4:	add	x0, x20, x22, lsl #3
   3ccc8:	mov	x1, x28
   3cccc:	mov	x2, x20
   3ccd0:	mov	w3, wzr
   3ccd4:	mov	x4, x21
   3ccd8:	mov	w5, wzr
   3ccdc:	mov	w6, wzr
   3cce0:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3cce4:	ldur	x3, [x29, #-8]
   3cce8:	mov	w2, #0x7                   	// #7
   3ccec:	mov	w6, #0x2                   	// #2
   3ccf0:	mov	x0, x26
   3ccf4:	mov	x1, x25
   3ccf8:	mov	x4, x21
   3ccfc:	mov	x5, x23
   3cd00:	mov	x7, x20
   3cd04:	bl	c3b0 <__gmpn_toom_eval_pm2exp@plt>
   3cd08:	add	x8, x21, x21, lsl #1
   3cd0c:	lsl	x23, x8, #2
   3cd10:	add	x8, x19, x8, lsl #5
   3cd14:	cmp	x24, #0x208
   3cd18:	b.le	3cda8 <__gmpn_toom8_sqr@@Base+0x9cc>
   3cd1c:	cmp	x24, #0x521
   3cd20:	b.lt	3ce14 <__gmpn_toom8_sqr@@Base+0xa38>  // b.tstop
   3cd24:	cmp	x24, #0x6e1
   3cd28:	b.lt	3ce70 <__gmpn_toom8_sqr@@Base+0xa94>  // b.tstop
   3cd2c:	add	x22, x8, #0x20
   3cd30:	cmp	x24, #0xa58
   3cd34:	mov	x0, x20
   3cd38:	mov	x1, x25
   3cd3c:	mov	x2, x27
   3cd40:	mov	x3, x22
   3cd44:	b.le	3cee4 <__gmpn_toom8_sqr@@Base+0xb08>
   3cd48:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3cd4c:	mov	x0, x25
   3cd50:	mov	x1, x26
   3cd54:	mov	x2, x27
   3cd58:	mov	x3, x22
   3cd5c:	mov	x26, x22
   3cd60:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3cd64:	mov	w5, #0x2                   	// #2
   3cd68:	mov	w6, #0x4                   	// #4
   3cd6c:	mov	x0, x25
   3cd70:	mov	x1, x28
   3cd74:	mov	x2, x20
   3cd78:	mov	w3, wzr
   3cd7c:	mov	x4, x21
   3cd80:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3cd84:	ldr	x22, [sp, #32]
   3cd88:	cmp	x24, #0xa60
   3cd8c:	b.le	3cf2c <__gmpn_toom8_sqr@@Base+0xb50>
   3cd90:	ldur	x1, [x29, #-8]
   3cd94:	mov	x0, x20
   3cd98:	mov	x2, x21
   3cd9c:	mov	x3, x26
   3cda0:	bl	d4d0 <__gmpn_toom8_sqr@plt>
   3cda4:	b	3cf5c <__gmpn_toom8_sqr@@Base+0xb80>
   3cda8:	add	x22, x8, #0x20
   3cdac:	mov	x0, x20
   3cdb0:	mov	x1, x25
   3cdb4:	mov	x2, x27
   3cdb8:	mov	x3, x22
   3cdbc:	bl	c060 <__gmpn_toom2_sqr@plt>
   3cdc0:	mov	x0, x25
   3cdc4:	mov	x1, x26
   3cdc8:	mov	x2, x27
   3cdcc:	mov	x3, x22
   3cdd0:	bl	c060 <__gmpn_toom2_sqr@plt>
   3cdd4:	mov	w5, #0x2                   	// #2
   3cdd8:	mov	w6, #0x4                   	// #4
   3cddc:	mov	x0, x25
   3cde0:	mov	x1, x28
   3cde4:	mov	x2, x20
   3cde8:	mov	w3, wzr
   3cdec:	mov	x4, x21
   3cdf0:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3cdf4:	ldr	x22, [sp, #32]
   3cdf8:	ldur	x1, [x29, #-8]
   3cdfc:	add	x8, x19, x23, lsl #3
   3ce00:	add	x3, x8, #0x20
   3ce04:	mov	x0, x20
   3ce08:	mov	x2, x21
   3ce0c:	bl	c060 <__gmpn_toom2_sqr@plt>
   3ce10:	b	3cf5c <__gmpn_toom8_sqr@@Base+0xb80>
   3ce14:	add	x22, x8, #0x20
   3ce18:	mov	x0, x20
   3ce1c:	mov	x1, x25
   3ce20:	mov	x2, x27
   3ce24:	mov	x3, x22
   3ce28:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3ce2c:	mov	x0, x25
   3ce30:	mov	x1, x26
   3ce34:	mov	x2, x27
   3ce38:	mov	x3, x22
   3ce3c:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3ce40:	mov	w5, #0x2                   	// #2
   3ce44:	mov	w6, #0x4                   	// #4
   3ce48:	mov	x0, x25
   3ce4c:	mov	x1, x28
   3ce50:	mov	x2, x20
   3ce54:	mov	w3, wzr
   3ce58:	mov	x4, x21
   3ce5c:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3ce60:	ldr	x22, [sp, #32]
   3ce64:	cmp	x24, #0x210
   3ce68:	b.le	3cdf8 <__gmpn_toom8_sqr@@Base+0xa1c>
   3ce6c:	b	3cec8 <__gmpn_toom8_sqr@@Base+0xaec>
   3ce70:	add	x22, x8, #0x20
   3ce74:	mov	x0, x20
   3ce78:	mov	x1, x25
   3ce7c:	mov	x2, x27
   3ce80:	mov	x3, x22
   3ce84:	bl	c230 <__gmpn_toom4_sqr@plt>
   3ce88:	mov	x0, x25
   3ce8c:	mov	x1, x26
   3ce90:	mov	x2, x27
   3ce94:	mov	x3, x22
   3ce98:	bl	c230 <__gmpn_toom4_sqr@plt>
   3ce9c:	mov	w5, #0x2                   	// #2
   3cea0:	mov	w6, #0x4                   	// #4
   3cea4:	mov	x0, x25
   3cea8:	mov	x1, x28
   3ceac:	mov	x2, x20
   3ceb0:	mov	w3, wzr
   3ceb4:	mov	x4, x21
   3ceb8:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3cebc:	ldr	x22, [sp, #32]
   3cec0:	cmp	x24, #0x528
   3cec4:	b.gt	3cf44 <__gmpn_toom8_sqr@@Base+0xb68>
   3cec8:	ldur	x1, [x29, #-8]
   3cecc:	add	x8, x19, x23, lsl #3
   3ced0:	add	x3, x8, #0x20
   3ced4:	mov	x0, x20
   3ced8:	mov	x2, x21
   3cedc:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3cee0:	b	3cf5c <__gmpn_toom8_sqr@@Base+0xb80>
   3cee4:	bl	d490 <__gmpn_toom6_sqr@plt>
   3cee8:	mov	x0, x25
   3ceec:	mov	x1, x26
   3cef0:	mov	x2, x27
   3cef4:	mov	x3, x22
   3cef8:	mov	x26, x22
   3cefc:	bl	d490 <__gmpn_toom6_sqr@plt>
   3cf00:	mov	w5, #0x2                   	// #2
   3cf04:	mov	w6, #0x4                   	// #4
   3cf08:	mov	x0, x25
   3cf0c:	mov	x1, x28
   3cf10:	mov	x2, x20
   3cf14:	mov	w3, wzr
   3cf18:	mov	x4, x21
   3cf1c:	bl	c990 <__gmpn_toom_couple_handling@plt>
   3cf20:	ldr	x22, [sp, #32]
   3cf24:	cmp	x24, #0x6e8
   3cf28:	b.le	3cf44 <__gmpn_toom8_sqr@@Base+0xb68>
   3cf2c:	ldur	x1, [x29, #-8]
   3cf30:	mov	x0, x20
   3cf34:	mov	x2, x21
   3cf38:	mov	x3, x26
   3cf3c:	bl	d490 <__gmpn_toom6_sqr@plt>
   3cf40:	b	3cf5c <__gmpn_toom8_sqr@@Base+0xb80>
   3cf44:	ldur	x1, [x29, #-8]
   3cf48:	add	x8, x19, x23, lsl #3
   3cf4c:	add	x3, x8, #0x20
   3cf50:	mov	x0, x20
   3cf54:	mov	x2, x21
   3cf58:	bl	c230 <__gmpn_toom4_sqr@plt>
   3cf5c:	ldur	x8, [x29, #-16]
   3cf60:	ldp	x1, x2, [x29, #-32]
   3cf64:	mov	x0, x20
   3cf68:	mov	x3, x22
   3cf6c:	lsl	x6, x8, #1
   3cf70:	add	x8, x19, x23, lsl #3
   3cf74:	add	x8, x8, #0x20
   3cf78:	mov	x4, x19
   3cf7c:	mov	x5, x21
   3cf80:	mov	w7, wzr
   3cf84:	str	x8, [sp]
   3cf88:	bl	d370 <__gmpn_toom_interpolate_16pts@plt>
   3cf8c:	ldp	x20, x19, [sp, #160]
   3cf90:	ldp	x22, x21, [sp, #144]
   3cf94:	ldp	x24, x23, [sp, #128]
   3cf98:	ldp	x26, x25, [sp, #112]
   3cf9c:	ldp	x28, x27, [sp, #96]
   3cfa0:	ldp	x29, x30, [sp, #80]
   3cfa4:	add	sp, sp, #0xb0
   3cfa8:	ret

000000000003cfac <__gmpn_toom_couple_handling@@Base>:
   3cfac:	stp	x29, x30, [sp, #-64]!
   3cfb0:	stp	x22, x21, [sp, #32]
   3cfb4:	mov	x21, x0
   3cfb8:	stp	x24, x23, [sp, #16]
   3cfbc:	stp	x20, x19, [sp, #48]
   3cfc0:	mov	w23, w6
   3cfc4:	mov	w24, w5
   3cfc8:	mov	x19, x4
   3cfcc:	mov	x22, x2
   3cfd0:	mov	x20, x1
   3cfd4:	mov	x0, x2
   3cfd8:	mov	x1, x21
   3cfdc:	mov	x29, sp
   3cfe0:	cbz	w3, 3cff0 <__gmpn_toom_couple_handling@@Base+0x44>
   3cfe4:	mov	x3, x20
   3cfe8:	bl	c860 <__gmpn_rsh1sub_n@plt>
   3cfec:	b	3cff8 <__gmpn_toom_couple_handling@@Base+0x4c>
   3cff0:	mov	x3, x20
   3cff4:	bl	c970 <__gmpn_rsh1add_n@plt>
   3cff8:	mov	x0, x21
   3cffc:	mov	x1, x21
   3d000:	mov	x2, x22
   3d004:	mov	x3, x20
   3d008:	cmp	w24, #0x1
   3d00c:	b.ne	3d018 <__gmpn_toom_couple_handling@@Base+0x6c>  // b.any
   3d010:	bl	c860 <__gmpn_rsh1sub_n@plt>
   3d014:	b	3d038 <__gmpn_toom_couple_handling@@Base+0x8c>
   3d018:	bl	c2e0 <__gmpn_sub_n@plt>
   3d01c:	cmp	w24, #0x1
   3d020:	b.lt	3d038 <__gmpn_toom_couple_handling@@Base+0x8c>  // b.tstop
   3d024:	mov	x0, x21
   3d028:	mov	x1, x21
   3d02c:	mov	x2, x20
   3d030:	mov	w3, w24
   3d034:	bl	c1b0 <__gmpn_rshift@plt>
   3d038:	cmp	w23, #0x1
   3d03c:	b.lt	3d054 <__gmpn_toom_couple_handling@@Base+0xa8>  // b.tstop
   3d040:	mov	x0, x22
   3d044:	mov	x1, x22
   3d048:	mov	x2, x20
   3d04c:	mov	w3, w23
   3d050:	bl	c1b0 <__gmpn_rshift@plt>
   3d054:	add	x0, x21, x19, lsl #3
   3d058:	sub	x3, x20, x19
   3d05c:	mov	x1, x0
   3d060:	mov	x2, x22
   3d064:	bl	ca90 <__gmpn_add_n@plt>
   3d068:	add	x10, x21, x20, lsl #3
   3d06c:	add	x8, x22, x20, lsl #3
   3d070:	str	x0, [x10]
   3d074:	sub	x11, x8, x19, lsl #3
   3d078:	ldr	x9, [x11]
   3d07c:	adds	x9, x9, x0
   3d080:	str	x9, [x10]
   3d084:	b.cc	3d0d8 <__gmpn_toom_couple_handling@@Base+0x12c>  // b.lo, b.ul, b.last
   3d088:	neg	x12, x19
   3d08c:	add	x9, x10, #0x8
   3d090:	mov	w13, #0x1                   	// #1
   3d094:	cmp	x13, x19
   3d098:	b.ge	3d108 <__gmpn_toom_couple_handling@@Base+0x15c>  // b.tcont
   3d09c:	ldr	x14, [x11, x13, lsl #3]
   3d0a0:	add	x13, x13, #0x1
   3d0a4:	adds	x14, x14, #0x1
   3d0a8:	str	x14, [x9], #8
   3d0ac:	b.cs	3d094 <__gmpn_toom_couple_handling@@Base+0xe8>  // b.hs, b.nlast
   3d0b0:	cmp	x11, x10
   3d0b4:	b.eq	3d108 <__gmpn_toom_couple_handling@@Base+0x15c>  // b.none
   3d0b8:	cmp	x13, x19
   3d0bc:	b.ge	3d108 <__gmpn_toom_couple_handling@@Base+0x15c>  // b.tcont
   3d0c0:	add	x10, x12, x13
   3d0c4:	ldr	x11, [x8, x10, lsl #3]
   3d0c8:	adds	x10, x10, #0x1
   3d0cc:	str	x11, [x9], #8
   3d0d0:	b.cc	3d0c4 <__gmpn_toom_couple_handling@@Base+0x118>  // b.lo, b.ul, b.last
   3d0d4:	b	3d108 <__gmpn_toom_couple_handling@@Base+0x15c>
   3d0d8:	cmp	x19, #0x2
   3d0dc:	b.lt	3d108 <__gmpn_toom_couple_handling@@Base+0x15c>  // b.tstop
   3d0e0:	cmp	x11, x10
   3d0e4:	b.eq	3d108 <__gmpn_toom_couple_handling@@Base+0x15c>  // b.none
   3d0e8:	mov	w9, #0x1                   	// #1
   3d0ec:	add	x10, x21, x20, lsl #3
   3d0f0:	sub	x9, x9, x19
   3d0f4:	add	x10, x10, #0x8
   3d0f8:	ldr	x11, [x8, x9, lsl #3]
   3d0fc:	adds	x9, x9, #0x1
   3d100:	str	x11, [x10], #8
   3d104:	b.cc	3d0f8 <__gmpn_toom_couple_handling@@Base+0x14c>  // b.lo, b.ul, b.last
   3d108:	ldp	x20, x19, [sp, #48]
   3d10c:	ldp	x22, x21, [sp, #32]
   3d110:	ldp	x24, x23, [sp, #16]
   3d114:	ldp	x29, x30, [sp], #64
   3d118:	ret

000000000003d11c <__gmpn_toom2_sqr@@Base>:
   3d11c:	sub	sp, sp, #0x70
   3d120:	stp	x22, x21, [sp, #80]
   3d124:	asr	x21, x2, #1
   3d128:	sub	x22, x2, x2, asr #1
   3d12c:	stp	x28, x27, [sp, #32]
   3d130:	stp	x24, x23, [sp, #64]
   3d134:	stp	x20, x19, [sp, #96]
   3d138:	mov	x27, x3
   3d13c:	mov	x28, x2
   3d140:	mov	x24, x1
   3d144:	mov	x20, x0
   3d148:	cmp	x21, x22
   3d14c:	add	x2, x1, x21, lsl #3
   3d150:	stp	x29, x30, [sp, #16]
   3d154:	stp	x26, x25, [sp, #48]
   3d158:	add	x29, sp, #0x10
   3d15c:	b.ne	3d1a0 <__gmpn_toom2_sqr@@Base+0x84>  // b.any
   3d160:	lsl	x8, x21, #4
   3d164:	sub	x8, x8, #0x8
   3d168:	mov	x10, x21
   3d16c:	subs	x9, x10, #0x1
   3d170:	b.lt	3d194 <__gmpn_toom2_sqr@@Base+0x78>  // b.tstop
   3d174:	add	x10, x24, x10, lsl #3
   3d178:	ldur	x10, [x10, #-8]
   3d17c:	ldr	x11, [x24, x8]
   3d180:	sub	x8, x8, #0x8
   3d184:	cmp	x10, x11
   3d188:	mov	x10, x9
   3d18c:	b.eq	3d16c <__gmpn_toom2_sqr@@Base+0x50>  // b.none
   3d190:	b.ls	3d218 <__gmpn_toom2_sqr@@Base+0xfc>  // b.plast
   3d194:	mov	x0, x20
   3d198:	mov	x1, x24
   3d19c:	b	3d224 <__gmpn_toom2_sqr@@Base+0x108>
   3d1a0:	ldr	x23, [x2]
   3d1a4:	cbz	x23, 3d1c8 <__gmpn_toom2_sqr@@Base+0xac>
   3d1a8:	add	x2, x24, x22, lsl #3
   3d1ac:	mov	x0, x20
   3d1b0:	mov	x1, x24
   3d1b4:	mov	x3, x21
   3d1b8:	bl	c2e0 <__gmpn_sub_n@plt>
   3d1bc:	sub	x8, x23, x0
   3d1c0:	str	x8, [x20, x21, lsl #3]
   3d1c4:	b	3d22c <__gmpn_toom2_sqr@@Base+0x110>
   3d1c8:	lsl	x8, x28, #3
   3d1cc:	add	x1, x24, x22, lsl #3
   3d1d0:	sub	x8, x8, #0x8
   3d1d4:	mov	x10, x21
   3d1d8:	subs	x9, x10, #0x1
   3d1dc:	b.lt	3d1a8 <__gmpn_toom2_sqr@@Base+0x8c>  // b.tstop
   3d1e0:	add	x10, x24, x10, lsl #3
   3d1e4:	ldur	x10, [x10, #-8]
   3d1e8:	ldr	x11, [x24, x8]
   3d1ec:	sub	x8, x8, #0x8
   3d1f0:	cmp	x10, x11
   3d1f4:	mov	x10, x9
   3d1f8:	b.eq	3d1d8 <__gmpn_toom2_sqr@@Base+0xbc>  // b.none
   3d1fc:	b.hi	3d1a8 <__gmpn_toom2_sqr@@Base+0x8c>  // b.pmore
   3d200:	mov	x0, x20
   3d204:	mov	x2, x24
   3d208:	mov	x3, x21
   3d20c:	bl	c2e0 <__gmpn_sub_n@plt>
   3d210:	str	xzr, [x20, x21, lsl #3]
   3d214:	b	3d22c <__gmpn_toom2_sqr@@Base+0x110>
   3d218:	mov	x0, x20
   3d21c:	mov	x1, x2
   3d220:	mov	x2, x24
   3d224:	mov	x3, x21
   3d228:	bl	c2e0 <__gmpn_sub_n@plt>
   3d22c:	cmp	x22, #0x11
   3d230:	b.le	3d250 <__gmpn_toom2_sqr@@Base+0x134>
   3d234:	add	x3, x27, x22, lsl #4
   3d238:	mov	x0, x27
   3d23c:	mov	x1, x20
   3d240:	mov	x2, x22
   3d244:	lsl	x25, x22, #1
   3d248:	bl	c060 <__gmpn_toom2_sqr@plt>
   3d24c:	b	3d264 <__gmpn_toom2_sqr@@Base+0x148>
   3d250:	mov	x0, x27
   3d254:	mov	x1, x20
   3d258:	mov	x2, x22
   3d25c:	bl	c1a0 <__gmpn_sqr_basecase@plt>
   3d260:	lsl	x25, x22, #1
   3d264:	add	x26, x20, x25, lsl #3
   3d268:	cmp	x28, #0x23
   3d26c:	add	x1, x24, x22, lsl #3
   3d270:	b.le	3d288 <__gmpn_toom2_sqr@@Base+0x16c>
   3d274:	add	x3, x27, x25, lsl #3
   3d278:	mov	x0, x26
   3d27c:	mov	x2, x21
   3d280:	bl	c060 <__gmpn_toom2_sqr@plt>
   3d284:	b	3d294 <__gmpn_toom2_sqr@@Base+0x178>
   3d288:	mov	x0, x26
   3d28c:	mov	x2, x21
   3d290:	bl	c1a0 <__gmpn_sqr_basecase@plt>
   3d294:	cmp	x22, #0x11
   3d298:	b.le	3d2b8 <__gmpn_toom2_sqr@@Base+0x19c>
   3d29c:	add	x3, x27, x25, lsl #3
   3d2a0:	mov	x0, x20
   3d2a4:	mov	x1, x24
   3d2a8:	mov	x2, x22
   3d2ac:	mov	x19, x27
   3d2b0:	bl	c060 <__gmpn_toom2_sqr@plt>
   3d2b4:	b	3d2cc <__gmpn_toom2_sqr@@Base+0x1b0>
   3d2b8:	mov	x0, x20
   3d2bc:	mov	x1, x24
   3d2c0:	mov	x2, x22
   3d2c4:	mov	x19, x27
   3d2c8:	bl	c1a0 <__gmpn_sqr_basecase@plt>
   3d2cc:	add	x27, x20, x22, lsl #3
   3d2d0:	mov	x0, x26
   3d2d4:	mov	x1, x27
   3d2d8:	mov	x2, x26
   3d2dc:	mov	x3, x22
   3d2e0:	bl	ca90 <__gmpn_add_n@plt>
   3d2e4:	mov	x24, x0
   3d2e8:	mov	x0, x27
   3d2ec:	mov	x1, x26
   3d2f0:	mov	x2, x20
   3d2f4:	mov	x3, x22
   3d2f8:	bl	ca90 <__gmpn_add_n@plt>
   3d2fc:	and	x8, x28, #0xfffffffffffffffe
   3d300:	str	x28, [sp, #8]
   3d304:	subs	x23, x8, x22
   3d308:	mov	x28, x0
   3d30c:	b.eq	3d34c <__gmpn_toom2_sqr@@Base+0x230>  // b.none
   3d310:	add	x2, x26, x22, lsl #3
   3d314:	mov	x0, x26
   3d318:	mov	x1, x26
   3d31c:	mov	x3, x23
   3d320:	bl	ca90 <__gmpn_add_n@plt>
   3d324:	cbz	x0, 3d34c <__gmpn_toom2_sqr@@Base+0x230>
   3d328:	mov	w8, #0x1                   	// #1
   3d32c:	cmp	x23, x22
   3d330:	b.ge	3d350 <__gmpn_toom2_sqr@@Base+0x234>  // b.tcont
   3d334:	ldr	x9, [x26, x23, lsl #3]
   3d338:	add	x10, x23, #0x1
   3d33c:	adds	x9, x9, #0x1
   3d340:	str	x9, [x26, x23, lsl #3]
   3d344:	mov	x23, x10
   3d348:	b.cs	3d32c <__gmpn_toom2_sqr@@Base+0x210>  // b.hs, b.nlast
   3d34c:	mov	x8, xzr
   3d350:	mov	x0, x27
   3d354:	mov	x1, x27
   3d358:	mov	x2, x19
   3d35c:	mov	x3, x25
   3d360:	add	x23, x8, x24
   3d364:	bl	c2e0 <__gmpn_sub_n@plt>
   3d368:	sub	x8, x23, x0
   3d36c:	cmp	x8, #0x3
   3d370:	b.cs	3d400 <__gmpn_toom2_sqr@@Base+0x2e4>  // b.hs, b.nlast
   3d374:	ldr	x9, [x26]
   3d378:	add	x10, x28, x24
   3d37c:	adds	x9, x9, x10
   3d380:	str	x9, [x26]
   3d384:	b.cc	3d3a0 <__gmpn_toom2_sqr@@Base+0x284>  // b.lo, b.ul, b.last
   3d388:	add	x9, x20, x25, lsl #3
   3d38c:	add	x9, x9, #0x8
   3d390:	ldr	x10, [x9]
   3d394:	adds	x10, x10, #0x1
   3d398:	str	x10, [x9], #8
   3d39c:	b.cs	3d390 <__gmpn_toom2_sqr@@Base+0x274>  // b.hs, b.nlast
   3d3a0:	mov	w9, #0x18                  	// #24
   3d3a4:	mul	x9, x22, x9
   3d3a8:	ldr	x10, [x20, x9]
   3d3ac:	adds	x8, x10, x8
   3d3b0:	str	x8, [x20, x9]
   3d3b4:	ldr	x8, [sp, #8]
   3d3b8:	b.cc	3d3e0 <__gmpn_toom2_sqr@@Base+0x2c4>  // b.lo, b.ul, b.last
   3d3bc:	add	x8, x8, x8, lsl #1
   3d3c0:	add	x9, x21, x21, lsl #1
   3d3c4:	sub	x8, x8, x9
   3d3c8:	add	x8, x20, x8, lsl #3
   3d3cc:	add	x8, x8, #0x8
   3d3d0:	ldr	x9, [x8]
   3d3d4:	adds	x9, x9, #0x1
   3d3d8:	str	x9, [x8], #8
   3d3dc:	b.cs	3d3d0 <__gmpn_toom2_sqr@@Base+0x2b4>  // b.hs, b.nlast
   3d3e0:	ldp	x20, x19, [sp, #96]
   3d3e4:	ldp	x22, x21, [sp, #80]
   3d3e8:	ldp	x24, x23, [sp, #64]
   3d3ec:	ldp	x26, x25, [sp, #48]
   3d3f0:	ldp	x28, x27, [sp, #32]
   3d3f4:	ldp	x29, x30, [sp, #16]
   3d3f8:	add	sp, sp, #0x70
   3d3fc:	ret
   3d400:	ldr	x8, [sp, #8]
   3d404:	mov	x0, x26
   3d408:	mov	w1, wzr
   3d40c:	sub	x8, x8, x21
   3d410:	lsl	x2, x8, #3
   3d414:	bl	c610 <memset@plt>
   3d418:	b	3d3e0 <__gmpn_toom2_sqr@@Base+0x2c4>

000000000003d41c <__gmpn_toom3_sqr@@Base>:
   3d41c:	sub	sp, sp, #0x90
   3d420:	mov	x9, #0xaaaaaaaaaaaaaaaa    	// #-6148914691236517206
   3d424:	add	x8, x2, #0x2
   3d428:	movk	x9, #0xaaab
   3d42c:	umulh	x8, x8, x9
   3d430:	stp	x22, x21, [sp, #112]
   3d434:	lsr	x21, x8, #1
   3d438:	stp	x29, x30, [sp, #48]
   3d43c:	add	x29, sp, #0x30
   3d440:	subs	x8, x2, x21, lsl #1
   3d444:	stp	x28, x27, [sp, #64]
   3d448:	stp	x26, x25, [sp, #80]
   3d44c:	stp	x24, x23, [sp, #96]
   3d450:	stp	x20, x19, [sp, #128]
   3d454:	stur	x8, [x29, #-8]
   3d458:	add	x8, x3, x21, lsl #5
   3d45c:	add	x9, x0, x21, lsl #3
   3d460:	mov	x19, x3
   3d464:	mov	x27, x2
   3d468:	mov	x22, x1
   3d46c:	add	x25, x3, x21, lsl #4
   3d470:	add	x24, x8, #0x20
   3d474:	add	x26, x9, #0x8
   3d478:	add	x2, x1, x21, lsl #4
   3d47c:	str	x0, [sp, #24]
   3d480:	stur	x2, [x29, #-16]
   3d484:	b.eq	3d4d0 <__gmpn_toom3_sqr@@Base+0xb4>  // b.none
   3d488:	ldur	x20, [x29, #-8]
   3d48c:	mov	x0, x19
   3d490:	mov	x1, x22
   3d494:	mov	x3, x20
   3d498:	bl	ca90 <__gmpn_add_n@plt>
   3d49c:	mov	x8, x20
   3d4a0:	cbz	x0, 3d4d4 <__gmpn_toom3_sqr@@Base+0xb8>
   3d4a4:	ldur	x9, [x29, #-8]
   3d4a8:	mov	w20, #0x1                   	// #1
   3d4ac:	cmp	x9, x21
   3d4b0:	b.ge	3d508 <__gmpn_toom3_sqr@@Base+0xec>  // b.tcont
   3d4b4:	ldr	x8, [x22, x9, lsl #3]
   3d4b8:	adds	x10, x8, #0x1
   3d4bc:	add	x8, x9, #0x1
   3d4c0:	str	x10, [x19, x9, lsl #3]
   3d4c4:	mov	x9, x8
   3d4c8:	b.cs	3d4ac <__gmpn_toom3_sqr@@Base+0x90>  // b.hs, b.nlast
   3d4cc:	b	3d4d4 <__gmpn_toom3_sqr@@Base+0xb8>
   3d4d0:	mov	x8, xzr
   3d4d4:	cmp	x19, x22
   3d4d8:	mov	x20, xzr
   3d4dc:	b.eq	3d508 <__gmpn_toom3_sqr@@Base+0xec>  // b.none
   3d4e0:	cmp	x8, x21
   3d4e4:	b.ge	3d508 <__gmpn_toom3_sqr@@Base+0xec>  // b.tcont
   3d4e8:	sub	x9, x21, x8
   3d4ec:	add	x10, x19, x8, lsl #3
   3d4f0:	add	x8, x22, x8, lsl #3
   3d4f4:	ldr	x11, [x8], #8
   3d4f8:	subs	x9, x9, #0x1
   3d4fc:	str	x11, [x10], #8
   3d500:	b.ne	3d4f4 <__gmpn_toom3_sqr@@Base+0xd8>  // b.any
   3d504:	mov	x20, xzr
   3d508:	str	x26, [sp, #16]
   3d50c:	mov	x26, x25
   3d510:	add	x23, x25, #0x10
   3d514:	add	x25, x22, x21, lsl #3
   3d518:	mov	x0, x24
   3d51c:	mov	x1, x19
   3d520:	mov	x2, x25
   3d524:	mov	x3, x21
   3d528:	bl	ca90 <__gmpn_add_n@plt>
   3d52c:	add	x8, x0, x20
   3d530:	mov	x28, x24
   3d534:	str	x8, [x24, x21, lsl #3]
   3d538:	cbz	x20, 3d628 <__gmpn_toom3_sqr@@Base+0x20c>
   3d53c:	mov	x0, x23
   3d540:	mov	x1, x19
   3d544:	mov	x2, x25
   3d548:	mov	x3, x21
   3d54c:	bl	c2e0 <__gmpn_sub_n@plt>
   3d550:	sub	x8, x20, x0
   3d554:	lsl	x9, x21, #1
   3d558:	ldur	x1, [x29, #-16]
   3d55c:	mov	x24, x26
   3d560:	ldr	x26, [sp, #16]
   3d564:	str	x9, [sp, #16]
   3d568:	mov	x25, x28
   3d56c:	mov	x28, x23
   3d570:	str	x8, [x23, x21, lsl #3]
   3d574:	ldur	x23, [x29, #-8]
   3d578:	mov	x0, x26
   3d57c:	mov	x2, x25
   3d580:	lsl	x20, x21, #2
   3d584:	mov	x3, x23
   3d588:	bl	ca90 <__gmpn_add_n@plt>
   3d58c:	subs	x9, x21, x23
   3d590:	b.eq	3d6c4 <__gmpn_toom3_sqr@@Base+0x2a8>  // b.none
   3d594:	ldur	x10, [x29, #-8]
   3d598:	ldr	x8, [x25, x10, lsl #3]
   3d59c:	adds	x8, x8, x0
   3d5a0:	str	x8, [x26, x10, lsl #3]
   3d5a4:	b.cc	3d674 <__gmpn_toom3_sqr@@Base+0x258>  // b.lo, b.ul, b.last
   3d5a8:	add	x8, x19, x21, lsl #4
   3d5ac:	mov	w10, #0x2                   	// #2
   3d5b0:	add	x11, x8, #0x28
   3d5b4:	sub	x8, x10, x21
   3d5b8:	ldr	x10, [sp, #24]
   3d5bc:	mov	w0, #0x1                   	// #1
   3d5c0:	add	x10, x10, x8, lsl #3
   3d5c4:	mov	w8, #0x1                   	// #1
   3d5c8:	cmp	x8, x9
   3d5cc:	b.ge	3d6c4 <__gmpn_toom3_sqr@@Base+0x2a8>  // b.tcont
   3d5d0:	ldr	x12, [x11, x27, lsl #3]
   3d5d4:	add	x8, x8, #0x1
   3d5d8:	add	x11, x11, #0x8
   3d5dc:	adds	x12, x12, #0x1
   3d5e0:	str	x12, [x10, x27, lsl #3]
   3d5e4:	add	x10, x10, #0x8
   3d5e8:	b.cs	3d5c8 <__gmpn_toom3_sqr@@Base+0x1ac>  // b.hs, b.nlast
   3d5ec:	cmp	x25, x26
   3d5f0:	mov	x0, xzr
   3d5f4:	b.eq	3d6c4 <__gmpn_toom3_sqr@@Base+0x2a8>  // b.none
   3d5f8:	cmp	x8, x9
   3d5fc:	b.ge	3d6c4 <__gmpn_toom3_sqr@@Base+0x2a8>  // b.tcont
   3d600:	add	x9, x11, x27, lsl #3
   3d604:	add	x11, x21, x21, lsl #1
   3d608:	add	x10, x10, x27, lsl #3
   3d60c:	sub	x11, x11, x27
   3d610:	ldr	x12, [x9], #8
   3d614:	sub	x11, x11, #0x1
   3d618:	cmp	x8, x11
   3d61c:	str	x12, [x10], #8
   3d620:	b.ne	3d610 <__gmpn_toom3_sqr@@Base+0x1f4>  // b.any
   3d624:	b	3d6c0 <__gmpn_toom3_sqr@@Base+0x2a4>
   3d628:	add	x8, x22, x21, lsl #4
   3d62c:	sub	x8, x8, #0x8
   3d630:	mov	x10, x21
   3d634:	subs	x9, x10, #0x1
   3d638:	b.lt	3d53c <__gmpn_toom3_sqr@@Base+0x120>  // b.tstop
   3d63c:	add	x10, x19, x10, lsl #3
   3d640:	ldur	x10, [x10, #-8]
   3d644:	ldr	x11, [x8], #-8
   3d648:	cmp	x10, x11
   3d64c:	mov	x10, x9
   3d650:	b.eq	3d634 <__gmpn_toom3_sqr@@Base+0x218>  // b.none
   3d654:	b.hi	3d53c <__gmpn_toom3_sqr@@Base+0x120>  // b.pmore
   3d658:	mov	x0, x23
   3d65c:	mov	x1, x25
   3d660:	mov	x2, x19
   3d664:	mov	x3, x21
   3d668:	bl	c2e0 <__gmpn_sub_n@plt>
   3d66c:	mov	x8, xzr
   3d670:	b	3d554 <__gmpn_toom3_sqr@@Base+0x138>
   3d674:	cmp	x25, x26
   3d678:	mov	x0, xzr
   3d67c:	b.eq	3d6c4 <__gmpn_toom3_sqr@@Base+0x2a8>  // b.none
   3d680:	cmp	x9, #0x2
   3d684:	b.lt	3d6c4 <__gmpn_toom3_sqr@@Base+0x2a8>  // b.tstop
   3d688:	ldr	x11, [sp, #24]
   3d68c:	add	x8, x21, x21, lsl #1
   3d690:	sub	x9, x27, x21
   3d694:	add	x10, x27, x21, lsl #1
   3d698:	sub	x8, x27, x8
   3d69c:	add	x9, x11, x9, lsl #3
   3d6a0:	add	x10, x19, x10, lsl #3
   3d6a4:	add	x8, x8, #0x1
   3d6a8:	add	x9, x9, #0x10
   3d6ac:	add	x10, x10, #0x28
   3d6b0:	ldr	x11, [x10], #8
   3d6b4:	adds	x8, x8, #0x1
   3d6b8:	str	x11, [x9], #8
   3d6bc:	b.cc	3d6b0 <__gmpn_toom3_sqr@@Base+0x294>  // b.lo, b.ul, b.last
   3d6c0:	mov	x0, xzr
   3d6c4:	ldr	x8, [x25, x21, lsl #3]
   3d6c8:	str	x25, [sp, #8]
   3d6cc:	mov	x1, x22
   3d6d0:	mov	x2, x26
   3d6d4:	add	x25, x8, x0
   3d6d8:	mov	x0, x26
   3d6dc:	mov	x3, x21
   3d6e0:	bl	d0b0 <__gmpn_rsblsh1_n@plt>
   3d6e4:	add	x8, x0, x25, lsl #1
   3d6e8:	mov	w9, #0x28                  	// #40
   3d6ec:	str	x8, [x26, x21, lsl #3]
   3d6f0:	madd	x8, x21, x9, x19
   3d6f4:	add	x25, x21, #0x1
   3d6f8:	add	x27, x8, #0x28
   3d6fc:	mov	x0, x19
   3d700:	mov	x1, x28
   3d704:	mov	x2, x25
   3d708:	mov	x3, x27
   3d70c:	bl	c060 <__gmpn_toom2_sqr@plt>
   3d710:	add	x28, x24, #0x8
   3d714:	mov	x0, x28
   3d718:	mov	x1, x26
   3d71c:	mov	x2, x25
   3d720:	mov	x3, x27
   3d724:	bl	c060 <__gmpn_toom2_sqr@plt>
   3d728:	ldr	x24, [sp, #24]
   3d72c:	mov	x3, x27
   3d730:	add	x26, x24, x20, lsl #3
   3d734:	ldp	x1, x20, [x29, #-16]
   3d738:	mov	x0, x26
   3d73c:	mov	x2, x20
   3d740:	bl	c060 <__gmpn_toom2_sqr@plt>
   3d744:	ldp	x8, x23, [x26]
   3d748:	mov	x2, x25
   3d74c:	mov	x3, x27
   3d750:	stur	x8, [x29, #-16]
   3d754:	ldp	x1, x8, [sp, #8]
   3d758:	add	x0, x24, x8, lsl #3
   3d75c:	bl	c060 <__gmpn_toom2_sqr@plt>
   3d760:	mov	x0, x24
   3d764:	mov	x1, x22
   3d768:	mov	x2, x21
   3d76c:	mov	x3, x27
   3d770:	str	x23, [x26, #8]
   3d774:	bl	c060 <__gmpn_toom2_sqr@plt>
   3d778:	lsl	x4, x20, #1
   3d77c:	mov	x0, x24
   3d780:	mov	x1, x28
   3d784:	mov	x2, x19
   3d788:	mov	x3, x21
   3d78c:	ldur	x6, [x29, #-16]
   3d790:	ldp	x20, x19, [sp, #128]
   3d794:	ldp	x22, x21, [sp, #112]
   3d798:	ldp	x24, x23, [sp, #96]
   3d79c:	ldp	x26, x25, [sp, #80]
   3d7a0:	ldp	x28, x27, [sp, #64]
   3d7a4:	ldp	x29, x30, [sp, #48]
   3d7a8:	mov	w5, wzr
   3d7ac:	add	sp, sp, #0x90
   3d7b0:	b	ca40 <__gmpn_toom_interpolate_5pts@plt>

000000000003d7b4 <__gmpn_toom4_sqr@@Base>:
   3d7b4:	sub	sp, sp, #0xa0
   3d7b8:	add	x8, x2, #0x3
   3d7bc:	stp	x22, x21, [sp, #128]
   3d7c0:	asr	x21, x8, #2
   3d7c4:	stp	x28, x27, [sp, #80]
   3d7c8:	and	x9, x8, #0xfffffffffffffffc
   3d7cc:	lsl	x28, x21, #1
   3d7d0:	str	x9, [sp, #16]
   3d7d4:	add	x9, x0, x9, lsl #3
   3d7d8:	add	x10, x3, x21, lsl #6
   3d7dc:	add	x8, x28, x8, asr #2
   3d7e0:	stp	x26, x25, [sp, #96]
   3d7e4:	stp	x24, x23, [sp, #112]
   3d7e8:	mov	x24, x1
   3d7ec:	add	x25, x9, #0x10
   3d7f0:	sub	x23, x2, x8
   3d7f4:	add	x22, x10, #0x28
   3d7f8:	stp	x29, x30, [sp, #64]
   3d7fc:	stp	x20, x19, [sp, #144]
   3d800:	add	x29, sp, #0x40
   3d804:	mov	x19, x3
   3d808:	mov	x26, x2
   3d80c:	mov	x1, x25
   3d810:	mov	x2, x24
   3d814:	mov	x3, x21
   3d818:	mov	x4, x23
   3d81c:	mov	x5, x22
   3d820:	mov	x20, x0
   3d824:	stur	x8, [x29, #-8]
   3d828:	bl	cd80 <__gmpn_toom_eval_dgr3_pm2@plt>
   3d82c:	add	x27, x21, #0x1
   3d830:	cmp	x26, #0x104
   3d834:	mov	x0, x19
   3d838:	mov	x1, x20
   3d83c:	mov	x2, x27
   3d840:	mov	x3, x22
   3d844:	str	x26, [sp, #32]
   3d848:	stp	x25, x19, [x29, #-24]
   3d84c:	b.le	3d874 <__gmpn_toom4_sqr@@Base+0xc0>
   3d850:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3d854:	add	x8, x19, x21, lsl #4
   3d858:	add	x0, x8, #0x8
   3d85c:	mov	x1, x25
   3d860:	mov	x2, x27
   3d864:	mov	x3, x22
   3d868:	str	x0, [sp, #8]
   3d86c:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3d870:	b	3d894 <__gmpn_toom4_sqr@@Base+0xe0>
   3d874:	bl	c060 <__gmpn_toom2_sqr@plt>
   3d878:	add	x8, x19, x21, lsl #4
   3d87c:	add	x0, x8, #0x8
   3d880:	mov	x1, x25
   3d884:	mov	x2, x27
   3d888:	mov	x3, x22
   3d88c:	str	x0, [sp, #8]
   3d890:	bl	c060 <__gmpn_toom2_sqr@plt>
   3d894:	add	x1, x24, x21, lsl #3
   3d898:	mov	x0, x20
   3d89c:	mov	x2, x24
   3d8a0:	mov	x3, x21
   3d8a4:	bl	cc60 <__gmpn_addlsh1_n@plt>
   3d8a8:	mov	x26, x0
   3d8ac:	add	x1, x24, x28, lsl #3
   3d8b0:	mov	x0, x20
   3d8b4:	mov	x2, x20
   3d8b8:	mov	x3, x21
   3d8bc:	str	x28, [sp, #24]
   3d8c0:	bl	cc60 <__gmpn_addlsh1_n@plt>
   3d8c4:	subs	x25, x21, x23
   3d8c8:	add	x28, x0, x26, lsl #1
   3d8cc:	b.le	3d940 <__gmpn_toom4_sqr@@Base+0x18c>
   3d8d0:	ldur	x8, [x29, #-8]
   3d8d4:	mov	x0, x20
   3d8d8:	mov	x2, x20
   3d8dc:	mov	x3, x23
   3d8e0:	add	x1, x24, x8, lsl #3
   3d8e4:	bl	cc60 <__gmpn_addlsh1_n@plt>
   3d8e8:	add	x26, x20, x23, lsl #3
   3d8ec:	mov	x19, x0
   3d8f0:	mov	w3, #0x1                   	// #1
   3d8f4:	mov	x0, x26
   3d8f8:	mov	x1, x26
   3d8fc:	mov	x2, x25
   3d900:	bl	c190 <__gmpn_lshift@plt>
   3d904:	add	x8, x0, x28, lsl #1
   3d908:	str	x8, [x20, x21, lsl #3]
   3d90c:	ldr	x8, [x26]
   3d910:	ldur	x10, [x29, #-16]
   3d914:	ldr	x11, [sp, #16]
   3d918:	adds	x8, x8, x19
   3d91c:	str	x8, [x26]
   3d920:	ldp	x25, x19, [sp, #24]
   3d924:	b.cc	3d96c <__gmpn_toom4_sqr@@Base+0x1b8>  // b.lo, b.ul, b.last
   3d928:	add	x8, x26, #0x8
   3d92c:	ldr	x9, [x8]
   3d930:	adds	x9, x9, #0x1
   3d934:	str	x9, [x8], #8
   3d938:	b.cs	3d92c <__gmpn_toom4_sqr@@Base+0x178>  // b.hs, b.nlast
   3d93c:	b	3d96c <__gmpn_toom4_sqr@@Base+0x1b8>
   3d940:	ldur	x8, [x29, #-8]
   3d944:	mov	x0, x20
   3d948:	mov	x2, x20
   3d94c:	mov	x3, x21
   3d950:	add	x1, x24, x8, lsl #3
   3d954:	bl	cc60 <__gmpn_addlsh1_n@plt>
   3d958:	add	x8, x0, x28, lsl #1
   3d95c:	str	x8, [x20, x21, lsl #3]
   3d960:	ldur	x10, [x29, #-16]
   3d964:	ldp	x25, x19, [sp, #24]
   3d968:	ldr	x11, [sp, #16]
   3d96c:	add	x8, x10, x11, lsl #3
   3d970:	add	x28, x8, #0x10
   3d974:	cmp	x19, #0x104
   3d978:	mov	x0, x28
   3d97c:	mov	x1, x20
   3d980:	mov	x2, x27
   3d984:	mov	x3, x22
   3d988:	b.le	3da18 <__gmpn_toom4_sqr@@Base+0x264>
   3d98c:	str	x28, [sp, #24]
   3d990:	mov	x28, x10
   3d994:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3d998:	ldur	x26, [x29, #-24]
   3d99c:	mov	x0, x20
   3d9a0:	mov	x2, x24
   3d9a4:	mov	x3, x21
   3d9a8:	mov	x1, x26
   3d9ac:	mov	x4, x23
   3d9b0:	mov	x5, x22
   3d9b4:	bl	c290 <__gmpn_toom_eval_dgr3_pm1@plt>
   3d9b8:	add	x0, x20, x25, lsl #3
   3d9bc:	mov	x1, x20
   3d9c0:	mov	x2, x27
   3d9c4:	mov	x3, x22
   3d9c8:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3d9cc:	add	x8, x21, x21, lsl #1
   3d9d0:	lsl	x9, x8, #1
   3d9d4:	add	x8, x28, x8, lsl #4
   3d9d8:	ldr	x28, [sp, #24]
   3d9dc:	add	x25, x8, #0x18
   3d9e0:	mov	x0, x25
   3d9e4:	mov	x1, x26
   3d9e8:	mov	x2, x27
   3d9ec:	mov	x3, x22
   3d9f0:	str	x9, [sp, #32]
   3d9f4:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3d9f8:	cmp	x19, #0x108
   3d9fc:	b.le	3da7c <__gmpn_toom4_sqr@@Base+0x2c8>
   3da00:	mov	x0, x20
   3da04:	mov	x1, x24
   3da08:	mov	x2, x21
   3da0c:	mov	x3, x22
   3da10:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3da14:	b	3da90 <__gmpn_toom4_sqr@@Base+0x2dc>
   3da18:	mov	x19, x10
   3da1c:	bl	c060 <__gmpn_toom2_sqr@plt>
   3da20:	ldur	x26, [x29, #-24]
   3da24:	mov	x0, x20
   3da28:	mov	x2, x24
   3da2c:	mov	x3, x21
   3da30:	mov	x1, x26
   3da34:	mov	x4, x23
   3da38:	mov	x5, x22
   3da3c:	bl	c290 <__gmpn_toom_eval_dgr3_pm1@plt>
   3da40:	add	x0, x20, x25, lsl #3
   3da44:	mov	x1, x20
   3da48:	mov	x2, x27
   3da4c:	mov	x3, x22
   3da50:	bl	c060 <__gmpn_toom2_sqr@plt>
   3da54:	add	x8, x21, x21, lsl #1
   3da58:	lsl	x9, x8, #1
   3da5c:	add	x8, x19, x8, lsl #4
   3da60:	add	x25, x8, #0x18
   3da64:	mov	x0, x25
   3da68:	mov	x1, x26
   3da6c:	mov	x2, x27
   3da70:	mov	x3, x22
   3da74:	str	x9, [sp, #32]
   3da78:	bl	c060 <__gmpn_toom2_sqr@plt>
   3da7c:	mov	x0, x20
   3da80:	mov	x1, x24
   3da84:	mov	x2, x21
   3da88:	mov	x3, x22
   3da8c:	bl	c060 <__gmpn_toom2_sqr@plt>
   3da90:	ldr	x8, [sp, #32]
   3da94:	cmp	x23, #0x42
   3da98:	mov	x2, x23
   3da9c:	mov	x3, x22
   3daa0:	add	x0, x20, x8, lsl #3
   3daa4:	ldur	x8, [x29, #-8]
   3daa8:	add	x1, x24, x8, lsl #3
   3daac:	b.le	3dab8 <__gmpn_toom4_sqr@@Base+0x304>
   3dab0:	bl	d2c0 <__gmpn_toom3_sqr@plt>
   3dab4:	b	3dabc <__gmpn_toom4_sqr@@Base+0x308>
   3dab8:	bl	c060 <__gmpn_toom2_sqr@plt>
   3dabc:	ldr	x3, [sp, #8]
   3dac0:	ldur	x5, [x29, #-16]
   3dac4:	lsl	x7, x23, #1
   3dac8:	mov	x0, x20
   3dacc:	mov	x1, x21
   3dad0:	mov	w2, wzr
   3dad4:	mov	x4, x25
   3dad8:	mov	x6, x28
   3dadc:	str	x22, [sp]
   3dae0:	bl	c830 <__gmpn_toom_interpolate_7pts@plt>
   3dae4:	ldp	x20, x19, [sp, #144]
   3dae8:	ldp	x22, x21, [sp, #128]
   3daec:	ldp	x24, x23, [sp, #112]
   3daf0:	ldp	x26, x25, [sp, #96]
   3daf4:	ldp	x28, x27, [sp, #80]
   3daf8:	ldp	x29, x30, [sp, #64]
   3dafc:	add	sp, sp, #0xa0
   3db00:	ret

000000000003db04 <__gmpn_toom_eval_dgr3_pm1@@Base>:
   3db04:	stp	x29, x30, [sp, #-80]!
   3db08:	stp	x24, x23, [sp, #32]
   3db0c:	mov	x23, x2
   3db10:	stp	x22, x21, [sp, #48]
   3db14:	mov	x21, x1
   3db18:	add	x2, x2, x3, lsl #4
   3db1c:	mov	x1, x23
   3db20:	str	x25, [sp, #16]
   3db24:	stp	x20, x19, [sp, #64]
   3db28:	mov	x29, sp
   3db2c:	mov	x19, x5
   3db30:	mov	x24, x4
   3db34:	mov	x22, x3
   3db38:	mov	x20, x0
   3db3c:	bl	ca90 <__gmpn_add_n@plt>
   3db40:	add	x25, x23, x22, lsl #3
   3db44:	str	x0, [x20, x22, lsl #3]
   3db48:	cbz	x24, 3db90 <__gmpn_toom_eval_dgr3_pm1@@Base+0x8c>
   3db4c:	mov	w8, #0x18                  	// #24
   3db50:	madd	x2, x22, x8, x23
   3db54:	mov	x0, x19
   3db58:	mov	x1, x25
   3db5c:	mov	x3, x24
   3db60:	bl	ca90 <__gmpn_add_n@plt>
   3db64:	cbz	x0, 3db98 <__gmpn_toom_eval_dgr3_pm1@@Base+0x94>
   3db68:	mov	w8, #0x1                   	// #1
   3db6c:	cmp	x24, x22
   3db70:	b.ge	3dbd0 <__gmpn_toom_eval_dgr3_pm1@@Base+0xcc>  // b.tcont
   3db74:	ldr	x9, [x25, x24, lsl #3]
   3db78:	adds	x10, x9, #0x1
   3db7c:	add	x9, x24, #0x1
   3db80:	str	x10, [x19, x24, lsl #3]
   3db84:	mov	x24, x9
   3db88:	b.cs	3db6c <__gmpn_toom_eval_dgr3_pm1@@Base+0x68>  // b.hs, b.nlast
   3db8c:	b	3db9c <__gmpn_toom_eval_dgr3_pm1@@Base+0x98>
   3db90:	mov	x9, xzr
   3db94:	b	3db9c <__gmpn_toom_eval_dgr3_pm1@@Base+0x98>
   3db98:	mov	x9, x24
   3db9c:	cmp	x25, x19
   3dba0:	mov	x8, xzr
   3dba4:	b.eq	3dbd0 <__gmpn_toom_eval_dgr3_pm1@@Base+0xcc>  // b.none
   3dba8:	cmp	x9, x22
   3dbac:	b.ge	3dbd0 <__gmpn_toom_eval_dgr3_pm1@@Base+0xcc>  // b.tcont
   3dbb0:	sub	x8, x22, x9
   3dbb4:	add	x10, x19, x9, lsl #3
   3dbb8:	add	x9, x9, x22
   3dbbc:	add	x9, x23, x9, lsl #3
   3dbc0:	ldr	x11, [x9], #8
   3dbc4:	subs	x8, x8, #0x1
   3dbc8:	str	x11, [x10], #8
   3dbcc:	b.ne	3dbc0 <__gmpn_toom_eval_dgr3_pm1@@Base+0xbc>  // b.any
   3dbd0:	add	x23, x22, #0x1
   3dbd4:	str	x8, [x19, x22, lsl #3]
   3dbd8:	add	x8, x22, #0x1
   3dbdc:	cmp	x8, #0x1
   3dbe0:	b.lt	3dbfc <__gmpn_toom_eval_dgr3_pm1@@Base+0xf8>  // b.tstop
   3dbe4:	ldr	x8, [x20, x22, lsl #3]
   3dbe8:	ldr	x9, [x19, x22, lsl #3]
   3dbec:	sub	x22, x22, #0x1
   3dbf0:	cmp	x8, x9
   3dbf4:	b.eq	3dbd8 <__gmpn_toom_eval_dgr3_pm1@@Base+0xd4>  // b.none
   3dbf8:	b.ls	3dc18 <__gmpn_toom_eval_dgr3_pm1@@Base+0x114>  // b.plast
   3dbfc:	mov	x0, x21
   3dc00:	mov	x1, x20
   3dc04:	mov	x2, x19
   3dc08:	mov	x3, x23
   3dc0c:	bl	c2e0 <__gmpn_sub_n@plt>
   3dc10:	mov	w21, wzr
   3dc14:	b	3dc30 <__gmpn_toom_eval_dgr3_pm1@@Base+0x12c>
   3dc18:	mov	x0, x21
   3dc1c:	mov	x1, x19
   3dc20:	mov	x2, x20
   3dc24:	mov	x3, x23
   3dc28:	bl	c2e0 <__gmpn_sub_n@plt>
   3dc2c:	mov	w21, #0xffffffff            	// #-1
   3dc30:	mov	x0, x20
   3dc34:	mov	x1, x20
   3dc38:	mov	x2, x19
   3dc3c:	mov	x3, x23
   3dc40:	bl	ca90 <__gmpn_add_n@plt>
   3dc44:	mov	w0, w21
   3dc48:	ldp	x20, x19, [sp, #64]
   3dc4c:	ldp	x22, x21, [sp, #48]
   3dc50:	ldp	x24, x23, [sp, #32]
   3dc54:	ldr	x25, [sp, #16]
   3dc58:	ldp	x29, x30, [sp], #80
   3dc5c:	ret

000000000003dc60 <__gmpn_toom_eval_dgr3_pm2@@Base>:
   3dc60:	stp	x29, x30, [sp, #-80]!
   3dc64:	stp	x24, x23, [sp, #32]
   3dc68:	mov	x24, x2
   3dc6c:	stp	x22, x21, [sp, #48]
   3dc70:	mov	x21, x1
   3dc74:	add	x2, x2, x3, lsl #4
   3dc78:	mov	x1, x24
   3dc7c:	str	x25, [sp, #16]
   3dc80:	stp	x20, x19, [sp, #64]
   3dc84:	mov	x29, sp
   3dc88:	mov	x19, x5
   3dc8c:	mov	x23, x4
   3dc90:	mov	x22, x3
   3dc94:	mov	x20, x0
   3dc98:	bl	cbc0 <__gmpn_addlsh2_n@plt>
   3dc9c:	add	x25, x24, x22, lsl #3
   3dca0:	mov	w8, #0x18                  	// #24
   3dca4:	str	x0, [x20, x22, lsl #3]
   3dca8:	madd	x2, x22, x8, x24
   3dcac:	mov	x0, x19
   3dcb0:	mov	x1, x25
   3dcb4:	mov	x3, x23
   3dcb8:	bl	cbc0 <__gmpn_addlsh2_n@plt>
   3dcbc:	subs	x8, x22, x23
   3dcc0:	b.le	3dda0 <__gmpn_toom_eval_dgr3_pm2@@Base+0x140>
   3dcc4:	ldr	x9, [x25, x23, lsl #3]
   3dcc8:	adds	x9, x9, x0
   3dccc:	str	x9, [x19, x23, lsl #3]
   3dcd0:	b.cc	3dd5c <__gmpn_toom_eval_dgr3_pm2@@Base+0xfc>  // b.lo, b.ul, b.last
   3dcd4:	add	x9, x23, x22
   3dcd8:	add	x11, x19, x23, lsl #3
   3dcdc:	add	x9, x24, x9, lsl #3
   3dce0:	mov	x10, xzr
   3dce4:	mov	w0, #0x1                   	// #1
   3dce8:	add	x11, x11, #0x8
   3dcec:	add	x12, x9, #0x8
   3dcf0:	mov	w9, #0x1                   	// #1
   3dcf4:	cmp	x9, x8
   3dcf8:	b.ge	3dda0 <__gmpn_toom_eval_dgr3_pm2@@Base+0x140>  // b.tcont
   3dcfc:	ldr	x13, [x12, x10]
   3dd00:	add	x9, x9, #0x1
   3dd04:	adds	x13, x13, #0x1
   3dd08:	str	x13, [x11, x10]
   3dd0c:	add	x10, x10, #0x8
   3dd10:	b.cs	3dcf4 <__gmpn_toom_eval_dgr3_pm2@@Base+0x94>  // b.hs, b.nlast
   3dd14:	cmp	x25, x19
   3dd18:	mov	x0, xzr
   3dd1c:	b.eq	3dda0 <__gmpn_toom_eval_dgr3_pm2@@Base+0x140>  // b.none
   3dd20:	cmp	x9, x8
   3dd24:	b.ge	3dda0 <__gmpn_toom_eval_dgr3_pm2@@Base+0x140>  // b.tcont
   3dd28:	add	x11, x23, x22
   3dd2c:	add	x12, x19, x23, lsl #3
   3dd30:	add	x11, x24, x11, lsl #3
   3dd34:	add	x12, x12, x10
   3dd38:	add	x10, x11, x10
   3dd3c:	add	x10, x10, #0x8
   3dd40:	add	x11, x12, #0x8
   3dd44:	ldr	x12, [x10], #8
   3dd48:	sub	x8, x8, #0x1
   3dd4c:	cmp	x9, x8
   3dd50:	str	x12, [x11], #8
   3dd54:	b.ne	3dd44 <__gmpn_toom_eval_dgr3_pm2@@Base+0xe4>  // b.any
   3dd58:	b	3dd9c <__gmpn_toom_eval_dgr3_pm2@@Base+0x13c>
   3dd5c:	cmp	x25, x19
   3dd60:	mov	x0, xzr
   3dd64:	b.eq	3dda0 <__gmpn_toom_eval_dgr3_pm2@@Base+0x140>  // b.none
   3dd68:	cmp	x8, #0x2
   3dd6c:	b.lt	3dda0 <__gmpn_toom_eval_dgr3_pm2@@Base+0x140>  // b.tstop
   3dd70:	add	x10, x23, x22
   3dd74:	mvn	x8, x23
   3dd78:	add	x9, x19, x23, lsl #3
   3dd7c:	add	x10, x24, x10, lsl #3
   3dd80:	add	x8, x8, x22
   3dd84:	add	x9, x9, #0x8
   3dd88:	add	x10, x10, #0x8
   3dd8c:	ldr	x11, [x10], #8
   3dd90:	subs	x8, x8, #0x1
   3dd94:	str	x11, [x9], #8
   3dd98:	b.ne	3dd8c <__gmpn_toom_eval_dgr3_pm2@@Base+0x12c>  // b.any
   3dd9c:	mov	x0, xzr
   3dda0:	add	x23, x22, #0x1
   3dda4:	str	x0, [x19, x22, lsl #3]
   3dda8:	mov	w3, #0x1                   	// #1
   3ddac:	mov	x0, x19
   3ddb0:	mov	x1, x19
   3ddb4:	mov	x2, x23
   3ddb8:	bl	c190 <__gmpn_lshift@plt>
   3ddbc:	add	x8, x22, #0x1
   3ddc0:	cmp	x8, #0x1
   3ddc4:	b.lt	3dde0 <__gmpn_toom_eval_dgr3_pm2@@Base+0x180>  // b.tstop
   3ddc8:	ldr	x8, [x20, x22, lsl #3]
   3ddcc:	ldr	x9, [x19, x22, lsl #3]
   3ddd0:	sub	x22, x22, #0x1
   3ddd4:	cmp	x8, x9
   3ddd8:	b.eq	3ddbc <__gmpn_toom_eval_dgr3_pm2@@Base+0x15c>  // b.none
   3dddc:	b.ls	3ddfc <__gmpn_toom_eval_dgr3_pm2@@Base+0x19c>  // b.plast
   3dde0:	mov	x0, x21
   3dde4:	mov	x1, x20
   3dde8:	mov	x2, x19
   3ddec:	mov	x3, x23
   3ddf0:	bl	c2e0 <__gmpn_sub_n@plt>
   3ddf4:	mov	w21, wzr
   3ddf8:	b	3de14 <__gmpn_toom_eval_dgr3_pm2@@Base+0x1b4>
   3ddfc:	mov	x0, x21
   3de00:	mov	x1, x19
   3de04:	mov	x2, x20
   3de08:	mov	x3, x23
   3de0c:	bl	c2e0 <__gmpn_sub_n@plt>
   3de10:	mov	w21, #0xffffffff            	// #-1
   3de14:	mov	x0, x20
   3de18:	mov	x1, x20
   3de1c:	mov	x2, x19
   3de20:	mov	x3, x23
   3de24:	bl	ca90 <__gmpn_add_n@plt>
   3de28:	mov	w0, w21
   3de2c:	ldp	x20, x19, [sp, #64]
   3de30:	ldp	x22, x21, [sp, #48]
   3de34:	ldp	x24, x23, [sp, #32]
   3de38:	ldr	x25, [sp, #16]
   3de3c:	ldp	x29, x30, [sp], #80
   3de40:	ret

000000000003de44 <__gmpn_toom_eval_pm1@@Base>:
   3de44:	stp	x29, x30, [sp, #-80]!
   3de48:	stp	x26, x25, [sp, #16]
   3de4c:	stp	x24, x23, [sp, #32]
   3de50:	stp	x22, x21, [sp, #48]
   3de54:	mov	x25, x3
   3de58:	mov	w24, w2
   3de5c:	mov	x21, x1
   3de60:	add	x2, x3, x4, lsl #4
   3de64:	mov	x1, x3
   3de68:	mov	x3, x4
   3de6c:	stp	x20, x19, [sp, #64]
   3de70:	mov	x29, sp
   3de74:	mov	x19, x6
   3de78:	mov	x23, x5
   3de7c:	mov	x22, x4
   3de80:	mov	x20, x0
   3de84:	bl	ca90 <__gmpn_add_n@plt>
   3de88:	cmp	w24, #0x5
   3de8c:	str	x0, [x20, x22, lsl #3]
   3de90:	b.cc	3deec <__gmpn_toom_eval_pm1@@Base+0xa8>  // b.lo, b.ul, b.last
   3de94:	mov	w26, #0x4                   	// #4
   3de98:	cbz	x22, 3dee0 <__gmpn_toom_eval_pm1@@Base+0x9c>
   3de9c:	mov	w8, w26
   3dea0:	mul	x8, x8, x22
   3dea4:	add	x2, x25, x8, lsl #3
   3dea8:	mov	x0, x20
   3deac:	mov	x1, x20
   3deb0:	mov	x3, x22
   3deb4:	bl	ca90 <__gmpn_add_n@plt>
   3deb8:	cbz	x0, 3dee0 <__gmpn_toom_eval_pm1@@Base+0x9c>
   3debc:	mov	x8, x22
   3dec0:	cmp	x8, x22
   3dec4:	b.gt	3dee0 <__gmpn_toom_eval_pm1@@Base+0x9c>
   3dec8:	ldr	x9, [x20, x8, lsl #3]
   3decc:	add	x10, x8, #0x1
   3ded0:	adds	x9, x9, #0x1
   3ded4:	str	x9, [x20, x8, lsl #3]
   3ded8:	mov	x8, x10
   3dedc:	b.cs	3dec0 <__gmpn_toom_eval_pm1@@Base+0x7c>  // b.hs, b.nlast
   3dee0:	add	w26, w26, #0x2
   3dee4:	cmp	w26, w24
   3dee8:	b.cc	3de98 <__gmpn_toom_eval_pm1@@Base+0x54>  // b.lo, b.ul, b.last
   3deec:	mov	w8, #0x18                  	// #24
   3def0:	add	x1, x25, x22, lsl #3
   3def4:	madd	x2, x22, x8, x25
   3def8:	mov	x0, x19
   3defc:	mov	x3, x22
   3df00:	bl	ca90 <__gmpn_add_n@plt>
   3df04:	cmp	w24, #0x6
   3df08:	str	x0, [x19, x22, lsl #3]
   3df0c:	b.cc	3df68 <__gmpn_toom_eval_pm1@@Base+0x124>  // b.lo, b.ul, b.last
   3df10:	mov	w26, #0x5                   	// #5
   3df14:	cbz	x22, 3df5c <__gmpn_toom_eval_pm1@@Base+0x118>
   3df18:	mov	w8, w26
   3df1c:	mul	x8, x8, x22
   3df20:	add	x2, x25, x8, lsl #3
   3df24:	mov	x0, x19
   3df28:	mov	x1, x19
   3df2c:	mov	x3, x22
   3df30:	bl	ca90 <__gmpn_add_n@plt>
   3df34:	cbz	x0, 3df5c <__gmpn_toom_eval_pm1@@Base+0x118>
   3df38:	mov	x8, x22
   3df3c:	cmp	x8, x22
   3df40:	b.gt	3df5c <__gmpn_toom_eval_pm1@@Base+0x118>
   3df44:	ldr	x9, [x19, x8, lsl #3]
   3df48:	add	x10, x8, #0x1
   3df4c:	adds	x9, x9, #0x1
   3df50:	str	x9, [x19, x8, lsl #3]
   3df54:	mov	x8, x10
   3df58:	b.cs	3df3c <__gmpn_toom_eval_pm1@@Base+0xf8>  // b.hs, b.nlast
   3df5c:	add	w26, w26, #0x2
   3df60:	cmp	w26, w24
   3df64:	b.cc	3df14 <__gmpn_toom_eval_pm1@@Base+0xd0>  // b.lo, b.ul, b.last
   3df68:	mov	w8, w24
   3df6c:	mul	x8, x8, x22
   3df70:	add	x26, x22, #0x1
   3df74:	add	x2, x25, x8, lsl #3
   3df78:	tbnz	w24, #0, 3dfb8 <__gmpn_toom_eval_pm1@@Base+0x174>
   3df7c:	cbz	x23, 3e008 <__gmpn_toom_eval_pm1@@Base+0x1c4>
   3df80:	mov	x0, x20
   3df84:	mov	x1, x20
   3df88:	mov	x3, x23
   3df8c:	bl	ca90 <__gmpn_add_n@plt>
   3df90:	cbz	x0, 3e008 <__gmpn_toom_eval_pm1@@Base+0x1c4>
   3df94:	cmp	x23, x22
   3df98:	b.gt	3e008 <__gmpn_toom_eval_pm1@@Base+0x1c4>
   3df9c:	ldr	x8, [x20, x23, lsl #3]
   3dfa0:	add	x9, x23, #0x1
   3dfa4:	adds	x8, x8, #0x1
   3dfa8:	str	x8, [x20, x23, lsl #3]
   3dfac:	mov	x23, x9
   3dfb0:	b.cs	3df94 <__gmpn_toom_eval_pm1@@Base+0x150>  // b.hs, b.nlast
   3dfb4:	b	3e008 <__gmpn_toom_eval_pm1@@Base+0x1c4>
   3dfb8:	cbz	x23, 3e008 <__gmpn_toom_eval_pm1@@Base+0x1c4>
   3dfbc:	mov	x0, x19
   3dfc0:	mov	x1, x19
   3dfc4:	mov	x3, x23
   3dfc8:	bl	ca90 <__gmpn_add_n@plt>
   3dfcc:	cbz	x0, 3e008 <__gmpn_toom_eval_pm1@@Base+0x1c4>
   3dfd0:	cmp	x23, x22
   3dfd4:	b.gt	3e008 <__gmpn_toom_eval_pm1@@Base+0x1c4>
   3dfd8:	ldr	x8, [x19, x23, lsl #3]
   3dfdc:	add	x9, x23, #0x1
   3dfe0:	adds	x8, x8, #0x1
   3dfe4:	str	x8, [x19, x23, lsl #3]
   3dfe8:	mov	x23, x9
   3dfec:	b.cs	3dfd0 <__gmpn_toom_eval_pm1@@Base+0x18c>  // b.hs, b.nlast
   3dff0:	b	3e008 <__gmpn_toom_eval_pm1@@Base+0x1c4>
   3dff4:	ldr	x8, [x20, x22, lsl #3]
   3dff8:	ldr	x9, [x19, x22, lsl #3]
   3dffc:	sub	x22, x22, #0x1
   3e000:	cmp	x8, x9
   3e004:	b.ne	3e018 <__gmpn_toom_eval_pm1@@Base+0x1d4>  // b.any
   3e008:	add	x8, x22, #0x1
   3e00c:	cmp	x8, #0x1
   3e010:	b.ge	3dff4 <__gmpn_toom_eval_pm1@@Base+0x1b0>  // b.tcont
   3e014:	b	3e01c <__gmpn_toom_eval_pm1@@Base+0x1d8>
   3e018:	b.ls	3e038 <__gmpn_toom_eval_pm1@@Base+0x1f4>  // b.plast
   3e01c:	mov	x0, x21
   3e020:	mov	x1, x20
   3e024:	mov	x2, x19
   3e028:	mov	x3, x26
   3e02c:	bl	c2e0 <__gmpn_sub_n@plt>
   3e030:	mov	w21, wzr
   3e034:	b	3e050 <__gmpn_toom_eval_pm1@@Base+0x20c>
   3e038:	mov	x0, x21
   3e03c:	mov	x1, x19
   3e040:	mov	x2, x20
   3e044:	mov	x3, x26
   3e048:	bl	c2e0 <__gmpn_sub_n@plt>
   3e04c:	mov	w21, #0xffffffff            	// #-1
   3e050:	mov	x0, x20
   3e054:	mov	x1, x20
   3e058:	mov	x2, x19
   3e05c:	mov	x3, x26
   3e060:	bl	ca90 <__gmpn_add_n@plt>
   3e064:	mov	w0, w21
   3e068:	ldp	x20, x19, [sp, #64]
   3e06c:	ldp	x22, x21, [sp, #48]
   3e070:	ldp	x24, x23, [sp, #32]
   3e074:	ldp	x26, x25, [sp, #16]
   3e078:	ldp	x29, x30, [sp], #80
   3e07c:	ret

000000000003e080 <__gmpn_toom_eval_pm2@@Base>:
   3e080:	stp	x29, x30, [sp, #-96]!
   3e084:	stp	x28, x27, [sp, #16]
   3e088:	sub	w28, w2, #0x2
   3e08c:	mov	w8, w2
   3e090:	mul	x9, x28, x4
   3e094:	mul	x8, x8, x4
   3e098:	add	x27, x3, x9, lsl #3
   3e09c:	stp	x24, x23, [sp, #48]
   3e0a0:	stp	x22, x21, [sp, #64]
   3e0a4:	mov	x23, x3
   3e0a8:	mov	w24, w2
   3e0ac:	mov	x21, x1
   3e0b0:	add	x2, x3, x8, lsl #3
   3e0b4:	mov	x1, x27
   3e0b8:	mov	x3, x5
   3e0bc:	stp	x26, x25, [sp, #32]
   3e0c0:	stp	x20, x19, [sp, #80]
   3e0c4:	mov	x29, sp
   3e0c8:	mov	x19, x6
   3e0cc:	mov	x25, x5
   3e0d0:	mov	x22, x4
   3e0d4:	mov	x20, x0
   3e0d8:	bl	cbc0 <__gmpn_addlsh2_n@plt>
   3e0dc:	subs	x8, x22, x25
   3e0e0:	mov	x26, x0
   3e0e4:	b.eq	3e1c8 <__gmpn_toom_eval_pm2@@Base+0x148>  // b.none
   3e0e8:	ldr	x9, [x27, x25, lsl #3]
   3e0ec:	adds	x9, x9, x26
   3e0f0:	str	x9, [x20, x25, lsl #3]
   3e0f4:	b.cc	3e184 <__gmpn_toom_eval_pm2@@Base+0x104>  // b.lo, b.ul, b.last
   3e0f8:	mul	x11, x22, x28
   3e0fc:	add	x9, x20, x25, lsl #3
   3e100:	add	x13, x25, x11
   3e104:	add	x12, x9, #0x8
   3e108:	add	x9, x23, x13, lsl #3
   3e10c:	mov	x10, xzr
   3e110:	mov	w26, #0x1                   	// #1
   3e114:	add	x13, x9, #0x8
   3e118:	mov	w9, #0x1                   	// #1
   3e11c:	cmp	x9, x8
   3e120:	b.ge	3e1c8 <__gmpn_toom_eval_pm2@@Base+0x148>  // b.tcont
   3e124:	ldr	x14, [x13, x10]
   3e128:	add	x9, x9, #0x1
   3e12c:	adds	x14, x14, #0x1
   3e130:	str	x14, [x12, x10]
   3e134:	add	x10, x10, #0x8
   3e138:	b.cs	3e11c <__gmpn_toom_eval_pm2@@Base+0x9c>  // b.hs, b.nlast
   3e13c:	cmp	x27, x20
   3e140:	mov	x26, xzr
   3e144:	b.eq	3e1c8 <__gmpn_toom_eval_pm2@@Base+0x148>  // b.none
   3e148:	cmp	x9, x8
   3e14c:	b.ge	3e1c8 <__gmpn_toom_eval_pm2@@Base+0x148>  // b.tcont
   3e150:	add	x11, x25, x11
   3e154:	add	x12, x20, x25, lsl #3
   3e158:	add	x11, x23, x11, lsl #3
   3e15c:	add	x12, x12, x10
   3e160:	add	x10, x11, x10
   3e164:	add	x10, x10, #0x8
   3e168:	add	x11, x12, #0x8
   3e16c:	ldr	x12, [x10], #8
   3e170:	sub	x8, x8, #0x1
   3e174:	cmp	x9, x8
   3e178:	str	x12, [x11], #8
   3e17c:	b.ne	3e16c <__gmpn_toom_eval_pm2@@Base+0xec>  // b.any
   3e180:	b	3e1c4 <__gmpn_toom_eval_pm2@@Base+0x144>
   3e184:	cmp	x27, x20
   3e188:	mov	x26, xzr
   3e18c:	b.eq	3e1c8 <__gmpn_toom_eval_pm2@@Base+0x148>  // b.none
   3e190:	cmp	x8, #0x2
   3e194:	b.lt	3e1c8 <__gmpn_toom_eval_pm2@@Base+0x148>  // b.tstop
   3e198:	madd	x10, x22, x28, x25
   3e19c:	mvn	x8, x25
   3e1a0:	add	x9, x20, x25, lsl #3
   3e1a4:	add	x10, x23, x10, lsl #3
   3e1a8:	add	x8, x8, x22
   3e1ac:	add	x9, x9, #0x8
   3e1b0:	add	x10, x10, #0x8
   3e1b4:	ldr	x11, [x10], #8
   3e1b8:	subs	x8, x8, #0x1
   3e1bc:	str	x11, [x9], #8
   3e1c0:	b.ne	3e1b4 <__gmpn_toom_eval_pm2@@Base+0x134>  // b.any
   3e1c4:	mov	x26, xzr
   3e1c8:	cmp	w24, #0x4
   3e1cc:	b.mi	3e1f8 <__gmpn_toom_eval_pm2@@Base+0x178>  // b.first
   3e1d0:	sub	w28, w28, #0x2
   3e1d4:	mul	x8, x28, x22
   3e1d8:	add	x1, x23, x8, lsl #3
   3e1dc:	mov	x0, x20
   3e1e0:	mov	x2, x20
   3e1e4:	mov	x3, x22
   3e1e8:	bl	cbc0 <__gmpn_addlsh2_n@plt>
   3e1ec:	cmp	w28, #0x1
   3e1f0:	add	x26, x0, x26, lsl #2
   3e1f4:	b.gt	3e1d0 <__gmpn_toom_eval_pm2@@Base+0x150>
   3e1f8:	sub	w25, w24, #0x1
   3e1fc:	sub	w8, w24, #0x3
   3e200:	mul	x8, x8, x22
   3e204:	mul	x9, x25, x22
   3e208:	add	x1, x23, x8, lsl #3
   3e20c:	add	x2, x23, x9, lsl #3
   3e210:	mov	x0, x19
   3e214:	mov	x3, x22
   3e218:	str	x26, [x20, x22, lsl #3]
   3e21c:	bl	cbc0 <__gmpn_addlsh2_n@plt>
   3e220:	subs	w26, w24, #0x5
   3e224:	mov	x24, x0
   3e228:	b.mi	3e258 <__gmpn_toom_eval_pm2@@Base+0x1d8>  // b.first
   3e22c:	mov	w8, w26
   3e230:	mul	x8, x8, x22
   3e234:	add	x1, x23, x8, lsl #3
   3e238:	mov	x0, x19
   3e23c:	mov	x2, x19
   3e240:	mov	x3, x22
   3e244:	bl	cbc0 <__gmpn_addlsh2_n@plt>
   3e248:	cmp	w26, #0x1
   3e24c:	sub	w26, w26, #0x2
   3e250:	add	x24, x0, x24, lsl #2
   3e254:	b.gt	3e22c <__gmpn_toom_eval_pm2@@Base+0x1ac>
   3e258:	add	x23, x22, #0x1
   3e25c:	mov	w3, #0x1                   	// #1
   3e260:	str	x24, [x19, x22, lsl #3]
   3e264:	tbnz	w25, #0, 3e274 <__gmpn_toom_eval_pm2@@Base+0x1f4>
   3e268:	mov	x0, x20
   3e26c:	mov	x1, x20
   3e270:	b	3e27c <__gmpn_toom_eval_pm2@@Base+0x1fc>
   3e274:	mov	x0, x19
   3e278:	mov	x1, x19
   3e27c:	mov	x2, x23
   3e280:	bl	c190 <__gmpn_lshift@plt>
   3e284:	and	w24, w25, #0x1
   3e288:	add	x8, x22, #0x1
   3e28c:	cmp	x8, #0x1
   3e290:	b.lt	3e2ac <__gmpn_toom_eval_pm2@@Base+0x22c>  // b.tstop
   3e294:	ldr	x8, [x20, x22, lsl #3]
   3e298:	ldr	x9, [x19, x22, lsl #3]
   3e29c:	sub	x22, x22, #0x1
   3e2a0:	cmp	x8, x9
   3e2a4:	b.eq	3e288 <__gmpn_toom_eval_pm2@@Base+0x208>  // b.none
   3e2a8:	b.ls	3e2c8 <__gmpn_toom_eval_pm2@@Base+0x248>  // b.plast
   3e2ac:	mov	x0, x21
   3e2b0:	mov	x1, x20
   3e2b4:	mov	x2, x19
   3e2b8:	mov	x3, x23
   3e2bc:	bl	c2e0 <__gmpn_sub_n@plt>
   3e2c0:	mov	w21, wzr
   3e2c4:	b	3e2e0 <__gmpn_toom_eval_pm2@@Base+0x260>
   3e2c8:	mov	x0, x21
   3e2cc:	mov	x1, x19
   3e2d0:	mov	x2, x20
   3e2d4:	mov	x3, x23
   3e2d8:	bl	c2e0 <__gmpn_sub_n@plt>
   3e2dc:	mov	w21, #0xffffffff            	// #-1
   3e2e0:	mov	x0, x20
   3e2e4:	mov	x1, x20
   3e2e8:	mov	x2, x19
   3e2ec:	mov	x3, x23
   3e2f0:	bl	ca90 <__gmpn_add_n@plt>
   3e2f4:	sub	w8, w24, #0x1
   3e2f8:	eor	w0, w21, w8
   3e2fc:	ldp	x20, x19, [sp, #80]
   3e300:	ldp	x22, x21, [sp, #64]
   3e304:	ldp	x24, x23, [sp, #48]
   3e308:	ldp	x26, x25, [sp, #32]
   3e30c:	ldp	x28, x27, [sp, #16]
   3e310:	ldp	x29, x30, [sp], #96
   3e314:	ret

000000000003e318 <__gmpn_toom_eval_pm2exp@@Base>:
   3e318:	sub	sp, sp, #0x70
   3e31c:	stp	x28, x27, [sp, #32]
   3e320:	lsl	w27, w6, #1
   3e324:	stp	x26, x25, [sp, #48]
   3e328:	stp	x24, x23, [sp, #64]
   3e32c:	stp	x22, x21, [sp, #80]
   3e330:	stp	x20, x19, [sp, #96]
   3e334:	mov	x26, x3
   3e338:	mov	w24, w2
   3e33c:	mov	x21, x1
   3e340:	mov	x20, x0
   3e344:	add	x1, x3, x4, lsl #4
   3e348:	mov	x0, x7
   3e34c:	mov	x2, x4
   3e350:	mov	w3, w27
   3e354:	stp	x29, x30, [sp, #16]
   3e358:	add	x29, sp, #0x10
   3e35c:	mov	x19, x7
   3e360:	mov	w25, w6
   3e364:	str	x5, [sp, #8]
   3e368:	mov	x22, x4
   3e36c:	bl	c190 <__gmpn_lshift@plt>
   3e370:	str	x0, [x20, x22, lsl #3]
   3e374:	mov	x0, x20
   3e378:	mov	x1, x26
   3e37c:	mov	x2, x19
   3e380:	mov	x3, x22
   3e384:	bl	ca90 <__gmpn_add_n@plt>
   3e388:	ldr	x8, [x20, x22, lsl #3]
   3e38c:	cmp	w24, #0x5
   3e390:	add	x8, x8, x0
   3e394:	str	x8, [x20, x22, lsl #3]
   3e398:	b.cc	3e3fc <__gmpn_toom_eval_pm2exp@@Base+0xe4>  // b.lo, b.ul, b.last
   3e39c:	lsl	w28, w25, #2
   3e3a0:	mov	w23, #0x4                   	// #4
   3e3a4:	mov	w8, w23
   3e3a8:	mul	x8, x8, x22
   3e3ac:	add	x1, x26, x8, lsl #3
   3e3b0:	mov	x0, x19
   3e3b4:	mov	x2, x22
   3e3b8:	mov	w3, w28
   3e3bc:	bl	c190 <__gmpn_lshift@plt>
   3e3c0:	ldr	x8, [x20, x22, lsl #3]
   3e3c4:	mov	x1, x20
   3e3c8:	mov	x2, x19
   3e3cc:	mov	x3, x22
   3e3d0:	add	x8, x8, x0
   3e3d4:	mov	x0, x20
   3e3d8:	str	x8, [x20, x22, lsl #3]
   3e3dc:	bl	ca90 <__gmpn_add_n@plt>
   3e3e0:	ldr	x8, [x20, x22, lsl #3]
   3e3e4:	add	w23, w23, #0x2
   3e3e8:	cmp	w23, w24
   3e3ec:	add	w28, w28, w27
   3e3f0:	add	x8, x8, x0
   3e3f4:	str	x8, [x20, x22, lsl #3]
   3e3f8:	b.cc	3e3a4 <__gmpn_toom_eval_pm2exp@@Base+0x8c>  // b.lo, b.ul, b.last
   3e3fc:	add	x1, x26, x22, lsl #3
   3e400:	mov	x0, x19
   3e404:	mov	x2, x22
   3e408:	mov	w3, w25
   3e40c:	bl	c190 <__gmpn_lshift@plt>
   3e410:	cmp	w24, #0x4
   3e414:	str	x0, [x19, x22, lsl #3]
   3e418:	b.cc	3e47c <__gmpn_toom_eval_pm2exp@@Base+0x164>  // b.lo, b.ul, b.last
   3e41c:	add	w28, w25, w25, lsl #1
   3e420:	mov	w23, #0x3                   	// #3
   3e424:	mov	w8, w23
   3e428:	mul	x8, x8, x22
   3e42c:	add	x1, x26, x8, lsl #3
   3e430:	mov	x0, x21
   3e434:	mov	x2, x22
   3e438:	mov	w3, w28
   3e43c:	bl	c190 <__gmpn_lshift@plt>
   3e440:	ldr	x8, [x19, x22, lsl #3]
   3e444:	mov	x1, x19
   3e448:	mov	x2, x21
   3e44c:	mov	x3, x22
   3e450:	add	x8, x8, x0
   3e454:	mov	x0, x19
   3e458:	str	x8, [x19, x22, lsl #3]
   3e45c:	bl	ca90 <__gmpn_add_n@plt>
   3e460:	ldr	x8, [x19, x22, lsl #3]
   3e464:	add	w23, w23, #0x2
   3e468:	cmp	w23, w24
   3e46c:	add	w28, w28, w27
   3e470:	add	x8, x8, x0
   3e474:	str	x8, [x19, x22, lsl #3]
   3e478:	b.cc	3e424 <__gmpn_toom_eval_pm2exp@@Base+0x10c>  // b.lo, b.ul, b.last
   3e47c:	ldr	x23, [sp, #8]
   3e480:	mov	w8, w24
   3e484:	mul	x8, x8, x22
   3e488:	add	x1, x26, x8, lsl #3
   3e48c:	mul	w3, w25, w24
   3e490:	mov	x0, x21
   3e494:	mov	x2, x23
   3e498:	bl	c190 <__gmpn_lshift@plt>
   3e49c:	str	x0, [x21, x23, lsl #3]
   3e4a0:	add	x25, x22, #0x1
   3e4a4:	add	x23, x23, #0x1
   3e4a8:	tbnz	w24, #0, 3e4ec <__gmpn_toom_eval_pm2exp@@Base+0x1d4>
   3e4ac:	cbz	x23, 3e540 <__gmpn_toom_eval_pm2exp@@Base+0x228>
   3e4b0:	mov	x0, x20
   3e4b4:	mov	x1, x20
   3e4b8:	mov	x2, x21
   3e4bc:	mov	x3, x23
   3e4c0:	bl	ca90 <__gmpn_add_n@plt>
   3e4c4:	cbz	x0, 3e540 <__gmpn_toom_eval_pm2exp@@Base+0x228>
   3e4c8:	cmp	x23, x22
   3e4cc:	b.gt	3e540 <__gmpn_toom_eval_pm2exp@@Base+0x228>
   3e4d0:	ldr	x8, [x20, x23, lsl #3]
   3e4d4:	add	x9, x23, #0x1
   3e4d8:	adds	x8, x8, #0x1
   3e4dc:	str	x8, [x20, x23, lsl #3]
   3e4e0:	mov	x23, x9
   3e4e4:	b.cs	3e4c8 <__gmpn_toom_eval_pm2exp@@Base+0x1b0>  // b.hs, b.nlast
   3e4e8:	b	3e540 <__gmpn_toom_eval_pm2exp@@Base+0x228>
   3e4ec:	cbz	x23, 3e540 <__gmpn_toom_eval_pm2exp@@Base+0x228>
   3e4f0:	mov	x0, x19
   3e4f4:	mov	x1, x19
   3e4f8:	mov	x2, x21
   3e4fc:	mov	x3, x23
   3e500:	bl	ca90 <__gmpn_add_n@plt>
   3e504:	cbz	x0, 3e540 <__gmpn_toom_eval_pm2exp@@Base+0x228>
   3e508:	cmp	x23, x22
   3e50c:	b.gt	3e540 <__gmpn_toom_eval_pm2exp@@Base+0x228>
   3e510:	ldr	x8, [x19, x23, lsl #3]
   3e514:	add	x9, x23, #0x1
   3e518:	adds	x8, x8, #0x1
   3e51c:	str	x8, [x19, x23, lsl #3]
   3e520:	mov	x23, x9
   3e524:	b.cs	3e508 <__gmpn_toom_eval_pm2exp@@Base+0x1f0>  // b.hs, b.nlast
   3e528:	b	3e540 <__gmpn_toom_eval_pm2exp@@Base+0x228>
   3e52c:	ldr	x8, [x20, x22, lsl #3]
   3e530:	ldr	x9, [x19, x22, lsl #3]
   3e534:	sub	x22, x22, #0x1
   3e538:	cmp	x8, x9
   3e53c:	b.ne	3e550 <__gmpn_toom_eval_pm2exp@@Base+0x238>  // b.any
   3e540:	add	x8, x22, #0x1
   3e544:	cmp	x8, #0x1
   3e548:	b.ge	3e52c <__gmpn_toom_eval_pm2exp@@Base+0x214>  // b.tcont
   3e54c:	b	3e554 <__gmpn_toom_eval_pm2exp@@Base+0x23c>
   3e550:	b.ls	3e570 <__gmpn_toom_eval_pm2exp@@Base+0x258>  // b.plast
   3e554:	mov	x0, x21
   3e558:	mov	x1, x20
   3e55c:	mov	x2, x19
   3e560:	mov	x3, x25
   3e564:	bl	c2e0 <__gmpn_sub_n@plt>
   3e568:	mov	w21, wzr
   3e56c:	b	3e588 <__gmpn_toom_eval_pm2exp@@Base+0x270>
   3e570:	mov	x0, x21
   3e574:	mov	x1, x19
   3e578:	mov	x2, x20
   3e57c:	mov	x3, x25
   3e580:	bl	c2e0 <__gmpn_sub_n@plt>
   3e584:	mov	w21, #0xffffffff            	// #-1
   3e588:	mov	x0, x20
   3e58c:	mov	x1, x20
   3e590:	mov	x2, x19
   3e594:	mov	x3, x25
   3e598:	bl	ca90 <__gmpn_add_n@plt>
   3e59c:	mov	w0, w21
   3e5a0:	ldp	x20, x19, [sp, #96]
   3e5a4:	ldp	x22, x21, [sp, #80]
   3e5a8:	ldp	x24, x23, [sp, #64]
   3e5ac:	ldp	x26, x25, [sp, #48]
   3e5b0:	ldp	x28, x27, [sp, #32]
   3e5b4:	ldp	x29, x30, [sp, #16]
   3e5b8:	add	sp, sp, #0x70
   3e5bc:	ret

000000000003e5c0 <__gmpn_toom_eval_pm2rexp@@Base>:
   3e5c0:	sub	sp, sp, #0x70
   3e5c4:	stp	x24, x23, [sp, #64]
   3e5c8:	mov	x23, x3
   3e5cc:	stp	x26, x25, [sp, #48]
   3e5d0:	stp	x22, x21, [sp, #80]
   3e5d4:	mov	w25, w2
   3e5d8:	mov	x21, x1
   3e5dc:	mul	w3, w6, w2
   3e5e0:	mov	x1, x23
   3e5e4:	mov	x2, x4
   3e5e8:	stp	x29, x30, [sp, #16]
   3e5ec:	stp	x28, x27, [sp, #32]
   3e5f0:	stp	x20, x19, [sp, #96]
   3e5f4:	add	x29, sp, #0x10
   3e5f8:	mov	x19, x7
   3e5fc:	mov	w24, w6
   3e600:	mov	x26, x5
   3e604:	mov	x22, x4
   3e608:	mov	x20, x0
   3e60c:	bl	c190 <__gmpn_lshift@plt>
   3e610:	sub	w28, w25, #0x1
   3e614:	str	x0, [x20, x22, lsl #3]
   3e618:	add	x1, x23, x22, lsl #3
   3e61c:	mul	w3, w28, w24
   3e620:	mov	x0, x19
   3e624:	mov	x2, x22
   3e628:	bl	c190 <__gmpn_lshift@plt>
   3e62c:	mov	w8, w25
   3e630:	mul	x8, x8, x22
   3e634:	add	x2, x23, x8, lsl #3
   3e638:	str	x0, [x19, x22, lsl #3]
   3e63c:	tbnz	w25, #0, 3e680 <__gmpn_toom_eval_pm2rexp@@Base+0xc0>
   3e640:	mov	x27, x23
   3e644:	cbz	x26, 3e700 <__gmpn_toom_eval_pm2rexp@@Base+0x140>
   3e648:	mov	x0, x20
   3e64c:	mov	x1, x20
   3e650:	mov	x3, x26
   3e654:	bl	ca90 <__gmpn_add_n@plt>
   3e658:	cbz	x0, 3e700 <__gmpn_toom_eval_pm2rexp@@Base+0x140>
   3e65c:	cmp	x26, x22
   3e660:	b.gt	3e700 <__gmpn_toom_eval_pm2rexp@@Base+0x140>
   3e664:	ldr	x8, [x20, x26, lsl #3]
   3e668:	add	x9, x26, #0x1
   3e66c:	adds	x8, x8, #0x1
   3e670:	str	x8, [x20, x26, lsl #3]
   3e674:	mov	x26, x9
   3e678:	b.cs	3e65c <__gmpn_toom_eval_pm2rexp@@Base+0x9c>  // b.hs, b.nlast
   3e67c:	b	3e700 <__gmpn_toom_eval_pm2rexp@@Base+0x140>
   3e680:	cbz	x26, 3e6b8 <__gmpn_toom_eval_pm2rexp@@Base+0xf8>
   3e684:	mov	x0, x19
   3e688:	mov	x1, x19
   3e68c:	mov	x3, x26
   3e690:	bl	ca90 <__gmpn_add_n@plt>
   3e694:	cbz	x0, 3e6b8 <__gmpn_toom_eval_pm2rexp@@Base+0xf8>
   3e698:	cmp	x26, x22
   3e69c:	b.gt	3e6b8 <__gmpn_toom_eval_pm2rexp@@Base+0xf8>
   3e6a0:	ldr	x8, [x19, x26, lsl #3]
   3e6a4:	add	x9, x26, #0x1
   3e6a8:	adds	x8, x8, #0x1
   3e6ac:	str	x8, [x19, x26, lsl #3]
   3e6b0:	mov	x26, x9
   3e6b4:	b.cs	3e698 <__gmpn_toom_eval_pm2rexp@@Base+0xd8>  // b.hs, b.nlast
   3e6b8:	mov	w8, w28
   3e6bc:	mul	x8, x8, x22
   3e6c0:	add	x1, x23, x8, lsl #3
   3e6c4:	mov	x0, x21
   3e6c8:	mov	x2, x22
   3e6cc:	mov	w3, w24
   3e6d0:	mov	x27, x23
   3e6d4:	bl	c190 <__gmpn_lshift@plt>
   3e6d8:	mov	x26, x0
   3e6dc:	mov	x0, x20
   3e6e0:	mov	x1, x20
   3e6e4:	mov	x2, x21
   3e6e8:	mov	x3, x22
   3e6ec:	bl	ca90 <__gmpn_add_n@plt>
   3e6f0:	ldr	x8, [x20, x22, lsl #3]
   3e6f4:	add	x9, x0, x26
   3e6f8:	add	x8, x9, x8
   3e6fc:	str	x8, [x20, x22, lsl #3]
   3e700:	cmp	w28, #0x3
   3e704:	add	x8, x22, #0x1
   3e708:	str	x8, [sp]
   3e70c:	b.cc	3e7e4 <__gmpn_toom_eval_pm2rexp@@Base+0x224>  // b.lo, b.ul, b.last
   3e710:	lsl	w9, w24, #1
   3e714:	sub	w8, w25, #0x2
   3e718:	stur	w9, [x29, #-4]
   3e71c:	sub	w9, w25, #0x3
   3e720:	mov	x26, x27
   3e724:	mov	w10, w28
   3e728:	mov	w28, wzr
   3e72c:	mul	w8, w24, w8
   3e730:	mul	w27, w24, w9
   3e734:	mov	w23, #0x2                   	// #2
   3e738:	str	w8, [sp, #8]
   3e73c:	mov	w8, w23
   3e740:	mul	x8, x8, x22
   3e744:	add	x1, x26, x8, lsl #3
   3e748:	ldr	w8, [sp, #8]
   3e74c:	mov	x0, x21
   3e750:	mov	x2, x22
   3e754:	mov	w25, w10
   3e758:	add	w3, w8, w28
   3e75c:	bl	c190 <__gmpn_lshift@plt>
   3e760:	mov	x24, x0
   3e764:	mov	x0, x20
   3e768:	mov	x1, x20
   3e76c:	mov	x2, x21
   3e770:	mov	x3, x22
   3e774:	bl	ca90 <__gmpn_add_n@plt>
   3e778:	ldr	x9, [x20, x22, lsl #3]
   3e77c:	add	w10, w23, #0x1
   3e780:	add	x8, x0, x24
   3e784:	mul	x10, x10, x22
   3e788:	add	x1, x26, x10, lsl #3
   3e78c:	add	x8, x8, x9
   3e790:	add	w3, w27, w28
   3e794:	mov	x0, x21
   3e798:	mov	x2, x22
   3e79c:	str	x8, [x20, x22, lsl #3]
   3e7a0:	bl	c190 <__gmpn_lshift@plt>
   3e7a4:	mov	x24, x0
   3e7a8:	mov	x0, x19
   3e7ac:	mov	x1, x19
   3e7b0:	mov	x2, x21
   3e7b4:	mov	x3, x22
   3e7b8:	bl	ca90 <__gmpn_add_n@plt>
   3e7bc:	ldr	x8, [x19, x22, lsl #3]
   3e7c0:	add	x9, x0, x24
   3e7c4:	add	w23, w23, #0x2
   3e7c8:	mov	w10, w25
   3e7cc:	add	x8, x9, x8
   3e7d0:	str	x8, [x19, x22, lsl #3]
   3e7d4:	ldur	w8, [x29, #-4]
   3e7d8:	cmp	w23, w25
   3e7dc:	sub	w28, w28, w8
   3e7e0:	b.cc	3e73c <__gmpn_toom_eval_pm2rexp@@Base+0x17c>  // b.lo, b.ul, b.last
   3e7e4:	add	x8, x22, #0x1
   3e7e8:	cmp	x8, #0x1
   3e7ec:	b.lt	3e808 <__gmpn_toom_eval_pm2rexp@@Base+0x248>  // b.tstop
   3e7f0:	ldr	x8, [x20, x22, lsl #3]
   3e7f4:	ldr	x9, [x19, x22, lsl #3]
   3e7f8:	sub	x22, x22, #0x1
   3e7fc:	cmp	x8, x9
   3e800:	b.eq	3e7e4 <__gmpn_toom_eval_pm2rexp@@Base+0x224>  // b.none
   3e804:	b.ls	3e828 <__gmpn_toom_eval_pm2rexp@@Base+0x268>  // b.plast
   3e808:	ldr	x22, [sp]
   3e80c:	mov	x0, x21
   3e810:	mov	x1, x20
   3e814:	mov	x2, x19
   3e818:	mov	x3, x22
   3e81c:	bl	c2e0 <__gmpn_sub_n@plt>
   3e820:	mov	w21, wzr
   3e824:	b	3e844 <__gmpn_toom_eval_pm2rexp@@Base+0x284>
   3e828:	ldr	x22, [sp]
   3e82c:	mov	x0, x21
   3e830:	mov	x1, x19
   3e834:	mov	x2, x20
   3e838:	mov	x3, x22
   3e83c:	bl	c2e0 <__gmpn_sub_n@plt>
   3e840:	mov	w21, #0xffffffff            	// #-1
   3e844:	mov	x0, x20
   3e848:	mov	x1, x20
   3e84c:	mov	x2, x19
   3e850:	mov	x3, x22
   3e854:	bl	ca90 <__gmpn_add_n@plt>
   3e858:	mov	w0, w21
   3e85c:	ldp	x20, x19, [sp, #96]
   3e860:	ldp	x22, x21, [sp, #80]
   3e864:	ldp	x24, x23, [sp, #64]
   3e868:	ldp	x26, x25, [sp, #48]
   3e86c:	ldp	x28, x27, [sp, #32]
   3e870:	ldp	x29, x30, [sp, #16]
   3e874:	add	sp, sp, #0x70
   3e878:	ret

000000000003e87c <__gmpn_toom_interpolate_5pts@@Base>:
   3e87c:	sub	sp, sp, #0x70
   3e880:	stp	x24, x23, [sp, #64]
   3e884:	add	x23, x0, x3, lsl #3
   3e888:	stp	x28, x27, [sp, #32]
   3e88c:	stp	x26, x25, [sp, #48]
   3e890:	mov	w27, #0x1                   	// #1
   3e894:	add	x25, x23, x3, lsl #3
   3e898:	stp	x22, x21, [sp, #80]
   3e89c:	bfi	x27, x3, #1, #63
   3e8a0:	add	x22, x25, x3, lsl #3
   3e8a4:	stp	x20, x19, [sp, #96]
   3e8a8:	mov	x24, x4
   3e8ac:	mov	x19, x3
   3e8b0:	mov	x28, x2
   3e8b4:	mov	x21, x1
   3e8b8:	lsl	x8, x3, #1
   3e8bc:	mov	x20, x0
   3e8c0:	add	x26, x22, x3, lsl #3
   3e8c4:	mov	x0, x1
   3e8c8:	mov	x3, x27
   3e8cc:	stp	x29, x30, [sp, #16]
   3e8d0:	add	x29, sp, #0x10
   3e8d4:	stp	x8, x6, [sp]
   3e8d8:	cbz	w5, 3e910 <__gmpn_toom_interpolate_5pts@@Base+0x94>
   3e8dc:	bl	ca90 <__gmpn_add_n@plt>
   3e8e0:	mov	x3, #0x5555555555555555    	// #6148914691236517205
   3e8e4:	mov	x0, x21
   3e8e8:	mov	x1, x21
   3e8ec:	mov	x2, x27
   3e8f0:	mov	x4, xzr
   3e8f4:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
   3e8f8:	mov	x0, x28
   3e8fc:	mov	x1, x25
   3e900:	mov	x2, x28
   3e904:	mov	x3, x27
   3e908:	bl	c970 <__gmpn_rsh1add_n@plt>
   3e90c:	b	3e940 <__gmpn_toom_interpolate_5pts@@Base+0xc4>
   3e910:	bl	c2e0 <__gmpn_sub_n@plt>
   3e914:	mov	x3, #0x5555555555555555    	// #6148914691236517205
   3e918:	mov	x0, x21
   3e91c:	mov	x1, x21
   3e920:	mov	x2, x27
   3e924:	mov	x4, xzr
   3e928:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
   3e92c:	mov	x0, x28
   3e930:	mov	x1, x25
   3e934:	mov	x2, x28
   3e938:	mov	x3, x27
   3e93c:	bl	c860 <__gmpn_rsh1sub_n@plt>
   3e940:	ldr	x3, [sp]
   3e944:	mov	x0, x25
   3e948:	mov	x1, x25
   3e94c:	mov	x2, x20
   3e950:	bl	c2e0 <__gmpn_sub_n@plt>
   3e954:	ldr	x8, [x26]
   3e958:	mov	x1, x21
   3e95c:	mov	x2, x25
   3e960:	mov	x3, x27
   3e964:	sub	x8, x8, x0
   3e968:	mov	x0, x21
   3e96c:	str	x8, [x26]
   3e970:	bl	c860 <__gmpn_rsh1sub_n@plt>
   3e974:	mov	x0, x25
   3e978:	mov	x1, x25
   3e97c:	mov	x2, x28
   3e980:	mov	x3, x27
   3e984:	bl	c2e0 <__gmpn_sub_n@plt>
   3e988:	mov	x0, x23
   3e98c:	mov	x1, x23
   3e990:	mov	x2, x28
   3e994:	mov	x3, x27
   3e998:	mov	x28, x20
   3e99c:	bl	ca90 <__gmpn_add_n@plt>
   3e9a0:	ldr	x8, [x22, #8]
   3e9a4:	adds	x8, x8, x0
   3e9a8:	str	x8, [x22, #8]
   3e9ac:	b.cc	3e9cc <__gmpn_toom_interpolate_5pts@@Base+0x150>  // b.lo, b.ul, b.last
   3e9b0:	mov	w8, #0x18                  	// #24
   3e9b4:	madd	x8, x19, x8, x28
   3e9b8:	add	x8, x8, #0x10
   3e9bc:	ldr	x9, [x8]
   3e9c0:	adds	x9, x9, #0x1
   3e9c4:	str	x9, [x8], #8
   3e9c8:	b.cs	3e9bc <__gmpn_toom_interpolate_5pts@@Base+0x140>  // b.hs, b.nlast
   3e9cc:	ldr	x8, [sp, #8]
   3e9d0:	ldr	x20, [x26]
   3e9d4:	mov	x0, x21
   3e9d8:	mov	x1, x21
   3e9dc:	mov	x2, x26
   3e9e0:	mov	x3, x24
   3e9e4:	str	x8, [x26]
   3e9e8:	bl	c460 <__gmpn_sublsh1_n@plt>
   3e9ec:	ldr	x8, [x21, x24, lsl #3]
   3e9f0:	subs	x8, x8, x0
   3e9f4:	str	x8, [x21, x24, lsl #3]
   3e9f8:	b.cs	3ea14 <__gmpn_toom_interpolate_5pts@@Base+0x198>  // b.hs, b.nlast
   3e9fc:	add	x8, x21, x24, lsl #3
   3ea00:	add	x8, x8, #0x8
   3ea04:	ldr	x9, [x8]
   3ea08:	sub	x10, x9, #0x1
   3ea0c:	str	x10, [x8], #8
   3ea10:	cbz	x9, 3ea04 <__gmpn_toom_interpolate_5pts@@Base+0x188>
   3ea14:	add	x3, x19, #0x1
   3ea18:	cmp	x3, x24
   3ea1c:	add	x2, x21, x19, lsl #3
   3ea20:	mov	x0, x26
   3ea24:	mov	x1, x26
   3ea28:	b.ge	3eb40 <__gmpn_toom_interpolate_5pts@@Base+0x2c4>  // b.tcont
   3ea2c:	bl	ca90 <__gmpn_add_n@plt>
   3ea30:	ldr	x8, [x22, x27, lsl #3]
   3ea34:	adds	x8, x8, x0
   3ea38:	str	x8, [x22, x27, lsl #3]
   3ea3c:	b.cc	3ea5c <__gmpn_toom_interpolate_5pts@@Base+0x1e0>  // b.lo, b.ul, b.last
   3ea40:	mov	w8, #0x28                  	// #40
   3ea44:	madd	x8, x19, x8, x28
   3ea48:	add	x8, x8, #0x10
   3ea4c:	ldr	x9, [x8]
   3ea50:	adds	x9, x9, #0x1
   3ea54:	str	x9, [x8], #8
   3ea58:	b.cs	3ea4c <__gmpn_toom_interpolate_5pts@@Base+0x1d0>  // b.hs, b.nlast
   3ea5c:	mov	x0, x25
   3ea60:	mov	x1, x25
   3ea64:	mov	x2, x26
   3ea68:	mov	x3, x24
   3ea6c:	bl	c2e0 <__gmpn_sub_n@plt>
   3ea70:	ldr	x27, [x26]
   3ea74:	str	x20, [x26]
   3ea78:	ldr	x8, [x25, x24, lsl #3]
   3ea7c:	subs	x8, x8, x0
   3ea80:	str	x8, [x25, x24, lsl #3]
   3ea84:	b.cs	3eaa4 <__gmpn_toom_interpolate_5pts@@Base+0x228>  // b.hs, b.nlast
   3ea88:	add	x8, x24, x19, lsl #1
   3ea8c:	add	x8, x28, x8, lsl #3
   3ea90:	add	x8, x8, #0x8
   3ea94:	ldr	x9, [x8]
   3ea98:	sub	x10, x9, #0x1
   3ea9c:	str	x10, [x8], #8
   3eaa0:	cbz	x9, 3ea94 <__gmpn_toom_interpolate_5pts@@Base+0x218>
   3eaa4:	mov	x0, x23
   3eaa8:	mov	x1, x23
   3eaac:	mov	x2, x21
   3eab0:	mov	x3, x19
   3eab4:	bl	c2e0 <__gmpn_sub_n@plt>
   3eab8:	ldr	x8, [x23, x19, lsl #3]
   3eabc:	subs	x8, x8, x0
   3eac0:	str	x8, [x23, x19, lsl #3]
   3eac4:	b.cs	3eae0 <__gmpn_toom_interpolate_5pts@@Base+0x264>  // b.hs, b.nlast
   3eac8:	add	x8, x28, x19, lsl #4
   3eacc:	add	x8, x8, #0x8
   3ead0:	ldr	x9, [x8]
   3ead4:	sub	x10, x9, #0x1
   3ead8:	str	x10, [x8], #8
   3eadc:	cbz	x9, 3ead0 <__gmpn_toom_interpolate_5pts@@Base+0x254>
   3eae0:	mov	x0, x22
   3eae4:	mov	x1, x22
   3eae8:	mov	x2, x21
   3eaec:	mov	x3, x19
   3eaf0:	bl	ca90 <__gmpn_add_n@plt>
   3eaf4:	ldr	x8, [x22, x19, lsl #3]
   3eaf8:	add	x8, x8, x0
   3eafc:	adds	x8, x8, x27
   3eb00:	str	x8, [x22, x19, lsl #3]
   3eb04:	b.cc	3eb20 <__gmpn_toom_interpolate_5pts@@Base+0x2a4>  // b.lo, b.ul, b.last
   3eb08:	add	x8, x28, x19, lsl #5
   3eb0c:	add	x8, x8, #0x8
   3eb10:	ldr	x9, [x8]
   3eb14:	adds	x9, x9, #0x1
   3eb18:	str	x9, [x8], #8
   3eb1c:	b.cs	3eb10 <__gmpn_toom_interpolate_5pts@@Base+0x294>  // b.hs, b.nlast
   3eb20:	ldp	x20, x19, [sp, #96]
   3eb24:	ldp	x22, x21, [sp, #80]
   3eb28:	ldp	x24, x23, [sp, #64]
   3eb2c:	ldp	x26, x25, [sp, #48]
   3eb30:	ldp	x28, x27, [sp, #32]
   3eb34:	ldp	x29, x30, [sp, #16]
   3eb38:	add	sp, sp, #0x70
   3eb3c:	ret
   3eb40:	mov	x3, x24
   3eb44:	bl	ca90 <__gmpn_add_n@plt>
   3eb48:	b	3ea5c <__gmpn_toom_interpolate_5pts@@Base+0x1e0>

000000000003eb4c <__gmpn_toom_interpolate_6pts@@Base>:
   3eb4c:	sub	sp, sp, #0x80
   3eb50:	stp	x26, x25, [sp, #64]
   3eb54:	mov	w25, #0x1                   	// #1
   3eb58:	stp	x28, x27, [sp, #48]
   3eb5c:	stp	x24, x23, [sp, #80]
   3eb60:	stp	x22, x21, [sp, #96]
   3eb64:	stp	x20, x19, [sp, #112]
   3eb68:	mov	x21, x6
   3eb6c:	mov	x23, x5
   3eb70:	mov	x27, x4
   3eb74:	mov	x22, x3
   3eb78:	mov	w28, w2
   3eb7c:	mov	x20, x1
   3eb80:	mov	x19, x0
   3eb84:	lsl	x24, x1, #1
   3eb88:	bfi	x25, x1, #1, #63
   3eb8c:	mov	x0, x4
   3eb90:	mov	x1, x5
   3eb94:	stp	x29, x30, [sp, #32]
   3eb98:	add	x29, sp, #0x20
   3eb9c:	tbnz	w2, #1, 3ebb0 <__gmpn_toom_interpolate_6pts@@Base+0x64>
   3eba0:	mov	x2, x27
   3eba4:	mov	x3, x25
   3eba8:	bl	c2e0 <__gmpn_sub_n@plt>
   3ebac:	b	3ebbc <__gmpn_toom_interpolate_6pts@@Base+0x70>
   3ebb0:	mov	x2, x27
   3ebb4:	mov	x3, x25
   3ebb8:	bl	ca90 <__gmpn_add_n@plt>
   3ebbc:	mov	w3, #0x2                   	// #2
   3ebc0:	mov	x0, x27
   3ebc4:	mov	x1, x27
   3ebc8:	mov	x2, x25
   3ebcc:	bl	c1b0 <__gmpn_rshift@plt>
   3ebd0:	mov	x0, x23
   3ebd4:	mov	x1, x23
   3ebd8:	mov	x2, x19
   3ebdc:	mov	x3, x24
   3ebe0:	bl	c2e0 <__gmpn_sub_n@plt>
   3ebe4:	ldr	x8, [x23, x24, lsl #3]
   3ebe8:	mov	w3, #0x1                   	// #1
   3ebec:	mov	x1, x23
   3ebf0:	mov	x2, x25
   3ebf4:	sub	x8, x8, x0
   3ebf8:	mov	x0, x23
   3ebfc:	str	x8, [x23, x24, lsl #3]
   3ec00:	bl	c1b0 <__gmpn_rshift@plt>
   3ec04:	mov	x0, x23
   3ec08:	mov	x1, x23
   3ec0c:	mov	x2, x27
   3ec10:	mov	x3, x25
   3ec14:	bl	c860 <__gmpn_rsh1sub_n@plt>
   3ec18:	add	x26, x19, x24, lsl #3
   3ec1c:	mov	x0, x22
   3ec20:	mov	x1, x26
   3ec24:	mov	x2, x22
   3ec28:	mov	x3, x25
   3ec2c:	tbnz	w28, #0, 3ec38 <__gmpn_toom_interpolate_6pts@@Base+0xec>
   3ec30:	bl	c860 <__gmpn_rsh1sub_n@plt>
   3ec34:	b	3ec3c <__gmpn_toom_interpolate_6pts@@Base+0xf0>
   3ec38:	bl	c970 <__gmpn_rsh1add_n@plt>
   3ec3c:	mov	x0, x27
   3ec40:	mov	x1, x27
   3ec44:	mov	x2, x22
   3ec48:	mov	x3, x25
   3ec4c:	bl	c2e0 <__gmpn_sub_n@plt>
   3ec50:	mov	x3, #0x5555555555555555    	// #6148914691236517205
   3ec54:	mov	x0, x27
   3ec58:	mov	x1, x27
   3ec5c:	mov	x2, x25
   3ec60:	mov	x4, xzr
   3ec64:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
   3ec68:	mov	x0, x26
   3ec6c:	mov	x1, x26
   3ec70:	mov	x2, x22
   3ec74:	mov	x3, x25
   3ec78:	bl	c2e0 <__gmpn_sub_n@plt>
   3ec7c:	mov	x0, x26
   3ec80:	mov	x1, x26
   3ec84:	mov	x2, x19
   3ec88:	mov	x3, x24
   3ec8c:	bl	c2e0 <__gmpn_sub_n@plt>
   3ec90:	ldr	x8, [x26, x24, lsl #3]
   3ec94:	mov	x1, x23
   3ec98:	mov	x2, x26
   3ec9c:	mov	x3, x25
   3eca0:	sub	x8, x8, x0
   3eca4:	mov	x0, x23
   3eca8:	str	x8, [x26, x24, lsl #3]
   3ecac:	bl	c2e0 <__gmpn_sub_n@plt>
   3ecb0:	mov	x3, #0x5555555555555555    	// #6148914691236517205
   3ecb4:	mov	x0, x23
   3ecb8:	mov	x1, x23
   3ecbc:	mov	x2, x25
   3ecc0:	mov	x4, xzr
   3ecc4:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
   3ecc8:	add	x28, x19, x20, lsl #3
   3eccc:	mov	x0, x28
   3ecd0:	mov	x1, x28
   3ecd4:	mov	x2, x22
   3ecd8:	mov	x3, x25
   3ecdc:	bl	ca90 <__gmpn_add_n@plt>
   3ece0:	mov	w8, #0x18                  	// #24
   3ece4:	madd	x25, x20, x8, x19
   3ece8:	ldr	x8, [x25, #8]
   3ecec:	adds	x8, x8, x0
   3ecf0:	str	x8, [x25, #8]
   3ecf4:	b.cc	3ed14 <__gmpn_toom_interpolate_6pts@@Base+0x1c8>  // b.lo, b.ul, b.last
   3ecf8:	mov	w8, #0x18                  	// #24
   3ecfc:	madd	x8, x20, x8, x19
   3ed00:	add	x8, x8, #0x10
   3ed04:	ldr	x9, [x8]
   3ed08:	adds	x9, x9, #0x1
   3ed0c:	str	x9, [x8], #8
   3ed10:	b.cs	3ed04 <__gmpn_toom_interpolate_6pts@@Base+0x1b8>  // b.hs, b.nlast
   3ed14:	mov	w8, #0x28                  	// #40
   3ed18:	madd	x22, x20, x8, x19
   3ed1c:	mov	x0, x27
   3ed20:	mov	x1, x27
   3ed24:	mov	x2, x22
   3ed28:	mov	x3, x21
   3ed2c:	bl	c170 <__gmpn_sublsh2_n@plt>
   3ed30:	ldr	x8, [x27, x21, lsl #3]
   3ed34:	subs	x8, x8, x0
   3ed38:	str	x8, [x27, x21, lsl #3]
   3ed3c:	b.cs	3ed58 <__gmpn_toom_interpolate_6pts@@Base+0x20c>  // b.hs, b.nlast
   3ed40:	add	x8, x27, x21, lsl #3
   3ed44:	add	x8, x8, #0x8
   3ed48:	ldr	x9, [x8]
   3ed4c:	sub	x10, x9, #0x1
   3ed50:	str	x10, [x8], #8
   3ed54:	cbz	x9, 3ed48 <__gmpn_toom_interpolate_6pts@@Base+0x1fc>
   3ed58:	mov	x0, x28
   3ed5c:	mov	x1, x28
   3ed60:	mov	x2, x27
   3ed64:	mov	x3, x20
   3ed68:	bl	c2e0 <__gmpn_sub_n@plt>
   3ed6c:	ldr	x8, [x26]
   3ed70:	subs	x8, x8, x0
   3ed74:	str	x8, [x26]
   3ed78:	b.cs	3ed94 <__gmpn_toom_interpolate_6pts@@Base+0x248>  // b.hs, b.nlast
   3ed7c:	add	x8, x19, x20, lsl #4
   3ed80:	add	x8, x8, #0x8
   3ed84:	ldr	x9, [x8]
   3ed88:	sub	x10, x9, #0x1
   3ed8c:	str	x10, [x8], #8
   3ed90:	cbz	x9, 3ed84 <__gmpn_toom_interpolate_6pts@@Base+0x238>
   3ed94:	ldr	x8, [x26, x24, lsl #3]
   3ed98:	mov	x0, x25
   3ed9c:	mov	x1, x25
   3eda0:	mov	x2, x27
   3eda4:	mov	x3, x20
   3eda8:	str	x8, [sp, #16]
   3edac:	bl	ca90 <__gmpn_add_n@plt>
   3edb0:	mov	x8, x19
   3edb4:	ldr	x19, [x27, x24, lsl #3]
   3edb8:	add	x28, x8, x20, lsl #5
   3edbc:	str	x0, [sp, #8]
   3edc0:	add	x2, x27, x20, lsl #3
   3edc4:	mov	x0, x28
   3edc8:	mov	x1, x23
   3edcc:	mov	x3, x20
   3edd0:	stur	x8, [x29, #-8]
   3edd4:	bl	ca90 <__gmpn_add_n@plt>
   3edd8:	add	x2, x23, x20, lsl #3
   3eddc:	ldr	x8, [x2]
   3ede0:	add	x9, x0, x19
   3ede4:	adds	x8, x8, x9
   3ede8:	str	x8, [x2]
   3edec:	b.cc	3ee04 <__gmpn_toom_interpolate_6pts@@Base+0x2b8>  // b.lo, b.ul, b.last
   3edf0:	add	x8, x2, #0x8
   3edf4:	ldr	x9, [x8]
   3edf8:	adds	x9, x9, #0x1
   3edfc:	str	x9, [x8], #8
   3ee00:	b.cs	3edf4 <__gmpn_toom_interpolate_6pts@@Base+0x2a8>  // b.hs, b.nlast
   3ee04:	cmp	x21, x20
   3ee08:	b.le	3efa8 <__gmpn_toom_interpolate_6pts@@Base+0x45c>
   3ee0c:	ldr	x19, [x23, x24, lsl #3]
   3ee10:	mov	x0, x22
   3ee14:	mov	x1, x22
   3ee18:	mov	x3, x20
   3ee1c:	bl	ca90 <__gmpn_add_n@plt>
   3ee20:	add	x23, x0, x19
   3ee24:	ldp	x9, x8, [sp, #8]
   3ee28:	ldur	x19, [x29, #-8]
   3ee2c:	add	x3, x21, x20
   3ee30:	mov	x0, x26
   3ee34:	mov	x1, x26
   3ee38:	mov	x2, x28
   3ee3c:	add	x24, x9, x8
   3ee40:	bl	c2e0 <__gmpn_sub_n@plt>
   3ee44:	sub	x8, x21, #0x1
   3ee48:	ldr	x9, [x22, x8, lsl #3]
   3ee4c:	mov	w10, #0x1                   	// #1
   3ee50:	cmp	x21, x20
   3ee54:	str	x10, [x22, x8, lsl #3]
   3ee58:	sub	x9, x9, #0x1
   3ee5c:	b.le	3ee94 <__gmpn_toom_interpolate_6pts@@Base+0x348>
   3ee60:	subs	x10, x24, x23
   3ee64:	b.ls	3eef4 <__gmpn_toom_interpolate_6pts@@Base+0x3a8>  // b.plast
   3ee68:	ldr	x11, [x28]
   3ee6c:	adds	x10, x11, x10
   3ee70:	str	x10, [x28]
   3ee74:	b.cc	3ef20 <__gmpn_toom_interpolate_6pts@@Base+0x3d4>  // b.lo, b.ul, b.last
   3ee78:	add	x10, x19, x20, lsl #5
   3ee7c:	add	x10, x10, #0x8
   3ee80:	ldr	x11, [x10]
   3ee84:	adds	x11, x11, #0x1
   3ee88:	str	x11, [x10], #8
   3ee8c:	b.cs	3ee80 <__gmpn_toom_interpolate_6pts@@Base+0x334>  // b.hs, b.nlast
   3ee90:	b	3ef20 <__gmpn_toom_interpolate_6pts@@Base+0x3d4>
   3ee94:	ldr	x10, [x28]
   3ee98:	adds	x10, x10, x24
   3ee9c:	str	x10, [x28]
   3eea0:	b.cc	3eebc <__gmpn_toom_interpolate_6pts@@Base+0x370>  // b.lo, b.ul, b.last
   3eea4:	add	x10, x19, x20, lsl #5
   3eea8:	add	x10, x10, #0x8
   3eeac:	ldr	x11, [x10]
   3eeb0:	adds	x11, x11, #0x1
   3eeb4:	str	x11, [x10], #8
   3eeb8:	b.cs	3eeac <__gmpn_toom_interpolate_6pts@@Base+0x360>  // b.hs, b.nlast
   3eebc:	ldr	x10, [x25, x21, lsl #3]
   3eec0:	add	x11, x0, x23
   3eec4:	subs	x10, x10, x11
   3eec8:	str	x10, [x25, x21, lsl #3]
   3eecc:	b.cs	3ef7c <__gmpn_toom_interpolate_6pts@@Base+0x430>  // b.hs, b.nlast
   3eed0:	add	x10, x20, x20, lsl #1
   3eed4:	add	x10, x21, x10
   3eed8:	add	x10, x19, x10, lsl #3
   3eedc:	add	x10, x10, #0x8
   3eee0:	ldr	x11, [x10]
   3eee4:	sub	x12, x11, #0x1
   3eee8:	str	x12, [x10], #8
   3eeec:	cbz	x11, 3eee0 <__gmpn_toom_interpolate_6pts@@Base+0x394>
   3eef0:	b	3ef7c <__gmpn_toom_interpolate_6pts@@Base+0x430>
   3eef4:	ldr	x10, [x28]
   3eef8:	sub	x11, x23, x24
   3eefc:	subs	x10, x10, x11
   3ef00:	str	x10, [x28]
   3ef04:	b.cs	3ef20 <__gmpn_toom_interpolate_6pts@@Base+0x3d4>  // b.hs, b.nlast
   3ef08:	add	x10, x19, x20, lsl #5
   3ef0c:	add	x10, x10, #0x8
   3ef10:	ldr	x11, [x10]
   3ef14:	sub	x12, x11, #0x1
   3ef18:	str	x12, [x10], #8
   3ef1c:	cbz	x11, 3ef10 <__gmpn_toom_interpolate_6pts@@Base+0x3c4>
   3ef20:	ldr	x10, [x25, x21, lsl #3]
   3ef24:	subs	x10, x10, x0
   3ef28:	str	x10, [x25, x21, lsl #3]
   3ef2c:	b.cs	3ef50 <__gmpn_toom_interpolate_6pts@@Base+0x404>  // b.hs, b.nlast
   3ef30:	add	x10, x20, x20, lsl #1
   3ef34:	add	x10, x21, x10
   3ef38:	add	x10, x19, x10, lsl #3
   3ef3c:	add	x10, x10, #0x8
   3ef40:	ldr	x11, [x10]
   3ef44:	sub	x12, x11, #0x1
   3ef48:	str	x12, [x10], #8
   3ef4c:	cbz	x11, 3ef40 <__gmpn_toom_interpolate_6pts@@Base+0x3f4>
   3ef50:	ldr	x10, [x22, x20, lsl #3]
   3ef54:	adds	x10, x10, x23
   3ef58:	str	x10, [x22, x20, lsl #3]
   3ef5c:	b.cc	3ef7c <__gmpn_toom_interpolate_6pts@@Base+0x430>  // b.lo, b.ul, b.last
   3ef60:	mov	w10, #0x30                  	// #48
   3ef64:	madd	x10, x20, x10, x19
   3ef68:	add	x10, x10, #0x8
   3ef6c:	ldr	x11, [x10]
   3ef70:	adds	x11, x11, #0x1
   3ef74:	str	x11, [x10], #8
   3ef78:	b.cs	3ef6c <__gmpn_toom_interpolate_6pts@@Base+0x420>  // b.hs, b.nlast
   3ef7c:	ldr	x10, [x22, x8, lsl #3]
   3ef80:	add	x9, x9, x10
   3ef84:	str	x9, [x22, x8, lsl #3]
   3ef88:	ldp	x20, x19, [sp, #112]
   3ef8c:	ldp	x22, x21, [sp, #96]
   3ef90:	ldp	x24, x23, [sp, #80]
   3ef94:	ldp	x26, x25, [sp, #64]
   3ef98:	ldp	x28, x27, [sp, #48]
   3ef9c:	ldp	x29, x30, [sp, #32]
   3efa0:	add	sp, sp, #0x80
   3efa4:	ret
   3efa8:	mov	x0, x22
   3efac:	mov	x1, x22
   3efb0:	mov	x3, x21
   3efb4:	bl	ca90 <__gmpn_add_n@plt>
   3efb8:	mov	x23, x0
   3efbc:	b	3ee24 <__gmpn_toom_interpolate_6pts@@Base+0x2d8>

000000000003efc0 <__gmpn_toom_interpolate_7pts@@Base>:
   3efc0:	sub	sp, sp, #0x90
   3efc4:	stp	x29, x30, [sp, #48]
   3efc8:	stp	x28, x27, [sp, #64]
   3efcc:	stp	x26, x25, [sp, #80]
   3efd0:	stp	x24, x23, [sp, #96]
   3efd4:	stp	x22, x21, [sp, #112]
   3efd8:	stp	x20, x19, [sp, #128]
   3efdc:	add	x29, sp, #0x30
   3efe0:	str	x7, [sp, #24]
   3efe4:	ldr	x8, [x29, #96]
   3efe8:	mov	w28, #0x1                   	// #1
   3efec:	bfi	x28, x1, #1, #63
   3eff0:	mov	x27, x3
   3eff4:	mov	w24, w2
   3eff8:	mov	x19, x1
   3effc:	mov	x20, x0
   3f000:	lsl	x21, x1, #1
   3f004:	mov	x0, x6
   3f008:	mov	x1, x6
   3f00c:	mov	x2, x5
   3f010:	mov	x3, x28
   3f014:	mov	x23, x6
   3f018:	mov	x22, x5
   3f01c:	mov	x25, x4
   3f020:	stur	x8, [x29, #-8]
   3f024:	bl	ca90 <__gmpn_add_n@plt>
   3f028:	mov	x0, x27
   3f02c:	str	w24, [sp, #12]
   3f030:	tbnz	w24, #0, 3f04c <__gmpn_toom_interpolate_7pts@@Base+0x8c>
   3f034:	mov	x1, x22
   3f038:	mov	x2, x27
   3f03c:	mov	x3, x28
   3f040:	bl	c860 <__gmpn_rsh1sub_n@plt>
   3f044:	cbnz	x19, 3f060 <__gmpn_toom_interpolate_7pts@@Base+0xa0>
   3f048:	b	3f0a0 <__gmpn_toom_interpolate_7pts@@Base+0xe0>
   3f04c:	mov	x1, x27
   3f050:	mov	x2, x22
   3f054:	mov	x3, x28
   3f058:	bl	c970 <__gmpn_rsh1add_n@plt>
   3f05c:	cbz	x19, 3f0a0 <__gmpn_toom_interpolate_7pts@@Base+0xe0>
   3f060:	mov	x0, x22
   3f064:	mov	x1, x22
   3f068:	mov	x2, x20
   3f06c:	mov	x3, x21
   3f070:	bl	c2e0 <__gmpn_sub_n@plt>
   3f074:	cbz	x0, 3f0a0 <__gmpn_toom_interpolate_7pts@@Base+0xe0>
   3f078:	add	x9, x22, x28, lsl #3
   3f07c:	mov	x8, xzr
   3f080:	sub	x9, x9, #0x8
   3f084:	cmp	x8, #0x8
   3f088:	b.eq	3f0a0 <__gmpn_toom_interpolate_7pts@@Base+0xe0>  // b.none
   3f08c:	ldr	x10, [x9, x8]
   3f090:	sub	x11, x10, #0x1
   3f094:	str	x11, [x9, x8]
   3f098:	add	x8, x8, #0x8
   3f09c:	cbz	x10, 3f084 <__gmpn_toom_interpolate_7pts@@Base+0xc4>
   3f0a0:	mov	x0, x22
   3f0a4:	mov	x1, x22
   3f0a8:	mov	x2, x27
   3f0ac:	mov	x3, x28
   3f0b0:	stur	x21, [x29, #-16]
   3f0b4:	bl	c2e0 <__gmpn_sub_n@plt>
   3f0b8:	mov	w3, #0x2                   	// #2
   3f0bc:	mov	x0, x22
   3f0c0:	mov	x1, x22
   3f0c4:	mov	x2, x28
   3f0c8:	bl	c1b0 <__gmpn_rshift@plt>
   3f0cc:	mov	w8, #0x30                  	// #48
   3f0d0:	mov	x26, x20
   3f0d4:	madd	x1, x19, x8, x20
   3f0d8:	ldur	x24, [x29, #-8]
   3f0dc:	ldr	x20, [sp, #24]
   3f0e0:	mov	w3, #0x4                   	// #4
   3f0e4:	str	x1, [sp, #16]
   3f0e8:	mov	x0, x24
   3f0ec:	mov	x2, x20
   3f0f0:	bl	c190 <__gmpn_lshift@plt>
   3f0f4:	adds	x21, x20, #0x1
   3f0f8:	str	x0, [x24, x20, lsl #3]
   3f0fc:	b.cs	3f138 <__gmpn_toom_interpolate_7pts@@Base+0x178>  // b.hs, b.nlast
   3f100:	ldur	x2, [x29, #-8]
   3f104:	mov	x0, x22
   3f108:	mov	x1, x22
   3f10c:	mov	x3, x21
   3f110:	bl	c2e0 <__gmpn_sub_n@plt>
   3f114:	cbz	x0, 3f138 <__gmpn_toom_interpolate_7pts@@Base+0x178>
   3f118:	cmp	x21, x28
   3f11c:	b.ge	3f138 <__gmpn_toom_interpolate_7pts@@Base+0x178>  // b.tcont
   3f120:	ldr	x8, [x22, x21, lsl #3]
   3f124:	add	x10, x21, #0x1
   3f128:	sub	x9, x8, #0x1
   3f12c:	str	x9, [x22, x21, lsl #3]
   3f130:	mov	x21, x10
   3f134:	cbz	x8, 3f118 <__gmpn_toom_interpolate_7pts@@Base+0x158>
   3f138:	ldur	x24, [x29, #-16]
   3f13c:	ldr	w8, [sp, #12]
   3f140:	mov	x20, x26
   3f144:	add	x21, x26, x24, lsl #3
   3f148:	tbnz	w8, #1, 3f164 <__gmpn_toom_interpolate_7pts@@Base+0x1a4>
   3f14c:	mov	x0, x25
   3f150:	mov	x1, x21
   3f154:	mov	x2, x25
   3f158:	mov	x3, x28
   3f15c:	bl	c860 <__gmpn_rsh1sub_n@plt>
   3f160:	b	3f178 <__gmpn_toom_interpolate_7pts@@Base+0x1b8>
   3f164:	mov	x0, x25
   3f168:	mov	x1, x25
   3f16c:	mov	x2, x21
   3f170:	mov	x3, x28
   3f174:	bl	c970 <__gmpn_rsh1add_n@plt>
   3f178:	ldr	x26, [sp, #24]
   3f17c:	mov	x0, x21
   3f180:	mov	x1, x21
   3f184:	mov	x2, x25
   3f188:	mov	x3, x28
   3f18c:	bl	c2e0 <__gmpn_sub_n@plt>
   3f190:	mov	w3, #0x41                  	// #65
   3f194:	mov	x0, x23
   3f198:	mov	x1, x21
   3f19c:	mov	x2, x28
   3f1a0:	bl	ca00 <__gmpn_submul_1@plt>
   3f1a4:	cbz	x26, 3f1e4 <__gmpn_toom_interpolate_7pts@@Base+0x224>
   3f1a8:	ldr	x2, [sp, #16]
   3f1ac:	mov	x0, x21
   3f1b0:	mov	x1, x21
   3f1b4:	mov	x3, x26
   3f1b8:	bl	c2e0 <__gmpn_sub_n@plt>
   3f1bc:	cbz	x0, 3f1e4 <__gmpn_toom_interpolate_7pts@@Base+0x224>
   3f1c0:	mov	x8, x26
   3f1c4:	cmp	x8, x28
   3f1c8:	b.ge	3f1e4 <__gmpn_toom_interpolate_7pts@@Base+0x224>  // b.tcont
   3f1cc:	ldr	x9, [x21, x8, lsl #3]
   3f1d0:	add	x11, x8, #0x1
   3f1d4:	sub	x10, x9, #0x1
   3f1d8:	str	x10, [x21, x8, lsl #3]
   3f1dc:	mov	x8, x11
   3f1e0:	cbz	x9, 3f1c4 <__gmpn_toom_interpolate_7pts@@Base+0x204>
   3f1e4:	cbz	x19, 3f224 <__gmpn_toom_interpolate_7pts@@Base+0x264>
   3f1e8:	mov	x0, x21
   3f1ec:	mov	x1, x21
   3f1f0:	mov	x2, x20
   3f1f4:	mov	x3, x24
   3f1f8:	bl	c2e0 <__gmpn_sub_n@plt>
   3f1fc:	cbz	x0, 3f224 <__gmpn_toom_interpolate_7pts@@Base+0x264>
   3f200:	mov	x8, xzr
   3f204:	add	x9, x20, x19, lsl #5
   3f208:	cmp	x8, #0x8
   3f20c:	b.eq	3f224 <__gmpn_toom_interpolate_7pts@@Base+0x264>  // b.none
   3f210:	ldr	x10, [x9, x8]
   3f214:	sub	x11, x10, #0x1
   3f218:	str	x11, [x9, x8]
   3f21c:	add	x8, x8, #0x8
   3f220:	cbz	x10, 3f208 <__gmpn_toom_interpolate_7pts@@Base+0x248>
   3f224:	mov	w3, #0x2d                  	// #45
   3f228:	mov	x0, x23
   3f22c:	mov	x1, x21
   3f230:	mov	x2, x28
   3f234:	bl	d420 <__gmpn_addmul_1@plt>
   3f238:	mov	w3, #0x1                   	// #1
   3f23c:	mov	x0, x23
   3f240:	mov	x1, x23
   3f244:	mov	x2, x28
   3f248:	bl	c1b0 <__gmpn_rshift@plt>
   3f24c:	mov	x0, x22
   3f250:	mov	x1, x22
   3f254:	mov	x2, x21
   3f258:	mov	x3, x28
   3f25c:	bl	c2e0 <__gmpn_sub_n@plt>
   3f260:	mov	x3, #0x5555555555555555    	// #6148914691236517205
   3f264:	mov	x0, x22
   3f268:	mov	x1, x22
   3f26c:	mov	x2, x28
   3f270:	mov	x4, xzr
   3f274:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
   3f278:	mov	x0, x21
   3f27c:	mov	x1, x21
   3f280:	mov	x2, x22
   3f284:	mov	x3, x28
   3f288:	bl	c2e0 <__gmpn_sub_n@plt>
   3f28c:	mov	x0, x27
   3f290:	mov	x1, x23
   3f294:	mov	x2, x27
   3f298:	mov	x3, x28
   3f29c:	bl	c2e0 <__gmpn_sub_n@plt>
   3f2a0:	ldur	x24, [x29, #-8]
   3f2a4:	mov	w3, #0x3                   	// #3
   3f2a8:	mov	x1, x25
   3f2ac:	mov	x2, x28
   3f2b0:	mov	x0, x24
   3f2b4:	bl	c190 <__gmpn_lshift@plt>
   3f2b8:	mov	x2, x24
   3f2bc:	ldur	x24, [x29, #-16]
   3f2c0:	mov	x0, x23
   3f2c4:	mov	x1, x23
   3f2c8:	mov	x3, x28
   3f2cc:	bl	c2e0 <__gmpn_sub_n@plt>
   3f2d0:	mov	x4, #0x8e39                	// #36409
   3f2d4:	movk	x4, #0x38e3, lsl #16
   3f2d8:	movk	x4, #0xe38e, lsl #32
   3f2dc:	mov	w3, #0x9                   	// #9
   3f2e0:	movk	x4, #0x8e38, lsl #48
   3f2e4:	mov	x0, x23
   3f2e8:	mov	x1, x23
   3f2ec:	mov	x2, x28
   3f2f0:	mov	w5, wzr
   3f2f4:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   3f2f8:	mov	x0, x25
   3f2fc:	mov	x1, x25
   3f300:	mov	x2, x23
   3f304:	mov	x3, x28
   3f308:	bl	c2e0 <__gmpn_sub_n@plt>
   3f30c:	mov	x3, #0x1111111111111111    	// #1229782938247303441
   3f310:	mov	x0, x27
   3f314:	mov	x1, x27
   3f318:	mov	x2, x28
   3f31c:	mov	x4, xzr
   3f320:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
   3f324:	mov	x0, x27
   3f328:	mov	x1, x27
   3f32c:	mov	x2, x23
   3f330:	mov	x3, x28
   3f334:	bl	c970 <__gmpn_rsh1add_n@plt>
   3f338:	ldr	x8, [x27, x24, lsl #3]
   3f33c:	mov	x0, x23
   3f340:	mov	x1, x23
   3f344:	mov	x2, x27
   3f348:	and	x8, x8, #0x7fffffffffffffff
   3f34c:	mov	x3, x28
   3f350:	str	x8, [x27, x24, lsl #3]
   3f354:	bl	c2e0 <__gmpn_sub_n@plt>
   3f358:	add	x0, x20, x19, lsl #3
   3f35c:	mov	x1, x0
   3f360:	mov	x2, x27
   3f364:	mov	x3, x28
   3f368:	bl	ca90 <__gmpn_add_n@plt>
   3f36c:	add	x8, x21, x19, lsl #3
   3f370:	ldr	x9, [x8, #8]
   3f374:	adds	x9, x9, x0
   3f378:	str	x9, [x8, #8]
   3f37c:	b.cc	3f39c <__gmpn_toom_interpolate_7pts@@Base+0x3dc>  // b.lo, b.ul, b.last
   3f380:	mov	w8, #0x18                  	// #24
   3f384:	madd	x8, x19, x8, x20
   3f388:	add	x8, x8, #0x10
   3f38c:	ldr	x9, [x8]
   3f390:	adds	x9, x9, #0x1
   3f394:	str	x9, [x8], #8
   3f398:	b.cs	3f38c <__gmpn_toom_interpolate_7pts@@Base+0x3cc>  // b.hs, b.nlast
   3f39c:	mov	w8, #0x18                  	// #24
   3f3a0:	madd	x0, x19, x8, x20
   3f3a4:	mov	x1, x0
   3f3a8:	mov	x2, x25
   3f3ac:	mov	x3, x19
   3f3b0:	bl	ca90 <__gmpn_add_n@plt>
   3f3b4:	add	x1, x25, x19, lsl #3
   3f3b8:	ldr	x8, [x21, x24, lsl #3]
   3f3bc:	ldr	x9, [x1]
   3f3c0:	add	x8, x8, x0
   3f3c4:	add	x8, x9, x8
   3f3c8:	str	x8, [x1]
   3f3cc:	ldr	x9, [x21, x24, lsl #3]
   3f3d0:	add	x9, x9, x0
   3f3d4:	cmp	x8, x9
   3f3d8:	b.cs	3f3f0 <__gmpn_toom_interpolate_7pts@@Base+0x430>  // b.hs, b.nlast
   3f3dc:	add	x8, x1, #0x8
   3f3e0:	ldr	x9, [x8]
   3f3e4:	adds	x9, x9, #0x1
   3f3e8:	str	x9, [x8], #8
   3f3ec:	b.cs	3f3e0 <__gmpn_toom_interpolate_7pts@@Base+0x420>  // b.hs, b.nlast
   3f3f0:	add	x0, x20, x19, lsl #5
   3f3f4:	mov	x2, x22
   3f3f8:	mov	x3, x19
   3f3fc:	bl	ca90 <__gmpn_add_n@plt>
   3f400:	add	x1, x22, x19, lsl #3
   3f404:	ldr	x8, [x25, x24, lsl #3]
   3f408:	ldr	x9, [x1]
   3f40c:	add	x8, x8, x0
   3f410:	add	x8, x9, x8
   3f414:	str	x8, [x1]
   3f418:	ldr	x9, [x25, x24, lsl #3]
   3f41c:	add	x9, x9, x0
   3f420:	cmp	x8, x9
   3f424:	b.cs	3f43c <__gmpn_toom_interpolate_7pts@@Base+0x47c>  // b.hs, b.nlast
   3f428:	add	x8, x1, #0x8
   3f42c:	ldr	x9, [x8]
   3f430:	adds	x9, x9, #0x1
   3f434:	str	x9, [x8], #8
   3f438:	b.cs	3f42c <__gmpn_toom_interpolate_7pts@@Base+0x46c>  // b.hs, b.nlast
   3f43c:	mov	w8, #0x28                  	// #40
   3f440:	madd	x0, x19, x8, x20
   3f444:	mov	x2, x23
   3f448:	mov	x3, x19
   3f44c:	bl	ca90 <__gmpn_add_n@plt>
   3f450:	add	x2, x23, x19, lsl #3
   3f454:	ldr	x8, [x22, x24, lsl #3]
   3f458:	ldr	x9, [x2]
   3f45c:	add	x8, x8, x0
   3f460:	add	x8, x9, x8
   3f464:	str	x8, [x2]
   3f468:	ldr	x9, [x22, x24, lsl #3]
   3f46c:	add	x9, x9, x0
   3f470:	cmp	x8, x9
   3f474:	b.cs	3f48c <__gmpn_toom_interpolate_7pts@@Base+0x4cc>  // b.hs, b.nlast
   3f478:	add	x8, x2, #0x8
   3f47c:	ldr	x9, [x8]
   3f480:	adds	x9, x9, #0x1
   3f484:	str	x9, [x8], #8
   3f488:	b.cs	3f47c <__gmpn_toom_interpolate_7pts@@Base+0x4bc>  // b.hs, b.nlast
   3f48c:	add	x3, x19, #0x1
   3f490:	cmp	x3, x26
   3f494:	b.ge	3f4f8 <__gmpn_toom_interpolate_7pts@@Base+0x538>  // b.tcont
   3f498:	ldr	x0, [sp, #16]
   3f49c:	mov	x1, x0
   3f4a0:	bl	ca90 <__gmpn_add_n@plt>
   3f4a4:	mov	w8, #0x38                  	// #56
   3f4a8:	madd	x8, x19, x8, x20
   3f4ac:	ldr	x9, [x8, #8]
   3f4b0:	adds	x9, x9, x0
   3f4b4:	str	x9, [x8, #8]
   3f4b8:	b.cc	3f4d8 <__gmpn_toom_interpolate_7pts@@Base+0x518>  // b.lo, b.ul, b.last
   3f4bc:	mov	w8, #0x38                  	// #56
   3f4c0:	madd	x8, x19, x8, x20
   3f4c4:	add	x8, x8, #0x10
   3f4c8:	ldr	x9, [x8]
   3f4cc:	adds	x9, x9, #0x1
   3f4d0:	str	x9, [x8], #8
   3f4d4:	b.cs	3f4c8 <__gmpn_toom_interpolate_7pts@@Base+0x508>  // b.hs, b.nlast
   3f4d8:	ldp	x20, x19, [sp, #128]
   3f4dc:	ldp	x22, x21, [sp, #112]
   3f4e0:	ldp	x24, x23, [sp, #96]
   3f4e4:	ldp	x26, x25, [sp, #80]
   3f4e8:	ldp	x28, x27, [sp, #64]
   3f4ec:	ldp	x29, x30, [sp, #48]
   3f4f0:	add	sp, sp, #0x90
   3f4f4:	ret
   3f4f8:	ldr	x0, [sp, #16]
   3f4fc:	mov	x3, x26
   3f500:	ldp	x20, x19, [sp, #128]
   3f504:	ldp	x22, x21, [sp, #112]
   3f508:	ldp	x24, x23, [sp, #96]
   3f50c:	ldp	x26, x25, [sp, #80]
   3f510:	ldp	x28, x27, [sp, #64]
   3f514:	ldp	x29, x30, [sp, #48]
   3f518:	mov	x1, x0
   3f51c:	add	sp, sp, #0x90
   3f520:	b	ca90 <__gmpn_add_n@plt>

000000000003f524 <__gmpn_toom_interpolate_8pts@@Base>:
   3f524:	sub	sp, sp, #0x80
   3f528:	stp	x29, x30, [sp, #32]
   3f52c:	stp	x28, x27, [sp, #48]
   3f530:	stp	x26, x25, [sp, #64]
   3f534:	stp	x24, x23, [sp, #80]
   3f538:	stp	x22, x21, [sp, #96]
   3f53c:	stp	x20, x19, [sp, #112]
   3f540:	add	x28, x2, x1, lsl #3
   3f544:	ldr	x8, [x0]
   3f548:	ldr	x9, [x28]
   3f54c:	mov	w10, #0x38                  	// #56
   3f550:	mov	x23, x5
   3f554:	mov	x22, x4
   3f558:	sub	x8, x9, x8, lsr #4
   3f55c:	str	x8, [x28]
   3f560:	ldr	x8, [x0]
   3f564:	mov	x26, x3
   3f568:	mov	x21, x2
   3f56c:	mov	x19, x1
   3f570:	mov	x20, x0
   3f574:	cmp	x9, x8, lsr #4
   3f578:	madd	x8, x1, x10, x0
   3f57c:	add	x29, sp, #0x20
   3f580:	str	x8, [sp, #8]
   3f584:	b.cs	3f59c <__gmpn_toom_interpolate_8pts@@Base+0x78>  // b.hs, b.nlast
   3f588:	add	x8, x28, #0x8
   3f58c:	ldr	x9, [x8]
   3f590:	sub	x10, x9, #0x1
   3f594:	str	x10, [x8], #8
   3f598:	cbz	x9, 3f58c <__gmpn_toom_interpolate_8pts@@Base+0x68>
   3f59c:	add	x8, x19, x19, lsl #1
   3f5a0:	str	x8, [sp, #16]
   3f5a4:	lsl	x8, x19, #1
   3f5a8:	add	x25, x20, #0x8
   3f5ac:	sub	x24, x8, #0x1
   3f5b0:	mov	w3, #0x3c                  	// #60
   3f5b4:	mov	x0, x23
   3f5b8:	mov	x1, x25
   3f5bc:	mov	x2, x24
   3f5c0:	stur	x8, [x29, #-8]
   3f5c4:	bl	c190 <__gmpn_lshift@plt>
   3f5c8:	mov	x27, x0
   3f5cc:	mov	x0, x28
   3f5d0:	mov	x1, x28
   3f5d4:	mov	x2, x23
   3f5d8:	mov	x3, x24
   3f5dc:	bl	c2e0 <__gmpn_sub_n@plt>
   3f5e0:	add	x8, x28, x19, lsl #4
   3f5e4:	ldur	x9, [x8, #-8]
   3f5e8:	add	x10, x0, x27
   3f5ec:	str	x28, [sp]
   3f5f0:	subs	x9, x9, x10
   3f5f4:	stur	x9, [x8, #-8]
   3f5f8:	b.cs	3f60c <__gmpn_toom_interpolate_8pts@@Base+0xe8>  // b.hs, b.nlast
   3f5fc:	ldr	x9, [x8]
   3f600:	sub	x10, x9, #0x1
   3f604:	str	x10, [x8], #8
   3f608:	cbz	x9, 3f5fc <__gmpn_toom_interpolate_8pts@@Base+0xd8>
   3f60c:	ldp	x1, x8, [sp, #8]
   3f610:	mov	w3, #0xc                   	// #12
   3f614:	mov	x0, x23
   3f618:	mov	x2, x22
   3f61c:	add	x28, x20, x8, lsl #3
   3f620:	bl	c190 <__gmpn_lshift@plt>
   3f624:	mov	x27, x0
   3f628:	mov	x0, x21
   3f62c:	mov	x1, x21
   3f630:	mov	x2, x23
   3f634:	mov	x3, x22
   3f638:	bl	c2e0 <__gmpn_sub_n@plt>
   3f63c:	ldr	x8, [x21, x22, lsl #3]
   3f640:	add	x9, x0, x27
   3f644:	subs	x8, x8, x9
   3f648:	str	x8, [x21, x22, lsl #3]
   3f64c:	b.cs	3f668 <__gmpn_toom_interpolate_8pts@@Base+0x144>  // b.hs, b.nlast
   3f650:	add	x8, x21, x22, lsl #3
   3f654:	add	x8, x8, #0x8
   3f658:	ldr	x9, [x8]
   3f65c:	sub	x10, x9, #0x1
   3f660:	str	x10, [x8], #8
   3f664:	cbz	x9, 3f658 <__gmpn_toom_interpolate_8pts@@Base+0x134>
   3f668:	add	x27, x28, x19, lsl #3
   3f66c:	ldr	x8, [x20]
   3f670:	ldr	x9, [x27]
   3f674:	sub	x8, x9, x8, lsr #2
   3f678:	str	x8, [x27]
   3f67c:	ldr	x8, [x20]
   3f680:	cmp	x9, x8, lsr #2
   3f684:	b.cs	3f6a0 <__gmpn_toom_interpolate_8pts@@Base+0x17c>  // b.hs, b.nlast
   3f688:	add	x8, x20, x19, lsl #5
   3f68c:	add	x8, x8, #0x8
   3f690:	ldr	x9, [x8]
   3f694:	sub	x10, x9, #0x1
   3f698:	str	x10, [x8], #8
   3f69c:	cbz	x9, 3f690 <__gmpn_toom_interpolate_8pts@@Base+0x16c>
   3f6a0:	mov	w3, #0x3e                  	// #62
   3f6a4:	mov	x0, x23
   3f6a8:	mov	x1, x25
   3f6ac:	mov	x2, x24
   3f6b0:	bl	c190 <__gmpn_lshift@plt>
   3f6b4:	mov	x25, x0
   3f6b8:	mov	x0, x27
   3f6bc:	mov	x1, x27
   3f6c0:	mov	x2, x23
   3f6c4:	mov	x3, x24
   3f6c8:	bl	c2e0 <__gmpn_sub_n@plt>
   3f6cc:	ldur	x8, [x29, #-8]
   3f6d0:	add	x10, x0, x25
   3f6d4:	add	x8, x27, x8, lsl #3
   3f6d8:	ldur	x9, [x8, #-8]
   3f6dc:	subs	x9, x9, x10
   3f6e0:	stur	x9, [x8, #-8]
   3f6e4:	b.cs	3f6f8 <__gmpn_toom_interpolate_8pts@@Base+0x1d4>  // b.hs, b.nlast
   3f6e8:	ldr	x9, [x8]
   3f6ec:	sub	x10, x9, #0x1
   3f6f0:	str	x10, [x8], #8
   3f6f4:	cbz	x9, 3f6e8 <__gmpn_toom_interpolate_8pts@@Base+0x1c4>
   3f6f8:	ldr	x1, [sp, #8]
   3f6fc:	mov	w3, #0x6                   	// #6
   3f700:	mov	x0, x23
   3f704:	mov	x2, x22
   3f708:	bl	c190 <__gmpn_lshift@plt>
   3f70c:	mov	x24, x0
   3f710:	mov	x0, x28
   3f714:	mov	x1, x28
   3f718:	mov	x2, x23
   3f71c:	mov	x3, x22
   3f720:	bl	c2e0 <__gmpn_sub_n@plt>
   3f724:	ldr	x8, [x28, x22, lsl #3]
   3f728:	add	x9, x0, x24
   3f72c:	subs	x8, x8, x9
   3f730:	str	x8, [x28, x22, lsl #3]
   3f734:	b.cs	3f758 <__gmpn_toom_interpolate_8pts@@Base+0x234>  // b.hs, b.nlast
   3f738:	add	x8, x19, x19, lsl #1
   3f73c:	add	x8, x22, x8
   3f740:	add	x8, x20, x8, lsl #3
   3f744:	add	x8, x8, #0x8
   3f748:	ldr	x9, [x8]
   3f74c:	sub	x10, x9, #0x1
   3f750:	str	x10, [x8], #8
   3f754:	cbz	x9, 3f748 <__gmpn_toom_interpolate_8pts@@Base+0x224>
   3f758:	ldur	x3, [x29, #-8]
   3f75c:	add	x23, x26, x19, lsl #3
   3f760:	mov	x0, x23
   3f764:	mov	x1, x23
   3f768:	mov	x2, x20
   3f76c:	bl	c2e0 <__gmpn_sub_n@plt>
   3f770:	ldp	x2, x9, [sp, #8]
   3f774:	mov	x1, x26
   3f778:	mov	x3, x22
   3f77c:	ldr	x8, [x26, x9, lsl #3]
   3f780:	sub	x8, x8, x0
   3f784:	mov	x0, x26
   3f788:	str	x8, [x26, x9, lsl #3]
   3f78c:	bl	c2e0 <__gmpn_sub_n@plt>
   3f790:	ldr	x8, [x26, x22, lsl #3]
   3f794:	subs	x8, x8, x0
   3f798:	str	x8, [x26, x22, lsl #3]
   3f79c:	b.cs	3f7b8 <__gmpn_toom_interpolate_8pts@@Base+0x294>  // b.hs, b.nlast
   3f7a0:	add	x8, x26, x22, lsl #3
   3f7a4:	add	x8, x8, #0x8
   3f7a8:	ldr	x9, [x8]
   3f7ac:	sub	x10, x9, #0x1
   3f7b0:	str	x10, [x8], #8
   3f7b4:	cbz	x9, 3f7a8 <__gmpn_toom_interpolate_8pts@@Base+0x284>
   3f7b8:	ldr	x8, [sp, #16]
   3f7bc:	mov	x0, x21
   3f7c0:	mov	x1, x21
   3f7c4:	mov	x2, x28
   3f7c8:	add	x24, x8, #0x1
   3f7cc:	mov	x3, x24
   3f7d0:	bl	c2e0 <__gmpn_sub_n@plt>
   3f7d4:	mov	w3, #0x2                   	// #2
   3f7d8:	mov	x0, x21
   3f7dc:	mov	x1, x21
   3f7e0:	mov	x2, x24
   3f7e4:	bl	c1b0 <__gmpn_rshift@plt>
   3f7e8:	mov	x0, x28
   3f7ec:	mov	x1, x28
   3f7f0:	mov	x2, x26
   3f7f4:	mov	x3, x24
   3f7f8:	bl	c2e0 <__gmpn_sub_n@plt>
   3f7fc:	mov	x0, x21
   3f800:	mov	x1, x21
   3f804:	mov	x2, x28
   3f808:	mov	x3, x24
   3f80c:	bl	c2e0 <__gmpn_sub_n@plt>
   3f810:	mov	x4, #0x4fa5                	// #20389
   3f814:	movk	x4, #0xa4fa, lsl #16
   3f818:	movk	x4, #0xfa4f, lsl #32
   3f81c:	mov	w3, #0x2d                  	// #45
   3f820:	movk	x4, #0x4fa4, lsl #48
   3f824:	mov	x0, x21
   3f828:	mov	x1, x21
   3f82c:	mov	x2, x24
   3f830:	mov	w5, wzr
   3f834:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   3f838:	mov	x3, #0x5555555555555555    	// #6148914691236517205
   3f83c:	mov	x0, x28
   3f840:	mov	x1, x28
   3f844:	mov	x2, x24
   3f848:	mov	x4, xzr
   3f84c:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
   3f850:	mov	x0, x28
   3f854:	mov	x1, x28
   3f858:	mov	x2, x21
   3f85c:	mov	x3, x24
   3f860:	bl	c170 <__gmpn_sublsh2_n@plt>
   3f864:	add	x24, x20, x19, lsl #3
   3f868:	mov	x0, x24
   3f86c:	mov	x1, x24
   3f870:	mov	x2, x26
   3f874:	mov	x3, x19
   3f878:	bl	ca90 <__gmpn_add_n@plt>
   3f87c:	mov	x25, x0
   3f880:	mov	x0, x24
   3f884:	mov	x1, x24
   3f888:	mov	x2, x28
   3f88c:	mov	x3, x19
   3f890:	bl	c2e0 <__gmpn_sub_n@plt>
   3f894:	sub	x8, x25, x0
   3f898:	cmp	x8, #0x1
   3f89c:	b.lt	3f8b8 <__gmpn_toom_interpolate_8pts@@Base+0x394>  // b.tstop
   3f8a0:	mov	x8, x23
   3f8a4:	ldr	x9, [x8]
   3f8a8:	adds	x9, x9, #0x1
   3f8ac:	str	x9, [x8], #8
   3f8b0:	b.cs	3f8a4 <__gmpn_toom_interpolate_8pts@@Base+0x380>  // b.hs, b.nlast
   3f8b4:	mov	x8, xzr
   3f8b8:	ldur	x24, [x29, #-8]
   3f8bc:	neg	x4, x8
   3f8c0:	mov	x1, x23
   3f8c4:	mov	x2, x27
   3f8c8:	add	x0, x20, x24, lsl #3
   3f8cc:	mov	x3, x19
   3f8d0:	bl	c780 <__gmpn_sub_nc@plt>
   3f8d4:	add	x2, x26, x24, lsl #3
   3f8d8:	ldr	x8, [x2]
   3f8dc:	subs	x8, x8, x0
   3f8e0:	str	x8, [x2]
   3f8e4:	b.cs	3f900 <__gmpn_toom_interpolate_8pts@@Base+0x3dc>  // b.hs, b.nlast
   3f8e8:	add	x8, x26, x19, lsl #4
   3f8ec:	add	x8, x8, #0x8
   3f8f0:	ldr	x9, [x8]
   3f8f4:	sub	x10, x9, #0x1
   3f8f8:	str	x10, [x8], #8
   3f8fc:	cbz	x9, 3f8f0 <__gmpn_toom_interpolate_8pts@@Base+0x3cc>
   3f900:	add	x23, x19, #0x1
   3f904:	mov	x0, x28
   3f908:	mov	x1, x28
   3f90c:	mov	x3, x23
   3f910:	bl	ca90 <__gmpn_add_n@plt>
   3f914:	ldur	x8, [x29, #-8]
   3f918:	mov	x24, x0
   3f91c:	mov	x2, x21
   3f920:	mov	x3, x19
   3f924:	add	x25, x28, x8, lsl #3
   3f928:	mov	x0, x25
   3f92c:	mov	x1, x25
   3f930:	bl	ca90 <__gmpn_add_n@plt>
   3f934:	ldr	x9, [sp, #16]
   3f938:	mov	x1, x28
   3f93c:	mov	x2, x25
   3f940:	mov	x3, x23
   3f944:	ldr	x8, [x28, x9, lsl #3]
   3f948:	add	x8, x8, x0
   3f94c:	mov	x0, x28
   3f950:	str	x8, [x28, x9, lsl #3]
   3f954:	bl	c2e0 <__gmpn_sub_n@plt>
   3f958:	subs	x8, x24, x0
   3f95c:	b.mi	3fafc <__gmpn_toom_interpolate_8pts@@Base+0x5d8>  // b.first
   3f960:	ldr	x9, [x27, #8]
   3f964:	ldr	x23, [sp]
   3f968:	adds	x8, x9, x8
   3f96c:	str	x8, [x27, #8]
   3f970:	b.cc	3f98c <__gmpn_toom_interpolate_8pts@@Base+0x468>  // b.lo, b.ul, b.last
   3f974:	add	x8, x20, x19, lsl #5
   3f978:	add	x8, x8, #0x10
   3f97c:	ldr	x9, [x8]
   3f980:	adds	x9, x9, #0x1
   3f984:	str	x9, [x8], #8
   3f988:	b.cs	3f97c <__gmpn_toom_interpolate_8pts@@Base+0x458>  // b.hs, b.nlast
   3f98c:	ldur	x8, [x29, #-8]
   3f990:	add	x0, x20, x19, lsl #5
   3f994:	mov	x1, x27
   3f998:	mov	x2, x23
   3f99c:	orr	x3, x8, #0x1
   3f9a0:	bl	c2e0 <__gmpn_sub_n@plt>
   3f9a4:	mov	w8, #0x30                  	// #48
   3f9a8:	madd	x11, x19, x8, x20
   3f9ac:	ldr	x8, [x11]
   3f9b0:	ldr	x9, [x23]
   3f9b4:	adds	x8, x9, x8
   3f9b8:	str	x8, [x11]
   3f9bc:	b.cc	3fa20 <__gmpn_toom_interpolate_8pts@@Base+0x4fc>  // b.lo, b.ul, b.last
   3f9c0:	mov	w9, #0x30                  	// #48
   3f9c4:	add	x8, x21, x19, lsl #3
   3f9c8:	madd	x9, x19, x9, x20
   3f9cc:	add	x8, x8, #0x8
   3f9d0:	add	x9, x9, #0x8
   3f9d4:	mov	w10, #0x1                   	// #1
   3f9d8:	cmp	x10, x19
   3f9dc:	b.ge	3fa64 <__gmpn_toom_interpolate_8pts@@Base+0x540>  // b.tcont
   3f9e0:	ldr	x12, [x8], #8
   3f9e4:	add	x10, x10, #0x1
   3f9e8:	adds	x12, x12, #0x1
   3f9ec:	str	x12, [x9], #8
   3f9f0:	b.cs	3f9d8 <__gmpn_toom_interpolate_8pts@@Base+0x4b4>  // b.hs, b.nlast
   3f9f4:	cmp	x23, x11
   3f9f8:	b.eq	3fa58 <__gmpn_toom_interpolate_8pts@@Base+0x534>  // b.none
   3f9fc:	cmp	x10, x19
   3fa00:	b.ge	3fa58 <__gmpn_toom_interpolate_8pts@@Base+0x534>  // b.tcont
   3fa04:	mov	x11, x19
   3fa08:	ldr	x12, [x8], #8
   3fa0c:	sub	x11, x11, #0x1
   3fa10:	cmp	x10, x11
   3fa14:	str	x12, [x9], #8
   3fa18:	b.ne	3fa08 <__gmpn_toom_interpolate_8pts@@Base+0x4e4>  // b.any
   3fa1c:	b	3fa58 <__gmpn_toom_interpolate_8pts@@Base+0x534>
   3fa20:	cmp	x19, #0x2
   3fa24:	b.lt	3fa58 <__gmpn_toom_interpolate_8pts@@Base+0x534>  // b.tstop
   3fa28:	cmp	x23, x11
   3fa2c:	b.eq	3fa58 <__gmpn_toom_interpolate_8pts@@Base+0x534>  // b.none
   3fa30:	mov	w9, #0x30                  	// #48
   3fa34:	add	x10, x21, x19, lsl #3
   3fa38:	madd	x9, x19, x9, x20
   3fa3c:	sub	x8, x19, #0x1
   3fa40:	add	x9, x9, #0x8
   3fa44:	add	x10, x10, #0x8
   3fa48:	ldr	x11, [x10], #8
   3fa4c:	subs	x8, x8, #0x1
   3fa50:	str	x11, [x9], #8
   3fa54:	b.ne	3fa48 <__gmpn_toom_interpolate_8pts@@Base+0x524>  // b.any
   3fa58:	ldur	x8, [x29, #-8]
   3fa5c:	add	x2, x21, x8, lsl #3
   3fa60:	b	3fa80 <__gmpn_toom_interpolate_8pts@@Base+0x55c>
   3fa64:	ldur	x8, [x29, #-8]
   3fa68:	add	x2, x21, x8, lsl #3
   3fa6c:	mov	x8, x2
   3fa70:	ldr	x9, [x8]
   3fa74:	adds	x9, x9, #0x1
   3fa78:	str	x9, [x8], #8
   3fa7c:	b.cs	3fa70 <__gmpn_toom_interpolate_8pts@@Base+0x54c>  // b.hs, b.nlast
   3fa80:	ldr	x0, [sp, #8]
   3fa84:	mov	x3, x19
   3fa88:	mov	x1, x0
   3fa8c:	bl	ca90 <__gmpn_add_n@plt>
   3fa90:	cmp	x22, x19
   3fa94:	b.eq	3fadc <__gmpn_toom_interpolate_8pts@@Base+0x5b8>  // b.none
   3fa98:	ldr	x11, [sp, #16]
   3fa9c:	lsl	x8, x19, #6
   3faa0:	ldr	x10, [x20, x8]
   3faa4:	ldr	x9, [x21, x11, lsl #3]
   3faa8:	add	x9, x9, x0
   3faac:	add	x9, x10, x9
   3fab0:	str	x9, [x20, x8]
   3fab4:	ldr	x8, [x21, x11, lsl #3]
   3fab8:	add	x8, x8, x0
   3fabc:	cmp	x9, x8
   3fac0:	b.cs	3fadc <__gmpn_toom_interpolate_8pts@@Base+0x5b8>  // b.hs, b.nlast
   3fac4:	add	x8, x20, x19, lsl #6
   3fac8:	add	x8, x8, #0x8
   3facc:	ldr	x9, [x8]
   3fad0:	adds	x9, x9, #0x1
   3fad4:	str	x9, [x8], #8
   3fad8:	b.cs	3facc <__gmpn_toom_interpolate_8pts@@Base+0x5a8>  // b.hs, b.nlast
   3fadc:	ldp	x20, x19, [sp, #112]
   3fae0:	ldp	x22, x21, [sp, #96]
   3fae4:	ldp	x24, x23, [sp, #80]
   3fae8:	ldp	x26, x25, [sp, #64]
   3faec:	ldp	x28, x27, [sp, #48]
   3faf0:	ldp	x29, x30, [sp, #32]
   3faf4:	add	sp, sp, #0x80
   3faf8:	ret
   3fafc:	ldr	x23, [sp]
   3fb00:	add	x8, x20, x19, lsl #5
   3fb04:	add	x8, x8, #0x8
   3fb08:	ldr	x9, [x8]
   3fb0c:	sub	x10, x9, #0x1
   3fb10:	str	x10, [x8], #8
   3fb14:	cbz	x9, 3fb08 <__gmpn_toom_interpolate_8pts@@Base+0x5e4>
   3fb18:	b	3f98c <__gmpn_toom_interpolate_8pts@@Base+0x468>

000000000003fb1c <__gmpn_toom_interpolate_12pts@@Base>:
   3fb1c:	sub	sp, sp, #0xc0
   3fb20:	stp	x29, x30, [sp, #96]
   3fb24:	stp	x28, x27, [sp, #112]
   3fb28:	stp	x26, x25, [sp, #128]
   3fb2c:	stp	x22, x21, [sp, #160]
   3fb30:	stp	x20, x19, [sp, #176]
   3fb34:	add	x29, sp, #0x60
   3fb38:	mov	x21, x4
   3fb3c:	mov	x28, x2
   3fb40:	mov	x26, x1
   3fb44:	mov	x20, x0
   3fb48:	add	x22, x4, x4, lsl #1
   3fb4c:	lsl	x8, x4, #3
   3fb50:	stp	x24, x23, [sp, #144]
   3fb54:	stp	x3, x7, [x29, #-16]
   3fb58:	str	x8, [sp, #16]
   3fb5c:	stur	x22, [x29, #-24]
   3fb60:	str	w6, [sp, #44]
   3fb64:	stur	x5, [x29, #-40]
   3fb68:	cbz	w6, 3fdc0 <__gmpn_toom_interpolate_12pts@@Base+0x2a4>
   3fb6c:	mov	w8, #0x58                  	// #88
   3fb70:	madd	x23, x21, x8, x20
   3fb74:	mov	x0, x28
   3fb78:	mov	x1, x28
   3fb7c:	mov	x2, x23
   3fb80:	mov	x3, x5
   3fb84:	mov	x25, x5
   3fb88:	bl	c2e0 <__gmpn_sub_n@plt>
   3fb8c:	ldr	x8, [x28, x25, lsl #3]
   3fb90:	subs	x8, x8, x0
   3fb94:	str	x8, [x28, x25, lsl #3]
   3fb98:	b.cs	3fbb4 <__gmpn_toom_interpolate_12pts@@Base+0x98>  // b.hs, b.nlast
   3fb9c:	add	x8, x28, x25, lsl #3
   3fba0:	add	x8, x8, #0x8
   3fba4:	ldr	x9, [x8]
   3fba8:	sub	x10, x9, #0x1
   3fbac:	str	x10, [x8], #8
   3fbb0:	cbz	x9, 3fba4 <__gmpn_toom_interpolate_12pts@@Base+0x88>
   3fbb4:	ldur	x24, [x29, #-8]
   3fbb8:	mov	w8, #0x38                  	// #56
   3fbbc:	mov	w3, #0xa                   	// #10
   3fbc0:	mov	x1, x23
   3fbc4:	mov	x0, x24
   3fbc8:	mov	x2, x25
   3fbcc:	madd	x19, x21, x8, x20
   3fbd0:	bl	c190 <__gmpn_lshift@plt>
   3fbd4:	mov	x22, x0
   3fbd8:	mov	x0, x19
   3fbdc:	mov	x1, x19
   3fbe0:	mov	x2, x24
   3fbe4:	mov	x3, x25
   3fbe8:	bl	c2e0 <__gmpn_sub_n@plt>
   3fbec:	ldr	x8, [x19, x25, lsl #3]
   3fbf0:	add	x9, x0, x22
   3fbf4:	subs	x8, x8, x9
   3fbf8:	str	x8, [x19, x25, lsl #3]
   3fbfc:	b.cs	3fc24 <__gmpn_toom_interpolate_12pts@@Base+0x108>  // b.hs, b.nlast
   3fc00:	ldr	x8, [sp, #16]
   3fc04:	sub	x8, x8, x21
   3fc08:	add	x8, x25, x8
   3fc0c:	add	x8, x20, x8, lsl #3
   3fc10:	add	x8, x8, #0x8
   3fc14:	ldr	x9, [x8]
   3fc18:	sub	x10, x9, #0x1
   3fc1c:	str	x10, [x8], #8
   3fc20:	cbz	x9, 3fc14 <__gmpn_toom_interpolate_12pts@@Base+0xf8>
   3fc24:	ldur	x10, [x29, #-16]
   3fc28:	ldr	x8, [x23]
   3fc2c:	ldr	x9, [x10]
   3fc30:	sub	x8, x9, x8, lsr #2
   3fc34:	str	x8, [x10]
   3fc38:	ldr	x8, [x23]
   3fc3c:	cmp	x9, x8, lsr #2
   3fc40:	b.cs	3fc5c <__gmpn_toom_interpolate_12pts@@Base+0x140>  // b.hs, b.nlast
   3fc44:	ldur	x8, [x29, #-16]
   3fc48:	add	x8, x8, #0x8
   3fc4c:	ldr	x9, [x8]
   3fc50:	sub	x10, x9, #0x1
   3fc54:	str	x10, [x8], #8
   3fc58:	cbz	x9, 3fc4c <__gmpn_toom_interpolate_12pts@@Base+0x130>
   3fc5c:	ldur	x22, [x29, #-8]
   3fc60:	add	x24, x23, #0x8
   3fc64:	sub	x25, x25, #0x1
   3fc68:	mov	w3, #0x3e                  	// #62
   3fc6c:	mov	x0, x22
   3fc70:	mov	x1, x24
   3fc74:	mov	x2, x25
   3fc78:	bl	c190 <__gmpn_lshift@plt>
   3fc7c:	ldur	x27, [x29, #-16]
   3fc80:	mov	x19, x0
   3fc84:	mov	x2, x22
   3fc88:	mov	x3, x25
   3fc8c:	mov	x0, x27
   3fc90:	mov	x1, x27
   3fc94:	bl	c2e0 <__gmpn_sub_n@plt>
   3fc98:	ldur	x8, [x29, #-40]
   3fc9c:	add	x10, x0, x19
   3fca0:	add	x8, x27, x8, lsl #3
   3fca4:	ldur	x9, [x8, #-8]
   3fca8:	ldur	x27, [x29, #-40]
   3fcac:	subs	x9, x9, x10
   3fcb0:	stur	x9, [x8, #-8]
   3fcb4:	b.cs	3fcc8 <__gmpn_toom_interpolate_12pts@@Base+0x1ac>  // b.hs, b.nlast
   3fcb8:	ldr	x9, [x8]
   3fcbc:	sub	x10, x9, #0x1
   3fcc0:	str	x10, [x8], #8
   3fcc4:	cbz	x9, 3fcb8 <__gmpn_toom_interpolate_12pts@@Base+0x19c>
   3fcc8:	ldur	x22, [x29, #-8]
   3fccc:	mov	w3, #0x14                  	// #20
   3fcd0:	mov	x1, x23
   3fcd4:	mov	x2, x27
   3fcd8:	mov	x0, x22
   3fcdc:	bl	c190 <__gmpn_lshift@plt>
   3fce0:	mov	x19, x0
   3fce4:	mov	x0, x26
   3fce8:	mov	x1, x26
   3fcec:	mov	x2, x22
   3fcf0:	mov	x3, x27
   3fcf4:	bl	c2e0 <__gmpn_sub_n@plt>
   3fcf8:	ldr	x8, [x26, x27, lsl #3]
   3fcfc:	add	x9, x0, x19
   3fd00:	subs	x8, x8, x9
   3fd04:	str	x8, [x26, x27, lsl #3]
   3fd08:	b.cs	3fd24 <__gmpn_toom_interpolate_12pts@@Base+0x208>  // b.hs, b.nlast
   3fd0c:	add	x8, x26, x27, lsl #3
   3fd10:	add	x8, x8, #0x8
   3fd14:	ldr	x9, [x8]
   3fd18:	sub	x10, x9, #0x1
   3fd1c:	str	x10, [x8], #8
   3fd20:	cbz	x9, 3fd14 <__gmpn_toom_interpolate_12pts@@Base+0x1f8>
   3fd24:	ldur	x8, [x29, #-24]
   3fd28:	add	x19, x20, x8, lsl #3
   3fd2c:	ldr	x8, [x23]
   3fd30:	ldr	x9, [x19]
   3fd34:	sub	x8, x9, x8, lsr #4
   3fd38:	str	x8, [x19]
   3fd3c:	ldr	x8, [x23]
   3fd40:	cmp	x9, x8, lsr #4
   3fd44:	b.cs	3fd64 <__gmpn_toom_interpolate_12pts@@Base+0x248>  // b.hs, b.nlast
   3fd48:	mov	w8, #0x18                  	// #24
   3fd4c:	madd	x8, x21, x8, x20
   3fd50:	add	x8, x8, #0x8
   3fd54:	ldr	x9, [x8]
   3fd58:	sub	x10, x9, #0x1
   3fd5c:	str	x10, [x8], #8
   3fd60:	cbz	x9, 3fd54 <__gmpn_toom_interpolate_12pts@@Base+0x238>
   3fd64:	ldur	x23, [x29, #-8]
   3fd68:	mov	w3, #0x3c                  	// #60
   3fd6c:	mov	x1, x24
   3fd70:	mov	x2, x25
   3fd74:	mov	x0, x23
   3fd78:	bl	c190 <__gmpn_lshift@plt>
   3fd7c:	mov	x22, x0
   3fd80:	mov	x0, x19
   3fd84:	mov	x1, x19
   3fd88:	mov	x2, x23
   3fd8c:	mov	x3, x25
   3fd90:	bl	c2e0 <__gmpn_sub_n@plt>
   3fd94:	add	x8, x19, x27, lsl #3
   3fd98:	ldur	x9, [x8, #-8]
   3fd9c:	add	x10, x0, x22
   3fda0:	ldur	x22, [x29, #-24]
   3fda4:	subs	x9, x9, x10
   3fda8:	stur	x9, [x8, #-8]
   3fdac:	b.cs	3fdc0 <__gmpn_toom_interpolate_12pts@@Base+0x2a4>  // b.hs, b.nlast
   3fdb0:	ldr	x9, [x8]
   3fdb4:	sub	x10, x9, #0x1
   3fdb8:	str	x10, [x8], #8
   3fdbc:	cbz	x9, 3fdb0 <__gmpn_toom_interpolate_12pts@@Base+0x294>
   3fdc0:	str	x28, [sp, #32]
   3fdc4:	ldur	x24, [x29, #-8]
   3fdc8:	mov	x27, x26
   3fdcc:	lsl	x26, x21, #1
   3fdd0:	add	x23, x20, x22, lsl #3
   3fdd4:	mov	w3, #0x14                  	// #20
   3fdd8:	mov	x0, x24
   3fddc:	mov	x1, x20
   3fde0:	mov	x2, x26
   3fde4:	add	x25, x22, #0x1
   3fde8:	add	x19, x23, x21, lsl #3
   3fdec:	bl	c190 <__gmpn_lshift@plt>
   3fdf0:	mov	x28, x20
   3fdf4:	mov	x20, x0
   3fdf8:	mov	x0, x19
   3fdfc:	mov	x1, x19
   3fe00:	mov	x2, x24
   3fe04:	mov	x3, x26
   3fe08:	bl	c2e0 <__gmpn_sub_n@plt>
   3fe0c:	ldr	x8, [x23, x22, lsl #3]
   3fe10:	add	x9, x0, x20
   3fe14:	add	x19, x27, x21, lsl #3
   3fe18:	mov	x20, x28
   3fe1c:	sub	x8, x8, x9
   3fe20:	str	x8, [x23, x22, lsl #3]
   3fe24:	ldr	x8, [x28]
   3fe28:	ldr	x9, [x19]
   3fe2c:	str	x27, [sp, #48]
   3fe30:	sub	x8, x9, x8, lsr #4
   3fe34:	str	x8, [x19]
   3fe38:	ldr	x8, [x28]
   3fe3c:	cmp	x9, x8, lsr #4
   3fe40:	b.cs	3fe58 <__gmpn_toom_interpolate_12pts@@Base+0x33c>  // b.hs, b.nlast
   3fe44:	add	x8, x19, #0x8
   3fe48:	ldr	x9, [x8]
   3fe4c:	sub	x10, x9, #0x1
   3fe50:	str	x10, [x8], #8
   3fe54:	cbz	x9, 3fe48 <__gmpn_toom_interpolate_12pts@@Base+0x32c>
   3fe58:	ldur	x27, [x29, #-8]
   3fe5c:	sub	x24, x26, #0x1
   3fe60:	add	x1, x20, #0x8
   3fe64:	mov	w3, #0x3c                  	// #60
   3fe68:	mov	x0, x27
   3fe6c:	mov	x2, x24
   3fe70:	str	x1, [sp, #24]
   3fe74:	bl	c190 <__gmpn_lshift@plt>
   3fe78:	mov	x22, x0
   3fe7c:	mov	x0, x19
   3fe80:	mov	x1, x19
   3fe84:	mov	x2, x27
   3fe88:	mov	x3, x24
   3fe8c:	bl	c2e0 <__gmpn_sub_n@plt>
   3fe90:	add	x8, x19, x26, lsl #3
   3fe94:	ldur	x9, [x8, #-8]
   3fe98:	add	x10, x0, x22
   3fe9c:	stur	x26, [x29, #-32]
   3fea0:	str	x19, [sp, #8]
   3fea4:	subs	x9, x9, x10
   3fea8:	stur	x9, [x8, #-8]
   3feac:	b.cs	3fec0 <__gmpn_toom_interpolate_12pts@@Base+0x3a4>  // b.hs, b.nlast
   3feb0:	ldr	x9, [x8]
   3feb4:	sub	x10, x9, #0x1
   3feb8:	str	x10, [x8], #8
   3febc:	cbz	x9, 3feb0 <__gmpn_toom_interpolate_12pts@@Base+0x394>
   3fec0:	ldr	x28, [sp, #48]
   3fec4:	ldur	x0, [x29, #-8]
   3fec8:	mov	x2, x23
   3fecc:	mov	x3, x25
   3fed0:	mov	x1, x28
   3fed4:	bl	ca90 <__gmpn_add_n@plt>
   3fed8:	mov	x0, x23
   3fedc:	mov	x1, x23
   3fee0:	mov	x2, x28
   3fee4:	mov	x3, x25
   3fee8:	bl	c2e0 <__gmpn_sub_n@plt>
   3feec:	ldur	x26, [x29, #-32]
   3fef0:	ldur	x19, [x29, #-16]
   3fef4:	mov	w3, #0xa                   	// #10
   3fef8:	mov	x0, x28
   3fefc:	mov	x1, x20
   3ff00:	mov	x2, x26
   3ff04:	add	x22, x19, x21, lsl #3
   3ff08:	bl	c190 <__gmpn_lshift@plt>
   3ff0c:	mov	x27, x0
   3ff10:	mov	x0, x22
   3ff14:	mov	x1, x22
   3ff18:	mov	x2, x28
   3ff1c:	mov	x3, x26
   3ff20:	bl	c2e0 <__gmpn_sub_n@plt>
   3ff24:	ldur	x11, [x29, #-24]
   3ff28:	add	x9, x0, x27
   3ff2c:	mov	w10, #0x38                  	// #56
   3ff30:	madd	x27, x21, x10, x20
   3ff34:	ldr	x8, [x19, x11, lsl #3]
   3ff38:	add	x22, x27, x21, lsl #3
   3ff3c:	ldr	x28, [sp, #32]
   3ff40:	sub	x8, x8, x9
   3ff44:	str	x8, [x19, x11, lsl #3]
   3ff48:	ldr	x8, [x20]
   3ff4c:	ldr	x9, [x22]
   3ff50:	sub	x8, x9, x8, lsr #2
   3ff54:	str	x8, [x22]
   3ff58:	ldr	x8, [x20]
   3ff5c:	cmp	x9, x8, lsr #2
   3ff60:	b.cs	3ff7c <__gmpn_toom_interpolate_12pts@@Base+0x460>  // b.hs, b.nlast
   3ff64:	add	x8, x20, x21, lsl #6
   3ff68:	add	x8, x8, #0x8
   3ff6c:	ldr	x9, [x8]
   3ff70:	sub	x10, x9, #0x1
   3ff74:	str	x10, [x8], #8
   3ff78:	cbz	x9, 3ff6c <__gmpn_toom_interpolate_12pts@@Base+0x450>
   3ff7c:	ldr	x26, [sp, #48]
   3ff80:	ldr	x1, [sp, #24]
   3ff84:	mov	w3, #0x3e                  	// #62
   3ff88:	mov	x2, x24
   3ff8c:	mov	x0, x26
   3ff90:	bl	c190 <__gmpn_lshift@plt>
   3ff94:	mov	x19, x0
   3ff98:	mov	x0, x22
   3ff9c:	mov	x1, x22
   3ffa0:	mov	x2, x26
   3ffa4:	mov	x3, x24
   3ffa8:	bl	c2e0 <__gmpn_sub_n@plt>
   3ffac:	ldur	x24, [x29, #-32]
   3ffb0:	add	x10, x0, x19
   3ffb4:	add	x8, x22, x24, lsl #3
   3ffb8:	ldur	x9, [x8, #-8]
   3ffbc:	subs	x9, x9, x10
   3ffc0:	stur	x9, [x8, #-8]
   3ffc4:	b.cs	3ffd8 <__gmpn_toom_interpolate_12pts@@Base+0x4bc>  // b.hs, b.nlast
   3ffc8:	ldr	x9, [x8]
   3ffcc:	sub	x10, x9, #0x1
   3ffd0:	str	x10, [x8], #8
   3ffd4:	cbz	x9, 3ffc8 <__gmpn_toom_interpolate_12pts@@Base+0x4ac>
   3ffd8:	ldur	x19, [x29, #-16]
   3ffdc:	mov	x0, x26
   3ffe0:	mov	x2, x27
   3ffe4:	mov	x3, x25
   3ffe8:	mov	x1, x19
   3ffec:	bl	c2e0 <__gmpn_sub_n@plt>
   3fff0:	mov	x0, x27
   3fff4:	mov	x1, x27
   3fff8:	mov	x2, x19
   3fffc:	mov	x3, x25
   40000:	bl	ca90 <__gmpn_add_n@plt>
   40004:	add	x0, x28, x21, lsl #3
   40008:	mov	x1, x0
   4000c:	mov	x2, x20
   40010:	mov	x3, x24
   40014:	str	x0, [sp, #24]
   40018:	bl	c2e0 <__gmpn_sub_n@plt>
   4001c:	ldur	x22, [x29, #-24]
   40020:	mov	w3, #0x101                 	// #257
   40024:	mov	x1, x26
   40028:	mov	x2, x25
   4002c:	ldr	x8, [x28, x22, lsl #3]
   40030:	sub	x8, x8, x0
   40034:	mov	x0, x23
   40038:	str	x8, [x28, x22, lsl #3]
   4003c:	bl	ca00 <__gmpn_submul_1@plt>
   40040:	mov	x4, #0x771b                	// #30491
   40044:	movk	x4, #0x53e3, lsl #16
   40048:	movk	x4, #0xc705, lsl #32
   4004c:	mov	w3, #0xb13                 	// #2835
   40050:	movk	x4, #0x938c, lsl #48
   40054:	mov	w5, #0x2                   	// #2
   40058:	mov	x0, x23
   4005c:	mov	x1, x23
   40060:	mov	x2, x25
   40064:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   40068:	ldr	x8, [x23, x22, lsl #3]
   4006c:	lsr	x9, x8, #61
   40070:	cbz	x9, 4007c <__gmpn_toom_interpolate_12pts@@Base+0x560>
   40074:	orr	x8, x8, #0xc000000000000000
   40078:	str	x8, [x23, x22, lsl #3]
   4007c:	mov	w3, #0x3c                  	// #60
   40080:	mov	x0, x26
   40084:	mov	x1, x23
   40088:	mov	x2, x25
   4008c:	bl	d420 <__gmpn_addmul_1@plt>
   40090:	mov	x3, #0x101010101010101     	// #72340172838076673
   40094:	mov	x0, x26
   40098:	mov	x1, x26
   4009c:	mov	x2, x25
   400a0:	mov	x4, xzr
   400a4:	bl	c2d0 <__gmpn_bdiv_dbm1c@plt>
   400a8:	ldur	x24, [x29, #-16]
   400ac:	mov	w3, #0x5                   	// #5
   400b0:	mov	x1, x28
   400b4:	mov	x2, x25
   400b8:	mov	x0, x24
   400bc:	bl	c190 <__gmpn_lshift@plt>
   400c0:	mov	x0, x27
   400c4:	mov	x1, x27
   400c8:	mov	x2, x24
   400cc:	mov	x3, x25
   400d0:	bl	c2e0 <__gmpn_sub_n@plt>
   400d4:	ldur	x19, [x29, #-8]
   400d8:	mov	w3, #0x64                  	// #100
   400dc:	mov	x1, x27
   400e0:	mov	x2, x25
   400e4:	mov	x0, x19
   400e8:	bl	ca00 <__gmpn_submul_1@plt>
   400ec:	mov	w3, #0x9                   	// #9
   400f0:	mov	x0, x24
   400f4:	mov	x1, x28
   400f8:	mov	x2, x25
   400fc:	bl	c190 <__gmpn_lshift@plt>
   40100:	mov	x0, x19
   40104:	mov	x1, x19
   40108:	mov	x2, x24
   4010c:	mov	x3, x25
   40110:	bl	c2e0 <__gmpn_sub_n@plt>
   40114:	mov	x4, #0x4c35                	// #19509
   40118:	movk	x4, #0x9f31, lsl #16
   4011c:	movk	x4, #0xd44, lsl #32
   40120:	mov	w3, #0xa61d                	// #42525
   40124:	movk	x4, #0xe7b4, lsl #48
   40128:	mov	x0, x19
   4012c:	mov	x1, x19
   40130:	mov	x2, x25
   40134:	mov	w5, wzr
   40138:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   4013c:	mov	w3, #0xe1                  	// #225
   40140:	mov	x0, x27
   40144:	mov	x1, x19
   40148:	mov	x2, x25
   4014c:	bl	ca00 <__gmpn_submul_1@plt>
   40150:	mov	x4, #0x8e39                	// #36409
   40154:	movk	x4, #0x38e3, lsl #16
   40158:	movk	x4, #0xe38e, lsl #32
   4015c:	mov	w3, #0x9                   	// #9
   40160:	movk	x4, #0x8e38, lsl #48
   40164:	mov	w5, #0x2                   	// #2
   40168:	mov	x0, x27
   4016c:	mov	x1, x27
   40170:	mov	x2, x25
   40174:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   40178:	mov	x0, x28
   4017c:	mov	x1, x28
   40180:	mov	x2, x27
   40184:	mov	x3, x25
   40188:	bl	c2e0 <__gmpn_sub_n@plt>
   4018c:	mov	x0, x23
   40190:	mov	x1, x27
   40194:	mov	x2, x23
   40198:	mov	x3, x25
   4019c:	bl	c860 <__gmpn_rsh1sub_n@plt>
   401a0:	ldr	x8, [x23, x22, lsl #3]
   401a4:	mov	x0, x27
   401a8:	mov	x1, x27
   401ac:	mov	x2, x23
   401b0:	and	x8, x8, #0x7fffffffffffffff
   401b4:	mov	x3, x25
   401b8:	str	x8, [x23, x22, lsl #3]
   401bc:	bl	c2e0 <__gmpn_sub_n@plt>
   401c0:	mov	x0, x26
   401c4:	mov	x1, x26
   401c8:	mov	x2, x19
   401cc:	mov	x3, x25
   401d0:	bl	c970 <__gmpn_rsh1add_n@plt>
   401d4:	ldr	x8, [x26, x22, lsl #3]
   401d8:	mov	x0, x28
   401dc:	mov	x1, x28
   401e0:	mov	x2, x19
   401e4:	and	x8, x8, #0x7fffffffffffffff
   401e8:	mov	x3, x25
   401ec:	str	x8, [x26, x22, lsl #3]
   401f0:	bl	c2e0 <__gmpn_sub_n@plt>
   401f4:	mov	x0, x19
   401f8:	mov	x1, x19
   401fc:	mov	x2, x26
   40200:	mov	x3, x25
   40204:	bl	c2e0 <__gmpn_sub_n@plt>
   40208:	add	x0, x20, x21, lsl #3
   4020c:	mov	x1, x0
   40210:	mov	x2, x26
   40214:	mov	x3, x21
   40218:	bl	ca90 <__gmpn_add_n@plt>
   4021c:	ldr	x8, [x26, x21, lsl #3]
   40220:	ldur	x24, [x29, #-32]
   40224:	adds	x8, x8, x0
   40228:	add	x11, x20, x24, lsl #3
   4022c:	str	x8, [x11]
   40230:	b.cc	4029c <__gmpn_toom_interpolate_12pts@@Base+0x780>  // b.lo, b.ul, b.last
   40234:	add	x8, x26, x21, lsl #3
   40238:	add	x9, x20, x21, lsl #4
   4023c:	mov	w4, #0x1                   	// #1
   40240:	add	x8, x8, #0x8
   40244:	add	x9, x9, #0x8
   40248:	mov	w10, #0x1                   	// #1
   4024c:	cmp	x10, x21
   40250:	b.ge	402dc <__gmpn_toom_interpolate_12pts@@Base+0x7c0>  // b.tcont
   40254:	ldr	x12, [x8], #8
   40258:	add	x10, x10, #0x1
   4025c:	adds	x12, x12, #0x1
   40260:	str	x12, [x9], #8
   40264:	b.cs	4024c <__gmpn_toom_interpolate_12pts@@Base+0x730>  // b.hs, b.nlast
   40268:	ldr	x12, [sp, #8]
   4026c:	mov	x4, xzr
   40270:	cmp	x12, x11
   40274:	b.eq	402dc <__gmpn_toom_interpolate_12pts@@Base+0x7c0>  // b.none
   40278:	cmp	x10, x21
   4027c:	b.ge	402dc <__gmpn_toom_interpolate_12pts@@Base+0x7c0>  // b.tcont
   40280:	mov	x11, x21
   40284:	ldr	x12, [x8], #8
   40288:	sub	x11, x11, #0x1
   4028c:	cmp	x10, x11
   40290:	str	x12, [x9], #8
   40294:	b.ne	40284 <__gmpn_toom_interpolate_12pts@@Base+0x768>  // b.any
   40298:	b	402d8 <__gmpn_toom_interpolate_12pts@@Base+0x7bc>
   4029c:	cmp	x21, #0x2
   402a0:	mov	x4, xzr
   402a4:	b.lt	402dc <__gmpn_toom_interpolate_12pts@@Base+0x7c0>  // b.tstop
   402a8:	ldr	x8, [sp, #8]
   402ac:	cmp	x8, x11
   402b0:	b.eq	402dc <__gmpn_toom_interpolate_12pts@@Base+0x7c0>  // b.none
   402b4:	add	x9, x20, x21, lsl #4
   402b8:	add	x10, x26, x21, lsl #3
   402bc:	sub	x8, x21, #0x1
   402c0:	add	x9, x9, #0x8
   402c4:	add	x10, x10, #0x8
   402c8:	ldr	x11, [x10], #8
   402cc:	subs	x8, x8, #0x1
   402d0:	str	x11, [x9], #8
   402d4:	b.ne	402c8 <__gmpn_toom_interpolate_12pts@@Base+0x7ac>  // b.any
   402d8:	mov	x4, xzr
   402dc:	ldr	x19, [x26, x22, lsl #3]
   402e0:	add	x2, x26, x24, lsl #3
   402e4:	mov	x0, x23
   402e8:	mov	x1, x23
   402ec:	mov	x3, x21
   402f0:	bl	ceb0 <__gmpn_add_nc@plt>
   402f4:	ldr	x8, [x23, x21, lsl #3]
   402f8:	add	x9, x0, x19
   402fc:	adds	x8, x8, x9
   40300:	str	x8, [x23, x21, lsl #3]
   40304:	b.cc	40320 <__gmpn_toom_interpolate_12pts@@Base+0x804>  // b.lo, b.ul, b.last
   40308:	add	x8, x20, x21, lsl #5
   4030c:	add	x8, x8, #0x8
   40310:	ldr	x9, [x8]
   40314:	adds	x9, x9, #0x1
   40318:	str	x9, [x8], #8
   4031c:	b.cs	40310 <__gmpn_toom_interpolate_12pts@@Base+0x7f4>  // b.hs, b.nlast
   40320:	mov	w8, #0x28                  	// #40
   40324:	madd	x0, x21, x8, x20
   40328:	mov	x1, x0
   4032c:	mov	x2, x28
   40330:	mov	x3, x21
   40334:	bl	ca90 <__gmpn_add_n@plt>
   40338:	add	x8, x21, x21, lsl #1
   4033c:	add	x11, x20, x8, lsl #4
   40340:	ldr	x9, [x11]
   40344:	add	x10, x9, x0
   40348:	str	x10, [x11]
   4034c:	ldr	x12, [x28, x21, lsl #3]
   40350:	lsl	x9, x8, #1
   40354:	adds	x8, x12, x10
   40358:	str	x8, [x11]
   4035c:	b.cc	403c8 <__gmpn_toom_interpolate_12pts@@Base+0x8ac>  // b.lo, b.ul, b.last
   40360:	add	x8, x28, x21, lsl #3
   40364:	add	x9, x20, x9, lsl #3
   40368:	mov	w4, #0x1                   	// #1
   4036c:	add	x8, x8, #0x8
   40370:	add	x9, x9, #0x8
   40374:	mov	w10, #0x1                   	// #1
   40378:	cmp	x10, x21
   4037c:	b.ge	40408 <__gmpn_toom_interpolate_12pts@@Base+0x8ec>  // b.tcont
   40380:	ldr	x12, [x8], #8
   40384:	add	x10, x10, #0x1
   40388:	adds	x12, x12, #0x1
   4038c:	str	x12, [x9], #8
   40390:	b.cs	40378 <__gmpn_toom_interpolate_12pts@@Base+0x85c>  // b.hs, b.nlast
   40394:	ldr	x12, [sp, #24]
   40398:	mov	x4, xzr
   4039c:	cmp	x12, x11
   403a0:	b.eq	40408 <__gmpn_toom_interpolate_12pts@@Base+0x8ec>  // b.none
   403a4:	cmp	x10, x21
   403a8:	b.ge	40408 <__gmpn_toom_interpolate_12pts@@Base+0x8ec>  // b.tcont
   403ac:	mov	x11, x21
   403b0:	ldr	x12, [x8], #8
   403b4:	sub	x11, x11, #0x1
   403b8:	cmp	x10, x11
   403bc:	str	x12, [x9], #8
   403c0:	b.ne	403b0 <__gmpn_toom_interpolate_12pts@@Base+0x894>  // b.any
   403c4:	b	40404 <__gmpn_toom_interpolate_12pts@@Base+0x8e8>
   403c8:	cmp	x21, #0x2
   403cc:	mov	x4, xzr
   403d0:	b.lt	40408 <__gmpn_toom_interpolate_12pts@@Base+0x8ec>  // b.tstop
   403d4:	ldr	x8, [sp, #24]
   403d8:	cmp	x8, x11
   403dc:	b.eq	40408 <__gmpn_toom_interpolate_12pts@@Base+0x8ec>  // b.none
   403e0:	add	x9, x20, x9, lsl #3
   403e4:	add	x10, x28, x21, lsl #3
   403e8:	sub	x8, x21, #0x1
   403ec:	add	x9, x9, #0x8
   403f0:	add	x10, x10, #0x8
   403f4:	ldr	x11, [x10], #8
   403f8:	subs	x8, x8, #0x1
   403fc:	str	x11, [x9], #8
   40400:	b.ne	403f4 <__gmpn_toom_interpolate_12pts@@Base+0x8d8>  // b.any
   40404:	mov	x4, xzr
   40408:	ldr	x19, [x28, x22, lsl #3]
   4040c:	add	x2, x28, x24, lsl #3
   40410:	mov	x0, x27
   40414:	mov	x1, x27
   40418:	mov	x3, x21
   4041c:	bl	ceb0 <__gmpn_add_nc@plt>
   40420:	lsl	x8, x21, #6
   40424:	ldr	x9, [x20, x8]
   40428:	add	x10, x0, x19
   4042c:	adds	x9, x9, x10
   40430:	str	x9, [x20, x8]
   40434:	b.cc	40454 <__gmpn_toom_interpolate_12pts@@Base+0x938>  // b.lo, b.ul, b.last
   40438:	ldr	x8, [sp, #16]
   4043c:	add	x8, x20, x8, lsl #3
   40440:	add	x8, x8, #0x8
   40444:	ldr	x9, [x8]
   40448:	adds	x9, x9, #0x1
   4044c:	str	x9, [x8], #8
   40450:	b.cs	40444 <__gmpn_toom_interpolate_12pts@@Base+0x928>  // b.hs, b.nlast
   40454:	ldur	x19, [x29, #-8]
   40458:	mov	w8, #0x48                  	// #72
   4045c:	madd	x0, x21, x8, x20
   40460:	mov	x1, x0
   40464:	mov	x2, x19
   40468:	mov	x3, x21
   4046c:	bl	ca90 <__gmpn_add_n@plt>
   40470:	mov	w8, #0x50                  	// #80
   40474:	madd	x8, x21, x8, x20
   40478:	ldr	x9, [x8]
   4047c:	ldur	x3, [x29, #-40]
   40480:	ldr	w12, [sp, #44]
   40484:	add	x10, x9, x0
   40488:	str	x10, [x8]
   4048c:	add	x9, x19, x21, lsl #3
   40490:	ldr	x11, [x9]
   40494:	add	x11, x11, x10
   40498:	str	x11, [x8]
   4049c:	cbz	w12, 40514 <__gmpn_toom_interpolate_12pts@@Base+0x9f8>
   404a0:	cmp	x11, x10
   404a4:	b.cs	4057c <__gmpn_toom_interpolate_12pts@@Base+0xa60>  // b.hs, b.nlast
   404a8:	ldur	x10, [x29, #-8]
   404ac:	mov	w11, #0x50                  	// #80
   404b0:	madd	x11, x21, x11, x20
   404b4:	mov	w4, #0x1                   	// #1
   404b8:	add	x10, x10, x21, lsl #3
   404bc:	add	x10, x10, #0x8
   404c0:	add	x11, x11, #0x8
   404c4:	mov	w12, #0x1                   	// #1
   404c8:	cmp	x12, x21
   404cc:	b.ge	405c0 <__gmpn_toom_interpolate_12pts@@Base+0xaa4>  // b.tcont
   404d0:	ldr	x13, [x10], #8
   404d4:	add	x12, x12, #0x1
   404d8:	adds	x13, x13, #0x1
   404dc:	str	x13, [x11], #8
   404e0:	b.cs	404c8 <__gmpn_toom_interpolate_12pts@@Base+0x9ac>  // b.hs, b.nlast
   404e4:	cmp	x9, x8
   404e8:	mov	x4, xzr
   404ec:	b.eq	405c0 <__gmpn_toom_interpolate_12pts@@Base+0xaa4>  // b.none
   404f0:	cmp	x12, x21
   404f4:	b.ge	405c0 <__gmpn_toom_interpolate_12pts@@Base+0xaa4>  // b.tcont
   404f8:	mov	x8, x21
   404fc:	ldr	x9, [x10], #8
   40500:	sub	x8, x8, #0x1
   40504:	cmp	x12, x8
   40508:	str	x9, [x11], #8
   4050c:	b.ne	404fc <__gmpn_toom_interpolate_12pts@@Base+0x9e0>  // b.any
   40510:	b	405bc <__gmpn_toom_interpolate_12pts@@Base+0xaa0>
   40514:	cmp	x11, x10
   40518:	b.cs	40624 <__gmpn_toom_interpolate_12pts@@Base+0xb08>  // b.hs, b.nlast
   4051c:	ldur	x10, [x29, #-8]
   40520:	mov	w11, #0x50                  	// #80
   40524:	madd	x11, x21, x11, x20
   40528:	add	x11, x11, #0x8
   4052c:	add	x10, x10, x21, lsl #3
   40530:	add	x10, x10, #0x8
   40534:	mov	w12, #0x1                   	// #1
   40538:	cmp	x12, x3
   4053c:	b.ge	40660 <__gmpn_toom_interpolate_12pts@@Base+0xb44>  // b.tcont
   40540:	ldr	x13, [x10], #8
   40544:	add	x12, x12, #0x1
   40548:	adds	x13, x13, #0x1
   4054c:	str	x13, [x11], #8
   40550:	b.cs	40538 <__gmpn_toom_interpolate_12pts@@Base+0xa1c>  // b.hs, b.nlast
   40554:	cmp	x9, x8
   40558:	b.eq	40660 <__gmpn_toom_interpolate_12pts@@Base+0xb44>  // b.none
   4055c:	cmp	x12, x3
   40560:	b.ge	40660 <__gmpn_toom_interpolate_12pts@@Base+0xb44>  // b.tcont
   40564:	ldr	x8, [x10], #8
   40568:	sub	x3, x3, #0x1
   4056c:	cmp	x12, x3
   40570:	str	x8, [x11], #8
   40574:	b.ne	40564 <__gmpn_toom_interpolate_12pts@@Base+0xa48>  // b.any
   40578:	b	40660 <__gmpn_toom_interpolate_12pts@@Base+0xb44>
   4057c:	cmp	x21, #0x2
   40580:	mov	x4, xzr
   40584:	b.lt	405c0 <__gmpn_toom_interpolate_12pts@@Base+0xaa4>  // b.tstop
   40588:	cmp	x9, x8
   4058c:	b.eq	405c0 <__gmpn_toom_interpolate_12pts@@Base+0xaa4>  // b.none
   40590:	ldur	x10, [x29, #-8]
   40594:	mov	w9, #0x50                  	// #80
   40598:	madd	x9, x21, x9, x20
   4059c:	sub	x8, x21, #0x1
   405a0:	add	x10, x10, x21, lsl #3
   405a4:	add	x9, x9, #0x8
   405a8:	add	x10, x10, #0x8
   405ac:	ldr	x11, [x10], #8
   405b0:	subs	x8, x8, #0x1
   405b4:	str	x11, [x9], #8
   405b8:	b.ne	405ac <__gmpn_toom_interpolate_12pts@@Base+0xa90>  // b.any
   405bc:	mov	x4, xzr
   405c0:	cmp	x3, x21
   405c4:	b.le	40680 <__gmpn_toom_interpolate_12pts@@Base+0xb64>
   405c8:	ldur	x9, [x29, #-8]
   405cc:	mov	w8, #0x58                  	// #88
   405d0:	madd	x0, x21, x8, x20
   405d4:	mov	x1, x0
   405d8:	ldr	x19, [x9, x22, lsl #3]
   405dc:	add	x2, x9, x24, lsl #3
   405e0:	mov	x3, x21
   405e4:	bl	ceb0 <__gmpn_add_nc@plt>
   405e8:	add	x8, x21, x21, lsl #1
   405ec:	lsl	x9, x8, #5
   405f0:	ldr	x10, [x20, x9]
   405f4:	add	x11, x0, x19
   405f8:	adds	x10, x10, x11
   405fc:	str	x10, [x20, x9]
   40600:	b.cc	40660 <__gmpn_toom_interpolate_12pts@@Base+0xb44>  // b.lo, b.ul, b.last
   40604:	lsl	x8, x8, #2
   40608:	add	x8, x20, x8, lsl #3
   4060c:	add	x8, x8, #0x8
   40610:	ldr	x9, [x8]
   40614:	adds	x9, x9, #0x1
   40618:	str	x9, [x8], #8
   4061c:	b.cs	40610 <__gmpn_toom_interpolate_12pts@@Base+0xaf4>  // b.hs, b.nlast
   40620:	b	40660 <__gmpn_toom_interpolate_12pts@@Base+0xb44>
   40624:	cmp	x3, #0x2
   40628:	b.lt	40660 <__gmpn_toom_interpolate_12pts@@Base+0xb44>  // b.tstop
   4062c:	cmp	x9, x8
   40630:	b.eq	40660 <__gmpn_toom_interpolate_12pts@@Base+0xb44>  // b.none
   40634:	ldur	x10, [x29, #-8]
   40638:	mov	w9, #0x50                  	// #80
   4063c:	madd	x9, x21, x9, x20
   40640:	sub	x8, x3, #0x1
   40644:	add	x10, x10, x21, lsl #3
   40648:	add	x9, x9, #0x8
   4064c:	add	x10, x10, #0x8
   40650:	ldr	x11, [x10], #8
   40654:	subs	x8, x8, #0x1
   40658:	str	x11, [x9], #8
   4065c:	b.ne	40650 <__gmpn_toom_interpolate_12pts@@Base+0xb34>  // b.any
   40660:	ldp	x20, x19, [sp, #176]
   40664:	ldp	x22, x21, [sp, #160]
   40668:	ldp	x24, x23, [sp, #144]
   4066c:	ldp	x26, x25, [sp, #128]
   40670:	ldp	x28, x27, [sp, #112]
   40674:	ldp	x29, x30, [sp, #96]
   40678:	add	sp, sp, #0xc0
   4067c:	ret
   40680:	mov	w8, #0x58                  	// #88
   40684:	madd	x0, x21, x8, x20
   40688:	ldur	x8, [x29, #-8]
   4068c:	ldp	x20, x19, [sp, #176]
   40690:	ldp	x22, x21, [sp, #160]
   40694:	ldp	x26, x25, [sp, #128]
   40698:	add	x2, x8, x24, lsl #3
   4069c:	ldp	x24, x23, [sp, #144]
   406a0:	ldp	x28, x27, [sp, #112]
   406a4:	ldp	x29, x30, [sp, #96]
   406a8:	mov	x1, x0
   406ac:	add	sp, sp, #0xc0
   406b0:	b	ceb0 <__gmpn_add_nc@plt>

00000000000406b4 <__gmpn_toom_interpolate_16pts@@Base>:
   406b4:	sub	sp, sp, #0xe0
   406b8:	stp	x29, x30, [sp, #128]
   406bc:	stp	x28, x27, [sp, #144]
   406c0:	stp	x26, x25, [sp, #160]
   406c4:	stp	x24, x23, [sp, #176]
   406c8:	stp	x22, x21, [sp, #192]
   406cc:	stp	x20, x19, [sp, #208]
   406d0:	add	x29, sp, #0x80
   406d4:	ldr	x27, [x29, #96]
   406d8:	mov	x20, x5
   406dc:	mov	x24, x3
   406e0:	mov	x21, x0
   406e4:	add	x25, x5, x5, lsl #1
   406e8:	lsl	x8, x5, #3
   406ec:	stp	x1, x4, [x29, #-40]
   406f0:	stur	x2, [x29, #-8]
   406f4:	str	x8, [sp, #24]
   406f8:	stur	x6, [x29, #-48]
   406fc:	stur	x25, [x29, #-24]
   40700:	str	w7, [sp, #52]
   40704:	cbz	w7, 40a54 <__gmpn_toom_interpolate_16pts@@Base+0x3a0>
   40708:	mov	w8, #0x38                  	// #56
   4070c:	mov	w9, #0x78                  	// #120
   40710:	madd	x22, x20, x8, x21
   40714:	madd	x19, x20, x9, x21
   40718:	mov	x0, x22
   4071c:	mov	x1, x22
   40720:	mov	x2, x19
   40724:	mov	x3, x6
   40728:	mov	x23, x6
   4072c:	bl	c2e0 <__gmpn_sub_n@plt>
   40730:	ldr	x8, [x22, x23, lsl #3]
   40734:	subs	x8, x8, x0
   40738:	str	x8, [x22, x23, lsl #3]
   4073c:	b.cs	40764 <__gmpn_toom_interpolate_16pts@@Base+0xb0>  // b.hs, b.nlast
   40740:	ldr	x8, [sp, #24]
   40744:	sub	x8, x8, x20
   40748:	add	x8, x23, x8
   4074c:	add	x8, x21, x8, lsl #3
   40750:	add	x8, x8, #0x8
   40754:	ldr	x9, [x8]
   40758:	sub	x10, x9, #0x1
   4075c:	str	x10, [x8], #8
   40760:	cbz	x9, 40754 <__gmpn_toom_interpolate_16pts@@Base+0xa0>
   40764:	mov	w3, #0xe                   	// #14
   40768:	mov	x0, x27
   4076c:	mov	x1, x19
   40770:	mov	x2, x23
   40774:	bl	c190 <__gmpn_lshift@plt>
   40778:	ldur	x26, [x29, #-8]
   4077c:	mov	x22, x0
   40780:	mov	x2, x27
   40784:	mov	x3, x23
   40788:	mov	x0, x26
   4078c:	mov	x1, x26
   40790:	bl	c2e0 <__gmpn_sub_n@plt>
   40794:	ldr	x8, [x26, x23, lsl #3]
   40798:	add	x9, x0, x22
   4079c:	subs	x8, x8, x9
   407a0:	str	x8, [x26, x23, lsl #3]
   407a4:	b.cs	407c4 <__gmpn_toom_interpolate_16pts@@Base+0x110>  // b.hs, b.nlast
   407a8:	ldur	x8, [x29, #-8]
   407ac:	add	x8, x8, x23, lsl #3
   407b0:	add	x8, x8, #0x8
   407b4:	ldr	x9, [x8]
   407b8:	sub	x10, x9, #0x1
   407bc:	str	x10, [x8], #8
   407c0:	cbz	x9, 407b4 <__gmpn_toom_interpolate_16pts@@Base+0x100>
   407c4:	add	x28, x21, x25, lsl #3
   407c8:	ldr	x8, [x19]
   407cc:	ldr	x9, [x28]
   407d0:	sub	x8, x9, x8, lsr #2
   407d4:	str	x8, [x28]
   407d8:	ldr	x8, [x19]
   407dc:	cmp	x9, x8, lsr #2
   407e0:	b.cs	40800 <__gmpn_toom_interpolate_16pts@@Base+0x14c>  // b.hs, b.nlast
   407e4:	mov	w8, #0x18                  	// #24
   407e8:	madd	x8, x20, x8, x21
   407ec:	add	x8, x8, #0x8
   407f0:	ldr	x9, [x8]
   407f4:	sub	x10, x9, #0x1
   407f8:	str	x10, [x8], #8
   407fc:	cbz	x9, 407f0 <__gmpn_toom_interpolate_16pts@@Base+0x13c>
   40800:	ldur	x23, [x29, #-48]
   40804:	add	x1, x19, #0x8
   40808:	mov	w3, #0x3e                  	// #62
   4080c:	mov	x0, x27
   40810:	sub	x22, x23, #0x1
   40814:	mov	x2, x22
   40818:	mov	x26, x1
   4081c:	bl	c190 <__gmpn_lshift@plt>
   40820:	mov	x25, x0
   40824:	mov	x0, x28
   40828:	mov	x1, x28
   4082c:	mov	x2, x27
   40830:	mov	x3, x22
   40834:	bl	c2e0 <__gmpn_sub_n@plt>
   40838:	add	x8, x28, x23, lsl #3
   4083c:	ldur	x9, [x8, #-8]
   40840:	add	x10, x0, x25
   40844:	mov	x2, x23
   40848:	subs	x9, x9, x10
   4084c:	stur	x9, [x8, #-8]
   40850:	b.cs	40864 <__gmpn_toom_interpolate_16pts@@Base+0x1b0>  // b.hs, b.nlast
   40854:	ldr	x9, [x8]
   40858:	sub	x10, x9, #0x1
   4085c:	str	x10, [x8], #8
   40860:	cbz	x9, 40854 <__gmpn_toom_interpolate_16pts@@Base+0x1a0>
   40864:	mov	w8, #0xb                   	// #11
   40868:	mul	x8, x20, x8
   4086c:	mov	w3, #0x1c                  	// #28
   40870:	mov	x0, x27
   40874:	mov	x1, x19
   40878:	stur	x8, [x29, #-16]
   4087c:	add	x25, x21, x8, lsl #3
   40880:	bl	c190 <__gmpn_lshift@plt>
   40884:	ldur	x3, [x29, #-48]
   40888:	mov	x28, x0
   4088c:	mov	x0, x25
   40890:	mov	x1, x25
   40894:	mov	x2, x27
   40898:	bl	c2e0 <__gmpn_sub_n@plt>
   4089c:	ldur	x8, [x29, #-48]
   408a0:	add	x9, x0, x28
   408a4:	ldur	x28, [x29, #-48]
   408a8:	ldr	x8, [x25, x8, lsl #3]
   408ac:	subs	x8, x8, x9
   408b0:	str	x8, [x25, x28, lsl #3]
   408b4:	b.cs	408d8 <__gmpn_toom_interpolate_16pts@@Base+0x224>  // b.hs, b.nlast
   408b8:	mov	w8, #0xb                   	// #11
   408bc:	madd	x8, x20, x8, x28
   408c0:	add	x8, x21, x8, lsl #3
   408c4:	add	x8, x8, #0x8
   408c8:	ldr	x9, [x8]
   408cc:	sub	x10, x9, #0x1
   408d0:	str	x10, [x8], #8
   408d4:	cbz	x9, 408c8 <__gmpn_toom_interpolate_16pts@@Base+0x214>
   408d8:	ldr	x8, [x19]
   408dc:	ldr	x9, [x24]
   408e0:	sub	x8, x9, x8, lsr #4
   408e4:	str	x8, [x24]
   408e8:	ldr	x8, [x19]
   408ec:	cmp	x9, x8, lsr #4
   408f0:	b.cs	40908 <__gmpn_toom_interpolate_16pts@@Base+0x254>  // b.hs, b.nlast
   408f4:	add	x8, x24, #0x8
   408f8:	ldr	x9, [x8]
   408fc:	sub	x10, x9, #0x1
   40900:	str	x10, [x8], #8
   40904:	cbz	x9, 408f8 <__gmpn_toom_interpolate_16pts@@Base+0x244>
   40908:	mov	w3, #0x3c                  	// #60
   4090c:	mov	x0, x27
   40910:	mov	x1, x26
   40914:	mov	x2, x22
   40918:	bl	c190 <__gmpn_lshift@plt>
   4091c:	mov	x25, x0
   40920:	mov	x0, x24
   40924:	mov	x1, x24
   40928:	mov	x2, x27
   4092c:	mov	x3, x22
   40930:	bl	c2e0 <__gmpn_sub_n@plt>
   40934:	add	x8, x24, x28, lsl #3
   40938:	ldur	x9, [x8, #-8]
   4093c:	add	x10, x0, x25
   40940:	subs	x9, x9, x10
   40944:	stur	x9, [x8, #-8]
   40948:	b.cs	4095c <__gmpn_toom_interpolate_16pts@@Base+0x2a8>  // b.hs, b.nlast
   4094c:	ldr	x9, [x8]
   40950:	sub	x10, x9, #0x1
   40954:	str	x10, [x8], #8
   40958:	cbz	x9, 4094c <__gmpn_toom_interpolate_16pts@@Base+0x298>
   4095c:	mov	w3, #0x2a                  	// #42
   40960:	mov	x0, x27
   40964:	mov	x1, x19
   40968:	mov	x2, x28
   4096c:	bl	c190 <__gmpn_lshift@plt>
   40970:	ldur	x23, [x29, #-40]
   40974:	mov	x25, x0
   40978:	mov	x2, x27
   4097c:	mov	x3, x28
   40980:	mov	x0, x23
   40984:	mov	x1, x23
   40988:	bl	c2e0 <__gmpn_sub_n@plt>
   4098c:	ldr	x8, [x23, x28, lsl #3]
   40990:	add	x9, x0, x25
   40994:	subs	x8, x8, x9
   40998:	str	x8, [x23, x28, lsl #3]
   4099c:	b.cs	409bc <__gmpn_toom_interpolate_16pts@@Base+0x308>  // b.hs, b.nlast
   409a0:	ldur	x8, [x29, #-40]
   409a4:	add	x8, x8, x28, lsl #3
   409a8:	add	x8, x8, #0x8
   409ac:	ldr	x9, [x8]
   409b0:	sub	x10, x9, #0x1
   409b4:	str	x10, [x8], #8
   409b8:	cbz	x9, 409ac <__gmpn_toom_interpolate_16pts@@Base+0x2f8>
   409bc:	ldp	x10, x25, [x29, #-32]
   409c0:	ldr	x8, [x19]
   409c4:	ldr	x9, [x10]
   409c8:	sub	x8, x9, x8, lsr #6
   409cc:	str	x8, [x10]
   409d0:	ldr	x8, [x19]
   409d4:	cmp	x9, x8, lsr #6
   409d8:	b.cs	409f4 <__gmpn_toom_interpolate_16pts@@Base+0x340>  // b.hs, b.nlast
   409dc:	ldur	x8, [x29, #-32]
   409e0:	add	x8, x8, #0x8
   409e4:	ldr	x9, [x8]
   409e8:	sub	x10, x9, #0x1
   409ec:	str	x10, [x8], #8
   409f0:	cbz	x9, 409e4 <__gmpn_toom_interpolate_16pts@@Base+0x330>
   409f4:	mov	w3, #0x3a                  	// #58
   409f8:	mov	x0, x27
   409fc:	mov	x1, x26
   40a00:	mov	x2, x22
   40a04:	bl	c190 <__gmpn_lshift@plt>
   40a08:	ldur	x23, [x29, #-32]
   40a0c:	mov	x19, x0
   40a10:	mov	x2, x27
   40a14:	mov	x3, x22
   40a18:	mov	x0, x23
   40a1c:	mov	x1, x23
   40a20:	bl	c2e0 <__gmpn_sub_n@plt>
   40a24:	add	x8, x23, x28, lsl #3
   40a28:	ldur	x9, [x8, #-8]
   40a2c:	add	x10, x0, x19
   40a30:	subs	x9, x9, x10
   40a34:	stur	x9, [x8, #-8]
   40a38:	b.cs	40a60 <__gmpn_toom_interpolate_16pts@@Base+0x3ac>  // b.hs, b.nlast
   40a3c:	ldur	x28, [x29, #-16]
   40a40:	ldr	x9, [x8]
   40a44:	sub	x10, x9, #0x1
   40a48:	str	x10, [x8], #8
   40a4c:	cbz	x9, 40a40 <__gmpn_toom_interpolate_16pts@@Base+0x38c>
   40a50:	b	40a64 <__gmpn_toom_interpolate_16pts@@Base+0x3b0>
   40a54:	mov	w8, #0xb                   	// #11
   40a58:	mul	x28, x20, x8
   40a5c:	b	40a64 <__gmpn_toom_interpolate_16pts@@Base+0x3b0>
   40a60:	ldur	x28, [x29, #-16]
   40a64:	lsl	x23, x20, #1
   40a68:	mov	w3, #0x1c                  	// #28
   40a6c:	mov	x0, x27
   40a70:	mov	x1, x21
   40a74:	mov	x2, x23
   40a78:	add	x19, x25, #0x1
   40a7c:	add	x26, x24, x20, lsl #3
   40a80:	bl	c190 <__gmpn_lshift@plt>
   40a84:	mov	x22, x0
   40a88:	mov	x0, x26
   40a8c:	mov	x1, x26
   40a90:	mov	x2, x27
   40a94:	mov	x3, x23
   40a98:	str	x26, [sp, #16]
   40a9c:	stur	x23, [x29, #-16]
   40aa0:	bl	c2e0 <__gmpn_sub_n@plt>
   40aa4:	ldr	x8, [x24, x25, lsl #3]
   40aa8:	add	x9, x0, x22
   40aac:	add	x11, x21, x28, lsl #3
   40ab0:	mov	x10, x25
   40ab4:	sub	x8, x8, x9
   40ab8:	add	x25, x11, x20, lsl #3
   40abc:	str	x8, [x24, x10, lsl #3]
   40ac0:	ldr	x8, [x21]
   40ac4:	ldr	x9, [x25]
   40ac8:	stur	x11, [x29, #-56]
   40acc:	sub	x8, x9, x8, lsr #4
   40ad0:	str	x8, [x25]
   40ad4:	ldr	x8, [x21]
   40ad8:	cmp	x9, x8, lsr #4
   40adc:	b.cs	40afc <__gmpn_toom_interpolate_16pts@@Base+0x448>  // b.hs, b.nlast
   40ae0:	add	x8, x28, x20
   40ae4:	add	x8, x21, x8, lsl #3
   40ae8:	add	x8, x8, #0x8
   40aec:	ldr	x9, [x8]
   40af0:	sub	x10, x9, #0x1
   40af4:	str	x10, [x8], #8
   40af8:	cbz	x9, 40aec <__gmpn_toom_interpolate_16pts@@Base+0x438>
   40afc:	mov	x26, x21
   40b00:	add	x1, x21, #0x8
   40b04:	ldur	x21, [x29, #-16]
   40b08:	mov	w3, #0x3c                  	// #60
   40b0c:	mov	x0, x27
   40b10:	str	x1, [sp, #56]
   40b14:	sub	x22, x21, #0x1
   40b18:	mov	x2, x22
   40b1c:	bl	c190 <__gmpn_lshift@plt>
   40b20:	mov	x28, x0
   40b24:	mov	x0, x25
   40b28:	mov	x1, x25
   40b2c:	mov	x2, x27
   40b30:	mov	x3, x22
   40b34:	bl	c2e0 <__gmpn_sub_n@plt>
   40b38:	add	x8, x25, x21, lsl #3
   40b3c:	ldur	x9, [x8, #-8]
   40b40:	add	x10, x0, x28
   40b44:	subs	x9, x9, x10
   40b48:	stur	x9, [x8, #-8]
   40b4c:	b.cs	40b60 <__gmpn_toom_interpolate_16pts@@Base+0x4ac>  // b.hs, b.nlast
   40b50:	ldr	x9, [x8]
   40b54:	sub	x10, x9, #0x1
   40b58:	str	x10, [x8], #8
   40b5c:	cbz	x9, 40b50 <__gmpn_toom_interpolate_16pts@@Base+0x49c>
   40b60:	str	x27, [sp, #40]
   40b64:	ldur	x21, [x29, #-56]
   40b68:	mov	x0, x27
   40b6c:	mov	x1, x24
   40b70:	mov	x3, x19
   40b74:	mov	x2, x21
   40b78:	bl	c2e0 <__gmpn_sub_n@plt>
   40b7c:	mov	x0, x21
   40b80:	mov	x1, x21
   40b84:	mov	x2, x24
   40b88:	mov	x3, x19
   40b8c:	bl	ca90 <__gmpn_add_n@plt>
   40b90:	ldp	x21, x27, [x29, #-24]
   40b94:	mov	w3, #0xe                   	// #14
   40b98:	mov	x0, x24
   40b9c:	mov	x1, x26
   40ba0:	add	x25, x26, x21, lsl #3
   40ba4:	mov	x2, x27
   40ba8:	add	x28, x25, x20, lsl #3
   40bac:	bl	c190 <__gmpn_lshift@plt>
   40bb0:	mov	x23, x0
   40bb4:	mov	x0, x28
   40bb8:	mov	x1, x28
   40bbc:	mov	x2, x24
   40bc0:	mov	x3, x27
   40bc4:	mov	x28, x24
   40bc8:	bl	c2e0 <__gmpn_sub_n@plt>
   40bcc:	ldr	x8, [x25, x21, lsl #3]
   40bd0:	ldur	x27, [x29, #-8]
   40bd4:	add	x9, x0, x23
   40bd8:	sub	x8, x8, x9
   40bdc:	add	x24, x27, x20, lsl #3
   40be0:	str	x8, [x25, x21, lsl #3]
   40be4:	ldr	x8, [x26]
   40be8:	ldr	x9, [x24]
   40bec:	mov	x21, x26
   40bf0:	sub	x8, x9, x8, lsr #2
   40bf4:	str	x8, [x24]
   40bf8:	ldr	x8, [x26]
   40bfc:	cmp	x9, x8, lsr #2
   40c00:	b.cs	40c18 <__gmpn_toom_interpolate_16pts@@Base+0x564>  // b.hs, b.nlast
   40c04:	add	x8, x24, #0x8
   40c08:	ldr	x9, [x8]
   40c0c:	sub	x10, x9, #0x1
   40c10:	str	x10, [x8], #8
   40c14:	cbz	x9, 40c08 <__gmpn_toom_interpolate_16pts@@Base+0x554>
   40c18:	ldr	x1, [sp, #56]
   40c1c:	mov	w3, #0x3e                  	// #62
   40c20:	mov	x0, x28
   40c24:	mov	x2, x22
   40c28:	bl	c190 <__gmpn_lshift@plt>
   40c2c:	mov	x23, x0
   40c30:	mov	x0, x24
   40c34:	mov	x1, x24
   40c38:	mov	x2, x28
   40c3c:	mov	x3, x22
   40c40:	bl	c2e0 <__gmpn_sub_n@plt>
   40c44:	ldur	x26, [x29, #-16]
   40c48:	add	x10, x0, x23
   40c4c:	str	x24, [sp, #8]
   40c50:	add	x8, x24, x26, lsl #3
   40c54:	ldur	x9, [x8, #-8]
   40c58:	subs	x9, x9, x10
   40c5c:	stur	x9, [x8, #-8]
   40c60:	b.cs	40c74 <__gmpn_toom_interpolate_16pts@@Base+0x5c0>  // b.hs, b.nlast
   40c64:	ldr	x9, [x8]
   40c68:	sub	x10, x9, #0x1
   40c6c:	str	x10, [x8], #8
   40c70:	cbz	x9, 40c64 <__gmpn_toom_interpolate_16pts@@Base+0x5b0>
   40c74:	mov	x0, x28
   40c78:	mov	x1, x27
   40c7c:	mov	x2, x25
   40c80:	mov	x3, x19
   40c84:	str	x28, [sp, #32]
   40c88:	bl	ca90 <__gmpn_add_n@plt>
   40c8c:	mov	x0, x25
   40c90:	mov	x1, x25
   40c94:	mov	x2, x27
   40c98:	mov	x3, x19
   40c9c:	bl	c2e0 <__gmpn_sub_n@plt>
   40ca0:	ldur	x24, [x29, #-32]
   40ca4:	mov	w3, #0x2a                  	// #42
   40ca8:	mov	x0, x27
   40cac:	mov	x1, x21
   40cb0:	mov	x2, x26
   40cb4:	add	x23, x24, x20, lsl #3
   40cb8:	bl	c190 <__gmpn_lshift@plt>
   40cbc:	mov	x28, x0
   40cc0:	mov	x0, x23
   40cc4:	mov	x1, x23
   40cc8:	mov	x2, x27
   40ccc:	mov	x3, x26
   40cd0:	bl	c2e0 <__gmpn_sub_n@plt>
   40cd4:	ldur	x10, [x29, #-24]
   40cd8:	ldur	x11, [x29, #-40]
   40cdc:	add	x9, x0, x28
   40ce0:	ldr	x27, [sp, #40]
   40ce4:	ldr	x8, [x24, x10, lsl #3]
   40ce8:	add	x11, x11, x20, lsl #3
   40cec:	str	x11, [sp, #64]
   40cf0:	sub	x8, x8, x9
   40cf4:	str	x8, [x24, x10, lsl #3]
   40cf8:	ldr	x8, [x21]
   40cfc:	ldr	x9, [x11]
   40d00:	sub	x8, x9, x8, lsr #6
   40d04:	str	x8, [x11]
   40d08:	ldr	x8, [x21]
   40d0c:	cmp	x9, x8, lsr #6
   40d10:	b.cs	40d2c <__gmpn_toom_interpolate_16pts@@Base+0x678>  // b.hs, b.nlast
   40d14:	ldr	x8, [sp, #64]
   40d18:	add	x8, x8, #0x8
   40d1c:	ldr	x9, [x8]
   40d20:	sub	x10, x9, #0x1
   40d24:	str	x10, [x8], #8
   40d28:	cbz	x9, 40d1c <__gmpn_toom_interpolate_16pts@@Base+0x668>
   40d2c:	ldur	x26, [x29, #-8]
   40d30:	ldr	x1, [sp, #56]
   40d34:	mov	w3, #0x3a                  	// #58
   40d38:	mov	x2, x22
   40d3c:	mov	x0, x26
   40d40:	bl	c190 <__gmpn_lshift@plt>
   40d44:	ldr	x28, [sp, #64]
   40d48:	mov	x23, x0
   40d4c:	mov	x2, x26
   40d50:	mov	x3, x22
   40d54:	mov	x0, x28
   40d58:	mov	x1, x28
   40d5c:	bl	c2e0 <__gmpn_sub_n@plt>
   40d60:	ldur	x8, [x29, #-16]
   40d64:	add	x10, x0, x23
   40d68:	add	x8, x28, x8, lsl #3
   40d6c:	ldur	x9, [x8, #-8]
   40d70:	subs	x9, x9, x10
   40d74:	stur	x9, [x8, #-8]
   40d78:	b.cs	40d8c <__gmpn_toom_interpolate_16pts@@Base+0x6d8>  // b.hs, b.nlast
   40d7c:	ldr	x9, [x8]
   40d80:	sub	x10, x9, #0x1
   40d84:	str	x10, [x8], #8
   40d88:	cbz	x9, 40d7c <__gmpn_toom_interpolate_16pts@@Base+0x6c8>
   40d8c:	ldur	x26, [x29, #-8]
   40d90:	ldp	x24, x22, [x29, #-40]
   40d94:	mov	x3, x19
   40d98:	mov	x0, x26
   40d9c:	mov	x1, x22
   40da0:	mov	x2, x24
   40da4:	bl	c2e0 <__gmpn_sub_n@plt>
   40da8:	mov	x0, x24
   40dac:	mov	x1, x24
   40db0:	mov	x2, x22
   40db4:	mov	x3, x19
   40db8:	bl	ca90 <__gmpn_add_n@plt>
   40dbc:	mov	w8, #0x38                  	// #56
   40dc0:	ldur	x3, [x29, #-16]
   40dc4:	madd	x22, x20, x8, x21
   40dc8:	add	x0, x22, x20, lsl #3
   40dcc:	mov	x1, x0
   40dd0:	mov	x2, x21
   40dd4:	bl	c2e0 <__gmpn_sub_n@plt>
   40dd8:	ldur	x23, [x29, #-24]
   40ddc:	mov	w3, #0x404                 	// #1028
   40de0:	mov	x1, x25
   40de4:	mov	x2, x19
   40de8:	ldr	x8, [x22, x23, lsl #3]
   40dec:	sub	x8, x8, x0
   40df0:	mov	x0, x27
   40df4:	str	x8, [x22, x23, lsl #3]
   40df8:	bl	ca00 <__gmpn_submul_1@plt>
   40dfc:	mov	w3, #0x514                 	// #1300
   40e00:	mov	x0, x26
   40e04:	mov	x1, x27
   40e08:	mov	x2, x19
   40e0c:	bl	ca00 <__gmpn_submul_1@plt>
   40e10:	mov	w3, #0x1010                	// #4112
   40e14:	movk	w3, #0x10, lsl #16
   40e18:	mov	x0, x26
   40e1c:	mov	x1, x25
   40e20:	mov	x2, x19
   40e24:	bl	ca00 <__gmpn_submul_1@plt>
   40e28:	mov	x4, #0x275b                	// #10075
   40e2c:	mov	x3, #0xb0d3                	// #45267
   40e30:	movk	x4, #0x6864, lsl #16
   40e34:	movk	x3, #0x313f, lsl #16
   40e38:	movk	x4, #0x993a, lsl #32
   40e3c:	movk	x3, #0xb, lsl #32
   40e40:	movk	x4, #0x6db, lsl #48
   40e44:	mov	x0, x26
   40e48:	mov	x1, x26
   40e4c:	mov	x2, x19
   40e50:	mov	w5, wzr
   40e54:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   40e58:	mov	w3, #0xc403                	// #50179
   40e5c:	movk	w3, #0xbf, lsl #16
   40e60:	mov	x0, x27
   40e64:	mov	x1, x26
   40e68:	mov	x2, x19
   40e6c:	bl	ca00 <__gmpn_submul_1@plt>
   40e70:	mov	x4, #0x771b                	// #30491
   40e74:	movk	x4, #0x53e3, lsl #16
   40e78:	movk	x4, #0xc705, lsl #32
   40e7c:	mov	w3, #0xb13                 	// #2835
   40e80:	movk	x4, #0x938c, lsl #48
   40e84:	mov	w5, #0x6                   	// #6
   40e88:	mov	x0, x27
   40e8c:	mov	x1, x27
   40e90:	mov	x2, x19
   40e94:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   40e98:	ldr	x8, [x27, x23, lsl #3]
   40e9c:	lsr	x9, x8, #57
   40ea0:	cbz	x9, 40eac <__gmpn_toom_interpolate_16pts@@Base+0x7f8>
   40ea4:	orr	x8, x8, #0xfc00000000000000
   40ea8:	str	x8, [x27, x23, lsl #3]
   40eac:	ldur	x1, [x29, #-8]
   40eb0:	mov	w3, #0xfff                 	// #4095
   40eb4:	mov	x0, x25
   40eb8:	mov	x2, x19
   40ebc:	bl	ca00 <__gmpn_submul_1@plt>
   40ec0:	mov	w3, #0xf0                  	// #240
   40ec4:	mov	x0, x25
   40ec8:	mov	x1, x27
   40ecc:	mov	x2, x19
   40ed0:	bl	d420 <__gmpn_addmul_1@plt>
   40ed4:	mov	x4, #0xfefefefefefefefe    	// #-72340172838076674
   40ed8:	mov	w3, #0xff                  	// #255
   40edc:	movk	x4, #0xfeff
   40ee0:	mov	w5, #0x2                   	// #2
   40ee4:	mov	x0, x25
   40ee8:	mov	x1, x25
   40eec:	mov	x2, x19
   40ef0:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   40ef4:	ldr	x8, [x25, x23, lsl #3]
   40ef8:	ldr	x24, [sp, #32]
   40efc:	lsr	x9, x8, #61
   40f00:	cbz	x9, 40f0c <__gmpn_toom_interpolate_16pts@@Base+0x858>
   40f04:	orr	x8, x8, #0xc000000000000000
   40f08:	str	x8, [x25, x23, lsl #3]
   40f0c:	ldur	x28, [x29, #-32]
   40f10:	mov	w3, #0x7                   	// #7
   40f14:	mov	x1, x22
   40f18:	mov	x2, x19
   40f1c:	mov	x0, x28
   40f20:	bl	c190 <__gmpn_lshift@plt>
   40f24:	mov	x0, x24
   40f28:	mov	x1, x24
   40f2c:	mov	x2, x28
   40f30:	mov	x3, x19
   40f34:	bl	c2e0 <__gmpn_sub_n@plt>
   40f38:	mov	w3, #0xd                   	// #13
   40f3c:	mov	x0, x28
   40f40:	mov	x1, x22
   40f44:	mov	x2, x19
   40f48:	bl	c190 <__gmpn_lshift@plt>
   40f4c:	ldur	x26, [x29, #-56]
   40f50:	mov	x2, x28
   40f54:	mov	x3, x19
   40f58:	mov	x0, x26
   40f5c:	mov	x1, x26
   40f60:	bl	c2e0 <__gmpn_sub_n@plt>
   40f64:	mov	w3, #0x190                 	// #400
   40f68:	mov	x0, x26
   40f6c:	mov	x1, x24
   40f70:	mov	x2, x19
   40f74:	bl	ca00 <__gmpn_submul_1@plt>
   40f78:	mov	w3, #0x13                  	// #19
   40f7c:	mov	x0, x28
   40f80:	mov	x1, x22
   40f84:	mov	x2, x19
   40f88:	bl	c190 <__gmpn_lshift@plt>
   40f8c:	ldur	x0, [x29, #-40]
   40f90:	mov	x2, x28
   40f94:	mov	x3, x19
   40f98:	mov	x1, x0
   40f9c:	mov	x28, x0
   40fa0:	bl	c2e0 <__gmpn_sub_n@plt>
   40fa4:	mov	w3, #0x594                 	// #1428
   40fa8:	mov	x0, x28
   40fac:	mov	x1, x26
   40fb0:	mov	x2, x19
   40fb4:	bl	ca00 <__gmpn_submul_1@plt>
   40fb8:	mov	w3, #0xb900                	// #47360
   40fbc:	movk	w3, #0x1, lsl #16
   40fc0:	mov	x0, x28
   40fc4:	mov	x1, x24
   40fc8:	mov	x2, x19
   40fcc:	bl	ca00 <__gmpn_submul_1@plt>
   40fd0:	mov	x4, #0xcb25                	// #52005
   40fd4:	mov	x3, #0x58ad                	// #22701
   40fd8:	movk	x4, #0x6fc4, lsl #16
   40fdc:	movk	x3, #0xd916, lsl #16
   40fe0:	movk	x4, #0x9a07, lsl #32
   40fe4:	movk	x3, #0xa, lsl #32
   40fe8:	movk	x4, #0x1b64, lsl #48
   40fec:	mov	x0, x28
   40ff0:	mov	x1, x28
   40ff4:	mov	x2, x19
   40ff8:	mov	w5, wzr
   40ffc:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   41000:	mov	w3, #0xa671                	// #42609
   41004:	movk	w3, #0xe7, lsl #16
   41008:	mov	x0, x26
   4100c:	mov	x1, x28
   41010:	mov	x2, x19
   41014:	bl	ca00 <__gmpn_submul_1@plt>
   41018:	mov	x4, #0x4c35                	// #19509
   4101c:	movk	x4, #0x9f31, lsl #16
   41020:	movk	x4, #0xd44, lsl #32
   41024:	mov	w3, #0xa61d                	// #42525
   41028:	movk	x4, #0xe7b4, lsl #48
   4102c:	mov	w5, #0x4                   	// #4
   41030:	mov	x0, x26
   41034:	mov	x1, x26
   41038:	mov	x2, x19
   4103c:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   41040:	mov	w3, #0xf81                 	// #3969
   41044:	mov	x0, x24
   41048:	mov	x1, x28
   4104c:	mov	x2, x19
   41050:	bl	ca00 <__gmpn_submul_1@plt>
   41054:	mov	w3, #0x384                 	// #900
   41058:	mov	x0, x24
   4105c:	mov	x1, x26
   41060:	mov	x2, x19
   41064:	bl	ca00 <__gmpn_submul_1@plt>
   41068:	mov	x4, #0x8e39                	// #36409
   4106c:	movk	x4, #0x38e3, lsl #16
   41070:	movk	x4, #0xe38e, lsl #32
   41074:	mov	w3, #0x9                   	// #9
   41078:	movk	x4, #0x8e38, lsl #48
   4107c:	mov	w5, #0x4                   	// #4
   41080:	mov	x0, x24
   41084:	mov	x1, x24
   41088:	mov	x2, x19
   4108c:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   41090:	mov	x0, x22
   41094:	mov	x1, x22
   41098:	mov	x2, x28
   4109c:	mov	x3, x19
   410a0:	bl	c2e0 <__gmpn_sub_n@plt>
   410a4:	mov	x0, x22
   410a8:	mov	x1, x22
   410ac:	mov	x2, x24
   410b0:	mov	x3, x19
   410b4:	bl	c2e0 <__gmpn_sub_n@plt>
   410b8:	mov	x0, x22
   410bc:	mov	x1, x22
   410c0:	mov	x2, x26
   410c4:	mov	x3, x19
   410c8:	bl	c2e0 <__gmpn_sub_n@plt>
   410cc:	mov	x0, x25
   410d0:	mov	x1, x26
   410d4:	mov	x2, x25
   410d8:	mov	x3, x19
   410dc:	bl	c970 <__gmpn_rsh1add_n@plt>
   410e0:	ldr	x8, [x25, x23, lsl #3]
   410e4:	mov	x0, x26
   410e8:	mov	x1, x26
   410ec:	mov	x2, x25
   410f0:	and	x8, x8, #0x7fffffffffffffff
   410f4:	mov	x3, x19
   410f8:	str	x8, [x25, x23, lsl #3]
   410fc:	bl	c2e0 <__gmpn_sub_n@plt>
   41100:	mov	x0, x27
   41104:	mov	x1, x24
   41108:	mov	x2, x27
   4110c:	mov	x3, x19
   41110:	bl	c860 <__gmpn_rsh1sub_n@plt>
   41114:	ldr	x8, [x27, x23, lsl #3]
   41118:	mov	x0, x24
   4111c:	mov	x1, x24
   41120:	mov	x2, x27
   41124:	and	x8, x8, #0x7fffffffffffffff
   41128:	mov	x3, x19
   4112c:	str	x8, [x27, x23, lsl #3]
   41130:	bl	c2e0 <__gmpn_sub_n@plt>
   41134:	ldur	x26, [x29, #-8]
   41138:	mov	x1, x28
   4113c:	mov	x3, x19
   41140:	mov	x0, x26
   41144:	mov	x2, x26
   41148:	bl	c970 <__gmpn_rsh1add_n@plt>
   4114c:	ldr	x8, [x26, x23, lsl #3]
   41150:	mov	x0, x28
   41154:	mov	x1, x28
   41158:	mov	x2, x26
   4115c:	and	x8, x8, #0x7fffffffffffffff
   41160:	mov	x3, x19
   41164:	str	x8, [x26, x23, lsl #3]
   41168:	bl	c2e0 <__gmpn_sub_n@plt>
   4116c:	add	x0, x21, x20, lsl #3
   41170:	mov	x1, x0
   41174:	mov	x2, x26
   41178:	mov	x3, x20
   4117c:	bl	ca90 <__gmpn_add_n@plt>
   41180:	ldr	x8, [x26, x20, lsl #3]
   41184:	ldur	x9, [x29, #-16]
   41188:	adds	x8, x8, x0
   4118c:	add	x11, x21, x9, lsl #3
   41190:	str	x8, [x11]
   41194:	b.cc	41208 <__gmpn_toom_interpolate_16pts@@Base+0xb54>  // b.lo, b.ul, b.last
   41198:	add	x8, x26, x20, lsl #3
   4119c:	ldur	x23, [x29, #-16]
   411a0:	ldur	x26, [x29, #-48]
   411a4:	add	x9, x21, x20, lsl #4
   411a8:	mov	w4, #0x1                   	// #1
   411ac:	add	x8, x8, #0x8
   411b0:	add	x9, x9, #0x8
   411b4:	mov	w10, #0x1                   	// #1
   411b8:	cmp	x10, x20
   411bc:	b.ge	41260 <__gmpn_toom_interpolate_16pts@@Base+0xbac>  // b.tcont
   411c0:	ldr	x12, [x8], #8
   411c4:	add	x10, x10, #0x1
   411c8:	adds	x12, x12, #0x1
   411cc:	str	x12, [x9], #8
   411d0:	b.cs	411b8 <__gmpn_toom_interpolate_16pts@@Base+0xb04>  // b.hs, b.nlast
   411d4:	ldr	x12, [sp, #8]
   411d8:	mov	x4, xzr
   411dc:	cmp	x12, x11
   411e0:	b.eq	41260 <__gmpn_toom_interpolate_16pts@@Base+0xbac>  // b.none
   411e4:	cmp	x10, x20
   411e8:	b.ge	41260 <__gmpn_toom_interpolate_16pts@@Base+0xbac>  // b.tcont
   411ec:	mov	x11, x20
   411f0:	ldr	x12, [x8], #8
   411f4:	sub	x11, x11, #0x1
   411f8:	cmp	x10, x11
   411fc:	str	x12, [x9], #8
   41200:	b.ne	411f0 <__gmpn_toom_interpolate_16pts@@Base+0xb3c>  // b.any
   41204:	b	41250 <__gmpn_toom_interpolate_16pts@@Base+0xb9c>
   41208:	cmp	x20, #0x2
   4120c:	mov	x4, xzr
   41210:	b.lt	41258 <__gmpn_toom_interpolate_16pts@@Base+0xba4>  // b.tstop
   41214:	ldr	x8, [sp, #8]
   41218:	ldur	x23, [x29, #-16]
   4121c:	ldur	x26, [x29, #-48]
   41220:	cmp	x8, x11
   41224:	b.eq	41260 <__gmpn_toom_interpolate_16pts@@Base+0xbac>  // b.none
   41228:	ldur	x10, [x29, #-8]
   4122c:	add	x9, x21, x20, lsl #4
   41230:	sub	x8, x20, #0x1
   41234:	add	x9, x9, #0x8
   41238:	add	x10, x10, x20, lsl #3
   4123c:	add	x10, x10, #0x8
   41240:	ldr	x11, [x10], #8
   41244:	subs	x8, x8, #0x1
   41248:	str	x11, [x9], #8
   4124c:	b.ne	41240 <__gmpn_toom_interpolate_16pts@@Base+0xb8c>  // b.any
   41250:	mov	x4, xzr
   41254:	b	41260 <__gmpn_toom_interpolate_16pts@@Base+0xbac>
   41258:	ldur	x23, [x29, #-16]
   4125c:	ldur	x26, [x29, #-48]
   41260:	ldur	x8, [x29, #-24]
   41264:	ldur	x9, [x29, #-8]
   41268:	mov	x0, x25
   4126c:	mov	x1, x25
   41270:	mov	x3, x20
   41274:	ldr	x19, [x9, x8, lsl #3]
   41278:	add	x2, x9, x23, lsl #3
   4127c:	bl	ceb0 <__gmpn_add_nc@plt>
   41280:	lsl	x8, x20, #5
   41284:	ldr	x9, [x21, x8]
   41288:	add	x10, x0, x19
   4128c:	adds	x9, x9, x10
   41290:	str	x9, [x21, x8]
   41294:	b.cc	412b0 <__gmpn_toom_interpolate_16pts@@Base+0xbfc>  // b.lo, b.ul, b.last
   41298:	add	x8, x21, x20, lsl #5
   4129c:	add	x8, x8, #0x8
   412a0:	ldr	x9, [x8]
   412a4:	adds	x9, x9, #0x1
   412a8:	str	x9, [x8], #8
   412ac:	b.cs	412a0 <__gmpn_toom_interpolate_16pts@@Base+0xbec>  // b.hs, b.nlast
   412b0:	mov	w8, #0x28                  	// #40
   412b4:	madd	x0, x20, x8, x21
   412b8:	mov	x1, x0
   412bc:	mov	x2, x27
   412c0:	mov	x3, x20
   412c4:	bl	ca90 <__gmpn_add_n@plt>
   412c8:	add	x8, x20, x20, lsl #1
   412cc:	add	x11, x21, x8, lsl #4
   412d0:	ldr	x9, [x11]
   412d4:	add	x12, x27, x20, lsl #3
   412d8:	ldur	x25, [x29, #-24]
   412dc:	add	x10, x9, x0
   412e0:	str	x10, [x11]
   412e4:	ldr	x13, [x12]
   412e8:	lsl	x9, x8, #1
   412ec:	adds	x8, x13, x10
   412f0:	str	x8, [x11]
   412f4:	b.cc	41358 <__gmpn_toom_interpolate_16pts@@Base+0xca4>  // b.lo, b.ul, b.last
   412f8:	add	x9, x21, x9, lsl #3
   412fc:	add	x8, x12, #0x8
   41300:	mov	w4, #0x1                   	// #1
   41304:	add	x9, x9, #0x8
   41308:	mov	w10, #0x1                   	// #1
   4130c:	cmp	x10, x20
   41310:	b.ge	41394 <__gmpn_toom_interpolate_16pts@@Base+0xce0>  // b.tcont
   41314:	ldr	x13, [x8], #8
   41318:	add	x10, x10, #0x1
   4131c:	adds	x13, x13, #0x1
   41320:	str	x13, [x9], #8
   41324:	b.cs	4130c <__gmpn_toom_interpolate_16pts@@Base+0xc58>  // b.hs, b.nlast
   41328:	cmp	x12, x11
   4132c:	mov	x4, xzr
   41330:	b.eq	41394 <__gmpn_toom_interpolate_16pts@@Base+0xce0>  // b.none
   41334:	cmp	x10, x20
   41338:	b.ge	41394 <__gmpn_toom_interpolate_16pts@@Base+0xce0>  // b.tcont
   4133c:	mov	x11, x20
   41340:	ldr	x12, [x8], #8
   41344:	sub	x11, x11, #0x1
   41348:	cmp	x10, x11
   4134c:	str	x12, [x9], #8
   41350:	b.ne	41340 <__gmpn_toom_interpolate_16pts@@Base+0xc8c>  // b.any
   41354:	b	41390 <__gmpn_toom_interpolate_16pts@@Base+0xcdc>
   41358:	cmp	x20, #0x2
   4135c:	mov	x4, xzr
   41360:	b.lt	41394 <__gmpn_toom_interpolate_16pts@@Base+0xce0>  // b.tstop
   41364:	cmp	x12, x11
   41368:	b.eq	41394 <__gmpn_toom_interpolate_16pts@@Base+0xce0>  // b.none
   4136c:	add	x9, x21, x9, lsl #3
   41370:	add	x10, x27, x20, lsl #3
   41374:	sub	x8, x20, #0x1
   41378:	add	x9, x9, #0x8
   4137c:	add	x10, x10, #0x8
   41380:	ldr	x11, [x10], #8
   41384:	subs	x8, x8, #0x1
   41388:	str	x11, [x9], #8
   4138c:	b.ne	41380 <__gmpn_toom_interpolate_16pts@@Base+0xccc>  // b.any
   41390:	mov	x4, xzr
   41394:	ldr	x19, [x27, x25, lsl #3]
   41398:	add	x2, x27, x23, lsl #3
   4139c:	mov	x0, x22
   413a0:	mov	x1, x22
   413a4:	mov	x3, x20
   413a8:	bl	ceb0 <__gmpn_add_nc@plt>
   413ac:	lsl	x8, x20, #6
   413b0:	ldr	x9, [x21, x8]
   413b4:	add	x10, x0, x19
   413b8:	adds	x9, x9, x10
   413bc:	str	x9, [x21, x8]
   413c0:	b.cc	413e0 <__gmpn_toom_interpolate_16pts@@Base+0xd2c>  // b.lo, b.ul, b.last
   413c4:	ldr	x8, [sp, #24]
   413c8:	add	x8, x21, x8, lsl #3
   413cc:	add	x8, x8, #0x8
   413d0:	ldr	x9, [x8]
   413d4:	adds	x9, x9, #0x1
   413d8:	str	x9, [x8], #8
   413dc:	b.cs	413d0 <__gmpn_toom_interpolate_16pts@@Base+0xd1c>  // b.hs, b.nlast
   413e0:	mov	w8, #0x48                  	// #72
   413e4:	madd	x0, x20, x8, x21
   413e8:	mov	x1, x0
   413ec:	mov	x2, x24
   413f0:	mov	x3, x20
   413f4:	bl	ca90 <__gmpn_add_n@plt>
   413f8:	mov	w8, #0x50                  	// #80
   413fc:	madd	x10, x20, x8, x21
   41400:	ldr	x8, [x10]
   41404:	add	x8, x8, x0
   41408:	str	x8, [x10]
   4140c:	ldr	x9, [x24, x20, lsl #3]
   41410:	adds	x8, x9, x8
   41414:	str	x8, [x10]
   41418:	b.cc	41488 <__gmpn_toom_interpolate_16pts@@Base+0xdd4>  // b.lo, b.ul, b.last
   4141c:	mov	w9, #0x50                  	// #80
   41420:	add	x8, x24, x20, lsl #3
   41424:	madd	x9, x20, x9, x21
   41428:	mov	w4, #0x1                   	// #1
   4142c:	add	x8, x8, #0x8
   41430:	add	x9, x9, #0x8
   41434:	mov	w11, #0x1                   	// #1
   41438:	cmp	x11, x20
   4143c:	b.ge	414cc <__gmpn_toom_interpolate_16pts@@Base+0xe18>  // b.tcont
   41440:	ldr	x12, [x8], #8
   41444:	add	x11, x11, #0x1
   41448:	adds	x12, x12, #0x1
   4144c:	str	x12, [x9], #8
   41450:	b.cs	41438 <__gmpn_toom_interpolate_16pts@@Base+0xd84>  // b.hs, b.nlast
   41454:	ldr	x12, [sp, #16]
   41458:	mov	x4, xzr
   4145c:	cmp	x12, x10
   41460:	b.eq	414cc <__gmpn_toom_interpolate_16pts@@Base+0xe18>  // b.none
   41464:	cmp	x11, x20
   41468:	b.ge	414cc <__gmpn_toom_interpolate_16pts@@Base+0xe18>  // b.tcont
   4146c:	mov	x10, x20
   41470:	ldr	x12, [x8], #8
   41474:	sub	x10, x10, #0x1
   41478:	cmp	x11, x10
   4147c:	str	x12, [x9], #8
   41480:	b.ne	41470 <__gmpn_toom_interpolate_16pts@@Base+0xdbc>  // b.any
   41484:	b	414c8 <__gmpn_toom_interpolate_16pts@@Base+0xe14>
   41488:	cmp	x20, #0x2
   4148c:	mov	x4, xzr
   41490:	b.lt	414cc <__gmpn_toom_interpolate_16pts@@Base+0xe18>  // b.tstop
   41494:	ldr	x8, [sp, #16]
   41498:	cmp	x8, x10
   4149c:	b.eq	414cc <__gmpn_toom_interpolate_16pts@@Base+0xe18>  // b.none
   414a0:	mov	w9, #0x50                  	// #80
   414a4:	add	x10, x24, x20, lsl #3
   414a8:	madd	x9, x20, x9, x21
   414ac:	sub	x8, x20, #0x1
   414b0:	add	x9, x9, #0x8
   414b4:	add	x10, x10, #0x8
   414b8:	ldr	x11, [x10], #8
   414bc:	subs	x8, x8, #0x1
   414c0:	str	x11, [x9], #8
   414c4:	b.ne	414b8 <__gmpn_toom_interpolate_16pts@@Base+0xe04>  // b.any
   414c8:	mov	x4, xzr
   414cc:	ldur	x0, [x29, #-56]
   414d0:	ldr	x19, [x24, x25, lsl #3]
   414d4:	add	x2, x24, x23, lsl #3
   414d8:	mov	x3, x20
   414dc:	mov	x1, x0
   414e0:	bl	ceb0 <__gmpn_add_nc@plt>
   414e4:	mov	w8, #0x60                  	// #96
   414e8:	mul	x8, x20, x8
   414ec:	ldr	x9, [x21, x8]
   414f0:	add	x10, x0, x19
   414f4:	adds	x9, x9, x10
   414f8:	str	x9, [x21, x8]
   414fc:	b.cc	4151c <__gmpn_toom_interpolate_16pts@@Base+0xe68>  // b.lo, b.ul, b.last
   41500:	mov	w8, #0x60                  	// #96
   41504:	madd	x8, x20, x8, x21
   41508:	add	x8, x8, #0x8
   4150c:	ldr	x9, [x8]
   41510:	adds	x9, x9, #0x1
   41514:	str	x9, [x8], #8
   41518:	b.cs	4150c <__gmpn_toom_interpolate_16pts@@Base+0xe58>  // b.hs, b.nlast
   4151c:	mov	w8, #0x68                  	// #104
   41520:	madd	x0, x20, x8, x21
   41524:	mov	x1, x0
   41528:	mov	x2, x28
   4152c:	mov	x3, x20
   41530:	bl	ca90 <__gmpn_add_n@plt>
   41534:	mov	w8, #0x70                  	// #112
   41538:	madd	x8, x20, x8, x21
   4153c:	ldr	x9, [x8]
   41540:	ldr	w11, [sp, #52]
   41544:	add	x9, x9, x0
   41548:	str	x9, [x8]
   4154c:	ldr	x10, [x28, x20, lsl #3]
   41550:	add	x10, x10, x9
   41554:	str	x10, [x8]
   41558:	cbz	w11, 415d0 <__gmpn_toom_interpolate_16pts@@Base+0xf1c>
   4155c:	cmp	x10, x9
   41560:	b.cs	41638 <__gmpn_toom_interpolate_16pts@@Base+0xf84>  // b.hs, b.nlast
   41564:	mov	w10, #0x70                  	// #112
   41568:	add	x9, x28, x20, lsl #3
   4156c:	madd	x10, x20, x10, x21
   41570:	mov	w4, #0x1                   	// #1
   41574:	add	x9, x9, #0x8
   41578:	add	x10, x10, #0x8
   4157c:	mov	w11, #0x1                   	// #1
   41580:	cmp	x11, x20
   41584:	b.ge	4167c <__gmpn_toom_interpolate_16pts@@Base+0xfc8>  // b.tcont
   41588:	ldr	x12, [x9], #8
   4158c:	add	x11, x11, #0x1
   41590:	adds	x12, x12, #0x1
   41594:	str	x12, [x10], #8
   41598:	b.cs	41580 <__gmpn_toom_interpolate_16pts@@Base+0xecc>  // b.hs, b.nlast
   4159c:	ldr	x12, [sp, #64]
   415a0:	mov	x4, xzr
   415a4:	cmp	x12, x8
   415a8:	b.eq	4167c <__gmpn_toom_interpolate_16pts@@Base+0xfc8>  // b.none
   415ac:	cmp	x11, x20
   415b0:	b.ge	4167c <__gmpn_toom_interpolate_16pts@@Base+0xfc8>  // b.tcont
   415b4:	mov	x8, x20
   415b8:	ldr	x12, [x9], #8
   415bc:	sub	x8, x8, #0x1
   415c0:	cmp	x11, x8
   415c4:	str	x12, [x10], #8
   415c8:	b.ne	415b8 <__gmpn_toom_interpolate_16pts@@Base+0xf04>  // b.any
   415cc:	b	41678 <__gmpn_toom_interpolate_16pts@@Base+0xfc4>
   415d0:	cmp	x10, x9
   415d4:	b.cs	416d4 <__gmpn_toom_interpolate_16pts@@Base+0x1020>  // b.hs, b.nlast
   415d8:	mov	w10, #0x70                  	// #112
   415dc:	add	x9, x28, x20, lsl #3
   415e0:	madd	x10, x20, x10, x21
   415e4:	add	x9, x9, #0x8
   415e8:	add	x10, x10, #0x8
   415ec:	mov	w11, #0x1                   	// #1
   415f0:	cmp	x11, x26
   415f4:	b.ge	41710 <__gmpn_toom_interpolate_16pts@@Base+0x105c>  // b.tcont
   415f8:	ldr	x12, [x9], #8
   415fc:	add	x11, x11, #0x1
   41600:	adds	x12, x12, #0x1
   41604:	str	x12, [x10], #8
   41608:	b.cs	415f0 <__gmpn_toom_interpolate_16pts@@Base+0xf3c>  // b.hs, b.nlast
   4160c:	ldr	x12, [sp, #64]
   41610:	cmp	x12, x8
   41614:	b.eq	41710 <__gmpn_toom_interpolate_16pts@@Base+0x105c>  // b.none
   41618:	cmp	x11, x26
   4161c:	b.ge	41710 <__gmpn_toom_interpolate_16pts@@Base+0x105c>  // b.tcont
   41620:	ldr	x8, [x9], #8
   41624:	sub	x26, x26, #0x1
   41628:	cmp	x11, x26
   4162c:	str	x8, [x10], #8
   41630:	b.ne	41620 <__gmpn_toom_interpolate_16pts@@Base+0xf6c>  // b.any
   41634:	b	41710 <__gmpn_toom_interpolate_16pts@@Base+0x105c>
   41638:	cmp	x20, #0x2
   4163c:	mov	x4, xzr
   41640:	b.lt	4167c <__gmpn_toom_interpolate_16pts@@Base+0xfc8>  // b.tstop
   41644:	ldr	x9, [sp, #64]
   41648:	cmp	x9, x8
   4164c:	b.eq	4167c <__gmpn_toom_interpolate_16pts@@Base+0xfc8>  // b.none
   41650:	mov	w9, #0x70                  	// #112
   41654:	add	x10, x28, x20, lsl #3
   41658:	madd	x9, x20, x9, x21
   4165c:	sub	x8, x20, #0x1
   41660:	add	x9, x9, #0x8
   41664:	add	x10, x10, #0x8
   41668:	ldr	x11, [x10], #8
   4166c:	subs	x8, x8, #0x1
   41670:	str	x11, [x9], #8
   41674:	b.ne	41668 <__gmpn_toom_interpolate_16pts@@Base+0xfb4>  // b.any
   41678:	mov	x4, xzr
   4167c:	cmp	x26, x20
   41680:	b.le	41730 <__gmpn_toom_interpolate_16pts@@Base+0x107c>
   41684:	ldr	x19, [x28, x25, lsl #3]
   41688:	mov	w8, #0x78                  	// #120
   4168c:	madd	x0, x20, x8, x21
   41690:	add	x2, x28, x23, lsl #3
   41694:	mov	x1, x0
   41698:	mov	x3, x20
   4169c:	bl	ceb0 <__gmpn_add_nc@plt>
   416a0:	lsl	x8, x20, #7
   416a4:	ldr	x9, [x21, x8]
   416a8:	add	x10, x0, x19
   416ac:	adds	x9, x9, x10
   416b0:	str	x9, [x21, x8]
   416b4:	b.cc	41710 <__gmpn_toom_interpolate_16pts@@Base+0x105c>  // b.lo, b.ul, b.last
   416b8:	add	x8, x21, x20, lsl #7
   416bc:	add	x8, x8, #0x8
   416c0:	ldr	x9, [x8]
   416c4:	adds	x9, x9, #0x1
   416c8:	str	x9, [x8], #8
   416cc:	b.cs	416c0 <__gmpn_toom_interpolate_16pts@@Base+0x100c>  // b.hs, b.nlast
   416d0:	b	41710 <__gmpn_toom_interpolate_16pts@@Base+0x105c>
   416d4:	cmp	x26, #0x2
   416d8:	b.lt	41710 <__gmpn_toom_interpolate_16pts@@Base+0x105c>  // b.tstop
   416dc:	ldr	x9, [sp, #64]
   416e0:	cmp	x9, x8
   416e4:	b.eq	41710 <__gmpn_toom_interpolate_16pts@@Base+0x105c>  // b.none
   416e8:	mov	w9, #0x70                  	// #112
   416ec:	add	x10, x28, x20, lsl #3
   416f0:	madd	x9, x20, x9, x21
   416f4:	sub	x8, x26, #0x1
   416f8:	add	x9, x9, #0x8
   416fc:	add	x10, x10, #0x8
   41700:	ldr	x11, [x10], #8
   41704:	subs	x8, x8, #0x1
   41708:	str	x11, [x9], #8
   4170c:	b.ne	41700 <__gmpn_toom_interpolate_16pts@@Base+0x104c>  // b.any
   41710:	ldp	x20, x19, [sp, #208]
   41714:	ldp	x22, x21, [sp, #192]
   41718:	ldp	x24, x23, [sp, #176]
   4171c:	ldp	x26, x25, [sp, #160]
   41720:	ldp	x28, x27, [sp, #144]
   41724:	ldp	x29, x30, [sp, #128]
   41728:	add	sp, sp, #0xe0
   4172c:	ret
   41730:	mov	w8, #0x78                  	// #120
   41734:	madd	x0, x20, x8, x21
   41738:	add	x2, x28, x23, lsl #3
   4173c:	mov	x3, x26
   41740:	ldp	x20, x19, [sp, #208]
   41744:	ldp	x22, x21, [sp, #192]
   41748:	ldp	x24, x23, [sp, #176]
   4174c:	ldp	x26, x25, [sp, #160]
   41750:	ldp	x28, x27, [sp, #144]
   41754:	ldp	x29, x30, [sp, #128]
   41758:	mov	x1, x0
   4175c:	add	sp, sp, #0xe0
   41760:	b	ceb0 <__gmpn_add_nc@plt>

0000000000041764 <__gmpn_ni_invertappr@@Base>:
   41764:	stp	x29, x30, [sp, #-96]!
   41768:	stp	x28, x27, [sp, #16]
   4176c:	stp	x26, x25, [sp, #32]
   41770:	stp	x24, x23, [sp, #48]
   41774:	stp	x22, x21, [sp, #64]
   41778:	stp	x20, x19, [sp, #80]
   4177c:	mov	x29, sp
   41780:	sub	sp, sp, #0x1a0
   41784:	mov	x19, sp
   41788:	mov	x20, x3
   4178c:	mov	x23, x2
   41790:	mov	x25, x1
   41794:	mov	x26, x0
   41798:	mov	x22, xzr
   4179c:	add	x8, x19, #0x58
   417a0:	mov	x21, x2
   417a4:	asr	x9, x21, #1
   417a8:	str	x21, [x8, x22, lsl #3]
   417ac:	cmp	x21, #0x143
   417b0:	add	x21, x9, #0x1
   417b4:	add	x22, x22, #0x1
   417b8:	b.gt	417a4 <__gmpn_ni_invertappr@@Base+0x40>
   417bc:	add	x11, x25, x23, lsl #3
   417c0:	add	x10, x26, x23, lsl #3
   417c4:	mvn	x8, x9
   417c8:	add	x0, x10, x8, lsl #3
   417cc:	add	x1, x11, x8, lsl #3
   417d0:	mov	x2, x21
   417d4:	mov	x3, x20
   417d8:	stp	x10, x11, [x19, #64]
   417dc:	bl	41c58 <__gmpn_ni_invertappr@@Base+0x4f4>
   417e0:	add	x0, x23, #0x1
   417e4:	str	xzr, [x19, #80]
   417e8:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   417ec:	asr	x8, x0, #1
   417f0:	cmp	x8, x23, asr #1
   417f4:	csel	x9, x8, x0, gt
   417f8:	cmp	x8, x23
   417fc:	csel	x8, x9, xzr, lt  // lt = tstop
   41800:	add	x8, x0, x8
   41804:	lsl	x8, x8, #3
   41808:	add	x1, x8, #0x20
   4180c:	mov	w8, #0x7f00                	// #32512
   41810:	cmp	x1, x8
   41814:	b.hi	41c40 <__gmpn_ni_invertappr@@Base+0x4dc>  // b.pmore
   41818:	add	x9, x1, #0xf
   4181c:	mov	x8, sp
   41820:	and	x9, x9, #0xfffffffffffffff0
   41824:	sub	x8, x8, x9
   41828:	str	x8, [x19, #16]
   4182c:	mov	sp, x8
   41830:	add	x8, x20, #0x8
   41834:	str	x8, [x19, #32]
   41838:	add	x8, x25, x23, lsl #3
   4183c:	sub	x9, x20, #0x8
   41840:	str	x9, [x19, #8]
   41844:	add	x9, x26, x23, lsl #3
   41848:	sub	x8, x8, #0x8
   4184c:	str	x8, [x19, #48]
   41850:	add	x8, x9, #0x8
   41854:	str	x8, [x19, #24]
   41858:	sub	x22, x22, #0x1
   4185c:	add	x8, x19, #0x58
   41860:	ldr	x23, [x8, x22, lsl #3]
   41864:	neg	x24, x21
   41868:	add	x0, x23, #0x1
   4186c:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   41870:	add	x8, x23, x21
   41874:	ldr	x9, [x19, #72]
   41878:	cmp	x0, x8
   4187c:	ldr	x8, [x19, #64]
   41880:	sub	x25, x9, x23, lsl #3
   41884:	sub	x4, x8, x21, lsl #3
   41888:	str	x4, [x19, #56]
   4188c:	b.le	418c8 <__gmpn_ni_invertappr@@Base+0x164>
   41890:	mov	x0, x20
   41894:	mov	x1, x25
   41898:	mov	x2, x23
   4189c:	mov	x3, x4
   418a0:	mov	x4, x21
   418a4:	bl	ccf0 <__gmpn_mul@plt>
   418a8:	add	x0, x20, x21, lsl #3
   418ac:	sub	x8, x23, x21
   418b0:	add	x3, x8, #0x1
   418b4:	mov	x1, x0
   418b8:	mov	x2, x25
   418bc:	bl	ca90 <__gmpn_add_n@plt>
   418c0:	mov	w8, #0x1                   	// #1
   418c4:	b	419a4 <__gmpn_ni_invertappr@@Base+0x240>
   418c8:	ldr	x6, [x19, #16]
   418cc:	mov	x26, x0
   418d0:	mov	x0, x20
   418d4:	mov	x1, x26
   418d8:	mov	x2, x25
   418dc:	mov	x3, x23
   418e0:	mov	x5, x21
   418e4:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   418e8:	add	x27, x20, x21, lsl #3
   418ec:	sub	x28, x26, x21
   418f0:	mov	x0, x27
   418f4:	mov	x1, x27
   418f8:	mov	x2, x25
   418fc:	mov	x3, x28
   41900:	bl	ca90 <__gmpn_add_n@plt>
   41904:	ldr	x8, [x19, #72]
   41908:	sub	x3, x23, x28
   4190c:	mov	x4, x0
   41910:	mov	x0, x20
   41914:	sub	x2, x8, x3, lsl #3
   41918:	mov	x1, x20
   4191c:	bl	ceb0 <__gmpn_add_nc@plt>
   41920:	mov	w10, #0x1                   	// #1
   41924:	add	x8, x27, x23, lsl #3
   41928:	str	x10, [x20, x26, lsl #3]
   4192c:	sub	x8, x8, x26, lsl #3
   41930:	ldr	x9, [x8]
   41934:	sub	x10, x10, x0
   41938:	subs	x9, x9, x10
   4193c:	str	x9, [x8]
   41940:	b.cs	41964 <__gmpn_ni_invertappr@@Base+0x200>  // b.hs, b.nlast
   41944:	ldr	x9, [x19, #32]
   41948:	add	x8, x21, x23
   4194c:	sub	x8, x8, x26
   41950:	add	x8, x9, x8, lsl #3
   41954:	ldr	x9, [x8]
   41958:	sub	x10, x9, #0x1
   4195c:	str	x10, [x8], #8
   41960:	cbz	x9, 41954 <__gmpn_ni_invertappr@@Base+0x1f0>
   41964:	ldr	x8, [x20, x26, lsl #3]
   41968:	ldr	x9, [x20]
   4196c:	mov	w10, #0x1                   	// #1
   41970:	add	x8, x8, x9
   41974:	sub	x8, x8, #0x1
   41978:	str	x8, [x20]
   4197c:	ldr	x8, [x20, x26, lsl #3]
   41980:	sub	x8, x10, x8
   41984:	cmp	x9, x8
   41988:	b.cs	419a0 <__gmpn_ni_invertappr@@Base+0x23c>  // b.hs, b.nlast
   4198c:	ldr	x8, [x19, #32]
   41990:	ldr	x9, [x8]
   41994:	sub	x10, x9, #0x1
   41998:	str	x10, [x8], #8
   4199c:	cbz	x9, 41990 <__gmpn_ni_invertappr@@Base+0x22c>
   419a0:	mov	x8, xzr
   419a4:	add	x26, x20, x23, lsl #3
   419a8:	ldr	x28, [x26]
   419ac:	neg	x27, x23
   419b0:	cmp	x28, #0x1
   419b4:	b.hi	41a08 <__gmpn_ni_invertappr@@Base+0x2a4>  // b.pmore
   419b8:	cbz	x28, 41a98 <__gmpn_ni_invertappr@@Base+0x334>
   419bc:	ldr	x8, [x19, #48]
   419c0:	add	x12, x28, #0x1
   419c4:	mov	x10, x23
   419c8:	subs	x9, x10, #0x1
   419cc:	b.lt	41a7c <__gmpn_ni_invertappr@@Base+0x318>  // b.tstop
   419d0:	add	x10, x20, x10, lsl #3
   419d4:	ldur	x10, [x10, #-8]
   419d8:	ldr	x11, [x8], #-8
   419dc:	cmp	x10, x11
   419e0:	mov	x10, x9
   419e4:	b.eq	419c8 <__gmpn_ni_invertappr@@Base+0x264>  // b.none
   419e8:	b.ls	41a7c <__gmpn_ni_invertappr@@Base+0x318>  // b.plast
   419ec:	mov	x0, x20
   419f0:	mov	x1, x20
   419f4:	mov	x2, x25
   419f8:	mov	x3, x23
   419fc:	bl	c460 <__gmpn_sublsh1_n@plt>
   41a00:	add	x8, x28, #0x2
   41a04:	b	41a9c <__gmpn_ni_invertappr@@Base+0x338>
   41a08:	ldr	x9, [x20]
   41a0c:	subs	x8, x9, x8
   41a10:	str	x8, [x20]
   41a14:	b.cs	41a2c <__gmpn_ni_invertappr@@Base+0x2c8>  // b.hs, b.nlast
   41a18:	ldr	x8, [x19, #32]
   41a1c:	ldr	x9, [x8]
   41a20:	sub	x10, x9, #0x1
   41a24:	str	x10, [x8], #8
   41a28:	cbz	x9, 41a1c <__gmpn_ni_invertappr@@Base+0x2b8>
   41a2c:	ldr	x8, [x26]
   41a30:	ldr	x28, [x19, #56]
   41a34:	cmn	x8, #0x1
   41a38:	b.eq	41a64 <__gmpn_ni_invertappr@@Base+0x300>  // b.none
   41a3c:	mov	x8, x28
   41a40:	ldr	x9, [x8]
   41a44:	adds	x9, x9, #0x1
   41a48:	str	x9, [x8], #8
   41a4c:	b.cs	41a40 <__gmpn_ni_invertappr@@Base+0x2dc>  // b.hs, b.nlast
   41a50:	mov	x0, x20
   41a54:	mov	x1, x20
   41a58:	mov	x2, x25
   41a5c:	mov	x3, x23
   41a60:	bl	ca90 <__gmpn_add_n@plt>
   41a64:	add	x8, x20, x23, lsl #4
   41a68:	add	x0, x8, x24, lsl #3
   41a6c:	add	x1, x26, x24, lsl #3
   41a70:	mov	x2, x21
   41a74:	bl	c2a0 <__gmpn_com@plt>
   41a78:	b	41b78 <__gmpn_ni_invertappr@@Base+0x414>
   41a7c:	mov	x0, x20
   41a80:	mov	x1, x20
   41a84:	mov	x2, x25
   41a88:	mov	x3, x23
   41a8c:	str	x12, [x19, #40]
   41a90:	bl	c2e0 <__gmpn_sub_n@plt>
   41a94:	b	41aa0 <__gmpn_ni_invertappr@@Base+0x33c>
   41a98:	mov	w8, #0x1                   	// #1
   41a9c:	str	x8, [x19, #40]
   41aa0:	ldp	x8, x28, [x19, #48]
   41aa4:	ldr	x13, [x19, #72]
   41aa8:	mov	x10, x23
   41aac:	subs	x9, x10, #0x1
   41ab0:	b.lt	41af0 <__gmpn_ni_invertappr@@Base+0x38c>  // b.tstop
   41ab4:	add	x10, x20, x10, lsl #3
   41ab8:	ldur	x10, [x10, #-8]
   41abc:	ldr	x11, [x8], #-8
   41ac0:	cmp	x10, x11
   41ac4:	mov	x10, x9
   41ac8:	b.eq	41aac <__gmpn_ni_invertappr@@Base+0x348>  // b.none
   41acc:	b.ls	41af0 <__gmpn_ni_invertappr@@Base+0x38c>  // b.plast
   41ad0:	mov	x0, x26
   41ad4:	mov	x1, x20
   41ad8:	mov	x2, x25
   41adc:	mov	x3, x23
   41ae0:	bl	d0b0 <__gmpn_rsblsh1_n@plt>
   41ae4:	ldr	x9, [x19, #40]
   41ae8:	add	x9, x9, #0x1
   41aec:	b	41b50 <__gmpn_ni_invertappr@@Base+0x3ec>
   41af0:	add	x8, x20, x23, lsl #4
   41af4:	add	x0, x8, x24, lsl #3
   41af8:	ldr	x8, [x19, #48]
   41afc:	ldr	x12, [x19, #8]
   41b00:	add	x1, x13, x24, lsl #3
   41b04:	add	x2, x26, x24, lsl #3
   41b08:	sub	x9, x23, x21
   41b0c:	add	x8, x8, x24, lsl #3
   41b10:	subs	x10, x9, #0x1
   41b14:	b.lt	41b38 <__gmpn_ni_invertappr@@Base+0x3d4>  // b.tstop
   41b18:	ldr	x9, [x12, x9, lsl #3]
   41b1c:	ldr	x11, [x8], #-8
   41b20:	cmp	x9, x11
   41b24:	mov	x9, x10
   41b28:	b.eq	41b10 <__gmpn_ni_invertappr@@Base+0x3ac>  // b.none
   41b2c:	mov	w8, #0x1                   	// #1
   41b30:	cneg	w8, w8, ls  // ls = plast
   41b34:	b	41b3c <__gmpn_ni_invertappr@@Base+0x3d8>
   41b38:	mov	w8, wzr
   41b3c:	cmp	w8, #0x0
   41b40:	cset	w4, gt
   41b44:	mov	x3, x21
   41b48:	bl	c780 <__gmpn_sub_nc@plt>
   41b4c:	ldr	x9, [x19, #40]
   41b50:	ldr	x8, [x28]
   41b54:	subs	x8, x8, x9
   41b58:	str	x8, [x28]
   41b5c:	b.cs	41b78 <__gmpn_ni_invertappr@@Base+0x414>  // b.hs, b.nlast
   41b60:	ldr	x8, [x19, #24]
   41b64:	add	x8, x8, x24, lsl #3
   41b68:	ldr	x9, [x8]
   41b6c:	sub	x10, x9, #0x1
   41b70:	str	x10, [x8], #8
   41b74:	cbz	x9, 41b68 <__gmpn_ni_invertappr@@Base+0x404>
   41b78:	add	x8, x20, x23, lsl #4
   41b7c:	add	x25, x8, x24, lsl #3
   41b80:	mov	x0, x20
   41b84:	mov	x1, x25
   41b88:	mov	x2, x28
   41b8c:	mov	x3, x21
   41b90:	bl	c9b0 <__gmpn_mul_n@plt>
   41b94:	add	x0, x20, x21, lsl #3
   41b98:	lsl	x8, x21, #1
   41b9c:	sub	x3, x8, x23
   41ba0:	mov	x1, x0
   41ba4:	mov	x2, x25
   41ba8:	bl	ca90 <__gmpn_add_n@plt>
   41bac:	ldr	x28, [x19, #64]
   41bb0:	add	x25, x21, x21, lsl #1
   41bb4:	add	x8, x20, x25, lsl #3
   41bb8:	mov	x4, x0
   41bbc:	add	x0, x28, x27, lsl #3
   41bc0:	add	x2, x26, x21, lsl #3
   41bc4:	add	x1, x8, x27, lsl #3
   41bc8:	sub	x3, x23, x21
   41bcc:	bl	ceb0 <__gmpn_add_nc@plt>
   41bd0:	ldr	x8, [x28, x24, lsl #3]
   41bd4:	adds	x8, x8, x0
   41bd8:	str	x8, [x28, x24, lsl #3]
   41bdc:	b.cc	41bf8 <__gmpn_ni_invertappr@@Base+0x494>  // b.lo, b.ul, b.last
   41be0:	ldr	x8, [x19, #24]
   41be4:	add	x8, x8, x24, lsl #3
   41be8:	ldr	x9, [x8]
   41bec:	adds	x9, x9, #0x1
   41bf0:	str	x9, [x8], #8
   41bf4:	b.cs	41be8 <__gmpn_ni_invertappr@@Base+0x484>  // b.hs, b.nlast
   41bf8:	mov	x21, x23
   41bfc:	cbnz	x22, 41858 <__gmpn_ni_invertappr@@Base+0xf4>
   41c00:	mvn	x8, x23
   41c04:	add	x8, x25, x8
   41c08:	ldr	x8, [x20, x8, lsl #3]
   41c0c:	ldr	x0, [x19, #80]
   41c10:	cmn	x8, #0x8
   41c14:	cset	w20, hi  // hi = pmore
   41c18:	cbnz	x0, 41c50 <__gmpn_ni_invertappr@@Base+0x4ec>
   41c1c:	mov	x0, x20
   41c20:	mov	sp, x29
   41c24:	ldp	x20, x19, [sp, #80]
   41c28:	ldp	x22, x21, [sp, #64]
   41c2c:	ldp	x24, x23, [sp, #48]
   41c30:	ldp	x26, x25, [sp, #32]
   41c34:	ldp	x28, x27, [sp, #16]
   41c38:	ldp	x29, x30, [sp], #96
   41c3c:	ret
   41c40:	add	x0, x19, #0x50
   41c44:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   41c48:	str	x0, [x19, #16]
   41c4c:	b	41830 <__gmpn_ni_invertappr@@Base+0xcc>
   41c50:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   41c54:	b	41c1c <__gmpn_ni_invertappr@@Base+0x4b8>
   41c58:	stp	x29, x30, [sp, #-64]!
   41c5c:	stp	x20, x19, [sp, #48]
   41c60:	mov	x20, x1
   41c64:	cmp	x2, #0x1
   41c68:	mov	x19, x0
   41c6c:	stp	x24, x23, [sp, #16]
   41c70:	stp	x22, x21, [sp, #32]
   41c74:	mov	x29, sp
   41c78:	b.ne	41c94 <__gmpn_ni_invertappr@@Base+0x530>  // b.any
   41c7c:	ldr	x0, [x20]
   41c80:	bl	d410 <__gmpn_invert_limb@plt>
   41c84:	mov	x8, x0
   41c88:	mov	x0, xzr
   41c8c:	str	x8, [x19]
   41c90:	b	41d7c <__gmpn_ni_invertappr@@Base+0x618>
   41c94:	mov	x22, x2
   41c98:	lsl	x2, x2, #3
   41c9c:	mov	w1, #0xff                  	// #255
   41ca0:	mov	x0, x3
   41ca4:	mov	x21, x3
   41ca8:	bl	c610 <memset@plt>
   41cac:	add	x0, x21, x22, lsl #3
   41cb0:	mov	x1, x20
   41cb4:	mov	x2, x22
   41cb8:	bl	c2a0 <__gmpn_com@plt>
   41cbc:	cmp	x22, #0x2
   41cc0:	b.ne	41ce4 <__gmpn_ni_invertappr@@Base+0x580>  // b.any
   41cc4:	mov	w3, #0x4                   	// #4
   41cc8:	mov	x0, x19
   41ccc:	mov	x1, xzr
   41cd0:	mov	x2, x21
   41cd4:	mov	x4, x20
   41cd8:	bl	c210 <__gmpn_divrem_2@plt>
   41cdc:	mov	x0, xzr
   41ce0:	b	41d7c <__gmpn_ni_invertappr@@Base+0x618>
   41ce4:	add	x24, x20, x22, lsl #3
   41ce8:	ldur	x23, [x24, #-8]
   41cec:	mov	x0, x23
   41cf0:	bl	d410 <__gmpn_invert_limb@plt>
   41cf4:	ldur	x8, [x24, #-16]
   41cf8:	mul	x9, x0, x23
   41cfc:	adds	x9, x9, x8
   41d00:	b.cc	41d1c <__gmpn_ni_invertappr@@Base+0x5b8>  // b.lo, b.ul, b.last
   41d04:	subs	x9, x9, x23
   41d08:	cset	w10, cs  // cs = hs, nlast
   41d0c:	csel	x11, x23, xzr, cs  // cs = hs, nlast
   41d10:	mvn	x10, x10
   41d14:	add	x0, x10, x0
   41d18:	sub	x9, x9, x11
   41d1c:	umulh	x10, x8, x0
   41d20:	adds	x9, x10, x9
   41d24:	b.cc	41d4c <__gmpn_ni_invertappr@@Base+0x5e8>  // b.lo, b.ul, b.last
   41d28:	cmp	x9, x23
   41d2c:	sub	x5, x0, #0x1
   41d30:	b.cc	41d50 <__gmpn_ni_invertappr@@Base+0x5ec>  // b.lo, b.ul, b.last
   41d34:	mul	x10, x0, x8
   41d38:	cmp	x9, x23
   41d3c:	sub	x11, x0, #0x2
   41d40:	ccmp	x10, x8, #0x2, ls  // ls = plast
   41d44:	csel	x5, x5, x11, cc  // cc = lo, ul, last
   41d48:	b	41d50 <__gmpn_ni_invertappr@@Base+0x5ec>
   41d4c:	mov	x5, x0
   41d50:	lsl	x2, x22, #1
   41d54:	mov	x0, x19
   41d58:	mov	x1, x21
   41d5c:	mov	x3, x20
   41d60:	mov	x4, x22
   41d64:	bl	c710 <__gmpn_sbpi1_divappr_q@plt>
   41d68:	mov	w0, #0x1                   	// #1
   41d6c:	ldr	x8, [x19]
   41d70:	sub	x9, x8, #0x1
   41d74:	str	x9, [x19], #8
   41d78:	cbz	x8, 41d6c <__gmpn_ni_invertappr@@Base+0x608>
   41d7c:	ldp	x20, x19, [sp, #48]
   41d80:	ldp	x22, x21, [sp, #32]
   41d84:	ldp	x24, x23, [sp, #16]
   41d88:	ldp	x29, x30, [sp], #64
   41d8c:	ret

0000000000041d90 <__gmpn_invertappr@@Base>:
   41d90:	cmp	x2, #0xa2
   41d94:	b.le	41d9c <__gmpn_invertappr@@Base+0xc>
   41d98:	b	d1a0 <__gmpn_ni_invertappr@plt>
   41d9c:	b	41c58 <__gmpn_ni_invertappr@@Base+0x4f4>

0000000000041da0 <__gmpn_invert@@Base>:
   41da0:	stp	x29, x30, [sp, #-64]!
   41da4:	stp	x20, x19, [sp, #48]
   41da8:	mov	x20, x1
   41dac:	cmp	x2, #0x1
   41db0:	mov	x19, x0
   41db4:	stp	x24, x23, [sp, #16]
   41db8:	stp	x22, x21, [sp, #32]
   41dbc:	mov	x29, sp
   41dc0:	b.ne	41dd4 <__gmpn_invert@@Base+0x34>  // b.any
   41dc4:	ldr	x0, [x20]
   41dc8:	bl	d410 <__gmpn_invert_limb@plt>
   41dcc:	str	x0, [x19]
   41dd0:	b	41dfc <__gmpn_invert@@Base+0x5c>
   41dd4:	mov	x21, x3
   41dd8:	mov	x22, x2
   41ddc:	cmp	x2, #0xa1
   41de0:	b.le	41e10 <__gmpn_invert@@Base+0x70>
   41de4:	mov	x0, x19
   41de8:	mov	x1, x20
   41dec:	mov	x2, x22
   41df0:	mov	x3, x21
   41df4:	bl	d1a0 <__gmpn_ni_invertappr@plt>
   41df8:	cbnz	x0, 41ef4 <__gmpn_invert@@Base+0x154>
   41dfc:	ldp	x20, x19, [sp, #48]
   41e00:	ldp	x22, x21, [sp, #32]
   41e04:	ldp	x24, x23, [sp, #16]
   41e08:	ldp	x29, x30, [sp], #64
   41e0c:	ret
   41e10:	lsl	x2, x22, #3
   41e14:	mov	w1, #0xff                  	// #255
   41e18:	mov	x0, x21
   41e1c:	bl	c610 <memset@plt>
   41e20:	add	x0, x21, x22, lsl #3
   41e24:	mov	x1, x20
   41e28:	mov	x2, x22
   41e2c:	bl	c2a0 <__gmpn_com@plt>
   41e30:	cmp	x22, #0x2
   41e34:	b.ne	41e60 <__gmpn_invert@@Base+0xc0>  // b.any
   41e38:	mov	x0, x19
   41e3c:	mov	x2, x21
   41e40:	mov	x4, x20
   41e44:	ldp	x20, x19, [sp, #48]
   41e48:	ldp	x22, x21, [sp, #32]
   41e4c:	ldp	x24, x23, [sp, #16]
   41e50:	mov	w3, #0x4                   	// #4
   41e54:	mov	x1, xzr
   41e58:	ldp	x29, x30, [sp], #64
   41e5c:	b	c210 <__gmpn_divrem_2@plt>
   41e60:	add	x24, x20, x22, lsl #3
   41e64:	ldur	x23, [x24, #-8]
   41e68:	mov	x0, x23
   41e6c:	bl	d410 <__gmpn_invert_limb@plt>
   41e70:	ldur	x8, [x24, #-16]
   41e74:	mul	x9, x0, x23
   41e78:	adds	x9, x9, x8
   41e7c:	b.cc	41e98 <__gmpn_invert@@Base+0xf8>  // b.lo, b.ul, b.last
   41e80:	subs	x9, x9, x23
   41e84:	cset	w10, cs  // cs = hs, nlast
   41e88:	csel	x11, x23, xzr, cs  // cs = hs, nlast
   41e8c:	mvn	x10, x10
   41e90:	add	x0, x10, x0
   41e94:	sub	x9, x9, x11
   41e98:	umulh	x10, x8, x0
   41e9c:	adds	x9, x10, x9
   41ea0:	b.cc	41ec8 <__gmpn_invert@@Base+0x128>  // b.lo, b.ul, b.last
   41ea4:	cmp	x9, x23
   41ea8:	sub	x5, x0, #0x1
   41eac:	b.cc	41ecc <__gmpn_invert@@Base+0x12c>  // b.lo, b.ul, b.last
   41eb0:	mul	x10, x0, x8
   41eb4:	cmp	x9, x23
   41eb8:	sub	x11, x0, #0x2
   41ebc:	ccmp	x10, x8, #0x2, ls  // ls = plast
   41ec0:	csel	x5, x5, x11, cc  // cc = lo, ul, last
   41ec4:	b	41ecc <__gmpn_invert@@Base+0x12c>
   41ec8:	mov	x5, x0
   41ecc:	lsl	x2, x22, #1
   41ed0:	mov	x0, x19
   41ed4:	mov	x1, x21
   41ed8:	mov	x3, x20
   41edc:	mov	x4, x22
   41ee0:	ldp	x20, x19, [sp, #48]
   41ee4:	ldp	x22, x21, [sp, #32]
   41ee8:	ldp	x24, x23, [sp, #16]
   41eec:	ldp	x29, x30, [sp], #64
   41ef0:	b	cf00 <__gmpn_sbpi1_div_q@plt>
   41ef4:	mov	x0, x21
   41ef8:	mov	x1, x19
   41efc:	mov	x2, x20
   41f00:	mov	x3, x22
   41f04:	bl	c9b0 <__gmpn_mul_n@plt>
   41f08:	mov	x0, x21
   41f0c:	mov	x1, x21
   41f10:	mov	x2, x20
   41f14:	mov	x3, x22
   41f18:	bl	ca90 <__gmpn_add_n@plt>
   41f1c:	cbz	x0, 41f64 <__gmpn_invert@@Base+0x1c4>
   41f20:	mov	x4, x0
   41f24:	add	x0, x21, x22, lsl #3
   41f28:	mov	x1, x0
   41f2c:	mov	x2, x20
   41f30:	mov	x3, x22
   41f34:	bl	ceb0 <__gmpn_add_nc@plt>
   41f38:	eor	x8, x0, #0x1
   41f3c:	ldr	x9, [x19]
   41f40:	adds	x8, x9, x8
   41f44:	str	x8, [x19]
   41f48:	b.cc	41dfc <__gmpn_invert@@Base+0x5c>  // b.lo, b.ul, b.last
   41f4c:	add	x8, x19, #0x8
   41f50:	ldr	x9, [x8]
   41f54:	adds	x9, x9, #0x1
   41f58:	str	x9, [x8], #8
   41f5c:	b.cs	41f50 <__gmpn_invert@@Base+0x1b0>  // b.hs, b.nlast
   41f60:	b	41dfc <__gmpn_invert@@Base+0x5c>
   41f64:	mov	w8, #0x1                   	// #1
   41f68:	b	41f3c <__gmpn_invert@@Base+0x19c>

0000000000041f6c <__gmpn_binvert_itch@@Base>:
   41f6c:	stp	x29, x30, [sp, #-32]!
   41f70:	str	x19, [sp, #16]
   41f74:	mov	x29, sp
   41f78:	mov	x19, x0
   41f7c:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   41f80:	add	x8, x19, #0x1
   41f84:	asr	x9, x0, #1
   41f88:	cmp	x9, x8, asr #1
   41f8c:	csel	x8, x0, x9, lt  // lt = tstop
   41f90:	cmp	x9, x19
   41f94:	ldr	x19, [sp, #16]
   41f98:	csel	x8, x8, xzr, lt  // lt = tstop
   41f9c:	add	x8, x8, x0, lsl #1
   41fa0:	add	x0, x8, #0x4
   41fa4:	ldp	x29, x30, [sp], #32
   41fa8:	ret

0000000000041fac <__gmpn_binvert@@Base>:
   41fac:	sub	sp, sp, #0x1b0
   41fb0:	stp	x28, x27, [sp, #352]
   41fb4:	stp	x22, x21, [sp, #400]
   41fb8:	stp	x20, x19, [sp, #416]
   41fbc:	mov	x19, x3
   41fc0:	mov	x20, x2
   41fc4:	mov	x21, x1
   41fc8:	cmp	x2, #0xc2
   41fcc:	mov	x22, x0
   41fd0:	add	x27, sp, #0x8
   41fd4:	stp	x29, x30, [sp, #336]
   41fd8:	stp	x26, x25, [sp, #368]
   41fdc:	stp	x24, x23, [sp, #384]
   41fe0:	add	x29, sp, #0x150
   41fe4:	b.lt	42078 <__gmpn_binvert@@Base+0xcc>  // b.tstop
   41fe8:	mov	x8, x20
   41fec:	add	x9, x8, #0x1
   41ff0:	asr	x23, x9, #1
   41ff4:	cmp	x8, #0x182
   41ff8:	str	x8, [x27], #8
   41ffc:	mov	x8, x23
   42000:	b.gt	41fec <__gmpn_binvert@@Base+0x40>
   42004:	cbz	x23, 42018 <__gmpn_binvert@@Base+0x6c>
   42008:	lsl	x2, x23, #3
   4200c:	mov	x0, x19
   42010:	mov	w1, wzr
   42014:	bl	c610 <memset@plt>
   42018:	mov	w8, #0x1                   	// #1
   4201c:	str	x8, [x19]
   42020:	ldr	x8, [x21]
   42024:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   42028:	ldr	x9, [x9, #3952]
   4202c:	orr	x11, xzr, #0xfffffffffffffffe
   42030:	ubfx	x10, x8, #1, #7
   42034:	cmp	x23, #0x5c
   42038:	ldrb	w9, [x9, x10]
   4203c:	mov	w10, #0x2                   	// #2
   42040:	mov	x0, x22
   42044:	mov	x1, x19
   42048:	msub	x12, x8, x9, x10
   4204c:	mul	x9, x12, x9
   42050:	msub	x10, x9, x8, x10
   42054:	mul	x9, x9, x10
   42058:	madd	x8, x9, x8, x11
   4205c:	mul	x5, x8, x9
   42060:	mov	x2, x23
   42064:	mov	x3, x21
   42068:	mov	x4, x23
   4206c:	b.le	42084 <__gmpn_binvert@@Base+0xd8>
   42070:	bl	ce30 <__gmpn_dcpi1_bdiv_q@plt>
   42074:	b	42088 <__gmpn_binvert@@Base+0xdc>
   42078:	mov	x23, x20
   4207c:	cbnz	x23, 42008 <__gmpn_binvert@@Base+0x5c>
   42080:	b	42018 <__gmpn_binvert@@Base+0x6c>
   42084:	bl	c530 <__gmpn_sbpi1_bdiv_q@plt>
   42088:	ldr	x10, [x22]
   4208c:	mov	x8, x22
   42090:	mov	x9, x23
   42094:	cbnz	x10, 420b4 <__gmpn_binvert@@Base+0x108>
   42098:	mov	x9, x23
   4209c:	mov	x8, x22
   420a0:	subs	x9, x9, #0x1
   420a4:	str	xzr, [x8]
   420a8:	b.eq	420d0 <__gmpn_binvert@@Base+0x124>  // b.none
   420ac:	ldr	x10, [x8, #8]!
   420b0:	cbz	x10, 420a0 <__gmpn_binvert@@Base+0xf4>
   420b4:	neg	x10, x10
   420b8:	subs	x2, x9, #0x1
   420bc:	str	x10, [x8]
   420c0:	b.eq	420d0 <__gmpn_binvert@@Base+0x124>  // b.none
   420c4:	add	x0, x8, #0x8
   420c8:	mov	x1, x0
   420cc:	bl	c2a0 <__gmpn_com@plt>
   420d0:	cmp	x23, x20
   420d4:	b.ge	42214 <__gmpn_binvert@@Base+0x268>  // b.tcont
   420d8:	add	x8, x19, #0x8
   420dc:	add	x28, x19, #0x10
   420e0:	str	x8, [sp]
   420e4:	ldr	x24, [x27, #-8]!
   420e8:	mov	x0, x24
   420ec:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   420f0:	mov	x25, x0
   420f4:	add	x26, x19, x0, lsl #3
   420f8:	mov	x0, x19
   420fc:	mov	x1, x25
   42100:	mov	x2, x21
   42104:	mov	x3, x24
   42108:	mov	x4, x22
   4210c:	mov	x5, x23
   42110:	mov	x6, x26
   42114:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   42118:	ldr	x9, [x19]
   4211c:	sub	x8, x24, x25
   42120:	add	x8, x8, x23
   42124:	sub	x10, x9, #0x1
   42128:	str	x10, [x26]
   4212c:	cbz	x9, 42164 <__gmpn_binvert@@Base+0x1b8>
   42130:	cbz	x25, 421b4 <__gmpn_binvert@@Base+0x208>
   42134:	cmp	x8, #0x2
   42138:	b.lt	421b4 <__gmpn_binvert@@Base+0x208>  // b.tstop
   4213c:	add	x8, x23, x24
   42140:	mvn	x9, x25
   42144:	add	x8, x9, x8
   42148:	ldr	x9, [sp]
   4214c:	ldr	x10, [x9]
   42150:	subs	x8, x8, #0x1
   42154:	str	x10, [x9, x25, lsl #3]
   42158:	add	x9, x9, #0x8
   4215c:	b.ne	4214c <__gmpn_binvert@@Base+0x1a0>  // b.any
   42160:	b	421b4 <__gmpn_binvert@@Base+0x208>
   42164:	mov	x11, x28
   42168:	mov	w9, #0x1                   	// #1
   4216c:	cmp	x9, x8
   42170:	b.ge	421b4 <__gmpn_binvert@@Base+0x208>  // b.tcont
   42174:	ldr	x12, [x19, x9, lsl #3]
   42178:	mov	x10, x11
   4217c:	sub	x11, x12, #0x1
   42180:	str	x11, [x26, x9, lsl #3]
   42184:	add	x9, x9, #0x1
   42188:	add	x11, x10, #0x8
   4218c:	cbz	x12, 4216c <__gmpn_binvert@@Base+0x1c0>
   42190:	cbz	x25, 421b4 <__gmpn_binvert@@Base+0x208>
   42194:	cmp	x9, x8
   42198:	b.ge	421b4 <__gmpn_binvert@@Base+0x208>  // b.tcont
   4219c:	ldr	x11, [x10]
   421a0:	sub	x8, x8, #0x1
   421a4:	cmp	x9, x8
   421a8:	str	x11, [x10, x25, lsl #3]
   421ac:	add	x10, x10, #0x8
   421b0:	b.ne	4219c <__gmpn_binvert@@Base+0x1f0>  // b.any
   421b4:	add	x25, x22, x23, lsl #3
   421b8:	add	x2, x19, x23, lsl #3
   421bc:	sub	x23, x24, x23
   421c0:	mov	x0, x25
   421c4:	mov	x1, x22
   421c8:	mov	x3, x23
   421cc:	bl	cee0 <__gmpn_mullo_n@plt>
   421d0:	ldr	x8, [x25]
   421d4:	cbnz	x8, 421ec <__gmpn_binvert@@Base+0x240>
   421d8:	subs	x23, x23, #0x1
   421dc:	str	xzr, [x25]
   421e0:	b.eq	42208 <__gmpn_binvert@@Base+0x25c>  // b.none
   421e4:	ldr	x8, [x25, #8]!
   421e8:	cbz	x8, 421d8 <__gmpn_binvert@@Base+0x22c>
   421ec:	neg	x8, x8
   421f0:	subs	x2, x23, #0x1
   421f4:	str	x8, [x25]
   421f8:	b.eq	42208 <__gmpn_binvert@@Base+0x25c>  // b.none
   421fc:	add	x0, x25, #0x8
   42200:	mov	x1, x0
   42204:	bl	c2a0 <__gmpn_com@plt>
   42208:	cmp	x24, x20
   4220c:	mov	x23, x24
   42210:	b.lt	420e4 <__gmpn_binvert@@Base+0x138>  // b.tstop
   42214:	ldp	x20, x19, [sp, #416]
   42218:	ldp	x22, x21, [sp, #400]
   4221c:	ldp	x24, x23, [sp, #384]
   42220:	ldp	x26, x25, [sp, #368]
   42224:	ldp	x28, x27, [sp, #352]
   42228:	ldp	x29, x30, [sp, #336]
   4222c:	add	sp, sp, #0x1b0
   42230:	ret

0000000000042234 <__gmpn_bc_mulmod_bnm1@@Base>:
   42234:	stp	x29, x30, [sp, #-48]!
   42238:	stp	x20, x19, [sp, #32]
   4223c:	mov	x19, x0
   42240:	mov	x0, x4
   42244:	str	x21, [sp, #16]
   42248:	mov	x29, sp
   4224c:	mov	x20, x4
   42250:	mov	x21, x3
   42254:	bl	c9b0 <__gmpn_mul_n@plt>
   42258:	add	x2, x20, x21, lsl #3
   4225c:	mov	x0, x19
   42260:	mov	x1, x20
   42264:	mov	x3, x21
   42268:	bl	ca90 <__gmpn_add_n@plt>
   4226c:	ldr	x8, [x19]
   42270:	adds	x8, x8, x0
   42274:	str	x8, [x19]
   42278:	b.cc	42290 <__gmpn_bc_mulmod_bnm1@@Base+0x5c>  // b.lo, b.ul, b.last
   4227c:	add	x8, x19, #0x8
   42280:	ldr	x9, [x8]
   42284:	adds	x9, x9, #0x1
   42288:	str	x9, [x8], #8
   4228c:	b.cs	42280 <__gmpn_bc_mulmod_bnm1@@Base+0x4c>  // b.hs, b.nlast
   42290:	ldp	x20, x19, [sp, #32]
   42294:	ldr	x21, [sp, #16]
   42298:	ldp	x29, x30, [sp], #48
   4229c:	ret

00000000000422a0 <__gmpn_mulmod_bnm1@@Base>:
   422a0:	sub	sp, sp, #0x70
   422a4:	stp	x28, x27, [sp, #32]
   422a8:	stp	x26, x25, [sp, #48]
   422ac:	stp	x22, x21, [sp, #80]
   422b0:	stp	x20, x19, [sp, #96]
   422b4:	mov	x20, x6
   422b8:	mov	x22, x5
   422bc:	mov	x25, x4
   422c0:	mov	x28, x3
   422c4:	mov	x27, x2
   422c8:	mov	x21, x1
   422cc:	cmp	x1, #0xa
   422d0:	mov	x19, x0
   422d4:	stp	x29, x30, [sp, #16]
   422d8:	stp	x24, x23, [sp, #64]
   422dc:	add	x29, sp, #0x10
   422e0:	b.lt	42348 <__gmpn_mulmod_bnm1@@Base+0xa8>  // b.tstop
   422e4:	tbnz	w21, #0, 42348 <__gmpn_mulmod_bnm1@@Base+0xa8>
   422e8:	lsr	x24, x21, #1
   422ec:	cmp	x24, x28
   422f0:	str	x28, [sp, #8]
   422f4:	b.ge	427bc <__gmpn_mulmod_bnm1@@Base+0x51c>  // b.tcont
   422f8:	subs	x28, x28, x24
   422fc:	add	x2, x27, x24, lsl #3
   42300:	str	x2, [sp]
   42304:	b.eq	42384 <__gmpn_mulmod_bnm1@@Base+0xe4>  // b.none
   42308:	mov	x0, x20
   4230c:	mov	x1, x27
   42310:	mov	x3, x28
   42314:	bl	ca90 <__gmpn_add_n@plt>
   42318:	mov	x9, x28
   4231c:	cbz	x0, 42388 <__gmpn_mulmod_bnm1@@Base+0xe8>
   42320:	mov	x8, x28
   42324:	cmp	x8, x24
   42328:	b.ge	423b8 <__gmpn_mulmod_bnm1@@Base+0x118>  // b.tcont
   4232c:	ldr	x9, [x27, x8, lsl #3]
   42330:	adds	x10, x9, #0x1
   42334:	add	x9, x8, #0x1
   42338:	str	x10, [x20, x8, lsl #3]
   4233c:	mov	x8, x9
   42340:	b.cs	42324 <__gmpn_mulmod_bnm1@@Base+0x84>  // b.hs, b.nlast
   42344:	b	42388 <__gmpn_mulmod_bnm1@@Base+0xe8>
   42348:	cmp	x22, x21
   4234c:	b.lt	427ec <__gmpn_mulmod_bnm1@@Base+0x54c>  // b.tstop
   42350:	mov	x0, x19
   42354:	mov	x1, x27
   42358:	mov	x2, x25
   4235c:	mov	x3, x21
   42360:	mov	x4, x20
   42364:	ldp	x20, x19, [sp, #96]
   42368:	ldp	x22, x21, [sp, #80]
   4236c:	ldp	x24, x23, [sp, #64]
   42370:	ldp	x26, x25, [sp, #48]
   42374:	ldp	x28, x27, [sp, #32]
   42378:	ldp	x29, x30, [sp, #16]
   4237c:	add	sp, sp, #0x70
   42380:	b	c310 <__gmpn_bc_mulmod_bnm1@plt>
   42384:	mov	x9, xzr
   42388:	cmp	x20, x27
   4238c:	b.eq	423cc <__gmpn_mulmod_bnm1@@Base+0x12c>  // b.none
   42390:	cmp	x9, x24
   42394:	b.ge	423cc <__gmpn_mulmod_bnm1@@Base+0x12c>  // b.tcont
   42398:	sub	x8, x24, x9
   4239c:	add	x10, x20, x9, lsl #3
   423a0:	add	x9, x27, x9, lsl #3
   423a4:	ldr	x11, [x9], #8
   423a8:	subs	x8, x8, #0x1
   423ac:	str	x11, [x10], #8
   423b0:	b.ne	423a4 <__gmpn_mulmod_bnm1@@Base+0x104>  // b.any
   423b4:	b	423cc <__gmpn_mulmod_bnm1@@Base+0x12c>
   423b8:	mov	x8, x20
   423bc:	ldr	x9, [x8]
   423c0:	adds	x9, x9, #0x1
   423c4:	str	x9, [x8], #8
   423c8:	b.cs	423bc <__gmpn_mulmod_bnm1@@Base+0x11c>  // b.hs, b.nlast
   423cc:	cmp	x24, x22
   423d0:	add	x26, x20, x24, lsl #3
   423d4:	b.ge	428e4 <__gmpn_mulmod_bnm1@@Base+0x644>  // b.tcont
   423d8:	subs	x23, x22, x24
   423dc:	b.eq	42418 <__gmpn_mulmod_bnm1@@Base+0x178>  // b.none
   423e0:	add	x2, x25, x24, lsl #3
   423e4:	mov	x0, x26
   423e8:	mov	x1, x25
   423ec:	mov	x3, x23
   423f0:	bl	ca90 <__gmpn_add_n@plt>
   423f4:	cbz	x0, 42418 <__gmpn_mulmod_bnm1@@Base+0x178>
   423f8:	add	x8, x20, x22, lsl #3
   423fc:	cmp	x23, x24
   42400:	b.ge	4244c <__gmpn_mulmod_bnm1@@Base+0x1ac>  // b.tcont
   42404:	ldr	x9, [x25, x23, lsl #3]
   42408:	add	x23, x23, #0x1
   4240c:	adds	x9, x9, #0x1
   42410:	str	x9, [x8], #8
   42414:	b.cs	423fc <__gmpn_mulmod_bnm1@@Base+0x15c>  // b.hs, b.nlast
   42418:	cmp	x26, x25
   4241c:	b.eq	42460 <__gmpn_mulmod_bnm1@@Base+0x1c0>  // b.none
   42420:	cmp	x23, x24
   42424:	b.ge	42460 <__gmpn_mulmod_bnm1@@Base+0x1c0>  // b.tcont
   42428:	add	x9, x23, x24
   4242c:	sub	x8, x24, x23
   42430:	add	x9, x20, x9, lsl #3
   42434:	add	x10, x25, x23, lsl #3
   42438:	ldr	x11, [x10], #8
   4243c:	subs	x8, x8, #0x1
   42440:	str	x11, [x9], #8
   42444:	b.ne	42438 <__gmpn_mulmod_bnm1@@Base+0x198>  // b.any
   42448:	b	42460 <__gmpn_mulmod_bnm1@@Base+0x1c0>
   4244c:	mov	x8, x26
   42450:	ldr	x9, [x8]
   42454:	adds	x9, x9, #0x1
   42458:	str	x9, [x8], #8
   4245c:	b.cs	42450 <__gmpn_mulmod_bnm1@@Base+0x1b0>  // b.hs, b.nlast
   42460:	add	x6, x26, x24, lsl #3
   42464:	mov	x5, x24
   42468:	mov	x0, x19
   4246c:	mov	x1, x24
   42470:	mov	x2, x20
   42474:	mov	x3, x24
   42478:	mov	x4, x26
   4247c:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   42480:	and	x23, x21, #0xfffffffffffffffe
   42484:	add	x8, x20, x23, lsl #3
   42488:	add	x26, x8, #0x10
   4248c:	cbz	x28, 424d4 <__gmpn_mulmod_bnm1@@Base+0x234>
   42490:	ldr	x2, [sp]
   42494:	mov	x0, x26
   42498:	mov	x1, x27
   4249c:	mov	x3, x28
   424a0:	bl	c2e0 <__gmpn_sub_n@plt>
   424a4:	cbz	x0, 424d4 <__gmpn_mulmod_bnm1@@Base+0x234>
   424a8:	ldr	x8, [sp, #8]
   424ac:	add	x8, x8, x24
   424b0:	add	x8, x20, x8, lsl #3
   424b4:	add	x8, x8, #0x10
   424b8:	cmp	x28, x24
   424bc:	b.ge	4279c <__gmpn_mulmod_bnm1@@Base+0x4fc>  // b.tcont
   424c0:	ldr	x9, [x27, x28, lsl #3]
   424c4:	add	x28, x28, #0x1
   424c8:	sub	x10, x9, #0x1
   424cc:	str	x10, [x8], #8
   424d0:	cbz	x9, 424b8 <__gmpn_mulmod_bnm1@@Base+0x218>
   424d4:	cmp	x26, x27
   424d8:	b.eq	42508 <__gmpn_mulmod_bnm1@@Base+0x268>  // b.none
   424dc:	cmp	x28, x24
   424e0:	b.ge	42508 <__gmpn_mulmod_bnm1@@Base+0x268>  // b.tcont
   424e4:	add	x9, x28, x23
   424e8:	add	x9, x20, x9, lsl #3
   424ec:	sub	x8, x24, x28
   424f0:	add	x9, x9, #0x10
   424f4:	add	x10, x27, x28, lsl #3
   424f8:	ldr	x11, [x10], #8
   424fc:	subs	x8, x8, #0x1
   42500:	str	x11, [x9], #8
   42504:	b.ne	424f8 <__gmpn_mulmod_bnm1@@Base+0x258>  // b.any
   42508:	mov	x8, xzr
   4250c:	str	xzr, [x26, x24, lsl #3]
   42510:	cmp	x24, x22
   42514:	add	x8, x8, x24
   42518:	str	x8, [sp]
   4251c:	b.ge	428f4 <__gmpn_mulmod_bnm1@@Base+0x654>  // b.tcont
   42520:	add	x8, x26, x24, lsl #3
   42524:	subs	x28, x22, x24
   42528:	add	x27, x8, #0x8
   4252c:	b.eq	42574 <__gmpn_mulmod_bnm1@@Base+0x2d4>  // b.none
   42530:	add	x2, x25, x24, lsl #3
   42534:	mov	x0, x27
   42538:	mov	x1, x25
   4253c:	mov	x3, x28
   42540:	bl	c2e0 <__gmpn_sub_n@plt>
   42544:	cbz	x0, 42574 <__gmpn_mulmod_bnm1@@Base+0x2d4>
   42548:	add	x8, x22, x23
   4254c:	add	x8, x20, x8, lsl #3
   42550:	add	x9, x8, #0x18
   42554:	mov	w8, #0x1                   	// #1
   42558:	cmp	x28, x24
   4255c:	b.ge	425b0 <__gmpn_mulmod_bnm1@@Base+0x310>  // b.tcont
   42560:	ldr	x10, [x25, x28, lsl #3]
   42564:	add	x28, x28, #0x1
   42568:	sub	x11, x10, #0x1
   4256c:	str	x11, [x9], #8
   42570:	cbz	x10, 42558 <__gmpn_mulmod_bnm1@@Base+0x2b8>
   42574:	cmp	x27, x25
   42578:	mov	x8, xzr
   4257c:	b.eq	425b0 <__gmpn_mulmod_bnm1@@Base+0x310>  // b.none
   42580:	cmp	x28, x24
   42584:	b.ge	425b0 <__gmpn_mulmod_bnm1@@Base+0x310>  // b.tcont
   42588:	add	x9, x24, x24, lsl #1
   4258c:	add	x9, x28, x9
   42590:	add	x9, x20, x9, lsl #3
   42594:	sub	x8, x24, x28
   42598:	add	x9, x9, #0x18
   4259c:	add	x10, x25, x28, lsl #3
   425a0:	ldr	x11, [x10], #8
   425a4:	subs	x8, x8, #0x1
   425a8:	str	x11, [x9], #8
   425ac:	b.ne	425a0 <__gmpn_mulmod_bnm1@@Base+0x300>  // b.any
   425b0:	lsl	x9, x21, #3
   425b4:	orr	x9, x9, #0x8
   425b8:	str	xzr, [x26, x9]
   425bc:	ldr	x9, [x27]
   425c0:	adds	x8, x9, x8
   425c4:	str	x8, [x27]
   425c8:	b.cc	425e8 <__gmpn_mulmod_bnm1@@Base+0x348>  // b.lo, b.ul, b.last
   425cc:	mov	w8, #0x18                  	// #24
   425d0:	madd	x8, x24, x8, x20
   425d4:	add	x8, x8, #0x20
   425d8:	ldr	x9, [x8]
   425dc:	adds	x9, x9, #0x1
   425e0:	str	x9, [x8], #8
   425e4:	b.cs	425d8 <__gmpn_mulmod_bnm1@@Base+0x338>  // b.hs, b.nlast
   425e8:	ldr	x8, [x27, x24, lsl #3]
   425ec:	add	x28, x8, x24
   425f0:	cmp	x21, #0x278
   425f4:	b.lt	42664 <__gmpn_mulmod_bnm1@@Base+0x3c4>  // b.tstop
   425f8:	mov	x0, x24
   425fc:	mov	w1, wzr
   42600:	bl	caf0 <__gmpn_fft_best_k@plt>
   42604:	mov	w8, #0xffffffff            	// #-1
   42608:	lsl	w8, w8, w0
   4260c:	mvn	w8, w8
   42610:	sxtw	x9, w8
   42614:	mov	w6, w0
   42618:	tst	x24, x9
   4261c:	b.eq	42634 <__gmpn_mulmod_bnm1@@Base+0x394>  // b.none
   42620:	sbfx	x9, x8, #1, #31
   42624:	asr	w8, w8, #1
   42628:	tst	x24, x9
   4262c:	sub	w6, w6, #0x1
   42630:	b.ne	42620 <__gmpn_mulmod_bnm1@@Base+0x380>  // b.any
   42634:	cmp	w6, #0x4
   42638:	b.lt	42664 <__gmpn_mulmod_bnm1@@Base+0x3c4>  // b.tstop
   4263c:	ldr	x3, [sp]
   42640:	mov	x0, x20
   42644:	mov	x1, x24
   42648:	mov	x2, x26
   4264c:	mov	x4, x27
   42650:	mov	x5, x28
   42654:	bl	c320 <__gmpn_mul_fft@plt>
   42658:	ldr	x26, [sp, #8]
   4265c:	str	x0, [x20, x24, lsl #3]
   42660:	b	426d0 <__gmpn_mulmod_bnm1@@Base+0x430>
   42664:	cmp	x27, x25
   42668:	b.eq	42900 <__gmpn_mulmod_bnm1@@Base+0x660>  // b.none
   4266c:	add	x3, x24, #0x1
   42670:	mov	x0, x20
   42674:	mov	x1, x26
   42678:	mov	x2, x27
   4267c:	bl	c9b0 <__gmpn_mul_n@plt>
   42680:	and	x8, x21, #0x1ffffffffffffffe
   42684:	ldr	x25, [x20, x8, lsl #3]
   42688:	add	x23, x20, x24, lsl #3
   4268c:	mov	x0, x20
   42690:	mov	x1, x20
   42694:	mov	x2, x23
   42698:	mov	x3, x24
   4269c:	bl	c2e0 <__gmpn_sub_n@plt>
   426a0:	str	xzr, [x23]
   426a4:	ldr	x8, [x20]
   426a8:	ldr	x26, [sp, #8]
   426ac:	add	x9, x0, x25
   426b0:	adds	x8, x8, x9
   426b4:	str	x8, [x20]
   426b8:	b.cc	426d0 <__gmpn_mulmod_bnm1@@Base+0x430>  // b.lo, b.ul, b.last
   426bc:	add	x8, x20, #0x8
   426c0:	ldr	x9, [x8]
   426c4:	adds	x9, x9, #0x1
   426c8:	str	x9, [x8], #8
   426cc:	b.cs	426c0 <__gmpn_mulmod_bnm1@@Base+0x420>  // b.hs, b.nlast
   426d0:	ldr	x23, [x20, x24, lsl #3]
   426d4:	mov	x0, x19
   426d8:	mov	x1, x19
   426dc:	mov	x2, x20
   426e0:	mov	x3, x24
   426e4:	bl	c970 <__gmpn_rsh1add_n@plt>
   426e8:	mov	x8, xzr
   426ec:	add	x9, x19, x24, lsl #3
   426f0:	add	x11, x0, x23
   426f4:	ldur	x10, [x9, #-8]
   426f8:	lsr	x12, x11, #1
   426fc:	lsl	x11, x11, #63
   42700:	adds	x13, x10, x11
   42704:	adc	x8, x12, x8
   42708:	stur	x13, [x9, #-8]
   4270c:	ldr	x9, [x19]
   42710:	adds	x8, x9, x8
   42714:	str	x8, [x19]
   42718:	b.cc	42730 <__gmpn_mulmod_bnm1@@Base+0x490>  // b.lo, b.ul, b.last
   4271c:	add	x8, x19, #0x8
   42720:	ldr	x9, [x8]
   42724:	adds	x9, x9, #0x1
   42728:	str	x9, [x8], #8
   4272c:	b.cs	42720 <__gmpn_mulmod_bnm1@@Base+0x480>  // b.hs, b.nlast
   42730:	add	x23, x22, x26
   42734:	cmp	x23, x21
   42738:	b.lt	42868 <__gmpn_mulmod_bnm1@@Base+0x5c8>  // b.tstop
   4273c:	ldr	x21, [x20, x24, lsl #3]
   42740:	add	x0, x19, x24, lsl #3
   42744:	mov	x1, x19
   42748:	mov	x2, x20
   4274c:	mov	x3, x24
   42750:	bl	c2e0 <__gmpn_sub_n@plt>
   42754:	ldr	x8, [x19]
   42758:	add	x9, x0, x21
   4275c:	subs	x8, x8, x9
   42760:	str	x8, [x19]
   42764:	b.cs	4277c <__gmpn_mulmod_bnm1@@Base+0x4dc>  // b.hs, b.nlast
   42768:	add	x8, x19, #0x8
   4276c:	ldr	x9, [x8]
   42770:	sub	x10, x9, #0x1
   42774:	str	x10, [x8], #8
   42778:	cbz	x9, 4276c <__gmpn_mulmod_bnm1@@Base+0x4cc>
   4277c:	ldp	x20, x19, [sp, #96]
   42780:	ldp	x22, x21, [sp, #80]
   42784:	ldp	x24, x23, [sp, #64]
   42788:	ldp	x26, x25, [sp, #48]
   4278c:	ldp	x28, x27, [sp, #32]
   42790:	ldp	x29, x30, [sp, #16]
   42794:	add	sp, sp, #0x70
   42798:	ret
   4279c:	mov	x8, x26
   427a0:	str	xzr, [x26, x24, lsl #3]
   427a4:	ldr	x9, [x8]
   427a8:	adds	x9, x9, #0x1
   427ac:	str	x9, [x8], #8
   427b0:	b.cs	427a4 <__gmpn_mulmod_bnm1@@Base+0x504>  // b.hs, b.nlast
   427b4:	ldr	x8, [x26, x24, lsl #3]
   427b8:	b	42510 <__gmpn_mulmod_bnm1@@Base+0x270>
   427bc:	mov	x0, x19
   427c0:	mov	x1, x24
   427c4:	mov	x2, x27
   427c8:	mov	x3, x28
   427cc:	mov	x4, x25
   427d0:	mov	x5, x22
   427d4:	mov	x6, x20
   427d8:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   427dc:	mov	x26, x27
   427e0:	mov	x27, x25
   427e4:	str	x28, [sp]
   427e8:	b	428f8 <__gmpn_mulmod_bnm1@@Base+0x658>
   427ec:	add	x23, x22, x28
   427f0:	cmp	x23, x21
   427f4:	b.le	429d4 <__gmpn_mulmod_bnm1@@Base+0x734>
   427f8:	mov	x0, x20
   427fc:	mov	x1, x27
   42800:	mov	x2, x28
   42804:	mov	x3, x25
   42808:	mov	x4, x22
   4280c:	bl	ccf0 <__gmpn_mul@plt>
   42810:	subs	x22, x23, x21
   42814:	b.eq	4297c <__gmpn_mulmod_bnm1@@Base+0x6dc>  // b.none
   42818:	add	x2, x20, x21, lsl #3
   4281c:	mov	x0, x19
   42820:	mov	x1, x20
   42824:	mov	x3, x22
   42828:	bl	ca90 <__gmpn_add_n@plt>
   4282c:	cbz	x0, 42984 <__gmpn_mulmod_bnm1@@Base+0x6e4>
   42830:	cmp	x22, x21
   42834:	b.ge	42854 <__gmpn_mulmod_bnm1@@Base+0x5b4>  // b.tcont
   42838:	ldr	x8, [x20, x22, lsl #3]
   4283c:	add	x9, x22, #0x1
   42840:	adds	x8, x8, #0x1
   42844:	str	x8, [x19, x22, lsl #3]
   42848:	mov	x22, x9
   4284c:	b.cs	42830 <__gmpn_mulmod_bnm1@@Base+0x590>  // b.hs, b.nlast
   42850:	b	42988 <__gmpn_mulmod_bnm1@@Base+0x6e8>
   42854:	ldr	x8, [x19]
   42858:	adds	x8, x8, #0x1
   4285c:	str	x8, [x19], #8
   42860:	b.cs	42854 <__gmpn_mulmod_bnm1@@Base+0x5b4>  // b.hs, b.nlast
   42864:	b	4277c <__gmpn_mulmod_bnm1@@Base+0x4dc>
   42868:	add	x0, x19, x24, lsl #3
   4286c:	sub	x3, x23, x24
   42870:	mov	x1, x19
   42874:	mov	x2, x20
   42878:	neg	x25, x21, lsr #1
   4287c:	bl	c2e0 <__gmpn_sub_n@plt>
   42880:	add	x8, x20, x26, lsl #3
   42884:	ldr	x24, [x20, x24, lsl #3]
   42888:	add	x9, x19, x26, lsl #3
   4288c:	add	x8, x8, x22, lsl #3
   42890:	mov	x4, x0
   42894:	add	x9, x9, x22, lsl #3
   42898:	add	x0, x8, x25, lsl #3
   4289c:	add	x1, x9, x25, lsl #3
   428a0:	sub	x3, x21, x23
   428a4:	mov	x2, x0
   428a8:	bl	c780 <__gmpn_sub_nc@plt>
   428ac:	ldr	x8, [x19]
   428b0:	add	x9, x0, x24
   428b4:	subs	x8, x8, x9
   428b8:	str	x8, [x19]
   428bc:	b.cs	4277c <__gmpn_mulmod_bnm1@@Base+0x4dc>  // b.hs, b.nlast
   428c0:	mov	w8, #0x1                   	// #1
   428c4:	cmp	x8, x23
   428c8:	b.ge	4277c <__gmpn_mulmod_bnm1@@Base+0x4dc>  // b.tcont
   428cc:	ldr	x9, [x19, x8, lsl #3]
   428d0:	sub	x10, x9, #0x1
   428d4:	str	x10, [x19, x8, lsl #3]
   428d8:	add	x8, x8, #0x1
   428dc:	cbz	x9, 428c4 <__gmpn_mulmod_bnm1@@Base+0x624>
   428e0:	b	4277c <__gmpn_mulmod_bnm1@@Base+0x4dc>
   428e4:	mov	x6, x26
   428e8:	mov	x5, x22
   428ec:	mov	x26, x25
   428f0:	b	42468 <__gmpn_mulmod_bnm1@@Base+0x1c8>
   428f4:	mov	x27, x25
   428f8:	mov	x28, x22
   428fc:	b	425f0 <__gmpn_mulmod_bnm1@@Base+0x350>
   42900:	ldr	x23, [sp]
   42904:	mov	x0, x20
   42908:	mov	x1, x26
   4290c:	mov	x3, x25
   42910:	mov	x2, x23
   42914:	mov	x4, x28
   42918:	bl	ccf0 <__gmpn_mul@plt>
   4291c:	sub	x8, x23, x24
   42920:	add	x8, x8, x28
   42924:	ldr	x26, [sp, #8]
   42928:	cmp	x8, x24
   4292c:	cset	w9, gt
   42930:	subs	x25, x8, x9
   42934:	add	x23, x20, x24, lsl #3
   42938:	b.eq	42974 <__gmpn_mulmod_bnm1@@Base+0x6d4>  // b.none
   4293c:	mov	x0, x20
   42940:	mov	x1, x20
   42944:	mov	x2, x23
   42948:	mov	x3, x25
   4294c:	bl	c2e0 <__gmpn_sub_n@plt>
   42950:	cbz	x0, 42974 <__gmpn_mulmod_bnm1@@Base+0x6d4>
   42954:	cmp	x25, x24
   42958:	b.ge	429b8 <__gmpn_mulmod_bnm1@@Base+0x718>  // b.tcont
   4295c:	ldr	x8, [x20, x25, lsl #3]
   42960:	add	x10, x25, #0x1
   42964:	sub	x9, x8, #0x1
   42968:	str	x9, [x20, x25, lsl #3]
   4296c:	mov	x25, x10
   42970:	cbz	x8, 42954 <__gmpn_mulmod_bnm1@@Base+0x6b4>
   42974:	str	xzr, [x23]
   42978:	b	426d0 <__gmpn_mulmod_bnm1@@Base+0x430>
   4297c:	mov	x9, xzr
   42980:	b	42988 <__gmpn_mulmod_bnm1@@Base+0x6e8>
   42984:	mov	x9, x22
   42988:	cmp	x19, x20
   4298c:	b.eq	4277c <__gmpn_mulmod_bnm1@@Base+0x4dc>  // b.none
   42990:	cmp	x9, x21
   42994:	b.ge	4277c <__gmpn_mulmod_bnm1@@Base+0x4dc>  // b.tcont
   42998:	sub	x8, x21, x9
   4299c:	add	x10, x19, x9, lsl #3
   429a0:	add	x9, x20, x9, lsl #3
   429a4:	ldr	x11, [x9], #8
   429a8:	subs	x8, x8, #0x1
   429ac:	str	x11, [x10], #8
   429b0:	b.ne	429a4 <__gmpn_mulmod_bnm1@@Base+0x704>  // b.any
   429b4:	b	4277c <__gmpn_mulmod_bnm1@@Base+0x4dc>
   429b8:	mov	x8, x20
   429bc:	str	xzr, [x23]
   429c0:	ldr	x9, [x8]
   429c4:	adds	x9, x9, #0x1
   429c8:	str	x9, [x8], #8
   429cc:	b.cs	429c0 <__gmpn_mulmod_bnm1@@Base+0x720>  // b.hs, b.nlast
   429d0:	b	426d0 <__gmpn_mulmod_bnm1@@Base+0x430>
   429d4:	mov	x0, x19
   429d8:	mov	x1, x27
   429dc:	mov	x2, x28
   429e0:	mov	x3, x25
   429e4:	mov	x4, x22
   429e8:	ldp	x20, x19, [sp, #96]
   429ec:	ldp	x22, x21, [sp, #80]
   429f0:	ldp	x24, x23, [sp, #64]
   429f4:	ldp	x26, x25, [sp, #48]
   429f8:	ldp	x28, x27, [sp, #32]
   429fc:	ldp	x29, x30, [sp, #16]
   42a00:	add	sp, sp, #0x70
   42a04:	b	ccf0 <__gmpn_mul@plt>

0000000000042a08 <__gmpn_mulmod_bnm1_next_size@@Base>:
   42a08:	cmp	x0, #0xa
   42a0c:	b.lt	42a60 <__gmpn_mulmod_bnm1_next_size@@Base+0x58>  // b.tstop
   42a10:	cmp	x0, #0x24
   42a14:	b.le	42a64 <__gmpn_mulmod_bnm1_next_size@@Base+0x5c>
   42a18:	cmp	x0, #0x48
   42a1c:	b.le	42a70 <__gmpn_mulmod_bnm1_next_size@@Base+0x68>
   42a20:	cmp	x0, #0x276
   42a24:	b.le	42a7c <__gmpn_mulmod_bnm1_next_size@@Base+0x74>
   42a28:	stp	x29, x30, [sp, #-32]!
   42a2c:	add	x8, x0, #0x1
   42a30:	str	x19, [sp, #16]
   42a34:	asr	x19, x8, #1
   42a38:	mov	x0, x19
   42a3c:	mov	w1, wzr
   42a40:	mov	x29, sp
   42a44:	bl	caf0 <__gmpn_fft_best_k@plt>
   42a48:	mov	w1, w0
   42a4c:	mov	x0, x19
   42a50:	bl	d1f0 <__gmpn_fft_next_size@plt>
   42a54:	ldr	x19, [sp, #16]
   42a58:	lsl	x0, x0, #1
   42a5c:	ldp	x29, x30, [sp], #32
   42a60:	ret
   42a64:	add	x8, x0, #0x1
   42a68:	and	x0, x8, #0xfffffffffffffffe
   42a6c:	ret
   42a70:	add	x8, x0, #0x3
   42a74:	and	x0, x8, #0xfffffffffffffffc
   42a78:	ret
   42a7c:	add	x8, x0, #0x7
   42a80:	and	x0, x8, #0xfffffffffffffff8
   42a84:	ret

0000000000042a88 <__gmpn_sqrmod_bnm1@@Base>:
   42a88:	stp	x29, x30, [sp, #-96]!
   42a8c:	stp	x24, x23, [sp, #48]
   42a90:	stp	x22, x21, [sp, #64]
   42a94:	stp	x20, x19, [sp, #80]
   42a98:	mov	x20, x4
   42a9c:	mov	x22, x3
   42aa0:	mov	x24, x2
   42aa4:	mov	x21, x1
   42aa8:	cmp	x1, #0xb
   42aac:	mov	x19, x0
   42ab0:	stp	x28, x27, [sp, #16]
   42ab4:	stp	x26, x25, [sp, #32]
   42ab8:	mov	x29, sp
   42abc:	b.lt	42b24 <__gmpn_sqrmod_bnm1@@Base+0x9c>  // b.tstop
   42ac0:	tbnz	w21, #0, 42b24 <__gmpn_sqrmod_bnm1@@Base+0x9c>
   42ac4:	lsr	x23, x21, #1
   42ac8:	cmp	x23, x22
   42acc:	b.ge	42e24 <__gmpn_sqrmod_bnm1@@Base+0x39c>  // b.tcont
   42ad0:	add	x25, x20, x23, lsl #3
   42ad4:	subs	x26, x22, x23
   42ad8:	add	x27, x24, x23, lsl #3
   42adc:	b.eq	42b78 <__gmpn_sqrmod_bnm1@@Base+0xf0>  // b.none
   42ae0:	mov	x0, x20
   42ae4:	mov	x1, x24
   42ae8:	mov	x2, x27
   42aec:	mov	x3, x26
   42af0:	bl	ca90 <__gmpn_add_n@plt>
   42af4:	mov	x9, x26
   42af8:	cbz	x0, 42b7c <__gmpn_sqrmod_bnm1@@Base+0xf4>
   42afc:	mov	x8, x26
   42b00:	cmp	x8, x23
   42b04:	b.ge	42bac <__gmpn_sqrmod_bnm1@@Base+0x124>  // b.tcont
   42b08:	ldr	x9, [x24, x8, lsl #3]
   42b0c:	adds	x10, x9, #0x1
   42b10:	add	x9, x8, #0x1
   42b14:	str	x10, [x20, x8, lsl #3]
   42b18:	mov	x8, x9
   42b1c:	b.cs	42b00 <__gmpn_sqrmod_bnm1@@Base+0x78>  // b.hs, b.nlast
   42b20:	b	42b7c <__gmpn_sqrmod_bnm1@@Base+0xf4>
   42b24:	cmp	x22, x21
   42b28:	b.lt	42e48 <__gmpn_sqrmod_bnm1@@Base+0x3c0>  // b.tstop
   42b2c:	mov	x0, x20
   42b30:	mov	x1, x24
   42b34:	mov	x2, x21
   42b38:	bl	c900 <__gmpn_sqr@plt>
   42b3c:	add	x2, x20, x21, lsl #3
   42b40:	mov	x0, x19
   42b44:	mov	x1, x20
   42b48:	mov	x3, x21
   42b4c:	bl	ca90 <__gmpn_add_n@plt>
   42b50:	ldr	x8, [x19]
   42b54:	adds	x8, x8, x0
   42b58:	str	x8, [x19]
   42b5c:	b.cc	42de8 <__gmpn_sqrmod_bnm1@@Base+0x360>  // b.lo, b.ul, b.last
   42b60:	add	x8, x19, #0x8
   42b64:	ldr	x9, [x8]
   42b68:	adds	x9, x9, #0x1
   42b6c:	str	x9, [x8], #8
   42b70:	b.cs	42b64 <__gmpn_sqrmod_bnm1@@Base+0xdc>  // b.hs, b.nlast
   42b74:	b	42de8 <__gmpn_sqrmod_bnm1@@Base+0x360>
   42b78:	mov	x9, xzr
   42b7c:	cmp	x20, x24
   42b80:	b.eq	42bc0 <__gmpn_sqrmod_bnm1@@Base+0x138>  // b.none
   42b84:	cmp	x9, x23
   42b88:	b.ge	42bc0 <__gmpn_sqrmod_bnm1@@Base+0x138>  // b.tcont
   42b8c:	sub	x8, x23, x9
   42b90:	add	x10, x20, x9, lsl #3
   42b94:	add	x9, x24, x9, lsl #3
   42b98:	ldr	x11, [x9], #8
   42b9c:	subs	x8, x8, #0x1
   42ba0:	str	x11, [x10], #8
   42ba4:	b.ne	42b98 <__gmpn_sqrmod_bnm1@@Base+0x110>  // b.any
   42ba8:	b	42bc0 <__gmpn_sqrmod_bnm1@@Base+0x138>
   42bac:	mov	x8, x20
   42bb0:	ldr	x9, [x8]
   42bb4:	adds	x9, x9, #0x1
   42bb8:	str	x9, [x8], #8
   42bbc:	b.cs	42bb0 <__gmpn_sqrmod_bnm1@@Base+0x128>  // b.hs, b.nlast
   42bc0:	mov	x0, x19
   42bc4:	mov	x1, x23
   42bc8:	mov	x2, x20
   42bcc:	mov	x3, x23
   42bd0:	mov	x4, x25
   42bd4:	bl	bf60 <__gmpn_sqrmod_bnm1@plt>
   42bd8:	and	x28, x21, #0xfffffffffffffffe
   42bdc:	add	x8, x20, x28, lsl #3
   42be0:	add	x25, x8, #0x10
   42be4:	cbz	x26, 42c28 <__gmpn_sqrmod_bnm1@@Base+0x1a0>
   42be8:	mov	x0, x25
   42bec:	mov	x1, x24
   42bf0:	mov	x2, x27
   42bf4:	mov	x3, x26
   42bf8:	bl	c2e0 <__gmpn_sub_n@plt>
   42bfc:	cbz	x0, 42c28 <__gmpn_sqrmod_bnm1@@Base+0x1a0>
   42c00:	add	x8, x22, x23
   42c04:	add	x8, x20, x8, lsl #3
   42c08:	add	x8, x8, #0x10
   42c0c:	cmp	x26, x23
   42c10:	b.ge	42e04 <__gmpn_sqrmod_bnm1@@Base+0x37c>  // b.tcont
   42c14:	ldr	x9, [x24, x26, lsl #3]
   42c18:	add	x26, x26, #0x1
   42c1c:	sub	x10, x9, #0x1
   42c20:	str	x10, [x8], #8
   42c24:	cbz	x9, 42c0c <__gmpn_sqrmod_bnm1@@Base+0x184>
   42c28:	cmp	x25, x24
   42c2c:	b.eq	42c5c <__gmpn_sqrmod_bnm1@@Base+0x1d4>  // b.none
   42c30:	cmp	x26, x23
   42c34:	b.ge	42c5c <__gmpn_sqrmod_bnm1@@Base+0x1d4>  // b.tcont
   42c38:	add	x9, x26, x28
   42c3c:	add	x9, x20, x9, lsl #3
   42c40:	sub	x8, x23, x26
   42c44:	add	x9, x9, #0x10
   42c48:	add	x10, x24, x26, lsl #3
   42c4c:	ldr	x11, [x10], #8
   42c50:	subs	x8, x8, #0x1
   42c54:	str	x11, [x9], #8
   42c58:	b.ne	42c4c <__gmpn_sqrmod_bnm1@@Base+0x1c4>  // b.any
   42c5c:	mov	x8, xzr
   42c60:	str	xzr, [x25, x23, lsl #3]
   42c64:	add	x26, x8, x23
   42c68:	cmp	x21, #0x278
   42c6c:	b.lt	42cd8 <__gmpn_sqrmod_bnm1@@Base+0x250>  // b.tstop
   42c70:	mov	w1, #0x1                   	// #1
   42c74:	mov	x0, x23
   42c78:	bl	caf0 <__gmpn_fft_best_k@plt>
   42c7c:	mov	w8, #0xffffffff            	// #-1
   42c80:	lsl	w8, w8, w0
   42c84:	mvn	w8, w8
   42c88:	sxtw	x9, w8
   42c8c:	mov	w6, w0
   42c90:	tst	x23, x9
   42c94:	b.eq	42cac <__gmpn_sqrmod_bnm1@@Base+0x224>  // b.none
   42c98:	sbfx	x9, x8, #1, #31
   42c9c:	asr	w8, w8, #1
   42ca0:	tst	x23, x9
   42ca4:	sub	w6, w6, #0x1
   42ca8:	b.ne	42c98 <__gmpn_sqrmod_bnm1@@Base+0x210>  // b.any
   42cac:	cmp	w6, #0x4
   42cb0:	b.lt	42cd8 <__gmpn_sqrmod_bnm1@@Base+0x250>  // b.tstop
   42cb4:	mov	x0, x20
   42cb8:	mov	x1, x23
   42cbc:	mov	x2, x25
   42cc0:	mov	x3, x26
   42cc4:	mov	x4, x25
   42cc8:	mov	x5, x26
   42ccc:	bl	c320 <__gmpn_mul_fft@plt>
   42cd0:	str	x0, [x20, x23, lsl #3]
   42cd4:	b	42d3c <__gmpn_sqrmod_bnm1@@Base+0x2b4>
   42cd8:	cmp	x25, x24
   42cdc:	b.eq	42f2c <__gmpn_sqrmod_bnm1@@Base+0x4a4>  // b.none
   42ce0:	add	x2, x23, #0x1
   42ce4:	mov	x0, x20
   42ce8:	mov	x1, x25
   42cec:	bl	c900 <__gmpn_sqr@plt>
   42cf0:	and	x8, x21, #0x1ffffffffffffffe
   42cf4:	ldr	x25, [x20, x8, lsl #3]
   42cf8:	add	x24, x20, x23, lsl #3
   42cfc:	mov	x0, x20
   42d00:	mov	x1, x20
   42d04:	mov	x2, x24
   42d08:	mov	x3, x23
   42d0c:	bl	c2e0 <__gmpn_sub_n@plt>
   42d10:	str	xzr, [x24]
   42d14:	ldr	x8, [x20]
   42d18:	add	x9, x0, x25
   42d1c:	adds	x8, x8, x9
   42d20:	str	x8, [x20]
   42d24:	b.cc	42d3c <__gmpn_sqrmod_bnm1@@Base+0x2b4>  // b.lo, b.ul, b.last
   42d28:	add	x8, x20, #0x8
   42d2c:	ldr	x9, [x8]
   42d30:	adds	x9, x9, #0x1
   42d34:	str	x9, [x8], #8
   42d38:	b.cs	42d2c <__gmpn_sqrmod_bnm1@@Base+0x2a4>  // b.hs, b.nlast
   42d3c:	ldr	x24, [x20, x23, lsl #3]
   42d40:	mov	x0, x19
   42d44:	mov	x1, x19
   42d48:	mov	x2, x20
   42d4c:	mov	x3, x23
   42d50:	bl	c970 <__gmpn_rsh1add_n@plt>
   42d54:	mov	x8, xzr
   42d58:	add	x9, x19, x23, lsl #3
   42d5c:	add	x11, x0, x24
   42d60:	ldur	x10, [x9, #-8]
   42d64:	lsr	x12, x11, #1
   42d68:	lsl	x11, x11, #63
   42d6c:	adds	x13, x10, x11
   42d70:	adc	x8, x12, x8
   42d74:	stur	x13, [x9, #-8]
   42d78:	ldr	x9, [x19]
   42d7c:	adds	x8, x9, x8
   42d80:	str	x8, [x19]
   42d84:	b.cc	42d9c <__gmpn_sqrmod_bnm1@@Base+0x314>  // b.lo, b.ul, b.last
   42d88:	add	x8, x19, #0x8
   42d8c:	ldr	x9, [x8]
   42d90:	adds	x9, x9, #0x1
   42d94:	str	x9, [x8], #8
   42d98:	b.cs	42d8c <__gmpn_sqrmod_bnm1@@Base+0x304>  // b.hs, b.nlast
   42d9c:	lsl	x22, x22, #1
   42da0:	cmp	x22, x21
   42da4:	b.lt	42ebc <__gmpn_sqrmod_bnm1@@Base+0x434>  // b.tstop
   42da8:	ldr	x21, [x20, x23, lsl #3]
   42dac:	add	x0, x19, x23, lsl #3
   42db0:	mov	x1, x19
   42db4:	mov	x2, x20
   42db8:	mov	x3, x23
   42dbc:	bl	c2e0 <__gmpn_sub_n@plt>
   42dc0:	ldr	x8, [x19]
   42dc4:	add	x9, x0, x21
   42dc8:	subs	x8, x8, x9
   42dcc:	str	x8, [x19]
   42dd0:	b.cs	42de8 <__gmpn_sqrmod_bnm1@@Base+0x360>  // b.hs, b.nlast
   42dd4:	add	x8, x19, #0x8
   42dd8:	ldr	x9, [x8]
   42ddc:	sub	x10, x9, #0x1
   42de0:	str	x10, [x8], #8
   42de4:	cbz	x9, 42dd8 <__gmpn_sqrmod_bnm1@@Base+0x350>
   42de8:	ldp	x20, x19, [sp, #80]
   42dec:	ldp	x22, x21, [sp, #64]
   42df0:	ldp	x24, x23, [sp, #48]
   42df4:	ldp	x26, x25, [sp, #32]
   42df8:	ldp	x28, x27, [sp, #16]
   42dfc:	ldp	x29, x30, [sp], #96
   42e00:	ret
   42e04:	mov	x8, x25
   42e08:	str	xzr, [x25, x23, lsl #3]
   42e0c:	ldr	x9, [x8]
   42e10:	adds	x9, x9, #0x1
   42e14:	str	x9, [x8], #8
   42e18:	b.cs	42e0c <__gmpn_sqrmod_bnm1@@Base+0x384>  // b.hs, b.nlast
   42e1c:	ldr	x8, [x25, x23, lsl #3]
   42e20:	b	42c64 <__gmpn_sqrmod_bnm1@@Base+0x1dc>
   42e24:	mov	x0, x19
   42e28:	mov	x1, x23
   42e2c:	mov	x2, x24
   42e30:	mov	x3, x22
   42e34:	mov	x4, x20
   42e38:	bl	bf60 <__gmpn_sqrmod_bnm1@plt>
   42e3c:	mov	x25, x24
   42e40:	mov	x26, x22
   42e44:	b	42c68 <__gmpn_sqrmod_bnm1@@Base+0x1e0>
   42e48:	lsl	x23, x22, #1
   42e4c:	cmp	x23, x21
   42e50:	b.le	42fe4 <__gmpn_sqrmod_bnm1@@Base+0x55c>
   42e54:	mov	x0, x20
   42e58:	mov	x1, x24
   42e5c:	mov	x2, x22
   42e60:	bl	c900 <__gmpn_sqr@plt>
   42e64:	subs	x22, x23, x21
   42e68:	b.eq	42f8c <__gmpn_sqrmod_bnm1@@Base+0x504>  // b.none
   42e6c:	add	x2, x20, x21, lsl #3
   42e70:	mov	x0, x19
   42e74:	mov	x1, x20
   42e78:	mov	x3, x22
   42e7c:	bl	ca90 <__gmpn_add_n@plt>
   42e80:	cbz	x0, 42f94 <__gmpn_sqrmod_bnm1@@Base+0x50c>
   42e84:	cmp	x22, x21
   42e88:	b.ge	42ea8 <__gmpn_sqrmod_bnm1@@Base+0x420>  // b.tcont
   42e8c:	ldr	x8, [x20, x22, lsl #3]
   42e90:	add	x9, x22, #0x1
   42e94:	adds	x8, x8, #0x1
   42e98:	str	x8, [x19, x22, lsl #3]
   42e9c:	mov	x22, x9
   42ea0:	b.cs	42e84 <__gmpn_sqrmod_bnm1@@Base+0x3fc>  // b.hs, b.nlast
   42ea4:	b	42f98 <__gmpn_sqrmod_bnm1@@Base+0x510>
   42ea8:	ldr	x8, [x19]
   42eac:	adds	x8, x8, #0x1
   42eb0:	str	x8, [x19], #8
   42eb4:	b.cs	42ea8 <__gmpn_sqrmod_bnm1@@Base+0x420>  // b.hs, b.nlast
   42eb8:	b	42de8 <__gmpn_sqrmod_bnm1@@Base+0x360>
   42ebc:	add	x0, x19, x23, lsl #3
   42ec0:	sub	x3, x22, x23
   42ec4:	mov	x1, x19
   42ec8:	mov	x2, x20
   42ecc:	bl	c2e0 <__gmpn_sub_n@plt>
   42ed0:	ldr	x24, [x20, x23, lsl #3]
   42ed4:	add	x8, x20, x22, lsl #3
   42ed8:	mov	x4, x0
   42edc:	sub	x0, x8, x23, lsl #3
   42ee0:	add	x8, x19, x22, lsl #3
   42ee4:	sub	x1, x8, x23, lsl #3
   42ee8:	sub	x3, x21, x22
   42eec:	mov	x2, x0
   42ef0:	bl	c780 <__gmpn_sub_nc@plt>
   42ef4:	ldr	x8, [x19]
   42ef8:	add	x9, x0, x24
   42efc:	subs	x8, x8, x9
   42f00:	str	x8, [x19]
   42f04:	b.cs	42de8 <__gmpn_sqrmod_bnm1@@Base+0x360>  // b.hs, b.nlast
   42f08:	mov	w8, #0x1                   	// #1
   42f0c:	cmp	x8, x22
   42f10:	b.ge	42de8 <__gmpn_sqrmod_bnm1@@Base+0x360>  // b.tcont
   42f14:	ldr	x9, [x19, x8, lsl #3]
   42f18:	sub	x10, x9, #0x1
   42f1c:	str	x10, [x19, x8, lsl #3]
   42f20:	add	x8, x8, #0x1
   42f24:	cbz	x9, 42f0c <__gmpn_sqrmod_bnm1@@Base+0x484>
   42f28:	b	42de8 <__gmpn_sqrmod_bnm1@@Base+0x360>
   42f2c:	mov	x0, x20
   42f30:	mov	x1, x24
   42f34:	mov	x2, x22
   42f38:	bl	c900 <__gmpn_sqr@plt>
   42f3c:	lsl	x8, x22, #1
   42f40:	subs	x25, x8, x23
   42f44:	add	x24, x20, x23, lsl #3
   42f48:	b.eq	42f84 <__gmpn_sqrmod_bnm1@@Base+0x4fc>  // b.none
   42f4c:	mov	x0, x20
   42f50:	mov	x1, x20
   42f54:	mov	x2, x24
   42f58:	mov	x3, x25
   42f5c:	bl	c2e0 <__gmpn_sub_n@plt>
   42f60:	cbz	x0, 42f84 <__gmpn_sqrmod_bnm1@@Base+0x4fc>
   42f64:	cmp	x25, x23
   42f68:	b.ge	42fc8 <__gmpn_sqrmod_bnm1@@Base+0x540>  // b.tcont
   42f6c:	ldr	x8, [x20, x25, lsl #3]
   42f70:	add	x10, x25, #0x1
   42f74:	sub	x9, x8, #0x1
   42f78:	str	x9, [x20, x25, lsl #3]
   42f7c:	mov	x25, x10
   42f80:	cbz	x8, 42f64 <__gmpn_sqrmod_bnm1@@Base+0x4dc>
   42f84:	str	xzr, [x24]
   42f88:	b	42d3c <__gmpn_sqrmod_bnm1@@Base+0x2b4>
   42f8c:	mov	x9, xzr
   42f90:	b	42f98 <__gmpn_sqrmod_bnm1@@Base+0x510>
   42f94:	mov	x9, x22
   42f98:	cmp	x19, x20
   42f9c:	b.eq	42de8 <__gmpn_sqrmod_bnm1@@Base+0x360>  // b.none
   42fa0:	cmp	x9, x21
   42fa4:	b.ge	42de8 <__gmpn_sqrmod_bnm1@@Base+0x360>  // b.tcont
   42fa8:	sub	x8, x21, x9
   42fac:	add	x10, x19, x9, lsl #3
   42fb0:	add	x9, x20, x9, lsl #3
   42fb4:	ldr	x11, [x9], #8
   42fb8:	subs	x8, x8, #0x1
   42fbc:	str	x11, [x10], #8
   42fc0:	b.ne	42fb4 <__gmpn_sqrmod_bnm1@@Base+0x52c>  // b.any
   42fc4:	b	42de8 <__gmpn_sqrmod_bnm1@@Base+0x360>
   42fc8:	mov	x8, x20
   42fcc:	str	xzr, [x24]
   42fd0:	ldr	x9, [x8]
   42fd4:	adds	x9, x9, #0x1
   42fd8:	str	x9, [x8], #8
   42fdc:	b.cs	42fd0 <__gmpn_sqrmod_bnm1@@Base+0x548>  // b.hs, b.nlast
   42fe0:	b	42d3c <__gmpn_sqrmod_bnm1@@Base+0x2b4>
   42fe4:	mov	x0, x19
   42fe8:	mov	x1, x24
   42fec:	mov	x2, x22
   42ff0:	ldp	x20, x19, [sp, #80]
   42ff4:	ldp	x22, x21, [sp, #64]
   42ff8:	ldp	x24, x23, [sp, #48]
   42ffc:	ldp	x26, x25, [sp, #32]
   43000:	ldp	x28, x27, [sp, #16]
   43004:	ldp	x29, x30, [sp], #96
   43008:	b	c900 <__gmpn_sqr@plt>

000000000004300c <__gmpn_sqrmod_bnm1_next_size@@Base>:
   4300c:	cmp	x0, #0xb
   43010:	b.lt	43064 <__gmpn_sqrmod_bnm1_next_size@@Base+0x58>  // b.tstop
   43014:	cmp	x0, #0x28
   43018:	b.le	43068 <__gmpn_sqrmod_bnm1_next_size@@Base+0x5c>
   4301c:	cmp	x0, #0x50
   43020:	b.le	43074 <__gmpn_sqrmod_bnm1_next_size@@Base+0x68>
   43024:	cmp	x0, #0x21e
   43028:	b.le	43080 <__gmpn_sqrmod_bnm1_next_size@@Base+0x74>
   4302c:	stp	x29, x30, [sp, #-32]!
   43030:	add	x8, x0, #0x1
   43034:	str	x19, [sp, #16]
   43038:	asr	x19, x8, #1
   4303c:	mov	w1, #0x1                   	// #1
   43040:	mov	x0, x19
   43044:	mov	x29, sp
   43048:	bl	caf0 <__gmpn_fft_best_k@plt>
   4304c:	mov	w1, w0
   43050:	mov	x0, x19
   43054:	bl	d1f0 <__gmpn_fft_next_size@plt>
   43058:	ldr	x19, [sp, #16]
   4305c:	lsl	x0, x0, #1
   43060:	ldp	x29, x30, [sp], #32
   43064:	ret
   43068:	add	x8, x0, #0x1
   4306c:	and	x0, x8, #0xfffffffffffffffe
   43070:	ret
   43074:	add	x8, x0, #0x3
   43078:	and	x0, x8, #0xfffffffffffffffc
   4307c:	ret
   43080:	add	x8, x0, #0x7
   43084:	and	x0, x8, #0xfffffffffffffff8
   43088:	ret

000000000004308c <__gmpn_div_qr_1@@Base>:
   4308c:	stp	x29, x30, [sp, #-80]!
   43090:	stp	x24, x23, [sp, #32]
   43094:	stp	x22, x21, [sp, #48]
   43098:	stp	x20, x19, [sp, #64]
   4309c:	mov	x19, x4
   430a0:	mov	x22, x2
   430a4:	mov	x24, x1
   430a8:	mov	x20, x0
   430ac:	stp	x26, x25, [sp, #16]
   430b0:	mov	x29, sp
   430b4:	tbnz	x4, #63, 43130 <__gmpn_div_qr_1@@Base+0xa4>
   430b8:	sub	x23, x3, #0x1
   430bc:	ldr	x25, [x22, x23, lsl #3]
   430c0:	clz	x21, x19
   430c4:	mov	x0, x20
   430c8:	mov	x1, x22
   430cc:	mov	x2, x23
   430d0:	mov	w3, w21
   430d4:	lsl	x19, x19, x21
   430d8:	lsl	x26, x25, x21
   430dc:	bl	c190 <__gmpn_lshift@plt>
   430e0:	neg	x9, x21
   430e4:	lsr	x10, x19, #32
   430e8:	lsr	x9, x25, x9
   430ec:	udiv	x14, x9, x10
   430f0:	orr	x8, x26, x0
   430f4:	and	x11, x19, #0xffffffff
   430f8:	msub	w9, w14, w10, w9
   430fc:	mul	x12, x14, x11
   43100:	extr	x13, x9, x8, #32
   43104:	cmp	x13, x12
   43108:	b.cs	4318c <__gmpn_div_qr_1@@Base+0x100>  // b.hs, b.nlast
   4310c:	add	x13, x13, x19
   43110:	cmp	x13, x19
   43114:	sub	x9, x14, #0x1
   43118:	b.cc	43190 <__gmpn_div_qr_1@@Base+0x104>  // b.lo, b.ul, b.last
   4311c:	cmp	x13, x12
   43120:	b.cs	43190 <__gmpn_div_qr_1@@Base+0x104>  // b.hs, b.nlast
   43124:	sub	x9, x14, #0x2
   43128:	add	x13, x13, x19
   4312c:	b	43190 <__gmpn_div_qr_1@@Base+0x104>
   43130:	sub	x23, x3, #0x1
   43134:	ldr	x8, [x22, x23, lsl #3]
   43138:	cmp	x8, x19
   4313c:	csel	x10, x19, xzr, cs  // cs = hs, nlast
   43140:	cset	w9, cs  // cs = hs, nlast
   43144:	cmp	x3, #0xd
   43148:	sub	x25, x8, x10
   4314c:	str	x9, [x24]
   43150:	b.le	431e8 <__gmpn_div_qr_1@@Base+0x15c>
   43154:	mov	x0, x19
   43158:	bl	d410 <__gmpn_invert_limb@plt>
   4315c:	mov	x5, x0
   43160:	mov	x0, x20
   43164:	mov	x1, x22
   43168:	mov	x2, x23
   4316c:	mov	x3, x25
   43170:	mov	x4, x19
   43174:	ldp	x20, x19, [sp, #64]
   43178:	ldp	x22, x21, [sp, #48]
   4317c:	ldp	x24, x23, [sp, #32]
   43180:	ldp	x26, x25, [sp, #16]
   43184:	ldp	x29, x30, [sp], #80
   43188:	b	c490 <__gmpn_div_qr_1n_pi1@plt>
   4318c:	mov	x9, x14
   43190:	sub	x13, x13, x12
   43194:	udiv	x12, x13, x10
   43198:	msub	w13, w12, w10, w13
   4319c:	mul	x10, x12, x11
   431a0:	bfi	x8, x13, #32, #32
   431a4:	cmp	x8, x10
   431a8:	b.cs	431d0 <__gmpn_div_qr_1@@Base+0x144>  // b.hs, b.nlast
   431ac:	add	x8, x8, x19
   431b0:	cmp	x8, x19
   431b4:	sub	x11, x12, #0x1
   431b8:	b.cc	431d4 <__gmpn_div_qr_1@@Base+0x148>  // b.lo, b.ul, b.last
   431bc:	cmp	x8, x10
   431c0:	b.cs	431d4 <__gmpn_div_qr_1@@Base+0x148>  // b.hs, b.nlast
   431c4:	sub	x11, x12, #0x2
   431c8:	add	x8, x8, x19
   431cc:	b	431d4 <__gmpn_div_qr_1@@Base+0x148>
   431d0:	mov	x11, x12
   431d4:	sub	x25, x8, x10
   431d8:	orr	x8, x11, x9, lsl #32
   431dc:	str	x8, [x24]
   431e0:	mov	x22, x20
   431e4:	b	431ec <__gmpn_div_qr_1@@Base+0x160>
   431e8:	mov	x21, xzr
   431ec:	subs	x8, x23, #0x1
   431f0:	b.lt	432a0 <__gmpn_div_qr_1@@Base+0x214>  // b.tstop
   431f4:	lsr	x9, x19, #32
   431f8:	and	x10, x19, #0xffffffff
   431fc:	ldr	x11, [x22, x8, lsl #3]
   43200:	udiv	x15, x25, x9
   43204:	msub	w12, w15, w9, w25
   43208:	mul	x13, x15, x10
   4320c:	extr	x14, x12, x11, #32
   43210:	cmp	x14, x13
   43214:	b.cs	4323c <__gmpn_div_qr_1@@Base+0x1b0>  // b.hs, b.nlast
   43218:	add	x14, x14, x19
   4321c:	cmp	x14, x19
   43220:	sub	x12, x15, #0x1
   43224:	b.cc	43240 <__gmpn_div_qr_1@@Base+0x1b4>  // b.lo, b.ul, b.last
   43228:	cmp	x14, x13
   4322c:	b.cs	43240 <__gmpn_div_qr_1@@Base+0x1b4>  // b.hs, b.nlast
   43230:	sub	x12, x15, #0x2
   43234:	add	x14, x14, x19
   43238:	b	43240 <__gmpn_div_qr_1@@Base+0x1b4>
   4323c:	mov	x12, x15
   43240:	sub	x13, x14, x13
   43244:	udiv	x14, x13, x9
   43248:	msub	w15, w14, w9, w13
   4324c:	mul	x13, x14, x10
   43250:	bfi	x11, x15, #32, #32
   43254:	cmp	x11, x13
   43258:	b.cs	43280 <__gmpn_div_qr_1@@Base+0x1f4>  // b.hs, b.nlast
   4325c:	add	x11, x11, x19
   43260:	cmp	x11, x19
   43264:	sub	x15, x14, #0x1
   43268:	b.cc	43284 <__gmpn_div_qr_1@@Base+0x1f8>  // b.lo, b.ul, b.last
   4326c:	cmp	x11, x13
   43270:	b.cs	43284 <__gmpn_div_qr_1@@Base+0x1f8>  // b.hs, b.nlast
   43274:	sub	x15, x14, #0x2
   43278:	add	x11, x11, x19
   4327c:	b	43284 <__gmpn_div_qr_1@@Base+0x1f8>
   43280:	mov	x15, x14
   43284:	orr	x12, x15, x12, lsl #32
   43288:	add	x14, x8, #0x1
   4328c:	str	x12, [x20, x8, lsl #3]
   43290:	sub	x8, x8, #0x1
   43294:	cmp	x14, #0x1
   43298:	sub	x25, x11, x13
   4329c:	b.gt	431fc <__gmpn_div_qr_1@@Base+0x170>
   432a0:	lsr	x0, x25, x21
   432a4:	ldp	x20, x19, [sp, #64]
   432a8:	ldp	x22, x21, [sp, #48]
   432ac:	ldp	x24, x23, [sp, #32]
   432b0:	ldp	x26, x25, [sp, #16]
   432b4:	ldp	x29, x30, [sp], #80
   432b8:	ret

00000000000432bc <__gmpn_div_qr_1n_pi1@@Base>:
   432bc:	cmp	x2, #0x1
   432c0:	b.ne	43308 <__gmpn_div_qr_1n_pi1@@Base+0x4c>  // b.any
   432c4:	ldr	x8, [x1]
   432c8:	umulh	x9, x3, x5
   432cc:	mul	x10, x5, x3
   432d0:	add	x11, x3, #0x1
   432d4:	adds	x12, x10, x8
   432d8:	adc	x9, x9, x11
   432dc:	msub	x8, x9, x4, x8
   432e0:	cmp	x8, x12
   432e4:	csel	x10, x4, xzr, hi  // hi = pmore
   432e8:	cset	w11, hi  // hi = pmore
   432ec:	add	x8, x10, x8
   432f0:	subs	x10, x8, x4
   432f4:	sub	x9, x9, x11
   432f8:	b.cc	434bc <__gmpn_div_qr_1n_pi1@@Base+0x200>  // b.lo, b.ul, b.last
   432fc:	add	x9, x9, #0x1
   43300:	mov	x8, x10
   43304:	b	434bc <__gmpn_div_qr_1n_pi1@@Base+0x200>
   43308:	umulh	x10, x5, x3
   4330c:	lsl	x11, x2, #3
   43310:	add	x10, x10, x3
   43314:	sub	x11, x11, #0x8
   43318:	sub	x15, x2, #0x2
   4331c:	ldr	x12, [x1, x11]
   43320:	str	x10, [x0, x11]
   43324:	ldr	x10, [x1, x15, lsl #3]
   43328:	mul	x9, x4, x5
   4332c:	mneg	x9, x9, x3
   43330:	mneg	x8, x4, x5
   43334:	adds	x9, x10, x9
   43338:	mov	w11, #0x2                   	// #2
   4333c:	umulh	x13, x8, x3
   43340:	cset	w10, cs  // cs = hs, nlast
   43344:	adds	x12, x12, x13
   43348:	cset	w13, cs  // cs = hs, nlast
   4334c:	csinc	x11, x11, xzr, cs  // cs = hs, nlast
   43350:	adds	x10, x12, x10
   43354:	csel	x16, x13, x11, cc  // cc = lo, ul, last
   43358:	subs	x17, x2, #0x3
   4335c:	mul	x18, x5, x3
   43360:	b.lt	43424 <__gmpn_div_qr_1n_pi1@@Base+0x168>  // b.tstop
   43364:	add	x12, x0, #0x10
   43368:	add	x13, x0, x2, lsl #3
   4336c:	mov	w14, #0x2                   	// #2
   43370:	neg	x2, x16
   43374:	mov	x11, xzr
   43378:	and	x6, x2, x5
   4337c:	adds	x7, x6, x10
   43380:	adc	x16, x16, x11
   43384:	umulh	x3, x10, x5
   43388:	adds	x6, x7, x3
   4338c:	adc	x16, x16, x11
   43390:	and	x2, x2, x8
   43394:	adds	x3, x6, x18
   43398:	adc	x16, x16, x11
   4339c:	adds	x18, x9, x2
   433a0:	cset	w9, cs  // cs = hs, nlast
   433a4:	csel	x2, x4, xzr, cs  // cs = hs, nlast
   433a8:	adds	x6, x3, x9
   433ac:	adc	x3, x16, x11
   433b0:	str	x6, [x0, x15, lsl #3]
   433b4:	mov	x15, x17
   433b8:	ldr	x17, [x12, x17, lsl #3]
   433bc:	mul	x11, x10, x5
   433c0:	umulh	x16, x10, x8
   433c4:	mul	x9, x10, x8
   433c8:	sub	x10, x18, x2
   433cc:	adds	x17, x17, x3
   433d0:	str	x17, [x12, x15, lsl #3]
   433d4:	b.cc	433ec <__gmpn_div_qr_1n_pi1@@Base+0x130>  // b.lo, b.ul, b.last
   433d8:	mov	x17, x13
   433dc:	ldr	x18, [x17]
   433e0:	adds	x18, x18, #0x1
   433e4:	str	x18, [x17], #8
   433e8:	b.cs	433dc <__gmpn_div_qr_1n_pi1@@Base+0x120>  // b.hs, b.nlast
   433ec:	ldr	x18, [x1, x15, lsl #3]
   433f0:	sub	x17, x15, #0x1
   433f4:	sub	x13, x13, #0x8
   433f8:	adds	x9, x18, x9
   433fc:	cset	w18, cs  // cs = hs, nlast
   43400:	adds	x10, x16, x10
   43404:	cset	w16, cs  // cs = hs, nlast
   43408:	csinc	x2, x14, xzr, cs  // cs = hs, nlast
   4340c:	adds	x10, x10, x18
   43410:	csel	x16, x16, x2, cc  // cc = lo, ul, last
   43414:	cmp	x15, #0x0
   43418:	mov	x18, x11
   4341c:	b.gt	43370 <__gmpn_div_qr_1n_pi1@@Base+0xb4>
   43420:	b	43428 <__gmpn_div_qr_1n_pi1@@Base+0x16c>
   43424:	mov	x11, x18
   43428:	mov	x12, xzr
   4342c:	cmp	x16, #0x0
   43430:	csel	x14, x4, x12, ne  // ne = any
   43434:	mov	w8, #0x2                   	// #2
   43438:	sub	x10, x10, x14
   4343c:	cset	w14, ne  // ne = any
   43440:	csinc	x8, x8, xzr, ne  // ne = any
   43444:	cmp	x10, x4
   43448:	csel	x14, x14, x8, cc  // cc = lo, ul, last
   4344c:	csel	x8, x4, x12, cs  // cs = hs, nlast
   43450:	sub	x8, x10, x8
   43454:	umulh	x10, x8, x5
   43458:	mul	x15, x8, x5
   4345c:	add	x8, x8, #0x1
   43460:	adds	x16, x15, x9
   43464:	adc	x8, x10, x8
   43468:	msub	x9, x8, x4, x9
   4346c:	cmp	x9, x16
   43470:	csel	x15, x4, x12, hi  // hi = pmore
   43474:	ldr	x13, [x0, #8]
   43478:	cset	w10, hi  // hi = pmore
   4347c:	add	x9, x15, x9
   43480:	sub	x8, x8, x10
   43484:	cmp	x9, x4
   43488:	cinc	x10, x8, cs  // cs = hs, nlast
   4348c:	csel	x8, x12, x4, cc  // cc = lo, ul, last
   43490:	sub	x8, x9, x8
   43494:	adds	x9, x11, x10
   43498:	adc	x10, x14, x12
   4349c:	adds	x10, x13, x10
   434a0:	str	x10, [x0, #8]
   434a4:	b.cc	434bc <__gmpn_div_qr_1n_pi1@@Base+0x200>  // b.lo, b.ul, b.last
   434a8:	add	x10, x0, #0x10
   434ac:	ldr	x11, [x10]
   434b0:	adds	x11, x11, #0x1
   434b4:	str	x11, [x10], #8
   434b8:	b.cs	434ac <__gmpn_div_qr_1n_pi1@@Base+0x1f0>  // b.hs, b.nlast
   434bc:	str	x9, [x0]
   434c0:	mov	x0, x8
   434c4:	ret

00000000000434c8 <__gmpn_div_qr_2@@Base>:
   434c8:	stp	x29, x30, [sp, #-80]!
   434cc:	str	x25, [sp, #16]
   434d0:	stp	x24, x23, [sp, #32]
   434d4:	stp	x22, x21, [sp, #48]
   434d8:	stp	x20, x19, [sp, #64]
   434dc:	ldp	x23, x25, [x4]
   434e0:	mov	x19, x3
   434e4:	mov	x20, x2
   434e8:	mov	x21, x1
   434ec:	mov	x22, x0
   434f0:	mov	x29, sp
   434f4:	tbnz	x25, #63, 435a4 <__gmpn_div_qr_2@@Base+0xdc>
   434f8:	clz	x24, x25
   434fc:	neg	x9, x24
   43500:	lsl	x8, x25, x24
   43504:	lsr	x9, x23, x9
   43508:	orr	x25, x9, x8
   4350c:	mov	x0, x25
   43510:	lsl	x23, x23, x24
   43514:	bl	d410 <__gmpn_invert_limb@plt>
   43518:	mul	x8, x0, x25
   4351c:	adds	x8, x8, x23
   43520:	b.cc	4353c <__gmpn_div_qr_2@@Base+0x74>  // b.lo, b.ul, b.last
   43524:	subs	x8, x8, x25
   43528:	cset	w9, cs  // cs = hs, nlast
   4352c:	csel	x10, x25, xzr, cs  // cs = hs, nlast
   43530:	mvn	x9, x9
   43534:	add	x0, x9, x0
   43538:	sub	x8, x8, x10
   4353c:	umulh	x9, x23, x0
   43540:	adds	x8, x9, x8
   43544:	b.cc	4356c <__gmpn_div_qr_2@@Base+0xa4>  // b.lo, b.ul, b.last
   43548:	cmp	x8, x25
   4354c:	sub	x7, x0, #0x1
   43550:	b.cc	43570 <__gmpn_div_qr_2@@Base+0xa8>  // b.lo, b.ul, b.last
   43554:	mul	x9, x0, x23
   43558:	cmp	x8, x25
   4355c:	sub	x10, x0, #0x2
   43560:	ccmp	x9, x23, #0x2, ls  // ls = plast
   43564:	csel	x7, x7, x10, cc  // cc = lo, ul, last
   43568:	b	43570 <__gmpn_div_qr_2@@Base+0xa8>
   4356c:	mov	x7, x0
   43570:	mov	x0, x22
   43574:	mov	x1, x21
   43578:	mov	x2, x20
   4357c:	mov	x3, x19
   43580:	mov	x4, x25
   43584:	mov	x5, x23
   43588:	mov	w6, w24
   4358c:	ldp	x20, x19, [sp, #64]
   43590:	ldp	x22, x21, [sp, #48]
   43594:	ldp	x24, x23, [sp, #32]
   43598:	ldr	x25, [sp, #16]
   4359c:	ldp	x29, x30, [sp], #80
   435a0:	b	cf40 <__gmpn_div_qr_2u_pi1@plt>
   435a4:	mov	x0, x25
   435a8:	bl	d410 <__gmpn_invert_limb@plt>
   435ac:	mul	x8, x0, x25
   435b0:	adds	x8, x8, x23
   435b4:	b.cc	435d0 <__gmpn_div_qr_2@@Base+0x108>  // b.lo, b.ul, b.last
   435b8:	subs	x8, x8, x25
   435bc:	cset	w9, cs  // cs = hs, nlast
   435c0:	csel	x10, x25, xzr, cs  // cs = hs, nlast
   435c4:	mvn	x9, x9
   435c8:	add	x0, x9, x0
   435cc:	sub	x8, x8, x10
   435d0:	umulh	x9, x23, x0
   435d4:	adds	x8, x9, x8
   435d8:	b.cc	43600 <__gmpn_div_qr_2@@Base+0x138>  // b.lo, b.ul, b.last
   435dc:	cmp	x8, x25
   435e0:	sub	x6, x0, #0x1
   435e4:	b.cc	43604 <__gmpn_div_qr_2@@Base+0x13c>  // b.lo, b.ul, b.last
   435e8:	mul	x9, x0, x23
   435ec:	cmp	x8, x25
   435f0:	sub	x10, x0, #0x2
   435f4:	ccmp	x9, x23, #0x2, ls  // ls = plast
   435f8:	csel	x6, x6, x10, cc  // cc = lo, ul, last
   435fc:	b	43604 <__gmpn_div_qr_2@@Base+0x13c>
   43600:	mov	x6, x0
   43604:	mov	x0, x22
   43608:	mov	x1, x21
   4360c:	mov	x2, x20
   43610:	mov	x3, x19
   43614:	mov	x4, x25
   43618:	mov	x5, x23
   4361c:	ldp	x20, x19, [sp, #64]
   43620:	ldp	x22, x21, [sp, #48]
   43624:	ldp	x24, x23, [sp, #32]
   43628:	ldr	x25, [sp, #16]
   4362c:	ldp	x29, x30, [sp], #80
   43630:	b	c940 <__gmpn_div_qr_2n_pi1@plt>

0000000000043634 <__gmpn_div_qr_2n_pi1@@Base>:
   43634:	add	x8, x2, x3, lsl #3
   43638:	ldp	x10, x9, [x8, #-16]
   4363c:	cmp	x9, x4
   43640:	b.cc	43650 <__gmpn_div_qr_2n_pi1@@Base+0x1c>  // b.lo, b.ul, b.last
   43644:	b.hi	43658 <__gmpn_div_qr_2n_pi1@@Base+0x24>  // b.pmore
   43648:	cmp	x10, x5
   4364c:	b.cs	43658 <__gmpn_div_qr_2n_pi1@@Base+0x24>  // b.hs, b.nlast
   43650:	mov	x8, xzr
   43654:	b	43668 <__gmpn_div_qr_2n_pi1@@Base+0x34>
   43658:	subs	x11, x10, x5
   4365c:	sbc	x9, x9, x4
   43660:	mov	w8, #0x1                   	// #1
   43664:	mov	x10, x11
   43668:	subs	x11, x3, #0x3
   4366c:	b.lt	43708 <__gmpn_div_qr_2n_pi1@@Base+0xd4>  // b.tstop
   43670:	mul	x13, x9, x6
   43674:	ldr	x12, [x2, x11, lsl #3]
   43678:	umulh	x14, x9, x6
   4367c:	adds	x15, x13, x10
   43680:	adc	x9, x14, x9
   43684:	msub	x10, x9, x4, x10
   43688:	mul	x13, x9, x5
   4368c:	umulh	x14, x5, x9
   43690:	subs	x16, x12, x5
   43694:	sbc	x10, x10, x4
   43698:	subs	x12, x16, x13
   4369c:	sbc	x13, x10, x14
   436a0:	cmp	x13, x15
   436a4:	cset	w10, cs  // cs = hs, nlast
   436a8:	csetm	x14, cs  // cs = hs, nlast
   436ac:	sub	x15, x9, x10
   436b0:	and	x9, x14, x5
   436b4:	and	x14, x14, x4
   436b8:	adds	x10, x12, x9
   436bc:	adc	x9, x13, x14
   436c0:	cmp	x9, x4
   436c4:	add	x12, x15, #0x1
   436c8:	b.cs	436e4 <__gmpn_div_qr_2n_pi1@@Base+0xb0>  // b.hs, b.nlast
   436cc:	sub	x13, x11, #0x1
   436d0:	cmp	x11, #0x0
   436d4:	str	x12, [x0, x11, lsl #3]
   436d8:	mov	x11, x13
   436dc:	b.gt	43670 <__gmpn_div_qr_2n_pi1@@Base+0x3c>
   436e0:	b	43708 <__gmpn_div_qr_2n_pi1@@Base+0xd4>
   436e4:	cmp	x10, x5
   436e8:	b.cs	436f4 <__gmpn_div_qr_2n_pi1@@Base+0xc0>  // b.hs, b.nlast
   436ec:	cmp	x9, x4
   436f0:	b.ls	436cc <__gmpn_div_qr_2n_pi1@@Base+0x98>  // b.plast
   436f4:	subs	x13, x10, x5
   436f8:	sbc	x9, x9, x4
   436fc:	add	x12, x12, #0x1
   43700:	mov	x10, x13
   43704:	b	436cc <__gmpn_div_qr_2n_pi1@@Base+0x98>
   43708:	mov	x0, x8
   4370c:	stp	x10, x9, [x1]
   43710:	ret

0000000000043714 <__gmpn_div_qr_2u_pi1@@Base>:
   43714:	add	x8, x2, x3, lsl #3
   43718:	ldp	x8, x12, [x8, #-16]
   4371c:	neg	w11, w6
   43720:	mov	w10, #0x40                  	// #64
   43724:	mov	w9, w6
   43728:	lsr	x13, x12, x11
   4372c:	lsl	x12, x12, x6
   43730:	lsr	x11, x8, x11
   43734:	lsl	x8, x8, x6
   43738:	orr	x11, x11, x12
   4373c:	mul	x12, x13, x7
   43740:	umulh	x14, x13, x7
   43744:	adds	x15, x12, x11
   43748:	adc	x12, x14, x13
   4374c:	msub	x11, x12, x4, x11
   43750:	subs	x16, x8, x5
   43754:	sbc	x8, x11, x4
   43758:	mul	x13, x12, x5
   4375c:	umulh	x14, x5, x12
   43760:	subs	x11, x16, x13
   43764:	sbc	x8, x8, x14
   43768:	cmp	x8, x15
   4376c:	cset	w13, cs  // cs = hs, nlast
   43770:	csetm	x14, cs  // cs = hs, nlast
   43774:	sub	x13, x12, x13
   43778:	and	x15, x14, x5
   4377c:	and	x14, x14, x4
   43780:	adds	x12, x11, x15
   43784:	adc	x11, x8, x14
   43788:	sub	w10, w10, w6
   4378c:	cmp	x11, x4
   43790:	add	x8, x13, #0x1
   43794:	b.cs	43860 <__gmpn_div_qr_2u_pi1@@Base+0x14c>  // b.hs, b.nlast
   43798:	subs	x13, x3, #0x3
   4379c:	b.lt	43844 <__gmpn_div_qr_2u_pi1@@Base+0x130>  // b.tstop
   437a0:	ldr	x14, [x2, x13, lsl #3]
   437a4:	mul	x15, x11, x7
   437a8:	umulh	x16, x11, x7
   437ac:	lsr	x17, x14, x10
   437b0:	orr	x12, x17, x12
   437b4:	lsl	x14, x14, x9
   437b8:	adds	x17, x15, x12
   437bc:	adc	x11, x16, x11
   437c0:	msub	x12, x11, x4, x12
   437c4:	mul	x15, x11, x5
   437c8:	umulh	x16, x5, x11
   437cc:	subs	x18, x14, x5
   437d0:	sbc	x12, x12, x4
   437d4:	subs	x14, x18, x15
   437d8:	sbc	x15, x12, x16
   437dc:	cmp	x15, x17
   437e0:	cset	w12, cs  // cs = hs, nlast
   437e4:	csetm	x16, cs  // cs = hs, nlast
   437e8:	sub	x17, x11, x12
   437ec:	and	x11, x16, x5
   437f0:	and	x16, x16, x4
   437f4:	adds	x12, x14, x11
   437f8:	adc	x11, x15, x16
   437fc:	cmp	x11, x4
   43800:	add	x14, x17, #0x1
   43804:	b.cs	43820 <__gmpn_div_qr_2u_pi1@@Base+0x10c>  // b.hs, b.nlast
   43808:	sub	x15, x13, #0x1
   4380c:	cmp	x13, #0x0
   43810:	str	x14, [x0, x13, lsl #3]
   43814:	mov	x13, x15
   43818:	b.gt	437a0 <__gmpn_div_qr_2u_pi1@@Base+0x8c>
   4381c:	b	43844 <__gmpn_div_qr_2u_pi1@@Base+0x130>
   43820:	cmp	x12, x5
   43824:	b.cs	43830 <__gmpn_div_qr_2u_pi1@@Base+0x11c>  // b.hs, b.nlast
   43828:	cmp	x11, x4
   4382c:	b.ls	43808 <__gmpn_div_qr_2u_pi1@@Base+0xf4>  // b.plast
   43830:	subs	x15, x12, x5
   43834:	sbc	x11, x11, x4
   43838:	add	x14, x14, #0x1
   4383c:	mov	x12, x15
   43840:	b	43808 <__gmpn_div_qr_2u_pi1@@Base+0xf4>
   43844:	lsr	x12, x12, x9
   43848:	lsl	x10, x11, x10
   4384c:	lsr	x9, x11, x9
   43850:	orr	x10, x10, x12
   43854:	mov	x0, x8
   43858:	stp	x10, x9, [x1]
   4385c:	ret
   43860:	cmp	x12, x5
   43864:	b.cs	43870 <__gmpn_div_qr_2u_pi1@@Base+0x15c>  // b.hs, b.nlast
   43868:	cmp	x11, x4
   4386c:	b.ls	43798 <__gmpn_div_qr_2u_pi1@@Base+0x84>  // b.plast
   43870:	subs	x13, x12, x5
   43874:	sbc	x11, x11, x4
   43878:	add	x8, x8, #0x1
   4387c:	mov	x12, x13
   43880:	b	43798 <__gmpn_div_qr_2u_pi1@@Base+0x84>

0000000000043884 <__gmpn_sbpi1_div_q@@Base>:
   43884:	sub	sp, sp, #0xf0
   43888:	stp	x28, x27, [sp, #160]
   4388c:	sub	x27, x2, x4
   43890:	add	x8, x27, #0x1
   43894:	stp	x8, x3, [sp, #32]
   43898:	subs	x8, x4, x8
   4389c:	stp	x26, x25, [sp, #176]
   438a0:	stp	x20, x19, [sp, #224]
   438a4:	add	x19, x1, x2, lsl #3
   438a8:	csinc	x25, x4, x27, le
   438ac:	str	x8, [sp, #16]
   438b0:	add	x8, x3, x8, lsl #3
   438b4:	stp	x29, x30, [sp, #144]
   438b8:	stp	x24, x23, [sp, #192]
   438bc:	stp	x22, x21, [sp, #208]
   438c0:	add	x29, sp, #0x90
   438c4:	mov	x21, x4
   438c8:	mov	x24, x2
   438cc:	mov	x20, x0
   438d0:	mov	x9, x25
   438d4:	csel	x22, x8, x3, gt
   438d8:	sub	x0, x19, x25, lsl #3
   438dc:	sub	x8, x19, #0x8
   438e0:	stur	x5, [x29, #-24]
   438e4:	str	x1, [sp, #56]
   438e8:	stur	x25, [x29, #-48]
   438ec:	subs	x10, x9, #0x1
   438f0:	b.lt	43914 <__gmpn_sbpi1_div_q@@Base+0x90>  // b.tstop
   438f4:	add	x9, x22, x9, lsl #3
   438f8:	ldr	x11, [x8], #-8
   438fc:	ldur	x12, [x9, #-8]
   43900:	mov	x9, x10
   43904:	cmp	x11, x12
   43908:	b.eq	438ec <__gmpn_sbpi1_div_q@@Base+0x68>  // b.none
   4390c:	cmp	x11, x12
   43910:	b.ls	43934 <__gmpn_sbpi1_div_q@@Base+0xb0>  // b.plast
   43914:	ldur	x3, [x29, #-48]
   43918:	mov	x1, x0
   4391c:	mov	x2, x22
   43920:	bl	c2e0 <__gmpn_sub_n@plt>
   43924:	mov	w9, #0x1                   	// #1
   43928:	mov	w8, #0x1                   	// #1
   4392c:	str	w8, [sp, #28]
   43930:	b	4393c <__gmpn_sbpi1_div_q@@Base+0xb8>
   43934:	mov	x9, xzr
   43938:	str	wzr, [sp, #28]
   4393c:	sub	x8, x25, #0x2
   43940:	sub	x10, x25, #0x1
   43944:	ldr	x15, [x22, x10, lsl #3]
   43948:	stp	x8, x22, [x29, #-40]
   4394c:	ldr	x22, [x22, x8, lsl #3]
   43950:	ldur	x23, [x19, #-8]
   43954:	subs	x8, x27, x25
   43958:	stur	x9, [x29, #-56]
   4395c:	stp	x22, x15, [x29, #-16]
   43960:	str	x21, [sp, #72]
   43964:	stur	x25, [x29, #-64]
   43968:	b.mi	43aec <__gmpn_sbpi1_div_q@@Base+0x268>  // b.first
   4396c:	mov	x9, x25
   43970:	sub	x25, x20, x21, lsl #3
   43974:	ldr	x21, [sp, #56]
   43978:	str	x27, [sp, #64]
   4397c:	add	x27, x8, #0x1
   43980:	mvn	x8, x9
   43984:	str	x24, [sp, #48]
   43988:	lsl	x24, x24, #3
   4398c:	add	x19, x21, x8, lsl #3
   43990:	str	x10, [sp, #8]
   43994:	cmp	x23, x15
   43998:	add	x28, x21, x24
   4399c:	b.eq	43a54 <__gmpn_sbpi1_div_q@@Base+0x1d0>  // b.none
   439a0:	ldur	x10, [x29, #-24]
   439a4:	ldp	x11, x8, [x28, #-24]
   439a8:	mul	x9, x23, x10
   439ac:	umulh	x10, x23, x10
   439b0:	adds	x12, x9, x8
   439b4:	adc	x9, x10, x23
   439b8:	msub	x8, x9, x15, x8
   439bc:	subs	x14, x11, x22
   439c0:	sbc	x8, x8, x15
   439c4:	mul	x10, x9, x22
   439c8:	umulh	x13, x22, x9
   439cc:	subs	x11, x14, x10
   439d0:	sbc	x8, x8, x13
   439d4:	cmp	x8, x12
   439d8:	cset	w10, cs  // cs = hs, nlast
   439dc:	csetm	x12, cs  // cs = hs, nlast
   439e0:	sub	x9, x9, x10
   439e4:	and	x10, x22, x12
   439e8:	and	x12, x15, x12
   439ec:	adds	x26, x11, x10
   439f0:	adc	x23, x8, x12
   439f4:	cmp	x23, x15
   439f8:	add	x20, x9, #0x1
   439fc:	b.cs	43a84 <__gmpn_sbpi1_div_q@@Base+0x200>  // b.hs, b.nlast
   43a00:	ldp	x2, x1, [x29, #-40]
   43a04:	add	x22, x19, x24
   43a08:	mov	x0, x22
   43a0c:	mov	x3, x20
   43a10:	bl	ca00 <__gmpn_submul_1@plt>
   43a14:	subs	x8, x26, x0
   43a18:	cset	w9, cc  // cc = lo, ul, last
   43a1c:	subs	x23, x23, x9
   43a20:	stur	x8, [x28, #-24]
   43a24:	b.cc	43aa8 <__gmpn_sbpi1_div_q@@Base+0x224>  // b.lo, b.ul, b.last
   43a28:	ldur	x15, [x29, #-8]
   43a2c:	ldur	x22, [x29, #-16]
   43a30:	sub	x27, x27, #0x1
   43a34:	add	x8, x25, x24
   43a38:	sub	x25, x25, #0x8
   43a3c:	sub	x21, x21, #0x8
   43a40:	cmp	x27, #0x0
   43a44:	sub	x19, x19, #0x8
   43a48:	stur	x20, [x8, #-8]
   43a4c:	b.gt	43994 <__gmpn_sbpi1_div_q@@Base+0x110>
   43a50:	b	43ad0 <__gmpn_sbpi1_div_q@@Base+0x24c>
   43a54:	ldur	x8, [x28, #-16]
   43a58:	cmp	x8, x22
   43a5c:	b.ne	439a0 <__gmpn_sbpi1_div_q@@Base+0x11c>  // b.any
   43a60:	ldur	x1, [x29, #-32]
   43a64:	ldur	x2, [x29, #-48]
   43a68:	add	x0, x19, x24
   43a6c:	mov	x3, #0xffffffffffffffff    	// #-1
   43a70:	mov	x20, #0xffffffffffffffff    	// #-1
   43a74:	bl	ca00 <__gmpn_submul_1@plt>
   43a78:	ldur	x15, [x29, #-8]
   43a7c:	ldur	x23, [x28, #-16]
   43a80:	b	43a30 <__gmpn_sbpi1_div_q@@Base+0x1ac>
   43a84:	cmp	x26, x22
   43a88:	b.cs	43a94 <__gmpn_sbpi1_div_q@@Base+0x210>  // b.hs, b.nlast
   43a8c:	cmp	x23, x15
   43a90:	b.ls	43a00 <__gmpn_sbpi1_div_q@@Base+0x17c>  // b.plast
   43a94:	subs	x8, x26, x22
   43a98:	sbc	x23, x23, x15
   43a9c:	add	x20, x20, #0x1
   43aa0:	mov	x26, x8
   43aa4:	b	43a00 <__gmpn_sbpi1_div_q@@Base+0x17c>
   43aa8:	ldur	x2, [x29, #-32]
   43aac:	ldr	x3, [sp, #8]
   43ab0:	mov	x0, x22
   43ab4:	mov	x1, x22
   43ab8:	bl	ca90 <__gmpn_add_n@plt>
   43abc:	ldur	x15, [x29, #-8]
   43ac0:	sub	x20, x20, #0x1
   43ac4:	add	x8, x23, x15
   43ac8:	add	x23, x8, x0
   43acc:	b	43a2c <__gmpn_sbpi1_div_q@@Base+0x1a8>
   43ad0:	ldr	x8, [sp, #48]
   43ad4:	ldr	x27, [sp, #64]
   43ad8:	add	x24, x25, x8, lsl #3
   43adc:	ldp	x25, x9, [x29, #-64]
   43ae0:	add	x8, x21, x8, lsl #3
   43ae4:	sub	x28, x8, #0x10
   43ae8:	b	43af4 <__gmpn_sbpi1_div_q@@Base+0x270>
   43aec:	add	x24, x20, x27, lsl #3
   43af0:	sub	x28, x19, #0x10
   43af4:	cmp	x25, #0x2
   43af8:	b.lt	43b9c <__gmpn_sbpi1_div_q@@Base+0x318>  // b.tstop
   43afc:	cmp	x23, x15
   43b00:	cset	w8, cs  // cs = hs, nlast
   43b04:	cmp	x25, #0x2
   43b08:	b.ne	43ba8 <__gmpn_sbpi1_div_q@@Base+0x324>  // b.any
   43b0c:	ldur	x25, [x29, #-32]
   43b10:	ldr	x21, [sp, #72]
   43b14:	mov	x19, x28
   43b18:	sub	x28, x28, #0x8
   43b1c:	mov	x26, #0xffffffffffffffff    	// #-1
   43b20:	cbnz	w8, 43d80 <__gmpn_sbpi1_div_q@@Base+0x4fc>
   43b24:	ldur	x10, [x29, #-24]
   43b28:	ldr	x8, [x19]
   43b2c:	ldr	x11, [x28]
   43b30:	ldur	x25, [x29, #-64]
   43b34:	mul	x9, x23, x10
   43b38:	umulh	x10, x23, x10
   43b3c:	adds	x12, x9, x8
   43b40:	adc	x9, x10, x23
   43b44:	msub	x8, x9, x15, x8
   43b48:	mul	x10, x9, x22
   43b4c:	umulh	x13, x22, x9
   43b50:	subs	x14, x11, x22
   43b54:	sbc	x8, x8, x15
   43b58:	subs	x11, x14, x10
   43b5c:	sbc	x10, x8, x13
   43b60:	cmp	x10, x12
   43b64:	cset	w8, cs  // cs = hs, nlast
   43b68:	csetm	x12, cs  // cs = hs, nlast
   43b6c:	sub	x9, x9, x8
   43b70:	and	x13, x22, x12
   43b74:	and	x12, x15, x12
   43b78:	adds	x8, x11, x13
   43b7c:	adc	x23, x10, x12
   43b80:	cmp	x23, x15
   43b84:	add	x20, x9, #0x1
   43b88:	b.cs	43e9c <__gmpn_sbpi1_div_q@@Base+0x618>  // b.hs, b.nlast
   43b8c:	ldur	x9, [x29, #-56]
   43b90:	str	x8, [x28]
   43b94:	str	x23, [x19]
   43b98:	b	43da8 <__gmpn_sbpi1_div_q@@Base+0x524>
   43b9c:	ldr	x21, [sp, #72]
   43ba0:	mov	x26, #0xffffffffffffffff    	// #-1
   43ba4:	b	43dac <__gmpn_sbpi1_div_q@@Base+0x528>
   43ba8:	mov	w9, #0x1                   	// #1
   43bac:	str	x27, [sp, #64]
   43bb0:	sub	x9, x9, x25
   43bb4:	ldur	x25, [x29, #-32]
   43bb8:	ldur	x27, [x29, #-48]
   43bbc:	mov	x21, xzr
   43bc0:	add	x9, x28, x9, lsl #3
   43bc4:	mov	x26, #0xffffffffffffffff    	// #-1
   43bc8:	stur	x9, [x29, #-40]
   43bcc:	mov	x2, x27
   43bd0:	sub	x22, x27, #0x2
   43bd4:	add	x19, x28, x21
   43bd8:	tbz	w8, #0, 43c08 <__gmpn_sbpi1_div_q@@Base+0x384>
   43bdc:	ldur	x0, [x29, #-40]
   43be0:	mov	x3, #0xffffffffffffffff    	// #-1
   43be4:	mov	x1, x25
   43be8:	mov	x20, #0xffffffffffffffff    	// #-1
   43bec:	mov	x27, x2
   43bf0:	bl	ca00 <__gmpn_submul_1@plt>
   43bf4:	cmp	x23, x0
   43bf8:	b.ne	43cdc <__gmpn_sbpi1_div_q@@Base+0x458>  // b.any
   43bfc:	ldur	x15, [x29, #-8]
   43c00:	ldr	x23, [x19]
   43c04:	b	43cb0 <__gmpn_sbpi1_div_q@@Base+0x42c>
   43c08:	stur	x26, [x29, #-48]
   43c0c:	ldp	x10, x16, [x29, #-24]
   43c10:	ldp	x11, x8, [x19, #-8]
   43c14:	mov	x26, x28
   43c18:	mov	x28, x24
   43c1c:	mul	x9, x23, x10
   43c20:	umulh	x10, x23, x10
   43c24:	adds	x12, x9, x8
   43c28:	adc	x9, x10, x23
   43c2c:	msub	x8, x9, x15, x8
   43c30:	subs	x14, x11, x16
   43c34:	sbc	x8, x8, x15
   43c38:	mul	x10, x9, x16
   43c3c:	umulh	x13, x16, x9
   43c40:	subs	x11, x14, x10
   43c44:	sbc	x8, x8, x13
   43c48:	cmp	x8, x12
   43c4c:	cset	w10, cs  // cs = hs, nlast
   43c50:	csetm	x12, cs  // cs = hs, nlast
   43c54:	sub	x9, x9, x10
   43c58:	and	x10, x16, x12
   43c5c:	and	x12, x15, x12
   43c60:	adds	x24, x11, x10
   43c64:	adc	x23, x8, x12
   43c68:	mov	x27, x2
   43c6c:	cmp	x23, x15
   43c70:	add	x20, x9, #0x1
   43c74:	b.cs	43d04 <__gmpn_sbpi1_div_q@@Base+0x480>  // b.hs, b.nlast
   43c78:	ldur	x0, [x29, #-40]
   43c7c:	mov	x1, x25
   43c80:	mov	x2, x22
   43c84:	mov	x3, x20
   43c88:	bl	ca00 <__gmpn_submul_1@plt>
   43c8c:	subs	x8, x24, x0
   43c90:	cset	w9, cc  // cc = lo, ul, last
   43c94:	subs	x23, x23, x9
   43c98:	stur	x8, [x19, #-8]
   43c9c:	b.cc	43d30 <__gmpn_sbpi1_div_q@@Base+0x4ac>  // b.lo, b.ul, b.last
   43ca0:	ldur	x15, [x29, #-8]
   43ca4:	mov	x24, x28
   43ca8:	mov	x28, x26
   43cac:	ldur	x26, [x29, #-48]
   43cb0:	and	x9, x26, x15
   43cb4:	add	x8, x24, x21
   43cb8:	cmp	x23, x9
   43cbc:	add	x25, x25, #0x8
   43cc0:	sub	x21, x21, #0x8
   43cc4:	stur	x20, [x8, #-8]
   43cc8:	cset	w8, cs  // cs = hs, nlast
   43ccc:	cmp	x22, #0x1
   43cd0:	sub	x27, x27, #0x1
   43cd4:	b.gt	43bcc <__gmpn_sbpi1_div_q@@Base+0x348>
   43cd8:	b	43d68 <__gmpn_sbpi1_div_q@@Base+0x4e4>
   43cdc:	and	x8, x0, x26
   43ce0:	cmp	x23, x8
   43ce4:	b.cs	43d5c <__gmpn_sbpi1_div_q@@Base+0x4d8>  // b.hs, b.nlast
   43ce8:	ldur	x0, [x29, #-40]
   43cec:	mov	x2, x25
   43cf0:	mov	x3, x27
   43cf4:	mov	x1, x0
   43cf8:	bl	ca90 <__gmpn_add_n@plt>
   43cfc:	mov	x20, #0xfffffffffffffffe    	// #-2
   43d00:	b	43bfc <__gmpn_sbpi1_div_q@@Base+0x378>
   43d04:	ldur	x8, [x29, #-16]
   43d08:	cmp	x24, x8
   43d0c:	b.cs	43d18 <__gmpn_sbpi1_div_q@@Base+0x494>  // b.hs, b.nlast
   43d10:	cmp	x23, x15
   43d14:	b.ls	43c78 <__gmpn_sbpi1_div_q@@Base+0x3f4>  // b.plast
   43d18:	ldur	x9, [x29, #-16]
   43d1c:	subs	x8, x24, x9
   43d20:	sbc	x23, x23, x15
   43d24:	add	x20, x20, #0x1
   43d28:	mov	x24, x8
   43d2c:	b	43c78 <__gmpn_sbpi1_div_q@@Base+0x3f4>
   43d30:	ldur	x0, [x29, #-40]
   43d34:	sub	x3, x27, #0x1
   43d38:	mov	x2, x25
   43d3c:	mov	x1, x0
   43d40:	bl	ca90 <__gmpn_add_n@plt>
   43d44:	ldur	x15, [x29, #-8]
   43d48:	sub	x20, x20, #0x1
   43d4c:	mov	x24, x28
   43d50:	add	x8, x23, x15
   43d54:	add	x23, x8, x0
   43d58:	b	43ca8 <__gmpn_sbpi1_div_q@@Base+0x424>
   43d5c:	mov	x26, xzr
   43d60:	mov	x20, #0xffffffffffffffff    	// #-1
   43d64:	b	43bfc <__gmpn_sbpi1_div_q@@Base+0x378>
   43d68:	add	x19, x28, x21
   43d6c:	add	x24, x24, x21
   43d70:	ldp	x27, x21, [sp, #64]
   43d74:	ldur	x22, [x29, #-16]
   43d78:	sub	x28, x19, #0x8
   43d7c:	cbz	w8, 43b24 <__gmpn_sbpi1_div_q@@Base+0x2a0>
   43d80:	mov	w2, #0x2                   	// #2
   43d84:	mov	x3, #0xffffffffffffffff    	// #-1
   43d88:	mov	x0, x28
   43d8c:	mov	x1, x25
   43d90:	mov	x20, #0xffffffffffffffff    	// #-1
   43d94:	bl	ca00 <__gmpn_submul_1@plt>
   43d98:	cmp	x23, x0
   43d9c:	b.ne	43ec0 <__gmpn_sbpi1_div_q@@Base+0x63c>  // b.any
   43da0:	ldp	x25, x9, [x29, #-64]
   43da4:	ldr	x23, [x19]
   43da8:	str	x20, [x24, #-8]!
   43dac:	ldr	x8, [x28, #8]
   43db0:	cmp	x8, x23
   43db4:	b.ne	4406c <__gmpn_sbpi1_div_q@@Base+0x7e8>  // b.any
   43db8:	and	x8, x26, x21
   43dbc:	cmp	x23, x8
   43dc0:	b.cc	43de8 <__gmpn_sbpi1_div_q@@Base+0x564>  // b.lo, b.ul, b.last
   43dc4:	ldp	x20, x19, [sp, #224]
   43dc8:	ldp	x22, x21, [sp, #208]
   43dcc:	ldp	x24, x23, [sp, #192]
   43dd0:	ldp	x26, x25, [sp, #176]
   43dd4:	ldp	x28, x27, [sp, #160]
   43dd8:	ldp	x29, x30, [sp, #144]
   43ddc:	mov	x0, x9
   43de0:	add	sp, sp, #0xf0
   43de4:	ret
   43de8:	mov	x26, x28
   43dec:	cmp	x21, #0x3
   43df0:	mov	x28, x24
   43df4:	b.lt	43e5c <__gmpn_sbpi1_div_q@@Base+0x5d8>  // b.tstop
   43df8:	mov	x24, x21
   43dfc:	ldr	x21, [x26]
   43e00:	subs	x22, x25, #0x3
   43e04:	b.lt	43e54 <__gmpn_sbpi1_div_q@@Base+0x5d0>  // b.tstop
   43e08:	sub	x19, x26, #0x8
   43e0c:	mov	w20, #0x1                   	// #1
   43e10:	mov	x8, x26
   43e14:	ldr	x3, [x28, x22, lsl #3]
   43e18:	ldur	x1, [x29, #-32]
   43e1c:	mov	x0, x19
   43e20:	mov	x2, x20
   43e24:	mov	x25, x9
   43e28:	bl	ca00 <__gmpn_submul_1@plt>
   43e2c:	subs	x21, x21, x0
   43e30:	b.cs	43e3c <__gmpn_sbpi1_div_q@@Base+0x5b8>  // b.hs, b.nlast
   43e34:	cbz	x23, 43f9c <__gmpn_sbpi1_div_q@@Base+0x718>
   43e38:	sub	x23, x23, #0x1
   43e3c:	mov	x9, x25
   43e40:	cmp	x22, #0x0
   43e44:	sub	x22, x22, #0x1
   43e48:	add	x20, x20, #0x1
   43e4c:	sub	x19, x19, #0x8
   43e50:	b.gt	43e14 <__gmpn_sbpi1_div_q@@Base+0x590>
   43e54:	str	x21, [x26]
   43e58:	mov	x21, x24
   43e5c:	ldr	x8, [sp, #32]
   43e60:	cmp	x8, x21
   43e64:	b.ge	43dc4 <__gmpn_sbpi1_div_q@@Base+0x540>  // b.tcont
   43e68:	ldr	w8, [sp, #28]
   43e6c:	cbz	w8, 43ef0 <__gmpn_sbpi1_div_q@@Base+0x66c>
   43e70:	ldr	x8, [sp, #56]
   43e74:	ldr	x2, [sp, #40]
   43e78:	ldr	x3, [sp, #16]
   43e7c:	mov	x26, x9
   43e80:	add	x0, x8, x27, lsl #3
   43e84:	mov	x1, x0
   43e88:	bl	c2e0 <__gmpn_sub_n@plt>
   43e8c:	cbz	x0, 43ef4 <__gmpn_sbpi1_div_q@@Base+0x670>
   43e90:	cbz	x23, 43fdc <__gmpn_sbpi1_div_q@@Base+0x758>
   43e94:	sub	x23, x23, #0x1
   43e98:	b	43ef4 <__gmpn_sbpi1_div_q@@Base+0x670>
   43e9c:	cmp	x8, x22
   43ea0:	b.cs	43eac <__gmpn_sbpi1_div_q@@Base+0x628>  // b.hs, b.nlast
   43ea4:	cmp	x23, x15
   43ea8:	b.ls	43b8c <__gmpn_sbpi1_div_q@@Base+0x308>  // b.plast
   43eac:	subs	x9, x8, x22
   43eb0:	sbc	x23, x23, x15
   43eb4:	add	x20, x20, #0x1
   43eb8:	mov	x8, x9
   43ebc:	b	43b8c <__gmpn_sbpi1_div_q@@Base+0x308>
   43ec0:	and	x8, x0, x26
   43ec4:	cmp	x23, x8
   43ec8:	b.cs	43f90 <__gmpn_sbpi1_div_q@@Base+0x70c>  // b.hs, b.nlast
   43ecc:	ldr	x8, [x19]
   43ed0:	mov	x20, #0xfffffffffffffffe    	// #-2
   43ed4:	ldp	x9, x10, [x25]
   43ed8:	ldr	x11, [x28]
   43edc:	adds	x12, x11, x9
   43ee0:	adc	x8, x8, x10
   43ee4:	str	x8, [x19]
   43ee8:	str	x12, [x28]
   43eec:	b	43da0 <__gmpn_sbpi1_div_q@@Base+0x51c>
   43ef0:	mov	x26, x9
   43ef4:	cbz	x27, 44064 <__gmpn_sbpi1_div_q@@Base+0x7e0>
   43ef8:	sub	x19, x21, x27
   43efc:	subs	x20, x19, #0x2
   43f00:	b.lt	44064 <__gmpn_sbpi1_div_q@@Base+0x7e0>  // b.tstop
   43f04:	ldr	x8, [sp, #56]
   43f08:	mov	x9, x21
   43f0c:	mov	x24, x28
   43f10:	add	x21, x8, x27, lsl #3
   43f14:	add	x22, x8, x9, lsl #3
   43f18:	ldr	x8, [sp, #40]
   43f1c:	mov	x1, x24
   43f20:	mov	x2, x27
   43f24:	ldr	x3, [x8, x20, lsl #3]
   43f28:	ldr	x8, [sp, #56]
   43f2c:	add	x0, x8, x20, lsl #3
   43f30:	bl	ca00 <__gmpn_submul_1@plt>
   43f34:	ldr	x8, [x21, x20, lsl #3]
   43f38:	subs	x8, x8, x0
   43f3c:	str	x8, [x21, x20, lsl #3]
   43f40:	b.cs	43f7c <__gmpn_sbpi1_div_q@@Base+0x6f8>  // b.hs, b.nlast
   43f44:	mvn	x8, x20
   43f48:	add	x8, x19, x8
   43f4c:	mov	x9, #0xffffffffffffffff    	// #-1
   43f50:	add	x10, x9, #0x2
   43f54:	cmp	x10, x8
   43f58:	b.ge	43f74 <__gmpn_sbpi1_div_q@@Base+0x6f0>  // b.tcont
   43f5c:	ldr	x10, [x22, x9, lsl #3]
   43f60:	sub	x11, x10, #0x1
   43f64:	str	x11, [x22, x9, lsl #3]
   43f68:	add	x9, x9, #0x1
   43f6c:	cbz	x10, 43f50 <__gmpn_sbpi1_div_q@@Base+0x6cc>
   43f70:	b	43f7c <__gmpn_sbpi1_div_q@@Base+0x6f8>
   43f74:	cbz	x23, 44030 <__gmpn_sbpi1_div_q@@Base+0x7ac>
   43f78:	sub	x23, x23, #0x1
   43f7c:	cmp	x20, #0x0
   43f80:	sub	x20, x20, #0x1
   43f84:	sub	x22, x22, #0x8
   43f88:	b.gt	43f18 <__gmpn_sbpi1_div_q@@Base+0x694>
   43f8c:	b	44064 <__gmpn_sbpi1_div_q@@Base+0x7e0>
   43f90:	mov	x26, xzr
   43f94:	mov	x20, #0xffffffffffffffff    	// #-1
   43f98:	b	43da0 <__gmpn_sbpi1_div_q@@Base+0x51c>
   43f9c:	ldr	x8, [x28]
   43fa0:	mov	x26, x25
   43fa4:	mov	x10, x28
   43fa8:	sub	x9, x8, #0x1
   43fac:	str	x9, [x28]
   43fb0:	cbnz	x8, 44064 <__gmpn_sbpi1_div_q@@Base+0x7e0>
   43fb4:	mov	w8, #0x1                   	// #1
   43fb8:	mov	x11, x27
   43fbc:	cmp	x8, x11
   43fc0:	b.ge	44084 <__gmpn_sbpi1_div_q@@Base+0x800>  // b.tcont
   43fc4:	ldr	x9, [x28, x8, lsl #3]
   43fc8:	sub	x10, x9, #0x1
   43fcc:	str	x10, [x28, x8, lsl #3]
   43fd0:	add	x8, x8, #0x1
   43fd4:	cbz	x9, 43fbc <__gmpn_sbpi1_div_q@@Base+0x738>
   43fd8:	b	44064 <__gmpn_sbpi1_div_q@@Base+0x7e0>
   43fdc:	cbz	x27, 44024 <__gmpn_sbpi1_div_q@@Base+0x7a0>
   43fe0:	ldr	x8, [x28]
   43fe4:	mov	x10, x28
   43fe8:	sub	x9, x8, #0x1
   43fec:	str	x9, [x28]
   43ff0:	cbnz	x8, 44020 <__gmpn_sbpi1_div_q@@Base+0x79c>
   43ff4:	mov	x11, x27
   43ff8:	mov	w0, #0x1                   	// #1
   43ffc:	mov	w8, #0x1                   	// #1
   44000:	cmp	x8, x11
   44004:	b.ge	44024 <__gmpn_sbpi1_div_q@@Base+0x7a0>  // b.tcont
   44008:	ldr	x9, [x28, x8, lsl #3]
   4400c:	mov	x12, x28
   44010:	sub	x10, x9, #0x1
   44014:	str	x10, [x28, x8, lsl #3]
   44018:	add	x8, x8, #0x1
   4401c:	cbz	x9, 44000 <__gmpn_sbpi1_div_q@@Base+0x77c>
   44020:	mov	x0, xzr
   44024:	mov	x9, x26
   44028:	sub	x9, x26, x0
   4402c:	b	43dc4 <__gmpn_sbpi1_div_q@@Base+0x540>
   44030:	ldr	x8, [x24]
   44034:	sub	x9, x8, #0x1
   44038:	str	x9, [x24]
   4403c:	cbnz	x8, 44064 <__gmpn_sbpi1_div_q@@Base+0x7e0>
   44040:	mov	w8, #0x1                   	// #1
   44044:	cmp	x8, x27
   44048:	b.ge	44064 <__gmpn_sbpi1_div_q@@Base+0x7e0>  // b.tcont
   4404c:	ldr	x9, [x28, x8, lsl #3]
   44050:	mov	x11, x28
   44054:	sub	x10, x9, #0x1
   44058:	str	x10, [x28, x8, lsl #3]
   4405c:	add	x8, x8, #0x1
   44060:	cbz	x9, 44044 <__gmpn_sbpi1_div_q@@Base+0x7c0>
   44064:	mov	x9, x26
   44068:	b	43dc4 <__gmpn_sbpi1_div_q@@Base+0x540>
   4406c:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   44070:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   44074:	add	x0, x0, #0x857
   44078:	add	x2, x2, #0x865
   4407c:	mov	w1, #0xc5                  	// #197
   44080:	bl	c6e0 <__gmp_assert_fail@plt>
   44084:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   44088:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   4408c:	add	x0, x0, #0x857
   44090:	add	x2, x2, #0x871
   44094:	mov	w1, #0xf8                  	// #248
   44098:	bl	c6e0 <__gmp_assert_fail@plt>

000000000004409c <__gmpn_sbpi1_div_qr@@Base>:
   4409c:	sub	sp, sp, #0xb0
   440a0:	stp	x20, x19, [sp, #160]
   440a4:	add	x20, x1, x2, lsl #3
   440a8:	stp	x29, x30, [sp, #80]
   440ac:	stp	x28, x27, [sp, #96]
   440b0:	stp	x24, x23, [sp, #128]
   440b4:	stp	x22, x21, [sp, #144]
   440b8:	add	x29, sp, #0x50
   440bc:	mov	x21, x4
   440c0:	mov	x22, x2
   440c4:	mov	x23, x1
   440c8:	mov	x27, x0
   440cc:	sub	x0, x20, x4, lsl #3
   440d0:	sub	x8, x20, #0x8
   440d4:	mov	x9, x4
   440d8:	mov	x12, x3
   440dc:	stp	x26, x25, [sp, #112]
   440e0:	stp	x5, x3, [x29, #-16]
   440e4:	subs	x10, x9, #0x1
   440e8:	b.lt	44108 <__gmpn_sbpi1_div_qr@@Base+0x6c>  // b.tstop
   440ec:	add	x9, x12, x9, lsl #3
   440f0:	ldr	x11, [x8], #-8
   440f4:	ldur	x9, [x9, #-8]
   440f8:	cmp	x11, x9
   440fc:	mov	x9, x10
   44100:	b.eq	440e4 <__gmpn_sbpi1_div_qr@@Base+0x48>  // b.none
   44104:	b.ls	44120 <__gmpn_sbpi1_div_qr@@Base+0x84>  // b.plast
   44108:	ldur	x2, [x29, #-8]
   4410c:	mov	x1, x0
   44110:	mov	x3, x21
   44114:	bl	c2e0 <__gmpn_sub_n@plt>
   44118:	mov	w0, #0x1                   	// #1
   4411c:	b	44124 <__gmpn_sbpi1_div_qr@@Base+0x88>
   44120:	mov	x0, xzr
   44124:	ldur	x19, [x20, #-8]
   44128:	sub	x8, x22, x21
   4412c:	cmp	x8, #0x1
   44130:	b.lt	442d4 <__gmpn_sbpi1_div_qr@@Base+0x238>  // b.tstop
   44134:	ldur	x9, [x29, #-8]
   44138:	stp	x0, x22, [sp, #24]
   4413c:	sub	x10, x21, #0x2
   44140:	sub	x11, x21, #0x1
   44144:	ldr	x16, [x9, x11, lsl #3]
   44148:	ldr	x9, [x9, x10, lsl #3]
   4414c:	lsl	x28, x22, #3
   44150:	add	x22, x8, #0x1
   44154:	str	x11, [sp, #16]
   44158:	stur	x9, [x29, #-24]
   4415c:	mvn	x9, x21
   44160:	add	x20, x27, x9, lsl #3
   44164:	add	x25, x23, x9, lsl #3
   44168:	str	x10, [sp, #40]
   4416c:	str	x21, [sp, #8]
   44170:	stur	x16, [x29, #-32]
   44174:	cmp	x19, x16
   44178:	add	x26, x23, x28
   4417c:	b.eq	44238 <__gmpn_sbpi1_div_qr@@Base+0x19c>  // b.none
   44180:	ldp	x15, x10, [x29, #-24]
   44184:	ldp	x11, x8, [x26, #-24]
   44188:	mul	x9, x19, x10
   4418c:	umulh	x10, x19, x10
   44190:	adds	x12, x9, x8
   44194:	adc	x9, x10, x19
   44198:	msub	x8, x9, x16, x8
   4419c:	subs	x14, x11, x15
   441a0:	sbc	x8, x8, x16
   441a4:	mul	x10, x9, x15
   441a8:	umulh	x13, x15, x9
   441ac:	subs	x11, x14, x10
   441b0:	sbc	x8, x8, x13
   441b4:	cmp	x8, x12
   441b8:	cset	w10, cs  // cs = hs, nlast
   441bc:	csetm	x12, cs  // cs = hs, nlast
   441c0:	sub	x9, x9, x10
   441c4:	and	x10, x15, x12
   441c8:	and	x12, x16, x12
   441cc:	adds	x21, x11, x10
   441d0:	adc	x19, x8, x12
   441d4:	cmp	x19, x16
   441d8:	add	x27, x9, #0x1
   441dc:	b.cs	4426c <__gmpn_sbpi1_div_qr@@Base+0x1d0>  // b.hs, b.nlast
   441e0:	ldur	x1, [x29, #-8]
   441e4:	ldr	x2, [sp, #40]
   441e8:	mov	x24, x28
   441ec:	add	x28, x25, x28
   441f0:	mov	x0, x28
   441f4:	mov	x3, x27
   441f8:	bl	ca00 <__gmpn_submul_1@plt>
   441fc:	subs	x8, x21, x0
   44200:	cset	w9, cc  // cc = lo, ul, last
   44204:	subs	x19, x19, x9
   44208:	stur	x8, [x26, #-24]
   4420c:	b.cc	44298 <__gmpn_sbpi1_div_qr@@Base+0x1fc>  // b.lo, b.ul, b.last
   44210:	ldur	x16, [x29, #-32]
   44214:	mov	x28, x24
   44218:	sub	x22, x22, #0x1
   4421c:	str	x27, [x20, x28]
   44220:	sub	x20, x20, #0x8
   44224:	sub	x23, x23, #0x8
   44228:	cmp	x22, #0x1
   4422c:	sub	x25, x25, #0x8
   44230:	b.gt	44174 <__gmpn_sbpi1_div_qr@@Base+0xd8>
   44234:	b	442c4 <__gmpn_sbpi1_div_qr@@Base+0x228>
   44238:	ldur	x8, [x26, #-16]
   4423c:	ldur	x9, [x29, #-24]
   44240:	cmp	x8, x9
   44244:	b.ne	44180 <__gmpn_sbpi1_div_qr@@Base+0xe4>  // b.any
   44248:	ldur	x1, [x29, #-8]
   4424c:	ldr	x2, [sp, #8]
   44250:	add	x0, x25, x28
   44254:	mov	x3, #0xffffffffffffffff    	// #-1
   44258:	mov	x27, #0xffffffffffffffff    	// #-1
   4425c:	bl	ca00 <__gmpn_submul_1@plt>
   44260:	ldur	x16, [x29, #-32]
   44264:	ldur	x19, [x26, #-16]
   44268:	b	44218 <__gmpn_sbpi1_div_qr@@Base+0x17c>
   4426c:	ldur	x8, [x29, #-24]
   44270:	cmp	x21, x8
   44274:	b.cs	44280 <__gmpn_sbpi1_div_qr@@Base+0x1e4>  // b.hs, b.nlast
   44278:	cmp	x19, x16
   4427c:	b.ls	441e0 <__gmpn_sbpi1_div_qr@@Base+0x144>  // b.plast
   44280:	ldur	x9, [x29, #-24]
   44284:	subs	x8, x21, x9
   44288:	sbc	x19, x19, x16
   4428c:	add	x27, x27, #0x1
   44290:	mov	x21, x8
   44294:	b	441e0 <__gmpn_sbpi1_div_qr@@Base+0x144>
   44298:	ldur	x2, [x29, #-8]
   4429c:	ldr	x3, [sp, #16]
   442a0:	mov	x0, x28
   442a4:	mov	x1, x28
   442a8:	bl	ca90 <__gmpn_add_n@plt>
   442ac:	ldur	x16, [x29, #-32]
   442b0:	sub	x27, x27, #0x1
   442b4:	mov	x28, x24
   442b8:	add	x8, x19, x16
   442bc:	add	x19, x8, x0
   442c0:	b	44218 <__gmpn_sbpi1_div_qr@@Base+0x17c>
   442c4:	ldp	x0, x8, [sp, #24]
   442c8:	add	x8, x23, x8, lsl #3
   442cc:	sub	x8, x8, #0x10
   442d0:	b	442d8 <__gmpn_sbpi1_div_qr@@Base+0x23c>
   442d4:	sub	x8, x20, #0x10
   442d8:	str	x19, [x8, #8]
   442dc:	ldp	x20, x19, [sp, #160]
   442e0:	ldp	x22, x21, [sp, #144]
   442e4:	ldp	x24, x23, [sp, #128]
   442e8:	ldp	x26, x25, [sp, #112]
   442ec:	ldp	x28, x27, [sp, #96]
   442f0:	ldp	x29, x30, [sp, #80]
   442f4:	add	sp, sp, #0xb0
   442f8:	ret

00000000000442fc <__gmpn_sbpi1_divappr_q@@Base>:
   442fc:	sub	sp, sp, #0xb0
   44300:	stp	x22, x21, [sp, #144]
   44304:	sub	x21, x2, x4
   44308:	add	x8, x21, #0x1
   4430c:	subs	x8, x4, x8
   44310:	stp	x20, x19, [sp, #160]
   44314:	add	x20, x1, x2, lsl #3
   44318:	add	x8, x3, x8, lsl #3
   4431c:	csinc	x9, x4, x21, le
   44320:	stp	x29, x30, [sp, #80]
   44324:	stp	x28, x27, [sp, #96]
   44328:	stp	x26, x25, [sp, #112]
   4432c:	stp	x24, x23, [sp, #128]
   44330:	add	x29, sp, #0x50
   44334:	mov	x27, x4
   44338:	mov	x25, x2
   4433c:	mov	x24, x1
   44340:	mov	x28, x0
   44344:	csel	x22, x8, x3, gt
   44348:	sub	x0, x20, x9, lsl #3
   4434c:	sub	x8, x20, #0x8
   44350:	stur	x5, [x29, #-24]
   44354:	str	x9, [sp, #24]
   44358:	subs	x10, x9, #0x1
   4435c:	b.lt	4437c <__gmpn_sbpi1_divappr_q@@Base+0x80>  // b.tstop
   44360:	add	x9, x22, x9, lsl #3
   44364:	ldr	x11, [x8], #-8
   44368:	ldur	x9, [x9, #-8]
   4436c:	cmp	x11, x9
   44370:	mov	x9, x10
   44374:	b.eq	44358 <__gmpn_sbpi1_divappr_q@@Base+0x5c>  // b.none
   44378:	b.ls	44398 <__gmpn_sbpi1_divappr_q@@Base+0x9c>  // b.plast
   4437c:	ldr	x26, [sp, #24]
   44380:	mov	x1, x0
   44384:	mov	x2, x22
   44388:	mov	x3, x26
   4438c:	bl	c2e0 <__gmpn_sub_n@plt>
   44390:	mov	w19, #0x1                   	// #1
   44394:	b	443a0 <__gmpn_sbpi1_divappr_q@@Base+0xa4>
   44398:	ldr	x26, [sp, #24]
   4439c:	mov	x19, xzr
   443a0:	sub	x8, x26, #0x2
   443a4:	sub	x9, x26, #0x1
   443a8:	ldr	x15, [x22, x9, lsl #3]
   443ac:	str	x8, [sp, #40]
   443b0:	ldr	x8, [x22, x8, lsl #3]
   443b4:	stur	x22, [x29, #-32]
   443b8:	stp	x8, x15, [x29, #-16]
   443bc:	ldur	x23, [x20, #-8]
   443c0:	subs	x8, x21, x26
   443c4:	b.mi	44544 <__gmpn_sbpi1_divappr_q@@Base+0x248>  // b.first
   443c8:	add	x22, x8, #0x1
   443cc:	mvn	x8, x26
   443d0:	sub	x21, x28, x27, lsl #3
   443d4:	str	x25, [sp, #32]
   443d8:	lsl	x25, x25, #3
   443dc:	add	x20, x24, x8, lsl #3
   443e0:	stp	x9, x19, [sp, #8]
   443e4:	cmp	x23, x15
   443e8:	add	x26, x24, x25
   443ec:	b.eq	444a4 <__gmpn_sbpi1_divappr_q@@Base+0x1a8>  // b.none
   443f0:	ldp	x10, x16, [x29, #-24]
   443f4:	ldp	x11, x8, [x26, #-24]
   443f8:	mul	x9, x23, x10
   443fc:	umulh	x10, x23, x10
   44400:	adds	x12, x9, x8
   44404:	adc	x9, x10, x23
   44408:	msub	x8, x9, x15, x8
   4440c:	subs	x14, x11, x16
   44410:	sbc	x8, x8, x15
   44414:	mul	x10, x9, x16
   44418:	umulh	x13, x16, x9
   4441c:	subs	x11, x14, x10
   44420:	sbc	x8, x8, x13
   44424:	cmp	x8, x12
   44428:	cset	w10, cs  // cs = hs, nlast
   4442c:	csetm	x12, cs  // cs = hs, nlast
   44430:	sub	x9, x9, x10
   44434:	and	x10, x16, x12
   44438:	and	x12, x15, x12
   4443c:	adds	x19, x11, x10
   44440:	adc	x23, x8, x12
   44444:	cmp	x23, x15
   44448:	add	x27, x9, #0x1
   4444c:	b.cs	444d8 <__gmpn_sbpi1_divappr_q@@Base+0x1dc>  // b.hs, b.nlast
   44450:	ldur	x1, [x29, #-32]
   44454:	ldr	x2, [sp, #40]
   44458:	add	x28, x20, x25
   4445c:	mov	x0, x28
   44460:	mov	x3, x27
   44464:	bl	ca00 <__gmpn_submul_1@plt>
   44468:	subs	x8, x19, x0
   4446c:	cset	w9, cc  // cc = lo, ul, last
   44470:	subs	x23, x23, x9
   44474:	stur	x8, [x26, #-24]
   44478:	b.cc	44504 <__gmpn_sbpi1_divappr_q@@Base+0x208>  // b.lo, b.ul, b.last
   4447c:	ldur	x15, [x29, #-8]
   44480:	sub	x22, x22, #0x1
   44484:	add	x8, x21, x25
   44488:	sub	x21, x21, #0x8
   4448c:	sub	x24, x24, #0x8
   44490:	cmp	x22, #0x0
   44494:	sub	x20, x20, #0x8
   44498:	stur	x27, [x8, #-8]
   4449c:	b.gt	443e4 <__gmpn_sbpi1_divappr_q@@Base+0xe8>
   444a0:	b	4452c <__gmpn_sbpi1_divappr_q@@Base+0x230>
   444a4:	ldur	x8, [x26, #-16]
   444a8:	ldur	x9, [x29, #-16]
   444ac:	cmp	x8, x9
   444b0:	b.ne	443f0 <__gmpn_sbpi1_divappr_q@@Base+0xf4>  // b.any
   444b4:	ldur	x1, [x29, #-32]
   444b8:	ldr	x2, [sp, #24]
   444bc:	add	x0, x20, x25
   444c0:	mov	x3, #0xffffffffffffffff    	// #-1
   444c4:	mov	x27, #0xffffffffffffffff    	// #-1
   444c8:	bl	ca00 <__gmpn_submul_1@plt>
   444cc:	ldur	x15, [x29, #-8]
   444d0:	ldur	x23, [x26, #-16]
   444d4:	b	44480 <__gmpn_sbpi1_divappr_q@@Base+0x184>
   444d8:	ldur	x8, [x29, #-16]
   444dc:	cmp	x19, x8
   444e0:	b.cs	444ec <__gmpn_sbpi1_divappr_q@@Base+0x1f0>  // b.hs, b.nlast
   444e4:	cmp	x23, x15
   444e8:	b.ls	44450 <__gmpn_sbpi1_divappr_q@@Base+0x154>  // b.plast
   444ec:	ldur	x9, [x29, #-16]
   444f0:	subs	x8, x19, x9
   444f4:	sbc	x23, x23, x15
   444f8:	add	x27, x27, #0x1
   444fc:	mov	x19, x8
   44500:	b	44450 <__gmpn_sbpi1_divappr_q@@Base+0x154>
   44504:	ldur	x2, [x29, #-32]
   44508:	ldr	x3, [sp, #8]
   4450c:	mov	x0, x28
   44510:	mov	x1, x28
   44514:	bl	ca90 <__gmpn_add_n@plt>
   44518:	ldur	x15, [x29, #-8]
   4451c:	sub	x27, x27, #0x1
   44520:	add	x8, x23, x15
   44524:	add	x23, x8, x0
   44528:	b	44480 <__gmpn_sbpi1_divappr_q@@Base+0x184>
   4452c:	ldr	x8, [sp, #32]
   44530:	ldr	x19, [sp, #16]
   44534:	add	x26, x21, x8, lsl #3
   44538:	add	x8, x24, x8, lsl #3
   4453c:	sub	x27, x8, #0x10
   44540:	b	4454c <__gmpn_sbpi1_divappr_q@@Base+0x250>
   44544:	add	x26, x28, x21, lsl #3
   44548:	sub	x27, x20, #0x10
   4454c:	ldr	x21, [sp, #24]
   44550:	cmp	x21, #0x2
   44554:	b.lt	445e4 <__gmpn_sbpi1_divappr_q@@Base+0x2e8>  // b.tstop
   44558:	cmp	x23, x15
   4455c:	cset	w8, cs  // cs = hs, nlast
   44560:	cmp	x21, #0x2
   44564:	b.ne	445ec <__gmpn_sbpi1_divappr_q@@Base+0x2f0>  // b.any
   44568:	sub	x22, x27, #0x8
   4456c:	mov	x21, #0xffffffffffffffff    	// #-1
   44570:	cbnz	w8, 447bc <__gmpn_sbpi1_divappr_q@@Base+0x4c0>
   44574:	ldp	x10, x16, [x29, #-24]
   44578:	ldr	x8, [x27]
   4457c:	ldr	x11, [x22]
   44580:	mul	x9, x23, x10
   44584:	umulh	x10, x23, x10
   44588:	adds	x12, x9, x8
   4458c:	adc	x9, x10, x23
   44590:	msub	x8, x9, x15, x8
   44594:	mul	x10, x9, x16
   44598:	umulh	x13, x16, x9
   4459c:	subs	x14, x11, x16
   445a0:	sbc	x8, x8, x15
   445a4:	subs	x11, x14, x10
   445a8:	sbc	x10, x8, x13
   445ac:	cmp	x10, x12
   445b0:	cset	w8, cs  // cs = hs, nlast
   445b4:	csetm	x12, cs  // cs = hs, nlast
   445b8:	sub	x9, x9, x8
   445bc:	and	x13, x16, x12
   445c0:	and	x12, x15, x12
   445c4:	adds	x8, x11, x13
   445c8:	adc	x23, x10, x12
   445cc:	cmp	x23, x15
   445d0:	add	x20, x9, #0x1
   445d4:	b.cs	44820 <__gmpn_sbpi1_divappr_q@@Base+0x524>  // b.hs, b.nlast
   445d8:	str	x23, [x27]
   445dc:	str	x8, [x22]
   445e0:	b	447ec <__gmpn_sbpi1_divappr_q@@Base+0x4f0>
   445e4:	mov	x22, x27
   445e8:	b	447f0 <__gmpn_sbpi1_divappr_q@@Base+0x4f4>
   445ec:	ldur	x22, [x29, #-32]
   445f0:	mov	w9, #0x1                   	// #1
   445f4:	sub	x9, x9, x21
   445f8:	str	x19, [sp, #16]
   445fc:	mov	x28, xzr
   44600:	add	x9, x27, x9, lsl #3
   44604:	mov	x19, #0xffffffffffffffff    	// #-1
   44608:	str	x9, [sp, #40]
   4460c:	str	x27, [sp, #32]
   44610:	sub	x24, x21, #0x2
   44614:	add	x20, x27, x28
   44618:	tbz	w8, #0, 44648 <__gmpn_sbpi1_divappr_q@@Base+0x34c>
   4461c:	ldr	x0, [sp, #40]
   44620:	mov	x3, #0xffffffffffffffff    	// #-1
   44624:	mov	x1, x22
   44628:	mov	x2, x21
   4462c:	mov	x25, #0xffffffffffffffff    	// #-1
   44630:	bl	ca00 <__gmpn_submul_1@plt>
   44634:	cmp	x23, x0
   44638:	b.ne	4471c <__gmpn_sbpi1_divappr_q@@Base+0x420>  // b.any
   4463c:	ldur	x15, [x29, #-8]
   44640:	ldr	x23, [x20]
   44644:	b	446f0 <__gmpn_sbpi1_divappr_q@@Base+0x3f4>
   44648:	stur	x19, [x29, #-32]
   4464c:	ldp	x10, x16, [x29, #-24]
   44650:	ldp	x11, x8, [x20, #-8]
   44654:	mov	x27, x26
   44658:	mov	x26, x21
   4465c:	mul	x9, x23, x10
   44660:	umulh	x10, x23, x10
   44664:	adds	x12, x9, x8
   44668:	adc	x9, x10, x23
   4466c:	msub	x8, x9, x15, x8
   44670:	subs	x14, x11, x16
   44674:	sbc	x8, x8, x15
   44678:	mul	x10, x9, x16
   4467c:	umulh	x13, x16, x9
   44680:	subs	x11, x14, x10
   44684:	sbc	x8, x8, x13
   44688:	cmp	x8, x12
   4468c:	cset	w10, cs  // cs = hs, nlast
   44690:	csetm	x12, cs  // cs = hs, nlast
   44694:	sub	x9, x9, x10
   44698:	and	x10, x16, x12
   4469c:	and	x12, x15, x12
   446a0:	adds	x19, x11, x10
   446a4:	adc	x21, x8, x12
   446a8:	cmp	x21, x15
   446ac:	add	x25, x9, #0x1
   446b0:	b.cs	44770 <__gmpn_sbpi1_divappr_q@@Base+0x474>  // b.hs, b.nlast
   446b4:	ldr	x0, [sp, #40]
   446b8:	mov	x1, x22
   446bc:	mov	x2, x24
   446c0:	mov	x3, x25
   446c4:	bl	ca00 <__gmpn_submul_1@plt>
   446c8:	subs	x8, x19, x0
   446cc:	cset	w9, cc  // cc = lo, ul, last
   446d0:	subs	x23, x21, x9
   446d4:	stur	x8, [x20, #-8]
   446d8:	b.cc	44744 <__gmpn_sbpi1_divappr_q@@Base+0x448>  // b.lo, b.ul, b.last
   446dc:	ldur	x15, [x29, #-8]
   446e0:	mov	x21, x26
   446e4:	mov	x26, x27
   446e8:	ldr	x27, [sp, #32]
   446ec:	ldur	x19, [x29, #-32]
   446f0:	and	x9, x19, x15
   446f4:	add	x8, x26, x28
   446f8:	cmp	x23, x9
   446fc:	add	x22, x22, #0x8
   44700:	sub	x28, x28, #0x8
   44704:	stur	x25, [x8, #-8]
   44708:	cset	w8, cs  // cs = hs, nlast
   4470c:	cmp	x24, #0x1
   44710:	sub	x21, x21, #0x1
   44714:	b.gt	44610 <__gmpn_sbpi1_divappr_q@@Base+0x314>
   44718:	b	447a0 <__gmpn_sbpi1_divappr_q@@Base+0x4a4>
   4471c:	and	x8, x0, x19
   44720:	cmp	x23, x8
   44724:	b.cs	44794 <__gmpn_sbpi1_divappr_q@@Base+0x498>  // b.hs, b.nlast
   44728:	ldr	x0, [sp, #40]
   4472c:	mov	x2, x22
   44730:	mov	x3, x21
   44734:	mov	x1, x0
   44738:	bl	ca90 <__gmpn_add_n@plt>
   4473c:	mov	x25, #0xfffffffffffffffe    	// #-2
   44740:	b	4463c <__gmpn_sbpi1_divappr_q@@Base+0x340>
   44744:	ldr	x0, [sp, #40]
   44748:	sub	x3, x26, #0x1
   4474c:	mov	x2, x22
   44750:	mov	x21, x26
   44754:	mov	x1, x0
   44758:	bl	ca90 <__gmpn_add_n@plt>
   4475c:	ldur	x15, [x29, #-8]
   44760:	sub	x25, x25, #0x1
   44764:	add	x8, x23, x15
   44768:	add	x23, x8, x0
   4476c:	b	446e4 <__gmpn_sbpi1_divappr_q@@Base+0x3e8>
   44770:	cmp	x19, x16
   44774:	b.cs	44780 <__gmpn_sbpi1_divappr_q@@Base+0x484>  // b.hs, b.nlast
   44778:	cmp	x21, x15
   4477c:	b.ls	446b4 <__gmpn_sbpi1_divappr_q@@Base+0x3b8>  // b.plast
   44780:	subs	x8, x19, x16
   44784:	sbc	x21, x21, x15
   44788:	add	x25, x25, #0x1
   4478c:	mov	x19, x8
   44790:	b	446b4 <__gmpn_sbpi1_divappr_q@@Base+0x3b8>
   44794:	mov	x19, xzr
   44798:	mov	x25, #0xffffffffffffffff    	// #-1
   4479c:	b	4463c <__gmpn_sbpi1_divappr_q@@Base+0x340>
   447a0:	mov	x21, x19
   447a4:	ldr	x19, [sp, #16]
   447a8:	add	x27, x27, x28
   447ac:	stur	x22, [x29, #-32]
   447b0:	sub	x22, x27, #0x8
   447b4:	add	x26, x26, x28
   447b8:	cbz	w8, 44574 <__gmpn_sbpi1_divappr_q@@Base+0x278>
   447bc:	ldur	x1, [x29, #-32]
   447c0:	mov	w2, #0x2                   	// #2
   447c4:	mov	x3, #0xffffffffffffffff    	// #-1
   447c8:	mov	x0, x22
   447cc:	mov	x20, #0xffffffffffffffff    	// #-1
   447d0:	bl	ca00 <__gmpn_submul_1@plt>
   447d4:	cmp	x23, x0
   447d8:	b.eq	447e8 <__gmpn_sbpi1_divappr_q@@Base+0x4ec>  // b.none
   447dc:	and	x8, x0, x21
   447e0:	cmp	x23, x8
   447e4:	b.cc	44848 <__gmpn_sbpi1_divappr_q@@Base+0x54c>  // b.lo, b.ul, b.last
   447e8:	ldr	x23, [x27]
   447ec:	stur	x20, [x26, #-8]
   447f0:	ldr	x8, [x22, #8]
   447f4:	cmp	x8, x23
   447f8:	b.ne	44870 <__gmpn_sbpi1_divappr_q@@Base+0x574>  // b.any
   447fc:	mov	x0, x19
   44800:	ldp	x20, x19, [sp, #160]
   44804:	ldp	x22, x21, [sp, #144]
   44808:	ldp	x24, x23, [sp, #128]
   4480c:	ldp	x26, x25, [sp, #112]
   44810:	ldp	x28, x27, [sp, #96]
   44814:	ldp	x29, x30, [sp, #80]
   44818:	add	sp, sp, #0xb0
   4481c:	ret
   44820:	cmp	x8, x16
   44824:	b.cs	44830 <__gmpn_sbpi1_divappr_q@@Base+0x534>  // b.hs, b.nlast
   44828:	cmp	x23, x15
   4482c:	b.ls	445d8 <__gmpn_sbpi1_divappr_q@@Base+0x2dc>  // b.plast
   44830:	ldur	x10, [x29, #-16]
   44834:	subs	x9, x8, x10
   44838:	sbc	x23, x23, x15
   4483c:	add	x20, x20, #0x1
   44840:	mov	x8, x9
   44844:	b	445d8 <__gmpn_sbpi1_divappr_q@@Base+0x2dc>
   44848:	ldur	x10, [x29, #-32]
   4484c:	ldr	x8, [x27]
   44850:	mov	x20, #0xfffffffffffffffe    	// #-2
   44854:	ldr	x11, [x22]
   44858:	ldp	x9, x10, [x10]
   4485c:	adds	x12, x11, x9
   44860:	adc	x8, x8, x10
   44864:	str	x8, [x27]
   44868:	str	x12, [x22]
   4486c:	b	447e8 <__gmpn_sbpi1_divappr_q@@Base+0x4ec>
   44870:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   44874:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   44878:	add	x0, x0, #0x879
   4487c:	add	x2, x2, #0x865
   44880:	mov	w1, #0xc3                  	// #195
   44884:	bl	c6e0 <__gmp_assert_fail@plt>

0000000000044888 <__gmpn_dcpi1_div_q@@Base>:
   44888:	stp	x29, x30, [sp, #-96]!
   4488c:	stp	x28, x27, [sp, #16]
   44890:	stp	x26, x25, [sp, #32]
   44894:	stp	x24, x23, [sp, #48]
   44898:	stp	x22, x21, [sp, #64]
   4489c:	stp	x20, x19, [sp, #80]
   448a0:	mov	x29, sp
   448a4:	sub	sp, sp, #0x10
   448a8:	add	x28, x2, #0x1
   448ac:	mov	x25, x1
   448b0:	lsl	x1, x28, #3
   448b4:	mov	w8, #0x7f00                	// #32512
   448b8:	mov	x20, x5
   448bc:	mov	x21, x4
   448c0:	mov	x26, x3
   448c4:	mov	x22, x2
   448c8:	mov	x19, x0
   448cc:	cmp	x1, x8
   448d0:	stur	xzr, [x29, #-8]
   448d4:	b.hi	44ac8 <__gmpn_dcpi1_div_q@@Base+0x240>  // b.pmore
   448d8:	add	x9, x1, #0xf
   448dc:	mov	x8, sp
   448e0:	and	x9, x9, #0xfffffffffffffff0
   448e4:	sub	x27, x8, x9
   448e8:	mov	sp, x27
   448ec:	add	x0, x27, #0x8
   448f0:	mov	x1, x25
   448f4:	mov	x2, x22
   448f8:	bl	ca70 <__gmpn_copyi@plt>
   448fc:	sub	x23, x22, x21
   44900:	lsl	x8, x23, #3
   44904:	add	x1, x8, #0x8
   44908:	mov	w8, #0x7f00                	// #32512
   4490c:	cmp	x1, x8
   44910:	str	xzr, [x27]
   44914:	b.hi	44ad8 <__gmpn_dcpi1_div_q@@Base+0x250>  // b.pmore
   44918:	add	x9, x1, #0xf
   4491c:	mov	x8, sp
   44920:	and	x9, x9, #0xfffffffffffffff0
   44924:	sub	x24, x8, x9
   44928:	mov	sp, x24
   4492c:	mov	x0, x24
   44930:	mov	x1, x27
   44934:	mov	x2, x28
   44938:	mov	x3, x26
   4493c:	mov	x4, x21
   44940:	mov	x5, x20
   44944:	bl	c4f0 <__gmpn_dcpi1_divappr_q@plt>
   44948:	ldr	x8, [x24]
   4494c:	mov	x20, x0
   44950:	cbz	x8, 44960 <__gmpn_dcpi1_div_q@@Base+0xd8>
   44954:	add	x1, x24, #0x8
   44958:	mov	x0, x19
   4495c:	b	44a24 <__gmpn_dcpi1_div_q@@Base+0x19c>
   44960:	cmp	x23, x21
   44964:	add	x28, x24, #0x8
   44968:	mov	x0, x27
   4496c:	b.le	44984 <__gmpn_dcpi1_div_q@@Base+0xfc>
   44970:	mov	x1, x28
   44974:	mov	x2, x23
   44978:	mov	x3, x26
   4497c:	mov	x4, x21
   44980:	b	44994 <__gmpn_dcpi1_div_q@@Base+0x10c>
   44984:	mov	x1, x26
   44988:	mov	x2, x21
   4498c:	mov	x3, x28
   44990:	mov	x4, x23
   44994:	bl	ccf0 <__gmpn_mul@plt>
   44998:	cbz	x20, 449b4 <__gmpn_dcpi1_div_q@@Base+0x12c>
   4499c:	add	x0, x27, x23, lsl #3
   449a0:	mov	x1, x0
   449a4:	mov	x2, x26
   449a8:	mov	x3, x21
   449ac:	bl	ca90 <__gmpn_add_n@plt>
   449b0:	cbnz	x0, 449e0 <__gmpn_dcpi1_div_q@@Base+0x158>
   449b4:	sub	x8, x25, #0x8
   449b8:	sub	x9, x27, #0x8
   449bc:	mov	x10, x22
   449c0:	subs	x11, x10, #0x1
   449c4:	b.lt	44a1c <__gmpn_dcpi1_div_q@@Base+0x194>  // b.tstop
   449c8:	ldr	x12, [x9, x10, lsl #3]
   449cc:	ldr	x10, [x8, x10, lsl #3]
   449d0:	cmp	x12, x10
   449d4:	mov	x10, x11
   449d8:	b.eq	449c0 <__gmpn_dcpi1_div_q@@Base+0x138>  // b.none
   449dc:	b.ls	44a1c <__gmpn_dcpi1_div_q@@Base+0x194>  // b.plast
   449e0:	ldr	x8, [x28]
   449e4:	sub	x9, x8, #0x1
   449e8:	str	x9, [x19]
   449ec:	cbz	x8, 44a30 <__gmpn_dcpi1_div_q@@Base+0x1a8>
   449f0:	cmp	x23, #0x2
   449f4:	mov	x8, xzr
   449f8:	b.lt	44a98 <__gmpn_dcpi1_div_q@@Base+0x210>  // b.tstop
   449fc:	cmp	x28, x19
   44a00:	b.eq	44a98 <__gmpn_dcpi1_div_q@@Base+0x210>  // b.none
   44a04:	mvn	x8, x21
   44a08:	add	x8, x8, x22
   44a0c:	add	x0, x19, #0x8
   44a10:	add	x1, x24, #0x10
   44a14:	lsl	x2, x8, #3
   44a18:	b	44a90 <__gmpn_dcpi1_div_q@@Base+0x208>
   44a1c:	mov	x0, x19
   44a20:	mov	x1, x28
   44a24:	mov	x2, x23
   44a28:	bl	ca70 <__gmpn_copyi@plt>
   44a2c:	b	44a9c <__gmpn_dcpi1_div_q@@Base+0x214>
   44a30:	mov	x9, xzr
   44a34:	add	x11, x24, #0x10
   44a38:	mov	w8, #0x1                   	// #1
   44a3c:	mov	w10, #0x1                   	// #1
   44a40:	cmp	x10, x23
   44a44:	b.ge	44a98 <__gmpn_dcpi1_div_q@@Base+0x210>  // b.tcont
   44a48:	ldr	x12, [x11, x9]
   44a4c:	add	x13, x19, x9
   44a50:	add	x10, x10, #0x1
   44a54:	add	x9, x9, #0x8
   44a58:	sub	x14, x12, #0x1
   44a5c:	str	x14, [x13, #8]
   44a60:	cbz	x12, 44a40 <__gmpn_dcpi1_div_q@@Base+0x1b8>
   44a64:	cmp	x28, x19
   44a68:	mov	x8, xzr
   44a6c:	b.eq	44a98 <__gmpn_dcpi1_div_q@@Base+0x210>  // b.none
   44a70:	cmp	x10, x23
   44a74:	b.ge	44a98 <__gmpn_dcpi1_div_q@@Base+0x210>  // b.tcont
   44a78:	add	x8, x19, x9
   44a7c:	add	x9, x24, x9
   44a80:	sub	x10, x23, x10
   44a84:	add	x0, x8, #0x8
   44a88:	add	x1, x9, #0x10
   44a8c:	lsl	x2, x10, #3
   44a90:	bl	bee0 <memcpy@plt>
   44a94:	mov	x8, xzr
   44a98:	sub	x20, x20, x8
   44a9c:	ldur	x0, [x29, #-8]
   44aa0:	cbnz	x0, 44ae8 <__gmpn_dcpi1_div_q@@Base+0x260>
   44aa4:	mov	x0, x20
   44aa8:	mov	sp, x29
   44aac:	ldp	x20, x19, [sp, #80]
   44ab0:	ldp	x22, x21, [sp, #64]
   44ab4:	ldp	x24, x23, [sp, #48]
   44ab8:	ldp	x26, x25, [sp, #32]
   44abc:	ldp	x28, x27, [sp, #16]
   44ac0:	ldp	x29, x30, [sp], #96
   44ac4:	ret
   44ac8:	sub	x0, x29, #0x8
   44acc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   44ad0:	mov	x27, x0
   44ad4:	b	448ec <__gmpn_dcpi1_div_q@@Base+0x64>
   44ad8:	sub	x0, x29, #0x8
   44adc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   44ae0:	mov	x24, x0
   44ae4:	b	4492c <__gmpn_dcpi1_div_q@@Base+0xa4>
   44ae8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   44aec:	b	44aa4 <__gmpn_dcpi1_div_q@@Base+0x21c>

0000000000044af0 <__gmpn_dcpi1_div_qr_n@@Base>:
   44af0:	sub	sp, sp, #0x80
   44af4:	stp	x26, x25, [sp, #64]
   44af8:	stp	x24, x23, [sp, #80]
   44afc:	asr	x23, x3, #1
   44b00:	sub	x25, x3, x3, asr #1
   44b04:	and	x8, x3, #0xfffffffffffffffe
   44b08:	stp	x28, x27, [sp, #48]
   44b0c:	stp	x22, x21, [sp, #96]
   44b10:	stp	x20, x19, [sp, #112]
   44b14:	mov	x26, x5
   44b18:	mov	x19, x3
   44b1c:	mov	x20, x2
   44b20:	mov	x21, x1
   44b24:	mov	x22, x0
   44b28:	add	x27, x0, x23, lsl #3
   44b2c:	cmp	x25, #0x29
   44b30:	add	x1, x1, x8, lsl #3
   44b34:	stp	x29, x30, [sp, #32]
   44b38:	add	x29, sp, #0x20
   44b3c:	stp	x8, x4, [sp, #8]
   44b40:	b.le	44b5c <__gmpn_dcpi1_div_qr_n@@Base+0x6c>
   44b44:	add	x2, x20, x23, lsl #3
   44b48:	mov	x0, x27
   44b4c:	mov	x3, x25
   44b50:	mov	x5, x26
   44b54:	bl	d400 <__gmpn_dcpi1_div_qr_n@plt>
   44b58:	b	44b74 <__gmpn_dcpi1_div_qr_n@@Base+0x84>
   44b5c:	ldr	x5, [x4]
   44b60:	lsl	x2, x25, #1
   44b64:	add	x3, x20, x23, lsl #3
   44b68:	mov	x0, x27
   44b6c:	mov	x4, x25
   44b70:	bl	c660 <__gmpn_sbpi1_div_qr@plt>
   44b74:	mov	x24, x0
   44b78:	mov	x0, x26
   44b7c:	mov	x1, x27
   44b80:	mov	x2, x25
   44b84:	mov	x3, x20
   44b88:	mov	x4, x23
   44b8c:	bl	ccf0 <__gmpn_mul@plt>
   44b90:	add	x28, x21, x23, lsl #3
   44b94:	mov	x0, x28
   44b98:	mov	x1, x28
   44b9c:	mov	x2, x26
   44ba0:	mov	x3, x19
   44ba4:	stur	x26, [x29, #-8]
   44ba8:	bl	c2e0 <__gmpn_sub_n@plt>
   44bac:	mov	x26, x0
   44bb0:	cbz	x24, 44bcc <__gmpn_dcpi1_div_qr_n@@Base+0xdc>
   44bb4:	add	x0, x21, x19, lsl #3
   44bb8:	mov	x1, x0
   44bbc:	mov	x2, x20
   44bc0:	mov	x3, x23
   44bc4:	bl	c2e0 <__gmpn_sub_n@plt>
   44bc8:	add	x26, x0, x26
   44bcc:	cbz	x26, 44c30 <__gmpn_dcpi1_div_qr_n@@Base+0x140>
   44bd0:	ldr	x8, [x27]
   44bd4:	sub	x9, x8, #0x1
   44bd8:	str	x9, [x27]
   44bdc:	cbnz	x8, 44c00 <__gmpn_dcpi1_div_qr_n@@Base+0x110>
   44be0:	mov	w8, #0x1                   	// #1
   44be4:	cmp	x8, x25
   44be8:	b.ge	44c28 <__gmpn_dcpi1_div_qr_n@@Base+0x138>  // b.tcont
   44bec:	ldr	x9, [x27, x8, lsl #3]
   44bf0:	sub	x10, x9, #0x1
   44bf4:	str	x10, [x27, x8, lsl #3]
   44bf8:	add	x8, x8, #0x1
   44bfc:	cbz	x9, 44be4 <__gmpn_dcpi1_div_qr_n@@Base+0xf4>
   44c00:	mov	x8, xzr
   44c04:	mov	x0, x28
   44c08:	mov	x1, x28
   44c0c:	mov	x2, x20
   44c10:	mov	x3, x19
   44c14:	sub	x24, x24, x8
   44c18:	bl	ca90 <__gmpn_add_n@plt>
   44c1c:	subs	x26, x26, x0
   44c20:	b.ne	44bd0 <__gmpn_dcpi1_div_qr_n@@Base+0xe0>  // b.any
   44c24:	b	44c30 <__gmpn_dcpi1_div_qr_n@@Base+0x140>
   44c28:	mov	w8, #0x1                   	// #1
   44c2c:	b	44c04 <__gmpn_dcpi1_div_qr_n@@Base+0x114>
   44c30:	add	x1, x21, x25, lsl #3
   44c34:	cmp	x19, #0x53
   44c38:	add	x3, x20, x25, lsl #3
   44c3c:	b.le	44c60 <__gmpn_dcpi1_div_qr_n@@Base+0x170>
   44c40:	ldur	x26, [x29, #-8]
   44c44:	ldr	x4, [sp, #16]
   44c48:	mov	x0, x22
   44c4c:	mov	x2, x3
   44c50:	mov	x3, x23
   44c54:	mov	x5, x26
   44c58:	bl	d400 <__gmpn_dcpi1_div_qr_n@plt>
   44c5c:	b	44c78 <__gmpn_dcpi1_div_qr_n@@Base+0x188>
   44c60:	ldp	x2, x8, [sp, #8]
   44c64:	mov	x0, x22
   44c68:	mov	x4, x23
   44c6c:	ldr	x5, [x8]
   44c70:	bl	c660 <__gmpn_sbpi1_div_qr@plt>
   44c74:	ldur	x26, [x29, #-8]
   44c78:	mov	x27, x0
   44c7c:	mov	x0, x26
   44c80:	mov	x1, x20
   44c84:	mov	x2, x25
   44c88:	mov	x3, x22
   44c8c:	mov	x4, x23
   44c90:	bl	ccf0 <__gmpn_mul@plt>
   44c94:	mov	x0, x21
   44c98:	mov	x1, x21
   44c9c:	mov	x2, x26
   44ca0:	mov	x3, x19
   44ca4:	bl	c2e0 <__gmpn_sub_n@plt>
   44ca8:	mov	x26, x0
   44cac:	cbz	x27, 44cc8 <__gmpn_dcpi1_div_qr_n@@Base+0x1d8>
   44cb0:	mov	x0, x28
   44cb4:	mov	x1, x28
   44cb8:	mov	x2, x20
   44cbc:	mov	x3, x25
   44cc0:	bl	c2e0 <__gmpn_sub_n@plt>
   44cc4:	add	x26, x0, x26
   44cc8:	cbz	x26, 44d18 <__gmpn_dcpi1_div_qr_n@@Base+0x228>
   44ccc:	ldr	x8, [x22]
   44cd0:	sub	x9, x8, #0x1
   44cd4:	str	x9, [x22]
   44cd8:	cbnz	x8, 44cfc <__gmpn_dcpi1_div_qr_n@@Base+0x20c>
   44cdc:	mov	w8, #0x1                   	// #1
   44ce0:	cmp	x8, x23
   44ce4:	b.ge	44cfc <__gmpn_dcpi1_div_qr_n@@Base+0x20c>  // b.tcont
   44ce8:	ldr	x9, [x22, x8, lsl #3]
   44cec:	sub	x10, x9, #0x1
   44cf0:	str	x10, [x22, x8, lsl #3]
   44cf4:	add	x8, x8, #0x1
   44cf8:	cbz	x9, 44ce0 <__gmpn_dcpi1_div_qr_n@@Base+0x1f0>
   44cfc:	mov	x0, x21
   44d00:	mov	x1, x21
   44d04:	mov	x2, x20
   44d08:	mov	x3, x19
   44d0c:	bl	ca90 <__gmpn_add_n@plt>
   44d10:	subs	x26, x26, x0
   44d14:	b.ne	44ccc <__gmpn_dcpi1_div_qr_n@@Base+0x1dc>  // b.any
   44d18:	mov	x0, x24
   44d1c:	ldp	x20, x19, [sp, #112]
   44d20:	ldp	x22, x21, [sp, #96]
   44d24:	ldp	x24, x23, [sp, #80]
   44d28:	ldp	x26, x25, [sp, #64]
   44d2c:	ldp	x28, x27, [sp, #48]
   44d30:	ldp	x29, x30, [sp, #32]
   44d34:	add	sp, sp, #0x80
   44d38:	ret

0000000000044d3c <__gmpn_dcpi1_div_qr@@Base>:
   44d3c:	stp	x29, x30, [sp, #-96]!
   44d40:	stp	x28, x27, [sp, #16]
   44d44:	stp	x26, x25, [sp, #32]
   44d48:	stp	x24, x23, [sp, #48]
   44d4c:	stp	x22, x21, [sp, #64]
   44d50:	stp	x20, x19, [sp, #80]
   44d54:	mov	x29, sp
   44d58:	sub	sp, sp, #0x50
   44d5c:	lsl	x25, x4, #3
   44d60:	mov	w8, #0x7f00                	// #32512
   44d64:	mov	x19, x4
   44d68:	mov	x20, x3
   44d6c:	mov	x26, x2
   44d70:	mov	x23, x1
   44d74:	mov	x21, x0
   44d78:	cmp	x25, x8
   44d7c:	stur	xzr, [x29, #-8]
   44d80:	stur	x5, [x29, #-24]
   44d84:	b.hi	4524c <__gmpn_dcpi1_div_qr@@Base+0x510>  // b.pmore
   44d88:	add	x9, x25, #0xf
   44d8c:	mov	x8, sp
   44d90:	and	x9, x9, #0xfffffffffffffff0
   44d94:	sub	x27, x8, x9
   44d98:	mov	sp, x27
   44d9c:	sub	x22, x26, x19
   44da0:	add	x9, x23, x26, lsl #3
   44da4:	cmp	x22, x19
   44da8:	add	x28, x20, x19, lsl #3
   44dac:	b.le	44e5c <__gmpn_dcpi1_div_qr@@Base+0x120>
   44db0:	add	x8, x21, x19, lsl #3
   44db4:	stp	x23, x27, [x29, #-40]
   44db8:	add	x10, x21, x22, lsl #3
   44dbc:	add	x11, x8, #0x8
   44dc0:	mov	x8, x25
   44dc4:	mov	x27, x22
   44dc8:	sub	x27, x27, x19
   44dcc:	mov	x24, x8
   44dd0:	mov	x23, x11
   44dd4:	add	x8, x8, x25
   44dd8:	cmp	x27, x19
   44ddc:	add	x11, x11, x25
   44de0:	b.gt	44dc8 <__gmpn_dcpi1_div_qr@@Base+0x8c>
   44de4:	sub	x10, x10, x27, lsl #3
   44de8:	cmp	x27, #0x2
   44dec:	sub	x26, x9, x27, lsl #3
   44df0:	stur	x10, [x29, #-16]
   44df4:	b.eq	44ed8 <__gmpn_dcpi1_div_qr@@Base+0x19c>  // b.none
   44df8:	cmp	x27, #0x1
   44dfc:	b.ne	44ef8 <__gmpn_dcpi1_div_qr@@Base+0x1bc>  // b.any
   44e00:	neg	x9, x19
   44e04:	stur	x9, [x29, #-48]
   44e08:	ldur	x9, [x29, #-40]
   44e0c:	sub	x13, x26, x19, lsl #3
   44e10:	add	x0, x13, #0x8
   44e14:	mov	x10, x19
   44e18:	stur	x13, [x29, #-56]
   44e1c:	subs	x11, x10, #0x1
   44e20:	b.lt	44e44 <__gmpn_dcpi1_div_qr@@Base+0x108>  // b.tstop
   44e24:	add	x10, x20, x10, lsl #3
   44e28:	ldr	x12, [x9, x8]
   44e2c:	ldur	x10, [x10, #-8]
   44e30:	sub	x9, x9, #0x8
   44e34:	cmp	x12, x10
   44e38:	mov	x10, x11
   44e3c:	b.eq	44e1c <__gmpn_dcpi1_div_qr@@Base+0xe0>  // b.none
   44e40:	b.ls	45104 <__gmpn_dcpi1_div_qr@@Base+0x3c8>  // b.plast
   44e44:	mov	x1, x0
   44e48:	mov	x2, x20
   44e4c:	mov	x3, x19
   44e50:	bl	c2e0 <__gmpn_sub_n@plt>
   44e54:	mov	w25, #0x1                   	// #1
   44e58:	b	45108 <__gmpn_dcpi1_div_qr@@Base+0x3cc>
   44e5c:	sub	x23, x9, x22, lsl #3
   44e60:	neg	x8, x22
   44e64:	cmp	x22, #0x29
   44e68:	sub	x1, x23, x22, lsl #3
   44e6c:	b.le	44e8c <__gmpn_dcpi1_div_qr@@Base+0x150>
   44e70:	ldur	x4, [x29, #-24]
   44e74:	add	x2, x28, x8, lsl #3
   44e78:	mov	x0, x21
   44e7c:	mov	x3, x22
   44e80:	mov	x5, x27
   44e84:	bl	d400 <__gmpn_dcpi1_div_qr_n@plt>
   44e88:	b	44ea8 <__gmpn_dcpi1_div_qr@@Base+0x16c>
   44e8c:	ldur	x9, [x29, #-24]
   44e90:	lsl	x2, x22, #1
   44e94:	add	x3, x28, x8, lsl #3
   44e98:	mov	x0, x21
   44e9c:	ldr	x5, [x9]
   44ea0:	mov	x4, x22
   44ea4:	bl	c660 <__gmpn_sbpi1_div_qr@plt>
   44ea8:	mov	x25, x0
   44eac:	cmp	x22, x19
   44eb0:	b.eq	45220 <__gmpn_dcpi1_div_qr@@Base+0x4e4>  // b.none
   44eb4:	sub	x26, x19, x22
   44eb8:	mov	x0, x27
   44ebc:	cmp	x22, x26
   44ec0:	b.le	44f24 <__gmpn_dcpi1_div_qr@@Base+0x1e8>
   44ec4:	mov	x1, x21
   44ec8:	mov	x2, x22
   44ecc:	mov	x3, x20
   44ed0:	mov	x4, x26
   44ed4:	b	44f34 <__gmpn_dcpi1_div_qr@@Base+0x1f8>
   44ed8:	ldur	x0, [x29, #-16]
   44edc:	sub	x2, x26, #0x10
   44ee0:	sub	x4, x28, #0x10
   44ee4:	mov	w3, #0x4                   	// #4
   44ee8:	mov	x1, xzr
   44eec:	bl	c210 <__gmpn_divrem_2@plt>
   44ef0:	ldur	x28, [x29, #-24]
   44ef4:	b	44ff0 <__gmpn_dcpi1_div_qr@@Base+0x2b4>
   44ef8:	neg	x8, x27
   44efc:	cmp	x27, #0x29
   44f00:	add	x1, x26, x8, lsl #3
   44f04:	b.le	44fd4 <__gmpn_dcpi1_div_qr@@Base+0x298>
   44f08:	add	x2, x28, x8, lsl #3
   44f0c:	ldp	x28, x0, [x29, #-24]
   44f10:	ldur	x5, [x29, #-32]
   44f14:	mov	x3, x27
   44f18:	mov	x4, x28
   44f1c:	bl	d400 <__gmpn_dcpi1_div_qr_n@plt>
   44f20:	b	44ff0 <__gmpn_dcpi1_div_qr@@Base+0x2b4>
   44f24:	mov	x1, x20
   44f28:	mov	x2, x26
   44f2c:	mov	x3, x21
   44f30:	mov	x4, x22
   44f34:	bl	ccf0 <__gmpn_mul@plt>
   44f38:	sub	x24, x23, x19, lsl #3
   44f3c:	mov	x0, x24
   44f40:	mov	x1, x24
   44f44:	mov	x2, x27
   44f48:	mov	x3, x19
   44f4c:	bl	c2e0 <__gmpn_sub_n@plt>
   44f50:	mov	x23, x0
   44f54:	cbz	x25, 44f70 <__gmpn_dcpi1_div_qr@@Base+0x234>
   44f58:	add	x0, x24, x22, lsl #3
   44f5c:	mov	x1, x0
   44f60:	mov	x2, x20
   44f64:	mov	x3, x26
   44f68:	bl	c2e0 <__gmpn_sub_n@plt>
   44f6c:	add	x23, x0, x23
   44f70:	cbz	x23, 45220 <__gmpn_dcpi1_div_qr@@Base+0x4e4>
   44f74:	ldr	x8, [x21]
   44f78:	sub	x9, x8, #0x1
   44f7c:	str	x9, [x21]
   44f80:	cbnz	x8, 44fa4 <__gmpn_dcpi1_div_qr@@Base+0x268>
   44f84:	mov	w8, #0x1                   	// #1
   44f88:	cmp	x8, x22
   44f8c:	b.ge	44fcc <__gmpn_dcpi1_div_qr@@Base+0x290>  // b.tcont
   44f90:	ldr	x9, [x21, x8, lsl #3]
   44f94:	sub	x10, x9, #0x1
   44f98:	str	x10, [x21, x8, lsl #3]
   44f9c:	add	x8, x8, #0x1
   44fa0:	cbz	x9, 44f88 <__gmpn_dcpi1_div_qr@@Base+0x24c>
   44fa4:	mov	x8, xzr
   44fa8:	mov	x0, x24
   44fac:	mov	x1, x24
   44fb0:	mov	x2, x20
   44fb4:	mov	x3, x19
   44fb8:	sub	x25, x25, x8
   44fbc:	bl	ca90 <__gmpn_add_n@plt>
   44fc0:	subs	x23, x23, x0
   44fc4:	b.ne	44f74 <__gmpn_dcpi1_div_qr@@Base+0x238>  // b.any
   44fc8:	b	45220 <__gmpn_dcpi1_div_qr@@Base+0x4e4>
   44fcc:	mov	w8, #0x1                   	// #1
   44fd0:	b	44fa8 <__gmpn_dcpi1_div_qr@@Base+0x26c>
   44fd4:	ldp	x9, x0, [x29, #-24]
   44fd8:	lsl	x2, x27, #1
   44fdc:	add	x3, x28, x8, lsl #3
   44fe0:	mov	x4, x27
   44fe4:	ldr	x5, [x9]
   44fe8:	mov	x28, x9
   44fec:	bl	c660 <__gmpn_sbpi1_div_qr@plt>
   44ff0:	mov	x25, x0
   44ff4:	cmp	x27, x19
   44ff8:	b.ne	45004 <__gmpn_dcpi1_div_qr@@Base+0x2c8>  // b.any
   44ffc:	neg	x10, x19
   45000:	b	451dc <__gmpn_dcpi1_div_qr@@Base+0x4a0>
   45004:	sub	x8, x19, x27
   45008:	cmp	x27, x8
   4500c:	stur	x8, [x29, #-56]
   45010:	b.le	45030 <__gmpn_dcpi1_div_qr@@Base+0x2f4>
   45014:	ldur	x28, [x29, #-32]
   45018:	ldur	x1, [x29, #-16]
   4501c:	mov	x2, x27
   45020:	mov	x3, x20
   45024:	mov	x0, x28
   45028:	mov	x4, x8
   4502c:	b	45048 <__gmpn_dcpi1_div_qr@@Base+0x30c>
   45030:	ldur	x28, [x29, #-32]
   45034:	ldur	x3, [x29, #-16]
   45038:	mov	x1, x20
   4503c:	mov	x2, x8
   45040:	mov	x0, x28
   45044:	mov	x4, x27
   45048:	bl	ccf0 <__gmpn_mul@plt>
   4504c:	sub	x26, x26, x19, lsl #3
   45050:	neg	x8, x19
   45054:	mov	x0, x26
   45058:	mov	x1, x26
   4505c:	mov	x2, x28
   45060:	mov	x3, x19
   45064:	stur	x8, [x29, #-48]
   45068:	bl	c2e0 <__gmpn_sub_n@plt>
   4506c:	mov	x28, x0
   45070:	cbz	x25, 4508c <__gmpn_dcpi1_div_qr@@Base+0x350>
   45074:	ldur	x3, [x29, #-56]
   45078:	add	x0, x26, x27, lsl #3
   4507c:	mov	x1, x0
   45080:	mov	x2, x20
   45084:	bl	c2e0 <__gmpn_sub_n@plt>
   45088:	add	x28, x0, x28
   4508c:	cbz	x28, 450f8 <__gmpn_dcpi1_div_qr@@Base+0x3bc>
   45090:	ldur	x10, [x29, #-16]
   45094:	ldr	x8, [x10]
   45098:	sub	x9, x8, #0x1
   4509c:	str	x9, [x10]
   450a0:	cbnz	x8, 450c8 <__gmpn_dcpi1_div_qr@@Base+0x38c>
   450a4:	mov	x8, x23
   450a8:	mov	w9, #0x1                   	// #1
   450ac:	cmp	x9, x27
   450b0:	b.ge	450f0 <__gmpn_dcpi1_div_qr@@Base+0x3b4>  // b.tcont
   450b4:	ldr	x10, [x8]
   450b8:	add	x9, x9, #0x1
   450bc:	sub	x11, x10, #0x1
   450c0:	str	x11, [x8], #8
   450c4:	cbz	x10, 450ac <__gmpn_dcpi1_div_qr@@Base+0x370>
   450c8:	mov	x8, xzr
   450cc:	mov	x0, x26
   450d0:	mov	x1, x26
   450d4:	mov	x2, x20
   450d8:	mov	x3, x19
   450dc:	sub	x25, x25, x8
   450e0:	bl	ca90 <__gmpn_add_n@plt>
   450e4:	subs	x28, x28, x0
   450e8:	b.ne	45090 <__gmpn_dcpi1_div_qr@@Base+0x354>  // b.any
   450ec:	b	450f8 <__gmpn_dcpi1_div_qr@@Base+0x3bc>
   450f0:	mov	w8, #0x1                   	// #1
   450f4:	b	450cc <__gmpn_dcpi1_div_qr@@Base+0x390>
   450f8:	ldur	x28, [x29, #-24]
   450fc:	ldur	x10, [x29, #-48]
   45100:	b	451dc <__gmpn_dcpi1_div_qr@@Base+0x4a0>
   45104:	mov	x25, xzr
   45108:	ldp	x10, x9, [x26, #-8]
   4510c:	ldp	x8, x23, [x28, #-16]
   45110:	cmp	x9, x23
   45114:	b.ne	45120 <__gmpn_dcpi1_div_qr@@Base+0x3e4>  // b.any
   45118:	cmp	x10, x8
   4511c:	b.eq	4528c <__gmpn_dcpi1_div_qr@@Base+0x550>  // b.none
   45120:	ldur	x11, [x29, #-24]
   45124:	ldur	x12, [x26, #-16]
   45128:	ldr	x11, [x11]
   4512c:	mul	x13, x11, x9
   45130:	umulh	x11, x9, x11
   45134:	adds	x14, x13, x10
   45138:	adc	x9, x11, x9
   4513c:	msub	x10, x9, x23, x10
   45140:	subs	x15, x12, x8
   45144:	sbc	x10, x10, x23
   45148:	mul	x11, x9, x8
   4514c:	umulh	x13, x8, x9
   45150:	subs	x12, x15, x11
   45154:	sbc	x10, x10, x13
   45158:	cmp	x10, x14
   4515c:	cset	w11, cs  // cs = hs, nlast
   45160:	csetm	x13, cs  // cs = hs, nlast
   45164:	sub	x9, x9, x11
   45168:	and	x11, x8, x13
   4516c:	and	x13, x23, x13
   45170:	adds	x14, x12, x11
   45174:	adc	x28, x10, x13
   45178:	cmp	x28, x23
   4517c:	add	x3, x9, #0x1
   45180:	b.cs	45268 <__gmpn_dcpi1_div_qr@@Base+0x52c>  // b.hs, b.nlast
   45184:	ldur	x10, [x29, #-48]
   45188:	cmp	x19, #0x3
   4518c:	b.lt	451cc <__gmpn_dcpi1_div_qr@@Base+0x490>  // b.tstop
   45190:	ldur	x0, [x29, #-56]
   45194:	sub	x2, x19, #0x2
   45198:	mov	x1, x20
   4519c:	stp	x28, x3, [x29, #-72]
   451a0:	mov	x28, x14
   451a4:	bl	ca00 <__gmpn_submul_1@plt>
   451a8:	subs	x8, x28, x0
   451ac:	ldur	x28, [x29, #-72]
   451b0:	cset	w9, cc  // cc = lo, ul, last
   451b4:	stur	x8, [x26, #-16]
   451b8:	subs	x28, x28, x9
   451bc:	b.cc	452ac <__gmpn_dcpi1_div_qr@@Base+0x570>  // b.lo, b.ul, b.last
   451c0:	ldur	x10, [x29, #-48]
   451c4:	ldur	x3, [x29, #-64]
   451c8:	b	451d0 <__gmpn_dcpi1_div_qr@@Base+0x494>
   451cc:	stur	x14, [x26, #-16]
   451d0:	stur	x28, [x26, #-8]
   451d4:	ldp	x28, x8, [x29, #-24]
   451d8:	str	x3, [x8]
   451dc:	sub	x22, x22, x27
   451e0:	ldp	x9, x27, [x29, #-40]
   451e4:	add	x8, x19, x10, lsl #1
   451e8:	lsl	x23, x10, #3
   451ec:	add	x21, x21, x10, lsl #3
   451f0:	add	x26, x9, x8, lsl #3
   451f4:	add	x0, x21, x24
   451f8:	add	x1, x26, x24
   451fc:	mov	x2, x20
   45200:	mov	x3, x19
   45204:	mov	x4, x28
   45208:	mov	x5, x27
   4520c:	bl	d400 <__gmpn_dcpi1_div_qr_n@plt>
   45210:	sub	x22, x22, x19
   45214:	cmp	x22, #0x0
   45218:	add	x24, x24, x23
   4521c:	b.gt	451f4 <__gmpn_dcpi1_div_qr@@Base+0x4b8>
   45220:	ldur	x0, [x29, #-8]
   45224:	cbnz	x0, 45260 <__gmpn_dcpi1_div_qr@@Base+0x524>
   45228:	mov	x0, x25
   4522c:	mov	sp, x29
   45230:	ldp	x20, x19, [sp, #80]
   45234:	ldp	x22, x21, [sp, #64]
   45238:	ldp	x24, x23, [sp, #48]
   4523c:	ldp	x26, x25, [sp, #32]
   45240:	ldp	x28, x27, [sp, #16]
   45244:	ldp	x29, x30, [sp], #96
   45248:	ret
   4524c:	sub	x0, x29, #0x8
   45250:	mov	x1, x25
   45254:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   45258:	mov	x27, x0
   4525c:	b	44d9c <__gmpn_dcpi1_div_qr@@Base+0x60>
   45260:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   45264:	b	45228 <__gmpn_dcpi1_div_qr@@Base+0x4ec>
   45268:	cmp	x14, x8
   4526c:	b.cs	45278 <__gmpn_dcpi1_div_qr@@Base+0x53c>  // b.hs, b.nlast
   45270:	cmp	x28, x23
   45274:	b.ls	45184 <__gmpn_dcpi1_div_qr@@Base+0x448>  // b.plast
   45278:	subs	x9, x14, x8
   4527c:	sbc	x28, x28, x23
   45280:	add	x3, x3, #0x1
   45284:	mov	x14, x9
   45288:	b	45184 <__gmpn_dcpi1_div_qr@@Base+0x448>
   4528c:	ldur	x0, [x29, #-56]
   45290:	mov	x3, #0xffffffffffffffff    	// #-1
   45294:	mov	x1, x20
   45298:	mov	x2, x19
   4529c:	bl	ca00 <__gmpn_submul_1@plt>
   452a0:	ldur	x10, [x29, #-48]
   452a4:	mov	x3, #0xffffffffffffffff    	// #-1
   452a8:	b	451d4 <__gmpn_dcpi1_div_qr@@Base+0x498>
   452ac:	ldur	x0, [x29, #-56]
   452b0:	sub	x3, x19, #0x1
   452b4:	mov	x2, x20
   452b8:	mov	x1, x0
   452bc:	bl	ca90 <__gmpn_add_n@plt>
   452c0:	ldur	x3, [x29, #-64]
   452c4:	ldur	x10, [x29, #-48]
   452c8:	add	x8, x28, x23
   452cc:	add	x28, x8, x0
   452d0:	cmp	x3, #0x0
   452d4:	cset	w8, eq  // eq = none
   452d8:	sub	x25, x25, x8
   452dc:	sub	x3, x3, #0x1
   452e0:	b	451d0 <__gmpn_dcpi1_div_qr@@Base+0x494>

00000000000452e4 <__gmpn_dcpi1_divappr_q@@Base>:
   452e4:	stp	x29, x30, [sp, #-96]!
   452e8:	stp	x28, x27, [sp, #16]
   452ec:	stp	x26, x25, [sp, #32]
   452f0:	stp	x24, x23, [sp, #48]
   452f4:	stp	x22, x21, [sp, #64]
   452f8:	stp	x20, x19, [sp, #80]
   452fc:	mov	x29, sp
   45300:	sub	sp, sp, #0x50
   45304:	sub	x23, x2, x4
   45308:	mov	x12, x5
   4530c:	mov	x28, x2
   45310:	mov	x22, x0
   45314:	cmp	x23, x4
   45318:	add	x16, x3, x4, lsl #3
   4531c:	stur	x3, [x29, #-8]
   45320:	b.ge	45384 <__gmpn_dcpi1_divappr_q@@Base+0xa0>  // b.tcont
   45324:	add	x4, x23, #0x1
   45328:	lsl	x10, x4, #3
   4532c:	add	x10, x10, #0xf
   45330:	add	x9, x1, x28, lsl #3
   45334:	mov	x11, sp
   45338:	and	x10, x10, #0xfffffffffffffff0
   4533c:	neg	x8, x23
   45340:	sub	x9, x9, x23, lsl #3
   45344:	sub	x20, x11, x10
   45348:	mov	sp, x20
   4534c:	cmp	x23, #0x97
   45350:	b.le	45468 <__gmpn_dcpi1_divappr_q@@Base+0x184>
   45354:	mov	x11, sp
   45358:	sub	x5, x11, x10
   4535c:	mov	sp, x5
   45360:	add	x8, x9, x8, lsl #3
   45364:	mvn	x9, x23
   45368:	sub	x1, x8, #0x10
   4536c:	add	x2, x16, x9, lsl #3
   45370:	mov	x0, x20
   45374:	mov	x3, x4
   45378:	mov	x4, x12
   4537c:	bl	4584c <__gmpn_dcpi1_divappr_q@@Base+0x568>
   45380:	b	45488 <__gmpn_dcpi1_divappr_q@@Base+0x1a4>
   45384:	lsl	x8, x28, #3
   45388:	add	x27, x1, x4, lsl #3
   4538c:	sub	x8, x8, x4, lsl #4
   45390:	mov	x20, x4
   45394:	mov	x21, xzr
   45398:	mov	x24, xzr
   4539c:	add	x10, x23, #0x1
   453a0:	sub	x14, x4, #0x1
   453a4:	lsl	x19, x4, #3
   453a8:	lsl	x11, x4, #4
   453ac:	add	x9, x8, #0x10
   453b0:	mov	x8, x27
   453b4:	stur	x12, [x29, #-24]
   453b8:	sub	x21, x21, x20
   453bc:	add	x26, x10, x21
   453c0:	add	x24, x24, x19
   453c4:	add	x8, x8, x19
   453c8:	cmp	x26, x20
   453cc:	sub	x9, x9, x11
   453d0:	b.gt	453b8 <__gmpn_dcpi1_divappr_q@@Base+0xd4>
   453d4:	add	x11, x19, #0xf
   453d8:	add	x23, x22, x24
   453dc:	mov	x10, sp
   453e0:	and	x11, x11, #0xfffffffffffffff0
   453e4:	sub	x22, x23, #0x8
   453e8:	add	x13, x27, x24
   453ec:	sub	x10, x10, x11
   453f0:	stur	x10, [x29, #-16]
   453f4:	mov	sp, x10
   453f8:	cmp	x26, #0x2
   453fc:	stp	x13, x1, [x29, #-40]
   45400:	b.eq	454a0 <__gmpn_dcpi1_divappr_q@@Base+0x1bc>  // b.none
   45404:	cmp	x26, #0x1
   45408:	b.ne	454bc <__gmpn_dcpi1_divappr_q@@Base+0x1d8>  // b.any
   4540c:	ldur	x2, [x29, #-8]
   45410:	add	x0, x1, x24
   45414:	mov	x9, xzr
   45418:	sub	x15, x0, #0x8
   4541c:	add	x10, x2, x14, lsl #3
   45420:	stp	x14, x15, [x29, #-56]
   45424:	add	x11, x20, x9
   45428:	cmp	x11, #0x1
   4542c:	b.lt	4544c <__gmpn_dcpi1_divappr_q@@Base+0x168>  // b.tstop
   45430:	add	x11, x8, x9, lsl #3
   45434:	ldur	x11, [x11, #-8]
   45438:	ldr	x12, [x10, x9, lsl #3]
   4543c:	sub	x9, x9, #0x1
   45440:	cmp	x11, x12
   45444:	b.eq	45424 <__gmpn_dcpi1_divappr_q@@Base+0x140>  // b.none
   45448:	b.ls	45628 <__gmpn_dcpi1_divappr_q@@Base+0x344>  // b.plast
   4544c:	mov	x1, x0
   45450:	mov	x3, x20
   45454:	mov	x25, x16
   45458:	bl	c2e0 <__gmpn_sub_n@plt>
   4545c:	mov	x16, x25
   45460:	mov	w25, #0x1                   	// #1
   45464:	b	4562c <__gmpn_dcpi1_divappr_q@@Base+0x348>
   45468:	ldr	x5, [x12]
   4546c:	add	x8, x9, x8, lsl #3
   45470:	sub	x1, x8, #0x10
   45474:	mvn	x8, x23
   45478:	lsl	x2, x4, #1
   4547c:	add	x3, x16, x8, lsl #3
   45480:	mov	x0, x20
   45484:	bl	c710 <__gmpn_sbpi1_divappr_q@plt>
   45488:	mov	x25, x0
   4548c:	add	x1, x20, #0x8
   45490:	mov	x0, x22
   45494:	mov	x2, x23
   45498:	bl	ca70 <__gmpn_copyi@plt>
   4549c:	b	457b8 <__gmpn_dcpi1_divappr_q@@Base+0x4d4>
   454a0:	sub	x2, x13, #0x18
   454a4:	sub	x4, x16, #0x10
   454a8:	mov	w3, #0x4                   	// #4
   454ac:	mov	x0, x22
   454b0:	mov	x1, xzr
   454b4:	bl	c210 <__gmpn_divrem_2@plt>
   454b8:	b	45524 <__gmpn_dcpi1_divappr_q@@Base+0x240>
   454bc:	cmp	x26, #0x29
   454c0:	sub	x1, x1, x9
   454c4:	b.le	454f4 <__gmpn_dcpi1_divappr_q@@Base+0x210>
   454c8:	ldp	x5, x9, [x29, #-16]
   454cc:	lsl	x8, x20, #1
   454d0:	sub	x8, x8, x28
   454d4:	ldur	x4, [x29, #-24]
   454d8:	add	x8, x9, x8, lsl #3
   454dc:	add	x8, x8, x24
   454e0:	sub	x2, x8, #0x8
   454e4:	mov	x0, x22
   454e8:	mov	x3, x26
   454ec:	bl	d400 <__gmpn_dcpi1_div_qr_n@plt>
   454f0:	b	45524 <__gmpn_dcpi1_divappr_q@@Base+0x240>
   454f4:	ldur	x9, [x29, #-24]
   454f8:	lsl	x8, x20, #1
   454fc:	sub	x8, x8, x28
   45500:	lsl	x2, x26, #1
   45504:	ldr	x5, [x9]
   45508:	ldur	x9, [x29, #-8]
   4550c:	mov	x0, x22
   45510:	mov	x4, x26
   45514:	add	x8, x9, x8, lsl #3
   45518:	add	x8, x8, x24
   4551c:	sub	x3, x8, #0x8
   45520:	bl	c660 <__gmpn_sbpi1_div_qr@plt>
   45524:	mvn	x8, x28
   45528:	add	x8, x8, x20, lsl #1
   4552c:	mov	x25, x0
   45530:	cmp	x8, x21
   45534:	b.eq	456fc <__gmpn_dcpi1_divappr_q@@Base+0x418>  // b.none
   45538:	lsl	x8, x20, #1
   4553c:	sub	x8, x8, x28
   45540:	mvn	x9, x21
   45544:	add	x8, x9, x8
   45548:	cmp	x26, x8
   4554c:	stur	x8, [x29, #-48]
   45550:	b.le	45568 <__gmpn_dcpi1_divappr_q@@Base+0x284>
   45554:	ldp	x28, x3, [x29, #-16]
   45558:	mov	x1, x22
   4555c:	mov	x2, x26
   45560:	mov	x4, x8
   45564:	b	45578 <__gmpn_dcpi1_divappr_q@@Base+0x294>
   45568:	ldp	x28, x1, [x29, #-16]
   4556c:	mov	x2, x8
   45570:	mov	x3, x22
   45574:	mov	x4, x26
   45578:	mov	x0, x28
   4557c:	bl	ccf0 <__gmpn_mul@plt>
   45580:	ldur	x8, [x29, #-32]
   45584:	mov	x2, x28
   45588:	mov	x3, x20
   4558c:	add	x8, x8, x24
   45590:	sub	x27, x8, #0x8
   45594:	mov	x0, x27
   45598:	mov	x1, x27
   4559c:	bl	c2e0 <__gmpn_sub_n@plt>
   455a0:	mov	x28, x0
   455a4:	cbz	x25, 455c0 <__gmpn_dcpi1_divappr_q@@Base+0x2dc>
   455a8:	ldur	x2, [x29, #-8]
   455ac:	ldur	x3, [x29, #-48]
   455b0:	add	x0, x27, x26, lsl #3
   455b4:	mov	x1, x0
   455b8:	bl	c2e0 <__gmpn_sub_n@plt>
   455bc:	add	x28, x0, x28
   455c0:	cbz	x28, 456fc <__gmpn_dcpi1_divappr_q@@Base+0x418>
   455c4:	ldur	x8, [x23, #-8]
   455c8:	sub	x9, x8, #0x1
   455cc:	stur	x9, [x23, #-8]
   455d0:	cbnz	x8, 455f8 <__gmpn_dcpi1_divappr_q@@Base+0x314>
   455d4:	mov	x8, x23
   455d8:	mov	w9, #0x1                   	// #1
   455dc:	cmp	x9, x26
   455e0:	b.ge	45620 <__gmpn_dcpi1_divappr_q@@Base+0x33c>  // b.tcont
   455e4:	ldr	x10, [x8]
   455e8:	add	x9, x9, #0x1
   455ec:	sub	x11, x10, #0x1
   455f0:	str	x11, [x8], #8
   455f4:	cbz	x10, 455dc <__gmpn_dcpi1_divappr_q@@Base+0x2f8>
   455f8:	mov	x8, xzr
   455fc:	ldur	x2, [x29, #-8]
   45600:	mov	x0, x27
   45604:	mov	x1, x27
   45608:	mov	x3, x20
   4560c:	sub	x25, x25, x8
   45610:	bl	ca90 <__gmpn_add_n@plt>
   45614:	subs	x28, x28, x0
   45618:	b.ne	455c4 <__gmpn_dcpi1_divappr_q@@Base+0x2e0>  // b.any
   4561c:	b	456fc <__gmpn_dcpi1_divappr_q@@Base+0x418>
   45620:	mov	w8, #0x1                   	// #1
   45624:	b	455fc <__gmpn_dcpi1_divappr_q@@Base+0x318>
   45628:	mov	x25, xzr
   4562c:	ldur	x8, [x29, #-40]
   45630:	add	x17, x27, x24
   45634:	ldur	x10, [x17, #-16]
   45638:	ldur	x9, [x8, #-8]
   4563c:	ldp	x8, x28, [x16, #-16]
   45640:	cmp	x9, x28
   45644:	b.ne	45650 <__gmpn_dcpi1_divappr_q@@Base+0x36c>  // b.any
   45648:	cmp	x10, x8
   4564c:	b.eq	45800 <__gmpn_dcpi1_divappr_q@@Base+0x51c>  // b.none
   45650:	ldur	x11, [x29, #-24]
   45654:	ldur	x12, [x17, #-24]
   45658:	ldr	x11, [x11]
   4565c:	mul	x13, x11, x9
   45660:	umulh	x11, x9, x11
   45664:	adds	x14, x13, x10
   45668:	adc	x9, x11, x9
   4566c:	msub	x10, x9, x28, x10
   45670:	subs	x15, x12, x8
   45674:	sbc	x10, x10, x28
   45678:	mul	x11, x9, x8
   4567c:	umulh	x13, x8, x9
   45680:	subs	x12, x15, x11
   45684:	sbc	x10, x10, x13
   45688:	cmp	x10, x14
   4568c:	cset	w11, cs  // cs = hs, nlast
   45690:	csetm	x13, cs  // cs = hs, nlast
   45694:	sub	x9, x9, x11
   45698:	and	x11, x8, x13
   4569c:	and	x13, x28, x13
   456a0:	adds	x26, x12, x11
   456a4:	adc	x27, x10, x13
   456a8:	cmp	x27, x28
   456ac:	add	x3, x9, #0x1
   456b0:	b.cs	457dc <__gmpn_dcpi1_divappr_q@@Base+0x4f8>  // b.hs, b.nlast
   456b4:	cmp	x20, #0x3
   456b8:	b.lt	456f0 <__gmpn_dcpi1_divappr_q@@Base+0x40c>  // b.tstop
   456bc:	ldur	x0, [x29, #-48]
   456c0:	ldur	x1, [x29, #-8]
   456c4:	sub	x2, x20, #0x2
   456c8:	stp	x3, x17, [x29, #-72]
   456cc:	bl	ca00 <__gmpn_submul_1@plt>
   456d0:	ldur	x17, [x29, #-64]
   456d4:	subs	x8, x26, x0
   456d8:	cset	w9, cc  // cc = lo, ul, last
   456dc:	subs	x27, x27, x9
   456e0:	stur	x8, [x17, #-24]
   456e4:	b.cc	4581c <__gmpn_dcpi1_divappr_q@@Base+0x538>  // b.lo, b.ul, b.last
   456e8:	ldur	x3, [x29, #-72]
   456ec:	b	456f4 <__gmpn_dcpi1_divappr_q@@Base+0x410>
   456f0:	stur	x26, [x17, #-24]
   456f4:	stur	x27, [x17, #-16]
   456f8:	stur	x3, [x23, #-8]
   456fc:	neg	x21, x21
   45700:	cmp	x21, x20
   45704:	neg	x10, x20
   45708:	b.le	45760 <__gmpn_dcpi1_divappr_q@@Base+0x47c>
   4570c:	ldp	x8, x27, [x29, #-32]
   45710:	ldp	x23, x28, [x29, #-16]
   45714:	neg	x26, x20, lsl #3
   45718:	stur	x10, [x29, #-40]
   4571c:	add	x8, x8, x24
   45720:	sub	x24, x8, #0x8
   45724:	add	x22, x22, x26
   45728:	add	x24, x24, x26
   4572c:	mov	x0, x22
   45730:	mov	x1, x24
   45734:	mov	x2, x28
   45738:	mov	x3, x20
   4573c:	mov	x4, x27
   45740:	mov	x5, x23
   45744:	bl	d400 <__gmpn_dcpi1_div_qr_n@plt>
   45748:	sub	x21, x21, x20
   4574c:	cmp	x21, x20
   45750:	b.gt	45724 <__gmpn_dcpi1_divappr_q@@Base+0x440>
   45754:	ldur	x10, [x29, #-40]
   45758:	add	x8, x24, x19
   4575c:	b	45770 <__gmpn_dcpi1_divappr_q@@Base+0x48c>
   45760:	ldur	x8, [x29, #-40]
   45764:	ldur	x27, [x29, #-24]
   45768:	ldur	x28, [x29, #-8]
   4576c:	sub	x8, x8, #0x8
   45770:	mov	w9, #0x1                   	// #1
   45774:	ldur	x5, [x29, #-16]
   45778:	ldr	x19, [x22]
   4577c:	sub	x9, x9, x21
   45780:	add	x26, x22, x9, lsl #3
   45784:	add	x8, x8, x10, lsl #3
   45788:	add	x1, x8, x10, lsl #3
   4578c:	mov	x0, x26
   45790:	mov	x2, x28
   45794:	mov	x3, x20
   45798:	mov	x4, x27
   4579c:	sub	x24, x21, #0x1
   457a0:	bl	4584c <__gmpn_dcpi1_divappr_q@@Base+0x568>
   457a4:	add	x1, x26, #0x8
   457a8:	mov	x0, x26
   457ac:	mov	x2, x24
   457b0:	bl	ca70 <__gmpn_copyi@plt>
   457b4:	str	x19, [x22]
   457b8:	mov	x0, x25
   457bc:	mov	sp, x29
   457c0:	ldp	x20, x19, [sp, #80]
   457c4:	ldp	x22, x21, [sp, #64]
   457c8:	ldp	x24, x23, [sp, #48]
   457cc:	ldp	x26, x25, [sp, #32]
   457d0:	ldp	x28, x27, [sp, #16]
   457d4:	ldp	x29, x30, [sp], #96
   457d8:	ret
   457dc:	cmp	x26, x8
   457e0:	b.cs	457ec <__gmpn_dcpi1_divappr_q@@Base+0x508>  // b.hs, b.nlast
   457e4:	cmp	x27, x28
   457e8:	b.ls	456b4 <__gmpn_dcpi1_divappr_q@@Base+0x3d0>  // b.plast
   457ec:	subs	x9, x26, x8
   457f0:	sbc	x27, x27, x28
   457f4:	add	x3, x3, #0x1
   457f8:	mov	x26, x9
   457fc:	b	456b4 <__gmpn_dcpi1_divappr_q@@Base+0x3d0>
   45800:	ldur	x0, [x29, #-48]
   45804:	ldur	x1, [x29, #-8]
   45808:	mov	x3, #0xffffffffffffffff    	// #-1
   4580c:	mov	x2, x20
   45810:	bl	ca00 <__gmpn_submul_1@plt>
   45814:	mov	x3, #0xffffffffffffffff    	// #-1
   45818:	b	456f8 <__gmpn_dcpi1_divappr_q@@Base+0x414>
   4581c:	ldp	x3, x0, [x29, #-56]
   45820:	ldur	x2, [x29, #-8]
   45824:	mov	x1, x0
   45828:	bl	ca90 <__gmpn_add_n@plt>
   4582c:	ldp	x3, x17, [x29, #-72]
   45830:	add	x8, x27, x28
   45834:	add	x27, x8, x0
   45838:	cmp	x3, #0x0
   4583c:	cset	w8, eq  // eq = none
   45840:	sub	x25, x25, x8
   45844:	sub	x3, x3, #0x1
   45848:	b	456f4 <__gmpn_dcpi1_divappr_q@@Base+0x410>
   4584c:	sub	sp, sp, #0x80
   45850:	stp	x28, x27, [sp, #48]
   45854:	stp	x20, x19, [sp, #112]
   45858:	asr	x20, x3, #1
   4585c:	sub	x27, x3, x3, asr #1
   45860:	and	x8, x3, #0xfffffffffffffffe
   45864:	stp	x29, x30, [sp, #32]
   45868:	stp	x26, x25, [sp, #64]
   4586c:	stp	x24, x23, [sp, #80]
   45870:	stp	x22, x21, [sp, #96]
   45874:	add	x29, sp, #0x20
   45878:	mov	x23, x5
   4587c:	mov	x21, x3
   45880:	mov	x25, x2
   45884:	mov	x28, x1
   45888:	add	x19, x0, x20, lsl #3
   4588c:	cmp	x27, #0x29
   45890:	add	x1, x1, x8, lsl #3
   45894:	stur	x0, [x29, #-8]
   45898:	stp	x8, x4, [sp, #8]
   4589c:	b.le	458b8 <__gmpn_dcpi1_divappr_q@@Base+0x5d4>
   458a0:	add	x2, x25, x20, lsl #3
   458a4:	mov	x0, x19
   458a8:	mov	x3, x27
   458ac:	mov	x5, x23
   458b0:	bl	d400 <__gmpn_dcpi1_div_qr_n@plt>
   458b4:	b	458d0 <__gmpn_dcpi1_divappr_q@@Base+0x5ec>
   458b8:	ldr	x5, [x4]
   458bc:	lsl	x2, x27, #1
   458c0:	add	x3, x25, x20, lsl #3
   458c4:	mov	x0, x19
   458c8:	mov	x4, x27
   458cc:	bl	c660 <__gmpn_sbpi1_div_qr@plt>
   458d0:	mov	x24, x0
   458d4:	mov	x0, x23
   458d8:	mov	x1, x19
   458dc:	mov	x2, x27
   458e0:	mov	x3, x25
   458e4:	mov	x4, x20
   458e8:	bl	ccf0 <__gmpn_mul@plt>
   458ec:	add	x26, x28, x20, lsl #3
   458f0:	mov	x0, x26
   458f4:	mov	x1, x26
   458f8:	mov	x2, x23
   458fc:	mov	x3, x21
   45900:	bl	c2e0 <__gmpn_sub_n@plt>
   45904:	mov	x22, x0
   45908:	cbz	x24, 45924 <__gmpn_dcpi1_divappr_q@@Base+0x640>
   4590c:	add	x0, x28, x21, lsl #3
   45910:	mov	x1, x0
   45914:	mov	x2, x25
   45918:	mov	x3, x20
   4591c:	bl	c2e0 <__gmpn_sub_n@plt>
   45920:	add	x22, x0, x22
   45924:	cbz	x22, 45988 <__gmpn_dcpi1_divappr_q@@Base+0x6a4>
   45928:	ldr	x8, [x19]
   4592c:	sub	x9, x8, #0x1
   45930:	str	x9, [x19]
   45934:	cbnz	x8, 45958 <__gmpn_dcpi1_divappr_q@@Base+0x674>
   45938:	mov	w8, #0x1                   	// #1
   4593c:	cmp	x8, x27
   45940:	b.ge	45980 <__gmpn_dcpi1_divappr_q@@Base+0x69c>  // b.tcont
   45944:	ldr	x9, [x19, x8, lsl #3]
   45948:	sub	x10, x9, #0x1
   4594c:	str	x10, [x19, x8, lsl #3]
   45950:	add	x8, x8, #0x1
   45954:	cbz	x9, 4593c <__gmpn_dcpi1_divappr_q@@Base+0x658>
   45958:	mov	x8, xzr
   4595c:	mov	x0, x26
   45960:	mov	x1, x26
   45964:	mov	x2, x25
   45968:	mov	x3, x21
   4596c:	sub	x24, x24, x8
   45970:	bl	ca90 <__gmpn_add_n@plt>
   45974:	subs	x22, x22, x0
   45978:	b.ne	45928 <__gmpn_dcpi1_divappr_q@@Base+0x644>  // b.any
   4597c:	b	45988 <__gmpn_dcpi1_divappr_q@@Base+0x6a4>
   45980:	mov	w8, #0x1                   	// #1
   45984:	b	4595c <__gmpn_dcpi1_divappr_q@@Base+0x678>
   45988:	add	x1, x28, x27, lsl #3
   4598c:	cmp	x21, #0x12f
   45990:	add	x3, x25, x27, lsl #3
   45994:	b.le	459bc <__gmpn_dcpi1_divappr_q@@Base+0x6d8>
   45998:	ldur	x19, [x29, #-8]
   4599c:	ldr	x4, [sp, #16]
   459a0:	mov	x2, x3
   459a4:	mov	x3, x20
   459a8:	mov	x0, x19
   459ac:	mov	x5, x23
   459b0:	bl	4584c <__gmpn_dcpi1_divappr_q@@Base+0x568>
   459b4:	cbnz	x0, 459d8 <__gmpn_dcpi1_divappr_q@@Base+0x6f4>
   459b8:	b	459e0 <__gmpn_dcpi1_divappr_q@@Base+0x6fc>
   459bc:	ldp	x2, x8, [sp, #8]
   459c0:	ldur	x19, [x29, #-8]
   459c4:	mov	x4, x20
   459c8:	ldr	x5, [x8]
   459cc:	mov	x0, x19
   459d0:	bl	c710 <__gmpn_sbpi1_divappr_q@plt>
   459d4:	cbz	x0, 459e0 <__gmpn_dcpi1_divappr_q@@Base+0x6fc>
   459d8:	cmp	x21, #0x2
   459dc:	b.ge	45a04 <__gmpn_dcpi1_divappr_q@@Base+0x720>  // b.tcont
   459e0:	mov	x0, x24
   459e4:	ldp	x20, x19, [sp, #112]
   459e8:	ldp	x22, x21, [sp, #96]
   459ec:	ldp	x24, x23, [sp, #80]
   459f0:	ldp	x26, x25, [sp, #64]
   459f4:	ldp	x28, x27, [sp, #48]
   459f8:	ldp	x29, x30, [sp, #32]
   459fc:	add	sp, sp, #0x80
   45a00:	ret
   45a04:	cmp	x20, #0x1
   45a08:	csinc	x8, x20, xzr, gt
   45a0c:	lsl	x2, x8, #3
   45a10:	mov	w1, #0xff                  	// #255
   45a14:	mov	x0, x19
   45a18:	bl	c610 <memset@plt>
   45a1c:	b	459e0 <__gmpn_dcpi1_divappr_q@@Base+0x6fc>

0000000000045a20 <__gmpn_mu_div_qr@@Base>:
   45a20:	sub	sp, sp, #0x80
   45a24:	stp	x22, x21, [sp, #96]
   45a28:	sub	x22, x3, x5
   45a2c:	add	x8, x22, #0x64
   45a30:	stp	x28, x27, [sp, #48]
   45a34:	stp	x26, x25, [sp, #64]
   45a38:	stp	x24, x23, [sp, #80]
   45a3c:	stp	x20, x19, [sp, #112]
   45a40:	mov	x25, x6
   45a44:	mov	x19, x5
   45a48:	mov	x26, x3
   45a4c:	mov	x27, x2
   45a50:	cmp	x8, x5
   45a54:	mov	x23, x0
   45a58:	stp	x29, x30, [sp, #32]
   45a5c:	add	x29, sp, #0x20
   45a60:	b.ge	45adc <__gmpn_mu_div_qr@@Base+0xbc>  // b.tcont
   45a64:	mov	w20, #0x1                   	// #1
   45a68:	add	x8, x1, x26, lsl #3
   45a6c:	bfi	x20, x22, #1, #63
   45a70:	add	x9, x27, x26, lsl #3
   45a74:	add	x10, x4, x19, lsl #3
   45a78:	add	x21, x22, #0x1
   45a7c:	mvn	x11, x22
   45a80:	sub	x24, x8, x20, lsl #3
   45a84:	str	x1, [sp]
   45a88:	mov	x28, x4
   45a8c:	sub	x2, x9, x20, lsl #3
   45a90:	add	x4, x10, x11, lsl #3
   45a94:	mov	x0, x23
   45a98:	mov	x1, x24
   45a9c:	mov	x3, x20
   45aa0:	mov	x5, x21
   45aa4:	mov	x6, x25
   45aa8:	bl	45c08 <__gmpn_mu_div_qr@@Base+0x1e8>
   45aac:	str	x21, [sp, #8]
   45ab0:	sub	x21, x19, x21
   45ab4:	cmp	x21, x22
   45ab8:	stur	x0, [x29, #-8]
   45abc:	mov	x0, x25
   45ac0:	str	x28, [sp, #16]
   45ac4:	b.le	45b10 <__gmpn_mu_div_qr@@Base+0xf0>
   45ac8:	mov	x1, x28
   45acc:	mov	x2, x21
   45ad0:	mov	x3, x23
   45ad4:	mov	x4, x22
   45ad8:	b	45b20 <__gmpn_mu_div_qr@@Base+0x100>
   45adc:	mov	x0, x23
   45ae0:	mov	x2, x27
   45ae4:	mov	x3, x26
   45ae8:	mov	x5, x19
   45aec:	mov	x6, x25
   45af0:	ldp	x20, x19, [sp, #112]
   45af4:	ldp	x22, x21, [sp, #96]
   45af8:	ldp	x24, x23, [sp, #80]
   45afc:	ldp	x26, x25, [sp, #64]
   45b00:	ldp	x28, x27, [sp, #48]
   45b04:	ldp	x29, x30, [sp, #32]
   45b08:	add	sp, sp, #0x80
   45b0c:	b	45c08 <__gmpn_mu_div_qr@@Base+0x1e8>
   45b10:	mov	x1, x23
   45b14:	mov	x2, x22
   45b18:	mov	x3, x28
   45b1c:	mov	x4, x21
   45b20:	bl	ccf0 <__gmpn_mul@plt>
   45b24:	neg	x8, x20
   45b28:	ldr	x28, [sp]
   45b2c:	str	x8, [sp]
   45b30:	ldur	x8, [x29, #-8]
   45b34:	cbz	x8, 45b50 <__gmpn_mu_div_qr@@Base+0x130>
   45b38:	ldr	x2, [sp, #16]
   45b3c:	add	x0, x25, x22, lsl #3
   45b40:	mov	x1, x0
   45b44:	mov	x3, x21
   45b48:	bl	ca90 <__gmpn_add_n@plt>
   45b4c:	b	45b54 <__gmpn_mu_div_qr@@Base+0x134>
   45b50:	mov	x0, xzr
   45b54:	add	x8, x25, x19, lsl #3
   45b58:	stur	x0, [x8, #-8]
   45b5c:	sub	x3, x26, x20
   45b60:	mov	x0, x28
   45b64:	mov	x1, x27
   45b68:	mov	x2, x25
   45b6c:	bl	c2e0 <__gmpn_sub_n@plt>
   45b70:	ldp	x9, x3, [sp]
   45b74:	add	x8, x25, x26, lsl #3
   45b78:	mov	x4, x0
   45b7c:	mov	x0, x24
   45b80:	add	x2, x8, x9, lsl #3
   45b84:	mov	x1, x24
   45b88:	bl	c780 <__gmpn_sub_nc@plt>
   45b8c:	ldur	x20, [x29, #-8]
   45b90:	cbz	x0, 45be4 <__gmpn_mu_div_qr@@Base+0x1c4>
   45b94:	ldr	x8, [x23]
   45b98:	sub	x9, x8, #0x1
   45b9c:	str	x9, [x23]
   45ba0:	cbnz	x8, 45bc8 <__gmpn_mu_div_qr@@Base+0x1a8>
   45ba4:	mov	w8, #0x1                   	// #1
   45ba8:	mov	w9, #0x1                   	// #1
   45bac:	cmp	x9, x22
   45bb0:	b.ge	45bcc <__gmpn_mu_div_qr@@Base+0x1ac>  // b.tcont
   45bb4:	ldr	x10, [x23, x9, lsl #3]
   45bb8:	sub	x11, x10, #0x1
   45bbc:	str	x11, [x23, x9, lsl #3]
   45bc0:	add	x9, x9, #0x1
   45bc4:	cbz	x10, 45bac <__gmpn_mu_div_qr@@Base+0x18c>
   45bc8:	mov	x8, xzr
   45bcc:	ldr	x2, [sp, #16]
   45bd0:	mov	x0, x28
   45bd4:	mov	x1, x28
   45bd8:	mov	x3, x19
   45bdc:	sub	x20, x20, x8
   45be0:	bl	ca90 <__gmpn_add_n@plt>
   45be4:	mov	x0, x20
   45be8:	ldp	x20, x19, [sp, #112]
   45bec:	ldp	x22, x21, [sp, #96]
   45bf0:	ldp	x24, x23, [sp, #80]
   45bf4:	ldp	x26, x25, [sp, #64]
   45bf8:	ldp	x28, x27, [sp, #48]
   45bfc:	ldp	x29, x30, [sp, #32]
   45c00:	add	sp, sp, #0x80
   45c04:	ret
   45c08:	sub	sp, sp, #0x70
   45c0c:	stp	x26, x25, [sp, #48]
   45c10:	sub	x26, x3, x5
   45c14:	stp	x24, x23, [sp, #64]
   45c18:	stp	x22, x21, [sp, #80]
   45c1c:	stp	x20, x19, [sp, #96]
   45c20:	mov	x19, x6
   45c24:	mov	x20, x5
   45c28:	mov	x21, x4
   45c2c:	mov	x22, x3
   45c30:	mov	x23, x2
   45c34:	mov	x24, x1
   45c38:	cmp	x26, x5
   45c3c:	mov	x25, x0
   45c40:	stp	x29, x30, [sp, #16]
   45c44:	stp	x28, x27, [sp, #32]
   45c48:	add	x29, sp, #0x10
   45c4c:	b.le	45c60 <__gmpn_mu_div_qr@@Base+0x240>
   45c50:	sub	x8, x26, #0x1
   45c54:	sdiv	x9, x8, x20
   45c58:	add	x9, x9, #0x1
   45c5c:	b	45c74 <__gmpn_mu_div_qr@@Base+0x254>
   45c60:	add	x8, x26, x26, lsl #1
   45c64:	cmp	x8, x20
   45c68:	b.le	45c7c <__gmpn_mu_div_qr@@Base+0x25c>
   45c6c:	sub	x8, x26, #0x1
   45c70:	mov	w9, #0x2                   	// #2
   45c74:	sdiv	x8, x8, x9
   45c78:	add	x26, x8, #0x1
   45c7c:	add	x28, x19, x26, lsl #3
   45c80:	cmp	x26, x20
   45c84:	add	x27, x28, #0x8
   45c88:	b.ne	45ccc <__gmpn_mu_div_qr@@Base+0x2ac>  // b.any
   45c8c:	add	x0, x27, #0x8
   45c90:	mov	x1, x21
   45c94:	mov	x2, x20
   45c98:	bl	ca70 <__gmpn_copyi@plt>
   45c9c:	add	x9, x27, x20, lsl #3
   45ca0:	mov	w8, #0x1                   	// #1
   45ca4:	add	x2, x20, #0x1
   45ca8:	add	x3, x9, #0x8
   45cac:	mov	x0, x19
   45cb0:	mov	x1, x27
   45cb4:	str	x8, [x27]
   45cb8:	bl	d080 <__gmpn_invertappr@plt>
   45cbc:	add	x1, x19, #0x8
   45cc0:	mov	x0, x19
   45cc4:	mov	x2, x20
   45cc8:	b	45d98 <__gmpn_mu_div_qr@@Base+0x378>
   45ccc:	add	x8, x21, x20, lsl #3
   45cd0:	mvn	x9, x26
   45cd4:	add	x11, x8, x9, lsl #3
   45cd8:	ldr	x10, [x11]
   45cdc:	adds	x10, x10, #0x1
   45ce0:	str	x10, [x27]
   45ce4:	b.cc	45d48 <__gmpn_mu_div_qr@@Base+0x328>  // b.lo, b.ul, b.last
   45ce8:	add	x10, x19, x26, lsl #3
   45cec:	sub	x13, x20, x26
   45cf0:	mov	x12, xzr
   45cf4:	add	x10, x10, #0x10
   45cf8:	add	x14, x21, x13, lsl #3
   45cfc:	add	x13, x12, #0x1
   45d00:	cmp	x13, x26
   45d04:	b.gt	45de4 <__gmpn_mu_div_qr@@Base+0x3c4>
   45d08:	ldr	x15, [x14, x12, lsl #3]
   45d0c:	mov	x12, x13
   45d10:	adds	x15, x15, #0x1
   45d14:	str	x15, [x10], #8
   45d18:	b.cs	45cfc <__gmpn_mu_div_qr@@Base+0x2dc>  // b.hs, b.nlast
   45d1c:	cmp	x11, x27
   45d20:	b.eq	45d74 <__gmpn_mu_div_qr@@Base+0x354>  // b.none
   45d24:	cmp	x13, x26
   45d28:	b.ge	45d74 <__gmpn_mu_div_qr@@Base+0x354>  // b.tcont
   45d2c:	add	x9, x9, x13
   45d30:	add	x9, x9, #0x1
   45d34:	ldr	x11, [x8, x9, lsl #3]
   45d38:	adds	x9, x9, #0x1
   45d3c:	str	x11, [x10], #8
   45d40:	b.cc	45d34 <__gmpn_mu_div_qr@@Base+0x314>  // b.lo, b.ul, b.last
   45d44:	b	45d74 <__gmpn_mu_div_qr@@Base+0x354>
   45d48:	cmp	x26, #0x1
   45d4c:	b.lt	45d74 <__gmpn_mu_div_qr@@Base+0x354>  // b.tstop
   45d50:	cmp	x11, x27
   45d54:	b.eq	45d74 <__gmpn_mu_div_qr@@Base+0x354>  // b.none
   45d58:	add	x10, x19, x26, lsl #3
   45d5c:	add	x9, x9, #0x1
   45d60:	add	x10, x10, #0x10
   45d64:	ldr	x11, [x8, x9, lsl #3]
   45d68:	adds	x9, x9, #0x1
   45d6c:	str	x11, [x10], #8
   45d70:	b.cc	45d64 <__gmpn_mu_div_qr@@Base+0x344>  // b.lo, b.ul, b.last
   45d74:	add	x8, x27, x26, lsl #3
   45d78:	add	x2, x26, #0x1
   45d7c:	add	x3, x8, #0x8
   45d80:	mov	x0, x19
   45d84:	mov	x1, x27
   45d88:	bl	d080 <__gmpn_invertappr@plt>
   45d8c:	add	x1, x19, #0x8
   45d90:	mov	x0, x19
   45d94:	mov	x2, x26
   45d98:	bl	ca70 <__gmpn_copyi@plt>
   45d9c:	mov	x0, x25
   45da0:	mov	x1, x24
   45da4:	mov	x2, x23
   45da8:	mov	x3, x22
   45dac:	mov	x4, x21
   45db0:	mov	x5, x20
   45db4:	mov	x6, x19
   45db8:	mov	x7, x26
   45dbc:	str	x28, [sp]
   45dc0:	bl	d0a0 <__gmpn_preinv_mu_div_qr@plt>
   45dc4:	ldp	x20, x19, [sp, #96]
   45dc8:	ldp	x22, x21, [sp, #80]
   45dcc:	ldp	x24, x23, [sp, #64]
   45dd0:	ldp	x26, x25, [sp, #48]
   45dd4:	ldp	x28, x27, [sp, #32]
   45dd8:	ldp	x29, x30, [sp, #16]
   45ddc:	add	sp, sp, #0x70
   45de0:	ret
   45de4:	cbz	x26, 45d9c <__gmpn_mu_div_qr@@Base+0x37c>
   45de8:	lsl	x2, x26, #3
   45dec:	mov	x0, x19
   45df0:	mov	w1, wzr
   45df4:	bl	c610 <memset@plt>
   45df8:	b	45d9c <__gmpn_mu_div_qr@@Base+0x37c>

0000000000045dfc <__gmpn_preinv_mu_div_qr@@Base>:
   45dfc:	sub	sp, sp, #0xb0
   45e00:	stp	x29, x30, [sp, #80]
   45e04:	add	x29, sp, #0x50
   45e08:	stp	x24, x23, [sp, #128]
   45e0c:	ldr	x24, [x29, #96]
   45e10:	stp	x28, x27, [sp, #96]
   45e14:	sub	x28, x3, x5
   45e18:	add	x8, x2, x3, lsl #3
   45e1c:	stp	x26, x25, [sp, #112]
   45e20:	stp	x22, x21, [sp, #144]
   45e24:	stp	x20, x19, [sp, #160]
   45e28:	mov	x19, x7
   45e2c:	mov	x20, x6
   45e30:	mov	x21, x5
   45e34:	mov	x22, x4
   45e38:	mov	x23, x1
   45e3c:	add	x1, x2, x28, lsl #3
   45e40:	add	x26, x0, x28, lsl #3
   45e44:	sub	x8, x8, #0x8
   45e48:	mov	x9, x5
   45e4c:	stur	x1, [x29, #-8]
   45e50:	subs	x10, x9, #0x1
   45e54:	b.lt	45e74 <__gmpn_preinv_mu_div_qr@@Base+0x78>  // b.tstop
   45e58:	add	x9, x22, x9, lsl #3
   45e5c:	ldr	x11, [x8], #-8
   45e60:	ldur	x9, [x9, #-8]
   45e64:	cmp	x11, x9
   45e68:	mov	x9, x10
   45e6c:	b.eq	45e50 <__gmpn_preinv_mu_div_qr@@Base+0x54>  // b.none
   45e70:	b.ls	45e90 <__gmpn_preinv_mu_div_qr@@Base+0x94>  // b.plast
   45e74:	mov	x0, x23
   45e78:	mov	x2, x22
   45e7c:	mov	x3, x21
   45e80:	bl	c2e0 <__gmpn_sub_n@plt>
   45e84:	mov	w8, #0x1                   	// #1
   45e88:	str	x8, [sp]
   45e8c:	b	45ea0 <__gmpn_preinv_mu_div_qr@@Base+0xa4>
   45e90:	mov	x0, x23
   45e94:	mov	x2, x21
   45e98:	bl	ca70 <__gmpn_copyi@plt>
   45e9c:	str	xzr, [sp]
   45ea0:	cmp	x28, #0x1
   45ea4:	b.lt	46170 <__gmpn_preinv_mu_div_qr@@Base+0x374>  // b.tstop
   45ea8:	add	x8, x23, x21, lsl #3
   45eac:	stur	x8, [x29, #-24]
   45eb0:	add	x8, x21, #0x1
   45eb4:	str	x8, [sp, #32]
   45eb8:	sub	x8, x23, #0x8
   45ebc:	str	x8, [sp, #16]
   45ec0:	add	x8, x24, #0x8
   45ec4:	neg	x25, x21
   45ec8:	str	x8, [sp, #8]
   45ecc:	sub	x8, x21, #0x1
   45ed0:	stur	x8, [x29, #-32]
   45ed4:	str	x25, [sp, #24]
   45ed8:	subs	x8, x19, x28
   45edc:	add	x8, x20, x8, lsl #3
   45ee0:	csel	x20, x8, x20, gt
   45ee4:	ldur	x8, [x29, #-24]
   45ee8:	csel	x19, x28, x19, gt
   45eec:	mov	x0, x24
   45ef0:	mov	x2, x20
   45ef4:	sub	x25, x8, x19, lsl #3
   45ef8:	mov	x1, x25
   45efc:	mov	x3, x19
   45f00:	sub	x26, x26, x19, lsl #3
   45f04:	bl	c9b0 <__gmpn_mul_n@plt>
   45f08:	add	x27, x24, x19, lsl #3
   45f0c:	mov	x0, x26
   45f10:	mov	x1, x27
   45f14:	mov	x2, x25
   45f18:	mov	x3, x19
   45f1c:	bl	ca90 <__gmpn_add_n@plt>
   45f20:	cbnz	x0, 46194 <__gmpn_preinv_mu_div_qr@@Base+0x398>
   45f24:	cmp	x19, #0x11
   45f28:	stur	x28, [x29, #-16]
   45f2c:	b.le	45fcc <__gmpn_preinv_mu_div_qr@@Base+0x1d0>
   45f30:	ldr	x0, [sp, #32]
   45f34:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   45f38:	mov	x28, x0
   45f3c:	add	x6, x24, x0, lsl #3
   45f40:	mov	x0, x24
   45f44:	mov	x1, x28
   45f48:	mov	x2, x22
   45f4c:	mov	x3, x21
   45f50:	mov	x4, x26
   45f54:	mov	x5, x19
   45f58:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   45f5c:	add	x8, x19, x21
   45f60:	sub	x25, x8, x28
   45f64:	cmp	x25, #0x1
   45f68:	b.lt	46060 <__gmpn_preinv_mu_div_qr@@Base+0x264>  // b.tstop
   45f6c:	neg	x8, x19
   45f70:	str	x8, [sp, #40]
   45f74:	ldur	x8, [x29, #-24]
   45f78:	mov	x0, x24
   45f7c:	mov	x1, x24
   45f80:	mov	x3, x25
   45f84:	sub	x2, x8, x25, lsl #3
   45f88:	bl	c2e0 <__gmpn_sub_n@plt>
   45f8c:	add	x8, x24, x25, lsl #3
   45f90:	ldr	x9, [x8]
   45f94:	subs	x9, x9, x0
   45f98:	str	x9, [x8]
   45f9c:	b.cs	45fe8 <__gmpn_preinv_mu_div_qr@@Base+0x1ec>  // b.hs, b.nlast
   45fa0:	ldr	x13, [sp, #24]
   45fa4:	sub	x9, x28, x25
   45fa8:	mov	w10, #0x1                   	// #1
   45fac:	cmp	x10, x9
   45fb0:	b.ge	45ff4 <__gmpn_preinv_mu_div_qr@@Base+0x1f8>  // b.tcont
   45fb4:	ldr	x11, [x8, x10, lsl #3]
   45fb8:	sub	x12, x11, #0x1
   45fbc:	str	x12, [x8, x10, lsl #3]
   45fc0:	add	x10, x10, #0x1
   45fc4:	cbz	x11, 45fac <__gmpn_preinv_mu_div_qr@@Base+0x1b0>
   45fc8:	b	45fec <__gmpn_preinv_mu_div_qr@@Base+0x1f0>
   45fcc:	mov	x0, x24
   45fd0:	mov	x1, x22
   45fd4:	mov	x2, x21
   45fd8:	mov	x3, x26
   45fdc:	mov	x4, x19
   45fe0:	bl	ccf0 <__gmpn_mul@plt>
   45fe4:	b	46060 <__gmpn_preinv_mu_div_qr@@Base+0x264>
   45fe8:	ldr	x13, [sp, #24]
   45fec:	mov	x8, xzr
   45ff0:	b	45ff8 <__gmpn_preinv_mu_div_qr@@Base+0x1fc>
   45ff4:	mov	w8, #0x1                   	// #1
   45ff8:	ldr	x9, [sp, #16]
   45ffc:	ldr	x10, [sp, #40]
   46000:	add	x9, x9, x10, lsl #3
   46004:	add	x10, x13, x28
   46008:	cmp	x10, #0x1
   4600c:	b.lt	46030 <__gmpn_preinv_mu_div_qr@@Base+0x234>  // b.tstop
   46010:	add	x11, x24, x28, lsl #3
   46014:	ldr	x10, [x9, x28, lsl #3]
   46018:	ldur	x11, [x11, #-8]
   4601c:	sub	x28, x28, #0x1
   46020:	cmp	x10, x11
   46024:	b.eq	46004 <__gmpn_preinv_mu_div_qr@@Base+0x208>  // b.none
   46028:	cset	w9, ls  // ls = plast
   4602c:	b	46034 <__gmpn_preinv_mu_div_qr@@Base+0x238>
   46030:	mov	x9, xzr
   46034:	subs	x8, x9, x8
   46038:	b.cc	461ac <__gmpn_preinv_mu_div_qr@@Base+0x3b0>  // b.lo, b.ul, b.last
   4603c:	ldr	x9, [x24]
   46040:	adds	x8, x9, x8
   46044:	str	x8, [x24]
   46048:	b.cc	46060 <__gmpn_preinv_mu_div_qr@@Base+0x264>  // b.lo, b.ul, b.last
   4604c:	ldr	x8, [sp, #8]
   46050:	ldr	x9, [x8]
   46054:	adds	x9, x9, #0x1
   46058:	str	x9, [x8], #8
   4605c:	b.cs	46050 <__gmpn_preinv_mu_div_qr@@Base+0x254>  // b.hs, b.nlast
   46060:	subs	x8, x21, x19
   46064:	ldr	x8, [x23, x8, lsl #3]
   46068:	ldr	x9, [x24, x21, lsl #3]
   4606c:	ldur	x1, [x29, #-8]
   46070:	subs	x25, x21, x19
   46074:	sub	x28, x8, x9
   46078:	sub	x1, x1, x19, lsl #3
   4607c:	stur	x1, [x29, #-8]
   46080:	b.ne	4609c <__gmpn_preinv_mu_div_qr@@Base+0x2a0>  // b.any
   46084:	mov	x0, x23
   46088:	mov	x2, x24
   4608c:	mov	x3, x21
   46090:	bl	c2e0 <__gmpn_sub_n@plt>
   46094:	mov	x25, x0
   46098:	b	460d8 <__gmpn_preinv_mu_div_qr@@Base+0x2dc>
   4609c:	mov	x0, x24
   460a0:	mov	x2, x24
   460a4:	mov	x3, x19
   460a8:	bl	c2e0 <__gmpn_sub_n@plt>
   460ac:	mov	x4, x0
   460b0:	mov	x0, x27
   460b4:	mov	x1, x23
   460b8:	mov	x2, x27
   460bc:	mov	x3, x25
   460c0:	bl	c780 <__gmpn_sub_nc@plt>
   460c4:	mov	x25, x0
   460c8:	mov	x0, x23
   460cc:	mov	x1, x24
   460d0:	mov	x2, x21
   460d4:	bl	ca70 <__gmpn_copyi@plt>
   460d8:	subs	x25, x28, x25
   460dc:	ldur	x28, [x29, #-16]
   460e0:	sub	x28, x28, x19
   460e4:	b.eq	46118 <__gmpn_preinv_mu_div_qr@@Base+0x31c>  // b.none
   460e8:	mov	x8, x26
   460ec:	ldr	x9, [x8]
   460f0:	adds	x9, x9, #0x1
   460f4:	str	x9, [x8], #8
   460f8:	b.cs	460ec <__gmpn_preinv_mu_div_qr@@Base+0x2f0>  // b.hs, b.nlast
   460fc:	mov	x0, x23
   46100:	mov	x1, x23
   46104:	mov	x2, x22
   46108:	mov	x3, x21
   4610c:	bl	c2e0 <__gmpn_sub_n@plt>
   46110:	subs	x25, x25, x0
   46114:	b.ne	460e8 <__gmpn_preinv_mu_div_qr@@Base+0x2ec>  // b.any
   46118:	ldur	x8, [x29, #-32]
   4611c:	add	x9, x8, #0x1
   46120:	cmp	x9, #0x1
   46124:	b.lt	46140 <__gmpn_preinv_mu_div_qr@@Base+0x344>  // b.tstop
   46128:	ldr	x9, [x23, x8, lsl #3]
   4612c:	ldr	x10, [x22, x8, lsl #3]
   46130:	sub	x8, x8, #0x1
   46134:	cmp	x9, x10
   46138:	b.eq	4611c <__gmpn_preinv_mu_div_qr@@Base+0x320>  // b.none
   4613c:	b.ls	46168 <__gmpn_preinv_mu_div_qr@@Base+0x36c>  // b.plast
   46140:	mov	x8, x26
   46144:	ldr	x9, [x8]
   46148:	adds	x9, x9, #0x1
   4614c:	str	x9, [x8], #8
   46150:	b.cs	46144 <__gmpn_preinv_mu_div_qr@@Base+0x348>  // b.hs, b.nlast
   46154:	mov	x0, x23
   46158:	mov	x1, x23
   4615c:	mov	x2, x22
   46160:	mov	x3, x21
   46164:	bl	c2e0 <__gmpn_sub_n@plt>
   46168:	cmp	x28, #0x0
   4616c:	b.gt	45ed8 <__gmpn_preinv_mu_div_qr@@Base+0xdc>
   46170:	ldr	x0, [sp]
   46174:	ldp	x20, x19, [sp, #160]
   46178:	ldp	x22, x21, [sp, #144]
   4617c:	ldp	x24, x23, [sp, #128]
   46180:	ldp	x26, x25, [sp, #112]
   46184:	ldp	x28, x27, [sp, #96]
   46188:	ldp	x29, x30, [sp, #80]
   4618c:	add	sp, sp, #0xb0
   46190:	ret
   46194:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   46198:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   4619c:	add	x0, x0, #0x88b
   461a0:	add	x2, x2, #0x871
   461a4:	mov	w1, #0x118                 	// #280
   461a8:	bl	c6e0 <__gmp_assert_fail@plt>
   461ac:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   461b0:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   461b4:	add	x0, x0, #0x88b
   461b8:	add	x2, x2, #0x897
   461bc:	mov	w1, #0x12c                 	// #300
   461c0:	bl	c6e0 <__gmp_assert_fail@plt>

00000000000461c4 <__gmpn_mu_div_qr_itch@@Base>:
   461c4:	stp	x29, x30, [sp, #-32]!
   461c8:	stp	x20, x19, [sp, #16]
   461cc:	sub	x20, x0, x1
   461d0:	mov	x19, x1
   461d4:	cmp	x20, x1
   461d8:	mov	x29, sp
   461dc:	cbz	w2, 461f0 <__gmpn_mu_div_qr_itch@@Base+0x2c>
   461e0:	csel	x8, x19, x20, gt
   461e4:	sub	x8, x8, #0x1
   461e8:	sxtw	x9, w2
   461ec:	b	46200 <__gmpn_mu_div_qr_itch@@Base+0x3c>
   461f0:	b.le	4624c <__gmpn_mu_div_qr_itch@@Base+0x88>
   461f4:	sub	x8, x20, #0x1
   461f8:	sdiv	x9, x8, x19
   461fc:	add	x9, x9, #0x1
   46200:	sdiv	x8, x8, x9
   46204:	add	x20, x8, #0x1
   46208:	add	x0, x19, #0x1
   4620c:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   46210:	asr	x8, x0, #1
   46214:	cmp	x8, x20
   46218:	csel	x10, x0, x8, lt  // lt = tstop
   4621c:	cmp	x8, x19
   46220:	csel	x8, x10, xzr, lt  // lt = tstop
   46224:	add	x9, x20, x20, lsl #1
   46228:	add	x8, x8, x0, lsl #1
   4622c:	add	x8, x8, #0x4
   46230:	add	x9, x9, #0x4
   46234:	cmp	x9, x8
   46238:	csel	x8, x9, x8, gt
   4623c:	add	x0, x8, x20
   46240:	ldp	x20, x19, [sp, #16]
   46244:	ldp	x29, x30, [sp], #32
   46248:	ret
   4624c:	add	x8, x20, x20, lsl #1
   46250:	cmp	x8, x19
   46254:	b.le	46208 <__gmpn_mu_div_qr_itch@@Base+0x44>
   46258:	sub	x8, x20, #0x1
   4625c:	cmp	x8, #0x0
   46260:	csel	x8, x20, x8, lt  // lt = tstop
   46264:	asr	x8, x8, #1
   46268:	b	46204 <__gmpn_mu_div_qr_itch@@Base+0x40>

000000000004626c <__gmpn_preinv_mu_div_qr_itch@@Base>:
   4626c:	stp	x29, x30, [sp, #-32]!
   46270:	add	x0, x1, #0x1
   46274:	stp	x20, x19, [sp, #16]
   46278:	mov	x29, sp
   4627c:	mov	x19, x2
   46280:	mov	x20, x1
   46284:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   46288:	asr	x8, x0, #1
   4628c:	cmp	x8, x19
   46290:	csel	x9, x0, x8, lt  // lt = tstop
   46294:	cmp	x8, x20
   46298:	ldp	x20, x19, [sp, #16]
   4629c:	csel	x8, x9, xzr, lt  // lt = tstop
   462a0:	add	x8, x8, x0, lsl #1
   462a4:	add	x0, x8, #0x4
   462a8:	ldp	x29, x30, [sp], #32
   462ac:	ret

00000000000462b0 <__gmpn_mu_divappr_q@@Base>:
   462b0:	sub	sp, sp, #0xc0
   462b4:	stp	x28, x27, [sp, #112]
   462b8:	sub	x28, x2, x4
   462bc:	add	x8, x28, #0x1
   462c0:	stp	x26, x25, [sp, #128]
   462c4:	stp	x24, x23, [sp, #144]
   462c8:	stp	x22, x21, [sp, #160]
   462cc:	stp	x20, x19, [sp, #176]
   462d0:	mov	x19, x5
   462d4:	mov	x21, x4
   462d8:	mov	x20, x3
   462dc:	mov	x24, x2
   462e0:	mov	x25, x1
   462e4:	cmp	x8, x4
   462e8:	mov	x26, x0
   462ec:	stp	x29, x30, [sp, #96]
   462f0:	add	x29, sp, #0x60
   462f4:	b.ge	46310 <__gmpn_mu_divappr_q@@Base+0x60>  // b.tcont
   462f8:	sub	x9, x21, x8
   462fc:	add	x25, x25, x9, lsl #3
   46300:	sub	x24, x24, x9
   46304:	add	x20, x20, x9, lsl #3
   46308:	mov	x21, x8
   4630c:	b	46328 <__gmpn_mu_divappr_q@@Base+0x78>
   46310:	cmp	x28, x21
   46314:	b.le	46328 <__gmpn_mu_divappr_q@@Base+0x78>
   46318:	sub	x8, x28, #0x1
   4631c:	sdiv	x9, x8, x21
   46320:	add	x9, x9, #0x1
   46324:	b	4633c <__gmpn_mu_divappr_q@@Base+0x8c>
   46328:	add	x8, x28, x28, lsl #1
   4632c:	cmp	x8, x21
   46330:	b.le	46344 <__gmpn_mu_divappr_q@@Base+0x94>
   46334:	sub	x8, x28, #0x1
   46338:	mov	w9, #0x2                   	// #2
   4633c:	sdiv	x8, x8, x9
   46340:	add	x28, x8, #0x1
   46344:	add	x23, x19, x28, lsl #3
   46348:	subs	x13, x21, x28
   4634c:	add	x27, x23, #0x8
   46350:	b.ne	46394 <__gmpn_mu_divappr_q@@Base+0xe4>  // b.any
   46354:	add	x0, x27, #0x8
   46358:	mov	x1, x20
   4635c:	mov	x2, x21
   46360:	bl	ca70 <__gmpn_copyi@plt>
   46364:	add	x9, x27, x21, lsl #3
   46368:	mov	w8, #0x1                   	// #1
   4636c:	add	x2, x21, #0x1
   46370:	add	x3, x9, #0x8
   46374:	mov	x0, x19
   46378:	mov	x1, x27
   4637c:	str	x8, [x27]
   46380:	bl	d080 <__gmpn_invertappr@plt>
   46384:	add	x1, x19, #0x8
   46388:	mov	x0, x19
   4638c:	mov	x2, x21
   46390:	b	4645c <__gmpn_mu_divappr_q@@Base+0x1ac>
   46394:	add	x8, x20, x21, lsl #3
   46398:	mvn	x9, x28
   4639c:	add	x11, x8, x9, lsl #3
   463a0:	ldr	x10, [x11]
   463a4:	adds	x10, x10, #0x1
   463a8:	str	x10, [x27]
   463ac:	b.cc	4640c <__gmpn_mu_divappr_q@@Base+0x15c>  // b.lo, b.ul, b.last
   463b0:	add	x10, x19, x28, lsl #3
   463b4:	mov	x12, xzr
   463b8:	add	x10, x10, #0x10
   463bc:	add	x14, x20, x13, lsl #3
   463c0:	add	x13, x12, #0x1
   463c4:	cmp	x13, x28
   463c8:	b.gt	46894 <__gmpn_mu_divappr_q@@Base+0x5e4>
   463cc:	ldr	x15, [x14, x12, lsl #3]
   463d0:	mov	x12, x13
   463d4:	adds	x15, x15, #0x1
   463d8:	str	x15, [x10], #8
   463dc:	b.cs	463c0 <__gmpn_mu_divappr_q@@Base+0x110>  // b.hs, b.nlast
   463e0:	cmp	x11, x27
   463e4:	b.eq	46438 <__gmpn_mu_divappr_q@@Base+0x188>  // b.none
   463e8:	cmp	x13, x28
   463ec:	b.ge	46438 <__gmpn_mu_divappr_q@@Base+0x188>  // b.tcont
   463f0:	add	x9, x9, x13
   463f4:	add	x9, x9, #0x1
   463f8:	ldr	x11, [x8, x9, lsl #3]
   463fc:	adds	x9, x9, #0x1
   46400:	str	x11, [x10], #8
   46404:	b.cc	463f8 <__gmpn_mu_divappr_q@@Base+0x148>  // b.lo, b.ul, b.last
   46408:	b	46438 <__gmpn_mu_divappr_q@@Base+0x188>
   4640c:	cmp	x28, #0x1
   46410:	b.lt	46438 <__gmpn_mu_divappr_q@@Base+0x188>  // b.tstop
   46414:	cmp	x11, x27
   46418:	b.eq	46438 <__gmpn_mu_divappr_q@@Base+0x188>  // b.none
   4641c:	add	x10, x19, x28, lsl #3
   46420:	add	x9, x9, #0x1
   46424:	add	x10, x10, #0x10
   46428:	ldr	x11, [x8, x9, lsl #3]
   4642c:	adds	x9, x9, #0x1
   46430:	str	x11, [x10], #8
   46434:	b.cc	46428 <__gmpn_mu_divappr_q@@Base+0x178>  // b.lo, b.ul, b.last
   46438:	add	x8, x27, x28, lsl #3
   4643c:	add	x2, x28, #0x1
   46440:	add	x3, x8, #0x8
   46444:	mov	x0, x19
   46448:	mov	x1, x27
   4644c:	bl	d080 <__gmpn_invertappr@plt>
   46450:	add	x1, x19, #0x8
   46454:	mov	x0, x19
   46458:	mov	x2, x28
   4645c:	bl	ca70 <__gmpn_copyi@plt>
   46460:	sub	x27, x24, x21
   46464:	add	x8, x25, x24, lsl #3
   46468:	add	x1, x25, x27, lsl #3
   4646c:	add	x24, x26, x27, lsl #3
   46470:	sub	x8, x8, #0x8
   46474:	mov	x9, x21
   46478:	stur	x1, [x29, #-8]
   4647c:	subs	x10, x9, #0x1
   46480:	b.lt	464a0 <__gmpn_mu_divappr_q@@Base+0x1f0>  // b.tstop
   46484:	add	x9, x20, x9, lsl #3
   46488:	ldr	x11, [x8], #-8
   4648c:	ldur	x9, [x9, #-8]
   46490:	cmp	x11, x9
   46494:	mov	x9, x10
   46498:	b.eq	4647c <__gmpn_mu_divappr_q@@Base+0x1cc>  // b.none
   4649c:	b.ls	464c0 <__gmpn_mu_divappr_q@@Base+0x210>  // b.plast
   464a0:	mov	x0, x23
   464a4:	mov	x2, x20
   464a8:	mov	x3, x21
   464ac:	bl	c2e0 <__gmpn_sub_n@plt>
   464b0:	mov	w8, wzr
   464b4:	mov	w0, #0x1                   	// #1
   464b8:	cbnz	x27, 464d8 <__gmpn_mu_divappr_q@@Base+0x228>
   464bc:	b	46874 <__gmpn_mu_divappr_q@@Base+0x5c4>
   464c0:	mov	x0, x23
   464c4:	mov	x2, x21
   464c8:	bl	ca70 <__gmpn_copyi@plt>
   464cc:	mov	x0, xzr
   464d0:	mov	w8, #0x1                   	// #1
   464d4:	cbz	x27, 46874 <__gmpn_mu_divappr_q@@Base+0x5c4>
   464d8:	cmp	x27, #0x1
   464dc:	str	w8, [sp, #4]
   464e0:	stp	x0, x27, [sp, #8]
   464e4:	b.lt	467dc <__gmpn_mu_divappr_q@@Base+0x52c>  // b.tstop
   464e8:	add	x8, x21, #0x1
   464ec:	stur	x8, [x29, #-32]
   464f0:	add	x8, x19, x21, lsl #4
   464f4:	sub	x9, x19, #0x8
   464f8:	add	x10, x21, x28
   464fc:	add	x8, x8, #0x8
   46500:	str	x9, [sp, #48]
   46504:	add	x9, x19, x28, lsl #3
   46508:	str	x8, [sp, #32]
   4650c:	add	x8, x19, x10, lsl #3
   46510:	add	x26, x23, x21, lsl #3
   46514:	stur	x19, [x29, #-16]
   46518:	add	x8, x8, #0x8
   4651c:	sub	x19, x9, #0x8
   46520:	mov	x25, x27
   46524:	str	x10, [sp, #40]
   46528:	str	x8, [sp, #24]
   4652c:	stur	x28, [x29, #-40]
   46530:	ldur	x2, [x29, #-16]
   46534:	subs	x8, x28, x25
   46538:	csel	x28, x25, x28, gt
   4653c:	sub	x22, x26, x28, lsl #3
   46540:	add	x8, x2, x8, lsl #3
   46544:	csel	x2, x8, x2, gt
   46548:	mov	x0, x26
   4654c:	mov	x1, x22
   46550:	mov	x3, x28
   46554:	sub	x24, x24, x28, lsl #3
   46558:	stur	x2, [x29, #-16]
   4655c:	bl	c9b0 <__gmpn_mul_n@plt>
   46560:	add	x27, x26, x28, lsl #3
   46564:	mov	x0, x24
   46568:	mov	x1, x27
   4656c:	mov	x2, x22
   46570:	mov	x3, x28
   46574:	bl	ca90 <__gmpn_add_n@plt>
   46578:	cbnz	x0, 468ac <__gmpn_mu_divappr_q@@Base+0x5fc>
   4657c:	subs	x25, x25, x28
   46580:	b.eq	467e0 <__gmpn_mu_divappr_q@@Base+0x530>  // b.none
   46584:	cmp	x28, #0x11
   46588:	stur	x25, [x29, #-24]
   4658c:	b.le	46634 <__gmpn_mu_divappr_q@@Base+0x384>
   46590:	ldur	x0, [x29, #-32]
   46594:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   46598:	mov	x22, x0
   4659c:	add	x6, x26, x0, lsl #3
   465a0:	mov	x0, x26
   465a4:	mov	x1, x22
   465a8:	mov	x2, x20
   465ac:	mov	x3, x21
   465b0:	mov	x4, x24
   465b4:	mov	x5, x28
   465b8:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   465bc:	add	x8, x28, x21
   465c0:	sub	x25, x8, x22
   465c4:	cmp	x25, #0x1
   465c8:	b.lt	466c4 <__gmpn_mu_divappr_q@@Base+0x414>  // b.tstop
   465cc:	sub	x2, x26, x25, lsl #3
   465d0:	mov	x0, x26
   465d4:	mov	x1, x26
   465d8:	mov	x3, x25
   465dc:	bl	c2e0 <__gmpn_sub_n@plt>
   465e0:	ldr	x8, [x26, x25, lsl #3]
   465e4:	subs	x8, x8, x0
   465e8:	str	x8, [x26, x25, lsl #3]
   465ec:	b.cs	4662c <__gmpn_mu_divappr_q@@Base+0x37c>  // b.hs, b.nlast
   465f0:	ldur	x10, [x29, #-40]
   465f4:	ldr	x11, [sp, #32]
   465f8:	mov	x9, xzr
   465fc:	sub	x8, x22, x25
   46600:	add	x10, x10, x28
   46604:	sub	x10, x10, x22
   46608:	add	x10, x11, x10, lsl #3
   4660c:	add	x11, x9, #0x1
   46610:	cmp	x11, x8
   46614:	b.ge	46650 <__gmpn_mu_divappr_q@@Base+0x3a0>  // b.tcont
   46618:	ldr	x12, [x10, x9, lsl #3]
   4661c:	sub	x13, x12, #0x1
   46620:	str	x13, [x10, x9, lsl #3]
   46624:	mov	x9, x11
   46628:	cbz	x12, 4660c <__gmpn_mu_divappr_q@@Base+0x35c>
   4662c:	mov	x8, xzr
   46630:	b	46654 <__gmpn_mu_divappr_q@@Base+0x3a4>
   46634:	mov	x0, x26
   46638:	mov	x1, x20
   4663c:	mov	x2, x21
   46640:	mov	x3, x24
   46644:	mov	x4, x28
   46648:	bl	ccf0 <__gmpn_mul@plt>
   4664c:	b	466c4 <__gmpn_mu_divappr_q@@Base+0x414>
   46650:	mov	w8, #0x1                   	// #1
   46654:	ldur	x11, [x29, #-40]
   46658:	ldp	x10, x12, [sp, #40]
   4665c:	sub	x9, x22, x21
   46660:	add	x11, x11, x22
   46664:	add	x10, x10, x22
   46668:	sub	x11, x11, x28
   4666c:	add	x10, x12, x10, lsl #3
   46670:	add	x11, x12, x11, lsl #3
   46674:	subs	x9, x9, #0x1
   46678:	b.lt	46694 <__gmpn_mu_divappr_q@@Base+0x3e4>  // b.tstop
   4667c:	ldr	x12, [x11], #-8
   46680:	ldr	x13, [x10], #-8
   46684:	cmp	x12, x13
   46688:	b.eq	46674 <__gmpn_mu_divappr_q@@Base+0x3c4>  // b.none
   4668c:	cset	w9, ls  // ls = plast
   46690:	b	46698 <__gmpn_mu_divappr_q@@Base+0x3e8>
   46694:	mov	x9, xzr
   46698:	subs	x8, x9, x8
   4669c:	b.cc	468c4 <__gmpn_mu_divappr_q@@Base+0x614>  // b.lo, b.ul, b.last
   466a0:	ldr	x9, [x26]
   466a4:	adds	x8, x9, x8
   466a8:	str	x8, [x26]
   466ac:	b.cc	466c4 <__gmpn_mu_divappr_q@@Base+0x414>  // b.lo, b.ul, b.last
   466b0:	ldr	x8, [sp, #24]
   466b4:	ldr	x9, [x8]
   466b8:	adds	x9, x9, #0x1
   466bc:	str	x9, [x8], #8
   466c0:	b.cs	466b4 <__gmpn_mu_divappr_q@@Base+0x404>  // b.hs, b.nlast
   466c4:	subs	x8, x21, x28
   466c8:	ldr	x8, [x23, x8, lsl #3]
   466cc:	ldr	x9, [x26, x21, lsl #3]
   466d0:	ldur	x1, [x29, #-8]
   466d4:	subs	x22, x21, x28
   466d8:	sub	x25, x8, x9
   466dc:	sub	x1, x1, x28, lsl #3
   466e0:	stur	x1, [x29, #-8]
   466e4:	b.ne	46700 <__gmpn_mu_divappr_q@@Base+0x450>  // b.any
   466e8:	mov	x0, x23
   466ec:	mov	x2, x26
   466f0:	mov	x3, x21
   466f4:	bl	c2e0 <__gmpn_sub_n@plt>
   466f8:	mov	x27, x0
   466fc:	b	4673c <__gmpn_mu_divappr_q@@Base+0x48c>
   46700:	mov	x0, x26
   46704:	mov	x2, x26
   46708:	mov	x3, x28
   4670c:	bl	c2e0 <__gmpn_sub_n@plt>
   46710:	mov	x4, x0
   46714:	mov	x0, x27
   46718:	mov	x1, x23
   4671c:	mov	x2, x27
   46720:	mov	x3, x22
   46724:	bl	c780 <__gmpn_sub_nc@plt>
   46728:	mov	x27, x0
   4672c:	mov	x0, x23
   46730:	mov	x1, x26
   46734:	mov	x2, x21
   46738:	bl	ca70 <__gmpn_copyi@plt>
   4673c:	subs	x22, x25, x27
   46740:	ldur	x25, [x29, #-24]
   46744:	b.eq	4677c <__gmpn_mu_divappr_q@@Base+0x4cc>  // b.none
   46748:	mov	x8, x24
   4674c:	ldr	x9, [x8]
   46750:	adds	x9, x9, #0x1
   46754:	str	x9, [x8], #8
   46758:	b.cs	4674c <__gmpn_mu_divappr_q@@Base+0x49c>  // b.hs, b.nlast
   4675c:	mov	x0, x23
   46760:	mov	x1, x23
   46764:	mov	x2, x20
   46768:	mov	x3, x21
   4676c:	bl	c2e0 <__gmpn_sub_n@plt>
   46770:	subs	x22, x22, x0
   46774:	b.ne	46748 <__gmpn_mu_divappr_q@@Base+0x498>  // b.any
   46778:	mov	x27, x0
   4677c:	mov	x8, x21
   46780:	subs	x9, x8, #0x1
   46784:	b.lt	467a4 <__gmpn_mu_divappr_q@@Base+0x4f4>  // b.tstop
   46788:	ldr	x10, [x19, x8, lsl #3]
   4678c:	add	x8, x20, x8, lsl #3
   46790:	ldur	x8, [x8, #-8]
   46794:	cmp	x10, x8
   46798:	mov	x8, x9
   4679c:	b.eq	46780 <__gmpn_mu_divappr_q@@Base+0x4d0>  // b.none
   467a0:	b.ls	467d0 <__gmpn_mu_divappr_q@@Base+0x520>  // b.plast
   467a4:	mov	x8, x24
   467a8:	ldr	x9, [x8]
   467ac:	adds	x9, x9, #0x1
   467b0:	str	x9, [x8], #8
   467b4:	b.cs	467a8 <__gmpn_mu_divappr_q@@Base+0x4f8>  // b.hs, b.nlast
   467b8:	mov	x0, x23
   467bc:	mov	x1, x23
   467c0:	mov	x2, x20
   467c4:	mov	x3, x21
   467c8:	bl	c2e0 <__gmpn_sub_n@plt>
   467cc:	mov	x27, x0
   467d0:	cmp	x25, #0x0
   467d4:	b.gt	46530 <__gmpn_mu_divappr_q@@Base+0x280>
   467d8:	b	467e4 <__gmpn_mu_divappr_q@@Base+0x534>
   467dc:	b	467e4 <__gmpn_mu_divappr_q@@Base+0x534>
   467e0:	mov	x27, xzr
   467e4:	ldr	x8, [x24]
   467e8:	ldr	x19, [sp, #8]
   467ec:	add	x9, x8, #0x3
   467f0:	cmn	x8, #0x3
   467f4:	str	x9, [x24]
   467f8:	b.cc	46828 <__gmpn_mu_divappr_q@@Base+0x578>  // b.lo, b.ul, b.last
   467fc:	ldr	x10, [sp, #16]
   46800:	ldr	w11, [sp, #4]
   46804:	mov	w8, #0x1                   	// #1
   46808:	cmp	x8, x10
   4680c:	b.ge	46838 <__gmpn_mu_divappr_q@@Base+0x588>  // b.tcont
   46810:	ldr	x9, [x24, x8, lsl #3]
   46814:	adds	x9, x9, #0x1
   46818:	str	x9, [x24, x8, lsl #3]
   4681c:	add	x8, x8, #0x1
   46820:	b.cs	46808 <__gmpn_mu_divappr_q@@Base+0x558>  // b.hs, b.nlast
   46824:	b	46830 <__gmpn_mu_divappr_q@@Base+0x580>
   46828:	ldr	x10, [sp, #16]
   4682c:	ldr	w11, [sp, #4]
   46830:	mov	x8, xzr
   46834:	b	4683c <__gmpn_mu_divappr_q@@Base+0x58c>
   46838:	mov	x8, #0xffffffffffffffff    	// #-1
   4683c:	cmp	x27, x8
   46840:	cset	w8, eq  // eq = none
   46844:	orr	w8, w11, w8
   46848:	csinc	x9, x19, xzr, eq  // eq = none
   4684c:	cmp	w8, #0x0
   46850:	csel	x0, x9, x19, ne  // ne = any
   46854:	tbnz	w8, #0, 46874 <__gmpn_mu_divappr_q@@Base+0x5c4>
   46858:	cmp	x10, #0x1
   4685c:	b.lt	46874 <__gmpn_mu_divappr_q@@Base+0x5c4>  // b.tstop
   46860:	lsl	x2, x10, #3
   46864:	mov	w1, #0xff                  	// #255
   46868:	mov	x0, x24
   4686c:	bl	c610 <memset@plt>
   46870:	mov	x0, x19
   46874:	ldp	x20, x19, [sp, #176]
   46878:	ldp	x22, x21, [sp, #160]
   4687c:	ldp	x24, x23, [sp, #144]
   46880:	ldp	x26, x25, [sp, #128]
   46884:	ldp	x28, x27, [sp, #112]
   46888:	ldp	x29, x30, [sp, #96]
   4688c:	add	sp, sp, #0xc0
   46890:	ret
   46894:	cbz	x28, 46460 <__gmpn_mu_divappr_q@@Base+0x1b0>
   46898:	lsl	x2, x28, #3
   4689c:	mov	x0, x19
   468a0:	mov	w1, wzr
   468a4:	bl	c610 <memset@plt>
   468a8:	b	46460 <__gmpn_mu_divappr_q@@Base+0x1b0>
   468ac:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   468b0:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   468b4:	add	x0, x0, #0x8a0
   468b8:	add	x2, x2, #0x871
   468bc:	mov	w1, #0xd0                  	// #208
   468c0:	bl	c6e0 <__gmp_assert_fail@plt>
   468c4:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   468c8:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   468cc:	add	x0, x0, #0x8a0
   468d0:	add	x2, x2, #0x897
   468d4:	mov	w1, #0xe6                  	// #230
   468d8:	bl	c6e0 <__gmp_assert_fail@plt>

00000000000468dc <__gmpn_mu_divappr_q_itch@@Base>:
   468dc:	stp	x29, x30, [sp, #-32]!
   468e0:	stp	x20, x19, [sp, #16]
   468e4:	sub	x20, x0, x1
   468e8:	add	x8, x20, #0x1
   468ec:	cmp	x8, x1
   468f0:	csinc	x19, x1, x20, ge  // ge = tcont
   468f4:	mov	x29, sp
   468f8:	cbz	w2, 46910 <__gmpn_mu_divappr_q_itch@@Base+0x34>
   468fc:	cmp	x19, x20
   46900:	csel	x8, x19, x20, lt  // lt = tstop
   46904:	sub	x8, x8, #0x1
   46908:	sxtw	x9, w2
   4690c:	b	46924 <__gmpn_mu_divappr_q_itch@@Base+0x48>
   46910:	cmp	x20, x19
   46914:	b.le	46974 <__gmpn_mu_divappr_q_itch@@Base+0x98>
   46918:	sub	x8, x20, #0x1
   4691c:	sdiv	x9, x8, x19
   46920:	add	x9, x9, #0x1
   46924:	sdiv	x8, x8, x9
   46928:	add	x20, x8, #0x1
   4692c:	add	x0, x19, #0x1
   46930:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   46934:	asr	x8, x0, #1
   46938:	cmp	x8, x20
   4693c:	csel	x10, x0, x8, lt  // lt = tstop
   46940:	cmp	x8, x19
   46944:	csel	x8, x10, xzr, lt  // lt = tstop
   46948:	add	x10, x19, x0, lsl #1
   4694c:	add	x9, x20, x20, lsl #1
   46950:	add	x8, x10, x8
   46954:	add	x9, x9, #0x4
   46958:	add	x8, x8, #0x4
   4695c:	cmp	x8, x9
   46960:	csel	x8, x8, x9, gt
   46964:	add	x0, x8, x20
   46968:	ldp	x20, x19, [sp, #16]
   4696c:	ldp	x29, x30, [sp], #32
   46970:	ret
   46974:	add	x8, x20, x20, lsl #1
   46978:	cmp	x8, x19
   4697c:	b.le	4692c <__gmpn_mu_divappr_q_itch@@Base+0x50>
   46980:	sub	x8, x20, #0x1
   46984:	cmp	x8, #0x0
   46988:	csel	x8, x20, x8, lt  // lt = tstop
   4698c:	asr	x8, x8, #1
   46990:	b	46928 <__gmpn_mu_divappr_q_itch@@Base+0x4c>

0000000000046994 <__gmpn_mu_div_q@@Base>:
   46994:	sub	sp, sp, #0x80
   46998:	stp	x22, x21, [sp, #96]
   4699c:	sub	x21, x2, x4
   469a0:	stp	x29, x30, [sp, #32]
   469a4:	add	x29, sp, #0x20
   469a8:	add	x22, x21, #0x1
   469ac:	stp	x28, x27, [sp, #48]
   469b0:	stp	x26, x25, [sp, #64]
   469b4:	mov	x26, x1
   469b8:	mov	x28, x0
   469bc:	lsl	x1, x22, #3
   469c0:	sub	x0, x29, #0x8
   469c4:	stp	x24, x23, [sp, #80]
   469c8:	stp	x20, x19, [sp, #112]
   469cc:	mov	x19, x5
   469d0:	mov	x24, x4
   469d4:	mov	x27, x3
   469d8:	mov	x23, x2
   469dc:	stur	xzr, [x29, #-8]
   469e0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   469e4:	cmp	x21, x24
   469e8:	mov	x25, x0
   469ec:	str	x0, [sp, #16]
   469f0:	b.ge	46a48 <__gmpn_mu_div_q@@Base+0xb4>  // b.tcont
   469f4:	lsl	x9, x21, #1
   469f8:	mov	x10, #0xfffffffffffffffe    	// #-2
   469fc:	add	x8, x26, x23, lsl #3
   46a00:	add	x11, x27, x24, lsl #3
   46a04:	mvn	x12, x21
   46a08:	add	x2, x9, #0x2
   46a0c:	sub	x9, x10, x21, lsl #1
   46a10:	add	x1, x8, x9, lsl #3
   46a14:	add	x3, x11, x12, lsl #3
   46a18:	mov	x0, x25
   46a1c:	mov	x4, x22
   46a20:	mov	x5, x19
   46a24:	bl	c730 <__gmpn_mu_divappr_q@plt>
   46a28:	ldr	x8, [x25]
   46a2c:	mov	x20, x0
   46a30:	cmp	x8, #0x7
   46a34:	b.cc	46ad0 <__gmpn_mu_div_q@@Base+0x13c>  // b.lo, b.ul, b.last
   46a38:	ldr	x8, [sp, #16]
   46a3c:	mov	x0, x28
   46a40:	add	x1, x8, #0x8
   46a44:	b	46c74 <__gmpn_mu_div_q@@Base+0x2e0>
   46a48:	add	x22, x23, #0x1
   46a4c:	lsl	x1, x22, #3
   46a50:	sub	x0, x29, #0x8
   46a54:	str	x28, [sp, #8]
   46a58:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   46a5c:	add	x20, x0, #0x8
   46a60:	mov	x28, x0
   46a64:	mov	x0, x20
   46a68:	mov	x1, x26
   46a6c:	mov	x2, x23
   46a70:	bl	ca70 <__gmpn_copyi@plt>
   46a74:	add	x8, x20, x23, lsl #3
   46a78:	sub	x0, x8, x24, lsl #3
   46a7c:	add	x8, x28, x23, lsl #3
   46a80:	mov	x9, x24
   46a84:	str	xzr, [x28]
   46a88:	subs	x10, x9, #0x1
   46a8c:	b.lt	46ab0 <__gmpn_mu_div_q@@Base+0x11c>  // b.tstop
   46a90:	add	x9, x27, x9, lsl #3
   46a94:	ldr	x11, [x8], #-8
   46a98:	ldur	x12, [x9, #-8]
   46a9c:	mov	x9, x10
   46aa0:	cmp	x11, x12
   46aa4:	b.eq	46a88 <__gmpn_mu_div_q@@Base+0xf4>  // b.none
   46aa8:	cmp	x11, x12
   46aac:	b.ls	46b74 <__gmpn_mu_div_q@@Base+0x1e0>  // b.plast
   46ab0:	mov	x1, x0
   46ab4:	mov	x2, x27
   46ab8:	mov	x3, x24
   46abc:	bl	c2e0 <__gmpn_sub_n@plt>
   46ac0:	mov	w8, #0x1                   	// #1
   46ac4:	mov	w20, #0x1                   	// #1
   46ac8:	str	x8, [sp]
   46acc:	b	46b7c <__gmpn_mu_div_q@@Base+0x1e8>
   46ad0:	lsl	x1, x23, #3
   46ad4:	sub	x0, x29, #0x8
   46ad8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   46adc:	ldr	x25, [sp, #16]
   46ae0:	mov	x1, x27
   46ae4:	mov	x2, x24
   46ae8:	mov	x4, x21
   46aec:	add	x19, x25, #0x8
   46af0:	mov	x3, x19
   46af4:	mov	x22, x0
   46af8:	bl	ccf0 <__gmpn_mul@plt>
   46afc:	cbz	x20, 46b18 <__gmpn_mu_div_q@@Base+0x184>
   46b00:	add	x0, x22, x21, lsl #3
   46b04:	mov	x1, x0
   46b08:	mov	x2, x27
   46b0c:	mov	x3, x24
   46b10:	bl	ca90 <__gmpn_add_n@plt>
   46b14:	cbnz	x0, 46b44 <__gmpn_mu_div_q@@Base+0x1b0>
   46b18:	sub	x8, x26, #0x8
   46b1c:	sub	x9, x22, #0x8
   46b20:	mov	x10, x23
   46b24:	subs	x11, x10, #0x1
   46b28:	b.lt	46c6c <__gmpn_mu_div_q@@Base+0x2d8>  // b.tstop
   46b2c:	ldr	x12, [x9, x10, lsl #3]
   46b30:	ldr	x10, [x8, x10, lsl #3]
   46b34:	cmp	x12, x10
   46b38:	mov	x10, x11
   46b3c:	b.eq	46b24 <__gmpn_mu_div_q@@Base+0x190>  // b.none
   46b40:	b.ls	46c6c <__gmpn_mu_div_q@@Base+0x2d8>  // b.plast
   46b44:	ldr	x8, [x19]
   46b48:	sub	x9, x8, #0x1
   46b4c:	str	x9, [x28]
   46b50:	cbz	x8, 46c80 <__gmpn_mu_div_q@@Base+0x2ec>
   46b54:	cmp	x21, #0x2
   46b58:	mov	x8, xzr
   46b5c:	b.lt	46d50 <__gmpn_mu_div_q@@Base+0x3bc>  // b.tstop
   46b60:	cmp	x19, x28
   46b64:	b.eq	46d50 <__gmpn_mu_div_q@@Base+0x3bc>  // b.none
   46b68:	add	x0, x28, #0x8
   46b6c:	add	x1, x25, #0x10
   46b70:	b	46c5c <__gmpn_mu_div_q@@Base+0x2c8>
   46b74:	str	xzr, [sp]
   46b78:	mov	w20, wzr
   46b7c:	mov	x0, x25
   46b80:	mov	x1, x28
   46b84:	mov	x2, x22
   46b88:	mov	x3, x27
   46b8c:	mov	x4, x24
   46b90:	mov	x5, x19
   46b94:	bl	c730 <__gmpn_mu_divappr_q@plt>
   46b98:	cbz	x0, 46ba0 <__gmpn_mu_div_q@@Base+0x20c>
   46b9c:	tbz	x21, #63, 46d88 <__gmpn_mu_div_q@@Base+0x3f4>
   46ba0:	ldr	x8, [x25], #8
   46ba4:	cmp	x8, #0x5
   46ba8:	b.cc	46bc4 <__gmpn_mu_div_q@@Base+0x230>  // b.lo, b.ul, b.last
   46bac:	ldr	x0, [sp, #8]
   46bb0:	mov	x1, x25
   46bb4:	mov	x2, x21
   46bb8:	bl	ca70 <__gmpn_copyi@plt>
   46bbc:	ldr	x20, [sp]
   46bc0:	b	46d54 <__gmpn_mu_div_q@@Base+0x3c0>
   46bc4:	mov	x0, x28
   46bc8:	mov	x1, x25
   46bcc:	mov	x2, x21
   46bd0:	mov	x3, x27
   46bd4:	mov	x4, x24
   46bd8:	bl	ccf0 <__gmpn_mul@plt>
   46bdc:	cbz	w20, 46bf8 <__gmpn_mu_div_q@@Base+0x264>
   46be0:	add	x0, x28, x21, lsl #3
   46be4:	mov	x1, x0
   46be8:	mov	x2, x27
   46bec:	mov	x3, x24
   46bf0:	bl	ca90 <__gmpn_add_n@plt>
   46bf4:	cbnz	x0, 46c24 <__gmpn_mu_div_q@@Base+0x290>
   46bf8:	sub	x8, x26, #0x8
   46bfc:	sub	x9, x28, #0x8
   46c00:	mov	x10, x23
   46c04:	subs	x11, x10, #0x1
   46c08:	b.lt	46bac <__gmpn_mu_div_q@@Base+0x218>  // b.tstop
   46c0c:	ldr	x12, [x9, x10, lsl #3]
   46c10:	ldr	x10, [x8, x10, lsl #3]
   46c14:	cmp	x12, x10
   46c18:	mov	x10, x11
   46c1c:	b.eq	46c04 <__gmpn_mu_div_q@@Base+0x270>  // b.none
   46c20:	b.ls	46bac <__gmpn_mu_div_q@@Base+0x218>  // b.plast
   46c24:	ldr	x8, [x25]
   46c28:	ldr	x15, [sp, #8]
   46c2c:	sub	x9, x8, #0x1
   46c30:	str	x9, [x15]
   46c34:	cbz	x8, 46cd4 <__gmpn_mu_div_q@@Base+0x340>
   46c38:	cmp	x21, #0x2
   46c3c:	mov	x8, xzr
   46c40:	b.lt	46d4c <__gmpn_mu_div_q@@Base+0x3b8>  // b.tstop
   46c44:	ldr	x20, [sp]
   46c48:	cmp	x25, x15
   46c4c:	b.eq	46d50 <__gmpn_mu_div_q@@Base+0x3bc>  // b.none
   46c50:	ldr	x8, [sp, #16]
   46c54:	add	x0, x15, #0x8
   46c58:	add	x1, x8, #0x10
   46c5c:	mvn	x8, x24
   46c60:	add	x8, x8, x23
   46c64:	lsl	x2, x8, #3
   46c68:	b	46d40 <__gmpn_mu_div_q@@Base+0x3ac>
   46c6c:	mov	x0, x28
   46c70:	mov	x1, x19
   46c74:	mov	x2, x21
   46c78:	bl	ca70 <__gmpn_copyi@plt>
   46c7c:	b	46d54 <__gmpn_mu_div_q@@Base+0x3c0>
   46c80:	mov	x9, xzr
   46c84:	add	x11, x25, #0x10
   46c88:	mov	w8, #0x1                   	// #1
   46c8c:	mov	w10, #0x1                   	// #1
   46c90:	cmp	x10, x21
   46c94:	b.ge	46d50 <__gmpn_mu_div_q@@Base+0x3bc>  // b.tcont
   46c98:	ldr	x12, [x11, x9]
   46c9c:	add	x13, x28, x9
   46ca0:	add	x10, x10, #0x1
   46ca4:	add	x9, x9, #0x8
   46ca8:	sub	x14, x12, #0x1
   46cac:	str	x14, [x13, #8]
   46cb0:	cbz	x12, 46c90 <__gmpn_mu_div_q@@Base+0x2fc>
   46cb4:	cmp	x19, x28
   46cb8:	mov	x8, xzr
   46cbc:	b.eq	46d50 <__gmpn_mu_div_q@@Base+0x3bc>  // b.none
   46cc0:	cmp	x10, x21
   46cc4:	b.ge	46d50 <__gmpn_mu_div_q@@Base+0x3bc>  // b.tcont
   46cc8:	add	x8, x28, x9
   46ccc:	add	x9, x25, x9
   46cd0:	b	46d30 <__gmpn_mu_div_q@@Base+0x39c>
   46cd4:	ldr	x8, [sp, #16]
   46cd8:	mov	x9, xzr
   46cdc:	mov	w10, #0x1                   	// #1
   46ce0:	add	x11, x8, #0x10
   46ce4:	mov	w8, #0x1                   	// #1
   46ce8:	cmp	x10, x21
   46cec:	b.ge	46d4c <__gmpn_mu_div_q@@Base+0x3b8>  // b.tcont
   46cf0:	ldr	x12, [x11, x9]
   46cf4:	add	x13, x15, x9
   46cf8:	add	x10, x10, #0x1
   46cfc:	add	x9, x9, #0x8
   46d00:	sub	x14, x12, #0x1
   46d04:	str	x14, [x13, #8]
   46d08:	cbz	x12, 46ce8 <__gmpn_mu_div_q@@Base+0x354>
   46d0c:	cmp	x25, x15
   46d10:	mov	x8, xzr
   46d14:	b.eq	46d4c <__gmpn_mu_div_q@@Base+0x3b8>  // b.none
   46d18:	ldr	x20, [sp]
   46d1c:	cmp	x10, x21
   46d20:	b.ge	46d50 <__gmpn_mu_div_q@@Base+0x3bc>  // b.tcont
   46d24:	ldr	x11, [sp, #16]
   46d28:	add	x8, x15, x9
   46d2c:	add	x9, x11, x9
   46d30:	sub	x10, x21, x10
   46d34:	add	x0, x8, #0x8
   46d38:	add	x1, x9, #0x10
   46d3c:	lsl	x2, x10, #3
   46d40:	bl	bee0 <memcpy@plt>
   46d44:	mov	x8, xzr
   46d48:	b	46d50 <__gmpn_mu_div_q@@Base+0x3bc>
   46d4c:	ldr	x20, [sp]
   46d50:	sub	x20, x20, x8
   46d54:	ldur	x0, [x29, #-8]
   46d58:	cbnz	x0, 46d80 <__gmpn_mu_div_q@@Base+0x3ec>
   46d5c:	mov	x0, x20
   46d60:	ldp	x20, x19, [sp, #112]
   46d64:	ldp	x22, x21, [sp, #96]
   46d68:	ldp	x24, x23, [sp, #80]
   46d6c:	ldp	x26, x25, [sp, #64]
   46d70:	ldp	x28, x27, [sp, #48]
   46d74:	ldp	x29, x30, [sp, #32]
   46d78:	add	sp, sp, #0x80
   46d7c:	ret
   46d80:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   46d84:	b	46d5c <__gmpn_mu_div_q@@Base+0x3c8>
   46d88:	sub	x8, x22, x24
   46d8c:	lsl	x2, x8, #3
   46d90:	mov	w1, #0xff                  	// #255
   46d94:	mov	x0, x25
   46d98:	bl	c610 <memset@plt>
   46d9c:	b	46ba0 <__gmpn_mu_div_q@@Base+0x20c>

0000000000046da0 <__gmpn_mu_div_q_itch@@Base>:
   46da0:	sub	x8, x0, x1
   46da4:	lsl	x9, x8, #1
   46da8:	cmp	x8, x1
   46dac:	add	x9, x9, #0x2
   46db0:	csinc	x1, x1, x8, ge  // ge = tcont
   46db4:	csinc	x0, x9, x0, lt  // lt = tstop
   46db8:	b	c0f0 <__gmpn_mu_divappr_q_itch@plt>
   46dbc:	nop

0000000000046dc0 <__gmpn_bdiv_q_1@@Base>:
   46dc0:	rbit	x6, x3
   46dc4:	clz	x5, x6
   46dc8:	lsr	x3, x3, x5
   46dcc:	adrp	x7, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   46dd0:	ubfx	x6, x3, #1, #7
   46dd4:	ldr	x7, [x7, #3952]
   46dd8:	ldrb	w6, [x7, x6]
   46ddc:	ubfiz	x7, x6, #1, #8
   46de0:	umull	x6, w6, w6
   46de4:	msub	x6, x6, x3, x7
   46de8:	lsl	x7, x6, #1
   46dec:	mul	x6, x6, x6
   46df0:	msub	x6, x6, x3, x7
   46df4:	lsl	x7, x6, #1
   46df8:	mul	x6, x6, x6
   46dfc:	msub	x4, x6, x3, x7
   46e00:	b	c500 <__gmpn_pi1_bdiv_q_1@plt>
   46e04:	nop

0000000000046e08 <__gmpn_pi1_bdiv_q_1@@Base>:
   46e08:	sub	x2, x2, #0x1
   46e0c:	subs	x6, x6, x6
   46e10:	ldr	x9, [x1], #8
   46e14:	cbz	x5, 46e5c <__gmpn_pi1_bdiv_q_1@@Base+0x54>
   46e18:	lsr	x12, x9, x5
   46e1c:	cbz	x2, 46e4c <__gmpn_pi1_bdiv_q_1@@Base+0x44>
   46e20:	neg	x8, x5
   46e24:	ldr	x9, [x1], #8
   46e28:	lsl	x7, x9, x8
   46e2c:	orr	x7, x7, x12
   46e30:	sbcs	x6, x7, x6
   46e34:	mul	x7, x6, x4
   46e38:	str	x7, [x0], #8
   46e3c:	lsr	x12, x9, x5
   46e40:	umulh	x6, x7, x3
   46e44:	sub	x2, x2, #0x1
   46e48:	cbnz	x2, 46e24 <__gmpn_pi1_bdiv_q_1@@Base+0x1c>
   46e4c:	sbcs	x6, x12, x6
   46e50:	mul	x6, x6, x4
   46e54:	str	x6, [x0]
   46e58:	ret
   46e5c:	mul	x5, x9, x4
   46e60:	str	x5, [x0], #8
   46e64:	cbz	x2, 46e84 <__gmpn_pi1_bdiv_q_1@@Base+0x7c>
   46e68:	ldr	x9, [x1], #8
   46e6c:	umulh	x5, x5, x3
   46e70:	sbcs	x5, x9, x5
   46e74:	mul	x5, x5, x4
   46e78:	str	x5, [x0], #8
   46e7c:	sub	x2, x2, #0x1
   46e80:	cbnz	x2, 46e68 <__gmpn_pi1_bdiv_q_1@@Base+0x60>
   46e84:	ret

0000000000046e88 <__gmpn_sbpi1_bdiv_q@@Base>:
   46e88:	stp	x29, x30, [sp, #-96]!
   46e8c:	stp	x26, x25, [sp, #32]
   46e90:	stp	x24, x23, [sp, #48]
   46e94:	stp	x22, x21, [sp, #64]
   46e98:	stp	x20, x19, [sp, #80]
   46e9c:	mov	x20, x5
   46ea0:	mov	x23, x4
   46ea4:	mov	x21, x3
   46ea8:	mov	x22, x1
   46eac:	subs	x25, x2, x4
   46eb0:	mov	x19, x0
   46eb4:	str	x27, [sp, #16]
   46eb8:	mov	x29, sp
   46ebc:	b.le	46f5c <__gmpn_sbpi1_bdiv_q@@Base+0xd4>
   46ec0:	ldr	x8, [x22]
   46ec4:	mvn	x9, x23
   46ec8:	add	x26, x9, x2
   46ecc:	mov	x0, x22
   46ed0:	mul	x24, x8, x20
   46ed4:	mov	x1, x21
   46ed8:	mov	x2, x23
   46edc:	mov	x3, x24
   46ee0:	bl	d420 <__gmpn_addmul_1@plt>
   46ee4:	cmp	x26, #0x1
   46ee8:	b.lt	46f40 <__gmpn_sbpi1_bdiv_q@@Base+0xb8>  // b.tstop
   46eec:	mov	x26, xzr
   46ef0:	mov	w27, #0x2                   	// #2
   46ef4:	str	x24, [x19], #8
   46ef8:	ldr	x8, [x22, x23, lsl #3]
   46efc:	adds	x9, x0, x26
   46f00:	cset	w10, cs  // cs = hs, nlast
   46f04:	csinc	x11, x27, xzr, cs  // cs = hs, nlast
   46f08:	adds	x8, x8, x9
   46f0c:	str	x8, [x22, x23, lsl #3]
   46f10:	ldr	x8, [x22, #8]!
   46f14:	mov	x1, x21
   46f18:	mov	x2, x23
   46f1c:	csel	x26, x10, x11, cc  // cc = lo, ul, last
   46f20:	mul	x24, x8, x20
   46f24:	mov	x0, x22
   46f28:	mov	x3, x24
   46f2c:	bl	d420 <__gmpn_addmul_1@plt>
   46f30:	sub	x25, x25, #0x1
   46f34:	cmp	x25, #0x1
   46f38:	b.gt	46ef4 <__gmpn_sbpi1_bdiv_q@@Base+0x6c>
   46f3c:	b	46f44 <__gmpn_sbpi1_bdiv_q@@Base+0xbc>
   46f40:	mov	x26, xzr
   46f44:	str	x24, [x19], #8
   46f48:	ldr	x8, [x22, x23, lsl #3]
   46f4c:	add	x9, x0, x26
   46f50:	add	x8, x9, x8
   46f54:	str	x8, [x22, x23, lsl #3]
   46f58:	add	x22, x22, #0x8
   46f5c:	ldr	x8, [x22]
   46f60:	cmp	x23, #0x2
   46f64:	mul	x24, x8, x20
   46f68:	b.lt	46f98 <__gmpn_sbpi1_bdiv_q@@Base+0x110>  // b.tstop
   46f6c:	mov	x0, x22
   46f70:	mov	x1, x21
   46f74:	mov	x2, x23
   46f78:	mov	x3, x24
   46f7c:	bl	d420 <__gmpn_addmul_1@plt>
   46f80:	str	x24, [x19], #8
   46f84:	ldr	x8, [x22, #8]!
   46f88:	cmp	x23, #0x2
   46f8c:	sub	x23, x23, #0x1
   46f90:	mul	x24, x8, x20
   46f94:	b.gt	46f6c <__gmpn_sbpi1_bdiv_q@@Base+0xe4>
   46f98:	str	x24, [x19]
   46f9c:	ldp	x20, x19, [sp, #80]
   46fa0:	ldp	x22, x21, [sp, #64]
   46fa4:	ldp	x24, x23, [sp, #48]
   46fa8:	ldp	x26, x25, [sp, #32]
   46fac:	ldr	x27, [sp, #16]
   46fb0:	ldp	x29, x30, [sp], #96
   46fb4:	ret

0000000000046fb8 <__gmpn_sbpi1_bdiv_qr@@Base>:
   46fb8:	stp	x29, x30, [sp, #-96]!
   46fbc:	cmp	x2, x4
   46fc0:	str	x27, [sp, #16]
   46fc4:	stp	x26, x25, [sp, #32]
   46fc8:	stp	x24, x23, [sp, #48]
   46fcc:	stp	x22, x21, [sp, #64]
   46fd0:	stp	x20, x19, [sp, #80]
   46fd4:	mov	x29, sp
   46fd8:	b.eq	4704c <__gmpn_sbpi1_bdiv_qr@@Base+0x94>  // b.none
   46fdc:	mov	x19, x5
   46fe0:	mov	x20, x4
   46fe4:	mov	x21, x3
   46fe8:	mov	x22, x2
   46fec:	mov	x23, x1
   46ff0:	mov	x24, x0
   46ff4:	mov	x25, xzr
   46ff8:	mov	w27, #0x2                   	// #2
   46ffc:	ldr	x8, [x23]
   47000:	mov	x0, x23
   47004:	mov	x1, x21
   47008:	mov	x2, x20
   4700c:	mul	x26, x8, x19
   47010:	mov	x3, x26
   47014:	bl	d420 <__gmpn_addmul_1@plt>
   47018:	str	x26, [x24], #8
   4701c:	ldr	x9, [x23, x20, lsl #3]
   47020:	adds	x8, x0, x25
   47024:	sub	x22, x22, #0x1
   47028:	cset	w10, cs  // cs = hs, nlast
   4702c:	csinc	x11, x27, xzr, cs  // cs = hs, nlast
   47030:	adds	x8, x9, x8
   47034:	csel	x25, x10, x11, cc  // cc = lo, ul, last
   47038:	str	x8, [x23, x20, lsl #3]
   4703c:	cmp	x20, x22
   47040:	add	x23, x23, #0x8
   47044:	b.ne	46ffc <__gmpn_sbpi1_bdiv_qr@@Base+0x44>  // b.any
   47048:	b	47050 <__gmpn_sbpi1_bdiv_qr@@Base+0x98>
   4704c:	mov	x25, xzr
   47050:	mov	x0, x25
   47054:	ldp	x20, x19, [sp, #80]
   47058:	ldp	x22, x21, [sp, #64]
   4705c:	ldp	x24, x23, [sp, #48]
   47060:	ldp	x26, x25, [sp, #32]
   47064:	ldr	x27, [sp, #16]
   47068:	ldp	x29, x30, [sp], #96
   4706c:	ret

0000000000047070 <__gmpn_sbpi1_bdiv_r@@Base>:
   47070:	stp	x29, x30, [sp, #-80]!
   47074:	cmp	x1, x3
   47078:	str	x25, [sp, #16]
   4707c:	stp	x24, x23, [sp, #32]
   47080:	stp	x22, x21, [sp, #48]
   47084:	stp	x20, x19, [sp, #64]
   47088:	mov	x29, sp
   4708c:	b.eq	470f4 <__gmpn_sbpi1_bdiv_r@@Base+0x84>  // b.none
   47090:	mov	x19, x4
   47094:	mov	x20, x3
   47098:	mov	x21, x2
   4709c:	mov	x22, x1
   470a0:	mov	x23, x0
   470a4:	mov	x24, xzr
   470a8:	mov	w25, #0x2                   	// #2
   470ac:	ldr	x8, [x23]
   470b0:	mov	x0, x23
   470b4:	mov	x1, x21
   470b8:	mov	x2, x20
   470bc:	mul	x3, x8, x19
   470c0:	bl	d420 <__gmpn_addmul_1@plt>
   470c4:	ldr	x9, [x23, x20, lsl #3]
   470c8:	adds	x8, x0, x24
   470cc:	sub	x22, x22, #0x1
   470d0:	cset	w10, cs  // cs = hs, nlast
   470d4:	csinc	x11, x25, xzr, cs  // cs = hs, nlast
   470d8:	adds	x8, x8, x9
   470dc:	csel	x24, x10, x11, cc  // cc = lo, ul, last
   470e0:	str	x8, [x23, x20, lsl #3]
   470e4:	cmp	x20, x22
   470e8:	add	x23, x23, #0x8
   470ec:	b.ne	470ac <__gmpn_sbpi1_bdiv_r@@Base+0x3c>  // b.any
   470f0:	b	470f8 <__gmpn_sbpi1_bdiv_r@@Base+0x88>
   470f4:	mov	x24, xzr
   470f8:	mov	x0, x24
   470fc:	ldp	x20, x19, [sp, #64]
   47100:	ldp	x22, x21, [sp, #48]
   47104:	ldp	x24, x23, [sp, #32]
   47108:	ldr	x25, [sp, #16]
   4710c:	ldp	x29, x30, [sp], #80
   47110:	ret

0000000000047114 <__gmpn_dcpi1_bdiv_q@@Base>:
   47114:	stp	x29, x30, [sp, #-96]!
   47118:	stp	x28, x27, [sp, #16]
   4711c:	stp	x26, x25, [sp, #32]
   47120:	stp	x24, x23, [sp, #48]
   47124:	stp	x22, x21, [sp, #64]
   47128:	stp	x20, x19, [sp, #80]
   4712c:	mov	x29, sp
   47130:	sub	sp, sp, #0x20
   47134:	lsl	x28, x4, #3
   47138:	add	x9, x28, #0xf
   4713c:	mov	x8, sp
   47140:	and	x9, x9, #0xfffffffffffffff0
   47144:	mov	x26, x2
   47148:	mov	x24, x1
   4714c:	sub	x21, x8, x9
   47150:	stur	x3, [x29, #-8]
   47154:	mov	sp, x21
   47158:	cmp	x2, x4
   4715c:	b.le	471d0 <__gmpn_dcpi1_bdiv_q@@Base+0xbc>
   47160:	lsl	x11, x26, #3
   47164:	sub	x11, x11, x4, lsl #3
   47168:	add	x9, x24, x26, lsl #3
   4716c:	add	x11, x11, x21
   47170:	mov	x22, x4
   47174:	neg	x8, x4, lsl #3
   47178:	add	x10, x9, #0x8
   4717c:	add	x11, x11, #0x8
   47180:	mov	x25, x26
   47184:	stur	x5, [x29, #-16]
   47188:	sub	x25, x25, x22
   4718c:	mov	x19, x10
   47190:	mov	x23, x9
   47194:	mov	x20, x11
   47198:	add	x10, x10, x8
   4719c:	add	x9, x9, x8
   471a0:	cmp	x25, x22
   471a4:	add	x11, x11, x8
   471a8:	b.gt	47188 <__gmpn_dcpi1_bdiv_q@@Base+0x74>
   471ac:	cmp	x25, #0x26
   471b0:	stur	x0, [x29, #-24]
   471b4:	b.le	471ec <__gmpn_dcpi1_bdiv_q@@Base+0xd8>
   471b8:	ldp	x4, x2, [x29, #-16]
   471bc:	mov	x1, x24
   471c0:	mov	x3, x25
   471c4:	mov	x5, x21
   471c8:	bl	d320 <__gmpn_dcpi1_bdiv_qr_n@plt>
   471cc:	b	47200 <__gmpn_dcpi1_bdiv_q@@Base+0xec>
   471d0:	mov	x1, x24
   471d4:	cmp	x26, #0x5c
   471d8:	b.le	47214 <__gmpn_dcpi1_bdiv_q@@Base+0x100>
   471dc:	ldur	x2, [x29, #-8]
   471e0:	mov	x3, x26
   471e4:	mov	x4, x5
   471e8:	b	47394 <__gmpn_dcpi1_bdiv_q@@Base+0x280>
   471ec:	ldp	x5, x3, [x29, #-16]
   471f0:	lsl	x2, x25, #1
   471f4:	mov	x1, x24
   471f8:	mov	x4, x25
   471fc:	bl	c840 <__gmpn_sbpi1_bdiv_qr@plt>
   47200:	mov	x27, x0
   47204:	cmp	x25, x22
   47208:	b.ne	47240 <__gmpn_dcpi1_bdiv_q@@Base+0x12c>  // b.any
   4720c:	sub	x20, x26, x25
   47210:	b	472f0 <__gmpn_dcpi1_bdiv_q@@Base+0x1dc>
   47214:	ldur	x3, [x29, #-8]
   47218:	mov	x2, x26
   4721c:	mov	x4, x26
   47220:	mov	sp, x29
   47224:	ldp	x20, x19, [sp, #80]
   47228:	ldp	x22, x21, [sp, #64]
   4722c:	ldp	x24, x23, [sp, #48]
   47230:	ldp	x26, x25, [sp, #32]
   47234:	ldp	x28, x27, [sp, #16]
   47238:	ldp	x29, x30, [sp], #96
   4723c:	b	c530 <__gmpn_sbpi1_bdiv_q@plt>
   47240:	ldur	x8, [x29, #-8]
   47244:	sub	x4, x22, x25
   47248:	cmp	x25, x4
   4724c:	mov	x0, x21
   47250:	add	x3, x8, x25, lsl #3
   47254:	b.le	47264 <__gmpn_dcpi1_bdiv_q@@Base+0x150>
   47258:	ldur	x1, [x29, #-24]
   4725c:	mov	x2, x25
   47260:	b	47274 <__gmpn_dcpi1_bdiv_q@@Base+0x160>
   47264:	mov	x1, x3
   47268:	ldur	x3, [x29, #-24]
   4726c:	mov	x2, x4
   47270:	mov	x4, x25
   47274:	bl	ccf0 <__gmpn_mul@plt>
   47278:	ldr	x8, [x21, x25, lsl #3]
   4727c:	adds	x8, x8, x27
   47280:	str	x8, [x21, x25, lsl #3]
   47284:	b.cc	47298 <__gmpn_dcpi1_bdiv_q@@Base+0x184>  // b.lo, b.ul, b.last
   47288:	ldr	x8, [x20]
   4728c:	adds	x8, x8, #0x1
   47290:	str	x8, [x20], #8
   47294:	b.cs	47288 <__gmpn_dcpi1_bdiv_q@@Base+0x174>  // b.hs, b.nlast
   47298:	sub	x20, x26, x25
   4729c:	cbz	x22, 472ec <__gmpn_dcpi1_bdiv_q@@Base+0x1d8>
   472a0:	add	x26, x24, x25, lsl #3
   472a4:	mov	x0, x26
   472a8:	mov	x1, x26
   472ac:	mov	x2, x21
   472b0:	mov	x3, x22
   472b4:	bl	ca90 <__gmpn_add_n@plt>
   472b8:	cbz	x0, 472ec <__gmpn_dcpi1_bdiv_q@@Base+0x1d8>
   472bc:	ldur	x10, [x29, #-24]
   472c0:	mov	x8, x22
   472c4:	cmp	x8, x20
   472c8:	b.ge	472e0 <__gmpn_dcpi1_bdiv_q@@Base+0x1cc>  // b.tcont
   472cc:	ldr	x9, [x26, x8, lsl #3]
   472d0:	add	x8, x8, #0x1
   472d4:	adds	x9, x9, #0x1
   472d8:	str	x9, [x23], #8
   472dc:	b.cs	472c4 <__gmpn_dcpi1_bdiv_q@@Base+0x1b0>  // b.hs, b.nlast
   472e0:	ldur	x26, [x29, #-8]
   472e4:	mov	x27, xzr
   472e8:	b	472f8 <__gmpn_dcpi1_bdiv_q@@Base+0x1e4>
   472ec:	mov	x27, xzr
   472f0:	ldur	x26, [x29, #-8]
   472f4:	ldur	x10, [x29, #-24]
   472f8:	add	x24, x24, x25, lsl #3
   472fc:	cmp	x20, x22
   47300:	add	x23, x10, x25, lsl #3
   47304:	b.le	4737c <__gmpn_dcpi1_bdiv_q@@Base+0x268>
   47308:	ldur	x25, [x29, #-16]
   4730c:	mov	x1, x24
   47310:	add	x24, x24, x22, lsl #3
   47314:	ldr	x8, [x24]
   47318:	sub	x20, x20, x22
   4731c:	adds	x8, x8, x27
   47320:	str	x8, [x24]
   47324:	b.cc	4734c <__gmpn_dcpi1_bdiv_q@@Base+0x238>  // b.lo, b.ul, b.last
   47328:	mov	x8, xzr
   4732c:	add	x9, x8, #0x1
   47330:	cmp	x9, x20
   47334:	b.ge	4734c <__gmpn_dcpi1_bdiv_q@@Base+0x238>  // b.tcont
   47338:	ldr	x10, [x24, x9, lsl #3]
   4733c:	adds	x10, x10, #0x1
   47340:	str	x10, [x19, x8, lsl #3]
   47344:	mov	x8, x9
   47348:	b.cs	4732c <__gmpn_dcpi1_bdiv_q@@Base+0x218>  // b.hs, b.nlast
   4734c:	mov	x0, x23
   47350:	mov	x2, x26
   47354:	mov	x3, x22
   47358:	mov	x4, x25
   4735c:	mov	x5, x21
   47360:	bl	d320 <__gmpn_dcpi1_bdiv_qr_n@plt>
   47364:	mov	x27, x0
   47368:	add	x23, x23, x22, lsl #3
   4736c:	cmp	x20, x22
   47370:	add	x19, x19, x28
   47374:	b.gt	4730c <__gmpn_dcpi1_bdiv_q@@Base+0x1f8>
   47378:	b	47380 <__gmpn_dcpi1_bdiv_q@@Base+0x26c>
   4737c:	ldur	x25, [x29, #-16]
   47380:	mov	x0, x23
   47384:	mov	x1, x24
   47388:	mov	x2, x26
   4738c:	mov	x3, x22
   47390:	mov	x4, x25
   47394:	mov	x5, x21
   47398:	bl	473bc <__gmpn_dcpi1_bdiv_q@@Base+0x2a8>
   4739c:	mov	sp, x29
   473a0:	ldp	x20, x19, [sp, #80]
   473a4:	ldp	x22, x21, [sp, #64]
   473a8:	ldp	x24, x23, [sp, #48]
   473ac:	ldp	x26, x25, [sp, #32]
   473b0:	ldp	x28, x27, [sp, #16]
   473b4:	ldp	x29, x30, [sp], #96
   473b8:	ret
   473bc:	stp	x29, x30, [sp, #-96]!
   473c0:	stp	x26, x25, [sp, #32]
   473c4:	stp	x22, x21, [sp, #64]
   473c8:	stp	x20, x19, [sp, #80]
   473cc:	mov	x19, x4
   473d0:	mov	x25, x3
   473d4:	mov	x20, x2
   473d8:	mov	x21, x1
   473dc:	cmp	x3, #0x5d
   473e0:	mov	x22, x0
   473e4:	str	x27, [sp, #16]
   473e8:	stp	x24, x23, [sp, #48]
   473ec:	mov	x29, sp
   473f0:	b.lt	47490 <__gmpn_dcpi1_bdiv_q@@Base+0x37c>  // b.tstop
   473f4:	mov	x23, x5
   473f8:	lsr	x26, x25, #1
   473fc:	mov	x0, x22
   47400:	mov	x1, x21
   47404:	mov	x2, x20
   47408:	mov	x3, x26
   4740c:	mov	x4, x19
   47410:	mov	x5, x23
   47414:	sub	x24, x25, x25, lsr #1
   47418:	bl	d320 <__gmpn_dcpi1_bdiv_qr_n@plt>
   4741c:	mov	x27, x0
   47420:	add	x2, x20, x24, lsl #3
   47424:	mov	x0, x23
   47428:	mov	x1, x22
   4742c:	mov	x3, x26
   47430:	bl	cee0 <__gmpn_mullo_n@plt>
   47434:	add	x0, x21, x24, lsl #3
   47438:	mov	x1, x0
   4743c:	mov	x2, x23
   47440:	mov	x3, x26
   47444:	bl	ca90 <__gmpn_add_n@plt>
   47448:	cmp	x26, x24
   4744c:	b.ge	47478 <__gmpn_dcpi1_bdiv_q@@Base+0x364>  // b.tcont
   47450:	ldr	x3, [x20, x26, lsl #3]
   47454:	add	x0, x21, x26, lsl #3
   47458:	mov	x1, x22
   4745c:	mov	x2, x26
   47460:	bl	d420 <__gmpn_addmul_1@plt>
   47464:	add	x8, x21, x25, lsl #3
   47468:	ldur	x9, [x8, #-8]
   4746c:	add	x10, x0, x27
   47470:	add	x9, x10, x9
   47474:	stur	x9, [x8, #-8]
   47478:	add	x22, x22, x26, lsl #3
   4747c:	cmp	x24, #0x5c
   47480:	add	x21, x21, x26, lsl #3
   47484:	mov	x25, x24
   47488:	b.gt	473f8 <__gmpn_dcpi1_bdiv_q@@Base+0x2e4>
   4748c:	b	47494 <__gmpn_dcpi1_bdiv_q@@Base+0x380>
   47490:	mov	x24, x25
   47494:	mov	x0, x22
   47498:	mov	x1, x21
   4749c:	mov	x2, x24
   474a0:	mov	x3, x20
   474a4:	mov	x4, x24
   474a8:	mov	x5, x19
   474ac:	ldp	x20, x19, [sp, #80]
   474b0:	ldp	x22, x21, [sp, #64]
   474b4:	ldp	x24, x23, [sp, #48]
   474b8:	ldp	x26, x25, [sp, #32]
   474bc:	ldr	x27, [sp, #16]
   474c0:	ldp	x29, x30, [sp], #96
   474c4:	b	c530 <__gmpn_sbpi1_bdiv_q@plt>

00000000000474c8 <__gmpn_dcpi1_bdiv_qr_n_itch@@Base>:
   474c8:	ret

00000000000474cc <__gmpn_dcpi1_bdiv_qr_n@@Base>:
   474cc:	stp	x29, x30, [sp, #-96]!
   474d0:	stp	x26, x25, [sp, #32]
   474d4:	stp	x24, x23, [sp, #48]
   474d8:	stp	x22, x21, [sp, #64]
   474dc:	stp	x20, x19, [sp, #80]
   474e0:	mov	x19, x5
   474e4:	mov	x25, x4
   474e8:	mov	x20, x3
   474ec:	mov	x24, x2
   474f0:	mov	x21, x1
   474f4:	mov	x26, x0
   474f8:	asr	x22, x3, #1
   474fc:	cmp	x3, #0x4d
   47500:	sub	x23, x3, x3, asr #1
   47504:	stp	x28, x27, [sp, #16]
   47508:	mov	x29, sp
   4750c:	b.le	47530 <__gmpn_dcpi1_bdiv_qr_n@@Base+0x64>
   47510:	mov	x0, x26
   47514:	mov	x1, x21
   47518:	mov	x2, x24
   4751c:	mov	x3, x22
   47520:	mov	x4, x25
   47524:	mov	x5, x19
   47528:	bl	d320 <__gmpn_dcpi1_bdiv_qr_n@plt>
   4752c:	b	4754c <__gmpn_dcpi1_bdiv_qr_n@@Base+0x80>
   47530:	and	x2, x20, #0xfffffffffffffffe
   47534:	mov	x0, x26
   47538:	mov	x1, x21
   4753c:	mov	x3, x24
   47540:	mov	x4, x22
   47544:	mov	x5, x25
   47548:	bl	c840 <__gmpn_sbpi1_bdiv_qr@plt>
   4754c:	mov	x27, x0
   47550:	add	x1, x24, x22, lsl #3
   47554:	mov	x0, x19
   47558:	mov	x2, x23
   4755c:	mov	x3, x26
   47560:	mov	x4, x22
   47564:	bl	ccf0 <__gmpn_mul@plt>
   47568:	ldr	x8, [x19, x22, lsl #3]
   4756c:	adds	x8, x8, x27
   47570:	str	x8, [x19, x22, lsl #3]
   47574:	b.cc	47590 <__gmpn_dcpi1_bdiv_qr_n@@Base+0xc4>  // b.lo, b.ul, b.last
   47578:	add	x8, x19, x22, lsl #3
   4757c:	add	x8, x8, #0x8
   47580:	ldr	x9, [x8]
   47584:	adds	x9, x9, #0x1
   47588:	str	x9, [x8], #8
   4758c:	b.cs	47580 <__gmpn_dcpi1_bdiv_qr_n@@Base+0xb4>  // b.hs, b.nlast
   47590:	add	x27, x21, x22, lsl #3
   47594:	cbz	x20, 475dc <__gmpn_dcpi1_bdiv_qr_n@@Base+0x110>
   47598:	mov	x0, x27
   4759c:	mov	x1, x27
   475a0:	mov	x2, x19
   475a4:	mov	x3, x20
   475a8:	bl	ca90 <__gmpn_add_n@plt>
   475ac:	cbz	x0, 475dc <__gmpn_dcpi1_bdiv_qr_n@@Base+0x110>
   475b0:	add	x8, x23, x20
   475b4:	mov	w28, #0x1                   	// #1
   475b8:	mov	x9, x20
   475bc:	cmp	x9, x8
   475c0:	b.ge	475e0 <__gmpn_dcpi1_bdiv_qr_n@@Base+0x114>  // b.tcont
   475c4:	ldr	x10, [x27, x9, lsl #3]
   475c8:	add	x11, x9, #0x1
   475cc:	adds	x10, x10, #0x1
   475d0:	str	x10, [x27, x9, lsl #3]
   475d4:	mov	x9, x11
   475d8:	b.cs	475bc <__gmpn_dcpi1_bdiv_qr_n@@Base+0xf0>  // b.hs, b.nlast
   475dc:	mov	x28, xzr
   475e0:	cmp	x23, #0x26
   475e4:	add	x26, x26, x22, lsl #3
   475e8:	b.le	4760c <__gmpn_dcpi1_bdiv_qr_n@@Base+0x140>
   475ec:	mov	x0, x26
   475f0:	mov	x1, x27
   475f4:	mov	x2, x24
   475f8:	mov	x3, x23
   475fc:	mov	x4, x25
   47600:	mov	x5, x19
   47604:	bl	d320 <__gmpn_dcpi1_bdiv_qr_n@plt>
   47608:	b	47628 <__gmpn_dcpi1_bdiv_qr_n@@Base+0x15c>
   4760c:	lsl	x2, x23, #1
   47610:	mov	x0, x26
   47614:	mov	x1, x27
   47618:	mov	x3, x24
   4761c:	mov	x4, x23
   47620:	mov	x5, x25
   47624:	bl	c840 <__gmpn_sbpi1_bdiv_qr@plt>
   47628:	mov	x25, x0
   4762c:	add	x3, x24, x23, lsl #3
   47630:	mov	x0, x19
   47634:	mov	x1, x26
   47638:	mov	x2, x23
   4763c:	mov	x4, x22
   47640:	bl	ccf0 <__gmpn_mul@plt>
   47644:	ldr	x8, [x19, x23, lsl #3]
   47648:	adds	x8, x8, x25
   4764c:	str	x8, [x19, x23, lsl #3]
   47650:	b.cc	47670 <__gmpn_dcpi1_bdiv_qr_n@@Base+0x1a4>  // b.lo, b.ul, b.last
   47654:	sub	x8, x20, x22
   47658:	add	x8, x19, x8, lsl #3
   4765c:	add	x8, x8, #0x8
   47660:	ldr	x9, [x8]
   47664:	adds	x9, x9, #0x1
   47668:	str	x9, [x8], #8
   4766c:	b.cs	47660 <__gmpn_dcpi1_bdiv_qr_n@@Base+0x194>  // b.hs, b.nlast
   47670:	add	x0, x21, x20, lsl #3
   47674:	mov	x1, x0
   47678:	mov	x2, x19
   4767c:	mov	x3, x20
   47680:	bl	ca90 <__gmpn_add_n@plt>
   47684:	add	x0, x0, x28
   47688:	ldp	x20, x19, [sp, #80]
   4768c:	ldp	x22, x21, [sp, #64]
   47690:	ldp	x24, x23, [sp, #48]
   47694:	ldp	x26, x25, [sp, #32]
   47698:	ldp	x28, x27, [sp, #16]
   4769c:	ldp	x29, x30, [sp], #96
   476a0:	ret

00000000000476a4 <__gmpn_dcpi1_bdiv_qr@@Base>:
   476a4:	stp	x29, x30, [sp, #-96]!
   476a8:	stp	x28, x27, [sp, #16]
   476ac:	stp	x26, x25, [sp, #32]
   476b0:	stp	x24, x23, [sp, #48]
   476b4:	stp	x22, x21, [sp, #64]
   476b8:	stp	x20, x19, [sp, #80]
   476bc:	mov	x29, sp
   476c0:	sub	sp, sp, #0x30
   476c4:	lsl	x28, x4, #3
   476c8:	add	x9, x28, #0xf
   476cc:	mov	x8, sp
   476d0:	and	x9, x9, #0xfffffffffffffff0
   476d4:	mov	x19, x4
   476d8:	mov	x21, x3
   476dc:	mov	x24, x2
   476e0:	sub	x20, x8, x9
   476e4:	stur	x5, [x29, #-8]
   476e8:	mov	sp, x20
   476ec:	sub	x25, x2, x4
   476f0:	cmp	x25, x4
   476f4:	b.le	47780 <__gmpn_dcpi1_bdiv_qr@@Base+0xdc>
   476f8:	mov	x12, x21
   476fc:	lsl	x11, x24, #1
   47700:	mov	x26, xzr
   47704:	neg	x8, x19, lsl #3
   47708:	lsl	x13, x24, #3
   4770c:	stp	x20, x12, [x29, #-24]
   47710:	sub	x21, x20, x19, lsl #3
   47714:	neg	x9, x1
   47718:	lsl	x10, x19, #1
   4771c:	sub	x22, x28, x12
   47720:	sub	x20, x28, x1
   47724:	sub	x2, x11, x19, lsl #1
   47728:	sub	x23, x28, x0
   4772c:	sub	x26, x26, x19
   47730:	add	x27, x25, x26
   47734:	add	x21, x21, x8
   47738:	add	x9, x9, x28
   4773c:	sub	x2, x2, x10
   47740:	add	x22, x22, x28
   47744:	add	x20, x20, x28
   47748:	cmp	x27, x19
   4774c:	add	x23, x23, x28
   47750:	b.gt	4772c <__gmpn_dcpi1_bdiv_qr@@Base+0x88>
   47754:	sub	x25, x13, x9
   47758:	cmp	x27, #0x26
   4775c:	sub	x8, x10, x24
   47760:	stp	x0, x13, [x29, #-40]
   47764:	b.le	477a8 <__gmpn_dcpi1_bdiv_qr@@Base+0x104>
   47768:	ldp	x2, x4, [x29, #-16]
   4776c:	ldur	x5, [x29, #-24]
   47770:	mov	x3, x27
   47774:	mov	x24, x8
   47778:	bl	d320 <__gmpn_dcpi1_bdiv_qr_n@plt>
   4777c:	b	477b8 <__gmpn_dcpi1_bdiv_qr@@Base+0x114>
   47780:	cmp	x25, #0x26
   47784:	b.le	477d8 <__gmpn_dcpi1_bdiv_qr@@Base+0x134>
   47788:	ldur	x4, [x29, #-8]
   4778c:	mov	x2, x21
   47790:	mov	x3, x25
   47794:	mov	x5, x20
   47798:	mov	x23, x0
   4779c:	mov	x26, x1
   477a0:	bl	d320 <__gmpn_dcpi1_bdiv_qr_n@plt>
   477a4:	b	477f4 <__gmpn_dcpi1_bdiv_qr@@Base+0x150>
   477a8:	ldp	x3, x5, [x29, #-16]
   477ac:	mov	x4, x27
   477b0:	mov	x24, x8
   477b4:	bl	c840 <__gmpn_sbpi1_bdiv_qr@plt>
   477b8:	ldur	x12, [x29, #-32]
   477bc:	mov	x8, x24
   477c0:	mov	x24, x0
   477c4:	subs	x4, x8, x26
   477c8:	b.ne	47808 <__gmpn_dcpi1_bdiv_qr@@Base+0x164>  // b.any
   477cc:	ldur	x27, [x29, #-24]
   477d0:	mov	x21, xzr
   477d4:	b	47964 <__gmpn_dcpi1_bdiv_qr@@Base+0x2c0>
   477d8:	ldur	x5, [x29, #-8]
   477dc:	lsl	x2, x25, #1
   477e0:	mov	x3, x21
   477e4:	mov	x4, x25
   477e8:	mov	x23, x0
   477ec:	mov	x26, x1
   477f0:	bl	c840 <__gmpn_sbpi1_bdiv_qr@plt>
   477f4:	mov	x22, x0
   477f8:	cmp	x25, x19
   477fc:	b.ne	47824 <__gmpn_dcpi1_bdiv_qr@@Base+0x180>  // b.any
   47800:	mov	x8, xzr
   47804:	b	47950 <__gmpn_dcpi1_bdiv_qr@@Base+0x2ac>
   47808:	cmp	x27, x4
   4780c:	sub	x3, x12, x22
   47810:	b.le	47844 <__gmpn_dcpi1_bdiv_qr@@Base+0x1a0>
   47814:	ldur	x0, [x29, #-24]
   47818:	ldur	x1, [x29, #-40]
   4781c:	mov	x2, x27
   47820:	b	47858 <__gmpn_dcpi1_bdiv_qr@@Base+0x1b4>
   47824:	sub	x4, x19, x25
   47828:	cmp	x25, x4
   4782c:	add	x3, x21, x25, lsl #3
   47830:	mov	x0, x20
   47834:	b.le	478dc <__gmpn_dcpi1_bdiv_qr@@Base+0x238>
   47838:	mov	x1, x23
   4783c:	mov	x2, x25
   47840:	b	478ec <__gmpn_dcpi1_bdiv_qr@@Base+0x248>
   47844:	ldur	x0, [x29, #-24]
   47848:	mov	x1, x3
   4784c:	ldur	x3, [x29, #-40]
   47850:	mov	x2, x4
   47854:	mov	x4, x27
   47858:	bl	ccf0 <__gmpn_mul@plt>
   4785c:	ldur	x12, [x29, #-32]
   47860:	ldr	x8, [x21, x12]
   47864:	adds	x8, x8, x24
   47868:	str	x8, [x21, x12]
   4786c:	b.cc	47888 <__gmpn_dcpi1_bdiv_qr@@Base+0x1e4>  // b.lo, b.ul, b.last
   47870:	add	x8, x21, x12
   47874:	add	x8, x8, #0x8
   47878:	ldr	x9, [x8]
   4787c:	adds	x9, x9, #0x1
   47880:	str	x9, [x8], #8
   47884:	b.cs	47878 <__gmpn_dcpi1_bdiv_qr@@Base+0x1d4>  // b.hs, b.nlast
   47888:	ldur	x27, [x29, #-24]
   4788c:	cbz	x19, 4795c <__gmpn_dcpi1_bdiv_qr@@Base+0x2b8>
   47890:	sub	x0, x12, x20
   47894:	mov	x1, x0
   47898:	mov	x2, x27
   4789c:	mov	x3, x19
   478a0:	bl	ca90 <__gmpn_add_n@plt>
   478a4:	cbz	x0, 47958 <__gmpn_dcpi1_bdiv_qr@@Base+0x2b4>
   478a8:	ldur	x12, [x29, #-32]
   478ac:	sub	x8, x19, x26
   478b0:	mov	w21, #0x1                   	// #1
   478b4:	mov	x9, x25
   478b8:	mov	x10, x19
   478bc:	cmp	x10, x8
   478c0:	b.ge	47960 <__gmpn_dcpi1_bdiv_qr@@Base+0x2bc>  // b.tcont
   478c4:	ldr	x11, [x9]
   478c8:	add	x10, x10, #0x1
   478cc:	adds	x11, x11, #0x1
   478d0:	str	x11, [x9], #8
   478d4:	b.cs	478bc <__gmpn_dcpi1_bdiv_qr@@Base+0x218>  // b.hs, b.nlast
   478d8:	b	4795c <__gmpn_dcpi1_bdiv_qr@@Base+0x2b8>
   478dc:	mov	x1, x3
   478e0:	mov	x2, x4
   478e4:	mov	x3, x23
   478e8:	mov	x4, x25
   478ec:	bl	ccf0 <__gmpn_mul@plt>
   478f0:	ldr	x8, [x20, x25, lsl #3]
   478f4:	adds	x8, x8, x22
   478f8:	str	x8, [x20, x25, lsl #3]
   478fc:	b.cc	47920 <__gmpn_dcpi1_bdiv_qr@@Base+0x27c>  // b.lo, b.ul, b.last
   47900:	lsl	x8, x24, #3
   47904:	sub	x8, x8, x19, lsl #3
   47908:	add	x8, x8, x20
   4790c:	add	x8, x8, #0x8
   47910:	ldr	x9, [x8]
   47914:	adds	x9, x9, #0x1
   47918:	str	x9, [x8], #8
   4791c:	b.cs	47910 <__gmpn_dcpi1_bdiv_qr@@Base+0x26c>  // b.hs, b.nlast
   47920:	cbz	x19, 47948 <__gmpn_dcpi1_bdiv_qr@@Base+0x2a4>
   47924:	add	x0, x26, x25, lsl #3
   47928:	mov	x1, x0
   4792c:	mov	x2, x20
   47930:	mov	x3, x19
   47934:	bl	ca90 <__gmpn_add_n@plt>
   47938:	cmp	x0, #0x0
   4793c:	mov	x22, xzr
   47940:	cset	w8, ne  // ne = any
   47944:	b	47950 <__gmpn_dcpi1_bdiv_qr@@Base+0x2ac>
   47948:	mov	x8, xzr
   4794c:	mov	x22, xzr
   47950:	add	x0, x22, x8
   47954:	b	479f0 <__gmpn_dcpi1_bdiv_qr@@Base+0x34c>
   47958:	ldur	x12, [x29, #-32]
   4795c:	mov	x21, xzr
   47960:	mov	x24, xzr
   47964:	sub	x1, x12, x20
   47968:	neg	x20, x26
   4796c:	ldur	x26, [x29, #-16]
   47970:	sub	x23, x12, x23
   47974:	add	x22, x1, x19, lsl #3
   47978:	ldr	x8, [x22]
   4797c:	adds	x8, x8, x24
   47980:	str	x8, [x22]
   47984:	b.cc	479a8 <__gmpn_dcpi1_bdiv_qr@@Base+0x304>  // b.lo, b.ul, b.last
   47988:	mov	w8, #0x1                   	// #1
   4798c:	cmp	x8, x20
   47990:	b.ge	479b0 <__gmpn_dcpi1_bdiv_qr@@Base+0x30c>  // b.tcont
   47994:	ldr	x9, [x25, x8, lsl #3]
   47998:	adds	x9, x9, #0x1
   4799c:	str	x9, [x25, x8, lsl #3]
   479a0:	add	x8, x8, #0x1
   479a4:	b.cs	4798c <__gmpn_dcpi1_bdiv_qr@@Base+0x2e8>  // b.hs, b.nlast
   479a8:	mov	x8, xzr
   479ac:	b	479b4 <__gmpn_dcpi1_bdiv_qr@@Base+0x310>
   479b0:	mov	w8, #0x1                   	// #1
   479b4:	ldur	x4, [x29, #-8]
   479b8:	mov	x0, x23
   479bc:	mov	x2, x26
   479c0:	mov	x3, x19
   479c4:	mov	x5, x27
   479c8:	add	x21, x8, x21
   479cc:	bl	d320 <__gmpn_dcpi1_bdiv_qr_n@plt>
   479d0:	sub	x20, x20, x19
   479d4:	mov	x24, x0
   479d8:	add	x23, x23, x19, lsl #3
   479dc:	cmp	x20, #0x0
   479e0:	add	x25, x25, x28
   479e4:	mov	x1, x22
   479e8:	b.gt	47974 <__gmpn_dcpi1_bdiv_qr@@Base+0x2d0>
   479ec:	add	x0, x21, x24
   479f0:	mov	sp, x29
   479f4:	ldp	x20, x19, [sp, #80]
   479f8:	ldp	x22, x21, [sp, #64]
   479fc:	ldp	x24, x23, [sp, #48]
   47a00:	ldp	x26, x25, [sp, #32]
   47a04:	ldp	x28, x27, [sp, #16]
   47a08:	ldp	x29, x30, [sp], #96
   47a0c:	ret

0000000000047a10 <__gmpn_mu_bdiv_q@@Base>:
   47a10:	sub	sp, sp, #0xd0
   47a14:	stp	x28, x27, [sp, #128]
   47a18:	stp	x26, x25, [sp, #144]
   47a1c:	stp	x22, x21, [sp, #176]
   47a20:	stp	x20, x19, [sp, #192]
   47a24:	mov	x19, x5
   47a28:	mov	x25, x3
   47a2c:	mov	x27, x2
   47a30:	mov	x28, x1
   47a34:	cmp	x2, x4
   47a38:	mov	x21, x0
   47a3c:	stp	x29, x30, [sp, #112]
   47a40:	stp	x24, x23, [sp, #160]
   47a44:	add	x29, sp, #0x70
   47a48:	b.le	47c50 <__gmpn_mu_bdiv_q@@Base+0x240>
   47a4c:	sub	x8, x27, #0x1
   47a50:	sdiv	x9, x8, x4
   47a54:	add	x9, x9, #0x1
   47a58:	sdiv	x20, x8, x9
   47a5c:	add	x26, x20, #0x1
   47a60:	add	x23, x19, x26, lsl #3
   47a64:	mov	x0, x19
   47a68:	mov	x1, x25
   47a6c:	mov	x2, x26
   47a70:	mov	x3, x23
   47a74:	mov	x22, x4
   47a78:	stur	x25, [x29, #-40]
   47a7c:	bl	cd40 <__gmpn_binvert@plt>
   47a80:	mov	x0, x23
   47a84:	mov	x1, x28
   47a88:	mov	x2, x22
   47a8c:	bl	ca70 <__gmpn_copyi@plt>
   47a90:	mov	x0, x21
   47a94:	mov	x1, x23
   47a98:	mov	x2, x19
   47a9c:	mov	x3, x26
   47aa0:	add	x25, x28, x22, lsl #3
   47aa4:	bl	cee0 <__gmpn_mullo_n@plt>
   47aa8:	sub	x24, x27, x26
   47aac:	cmp	x24, x26
   47ab0:	mov	w28, wzr
   47ab4:	stp	x20, x19, [x29, #-32]
   47ab8:	stur	x22, [x29, #-48]
   47abc:	stur	x23, [x29, #-8]
   47ac0:	str	x27, [sp, #8]
   47ac4:	b.le	47d14 <__gmpn_mu_bdiv_q@@Base+0x304>
   47ac8:	add	x8, x26, x22
   47acc:	str	x8, [sp, #48]
   47ad0:	add	x8, x23, x26, lsl #3
   47ad4:	add	x27, x23, x22, lsl #3
   47ad8:	str	x8, [sp, #40]
   47adc:	sub	x8, x22, x26
   47ae0:	str	x8, [sp, #32]
   47ae4:	mvn	x8, x20
   47ae8:	add	x10, x27, x26, lsl #3
   47aec:	add	x9, x20, x22
   47af0:	str	x10, [sp, #24]
   47af4:	add	x10, x27, x22, lsl #3
   47af8:	add	x8, x27, x8, lsl #3
   47afc:	stur	x10, [x29, #-16]
   47b00:	str	x8, [sp, #56]
   47b04:	add	x8, x19, x9, lsl #4
   47b08:	add	x8, x8, #0x18
   47b0c:	mov	x19, x21
   47b10:	str	x8, [sp, #16]
   47b14:	cmp	x20, #0x10
   47b18:	b.le	47b9c <__gmpn_mu_bdiv_q@@Base+0x18c>
   47b1c:	mov	x0, x22
   47b20:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   47b24:	ldur	x2, [x29, #-40]
   47b28:	mov	x23, x0
   47b2c:	add	x20, x27, x0, lsl #3
   47b30:	mov	x0, x27
   47b34:	mov	x1, x23
   47b38:	mov	x3, x22
   47b3c:	mov	x4, x19
   47b40:	mov	x5, x26
   47b44:	mov	x6, x20
   47b48:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   47b4c:	ldr	x8, [sp, #48]
   47b50:	sub	x22, x8, x23
   47b54:	cmp	x22, #0x1
   47b58:	b.lt	47bb4 <__gmpn_mu_bdiv_q@@Base+0x1a4>  // b.tstop
   47b5c:	ldur	x2, [x29, #-8]
   47b60:	mov	x0, x20
   47b64:	mov	x1, x27
   47b68:	mov	x3, x22
   47b6c:	bl	c2e0 <__gmpn_sub_n@plt>
   47b70:	ldr	x8, [x27, x22, lsl #3]
   47b74:	subs	x8, x8, w0, sxtw
   47b78:	str	x8, [x27, x22, lsl #3]
   47b7c:	b.cs	47bb4 <__gmpn_mu_bdiv_q@@Base+0x1a4>  // b.hs, b.nlast
   47b80:	ldr	x8, [sp, #16]
   47b84:	sub	x8, x8, x23, lsl #3
   47b88:	ldr	x9, [x8]
   47b8c:	sub	x10, x9, #0x1
   47b90:	str	x10, [x8], #8
   47b94:	cbz	x9, 47b88 <__gmpn_mu_bdiv_q@@Base+0x178>
   47b98:	b	47bb4 <__gmpn_mu_bdiv_q@@Base+0x1a4>
   47b9c:	ldur	x1, [x29, #-40]
   47ba0:	mov	x0, x27
   47ba4:	mov	x2, x22
   47ba8:	mov	x3, x19
   47bac:	mov	x4, x26
   47bb0:	bl	ccf0 <__gmpn_mul@plt>
   47bb4:	ldur	x22, [x29, #-48]
   47bb8:	ldur	x20, [x29, #-24]
   47bbc:	add	x19, x19, x26, lsl #3
   47bc0:	cmp	x26, x22
   47bc4:	b.ne	47bd0 <__gmpn_mu_bdiv_q@@Base+0x1c0>  // b.any
   47bc8:	ldur	x23, [x29, #-8]
   47bcc:	b	47c08 <__gmpn_mu_bdiv_q@@Base+0x1f8>
   47bd0:	ldur	x23, [x29, #-8]
   47bd4:	ldp	x3, x1, [sp, #32]
   47bd8:	ldr	x2, [sp, #24]
   47bdc:	mov	x0, x23
   47be0:	bl	c2e0 <__gmpn_sub_n@plt>
   47be4:	add	w28, w28, w0
   47be8:	cmp	w28, #0x2
   47bec:	b.ne	47c08 <__gmpn_mu_bdiv_q@@Base+0x1f8>  // b.any
   47bf0:	ldur	x8, [x29, #-16]
   47bf4:	ldr	x9, [x8]
   47bf8:	adds	x9, x9, #0x1
   47bfc:	str	x9, [x8], #8
   47c00:	b.cs	47bf4 <__gmpn_mu_bdiv_q@@Base+0x1e4>  // b.hs, b.nlast
   47c04:	mov	w28, #0x1                   	// #1
   47c08:	ldr	x0, [sp, #56]
   47c0c:	ldur	x2, [x29, #-16]
   47c10:	sxtw	x4, w28
   47c14:	mov	x1, x25
   47c18:	mov	x3, x26
   47c1c:	bl	c780 <__gmpn_sub_nc@plt>
   47c20:	mov	x28, x0
   47c24:	mov	x0, x19
   47c28:	mov	x1, x23
   47c2c:	mov	x2, x20
   47c30:	mov	x3, x26
   47c34:	add	x25, x25, x26, lsl #3
   47c38:	bl	cee0 <__gmpn_mullo_n@plt>
   47c3c:	ldur	x20, [x29, #-32]
   47c40:	sub	x24, x24, x26
   47c44:	cmp	x24, x26
   47c48:	b.gt	47b14 <__gmpn_mu_bdiv_q@@Base+0x104>
   47c4c:	b	47d18 <__gmpn_mu_bdiv_q@@Base+0x308>
   47c50:	sub	x24, x27, x27, asr #1
   47c54:	add	x23, x19, x24, lsl #3
   47c58:	mov	x0, x19
   47c5c:	mov	x1, x25
   47c60:	mov	x2, x24
   47c64:	mov	x3, x23
   47c68:	asr	x22, x27, #1
   47c6c:	bl	cd40 <__gmpn_binvert@plt>
   47c70:	mov	x0, x21
   47c74:	mov	x1, x28
   47c78:	mov	x2, x19
   47c7c:	mov	x3, x24
   47c80:	bl	cee0 <__gmpn_mullo_n@plt>
   47c84:	cmp	x24, #0x11
   47c88:	b.le	47db4 <__gmpn_mu_bdiv_q@@Base+0x3a4>
   47c8c:	mov	x0, x27
   47c90:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   47c94:	mov	x2, x25
   47c98:	mov	x25, x0
   47c9c:	add	x6, x23, x0, lsl #3
   47ca0:	mov	x0, x23
   47ca4:	mov	x1, x25
   47ca8:	mov	x3, x27
   47cac:	mov	x4, x21
   47cb0:	mov	x5, x24
   47cb4:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   47cb8:	add	x8, x24, x27
   47cbc:	sub	x8, x8, x25
   47cc0:	cmp	x8, #0x1
   47cc4:	b.lt	47ec0 <__gmpn_mu_bdiv_q@@Base+0x4b0>  // b.tstop
   47cc8:	lsl	x9, x27, #1
   47ccc:	add	x10, x25, x22
   47cd0:	add	x11, x27, x27, lsl #1
   47cd4:	sub	x9, x9, x10
   47cd8:	sub	x10, x11, x25
   47cdc:	sub	x10, x10, x22, lsl #1
   47ce0:	add	x9, x28, x9, lsl #3
   47ce4:	add	x10, x19, x10, lsl #3
   47ce8:	sub	x9, x9, #0x8
   47cec:	sub	x10, x10, #0x8
   47cf0:	mov	x11, x8
   47cf4:	subs	x11, x11, #0x1
   47cf8:	b.lt	47e88 <__gmpn_mu_bdiv_q@@Base+0x478>  // b.tstop
   47cfc:	ldr	x12, [x10], #-8
   47d00:	ldr	x13, [x9], #-8
   47d04:	cmp	x12, x13
   47d08:	b.eq	47cf4 <__gmpn_mu_bdiv_q@@Base+0x2e4>  // b.none
   47d0c:	cset	w9, ls  // ls = plast
   47d10:	b	47e8c <__gmpn_mu_bdiv_q@@Base+0x47c>
   47d14:	mov	x19, x21
   47d18:	cmp	x20, #0x10
   47d1c:	b.le	47dd0 <__gmpn_mu_bdiv_q@@Base+0x3c0>
   47d20:	mov	x0, x22
   47d24:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   47d28:	ldur	x2, [x29, #-40]
   47d2c:	mov	x8, x23
   47d30:	mov	x23, x0
   47d34:	add	x27, x8, x22, lsl #3
   47d38:	add	x6, x27, x0, lsl #3
   47d3c:	mov	x0, x27
   47d40:	mov	x1, x23
   47d44:	mov	x3, x22
   47d48:	mov	x4, x19
   47d4c:	mov	x5, x26
   47d50:	stur	x6, [x29, #-16]
   47d54:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   47d58:	add	x8, x26, x22
   47d5c:	sub	x20, x8, x23
   47d60:	cmp	x20, #0x1
   47d64:	b.lt	47de8 <__gmpn_mu_bdiv_q@@Base+0x3d8>  // b.tstop
   47d68:	ldp	x0, x2, [x29, #-16]
   47d6c:	mov	x1, x27
   47d70:	mov	x3, x20
   47d74:	bl	c2e0 <__gmpn_sub_n@plt>
   47d78:	ldr	x8, [x27, x20, lsl #3]
   47d7c:	subs	x8, x8, w0, sxtw
   47d80:	str	x8, [x27, x20, lsl #3]
   47d84:	b.cs	47de8 <__gmpn_mu_bdiv_q@@Base+0x3d8>  // b.hs, b.nlast
   47d88:	ldp	x8, x9, [x29, #-32]
   47d8c:	add	x8, x8, x22
   47d90:	lsl	x8, x8, #1
   47d94:	sub	x8, x8, x23
   47d98:	add	x8, x9, x8, lsl #3
   47d9c:	add	x8, x8, #0x18
   47da0:	ldr	x9, [x8]
   47da4:	sub	x10, x9, #0x1
   47da8:	str	x10, [x8], #8
   47dac:	cbz	x9, 47da0 <__gmpn_mu_bdiv_q@@Base+0x390>
   47db0:	b	47de8 <__gmpn_mu_bdiv_q@@Base+0x3d8>
   47db4:	mov	x0, x23
   47db8:	mov	x1, x25
   47dbc:	mov	x2, x27
   47dc0:	mov	x3, x21
   47dc4:	mov	x4, x24
   47dc8:	bl	ccf0 <__gmpn_mul@plt>
   47dcc:	b	47ec0 <__gmpn_mu_bdiv_q@@Base+0x4b0>
   47dd0:	ldur	x1, [x29, #-40]
   47dd4:	add	x0, x23, x22, lsl #3
   47dd8:	mov	x2, x22
   47ddc:	mov	x3, x19
   47de0:	mov	x4, x26
   47de4:	bl	ccf0 <__gmpn_mul@plt>
   47de8:	subs	x20, x26, x22
   47dec:	add	x19, x19, x26, lsl #3
   47df0:	b.ne	47e04 <__gmpn_mu_bdiv_q@@Base+0x3f4>  // b.any
   47df4:	ldr	x27, [sp, #8]
   47df8:	ldur	x10, [x29, #-32]
   47dfc:	mov	x23, x22
   47e00:	b	47e50 <__gmpn_mu_bdiv_q@@Base+0x440>
   47e04:	ldur	x0, [x29, #-8]
   47e08:	mov	x23, x22
   47e0c:	sub	x3, x23, x26
   47e10:	add	x22, x0, x22, lsl #3
   47e14:	add	x1, x0, x26, lsl #3
   47e18:	add	x2, x22, x26, lsl #3
   47e1c:	bl	c2e0 <__gmpn_sub_n@plt>
   47e20:	ldr	x27, [sp, #8]
   47e24:	ldur	x10, [x29, #-32]
   47e28:	add	w28, w28, w0
   47e2c:	cmp	w28, #0x2
   47e30:	b.ne	47e50 <__gmpn_mu_bdiv_q@@Base+0x440>  // b.any
   47e34:	add	x8, x22, x23, lsl #3
   47e38:	ldr	x9, [x8]
   47e3c:	adds	x9, x9, #0x1
   47e40:	str	x9, [x8], #8
   47e44:	b.cs	47e38 <__gmpn_mu_bdiv_q@@Base+0x428>  // b.hs, b.nlast
   47e48:	ldur	x23, [x29, #-48]
   47e4c:	mov	w28, #0x1                   	// #1
   47e50:	ldur	x22, [x29, #-8]
   47e54:	mvn	x9, x10
   47e58:	add	x3, x20, x24
   47e5c:	sxtw	x4, w28
   47e60:	add	x8, x22, x23, lsl #3
   47e64:	add	x0, x8, x9, lsl #3
   47e68:	add	x2, x8, x23, lsl #3
   47e6c:	mov	x1, x25
   47e70:	bl	c780 <__gmpn_sub_nc@plt>
   47e74:	ldur	x2, [x29, #-24]
   47e78:	mov	x0, x19
   47e7c:	mov	x1, x22
   47e80:	mov	x3, x24
   47e84:	b	47ee4 <__gmpn_mu_bdiv_q@@Base+0x4d4>
   47e88:	mov	x9, xzr
   47e8c:	ldr	x10, [x23, x8, lsl #3]
   47e90:	subs	x9, x10, x9
   47e94:	str	x9, [x23, x8, lsl #3]
   47e98:	b.cs	47ec0 <__gmpn_mu_bdiv_q@@Base+0x4b0>  // b.hs, b.nlast
   47e9c:	add	x8, x27, x27, lsl #1
   47ea0:	sub	x8, x8, x25
   47ea4:	sub	x8, x8, x22, lsl #1
   47ea8:	add	x8, x19, x8, lsl #3
   47eac:	add	x8, x8, #0x8
   47eb0:	ldr	x9, [x8]
   47eb4:	sub	x10, x9, #0x1
   47eb8:	str	x10, [x8], #8
   47ebc:	cbz	x9, 47eb0 <__gmpn_mu_bdiv_q@@Base+0x4a0>
   47ec0:	add	x1, x28, x24, lsl #3
   47ec4:	add	x2, x23, x24, lsl #3
   47ec8:	mov	x0, x23
   47ecc:	mov	x3, x22
   47ed0:	bl	c2e0 <__gmpn_sub_n@plt>
   47ed4:	add	x0, x21, x24, lsl #3
   47ed8:	mov	x1, x23
   47edc:	mov	x2, x19
   47ee0:	mov	x3, x22
   47ee4:	bl	cee0 <__gmpn_mullo_n@plt>
   47ee8:	ldr	x8, [x21]
   47eec:	cbnz	x8, 47f04 <__gmpn_mu_bdiv_q@@Base+0x4f4>
   47ef0:	subs	x27, x27, #0x1
   47ef4:	str	xzr, [x21]
   47ef8:	b.eq	47f3c <__gmpn_mu_bdiv_q@@Base+0x52c>  // b.none
   47efc:	ldr	x8, [x21, #8]!
   47f00:	cbz	x8, 47ef0 <__gmpn_mu_bdiv_q@@Base+0x4e0>
   47f04:	neg	x8, x8
   47f08:	subs	x2, x27, #0x1
   47f0c:	str	x8, [x21]
   47f10:	b.eq	47f3c <__gmpn_mu_bdiv_q@@Base+0x52c>  // b.none
   47f14:	add	x0, x21, #0x8
   47f18:	ldp	x20, x19, [sp, #192]
   47f1c:	ldp	x22, x21, [sp, #176]
   47f20:	ldp	x24, x23, [sp, #160]
   47f24:	ldp	x26, x25, [sp, #144]
   47f28:	ldp	x28, x27, [sp, #128]
   47f2c:	ldp	x29, x30, [sp, #112]
   47f30:	mov	x1, x0
   47f34:	add	sp, sp, #0xd0
   47f38:	b	c2a0 <__gmpn_com@plt>
   47f3c:	ldp	x20, x19, [sp, #192]
   47f40:	ldp	x22, x21, [sp, #176]
   47f44:	ldp	x24, x23, [sp, #160]
   47f48:	ldp	x26, x25, [sp, #144]
   47f4c:	ldp	x28, x27, [sp, #128]
   47f50:	ldp	x29, x30, [sp, #112]
   47f54:	add	sp, sp, #0xd0
   47f58:	ret

0000000000047f5c <__gmpn_mu_bdiv_q_itch@@Base>:
   47f5c:	stp	x29, x30, [sp, #-48]!
   47f60:	str	x21, [sp, #16]
   47f64:	mov	x21, x0
   47f68:	cmp	x0, x1
   47f6c:	stp	x20, x19, [sp, #32]
   47f70:	mov	x29, sp
   47f74:	b.le	47fc0 <__gmpn_mu_bdiv_q_itch@@Base+0x64>
   47f78:	sub	x8, x21, #0x1
   47f7c:	sdiv	x9, x8, x1
   47f80:	add	x9, x9, #0x1
   47f84:	sdiv	x21, x8, x9
   47f88:	mov	x20, x1
   47f8c:	cmp	x21, #0x10
   47f90:	add	x19, x21, #0x1
   47f94:	b.le	47ff4 <__gmpn_mu_bdiv_q_itch@@Base+0x98>
   47f98:	mov	x0, x20
   47f9c:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   47fa0:	asr	x8, x0, #1
   47fa4:	cmp	x8, x21
   47fa8:	csel	x9, x8, x0, gt
   47fac:	cmp	x8, x20
   47fb0:	csel	x8, x9, xzr, lt  // lt = tstop
   47fb4:	add	x8, x0, x8
   47fb8:	add	x8, x8, #0x4
   47fbc:	b	47ffc <__gmpn_mu_bdiv_q_itch@@Base+0xa0>
   47fc0:	sub	x19, x21, x21, asr #1
   47fc4:	cmp	x19, #0x11
   47fc8:	b.le	48008 <__gmpn_mu_bdiv_q_itch@@Base+0xac>
   47fcc:	mov	x0, x21
   47fd0:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   47fd4:	asr	x8, x0, #1
   47fd8:	cmp	x8, x19
   47fdc:	csel	x9, x0, x8, lt  // lt = tstop
   47fe0:	cmp	x8, x21
   47fe4:	csel	x8, x9, xzr, lt  // lt = tstop
   47fe8:	add	x8, x0, x8
   47fec:	add	x8, x8, #0x4
   47ff0:	b	48010 <__gmpn_mu_bdiv_q_itch@@Base+0xb4>
   47ff4:	mov	x8, xzr
   47ff8:	add	x0, x19, x20
   47ffc:	add	x9, x0, x20
   48000:	add	x20, x9, x8
   48004:	b	48014 <__gmpn_mu_bdiv_q_itch@@Base+0xb8>
   48008:	mov	x8, xzr
   4800c:	add	x0, x19, x21
   48010:	add	x20, x8, x0
   48014:	mov	x0, x19
   48018:	bl	d200 <__gmpn_binvert_itch@plt>
   4801c:	cmp	x20, x0
   48020:	csel	x8, x20, x0, gt
   48024:	add	x0, x8, x19
   48028:	ldp	x20, x19, [sp, #32]
   4802c:	ldr	x21, [sp, #16]
   48030:	ldp	x29, x30, [sp], #48
   48034:	ret

0000000000048038 <__gmpn_mu_bdiv_qr@@Base>:
   48038:	sub	sp, sp, #0xd0
   4803c:	stp	x24, x23, [sp, #160]
   48040:	sub	x24, x3, x5
   48044:	stp	x29, x30, [sp, #112]
   48048:	stp	x28, x27, [sp, #128]
   4804c:	stp	x26, x25, [sp, #144]
   48050:	stp	x22, x21, [sp, #176]
   48054:	stp	x20, x19, [sp, #192]
   48058:	add	x29, sp, #0x70
   4805c:	mov	x21, x6
   48060:	mov	x23, x5
   48064:	mov	x28, x4
   48068:	mov	x25, x2
   4806c:	cmp	x24, x5
   48070:	mov	x20, x0
   48074:	stp	x5, x6, [x29, #-40]
   48078:	stur	x1, [x29, #-8]
   4807c:	stur	x4, [x29, #-48]
   48080:	b.le	4826c <__gmpn_mu_bdiv_qr@@Base+0x234>
   48084:	sub	x8, x24, #0x1
   48088:	sdiv	x9, x8, x23
   4808c:	add	x9, x9, #0x1
   48090:	sdiv	x27, x8, x9
   48094:	mov	x19, x1
   48098:	mov	x1, x28
   4809c:	add	x28, x27, #0x1
   480a0:	add	x22, x21, x28, lsl #3
   480a4:	mov	x0, x21
   480a8:	mov	x2, x28
   480ac:	mov	x3, x22
   480b0:	bl	cd40 <__gmpn_binvert@plt>
   480b4:	mov	x0, x19
   480b8:	mov	x1, x25
   480bc:	mov	x2, x23
   480c0:	bl	ca70 <__gmpn_copyi@plt>
   480c4:	cmp	x24, x28
   480c8:	add	x25, x25, x23, lsl #3
   480cc:	mov	x26, xzr
   480d0:	stur	x22, [x29, #-16]
   480d4:	str	x27, [sp, #56]
   480d8:	b.le	4834c <__gmpn_mu_bdiv_qr@@Base+0x314>
   480dc:	add	x8, x28, x23
   480e0:	str	x8, [sp, #40]
   480e4:	add	x8, x19, x28, lsl #3
   480e8:	str	x8, [sp, #32]
   480ec:	add	x8, x22, x28, lsl #3
   480f0:	str	x8, [sp, #24]
   480f4:	sub	x8, x23, x28
   480f8:	str	x8, [sp, #16]
   480fc:	add	x8, x22, x23, lsl #3
   48100:	stur	x8, [x29, #-24]
   48104:	add	x8, x19, x23, lsl #3
   48108:	mvn	x9, x27
   4810c:	add	x10, x23, x27, lsl #1
   48110:	add	x8, x8, x9, lsl #3
   48114:	str	x8, [sp, #48]
   48118:	add	x8, x21, x10, lsl #3
   4811c:	add	x8, x8, #0x18
   48120:	mov	x22, x20
   48124:	mov	x27, x24
   48128:	str	x8, [sp, #8]
   4812c:	mov	x0, x22
   48130:	mov	x1, x19
   48134:	mov	x2, x21
   48138:	mov	x3, x28
   4813c:	bl	cee0 <__gmpn_mullo_n@plt>
   48140:	ldr	x8, [sp, #56]
   48144:	cmp	x8, #0x10
   48148:	b.le	481cc <__gmpn_mu_bdiv_qr@@Base+0x194>
   4814c:	mov	x0, x23
   48150:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   48154:	mov	x21, x0
   48158:	ldur	x0, [x29, #-16]
   4815c:	ldur	x2, [x29, #-48]
   48160:	mov	x1, x21
   48164:	mov	x3, x23
   48168:	add	x19, x0, x21, lsl #3
   4816c:	mov	x4, x22
   48170:	mov	x5, x28
   48174:	mov	x6, x19
   48178:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   4817c:	ldr	x8, [sp, #40]
   48180:	sub	x23, x8, x21
   48184:	cmp	x23, #0x1
   48188:	b.lt	481e4 <__gmpn_mu_bdiv_qr@@Base+0x1ac>  // b.tstop
   4818c:	mov	x0, x19
   48190:	ldp	x19, x2, [x29, #-16]
   48194:	mov	x3, x23
   48198:	mov	x1, x19
   4819c:	bl	c2e0 <__gmpn_sub_n@plt>
   481a0:	ldr	x8, [x19, x23, lsl #3]
   481a4:	subs	x8, x8, x0
   481a8:	str	x8, [x19, x23, lsl #3]
   481ac:	b.cs	481e4 <__gmpn_mu_bdiv_qr@@Base+0x1ac>  // b.hs, b.nlast
   481b0:	ldr	x8, [sp, #8]
   481b4:	sub	x8, x8, x21, lsl #3
   481b8:	ldr	x9, [x8]
   481bc:	sub	x10, x9, #0x1
   481c0:	str	x10, [x8], #8
   481c4:	cbz	x9, 481b8 <__gmpn_mu_bdiv_qr@@Base+0x180>
   481c8:	b	481e4 <__gmpn_mu_bdiv_qr@@Base+0x1ac>
   481cc:	ldur	x0, [x29, #-16]
   481d0:	ldur	x1, [x29, #-48]
   481d4:	mov	x2, x23
   481d8:	mov	x3, x22
   481dc:	mov	x4, x28
   481e0:	bl	ccf0 <__gmpn_mul@plt>
   481e4:	ldur	x23, [x29, #-40]
   481e8:	add	x22, x22, x28, lsl #3
   481ec:	sub	x27, x27, x28
   481f0:	cmp	x28, x23
   481f4:	b.ne	48204 <__gmpn_mu_bdiv_qr@@Base+0x1cc>  // b.any
   481f8:	ldur	x19, [x29, #-8]
   481fc:	ldur	x21, [x29, #-32]
   48200:	b	48240 <__gmpn_mu_bdiv_qr@@Base+0x208>
   48204:	ldur	x19, [x29, #-8]
   48208:	ldp	x2, x1, [sp, #24]
   4820c:	ldr	x3, [sp, #16]
   48210:	mov	x0, x19
   48214:	bl	c2e0 <__gmpn_sub_n@plt>
   48218:	ldur	x21, [x29, #-32]
   4821c:	add	x26, x0, x26
   48220:	cmp	x26, #0x2
   48224:	b.ne	48240 <__gmpn_mu_bdiv_qr@@Base+0x208>  // b.any
   48228:	ldur	x8, [x29, #-24]
   4822c:	ldr	x9, [x8]
   48230:	adds	x9, x9, #0x1
   48234:	str	x9, [x8], #8
   48238:	b.cs	4822c <__gmpn_mu_bdiv_qr@@Base+0x1f4>  // b.hs, b.nlast
   4823c:	mov	w26, #0x1                   	// #1
   48240:	ldr	x0, [sp, #48]
   48244:	ldur	x2, [x29, #-24]
   48248:	mov	x1, x25
   4824c:	mov	x3, x28
   48250:	mov	x4, x26
   48254:	bl	c780 <__gmpn_sub_nc@plt>
   48258:	mov	x26, x0
   4825c:	cmp	x27, x28
   48260:	add	x25, x25, x28, lsl #3
   48264:	b.gt	4812c <__gmpn_mu_bdiv_qr@@Base+0xf4>
   48268:	b	48354 <__gmpn_mu_bdiv_qr@@Base+0x31c>
   4826c:	sub	x26, x24, x24, asr #1
   48270:	add	x27, x21, x26, lsl #3
   48274:	stur	x3, [x29, #-24]
   48278:	mov	x0, x21
   4827c:	mov	x1, x28
   48280:	mov	x2, x26
   48284:	mov	x3, x27
   48288:	asr	x22, x24, #1
   4828c:	bl	cd40 <__gmpn_binvert@plt>
   48290:	mov	x0, x20
   48294:	mov	x1, x25
   48298:	mov	x2, x21
   4829c:	mov	x3, x26
   482a0:	bl	cee0 <__gmpn_mullo_n@plt>
   482a4:	cmp	x26, #0x11
   482a8:	b.le	48410 <__gmpn_mu_bdiv_qr@@Base+0x3d8>
   482ac:	mov	x0, x23
   482b0:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   482b4:	mov	x21, x0
   482b8:	mov	x19, x23
   482bc:	add	x23, x27, x0, lsl #3
   482c0:	mov	x0, x27
   482c4:	mov	x1, x21
   482c8:	mov	x2, x28
   482cc:	mov	x3, x19
   482d0:	mov	x4, x20
   482d4:	mov	x5, x26
   482d8:	mov	x6, x23
   482dc:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   482e0:	add	x8, x26, x19
   482e4:	sub	x19, x8, x21
   482e8:	cmp	x19, #0x1
   482ec:	b.lt	48428 <__gmpn_mu_bdiv_qr@@Base+0x3f0>  // b.tstop
   482f0:	mov	x0, x23
   482f4:	mov	x1, x27
   482f8:	mov	x2, x25
   482fc:	mov	x3, x19
   48300:	bl	c2e0 <__gmpn_sub_n@plt>
   48304:	ldr	x8, [x27, x19, lsl #3]
   48308:	subs	x8, x8, x0
   4830c:	str	x8, [x27, x19, lsl #3]
   48310:	b.cs	48428 <__gmpn_mu_bdiv_qr@@Base+0x3f0>  // b.hs, b.nlast
   48314:	ldur	x8, [x29, #-24]
   48318:	ldur	x9, [x29, #-40]
   4831c:	lsl	x8, x8, #1
   48320:	add	x9, x21, x9
   48324:	sub	x8, x8, x9
   48328:	ldur	x9, [x29, #-32]
   4832c:	sub	x8, x8, x22, lsl #1
   48330:	add	x8, x9, x8, lsl #3
   48334:	add	x8, x8, #0x8
   48338:	ldr	x9, [x8]
   4833c:	sub	x10, x9, #0x1
   48340:	str	x10, [x8], #8
   48344:	cbz	x9, 48338 <__gmpn_mu_bdiv_qr@@Base+0x300>
   48348:	b	48428 <__gmpn_mu_bdiv_qr@@Base+0x3f0>
   4834c:	mov	x27, x24
   48350:	mov	x22, x20
   48354:	mov	x0, x22
   48358:	mov	x1, x19
   4835c:	mov	x2, x21
   48360:	mov	x3, x27
   48364:	bl	cee0 <__gmpn_mullo_n@plt>
   48368:	cmp	x27, #0x11
   4836c:	b.le	484f0 <__gmpn_mu_bdiv_qr@@Base+0x4b8>
   48370:	mov	x0, x23
   48374:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   48378:	mov	x21, x0
   4837c:	ldur	x0, [x29, #-16]
   48380:	ldur	x28, [x29, #-48]
   48384:	mov	x19, x23
   48388:	mov	x1, x21
   4838c:	add	x23, x0, x21, lsl #3
   48390:	mov	x2, x28
   48394:	mov	x3, x19
   48398:	mov	x4, x22
   4839c:	mov	x5, x27
   483a0:	mov	x6, x23
   483a4:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   483a8:	add	x8, x27, x19
   483ac:	sub	x19, x8, x21
   483b0:	cmp	x19, #0x1
   483b4:	b.lt	4850c <__gmpn_mu_bdiv_qr@@Base+0x4d4>  // b.tstop
   483b8:	ldp	x22, x2, [x29, #-16]
   483bc:	mov	x0, x23
   483c0:	mov	x3, x19
   483c4:	mov	x1, x22
   483c8:	bl	c2e0 <__gmpn_sub_n@plt>
   483cc:	ldr	x8, [x22, x19, lsl #3]
   483d0:	subs	x8, x8, x0
   483d4:	str	x8, [x22, x19, lsl #3]
   483d8:	b.cs	4850c <__gmpn_mu_bdiv_qr@@Base+0x4d4>  // b.hs, b.nlast
   483dc:	ldr	x8, [sp, #56]
   483e0:	ldur	x9, [x29, #-40]
   483e4:	add	x8, x27, x8
   483e8:	add	x8, x8, x9
   483ec:	ldur	x9, [x29, #-32]
   483f0:	sub	x8, x8, x21
   483f4:	add	x8, x9, x8, lsl #3
   483f8:	add	x8, x8, #0x10
   483fc:	ldr	x9, [x8]
   48400:	sub	x10, x9, #0x1
   48404:	str	x10, [x8], #8
   48408:	cbz	x9, 483fc <__gmpn_mu_bdiv_qr@@Base+0x3c4>
   4840c:	b	4850c <__gmpn_mu_bdiv_qr@@Base+0x4d4>
   48410:	mov	x0, x27
   48414:	mov	x1, x28
   48418:	mov	x2, x23
   4841c:	mov	x3, x20
   48420:	mov	x4, x26
   48424:	bl	ccf0 <__gmpn_mul@plt>
   48428:	ldur	x21, [x29, #-8]
   4842c:	ldur	x23, [x29, #-40]
   48430:	add	x1, x25, x26, lsl #3
   48434:	add	x2, x27, x26, lsl #3
   48438:	mov	x0, x21
   4843c:	mov	x3, x23
   48440:	add	x19, x20, x26, lsl #3
   48444:	bl	c2e0 <__gmpn_sub_n@plt>
   48448:	ldur	x2, [x29, #-32]
   4844c:	stur	x0, [x29, #-16]
   48450:	mov	x0, x19
   48454:	mov	x1, x21
   48458:	mov	x3, x22
   4845c:	bl	cee0 <__gmpn_mullo_n@plt>
   48460:	cmp	x24, #0x23
   48464:	b.le	48520 <__gmpn_mu_bdiv_qr@@Base+0x4e8>
   48468:	mov	x0, x23
   4846c:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   48470:	mov	x2, x28
   48474:	mov	x28, x0
   48478:	add	x21, x27, x0, lsl #3
   4847c:	mov	x0, x27
   48480:	mov	x1, x28
   48484:	mov	x3, x23
   48488:	mov	x4, x19
   4848c:	mov	x5, x22
   48490:	mov	x6, x21
   48494:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   48498:	add	x8, x22, x23
   4849c:	sub	x19, x8, x28
   484a0:	cmp	x19, #0x1
   484a4:	b.lt	48538 <__gmpn_mu_bdiv_qr@@Base+0x500>  // b.tstop
   484a8:	ldur	x2, [x29, #-8]
   484ac:	mov	x0, x21
   484b0:	mov	x1, x27
   484b4:	mov	x3, x19
   484b8:	bl	c2e0 <__gmpn_sub_n@plt>
   484bc:	ldr	x8, [x27, x19, lsl #3]
   484c0:	subs	x8, x8, x0
   484c4:	str	x8, [x27, x19, lsl #3]
   484c8:	b.cs	48538 <__gmpn_mu_bdiv_qr@@Base+0x500>  // b.hs, b.nlast
   484cc:	ldp	x9, x8, [x29, #-32]
   484d0:	sub	x8, x8, x28
   484d4:	add	x8, x9, x8, lsl #3
   484d8:	add	x8, x8, #0x8
   484dc:	ldr	x9, [x8]
   484e0:	sub	x10, x9, #0x1
   484e4:	str	x10, [x8], #8
   484e8:	cbz	x9, 484dc <__gmpn_mu_bdiv_qr@@Base+0x4a4>
   484ec:	b	48538 <__gmpn_mu_bdiv_qr@@Base+0x500>
   484f0:	ldur	x28, [x29, #-48]
   484f4:	ldur	x0, [x29, #-16]
   484f8:	mov	x2, x23
   484fc:	mov	x3, x22
   48500:	mov	x1, x28
   48504:	mov	x4, x27
   48508:	bl	ccf0 <__gmpn_mul@plt>
   4850c:	ldur	x23, [x29, #-40]
   48510:	cmp	x27, x23
   48514:	b.ne	4859c <__gmpn_mu_bdiv_qr@@Base+0x564>  // b.any
   48518:	ldp	x21, x19, [x29, #-16]
   4851c:	b	485d8 <__gmpn_mu_bdiv_qr@@Base+0x5a0>
   48520:	mov	x0, x27
   48524:	mov	x1, x28
   48528:	mov	x2, x23
   4852c:	mov	x3, x19
   48530:	mov	x4, x22
   48534:	bl	ccf0 <__gmpn_mul@plt>
   48538:	ldur	x19, [x29, #-8]
   4853c:	ldur	x8, [x29, #-32]
   48540:	sub	x3, x23, x22
   48544:	add	x1, x19, x22, lsl #3
   48548:	add	x2, x8, x24, lsl #3
   4854c:	mov	x0, x19
   48550:	bl	c2e0 <__gmpn_sub_n@plt>
   48554:	ldur	x8, [x29, #-16]
   48558:	ldur	x28, [x29, #-48]
   4855c:	add	x4, x0, x8
   48560:	cmp	x4, #0x2
   48564:	b.ne	48580 <__gmpn_mu_bdiv_qr@@Base+0x548>  // b.any
   48568:	add	x8, x27, x23, lsl #3
   4856c:	mov	w4, #0x1                   	// #1
   48570:	ldr	x9, [x8]
   48574:	adds	x9, x9, #0x1
   48578:	str	x9, [x8], #8
   4857c:	b.cs	48570 <__gmpn_mu_bdiv_qr@@Base+0x538>  // b.hs, b.nlast
   48580:	add	x8, x19, x23, lsl #3
   48584:	add	x9, x25, x23, lsl #3
   48588:	sub	x0, x8, x22, lsl #3
   4858c:	add	x1, x9, x26, lsl #3
   48590:	add	x2, x27, x23, lsl #3
   48594:	mov	x3, x22
   48598:	b	485f0 <__gmpn_mu_bdiv_qr@@Base+0x5b8>
   4859c:	ldp	x21, x19, [x29, #-16]
   485a0:	sub	x3, x23, x27
   485a4:	add	x1, x19, x27, lsl #3
   485a8:	add	x2, x21, x27, lsl #3
   485ac:	mov	x0, x19
   485b0:	bl	c2e0 <__gmpn_sub_n@plt>
   485b4:	add	x26, x0, x26
   485b8:	cmp	x26, #0x2
   485bc:	b.ne	485d8 <__gmpn_mu_bdiv_qr@@Base+0x5a0>  // b.any
   485c0:	add	x8, x21, x23, lsl #3
   485c4:	mov	w26, #0x1                   	// #1
   485c8:	ldr	x9, [x8]
   485cc:	adds	x9, x9, #0x1
   485d0:	str	x9, [x8], #8
   485d4:	b.cs	485c8 <__gmpn_mu_bdiv_qr@@Base+0x590>  // b.hs, b.nlast
   485d8:	add	x8, x19, x23, lsl #3
   485dc:	sub	x0, x8, x27, lsl #3
   485e0:	add	x2, x21, x23, lsl #3
   485e4:	mov	x1, x25
   485e8:	mov	x3, x27
   485ec:	mov	x4, x26
   485f0:	bl	c780 <__gmpn_sub_nc@plt>
   485f4:	ldr	x8, [x20]
   485f8:	mov	x21, x0
   485fc:	cbz	x8, 4865c <__gmpn_mu_bdiv_qr@@Base+0x624>
   48600:	neg	x8, x8
   48604:	subs	x2, x24, #0x1
   48608:	str	x8, [x20]
   4860c:	b.eq	4861c <__gmpn_mu_bdiv_qr@@Base+0x5e4>  // b.none
   48610:	add	x0, x20, #0x8
   48614:	mov	x1, x0
   48618:	bl	c2a0 <__gmpn_com@plt>
   4861c:	mov	x0, x19
   48620:	mov	x1, x19
   48624:	mov	x2, x28
   48628:	mov	x3, x23
   4862c:	bl	ca90 <__gmpn_add_n@plt>
   48630:	sub	x0, x0, x21
   48634:	ldp	x20, x19, [sp, #192]
   48638:	ldp	x22, x21, [sp, #176]
   4863c:	ldp	x24, x23, [sp, #160]
   48640:	ldp	x26, x25, [sp, #144]
   48644:	ldp	x28, x27, [sp, #128]
   48648:	ldp	x29, x30, [sp, #112]
   4864c:	add	sp, sp, #0xd0
   48650:	ret
   48654:	ldr	x8, [x20, #8]!
   48658:	cbnz	x8, 48600 <__gmpn_mu_bdiv_qr@@Base+0x5c8>
   4865c:	subs	x24, x24, #0x1
   48660:	str	xzr, [x20]
   48664:	b.ne	48654 <__gmpn_mu_bdiv_qr@@Base+0x61c>  // b.any
   48668:	mov	x0, xzr
   4866c:	b	48634 <__gmpn_mu_bdiv_qr@@Base+0x5fc>

0000000000048670 <__gmpn_mu_bdiv_qr_itch@@Base>:
   48670:	stp	x29, x30, [sp, #-48]!
   48674:	sub	x8, x0, x1
   48678:	stp	x20, x19, [sp, #32]
   4867c:	mov	x20, x1
   48680:	cmp	x8, x1
   48684:	stp	x22, x21, [sp, #16]
   48688:	mov	x29, sp
   4868c:	b.le	486a8 <__gmpn_mu_bdiv_qr_itch@@Base+0x38>
   48690:	sub	x8, x8, #0x1
   48694:	sdiv	x9, x8, x20
   48698:	add	x9, x9, #0x1
   4869c:	sdiv	x8, x8, x9
   486a0:	add	x19, x8, #0x1
   486a4:	b	486ac <__gmpn_mu_bdiv_qr_itch@@Base+0x3c>
   486a8:	sub	x19, x8, x8, asr #1
   486ac:	cmp	x19, #0x11
   486b0:	b.le	486e0 <__gmpn_mu_bdiv_qr_itch@@Base+0x70>
   486b4:	mov	x0, x20
   486b8:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   486bc:	asr	x8, x0, #1
   486c0:	cmp	x8, x19
   486c4:	csel	x9, x0, x8, lt  // lt = tstop
   486c8:	cmp	x8, x20
   486cc:	csel	x8, x9, xzr, lt  // lt = tstop
   486d0:	add	x8, x0, x8
   486d4:	mov	x21, x0
   486d8:	add	x22, x8, #0x4
   486dc:	b	486e8 <__gmpn_mu_bdiv_qr_itch@@Base+0x78>
   486e0:	mov	x22, xzr
   486e4:	add	x21, x19, x20
   486e8:	mov	x0, x19
   486ec:	bl	d200 <__gmpn_binvert_itch@plt>
   486f0:	add	x8, x21, x22
   486f4:	cmp	x8, x0
   486f8:	csel	x8, x8, x0, gt
   486fc:	add	x0, x8, x19
   48700:	ldp	x20, x19, [sp, #32]
   48704:	ldp	x22, x21, [sp, #16]
   48708:	ldp	x29, x30, [sp], #48
   4870c:	ret

0000000000048710 <__gmpn_bdiv_q@@Base>:
   48710:	stp	x29, x30, [sp, #-64]!
   48714:	str	x23, [sp, #16]
   48718:	stp	x22, x21, [sp, #32]
   4871c:	stp	x20, x19, [sp, #48]
   48720:	mov	x21, x5
   48724:	mov	x19, x4
   48728:	mov	x20, x3
   4872c:	mov	x22, x2
   48730:	cmp	x4, #0x5c
   48734:	mov	x23, x0
   48738:	mov	x29, sp
   4873c:	b.le	48770 <__gmpn_bdiv_q@@Base+0x60>
   48740:	cmp	x19, #0x39b
   48744:	b.le	487d8 <__gmpn_bdiv_q@@Base+0xc8>
   48748:	mov	x0, x23
   4874c:	mov	x2, x22
   48750:	mov	x3, x20
   48754:	mov	x4, x19
   48758:	mov	x5, x21
   4875c:	ldp	x20, x19, [sp, #48]
   48760:	ldp	x22, x21, [sp, #32]
   48764:	ldr	x23, [sp, #16]
   48768:	ldp	x29, x30, [sp], #64
   4876c:	b	d3e0 <__gmpn_mu_bdiv_q@plt>
   48770:	mov	x0, x21
   48774:	mov	x2, x22
   48778:	bl	ca70 <__gmpn_copyi@plt>
   4877c:	ldr	x8, [x20]
   48780:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   48784:	ldr	x9, [x9, #3952]
   48788:	mov	x0, x23
   4878c:	ubfx	x10, x8, #1, #7
   48790:	mov	x1, x21
   48794:	ldrb	w9, [x9, x10]
   48798:	mov	w10, #0x2                   	// #2
   4879c:	mov	x2, x22
   487a0:	mov	x3, x20
   487a4:	msub	x11, x8, x9, x10
   487a8:	mul	x9, x11, x9
   487ac:	msub	x10, x9, x8, x10
   487b0:	mov	x4, x19
   487b4:	ldp	x20, x19, [sp, #48]
   487b8:	ldp	x22, x21, [sp, #32]
   487bc:	ldr	x23, [sp, #16]
   487c0:	mul	x9, x9, x10
   487c4:	orr	x10, xzr, #0xfffffffffffffffe
   487c8:	madd	x8, x9, x8, x10
   487cc:	mul	x5, x8, x9
   487d0:	ldp	x29, x30, [sp], #64
   487d4:	b	c530 <__gmpn_sbpi1_bdiv_q@plt>
   487d8:	mov	x0, x21
   487dc:	mov	x2, x22
   487e0:	bl	ca70 <__gmpn_copyi@plt>
   487e4:	ldr	x8, [x20]
   487e8:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   487ec:	ldr	x9, [x9, #3952]
   487f0:	mov	x0, x23
   487f4:	ubfx	x10, x8, #1, #7
   487f8:	mov	x1, x21
   487fc:	ldrb	w9, [x9, x10]
   48800:	mov	w10, #0x2                   	// #2
   48804:	mov	x2, x22
   48808:	mov	x3, x20
   4880c:	msub	x11, x8, x9, x10
   48810:	mul	x9, x11, x9
   48814:	msub	x10, x9, x8, x10
   48818:	mov	x4, x19
   4881c:	ldp	x20, x19, [sp, #48]
   48820:	ldp	x22, x21, [sp, #32]
   48824:	ldr	x23, [sp, #16]
   48828:	mul	x9, x9, x10
   4882c:	orr	x10, xzr, #0xfffffffffffffffe
   48830:	madd	x8, x9, x8, x10
   48834:	mul	x5, x8, x9
   48838:	ldp	x29, x30, [sp], #64
   4883c:	b	ce30 <__gmpn_dcpi1_bdiv_q@plt>

0000000000048840 <__gmpn_bdiv_q_itch@@Base>:
   48840:	cmp	x1, #0x39c
   48844:	b.lt	4884c <__gmpn_bdiv_q_itch@@Base+0xc>  // b.tstop
   48848:	b	c8a0 <__gmpn_mu_bdiv_q_itch@plt>
   4884c:	ret

0000000000048850 <__gmpn_bdiv_qr@@Base>:
   48850:	stp	x29, x30, [sp, #-64]!
   48854:	stp	x24, x23, [sp, #16]
   48858:	stp	x22, x21, [sp, #32]
   4885c:	stp	x20, x19, [sp, #48]
   48860:	mov	x20, x6
   48864:	mov	x19, x5
   48868:	mov	x23, x4
   4886c:	mov	x22, x3
   48870:	mov	x21, x1
   48874:	cmp	x5, #0x27
   48878:	mov	x24, x0
   4887c:	mov	x29, sp
   48880:	b.lt	488c4 <__gmpn_bdiv_qr@@Base+0x74>  // b.tstop
   48884:	sub	x8, x22, x19
   48888:	cmp	x8, #0x26
   4888c:	b.le	488c4 <__gmpn_bdiv_qr@@Base+0x74>
   48890:	cmp	x19, #0x326
   48894:	b.le	48924 <__gmpn_bdiv_qr@@Base+0xd4>
   48898:	mov	x0, x24
   4889c:	mov	x1, x21
   488a0:	mov	x3, x22
   488a4:	mov	x4, x23
   488a8:	mov	x5, x19
   488ac:	mov	x6, x20
   488b0:	ldp	x20, x19, [sp, #48]
   488b4:	ldp	x22, x21, [sp, #32]
   488b8:	ldp	x24, x23, [sp, #16]
   488bc:	ldp	x29, x30, [sp], #64
   488c0:	b	ccd0 <__gmpn_mu_bdiv_qr@plt>
   488c4:	mov	x0, x20
   488c8:	mov	x1, x2
   488cc:	mov	x2, x22
   488d0:	bl	ca70 <__gmpn_copyi@plt>
   488d4:	ldr	x8, [x23]
   488d8:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   488dc:	ldr	x9, [x9, #3952]
   488e0:	mov	x0, x24
   488e4:	ubfx	x10, x8, #1, #7
   488e8:	mov	x1, x20
   488ec:	ldrb	w9, [x9, x10]
   488f0:	mov	w10, #0x2                   	// #2
   488f4:	mov	x2, x22
   488f8:	mov	x3, x23
   488fc:	msub	x11, x8, x9, x10
   48900:	mul	x9, x11, x9
   48904:	msub	x10, x9, x8, x10
   48908:	mul	x9, x9, x10
   4890c:	orr	x10, xzr, #0xfffffffffffffffe
   48910:	madd	x8, x9, x8, x10
   48914:	mul	x5, x8, x9
   48918:	mov	x4, x19
   4891c:	bl	c840 <__gmpn_sbpi1_bdiv_qr@plt>
   48920:	b	48980 <__gmpn_bdiv_qr@@Base+0x130>
   48924:	mov	x0, x20
   48928:	mov	x1, x2
   4892c:	mov	x2, x22
   48930:	bl	ca70 <__gmpn_copyi@plt>
   48934:	ldr	x8, [x23]
   48938:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4893c:	ldr	x9, [x9, #3952]
   48940:	mov	x0, x24
   48944:	ubfx	x10, x8, #1, #7
   48948:	mov	x1, x20
   4894c:	ldrb	w9, [x9, x10]
   48950:	mov	w10, #0x2                   	// #2
   48954:	mov	x2, x22
   48958:	mov	x3, x23
   4895c:	msub	x11, x8, x9, x10
   48960:	mul	x9, x11, x9
   48964:	msub	x10, x9, x8, x10
   48968:	mul	x9, x9, x10
   4896c:	orr	x10, xzr, #0xfffffffffffffffe
   48970:	madd	x8, x9, x8, x10
   48974:	mul	x5, x8, x9
   48978:	mov	x4, x19
   4897c:	bl	c600 <__gmpn_dcpi1_bdiv_qr@plt>
   48980:	add	x8, x20, x22, lsl #3
   48984:	mov	x23, x0
   48988:	sub	x1, x8, x19, lsl #3
   4898c:	mov	x0, x21
   48990:	mov	x2, x19
   48994:	bl	ca70 <__gmpn_copyi@plt>
   48998:	mov	x0, x23
   4899c:	ldp	x20, x19, [sp, #48]
   489a0:	ldp	x22, x21, [sp, #32]
   489a4:	ldp	x24, x23, [sp, #16]
   489a8:	ldp	x29, x30, [sp], #64
   489ac:	ret

00000000000489b0 <__gmpn_bdiv_qr_itch@@Base>:
   489b0:	cmp	x1, #0x327
   489b4:	b.lt	489bc <__gmpn_bdiv_qr_itch@@Base+0xc>  // b.tstop
   489b8:	b	d190 <__gmpn_mu_bdiv_qr_itch@plt>
   489bc:	ret

00000000000489c0 <__gmpn_broot_invm1@@Base>:
   489c0:	stp	x29, x30, [sp, #-96]!
   489c4:	stp	x28, x27, [sp, #16]
   489c8:	stp	x26, x25, [sp, #32]
   489cc:	stp	x24, x23, [sp, #48]
   489d0:	stp	x22, x21, [sp, #64]
   489d4:	stp	x20, x19, [sp, #80]
   489d8:	mov	x29, sp
   489dc:	sub	sp, sp, #0x440
   489e0:	mov	x23, x1
   489e4:	lsl	x1, x2, #5
   489e8:	mov	w8, #0x7f00                	// #32512
   489ec:	mov	x19, sp
   489f0:	mov	x20, x3
   489f4:	mov	x25, x2
   489f8:	cmp	x1, x8
   489fc:	stp	x0, xzr, [x19, #24]
   48a00:	b.hi	48ccc <__gmpn_broot_invm1@@Base+0x30c>  // b.pmore
   48a04:	add	x9, x1, #0xf
   48a08:	mov	x8, sp
   48a0c:	and	x9, x9, #0xfffffffffffffff0
   48a10:	sub	x22, x8, x9
   48a14:	mov	sp, x22
   48a18:	add	x5, x22, x25, lsl #3
   48a1c:	sub	x8, x20, #0x1
   48a20:	add	x2, x19, #0x30
   48a24:	mov	w3, #0x1                   	// #1
   48a28:	mov	x0, x22
   48a2c:	mov	x1, x23
   48a30:	mov	x4, x25
   48a34:	str	x8, [x19, #48]
   48a38:	mov	w21, #0x1                   	// #1
   48a3c:	str	x5, [x19, #16]
   48a40:	bl	c3e0 <__gmpn_powlo@plt>
   48a44:	adrp	x11, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   48a48:	ldr	w9, [x23]
   48a4c:	ldr	x11, [x11, #3952]
   48a50:	ubfx	x10, x20, #1, #7
   48a54:	mov	w13, #0x2                   	// #2
   48a58:	lsl	w12, w9, #1
   48a5c:	ldrb	w11, [x11, x10]
   48a60:	eor	w9, w12, w9, lsl #2
   48a64:	and	w9, w9, w20, lsl #2
   48a68:	ldr	x8, [x22]
   48a6c:	msub	x12, x11, x20, x13
   48a70:	mul	x11, x12, x11
   48a74:	msub	x12, x11, x20, x13
   48a78:	and	x9, x9, #0x8
   48a7c:	mul	x11, x11, x12
   48a80:	orr	x12, x9, #0x1
   48a84:	msub	x9, x11, x20, x13
   48a88:	mul	x24, x11, x9
   48a8c:	ands	x10, x20, #0x7f
   48a90:	mul	x11, x24, x12
   48a94:	add	x9, x20, #0x1
   48a98:	b.eq	48ab8 <__gmpn_broot_invm1@@Base+0xf8>  // b.none
   48a9c:	mov	w21, #0x1                   	// #1
   48aa0:	tst	x10, #0x1
   48aa4:	csinc	x13, x12, xzr, ne  // ne = any
   48aa8:	lsr	x10, x10, #1
   48aac:	mul	x21, x13, x21
   48ab0:	mul	x12, x12, x12
   48ab4:	cbnz	x10, 48aa0 <__gmpn_broot_invm1@@Base+0xe0>
   48ab8:	msub	x10, x21, x8, x9
   48abc:	mul	x11, x11, x10
   48ac0:	ands	x13, x20, #0x7fff
   48ac4:	mul	x10, x11, x24
   48ac8:	mov	w12, #0x1                   	// #1
   48acc:	b.eq	48ae8 <__gmpn_broot_invm1@@Base+0x128>  // b.none
   48ad0:	tst	x13, #0x1
   48ad4:	csinc	x14, x11, xzr, ne  // ne = any
   48ad8:	lsr	x13, x13, #1
   48adc:	mul	x12, x14, x12
   48ae0:	mul	x11, x11, x11
   48ae4:	cbnz	x13, 48ad0 <__gmpn_broot_invm1@@Base+0x110>
   48ae8:	msub	x11, x12, x8, x9
   48aec:	mul	x11, x10, x11
   48af0:	mul	x10, x11, x24
   48af4:	cbz	x20, 48b48 <__gmpn_broot_invm1@@Base+0x188>
   48af8:	mov	w12, #0x1                   	// #1
   48afc:	mov	x13, x20
   48b00:	tst	x13, #0x1
   48b04:	csinc	x14, x11, xzr, ne  // ne = any
   48b08:	lsr	x13, x13, #1
   48b0c:	mul	x12, x14, x12
   48b10:	mul	x11, x11, x11
   48b14:	cbnz	x13, 48b00 <__gmpn_broot_invm1@@Base+0x140>
   48b18:	msub	x11, x12, x8, x9
   48b1c:	mul	x10, x11, x10
   48b20:	mov	w11, #0x1                   	// #1
   48b24:	mov	x12, x10
   48b28:	mov	x13, x20
   48b2c:	tst	x13, #0x1
   48b30:	csinc	x14, x12, xzr, ne  // ne = any
   48b34:	lsr	x13, x13, #1
   48b38:	mul	x11, x14, x11
   48b3c:	mul	x12, x12, x12
   48b40:	cbnz	x13, 48b2c <__gmpn_broot_invm1@@Base+0x16c>
   48b44:	b	48b54 <__gmpn_broot_invm1@@Base+0x194>
   48b48:	sub	x11, x9, x8
   48b4c:	mul	x10, x10, x11
   48b50:	mov	w11, #0x1                   	// #1
   48b54:	msub	x8, x11, x8, x9
   48b58:	ldr	x9, [x19, #24]
   48b5c:	mul	x10, x10, x24
   48b60:	mul	x8, x10, x8
   48b64:	cmp	x25, #0x1
   48b68:	str	x8, [x9]
   48b6c:	b.eq	48ca4 <__gmpn_broot_invm1@@Base+0x2e4>  // b.none
   48b70:	mov	w1, #0x8                   	// #8
   48b74:	lsr	x8, x20, #1
   48b78:	bfi	x1, x25, #4, #60
   48b7c:	mov	w9, #0x7f00                	// #32512
   48b80:	add	x8, x8, #0x1
   48b84:	cmp	x1, x9
   48b88:	str	x8, [x19, #40]
   48b8c:	str	x22, [x19, #8]
   48b90:	b.hi	48ce4 <__gmpn_broot_invm1@@Base+0x324>  // b.pmore
   48b94:	add	x9, x1, #0xf
   48b98:	mov	x8, sp
   48b9c:	and	x9, x9, #0xfffffffffffffff0
   48ba0:	sub	x26, x8, x9
   48ba4:	mov	sp, x26
   48ba8:	cmp	x25, #0x2
   48bac:	b.lt	48ca4 <__gmpn_broot_invm1@@Base+0x2e4>  // b.tstop
   48bb0:	mov	w9, wzr
   48bb4:	add	x27, x26, x25, lsl #3
   48bb8:	add	x8, x19, #0x38
   48bbc:	add	x10, x25, #0x1
   48bc0:	add	x11, x25, #0x2
   48bc4:	cmp	x10, #0x0
   48bc8:	csinc	x10, x11, x25, lt  // lt = tstop
   48bcc:	str	x25, [x8, w9, uxtw #3]
   48bd0:	cmp	x25, #0x2
   48bd4:	asr	x25, x10, #1
   48bd8:	add	w9, w9, #0x1
   48bdc:	b.gt	48bbc <__gmpn_broot_invm1@@Base+0x1fc>
   48be0:	cbz	w9, 48ca4 <__gmpn_broot_invm1@@Base+0x2e4>
   48be4:	mov	w22, w9
   48be8:	mov	w25, #0x1                   	// #1
   48bec:	ldr	x28, [x19, #24]
   48bf0:	mov	x0, x27
   48bf4:	mov	x2, x25
   48bf8:	mov	x23, x25
   48bfc:	mov	x1, x28
   48c00:	sub	w21, w22, #0x1
   48c04:	bl	c900 <__gmpn_sqr@plt>
   48c08:	add	x8, x19, #0x38
   48c0c:	ldr	x25, [x8, w21, uxtw #3]
   48c10:	ldr	x5, [x19, #16]
   48c14:	add	x2, x19, #0x28
   48c18:	mov	w3, #0x1                   	// #1
   48c1c:	mov	x0, x26
   48c20:	mov	x1, x27
   48c24:	mov	x4, x25
   48c28:	bl	c3e0 <__gmpn_powlo@plt>
   48c2c:	ldr	x2, [x19, #8]
   48c30:	mov	x0, x27
   48c34:	mov	x1, x26
   48c38:	mov	x3, x25
   48c3c:	bl	cee0 <__gmpn_mullo_n@plt>
   48c40:	add	x28, x28, x23, lsl #3
   48c44:	add	x1, x27, x23, lsl #3
   48c48:	sub	x23, x25, x23
   48c4c:	mov	x0, x28
   48c50:	mov	x2, x23
   48c54:	mov	x3, x20
   48c58:	mov	x4, x24
   48c5c:	mov	w5, wzr
   48c60:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   48c64:	ldr	x8, [x28]
   48c68:	cbnz	x8, 48c80 <__gmpn_broot_invm1@@Base+0x2c0>
   48c6c:	subs	x23, x23, #0x1
   48c70:	str	xzr, [x28]
   48c74:	b.eq	48c9c <__gmpn_broot_invm1@@Base+0x2dc>  // b.none
   48c78:	ldr	x8, [x28, #8]!
   48c7c:	cbz	x8, 48c6c <__gmpn_broot_invm1@@Base+0x2ac>
   48c80:	neg	x8, x8
   48c84:	subs	x2, x23, #0x1
   48c88:	str	x8, [x28]
   48c8c:	b.eq	48c9c <__gmpn_broot_invm1@@Base+0x2dc>  // b.none
   48c90:	add	x0, x28, #0x8
   48c94:	mov	x1, x0
   48c98:	bl	c2a0 <__gmpn_com@plt>
   48c9c:	sub	x22, x22, #0x1
   48ca0:	cbnz	w21, 48bec <__gmpn_broot_invm1@@Base+0x22c>
   48ca4:	ldr	x0, [x19, #32]
   48ca8:	cbnz	x0, 48cdc <__gmpn_broot_invm1@@Base+0x31c>
   48cac:	mov	sp, x29
   48cb0:	ldp	x20, x19, [sp, #80]
   48cb4:	ldp	x22, x21, [sp, #64]
   48cb8:	ldp	x24, x23, [sp, #48]
   48cbc:	ldp	x26, x25, [sp, #32]
   48cc0:	ldp	x28, x27, [sp, #16]
   48cc4:	ldp	x29, x30, [sp], #96
   48cc8:	ret
   48ccc:	add	x0, x19, #0x20
   48cd0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   48cd4:	mov	x22, x0
   48cd8:	b	48a18 <__gmpn_broot_invm1@@Base+0x58>
   48cdc:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   48ce0:	b	48cac <__gmpn_broot_invm1@@Base+0x2ec>
   48ce4:	add	x0, x19, #0x20
   48ce8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   48cec:	mov	x26, x0
   48cf0:	b	48ba8 <__gmpn_broot_invm1@@Base+0x1e8>

0000000000048cf4 <__gmpn_broot@@Base>:
   48cf4:	stp	x29, x30, [sp, #-64]!
   48cf8:	stp	x22, x21, [sp, #32]
   48cfc:	stp	x20, x19, [sp, #48]
   48d00:	mov	x19, x2
   48d04:	mov	x20, x1
   48d08:	cmp	x3, #0x1
   48d0c:	mov	x21, x0
   48d10:	str	x23, [sp, #16]
   48d14:	mov	x29, sp
   48d18:	b.ne	48d30 <__gmpn_broot@@Base+0x3c>  // b.any
   48d1c:	mov	x0, x21
   48d20:	mov	x1, x20
   48d24:	mov	x2, x19
   48d28:	bl	ca70 <__gmpn_copyi@plt>
   48d2c:	b	48d8c <__gmpn_broot@@Base+0x98>
   48d30:	lsl	x1, x19, #3
   48d34:	mov	w8, #0x7f00                	// #32512
   48d38:	mov	x22, x3
   48d3c:	cmp	x1, x8
   48d40:	str	xzr, [x29, #24]
   48d44:	b.hi	48da4 <__gmpn_broot@@Base+0xb0>  // b.pmore
   48d48:	add	x9, x1, #0xf
   48d4c:	mov	x8, sp
   48d50:	and	x9, x9, #0xfffffffffffffff0
   48d54:	sub	x23, x8, x9
   48d58:	mov	sp, x23
   48d5c:	mov	x0, x23
   48d60:	mov	x1, x20
   48d64:	mov	x2, x19
   48d68:	mov	x3, x22
   48d6c:	bl	c950 <__gmpn_broot_invm1@plt>
   48d70:	mov	x0, x21
   48d74:	mov	x1, x23
   48d78:	mov	x2, x20
   48d7c:	mov	x3, x19
   48d80:	bl	cee0 <__gmpn_mullo_n@plt>
   48d84:	ldr	x0, [x29, #24]
   48d88:	cbnz	x0, 48db4 <__gmpn_broot@@Base+0xc0>
   48d8c:	mov	sp, x29
   48d90:	ldp	x20, x19, [sp, #48]
   48d94:	ldp	x22, x21, [sp, #32]
   48d98:	ldr	x23, [sp, #16]
   48d9c:	ldp	x29, x30, [sp], #64
   48da0:	ret
   48da4:	add	x0, x29, #0x18
   48da8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   48dac:	mov	x23, x0
   48db0:	b	48d5c <__gmpn_broot@@Base+0x68>
   48db4:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   48db8:	b	48d8c <__gmpn_broot@@Base+0x98>

0000000000048dbc <__gmpn_brootinv@@Base>:
   48dbc:	stp	x29, x30, [sp, #-96]!
   48dc0:	stp	x28, x27, [sp, #16]
   48dc4:	stp	x26, x25, [sp, #32]
   48dc8:	stp	x24, x23, [sp, #48]
   48dcc:	stp	x22, x21, [sp, #64]
   48dd0:	stp	x20, x19, [sp, #80]
   48dd4:	mov	x29, sp
   48dd8:	sub	sp, sp, #0x220
   48ddc:	adrp	x12, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   48de0:	ldr	x12, [x12, #3952]
   48de4:	add	x8, x2, #0x3
   48de8:	lsr	x9, x3, #1
   48dec:	ubfx	x10, x3, #1, #7
   48df0:	asr	x11, x8, #1
   48df4:	add	x8, x9, #0x1
   48df8:	ldrb	w12, [x12, x10]
   48dfc:	stur	x8, [x29, #-16]
   48e00:	ldr	x10, [x1]
   48e04:	mov	w14, #0x2                   	// #2
   48e08:	msub	x13, x12, x3, x14
   48e0c:	mul	x12, x13, x12
   48e10:	msub	x13, x12, x3, x14
   48e14:	lsl	w15, w10, #1
   48e18:	mul	x13, x12, x13
   48e1c:	eor	w12, w15, w10, lsl #2
   48e20:	and	w12, w12, w8, lsl #3
   48e24:	and	x12, x12, #0x8
   48e28:	eor	x12, x12, x10
   48e2c:	mov	x19, x4
   48e30:	mov	x20, x3
   48e34:	mov	x22, x0
   48e38:	lsl	x9, x8, #1
   48e3c:	msub	x14, x13, x3, x14
   48e40:	and	x16, x8, #0x3f
   48e44:	mov	w15, #0x1                   	// #1
   48e48:	mov	x17, x12
   48e4c:	str	x1, [sp]
   48e50:	mul	x17, x17, x17
   48e54:	tst	x16, #0x1
   48e58:	csinc	x18, x17, xzr, ne  // ne = any
   48e5c:	lsr	x16, x16, #1
   48e60:	mul	x15, x18, x15
   48e64:	cbnz	x16, 48e50 <__gmpn_brootinv@@Base+0x94>
   48e68:	add	x23, x19, x2, lsl #3
   48e6c:	mul	x24, x13, x14
   48e70:	mul	x13, x15, x10
   48e74:	add	x25, x23, x11, lsl #3
   48e78:	neg	x11, x13
   48e7c:	madd	x11, x9, x12, x11
   48e80:	mul	x11, x11, x24
   48e84:	and	x13, x8, #0x3fff
   48e88:	mov	w12, #0x1                   	// #1
   48e8c:	mov	x14, x11
   48e90:	mul	x14, x14, x14
   48e94:	tst	x13, #0x1
   48e98:	csinc	x15, x14, xzr, ne  // ne = any
   48e9c:	lsr	x13, x13, #1
   48ea0:	mul	x12, x15, x12
   48ea4:	cbnz	x13, 48e90 <__gmpn_brootinv@@Base+0xd4>
   48ea8:	mul	x12, x12, x10
   48eac:	neg	x12, x12
   48eb0:	madd	x11, x9, x11, x12
   48eb4:	mul	x11, x11, x24
   48eb8:	mov	w12, #0x10                  	// #16
   48ebc:	mov	x13, x11
   48ec0:	mov	x15, x8
   48ec4:	mov	w14, #0x1                   	// #1
   48ec8:	mul	x13, x13, x13
   48ecc:	tst	x15, #0x1
   48ed0:	csinc	x16, x13, xzr, ne  // ne = any
   48ed4:	lsr	x15, x15, #1
   48ed8:	mul	x14, x16, x14
   48edc:	cbnz	x15, 48ec8 <__gmpn_brootinv@@Base+0x10c>
   48ee0:	mul	x13, x14, x10
   48ee4:	neg	x13, x13
   48ee8:	lsl	w12, w12, #1
   48eec:	madd	x11, x9, x11, x13
   48ef0:	cmp	w12, #0x40
   48ef4:	mul	x11, x11, x24
   48ef8:	b.cc	48ebc <__gmpn_brootinv@@Base+0x100>  // b.lo, b.ul, b.last
   48efc:	cmp	x2, #0x1
   48f00:	str	x11, [x22]
   48f04:	b.eq	49044 <__gmpn_brootinv@@Base+0x288>  // b.none
   48f08:	cmp	x2, #0x2
   48f0c:	b.ne	48f18 <__gmpn_brootinv@@Base+0x15c>  // b.any
   48f10:	mov	w8, wzr
   48f14:	b	48f38 <__gmpn_brootinv@@Base+0x17c>
   48f18:	mov	x8, xzr
   48f1c:	add	x9, sp, #0x8
   48f20:	add	x10, x2, #0x1
   48f24:	str	x2, [x9, x8, lsl #3]
   48f28:	asr	x2, x10, #1
   48f2c:	cmp	x2, #0x2
   48f30:	add	x8, x8, #0x1
   48f34:	b.ne	48f20 <__gmpn_brootinv@@Base+0x164>  // b.any
   48f38:	mov	w9, #0x2                   	// #2
   48f3c:	add	x10, sp, #0x8
   48f40:	sxtw	x28, w8
   48f44:	mov	w26, #0x1                   	// #1
   48f48:	str	x9, [x10, w8, uxtw #3]
   48f4c:	mov	x0, x19
   48f50:	mov	x1, x22
   48f54:	mov	x2, x26
   48f58:	bl	c900 <__gmpn_sqr@plt>
   48f5c:	ldur	x8, [x29, #-16]
   48f60:	mov	x0, x23
   48f64:	mov	x1, x22
   48f68:	mov	x2, x26
   48f6c:	lsl	x3, x8, #1
   48f70:	bl	d4b0 <__gmpn_mul_1@plt>
   48f74:	str	x0, [x23, x26, lsl #3]
   48f78:	add	x8, sp, #0x8
   48f7c:	ldr	x26, [x8, x28, lsl #3]
   48f80:	sub	x2, x29, #0x10
   48f84:	mov	w3, #0x1                   	// #1
   48f88:	mov	x0, x22
   48f8c:	mov	x1, x19
   48f90:	mov	x4, x26
   48f94:	mov	x5, x25
   48f98:	bl	c3e0 <__gmpn_powlo@plt>
   48f9c:	ldr	x1, [sp]
   48fa0:	mov	x0, x19
   48fa4:	mov	x2, x22
   48fa8:	mov	x3, x26
   48fac:	bl	cee0 <__gmpn_mullo_n@plt>
   48fb0:	add	x21, x26, #0x3
   48fb4:	asr	x27, x21, #1
   48fb8:	mov	x0, x19
   48fbc:	mov	x1, x23
   48fc0:	mov	x2, x19
   48fc4:	mov	x3, x27
   48fc8:	bl	c2e0 <__gmpn_sub_n@plt>
   48fcc:	cmp	x26, x21, asr #1
   48fd0:	b.le	4901c <__gmpn_brootinv@@Base+0x260>
   48fd4:	mov	x8, x0
   48fd8:	add	x0, x19, x27, lsl #3
   48fdc:	sub	x2, x26, x27
   48fe0:	cbnz	x8, 49014 <__gmpn_brootinv@@Base+0x258>
   48fe4:	ldr	x8, [x0]
   48fe8:	cbnz	x8, 49000 <__gmpn_brootinv@@Base+0x244>
   48fec:	subs	x2, x2, #0x1
   48ff0:	str	xzr, [x0]
   48ff4:	b.eq	4901c <__gmpn_brootinv@@Base+0x260>  // b.none
   48ff8:	ldr	x8, [x0, #8]!
   48ffc:	cbz	x8, 48fec <__gmpn_brootinv@@Base+0x230>
   49000:	neg	x8, x8
   49004:	subs	x2, x2, #0x1
   49008:	str	x8, [x0]
   4900c:	b.eq	4901c <__gmpn_brootinv@@Base+0x260>  // b.none
   49010:	add	x0, x0, #0x8
   49014:	mov	x1, x0
   49018:	bl	c2a0 <__gmpn_com@plt>
   4901c:	mov	x0, x22
   49020:	mov	x1, x19
   49024:	mov	x2, x26
   49028:	mov	x3, x20
   4902c:	mov	x4, x24
   49030:	mov	w5, wzr
   49034:	bl	c500 <__gmpn_pi1_bdiv_q_1@plt>
   49038:	cmp	x28, #0x0
   4903c:	sub	x28, x28, #0x1
   49040:	b.gt	48f4c <__gmpn_brootinv@@Base+0x190>
   49044:	add	sp, sp, #0x220
   49048:	ldp	x20, x19, [sp, #80]
   4904c:	ldp	x22, x21, [sp, #64]
   49050:	ldp	x24, x23, [sp, #48]
   49054:	ldp	x26, x25, [sp, #32]
   49058:	ldp	x28, x27, [sp, #16]
   4905c:	ldp	x29, x30, [sp], #96
   49060:	ret

0000000000049064 <__gmpn_bsqrt@@Base>:
   49064:	stp	x29, x30, [sp, #-48]!
   49068:	stp	x22, x21, [sp, #16]
   4906c:	stp	x20, x19, [sp, #32]
   49070:	mov	x19, x3
   49074:	lsr	x22, x2, #6
   49078:	mov	x21, x0
   4907c:	add	x3, x3, x22, lsl #3
   49080:	mov	x0, x19
   49084:	mov	x29, sp
   49088:	mov	x20, x1
   4908c:	bl	c770 <__gmpn_bsqrtinv@plt>
   49090:	mov	x0, x21
   49094:	mov	x1, x19
   49098:	mov	x2, x20
   4909c:	mov	x3, x22
   490a0:	ldp	x20, x19, [sp, #32]
   490a4:	ldp	x22, x21, [sp, #16]
   490a8:	ldp	x29, x30, [sp], #48
   490ac:	b	cee0 <__gmpn_mullo_n@plt>

00000000000490b0 <__gmpn_bsqrtinv@@Base>:
   490b0:	stp	x29, x30, [sp, #-80]!
   490b4:	stp	x28, x25, [sp, #16]
   490b8:	stp	x24, x23, [sp, #32]
   490bc:	stp	x22, x21, [sp, #48]
   490c0:	stp	x20, x19, [sp, #64]
   490c4:	mov	x29, sp
   490c8:	sub	sp, sp, #0x210
   490cc:	mov	w8, #0x1                   	// #1
   490d0:	str	x8, [x0]
   490d4:	ldr	x8, [x1]
   490d8:	cmp	x2, #0x1
   490dc:	b.ne	490f0 <__gmpn_bsqrtinv@@Base+0x40>  // b.any
   490e0:	and	x8, x8, #0x3
   490e4:	cmp	x8, #0x1
   490e8:	b.eq	491c8 <__gmpn_bsqrtinv@@Base+0x118>  // b.none
   490ec:	b	491d0 <__gmpn_bsqrtinv@@Base+0x120>
   490f0:	and	x8, x8, #0x7
   490f4:	cmp	x8, #0x1
   490f8:	b.ne	491d0 <__gmpn_bsqrtinv@@Base+0x120>  // b.any
   490fc:	cmp	x2, #0x2
   49100:	b.eq	491c8 <__gmpn_bsqrtinv@@Base+0x118>  // b.none
   49104:	lsr	x9, x2, #3
   49108:	and	x9, x9, #0x1ffffffffffffff8
   4910c:	add	x9, x9, x3
   49110:	mov	x19, x1
   49114:	mov	x20, x0
   49118:	mov	x21, x3
   4911c:	mov	x8, xzr
   49120:	add	x22, x9, #0x8
   49124:	add	x9, sp, #0x8
   49128:	add	x10, x2, #0x2
   4912c:	str	x2, [x9, x8, lsl #3]
   49130:	lsr	x2, x10, #1
   49134:	cmp	x2, #0x2
   49138:	add	x8, x8, #0x1
   4913c:	b.ne	49128 <__gmpn_bsqrtinv@@Base+0x78>  // b.any
   49140:	cmp	w8, #0x1
   49144:	b.lt	491c8 <__gmpn_bsqrtinv@@Base+0x118>  // b.tstop
   49148:	and	x24, x8, #0xffffffff
   4914c:	add	x8, sp, #0x8
   49150:	sub	x25, x8, #0x8
   49154:	ldr	x8, [x25, x24, lsl #3]
   49158:	mov	x0, x21
   4915c:	mov	x1, x20
   49160:	lsr	x8, x8, #6
   49164:	add	x23, x8, #0x1
   49168:	mov	x2, x23
   4916c:	bl	ca10 <__gmpn_sqrlo@plt>
   49170:	mov	x0, x22
   49174:	mov	x1, x20
   49178:	mov	x2, x21
   4917c:	mov	x3, x23
   49180:	bl	cee0 <__gmpn_mullo_n@plt>
   49184:	mov	w3, #0x3                   	// #3
   49188:	mov	x0, x21
   4918c:	mov	x1, x20
   49190:	mov	x2, x23
   49194:	bl	d4b0 <__gmpn_mul_1@plt>
   49198:	mov	x0, x20
   4919c:	mov	x1, x19
   491a0:	mov	x2, x22
   491a4:	mov	x3, x23
   491a8:	bl	cee0 <__gmpn_mullo_n@plt>
   491ac:	mov	x0, x20
   491b0:	mov	x1, x21
   491b4:	mov	x2, x20
   491b8:	mov	x3, x23
   491bc:	bl	c860 <__gmpn_rsh1sub_n@plt>
   491c0:	subs	x24, x24, #0x1
   491c4:	b.gt	49154 <__gmpn_bsqrtinv@@Base+0xa4>
   491c8:	mov	w0, #0x1                   	// #1
   491cc:	b	491d4 <__gmpn_bsqrtinv@@Base+0x124>
   491d0:	mov	w0, wzr
   491d4:	add	sp, sp, #0x210
   491d8:	ldp	x20, x19, [sp, #64]
   491dc:	ldp	x22, x21, [sp, #48]
   491e0:	ldp	x24, x23, [sp, #32]
   491e4:	ldp	x28, x25, [sp, #16]
   491e8:	ldp	x29, x30, [sp], #80
   491ec:	ret

00000000000491f0 <__gmpn_divexact@@Base>:
   491f0:	stp	x29, x30, [sp, #-96]!
   491f4:	stp	x26, x25, [sp, #32]
   491f8:	stp	x24, x23, [sp, #48]
   491fc:	stp	x22, x21, [sp, #64]
   49200:	stp	x20, x19, [sp, #80]
   49204:	mov	x23, x3
   49208:	ldr	x3, [x3]
   4920c:	mov	x22, x4
   49210:	mov	x20, x1
   49214:	mov	x19, x0
   49218:	str	x27, [sp, #16]
   4921c:	mov	x29, sp
   49220:	cbnz	x3, 49238 <__gmpn_divexact@@Base+0x48>
   49224:	ldr	x3, [x23, #8]!
   49228:	add	x20, x20, #0x8
   4922c:	sub	x22, x22, #0x1
   49230:	sub	x2, x2, #0x1
   49234:	cbz	x3, 49224 <__gmpn_divexact@@Base+0x34>
   49238:	cmp	x22, #0x1
   4923c:	b.ne	49250 <__gmpn_divexact@@Base+0x60>  // b.any
   49240:	mov	x0, x19
   49244:	mov	x1, x20
   49248:	bl	c790 <__gmpn_divexact_1@plt>
   4924c:	b	49380 <__gmpn_divexact@@Base+0x190>
   49250:	sub	x8, x2, x22
   49254:	rbit	x9, x3
   49258:	clz	x24, x9
   4925c:	add	x21, x8, #0x1
   49260:	str	xzr, [x29, #24]
   49264:	cbz	w24, 492ec <__gmpn_divexact@@Base+0xfc>
   49268:	cmp	x22, x21
   4926c:	csinc	x27, x22, x21, le
   49270:	lsl	x1, x27, #3
   49274:	mov	w8, #0x7f00                	// #32512
   49278:	cmp	x1, x8
   4927c:	add	x25, x21, #0x1
   49280:	b.hi	493b8 <__gmpn_divexact@@Base+0x1c8>  // b.pmore
   49284:	add	x9, x1, #0xf
   49288:	mov	x8, sp
   4928c:	and	x9, x9, #0xfffffffffffffff0
   49290:	sub	x26, x8, x9
   49294:	mov	sp, x26
   49298:	mov	x0, x26
   4929c:	mov	x1, x23
   492a0:	mov	x2, x27
   492a4:	mov	w3, w24
   492a8:	bl	c1b0 <__gmpn_rshift@plt>
   492ac:	lsl	x1, x25, #3
   492b0:	mov	w8, #0x7f00                	// #32512
   492b4:	cmp	x1, x8
   492b8:	b.hi	493c8 <__gmpn_divexact@@Base+0x1d8>  // b.pmore
   492bc:	add	x9, x1, #0xf
   492c0:	mov	x8, sp
   492c4:	and	x9, x9, #0xfffffffffffffff0
   492c8:	sub	x27, x8, x9
   492cc:	mov	sp, x27
   492d0:	mov	x0, x27
   492d4:	mov	x1, x20
   492d8:	mov	x2, x25
   492dc:	mov	w3, w24
   492e0:	bl	c1b0 <__gmpn_rshift@plt>
   492e4:	mov	x23, x26
   492e8:	mov	x20, x27
   492ec:	cmp	x22, x21
   492f0:	csel	x22, x21, x22, gt
   492f4:	mov	x0, x21
   492f8:	mov	x1, x22
   492fc:	bl	d3a0 <__gmpn_bdiv_q_itch@plt>
   49300:	lsl	x1, x0, #3
   49304:	mov	w8, #0x7f00                	// #32512
   49308:	cmp	x1, x8
   4930c:	b.hi	493a0 <__gmpn_divexact@@Base+0x1b0>  // b.pmore
   49310:	add	x9, x1, #0xf
   49314:	mov	x8, sp
   49318:	and	x9, x9, #0xfffffffffffffff0
   4931c:	sub	x5, x8, x9
   49320:	mov	sp, x5
   49324:	mov	x0, x19
   49328:	mov	x1, x20
   4932c:	mov	x2, x21
   49330:	mov	x3, x23
   49334:	mov	x4, x22
   49338:	bl	ca50 <__gmpn_bdiv_q@plt>
   4933c:	ldr	x0, [x29, #24]
   49340:	cbnz	x0, 493b0 <__gmpn_divexact@@Base+0x1c0>
   49344:	ldr	x8, [x19]
   49348:	cbz	x8, 49374 <__gmpn_divexact@@Base+0x184>
   4934c:	neg	x8, x8
   49350:	subs	x2, x21, #0x1
   49354:	str	x8, [x19]
   49358:	b.eq	49380 <__gmpn_divexact@@Base+0x190>  // b.none
   4935c:	add	x0, x19, #0x8
   49360:	mov	x1, x0
   49364:	bl	c2a0 <__gmpn_com@plt>
   49368:	b	49380 <__gmpn_divexact@@Base+0x190>
   4936c:	ldr	x8, [x19, #8]!
   49370:	cbnz	x8, 4934c <__gmpn_divexact@@Base+0x15c>
   49374:	subs	x21, x21, #0x1
   49378:	str	xzr, [x19]
   4937c:	b.ne	4936c <__gmpn_divexact@@Base+0x17c>  // b.any
   49380:	mov	sp, x29
   49384:	ldp	x20, x19, [sp, #80]
   49388:	ldp	x22, x21, [sp, #64]
   4938c:	ldp	x24, x23, [sp, #48]
   49390:	ldp	x26, x25, [sp, #32]
   49394:	ldr	x27, [sp, #16]
   49398:	ldp	x29, x30, [sp], #96
   4939c:	ret
   493a0:	add	x0, x29, #0x18
   493a4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   493a8:	mov	x5, x0
   493ac:	b	49324 <__gmpn_divexact@@Base+0x134>
   493b0:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   493b4:	b	49344 <__gmpn_divexact@@Base+0x154>
   493b8:	add	x0, x29, #0x18
   493bc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   493c0:	mov	x26, x0
   493c4:	b	49298 <__gmpn_divexact@@Base+0xa8>
   493c8:	add	x0, x29, #0x18
   493cc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   493d0:	mov	x27, x0
   493d4:	b	492d0 <__gmpn_divexact@@Base+0xe0>
   493d8:	nop
   493dc:	nop

00000000000493e0 <__gmpn_bdiv_dbm1c@@Base>:
   493e0:	ldr	x5, [x1], #8
   493e4:	ands	x6, x2, #0x3
   493e8:	b.eq	49408 <__gmpn_bdiv_dbm1c@@Base+0x28>  // b.none
   493ec:	cmp	x6, #0x2
   493f0:	b.cc	49418 <__gmpn_bdiv_dbm1c@@Base+0x38>  // b.lo, b.ul, b.last
   493f4:	b.eq	49430 <__gmpn_bdiv_dbm1c@@Base+0x50>  // b.none
   493f8:	mul	x12, x5, x3
   493fc:	umulh	x13, x5, x3
   49400:	ldr	x5, [x1], #8
   49404:	b	49480 <__gmpn_bdiv_dbm1c@@Base+0xa0>
   49408:	mul	x10, x5, x3
   4940c:	umulh	x11, x5, x3
   49410:	ldr	x5, [x1], #8
   49414:	b	49468 <__gmpn_bdiv_dbm1c@@Base+0x88>
   49418:	subs	x2, x2, #0x1
   4941c:	mul	x12, x5, x3
   49420:	umulh	x13, x5, x3
   49424:	b.ls	494b4 <__gmpn_bdiv_dbm1c@@Base+0xd4>  // b.plast
   49428:	ldr	x5, [x1], #8
   4942c:	b	49450 <__gmpn_bdiv_dbm1c@@Base+0x70>
   49430:	mul	x10, x5, x3
   49434:	umulh	x11, x5, x3
   49438:	ldr	x5, [x1], #8
   4943c:	b	49498 <__gmpn_bdiv_dbm1c@@Base+0xb8>
   49440:	ldr	x5, [x1], #8
   49444:	subs	x4, x4, x10
   49448:	str	x4, [x0], #8
   4944c:	sbc	x4, x4, x11
   49450:	mul	x10, x5, x3
   49454:	umulh	x11, x5, x3
   49458:	ldr	x5, [x1], #8
   4945c:	subs	x4, x4, x12
   49460:	str	x4, [x0], #8
   49464:	sbc	x4, x4, x13
   49468:	mul	x12, x5, x3
   4946c:	umulh	x13, x5, x3
   49470:	ldr	x5, [x1], #8
   49474:	subs	x4, x4, x10
   49478:	str	x4, [x0], #8
   4947c:	sbc	x4, x4, x11
   49480:	mul	x10, x5, x3
   49484:	umulh	x11, x5, x3
   49488:	ldr	x5, [x1], #8
   4948c:	subs	x4, x4, x12
   49490:	str	x4, [x0], #8
   49494:	sbc	x4, x4, x13
   49498:	subs	x2, x2, #0x4
   4949c:	mul	x12, x5, x3
   494a0:	umulh	x13, x5, x3
   494a4:	b.hi	49440 <__gmpn_bdiv_dbm1c@@Base+0x60>  // b.pmore
   494a8:	subs	x4, x4, x10
   494ac:	str	x4, [x0], #8
   494b0:	sbc	x4, x4, x11
   494b4:	subs	x4, x4, x12
   494b8:	str	x4, [x0]
   494bc:	sbc	x0, x4, x13
   494c0:	ret

00000000000494c4 <__gmpn_redc_1@@Base>:
   494c4:	stp	x29, x30, [sp, #-64]!
   494c8:	stp	x22, x21, [sp, #32]
   494cc:	stp	x20, x19, [sp, #48]
   494d0:	mov	x19, x3
   494d4:	mov	x20, x1
   494d8:	cmp	x3, #0x1
   494dc:	mov	x21, x0
   494e0:	stp	x24, x23, [sp, #16]
   494e4:	mov	x29, sp
   494e8:	b.lt	49520 <__gmpn_redc_1@@Base+0x5c>  // b.tstop
   494ec:	mov	x22, x4
   494f0:	mov	x23, x2
   494f4:	add	x24, x19, #0x1
   494f8:	ldr	x8, [x20]
   494fc:	mov	x0, x20
   49500:	mov	x1, x23
   49504:	mov	x2, x19
   49508:	mul	x3, x8, x22
   4950c:	bl	d420 <__gmpn_addmul_1@plt>
   49510:	sub	x24, x24, #0x1
   49514:	cmp	x24, #0x1
   49518:	str	x0, [x20], #8
   4951c:	b.gt	494f8 <__gmpn_redc_1@@Base+0x34>
   49520:	sub	x2, x20, x19, lsl #3
   49524:	mov	x0, x21
   49528:	mov	x1, x20
   4952c:	mov	x3, x19
   49530:	ldp	x20, x19, [sp, #48]
   49534:	ldp	x22, x21, [sp, #32]
   49538:	ldp	x24, x23, [sp, #16]
   4953c:	ldp	x29, x30, [sp], #64
   49540:	b	ca90 <__gmpn_add_n@plt>

0000000000049544 <__gmpn_redc_2@@Base>:
   49544:	stp	x29, x30, [sp, #-96]!
   49548:	stp	x24, x23, [sp, #48]
   4954c:	stp	x22, x21, [sp, #64]
   49550:	stp	x20, x19, [sp, #80]
   49554:	mov	x22, x4
   49558:	mov	x19, x3
   4955c:	mov	x23, x2
   49560:	mov	x20, x1
   49564:	mov	x21, x0
   49568:	str	x27, [sp, #16]
   4956c:	stp	x26, x25, [sp, #32]
   49570:	mov	x29, sp
   49574:	tbz	w19, #0, 49598 <__gmpn_redc_2@@Base+0x54>
   49578:	ldr	x8, [x20]
   4957c:	ldr	x9, [x22]
   49580:	mov	x0, x20
   49584:	mov	x1, x23
   49588:	mov	x2, x19
   4958c:	mul	x3, x9, x8
   49590:	bl	d420 <__gmpn_addmul_1@plt>
   49594:	str	x0, [x20], #8
   49598:	cmp	x19, #0x2
   4959c:	b.lt	49610 <__gmpn_redc_2@@Base+0xcc>  // b.tstop
   495a0:	add	x26, x19, #0x2
   495a4:	mov	x24, x20
   495a8:	ldp	x8, x11, [x22]
   495ac:	ldr	x9, [x20]
   495b0:	ldr	x10, [x24, #8]!
   495b4:	ldr	x27, [x20, x19, lsl #3]
   495b8:	umulh	x12, x8, x9
   495bc:	mul	x3, x9, x8
   495c0:	madd	x8, x10, x8, x12
   495c4:	mov	x0, x20
   495c8:	mov	x1, x23
   495cc:	mov	x2, x19
   495d0:	madd	x25, x11, x9, x8
   495d4:	bl	d420 <__gmpn_addmul_1@plt>
   495d8:	str	x0, [x20, x19, lsl #3]
   495dc:	mov	x0, x24
   495e0:	mov	x1, x23
   495e4:	mov	x2, x19
   495e8:	mov	x3, x25
   495ec:	bl	d420 <__gmpn_addmul_1@plt>
   495f0:	str	x0, [x24]
   495f4:	ldr	x8, [x20, x19, lsl #3]
   495f8:	sub	x26, x26, #0x2
   495fc:	cmp	x26, #0x3
   49600:	str	x8, [x20]
   49604:	str	x27, [x20, x19, lsl #3]
   49608:	add	x20, x20, #0x10
   4960c:	b.gt	495a4 <__gmpn_redc_2@@Base+0x60>
   49610:	sub	x2, x20, x19, lsl #3
   49614:	mov	x0, x21
   49618:	mov	x1, x20
   4961c:	mov	x3, x19
   49620:	ldp	x20, x19, [sp, #80]
   49624:	ldp	x22, x21, [sp, #64]
   49628:	ldp	x24, x23, [sp, #48]
   4962c:	ldp	x26, x25, [sp, #32]
   49630:	ldr	x27, [sp, #16]
   49634:	ldp	x29, x30, [sp], #96
   49638:	b	ca90 <__gmpn_add_n@plt>

000000000004963c <__gmpn_redc_n@@Base>:
   4963c:	stp	x29, x30, [sp, #-96]!
   49640:	stp	x22, x21, [sp, #64]
   49644:	mov	x29, sp
   49648:	mov	x21, x0
   4964c:	mov	x0, x3
   49650:	str	x27, [sp, #16]
   49654:	stp	x26, x25, [sp, #32]
   49658:	stp	x24, x23, [sp, #48]
   4965c:	stp	x20, x19, [sp, #80]
   49660:	mov	x25, x4
   49664:	mov	x19, x3
   49668:	mov	x20, x2
   4966c:	mov	x22, x1
   49670:	str	xzr, [x29, #24]
   49674:	bl	c880 <__gmpn_mulmod_bnm1_next_size@plt>
   49678:	cmp	x19, x0, asr #1
   4967c:	add	x8, x19, x0, lsl #1
   49680:	csel	x9, x0, xzr, gt
   49684:	add	x8, x8, x9
   49688:	lsl	x8, x8, #3
   4968c:	add	x1, x8, #0x20
   49690:	mov	w8, #0x7f00                	// #32512
   49694:	mov	x23, x0
   49698:	cmp	x1, x8
   4969c:	b.hi	4979c <__gmpn_redc_n@@Base+0x160>  // b.pmore
   496a0:	add	x9, x1, #0xf
   496a4:	mov	x8, sp
   496a8:	and	x9, x9, #0xfffffffffffffff0
   496ac:	sub	x24, x8, x9
   496b0:	mov	sp, x24
   496b4:	mov	x0, x24
   496b8:	mov	x1, x22
   496bc:	mov	x2, x25
   496c0:	mov	x3, x19
   496c4:	bl	cee0 <__gmpn_mullo_n@plt>
   496c8:	add	x25, x24, x19, lsl #3
   496cc:	add	x26, x25, x23, lsl #3
   496d0:	mov	x0, x25
   496d4:	mov	x1, x23
   496d8:	mov	x2, x24
   496dc:	mov	x3, x19
   496e0:	mov	x4, x20
   496e4:	mov	x5, x19
   496e8:	mov	x6, x26
   496ec:	bl	c9a0 <__gmpn_mulmod_bnm1@plt>
   496f0:	lsl	x27, x19, #1
   496f4:	subs	x3, x27, x23
   496f8:	b.le	497b4 <__gmpn_redc_n@@Base+0x178>
   496fc:	mov	x0, x26
   49700:	mov	x1, x25
   49704:	mov	x2, x22
   49708:	bl	c2e0 <__gmpn_sub_n@plt>
   4970c:	add	x8, x25, x27, lsl #3
   49710:	sub	x8, x8, x23, lsl #3
   49714:	ldr	x9, [x8]
   49718:	subs	x9, x9, x0
   4971c:	str	x9, [x8]
   49720:	b.cs	49748 <__gmpn_redc_n@@Base+0x10c>  // b.hs, b.nlast
   49724:	mov	w8, #0x18                  	// #24
   49728:	mul	x8, x19, x8
   4972c:	sub	x8, x8, x23, lsl #3
   49730:	add	x8, x8, x24
   49734:	add	x8, x8, #0x8
   49738:	ldr	x9, [x8]
   4973c:	sub	x10, x9, #0x1
   49740:	str	x10, [x8], #8
   49744:	cbz	x9, 49738 <__gmpn_redc_n@@Base+0xfc>
   49748:	add	x1, x22, x19, lsl #3
   4974c:	add	x2, x25, x19, lsl #3
   49750:	mov	x0, x21
   49754:	mov	x3, x19
   49758:	bl	c2e0 <__gmpn_sub_n@plt>
   4975c:	cbz	x0, 49774 <__gmpn_redc_n@@Base+0x138>
   49760:	mov	x0, x21
   49764:	mov	x1, x21
   49768:	mov	x2, x20
   4976c:	mov	x3, x19
   49770:	bl	ca90 <__gmpn_add_n@plt>
   49774:	ldr	x0, [x29, #24]
   49778:	cbnz	x0, 497ac <__gmpn_redc_n@@Base+0x170>
   4977c:	mov	sp, x29
   49780:	ldp	x20, x19, [sp, #80]
   49784:	ldp	x22, x21, [sp, #64]
   49788:	ldp	x24, x23, [sp, #48]
   4978c:	ldp	x26, x25, [sp, #32]
   49790:	ldr	x27, [sp, #16]
   49794:	ldp	x29, x30, [sp], #96
   49798:	ret
   4979c:	add	x0, x29, #0x18
   497a0:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   497a4:	mov	x24, x0
   497a8:	b	496b4 <__gmpn_redc_n@@Base+0x78>
   497ac:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   497b0:	b	4977c <__gmpn_redc_n@@Base+0x140>
   497b4:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   497b8:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   497bc:	add	x0, x0, #0x8af
   497c0:	add	x2, x2, #0x8b8
   497c4:	mov	w1, #0x46                  	// #70
   497c8:	bl	c6e0 <__gmp_assert_fail@plt>

00000000000497cc <__gmpn_powm@@Base>:
   497cc:	stp	x29, x30, [sp, #-96]!
   497d0:	stp	x28, x27, [sp, #16]
   497d4:	stp	x26, x25, [sp, #32]
   497d8:	stp	x24, x23, [sp, #48]
   497dc:	stp	x22, x21, [sp, #64]
   497e0:	stp	x20, x19, [sp, #80]
   497e4:	mov	x29, sp
   497e8:	sub	sp, sp, #0x50
   497ec:	stur	xzr, [x29, #-24]
   497f0:	add	x8, x3, x4, lsl #3
   497f4:	ldur	x8, [x8, #-8]
   497f8:	lsl	x9, x4, #6
   497fc:	mov	x22, x7
   49800:	mov	x19, x6
   49804:	clz	x8, x8
   49808:	sub	x26, x9, x8
   4980c:	adrp	x8, 54000 <__gmpn_bases@@Base+0x2938>
   49810:	mov	x20, x5
   49814:	mov	x27, x1
   49818:	mov	x21, x0
   4981c:	mov	x28, xzr
   49820:	mov	x24, xzr
   49824:	add	x8, x8, #0x8c8
   49828:	mov	x23, x26
   4982c:	mov	x9, #0x100000000           	// #4294967296
   49830:	stur	x3, [x29, #-48]
   49834:	add	x10, x8, x24, lsl #3
   49838:	ldr	x10, [x10, #8]
   4983c:	add	x24, x24, #0x1
   49840:	add	x28, x28, x9
   49844:	cmp	x10, x26
   49848:	b.cc	49834 <__gmpn_powm@@Base+0x68>  // b.lo, b.ul, b.last
   4984c:	cmp	x19, #0x2a
   49850:	lsl	x1, x19, #3
   49854:	stur	x1, [x29, #-64]
   49858:	stur	x23, [x29, #-40]
   4985c:	b.le	498a8 <__gmpn_powm@@Base+0xdc>
   49860:	mov	w8, #0x7f00                	// #32512
   49864:	stur	x27, [x29, #-32]
   49868:	mov	x27, x2
   4986c:	cmp	x1, x8
   49870:	b.hi	4a218 <__gmpn_powm@@Base+0xa4c>  // b.pmore
   49874:	add	x9, x1, #0xf
   49878:	mov	x8, sp
   4987c:	and	x9, x9, #0xfffffffffffffff0
   49880:	sub	x25, x8, x9
   49884:	mov	sp, x25
   49888:	mov	x0, x25
   4988c:	mov	x1, x20
   49890:	mov	x2, x19
   49894:	mov	x3, x22
   49898:	bl	cd40 <__gmpn_binvert@plt>
   4989c:	mov	x2, x27
   498a0:	ldur	x27, [x29, #-32]
   498a4:	b	498e4 <__gmpn_powm@@Base+0x118>
   498a8:	ldr	x8, [x20]
   498ac:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   498b0:	ldr	x9, [x9, #3952]
   498b4:	sub	x25, x29, #0x10
   498b8:	ubfx	x10, x8, #1, #7
   498bc:	ldrb	w9, [x9, x10]
   498c0:	mov	w10, #0x2                   	// #2
   498c4:	msub	x11, x8, x9, x10
   498c8:	mul	x9, x11, x9
   498cc:	msub	x10, x9, x8, x10
   498d0:	mul	x9, x9, x10
   498d4:	orr	x10, xzr, #0xfffffffffffffffe
   498d8:	madd	x8, x9, x8, x10
   498dc:	mul	x8, x8, x9
   498e0:	stur	x8, [x29, #-16]
   498e4:	sub	x23, x24, #0x1
   498e8:	lsl	x8, x19, x23
   498ec:	lsl	x1, x8, #3
   498f0:	mov	w8, #0x7f00                	// #32512
   498f4:	cmp	x1, x8
   498f8:	b.hi	4a1fc <__gmpn_powm@@Base+0xa30>  // b.pmore
   498fc:	add	x9, x1, #0xf
   49900:	mov	x8, sp
   49904:	and	x9, x9, #0xfffffffffffffff0
   49908:	sub	x0, x8, x9
   4990c:	mov	sp, x0
   49910:	mov	x1, x27
   49914:	mov	x3, x20
   49918:	mov	x4, x19
   4991c:	mov	x27, x0
   49920:	bl	4a228 <__gmpn_powm@@Base+0xa5c>
   49924:	mov	x0, x22
   49928:	mov	x1, x27
   4992c:	mov	x2, x19
   49930:	stur	x27, [x29, #-32]
   49934:	bl	c900 <__gmpn_sqr@plt>
   49938:	cmp	x19, #0x2a
   4993c:	b.le	4995c <__gmpn_powm@@Base+0x190>
   49940:	mov	x0, x21
   49944:	mov	x1, x22
   49948:	mov	x2, x20
   4994c:	mov	x3, x19
   49950:	mov	x4, x25
   49954:	bl	c7f0 <__gmpn_redc_n@plt>
   49958:	b	4998c <__gmpn_powm@@Base+0x1c0>
   4995c:	ldr	x4, [x25]
   49960:	mov	x0, x21
   49964:	mov	x1, x22
   49968:	mov	x2, x20
   4996c:	mov	x3, x19
   49970:	bl	d110 <__gmpn_redc_1@plt>
   49974:	cbz	x0, 4998c <__gmpn_powm@@Base+0x1c0>
   49978:	mov	x0, x21
   4997c:	mov	x1, x21
   49980:	mov	x2, x20
   49984:	mov	x3, x19
   49988:	bl	c2e0 <__gmpn_sub_n@plt>
   4998c:	mov	w8, #0xffffffff            	// #-1
   49990:	lsl	w8, w8, w23
   49994:	cmn	w8, #0x2
   49998:	b.gt	49a6c <__gmpn_powm@@Base+0x2a0>
   4999c:	ldur	x27, [x29, #-32]
   499a0:	mvn	w8, w8
   499a4:	sxtw	x8, w8
   499a8:	add	x23, x8, #0x1
   499ac:	cmp	x19, #0x1
   499b0:	b.ne	499f4 <__gmpn_powm@@Base+0x228>  // b.any
   499b4:	ldr	x8, [x27]
   499b8:	ldr	x9, [x21]
   499bc:	umulh	x10, x8, x9
   499c0:	mul	x8, x9, x8
   499c4:	stp	x8, x10, [x22]
   499c8:	ldr	x9, [x25]
   499cc:	ldr	x11, [x20]
   499d0:	cmp	x8, #0x0
   499d4:	mul	x9, x9, x8
   499d8:	umulh	x9, x11, x9
   499dc:	cinc	x8, x9, ne  // ne = any
   499e0:	adds	x8, x8, x10
   499e4:	csel	x9, x11, xzr, cs  // cs = hs, nlast
   499e8:	sub	x8, x8, x9
   499ec:	str	x8, [x27, #8]!
   499f0:	b	49a60 <__gmpn_powm@@Base+0x294>
   499f4:	mov	x0, x22
   499f8:	mov	x1, x27
   499fc:	mov	x2, x21
   49a00:	mov	x3, x19
   49a04:	bl	c9b0 <__gmpn_mul_n@plt>
   49a08:	cmp	x19, #0x2a
   49a0c:	add	x27, x27, x19, lsl #3
   49a10:	b.le	49a30 <__gmpn_powm@@Base+0x264>
   49a14:	mov	x0, x27
   49a18:	mov	x1, x22
   49a1c:	mov	x2, x20
   49a20:	mov	x3, x19
   49a24:	mov	x4, x25
   49a28:	bl	c7f0 <__gmpn_redc_n@plt>
   49a2c:	b	49a60 <__gmpn_powm@@Base+0x294>
   49a30:	ldr	x4, [x25]
   49a34:	mov	x0, x27
   49a38:	mov	x1, x22
   49a3c:	mov	x2, x20
   49a40:	mov	x3, x19
   49a44:	bl	d110 <__gmpn_redc_1@plt>
   49a48:	cbz	x0, 49a60 <__gmpn_powm@@Base+0x294>
   49a4c:	mov	x0, x27
   49a50:	mov	x1, x27
   49a54:	mov	x2, x20
   49a58:	mov	x3, x19
   49a5c:	bl	c2e0 <__gmpn_sub_n@plt>
   49a60:	sub	x23, x23, #0x1
   49a64:	cmp	x23, #0x1
   49a68:	b.gt	499ac <__gmpn_powm@@Base+0x1e0>
   49a6c:	cmp	x26, x28, asr #32
   49a70:	asr	x13, x28, #32
   49a74:	b.cs	49a84 <__gmpn_powm@@Base+0x2b8>  // b.hs, b.nlast
   49a78:	ldp	x28, x11, [x29, #-48]
   49a7c:	ldr	x8, [x28]
   49a80:	b	49ac0 <__gmpn_powm@@Base+0x2f4>
   49a84:	ldur	x28, [x29, #-48]
   49a88:	sub	x8, x26, x13
   49a8c:	lsr	x9, x8, #6
   49a90:	and	x10, x8, #0x3f
   49a94:	ldr	x11, [x28, x9, lsl #3]
   49a98:	mov	w12, #0x40                  	// #64
   49a9c:	sub	w10, w12, w10
   49aa0:	cmp	w10, w24
   49aa4:	lsr	x8, x11, x8
   49aa8:	b.ge	49abc <__gmpn_powm@@Base+0x2f0>  // b.tcont
   49aac:	add	x9, x28, x9, lsl #3
   49ab0:	ldr	x9, [x9, #8]
   49ab4:	lsl	x9, x9, x10
   49ab8:	add	x8, x9, x8
   49abc:	and	x11, x24, #0xffffffff
   49ac0:	mov	x9, #0xffffffffffffffff    	// #-1
   49ac4:	lsl	x9, x9, x11
   49ac8:	bic	x8, x8, x9
   49acc:	subs	x10, x26, x13
   49ad0:	rbit	x9, x8
   49ad4:	csel	x10, xzr, x10, cc  // cc = lo, ul, last
   49ad8:	clz	x9, x9
   49adc:	add	x26, x9, x10
   49ae0:	lsr	x8, x8, x9
   49ae4:	ldur	x9, [x29, #-32]
   49ae8:	lsr	x8, x8, #1
   49aec:	mul	x8, x8, x19
   49af0:	mov	x0, x21
   49af4:	add	x1, x9, x8, lsl #3
   49af8:	mov	x2, x19
   49afc:	stur	x13, [x29, #-40]
   49b00:	bl	ca70 <__gmpn_copyi@plt>
   49b04:	subs	x27, x19, #0x1
   49b08:	b.ne	49c70 <__gmpn_powm@@Base+0x4a4>  // b.any
   49b0c:	cbz	x26, 4a128 <__gmpn_powm@@Base+0x95c>
   49b10:	ldur	x0, [x29, #-40]
   49b14:	mov	x8, #0xffffffffffffffff    	// #-1
   49b18:	lsl	x9, x8, x24
   49b1c:	mvn	x9, x9
   49b20:	mov	w10, #0x40                  	// #64
   49b24:	sub	x11, x26, #0x1
   49b28:	lsr	x12, x11, #3
   49b2c:	and	x12, x12, #0x1ffffffffffffff8
   49b30:	ldr	x12, [x28, x12]
   49b34:	lsr	x12, x12, x11
   49b38:	tbz	w12, #0, 49b54 <__gmpn_powm@@Base+0x388>
   49b3c:	subs	x11, x26, x0
   49b40:	b.cs	49b98 <__gmpn_powm@@Base+0x3cc>  // b.hs, b.nlast
   49b44:	ldr	x11, [x28]
   49b48:	lsl	x12, x8, x26
   49b4c:	bic	x11, x11, x12
   49b50:	b	49bc8 <__gmpn_powm@@Base+0x3fc>
   49b54:	ldr	x12, [x21]
   49b58:	umulh	x13, x12, x12
   49b5c:	mov	x26, x11
   49b60:	mul	x12, x12, x12
   49b64:	stp	x12, x13, [x22]
   49b68:	ldr	x14, [x25]
   49b6c:	ldr	x15, [x20]
   49b70:	cmp	x12, #0x0
   49b74:	mul	x14, x14, x12
   49b78:	umulh	x14, x15, x14
   49b7c:	cinc	x12, x14, ne  // ne = any
   49b80:	adds	x12, x12, x13
   49b84:	csel	x13, x15, xzr, cs  // cs = hs, nlast
   49b88:	sub	x12, x12, x13
   49b8c:	str	x12, [x21]
   49b90:	cbnz	x11, 49b24 <__gmpn_powm@@Base+0x358>
   49b94:	b	4a110 <__gmpn_powm@@Base+0x944>
   49b98:	lsr	x12, x11, #6
   49b9c:	ldr	x14, [x28, x12, lsl #3]
   49ba0:	and	x13, x11, #0x3f
   49ba4:	sub	w13, w10, w13
   49ba8:	cmp	w13, w24
   49bac:	lsr	x11, x14, x11
   49bb0:	b.ge	49bc4 <__gmpn_powm@@Base+0x3f8>  // b.tcont
   49bb4:	add	x12, x28, x12, lsl #3
   49bb8:	ldr	x12, [x12, #8]
   49bbc:	lsl	x12, x12, x13
   49bc0:	add	x11, x12, x11
   49bc4:	and	x11, x11, x9
   49bc8:	ldr	x12, [x25]
   49bcc:	ldr	x15, [x21]
   49bd0:	subs	x13, x26, x0
   49bd4:	rbit	x14, x11
   49bd8:	csel	w16, w26, w24, cc  // cc = lo, ul, last
   49bdc:	csel	x17, xzr, x13, cc  // cc = lo, ul, last
   49be0:	clz	x13, x14
   49be4:	add	x26, x13, x17
   49be8:	sub	w14, w13, w16
   49bec:	umulh	x16, x15, x15
   49bf0:	mul	x15, x15, x15
   49bf4:	stp	x15, x16, [x22]
   49bf8:	ldr	x17, [x20]
   49bfc:	mul	x18, x12, x15
   49c00:	cmp	x15, #0x0
   49c04:	umulh	x15, x17, x18
   49c08:	cinc	x15, x15, ne  // ne = any
   49c0c:	adds	x15, x15, x16
   49c10:	csel	x16, x17, xzr, cs  // cs = hs, nlast
   49c14:	sub	x15, x15, x16
   49c18:	adds	w14, w14, #0x1
   49c1c:	str	x15, [x21]
   49c20:	b.cc	49bec <__gmpn_powm@@Base+0x420>  // b.lo, b.ul, b.last
   49c24:	lsr	x11, x11, x13
   49c28:	ldur	x13, [x29, #-32]
   49c2c:	lsl	x11, x11, #2
   49c30:	and	x11, x11, #0xfffffffffffffff8
   49c34:	ldr	x11, [x13, x11]
   49c38:	umulh	x13, x15, x11
   49c3c:	mul	x11, x11, x15
   49c40:	stp	x11, x13, [x22]
   49c44:	ldr	x14, [x20]
   49c48:	mul	x12, x11, x12
   49c4c:	cmp	x11, #0x0
   49c50:	umulh	x12, x14, x12
   49c54:	cinc	x11, x12, ne  // ne = any
   49c58:	adds	x11, x11, x13
   49c5c:	csel	x12, x14, xzr, cs  // cs = hs, nlast
   49c60:	sub	x11, x11, x12
   49c64:	str	x11, [x21]
   49c68:	cbnz	x26, 49b24 <__gmpn_powm@@Base+0x358>
   49c6c:	b	4a110 <__gmpn_powm@@Base+0x944>
   49c70:	cmp	x19, #0xd
   49c74:	b.le	49dd8 <__gmpn_powm@@Base+0x60c>
   49c78:	cmp	x19, #0x2a
   49c7c:	b.le	49f78 <__gmpn_powm@@Base+0x7ac>
   49c80:	cbz	x26, 4a128 <__gmpn_powm@@Base+0x95c>
   49c84:	ldur	x12, [x29, #-40]
   49c88:	mov	x8, #0xffffffffffffffff    	// #-1
   49c8c:	lsl	x8, x8, x24
   49c90:	mvn	x8, x8
   49c94:	stur	x8, [x29, #-72]
   49c98:	sub	x23, x26, #0x1
   49c9c:	lsr	x8, x23, #3
   49ca0:	and	x8, x8, #0x1ffffffffffffff8
   49ca4:	ldr	x8, [x28, x8]
   49ca8:	lsr	x8, x8, x23
   49cac:	tbz	w8, #0, 49ccc <__gmpn_powm@@Base+0x500>
   49cb0:	subs	x8, x26, x12
   49cb4:	b.cs	49d04 <__gmpn_powm@@Base+0x538>  // b.hs, b.nlast
   49cb8:	ldr	x8, [x28]
   49cbc:	mov	x9, #0xffffffffffffffff    	// #-1
   49cc0:	lsl	x9, x9, x26
   49cc4:	bic	x9, x8, x9
   49cc8:	b	49d3c <__gmpn_powm@@Base+0x570>
   49ccc:	mov	x0, x22
   49cd0:	mov	x1, x21
   49cd4:	mov	x2, x19
   49cd8:	bl	c900 <__gmpn_sqr@plt>
   49cdc:	mov	x0, x21
   49ce0:	mov	x1, x22
   49ce4:	mov	x2, x20
   49ce8:	mov	x3, x19
   49cec:	mov	x4, x25
   49cf0:	bl	c7f0 <__gmpn_redc_n@plt>
   49cf4:	ldur	x12, [x29, #-40]
   49cf8:	mov	x26, x23
   49cfc:	cbnz	x23, 49c98 <__gmpn_powm@@Base+0x4cc>
   49d00:	b	4a110 <__gmpn_powm@@Base+0x944>
   49d04:	lsr	x9, x8, #6
   49d08:	ldr	x11, [x28, x9, lsl #3]
   49d0c:	and	x10, x8, #0x3f
   49d10:	mov	w13, #0x40                  	// #64
   49d14:	sub	w10, w13, w10
   49d18:	cmp	w10, w24
   49d1c:	lsr	x8, x11, x8
   49d20:	b.ge	49d34 <__gmpn_powm@@Base+0x568>  // b.tcont
   49d24:	add	x9, x28, x9, lsl #3
   49d28:	ldr	x9, [x9, #8]
   49d2c:	lsl	x9, x9, x10
   49d30:	add	x8, x9, x8
   49d34:	ldur	x9, [x29, #-72]
   49d38:	and	x9, x8, x9
   49d3c:	subs	x8, x26, x12
   49d40:	stur	x9, [x29, #-56]
   49d44:	rbit	x9, x9
   49d48:	csel	w10, w26, w24, cc  // cc = lo, ul, last
   49d4c:	csel	x8, xzr, x8, cc  // cc = lo, ul, last
   49d50:	clz	x28, x9
   49d54:	add	x26, x28, x8
   49d58:	sub	w23, w28, w10
   49d5c:	mov	x0, x22
   49d60:	mov	x1, x21
   49d64:	mov	x2, x19
   49d68:	bl	c900 <__gmpn_sqr@plt>
   49d6c:	mov	x0, x21
   49d70:	mov	x1, x22
   49d74:	mov	x2, x20
   49d78:	mov	x3, x19
   49d7c:	mov	x4, x25
   49d80:	bl	c7f0 <__gmpn_redc_n@plt>
   49d84:	adds	w23, w23, #0x1
   49d88:	b.cc	49d5c <__gmpn_powm@@Base+0x590>  // b.lo, b.ul, b.last
   49d8c:	ldur	x8, [x29, #-56]
   49d90:	ldur	x9, [x29, #-32]
   49d94:	mov	x0, x22
   49d98:	mov	x1, x21
   49d9c:	lsr	x8, x8, x28
   49da0:	lsr	x8, x8, #1
   49da4:	mul	x8, x8, x19
   49da8:	add	x2, x9, x8, lsl #3
   49dac:	mov	x3, x19
   49db0:	bl	c9b0 <__gmpn_mul_n@plt>
   49db4:	mov	x0, x21
   49db8:	mov	x1, x22
   49dbc:	mov	x2, x20
   49dc0:	mov	x3, x19
   49dc4:	mov	x4, x25
   49dc8:	bl	c7f0 <__gmpn_redc_n@plt>
   49dcc:	ldp	x28, x12, [x29, #-48]
   49dd0:	cbnz	x26, 49c98 <__gmpn_powm@@Base+0x4cc>
   49dd4:	b	4a110 <__gmpn_powm@@Base+0x944>
   49dd8:	ldur	x12, [x29, #-40]
   49ddc:	cbz	x26, 4a110 <__gmpn_powm@@Base+0x944>
   49de0:	mov	x8, #0xffffffffffffffff    	// #-1
   49de4:	lsl	x8, x8, x24
   49de8:	mvn	x8, x8
   49dec:	stur	x8, [x29, #-72]
   49df0:	sub	x8, x26, #0x1
   49df4:	lsr	x9, x8, #3
   49df8:	and	x9, x9, #0x1ffffffffffffff8
   49dfc:	ldr	x9, [x28, x9]
   49e00:	lsr	x9, x9, x8
   49e04:	tbz	w9, #0, 49e24 <__gmpn_powm@@Base+0x658>
   49e08:	subs	x8, x26, x12
   49e0c:	b.cs	49e6c <__gmpn_powm@@Base+0x6a0>  // b.hs, b.nlast
   49e10:	ldr	x8, [x28]
   49e14:	mov	x9, #0xffffffffffffffff    	// #-1
   49e18:	lsl	x9, x9, x26
   49e1c:	bic	x9, x8, x9
   49e20:	b	49ea4 <__gmpn_powm@@Base+0x6d8>
   49e24:	mov	x0, x22
   49e28:	mov	x1, x21
   49e2c:	mov	x2, x19
   49e30:	mov	x26, x8
   49e34:	bl	c1a0 <__gmpn_sqr_basecase@plt>
   49e38:	ldr	x4, [x25]
   49e3c:	mov	x0, x21
   49e40:	mov	x1, x22
   49e44:	mov	x2, x20
   49e48:	mov	x3, x19
   49e4c:	bl	d110 <__gmpn_redc_1@plt>
   49e50:	cbz	x0, 49f6c <__gmpn_powm@@Base+0x7a0>
   49e54:	mov	x0, x21
   49e58:	mov	x1, x21
   49e5c:	mov	x2, x20
   49e60:	mov	x3, x19
   49e64:	bl	c2e0 <__gmpn_sub_n@plt>
   49e68:	b	49f6c <__gmpn_powm@@Base+0x7a0>
   49e6c:	lsr	x9, x8, #6
   49e70:	ldr	x11, [x28, x9, lsl #3]
   49e74:	and	x10, x8, #0x3f
   49e78:	mov	w13, #0x40                  	// #64
   49e7c:	sub	w10, w13, w10
   49e80:	cmp	w10, w24
   49e84:	lsr	x8, x11, x8
   49e88:	b.ge	49e9c <__gmpn_powm@@Base+0x6d0>  // b.tcont
   49e8c:	add	x9, x28, x9, lsl #3
   49e90:	ldr	x9, [x9, #8]
   49e94:	lsl	x9, x9, x10
   49e98:	add	x8, x9, x8
   49e9c:	ldur	x9, [x29, #-72]
   49ea0:	and	x9, x8, x9
   49ea4:	subs	x8, x26, x12
   49ea8:	stur	x9, [x29, #-56]
   49eac:	rbit	x9, x9
   49eb0:	csel	w10, w26, w24, cc  // cc = lo, ul, last
   49eb4:	csel	x8, xzr, x8, cc  // cc = lo, ul, last
   49eb8:	clz	x28, x9
   49ebc:	add	x26, x28, x8
   49ec0:	sub	w23, w28, w10
   49ec4:	mov	x0, x22
   49ec8:	mov	x1, x21
   49ecc:	mov	x2, x19
   49ed0:	bl	c1a0 <__gmpn_sqr_basecase@plt>
   49ed4:	ldr	x4, [x25]
   49ed8:	mov	x0, x21
   49edc:	mov	x1, x22
   49ee0:	mov	x2, x20
   49ee4:	mov	x3, x19
   49ee8:	bl	d110 <__gmpn_redc_1@plt>
   49eec:	cbz	x0, 49f04 <__gmpn_powm@@Base+0x738>
   49ef0:	mov	x0, x21
   49ef4:	mov	x1, x21
   49ef8:	mov	x2, x20
   49efc:	mov	x3, x19
   49f00:	bl	c2e0 <__gmpn_sub_n@plt>
   49f04:	adds	w23, w23, #0x1
   49f08:	b.cc	49ec4 <__gmpn_powm@@Base+0x6f8>  // b.lo, b.ul, b.last
   49f0c:	ldur	x8, [x29, #-56]
   49f10:	ldur	x9, [x29, #-32]
   49f14:	mov	x0, x22
   49f18:	mov	x1, x21
   49f1c:	lsr	x8, x8, x28
   49f20:	lsr	x8, x8, #1
   49f24:	mul	x8, x8, x19
   49f28:	add	x3, x9, x8, lsl #3
   49f2c:	mov	x2, x19
   49f30:	mov	x4, x19
   49f34:	bl	c570 <__gmpn_mul_basecase@plt>
   49f38:	ldr	x4, [x25]
   49f3c:	mov	x0, x21
   49f40:	mov	x1, x22
   49f44:	mov	x2, x20
   49f48:	mov	x3, x19
   49f4c:	bl	d110 <__gmpn_redc_1@plt>
   49f50:	cbz	x0, 49f68 <__gmpn_powm@@Base+0x79c>
   49f54:	mov	x0, x21
   49f58:	mov	x1, x21
   49f5c:	mov	x2, x20
   49f60:	mov	x3, x19
   49f64:	bl	c2e0 <__gmpn_sub_n@plt>
   49f68:	ldur	x28, [x29, #-48]
   49f6c:	ldur	x12, [x29, #-40]
   49f70:	cbnz	x26, 49df0 <__gmpn_powm@@Base+0x624>
   49f74:	b	4a110 <__gmpn_powm@@Base+0x944>
   49f78:	cbz	x26, 4a128 <__gmpn_powm@@Base+0x95c>
   49f7c:	ldur	x12, [x29, #-40]
   49f80:	mov	x8, #0xffffffffffffffff    	// #-1
   49f84:	lsl	x8, x8, x24
   49f88:	mvn	x8, x8
   49f8c:	stur	x8, [x29, #-72]
   49f90:	sub	x8, x26, #0x1
   49f94:	lsr	x9, x8, #3
   49f98:	and	x9, x9, #0x1ffffffffffffff8
   49f9c:	ldr	x9, [x28, x9]
   49fa0:	lsr	x9, x9, x8
   49fa4:	tbz	w9, #0, 49fc4 <__gmpn_powm@@Base+0x7f8>
   49fa8:	subs	x8, x26, x12
   49fac:	b.cs	4a00c <__gmpn_powm@@Base+0x840>  // b.hs, b.nlast
   49fb0:	ldr	x8, [x28]
   49fb4:	mov	x9, #0xffffffffffffffff    	// #-1
   49fb8:	lsl	x9, x9, x26
   49fbc:	bic	x9, x8, x9
   49fc0:	b	4a044 <__gmpn_powm@@Base+0x878>
   49fc4:	mov	x0, x22
   49fc8:	mov	x1, x21
   49fcc:	mov	x2, x19
   49fd0:	mov	x26, x8
   49fd4:	bl	c900 <__gmpn_sqr@plt>
   49fd8:	ldr	x4, [x25]
   49fdc:	mov	x0, x21
   49fe0:	mov	x1, x22
   49fe4:	mov	x2, x20
   49fe8:	mov	x3, x19
   49fec:	bl	d110 <__gmpn_redc_1@plt>
   49ff0:	cbz	x0, 4a108 <__gmpn_powm@@Base+0x93c>
   49ff4:	mov	x0, x21
   49ff8:	mov	x1, x21
   49ffc:	mov	x2, x20
   4a000:	mov	x3, x19
   4a004:	bl	c2e0 <__gmpn_sub_n@plt>
   4a008:	b	4a108 <__gmpn_powm@@Base+0x93c>
   4a00c:	lsr	x9, x8, #6
   4a010:	ldr	x11, [x28, x9, lsl #3]
   4a014:	and	x10, x8, #0x3f
   4a018:	mov	w13, #0x40                  	// #64
   4a01c:	sub	w10, w13, w10
   4a020:	cmp	w10, w24
   4a024:	lsr	x8, x11, x8
   4a028:	b.ge	4a03c <__gmpn_powm@@Base+0x870>  // b.tcont
   4a02c:	add	x9, x28, x9, lsl #3
   4a030:	ldr	x9, [x9, #8]
   4a034:	lsl	x9, x9, x10
   4a038:	add	x8, x9, x8
   4a03c:	ldur	x9, [x29, #-72]
   4a040:	and	x9, x8, x9
   4a044:	subs	x8, x26, x12
   4a048:	stur	x9, [x29, #-56]
   4a04c:	rbit	x9, x9
   4a050:	csel	w10, w26, w24, cc  // cc = lo, ul, last
   4a054:	csel	x8, xzr, x8, cc  // cc = lo, ul, last
   4a058:	clz	x28, x9
   4a05c:	add	x26, x28, x8
   4a060:	sub	w23, w28, w10
   4a064:	mov	x0, x22
   4a068:	mov	x1, x21
   4a06c:	mov	x2, x19
   4a070:	bl	c900 <__gmpn_sqr@plt>
   4a074:	ldr	x4, [x25]
   4a078:	mov	x0, x21
   4a07c:	mov	x1, x22
   4a080:	mov	x2, x20
   4a084:	mov	x3, x19
   4a088:	bl	d110 <__gmpn_redc_1@plt>
   4a08c:	cbz	x0, 4a0a4 <__gmpn_powm@@Base+0x8d8>
   4a090:	mov	x0, x21
   4a094:	mov	x1, x21
   4a098:	mov	x2, x20
   4a09c:	mov	x3, x19
   4a0a0:	bl	c2e0 <__gmpn_sub_n@plt>
   4a0a4:	adds	w23, w23, #0x1
   4a0a8:	b.cc	4a064 <__gmpn_powm@@Base+0x898>  // b.lo, b.ul, b.last
   4a0ac:	ldur	x8, [x29, #-56]
   4a0b0:	ldur	x9, [x29, #-32]
   4a0b4:	mov	x0, x22
   4a0b8:	mov	x1, x21
   4a0bc:	lsr	x8, x8, x28
   4a0c0:	lsr	x8, x8, #1
   4a0c4:	mul	x8, x8, x19
   4a0c8:	add	x2, x9, x8, lsl #3
   4a0cc:	mov	x3, x19
   4a0d0:	bl	c9b0 <__gmpn_mul_n@plt>
   4a0d4:	ldr	x4, [x25]
   4a0d8:	mov	x0, x21
   4a0dc:	mov	x1, x22
   4a0e0:	mov	x2, x20
   4a0e4:	mov	x3, x19
   4a0e8:	bl	d110 <__gmpn_redc_1@plt>
   4a0ec:	cbz	x0, 4a104 <__gmpn_powm@@Base+0x938>
   4a0f0:	mov	x0, x21
   4a0f4:	mov	x1, x21
   4a0f8:	mov	x2, x20
   4a0fc:	mov	x3, x19
   4a100:	bl	c2e0 <__gmpn_sub_n@plt>
   4a104:	ldur	x28, [x29, #-48]
   4a108:	ldur	x12, [x29, #-40]
   4a10c:	cbnz	x26, 49f90 <__gmpn_powm@@Base+0x7c4>
   4a110:	mov	x0, x22
   4a114:	mov	x1, x21
   4a118:	mov	x2, x19
   4a11c:	bl	ca70 <__gmpn_copyi@plt>
   4a120:	cbnz	x19, 4a138 <__gmpn_powm@@Base+0x96c>
   4a124:	b	4a148 <__gmpn_powm@@Base+0x97c>
   4a128:	mov	x0, x22
   4a12c:	mov	x1, x21
   4a130:	mov	x2, x19
   4a134:	bl	ca70 <__gmpn_copyi@plt>
   4a138:	ldur	x2, [x29, #-64]
   4a13c:	add	x0, x22, x19, lsl #3
   4a140:	mov	w1, wzr
   4a144:	bl	c610 <memset@plt>
   4a148:	cmp	x19, #0x2a
   4a14c:	b.le	4a16c <__gmpn_powm@@Base+0x9a0>
   4a150:	mov	x0, x21
   4a154:	mov	x1, x22
   4a158:	mov	x2, x20
   4a15c:	mov	x3, x19
   4a160:	mov	x4, x25
   4a164:	bl	c7f0 <__gmpn_redc_n@plt>
   4a168:	b	4a19c <__gmpn_powm@@Base+0x9d0>
   4a16c:	ldr	x4, [x25]
   4a170:	mov	x0, x21
   4a174:	mov	x1, x22
   4a178:	mov	x2, x20
   4a17c:	mov	x3, x19
   4a180:	bl	d110 <__gmpn_redc_1@plt>
   4a184:	cbz	x0, 4a19c <__gmpn_powm@@Base+0x9d0>
   4a188:	mov	x0, x21
   4a18c:	mov	x1, x21
   4a190:	mov	x2, x20
   4a194:	mov	x3, x19
   4a198:	bl	c2e0 <__gmpn_sub_n@plt>
   4a19c:	add	x8, x27, #0x1
   4a1a0:	cmp	x8, #0x1
   4a1a4:	b.lt	4a1c0 <__gmpn_powm@@Base+0x9f4>  // b.tstop
   4a1a8:	ldr	x8, [x21, x27, lsl #3]
   4a1ac:	ldr	x9, [x20, x27, lsl #3]
   4a1b0:	sub	x27, x27, #0x1
   4a1b4:	cmp	x8, x9
   4a1b8:	b.eq	4a19c <__gmpn_powm@@Base+0x9d0>  // b.none
   4a1bc:	b.ls	4a1d4 <__gmpn_powm@@Base+0xa08>  // b.plast
   4a1c0:	mov	x0, x21
   4a1c4:	mov	x1, x21
   4a1c8:	mov	x2, x20
   4a1cc:	mov	x3, x19
   4a1d0:	bl	c2e0 <__gmpn_sub_n@plt>
   4a1d4:	ldur	x0, [x29, #-24]
   4a1d8:	cbnz	x0, 4a210 <__gmpn_powm@@Base+0xa44>
   4a1dc:	mov	sp, x29
   4a1e0:	ldp	x20, x19, [sp, #80]
   4a1e4:	ldp	x22, x21, [sp, #64]
   4a1e8:	ldp	x24, x23, [sp, #48]
   4a1ec:	ldp	x26, x25, [sp, #32]
   4a1f0:	ldp	x28, x27, [sp, #16]
   4a1f4:	ldp	x29, x30, [sp], #96
   4a1f8:	ret
   4a1fc:	sub	x0, x29, #0x18
   4a200:	stur	x2, [x29, #-32]
   4a204:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   4a208:	ldur	x2, [x29, #-32]
   4a20c:	b	49910 <__gmpn_powm@@Base+0x144>
   4a210:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   4a214:	b	4a1dc <__gmpn_powm@@Base+0xa10>
   4a218:	sub	x0, x29, #0x18
   4a21c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   4a220:	mov	x25, x0
   4a224:	b	49888 <__gmpn_powm@@Base+0xbc>
   4a228:	stp	x29, x30, [sp, #-80]!
   4a22c:	stp	x26, x25, [sp, #16]
   4a230:	stp	x24, x23, [sp, #32]
   4a234:	stp	x22, x21, [sp, #48]
   4a238:	stp	x20, x19, [sp, #64]
   4a23c:	mov	x29, sp
   4a240:	sub	sp, sp, #0x10
   4a244:	add	x21, x4, x2
   4a248:	add	x8, x2, x21
   4a24c:	lsl	x8, x8, #3
   4a250:	mov	x24, x1
   4a254:	add	x1, x8, #0x8
   4a258:	mov	w8, #0x7f00                	// #32512
   4a25c:	mov	x19, x4
   4a260:	mov	x20, x3
   4a264:	mov	x23, x2
   4a268:	mov	x22, x0
   4a26c:	cmp	x1, x8
   4a270:	stur	xzr, [x29, #-8]
   4a274:	b.hi	4a2f8 <__gmpn_powm@@Base+0xb2c>  // b.pmore
   4a278:	add	x9, x1, #0xf
   4a27c:	mov	x8, sp
   4a280:	and	x9, x9, #0xfffffffffffffff0
   4a284:	sub	x25, x8, x9
   4a288:	mov	sp, x25
   4a28c:	add	x26, x25, x21, lsl #3
   4a290:	cbz	x19, 4a2a4 <__gmpn_powm@@Base+0xad8>
   4a294:	lsl	x2, x19, #3
   4a298:	mov	x0, x25
   4a29c:	mov	w1, wzr
   4a2a0:	bl	c610 <memset@plt>
   4a2a4:	add	x0, x25, x19, lsl #3
   4a2a8:	mov	x1, x24
   4a2ac:	mov	x2, x23
   4a2b0:	bl	ca70 <__gmpn_copyi@plt>
   4a2b4:	mov	x0, x26
   4a2b8:	mov	x1, x22
   4a2bc:	mov	x2, xzr
   4a2c0:	mov	x3, x25
   4a2c4:	mov	x4, x21
   4a2c8:	mov	x5, x20
   4a2cc:	mov	x6, x19
   4a2d0:	bl	bf10 <__gmpn_tdiv_qr@plt>
   4a2d4:	ldur	x0, [x29, #-8]
   4a2d8:	cbnz	x0, 4a308 <__gmpn_powm@@Base+0xb3c>
   4a2dc:	mov	sp, x29
   4a2e0:	ldp	x20, x19, [sp, #64]
   4a2e4:	ldp	x22, x21, [sp, #48]
   4a2e8:	ldp	x24, x23, [sp, #32]
   4a2ec:	ldp	x26, x25, [sp, #16]
   4a2f0:	ldp	x29, x30, [sp], #80
   4a2f4:	ret
   4a2f8:	sub	x0, x29, #0x8
   4a2fc:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   4a300:	mov	x25, x0
   4a304:	b	4a28c <__gmpn_powm@@Base+0xac0>
   4a308:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   4a30c:	b	4a2dc <__gmpn_powm@@Base+0xb10>

000000000004a310 <__gmpn_powlo@@Base>:
   4a310:	stp	x29, x30, [sp, #-96]!
   4a314:	stp	x28, x27, [sp, #16]
   4a318:	stp	x26, x25, [sp, #32]
   4a31c:	stp	x24, x23, [sp, #48]
   4a320:	stp	x22, x21, [sp, #64]
   4a324:	stp	x20, x19, [sp, #80]
   4a328:	mov	x29, sp
   4a32c:	sub	sp, sp, #0x30
   4a330:	stur	xzr, [x29, #-8]
   4a334:	add	x8, x2, x3, lsl #3
   4a338:	ldur	x8, [x8, #-8]
   4a33c:	lsl	x9, x3, #6
   4a340:	mov	x23, x5
   4a344:	mov	x19, x4
   4a348:	clz	x8, x8
   4a34c:	sub	x25, x9, x8
   4a350:	adrp	x8, 54000 <__gmpn_bases@@Base+0x2938>
   4a354:	mov	x21, x2
   4a358:	mov	x24, x1
   4a35c:	mov	x20, x0
   4a360:	mov	w26, #0xffffffff            	// #-1
   4a364:	add	x8, x8, #0x920
   4a368:	add	w26, w26, #0x1
   4a36c:	ldr	x9, [x8, w26, uxtw #3]
   4a370:	cmp	x9, x25
   4a374:	b.cc	4a368 <__gmpn_powlo@@Base+0x58>  // b.lo, b.ul, b.last
   4a378:	add	w27, w26, #0x1
   4a37c:	cmp	w27, #0x2
   4a380:	stur	w27, [x29, #-28]
   4a384:	b.cc	4a42c <__gmpn_powlo@@Base+0x11c>  // b.lo, b.ul, b.last
   4a388:	lsl	x8, x19, x26
   4a38c:	lsl	x1, x8, #3
   4a390:	mov	w8, #0x7f00                	// #32512
   4a394:	cmp	x1, x8
   4a398:	b.hi	4a678 <__gmpn_powlo@@Base+0x368>  // b.pmore
   4a39c:	add	x9, x1, #0xf
   4a3a0:	mov	x8, sp
   4a3a4:	and	x9, x9, #0xfffffffffffffff0
   4a3a8:	sub	x28, x8, x9
   4a3ac:	mov	sp, x28
   4a3b0:	mov	x0, x28
   4a3b4:	mov	x1, x24
   4a3b8:	mov	x2, x19
   4a3bc:	bl	ca70 <__gmpn_copyi@plt>
   4a3c0:	mov	x0, x23
   4a3c4:	mov	x1, x24
   4a3c8:	mov	x2, x19
   4a3cc:	bl	ca10 <__gmpn_sqrlo@plt>
   4a3d0:	mov	w8, #0xffffffff            	// #-1
   4a3d4:	lsl	w8, w8, w26
   4a3d8:	mvn	w8, w8
   4a3dc:	sxtw	x22, w8
   4a3e0:	lsl	x26, x19, #3
   4a3e4:	mov	x1, x28
   4a3e8:	add	x24, x1, x26
   4a3ec:	mov	x0, x24
   4a3f0:	mov	x2, x23
   4a3f4:	mov	x3, x19
   4a3f8:	bl	cee0 <__gmpn_mullo_n@plt>
   4a3fc:	subs	x22, x22, #0x1
   4a400:	mov	x1, x24
   4a404:	b.ne	4a3e8 <__gmpn_powlo@@Base+0xd8>  // b.any
   4a408:	cmp	x25, w27, uxtw
   4a40c:	mov	w26, w27
   4a410:	b.cs	4a45c <__gmpn_powlo@@Base+0x14c>  // b.hs, b.nlast
   4a414:	ldr	x8, [x21]
   4a418:	mov	x9, #0xffffffffffffffff    	// #-1
   4a41c:	lsl	x9, x9, x25
   4a420:	bic	x9, x8, x9
   4a424:	sub	x8, x25, x26
   4a428:	b	4a49c <__gmpn_powlo@@Base+0x18c>
   4a42c:	add	x28, x23, x19, lsl #3
   4a430:	mov	x0, x28
   4a434:	mov	x1, x24
   4a438:	mov	x2, x19
   4a43c:	bl	ca70 <__gmpn_copyi@plt>
   4a440:	mov	x0, x20
   4a444:	mov	x1, x24
   4a448:	mov	x2, x19
   4a44c:	bl	ca70 <__gmpn_copyi@plt>
   4a450:	sub	x25, x25, #0x1
   4a454:	mov	w26, w27
   4a458:	b	4a4c4 <__gmpn_powlo@@Base+0x1b4>
   4a45c:	sub	x8, x25, x26
   4a460:	lsr	x10, x8, #6
   4a464:	ldr	x12, [x21, x10, lsl #3]
   4a468:	and	x9, x8, #0x3f
   4a46c:	mov	w11, #0x40                  	// #64
   4a470:	sub	w11, w11, w9
   4a474:	cmp	w11, w27
   4a478:	lsr	x9, x12, x8
   4a47c:	b.cs	4a490 <__gmpn_powlo@@Base+0x180>  // b.hs, b.nlast
   4a480:	add	x10, x21, x10, lsl #3
   4a484:	ldr	x10, [x10, #8]
   4a488:	lsl	x10, x10, x11
   4a48c:	add	x9, x10, x9
   4a490:	mov	x10, #0xffffffffffffffff    	// #-1
   4a494:	lsl	x10, x10, x26
   4a498:	bic	x9, x9, x10
   4a49c:	rbit	x10, x9
   4a4a0:	clz	x10, x10
   4a4a4:	add	x25, x8, x10
   4a4a8:	lsr	x8, x9, x10
   4a4ac:	lsr	x8, x8, #1
   4a4b0:	mul	x8, x8, x19
   4a4b4:	add	x1, x28, x8, lsl #3
   4a4b8:	mov	x0, x20
   4a4bc:	mov	x2, x19
   4a4c0:	bl	ca70 <__gmpn_copyi@plt>
   4a4c4:	mov	x8, #0xffffffffffffffff    	// #-1
   4a4c8:	lsl	x8, x8, x26
   4a4cc:	mov	w27, wzr
   4a4d0:	mvn	x8, x8
   4a4d4:	stp	x28, x21, [x29, #-24]
   4a4d8:	stur	x8, [x29, #-40]
   4a4dc:	sub	x22, x25, #0x1
   4a4e0:	lsr	x8, x22, #3
   4a4e4:	and	x8, x8, #0x1ffffffffffffff8
   4a4e8:	ldr	x8, [x21, x8]
   4a4ec:	mov	x24, x20
   4a4f0:	mov	x20, x23
   4a4f4:	lsr	x8, x8, x22
   4a4f8:	tbz	w8, #0, 4a518 <__gmpn_powlo@@Base+0x208>
   4a4fc:	subs	x8, x25, x26
   4a500:	b.cs	4a540 <__gmpn_powlo@@Base+0x230>  // b.hs, b.nlast
   4a504:	ldr	x8, [x21]
   4a508:	mov	x9, #0xffffffffffffffff    	// #-1
   4a50c:	lsl	x9, x9, x25
   4a510:	bic	x23, x8, x9
   4a514:	b	4a57c <__gmpn_powlo@@Base+0x26c>
   4a518:	mov	x0, x20
   4a51c:	mov	x1, x24
   4a520:	mov	x2, x19
   4a524:	bl	ca10 <__gmpn_sqrlo@plt>
   4a528:	cmp	w27, #0x0
   4a52c:	cset	w27, eq  // eq = none
   4a530:	mov	x25, x22
   4a534:	mov	x23, x24
   4a538:	cbnz	x22, 4a4dc <__gmpn_powlo@@Base+0x1cc>
   4a53c:	b	4a634 <__gmpn_powlo@@Base+0x324>
   4a540:	lsr	x9, x8, #6
   4a544:	and	x10, x8, #0x3f
   4a548:	mov	w12, #0x40                  	// #64
   4a54c:	ldr	x11, [x21, x9, lsl #3]
   4a550:	sub	w10, w12, w10
   4a554:	ldur	w12, [x29, #-28]
   4a558:	lsr	x8, x11, x8
   4a55c:	cmp	w10, w12
   4a560:	b.cs	4a574 <__gmpn_powlo@@Base+0x264>  // b.hs, b.nlast
   4a564:	add	x9, x21, x9, lsl #3
   4a568:	ldr	x9, [x9, #8]
   4a56c:	lsl	x9, x9, x10
   4a570:	add	x8, x9, x8
   4a574:	ldur	x9, [x29, #-40]
   4a578:	and	x23, x8, x9
   4a57c:	cmp	x25, x26
   4a580:	rbit	x8, x23
   4a584:	csel	x9, x26, x25, hi  // hi = pmore
   4a588:	clz	x28, x8
   4a58c:	sub	w21, w9, w28
   4a590:	cmp	w21, #0x2
   4a594:	sub	x25, x25, x9
   4a598:	b.cc	4a5d0 <__gmpn_powlo@@Base+0x2c0>  // b.lo, b.ul, b.last
   4a59c:	mov	w22, w21
   4a5a0:	mov	x0, x20
   4a5a4:	mov	x1, x24
   4a5a8:	mov	x2, x19
   4a5ac:	bl	ca10 <__gmpn_sqrlo@plt>
   4a5b0:	mov	x0, x24
   4a5b4:	mov	x1, x20
   4a5b8:	mov	x2, x19
   4a5bc:	bl	ca10 <__gmpn_sqrlo@plt>
   4a5c0:	sub	w22, w22, #0x2
   4a5c4:	cmp	w22, #0x1
   4a5c8:	b.hi	4a5a0 <__gmpn_powlo@@Base+0x290>  // b.pmore
   4a5cc:	and	w21, w21, #0x1
   4a5d0:	add	x25, x28, x25
   4a5d4:	lsr	x28, x23, x28
   4a5d8:	cbz	w21, 4a5f8 <__gmpn_powlo@@Base+0x2e8>
   4a5dc:	mov	x0, x20
   4a5e0:	mov	x1, x24
   4a5e4:	mov	x2, x19
   4a5e8:	bl	ca10 <__gmpn_sqrlo@plt>
   4a5ec:	mov	x23, x20
   4a5f0:	mov	x20, x24
   4a5f4:	b	4a608 <__gmpn_powlo@@Base+0x2f8>
   4a5f8:	cmp	w27, #0x0
   4a5fc:	cset	w27, eq  // eq = none
   4a600:	mov	x23, x24
   4a604:	mov	x24, x20
   4a608:	ldur	x9, [x29, #-24]
   4a60c:	lsr	x8, x28, #1
   4a610:	mul	x8, x8, x19
   4a614:	mov	x0, x24
   4a618:	add	x2, x9, x8, lsl #3
   4a61c:	mov	x1, x23
   4a620:	mov	x3, x19
   4a624:	bl	cee0 <__gmpn_mullo_n@plt>
   4a628:	ldur	x21, [x29, #-16]
   4a62c:	mov	x24, x23
   4a630:	cbnz	x25, 4a4dc <__gmpn_powlo@@Base+0x1cc>
   4a634:	cbz	w27, 4a648 <__gmpn_powlo@@Base+0x338>
   4a638:	mov	x0, x24
   4a63c:	mov	x1, x20
   4a640:	mov	x2, x19
   4a644:	bl	ca70 <__gmpn_copyi@plt>
   4a648:	ldur	x0, [x29, #-8]
   4a64c:	cbnz	x0, 4a670 <__gmpn_powlo@@Base+0x360>
   4a650:	mov	sp, x29
   4a654:	ldp	x20, x19, [sp, #80]
   4a658:	ldp	x22, x21, [sp, #64]
   4a65c:	ldp	x24, x23, [sp, #48]
   4a660:	ldp	x26, x25, [sp, #32]
   4a664:	ldp	x28, x27, [sp, #16]
   4a668:	ldp	x29, x30, [sp], #96
   4a66c:	ret
   4a670:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   4a674:	b	4a650 <__gmpn_powlo@@Base+0x340>
   4a678:	sub	x0, x29, #0x8
   4a67c:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   4a680:	mov	x28, x0
   4a684:	b	4a3b0 <__gmpn_powlo@@Base+0xa0>

000000000004a688 <__gmpn_sec_powm@@Base>:
   4a688:	sub	sp, sp, #0xb0
   4a68c:	adrp	x8, 54000 <__gmpn_bases@@Base+0x2938>
   4a690:	stp	x29, x30, [sp, #80]
   4a694:	stp	x28, x27, [sp, #96]
   4a698:	stp	x26, x25, [sp, #112]
   4a69c:	stp	x24, x23, [sp, #128]
   4a6a0:	stp	x22, x21, [sp, #144]
   4a6a4:	stp	x20, x19, [sp, #160]
   4a6a8:	add	x29, sp, #0x50
   4a6ac:	mov	x19, x6
   4a6b0:	mov	x20, x5
   4a6b4:	mov	x28, x1
   4a6b8:	mov	x21, x0
   4a6bc:	mov	x23, xzr
   4a6c0:	mov	x26, xzr
   4a6c4:	add	x8, x8, #0x990
   4a6c8:	mov	x9, #0x100000000           	// #4294967296
   4a6cc:	stp	x7, x3, [x29, #-16]
   4a6d0:	stur	x2, [x29, #-24]
   4a6d4:	add	x10, x8, x23, lsl #3
   4a6d8:	ldr	x10, [x10, #8]
   4a6dc:	add	x26, x26, x9
   4a6e0:	add	x23, x23, #0x1
   4a6e4:	cmp	x10, x4
   4a6e8:	b.cc	4a6d4 <__gmpn_sec_powm@@Base+0x4c>  // b.lo, b.ul, b.last
   4a6ec:	str	x4, [sp, #8]
   4a6f0:	ldr	x8, [x20]
   4a6f4:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4a6f8:	ldr	x9, [x9, #3952]
   4a6fc:	ldur	x0, [x29, #-16]
   4a700:	ubfx	x10, x8, #1, #7
   4a704:	orr	x11, xzr, #0xfffffffffffffffe
   4a708:	ldrb	w9, [x9, x10]
   4a70c:	mov	w10, #0x2                   	// #2
   4a710:	add	x27, x0, x19, lsl #3
   4a714:	mov	w22, #0x1                   	// #1
   4a718:	msub	x12, x8, x9, x10
   4a71c:	mul	x9, x12, x9
   4a720:	msub	x10, x9, x8, x10
   4a724:	mul	x9, x9, x10
   4a728:	mov	x5, x27
   4a72c:	lsl	x12, x19, x23
   4a730:	madd	x8, x9, x8, x11
   4a734:	str	x22, [x5], #8
   4a738:	mov	w2, #0x1                   	// #1
   4a73c:	mov	x1, x27
   4a740:	mov	x3, x20
   4a744:	mov	x4, x19
   4a748:	add	x24, x0, x12, lsl #3
   4a74c:	mul	x25, x8, x9
   4a750:	bl	4aaec <__gmpn_sec_powm@@Base+0x464>
   4a754:	ldur	x2, [x29, #-24]
   4a758:	add	x5, x27, x19, lsl #3
   4a75c:	mov	x0, x27
   4a760:	mov	x1, x28
   4a764:	mov	x3, x20
   4a768:	mov	x4, x19
   4a76c:	stur	x27, [x29, #-32]
   4a770:	bl	4aaec <__gmpn_sec_powm@@Base+0x464>
   4a774:	lsl	w8, w22, w23
   4a778:	stur	x23, [x29, #-24]
   4a77c:	str	x8, [sp, #16]
   4a780:	cmp	w8, #0x3
   4a784:	lsl	x8, x19, #3
   4a788:	str	x8, [sp, #40]
   4a78c:	b.lt	4a87c <__gmpn_sec_powm@@Base+0x1f4>  // b.tstop
   4a790:	add	x9, x19, x19, lsl #1
   4a794:	ldr	x8, [sp, #16]
   4a798:	lsl	x9, x9, #3
   4a79c:	str	x9, [sp, #32]
   4a7a0:	lsl	x9, x19, #4
   4a7a4:	str	x9, [sp, #24]
   4a7a8:	ldur	x28, [x29, #-32]
   4a7ac:	ldur	x23, [x29, #-16]
   4a7b0:	sub	w8, w8, #0x2
   4a7b4:	sxtw	x8, w8
   4a7b8:	add	x27, x8, #0x2
   4a7bc:	mov	x0, x24
   4a7c0:	mov	x1, x28
   4a7c4:	mov	x2, x19
   4a7c8:	cmp	x19, #0x11
   4a7cc:	b.le	4a7e0 <__gmpn_sec_powm@@Base+0x158>
   4a7d0:	mov	x3, x28
   4a7d4:	mov	x4, x19
   4a7d8:	bl	c570 <__gmpn_mul_basecase@plt>
   4a7dc:	b	4a7e4 <__gmpn_sec_powm@@Base+0x15c>
   4a7e0:	bl	c1a0 <__gmpn_sqr_basecase@plt>
   4a7e4:	ldr	x8, [sp, #24]
   4a7e8:	mov	x1, x24
   4a7ec:	mov	x2, x20
   4a7f0:	mov	x3, x19
   4a7f4:	add	x22, x23, x8
   4a7f8:	mov	x0, x22
   4a7fc:	mov	x4, x25
   4a800:	bl	d110 <__gmpn_redc_1@plt>
   4a804:	mov	x1, x22
   4a808:	mov	x2, x22
   4a80c:	mov	x3, x20
   4a810:	mov	x4, x19
   4a814:	bl	c030 <__gmpn_cnd_sub_n@plt>
   4a818:	ldur	x3, [x29, #-32]
   4a81c:	mov	x0, x24
   4a820:	mov	x1, x22
   4a824:	mov	x2, x19
   4a828:	mov	x4, x19
   4a82c:	bl	c570 <__gmpn_mul_basecase@plt>
   4a830:	ldr	x8, [sp, #32]
   4a834:	mov	x1, x24
   4a838:	mov	x2, x20
   4a83c:	mov	x3, x19
   4a840:	add	x23, x23, x8
   4a844:	mov	x0, x23
   4a848:	mov	x4, x25
   4a84c:	bl	d110 <__gmpn_redc_1@plt>
   4a850:	mov	x1, x23
   4a854:	mov	x2, x23
   4a858:	mov	x3, x20
   4a85c:	mov	x4, x19
   4a860:	bl	c030 <__gmpn_cnd_sub_n@plt>
   4a864:	ldr	x8, [sp, #40]
   4a868:	sub	x27, x27, #0x2
   4a86c:	cmp	x27, #0x2
   4a870:	mov	x23, x22
   4a874:	add	x28, x28, x8
   4a878:	b.gt	4a7bc <__gmpn_sec_powm@@Base+0x134>
   4a87c:	ldr	x9, [sp, #8]
   4a880:	asr	x23, x26, #32
   4a884:	cmp	x23, x9
   4a888:	b.hi	4aad4 <__gmpn_sec_powm@@Base+0x44c>  // b.pmore
   4a88c:	ldur	x11, [x29, #-8]
   4a890:	sub	x22, x9, x23
   4a894:	lsr	x10, x22, #6
   4a898:	ldur	x27, [x29, #-24]
   4a89c:	ldr	x12, [x11, x10, lsl #3]
   4a8a0:	and	x9, x22, #0x3f
   4a8a4:	mov	w11, #0x40                  	// #64
   4a8a8:	sub	w11, w11, w9
   4a8ac:	and	x8, x27, #0xffffffff
   4a8b0:	cmp	w11, w27
   4a8b4:	lsr	x9, x12, x22
   4a8b8:	b.ge	4a8d0 <__gmpn_sec_powm@@Base+0x248>  // b.tcont
   4a8bc:	ldur	x12, [x29, #-8]
   4a8c0:	add	x10, x12, x10, lsl #3
   4a8c4:	ldr	x10, [x10, #8]
   4a8c8:	lsl	x10, x10, x11
   4a8cc:	add	x9, x10, x9
   4a8d0:	mov	x10, #0xffffffffffffffff    	// #-1
   4a8d4:	lsl	x26, x10, x8
   4a8d8:	ldr	x8, [sp, #16]
   4a8dc:	ldur	x1, [x29, #-16]
   4a8e0:	bic	x4, x9, x26
   4a8e4:	mov	x0, x21
   4a8e8:	sxtw	x3, w8
   4a8ec:	mov	x2, x19
   4a8f0:	stur	x3, [x29, #-32]
   4a8f4:	bl	c4e0 <__gmpn_sec_tabselect@plt>
   4a8f8:	cbz	x22, 4aa38 <__gmpn_sec_powm@@Base+0x3b0>
   4a8fc:	mvn	x8, x26
   4a900:	add	x28, x24, x19, lsl #4
   4a904:	str	x8, [sp, #32]
   4a908:	subs	x8, x22, x23
   4a90c:	b.cs	4a928 <__gmpn_sec_powm@@Base+0x2a0>  // b.hs, b.nlast
   4a910:	ldur	x8, [x29, #-8]
   4a914:	mov	x9, #0xffffffffffffffff    	// #-1
   4a918:	lsl	x9, x9, x22
   4a91c:	ldr	x8, [x8]
   4a920:	bic	x26, x8, x9
   4a924:	b	4a968 <__gmpn_sec_powm@@Base+0x2e0>
   4a928:	ldur	x10, [x29, #-8]
   4a92c:	lsr	x9, x8, #6
   4a930:	mov	w12, #0x40                  	// #64
   4a934:	ldr	x11, [x10, x9, lsl #3]
   4a938:	and	x10, x8, #0x3f
   4a93c:	sub	w10, w12, w10
   4a940:	cmp	w10, w27
   4a944:	lsr	x8, x11, x8
   4a948:	b.ge	4a960 <__gmpn_sec_powm@@Base+0x2d8>  // b.tcont
   4a94c:	ldur	x11, [x29, #-8]
   4a950:	add	x9, x11, x9, lsl #3
   4a954:	ldr	x9, [x9, #8]
   4a958:	lsl	x9, x9, x10
   4a95c:	add	x8, x9, x8
   4a960:	ldr	x9, [sp, #32]
   4a964:	and	x26, x8, x9
   4a968:	cmp	x22, x23
   4a96c:	csel	w27, w22, w27, cc  // cc = lo, ul, last
   4a970:	mov	x0, x24
   4a974:	mov	x1, x21
   4a978:	mov	x2, x19
   4a97c:	cmp	x19, #0x11
   4a980:	b.le	4a994 <__gmpn_sec_powm@@Base+0x30c>
   4a984:	mov	x3, x21
   4a988:	mov	x4, x19
   4a98c:	bl	c570 <__gmpn_mul_basecase@plt>
   4a990:	b	4a998 <__gmpn_sec_powm@@Base+0x310>
   4a994:	bl	c1a0 <__gmpn_sqr_basecase@plt>
   4a998:	mov	x0, x21
   4a99c:	mov	x1, x24
   4a9a0:	mov	x2, x20
   4a9a4:	mov	x3, x19
   4a9a8:	mov	x4, x25
   4a9ac:	bl	d110 <__gmpn_redc_1@plt>
   4a9b0:	mov	x1, x21
   4a9b4:	mov	x2, x21
   4a9b8:	mov	x3, x20
   4a9bc:	mov	x4, x19
   4a9c0:	bl	c030 <__gmpn_cnd_sub_n@plt>
   4a9c4:	subs	w27, w27, #0x1
   4a9c8:	b.ne	4a970 <__gmpn_sec_powm@@Base+0x2e8>  // b.any
   4a9cc:	ldur	x1, [x29, #-16]
   4a9d0:	ldur	x3, [x29, #-32]
   4a9d4:	mov	x0, x28
   4a9d8:	mov	x2, x19
   4a9dc:	mov	x4, x26
   4a9e0:	bl	c4e0 <__gmpn_sec_tabselect@plt>
   4a9e4:	mov	x0, x24
   4a9e8:	mov	x1, x21
   4a9ec:	mov	x2, x19
   4a9f0:	mov	x3, x28
   4a9f4:	mov	x4, x19
   4a9f8:	bl	c570 <__gmpn_mul_basecase@plt>
   4a9fc:	mov	x0, x21
   4aa00:	mov	x1, x24
   4aa04:	mov	x2, x20
   4aa08:	mov	x3, x19
   4aa0c:	mov	x4, x25
   4aa10:	bl	d110 <__gmpn_redc_1@plt>
   4aa14:	mov	x1, x21
   4aa18:	mov	x2, x21
   4aa1c:	mov	x3, x20
   4aa20:	mov	x4, x19
   4aa24:	bl	c030 <__gmpn_cnd_sub_n@plt>
   4aa28:	ldur	x27, [x29, #-24]
   4aa2c:	subs	x8, x22, x23
   4aa30:	csel	x22, xzr, x8, cc  // cc = lo, ul, last
   4aa34:	b.hi	4a908 <__gmpn_sec_powm@@Base+0x280>  // b.pmore
   4aa38:	mov	x0, x24
   4aa3c:	mov	x1, x21
   4aa40:	mov	x2, x19
   4aa44:	bl	ca70 <__gmpn_copyi@plt>
   4aa48:	cbz	x19, 4aa5c <__gmpn_sec_powm@@Base+0x3d4>
   4aa4c:	ldr	x2, [sp, #40]
   4aa50:	add	x0, x24, x19, lsl #3
   4aa54:	mov	w1, wzr
   4aa58:	bl	c610 <memset@plt>
   4aa5c:	mov	x0, x21
   4aa60:	mov	x1, x24
   4aa64:	mov	x2, x20
   4aa68:	mov	x3, x19
   4aa6c:	mov	x4, x25
   4aa70:	bl	d110 <__gmpn_redc_1@plt>
   4aa74:	mov	x1, x21
   4aa78:	mov	x2, x21
   4aa7c:	mov	x3, x20
   4aa80:	mov	x4, x19
   4aa84:	bl	c030 <__gmpn_cnd_sub_n@plt>
   4aa88:	mov	x0, x24
   4aa8c:	mov	x1, x21
   4aa90:	mov	x2, x20
   4aa94:	mov	x3, x19
   4aa98:	bl	c2e0 <__gmpn_sub_n@plt>
   4aa9c:	mov	x1, x21
   4aaa0:	mov	x2, x21
   4aaa4:	mov	x3, x20
   4aaa8:	mov	x4, x19
   4aaac:	ldp	x20, x19, [sp, #160]
   4aab0:	ldp	x22, x21, [sp, #144]
   4aab4:	ldp	x24, x23, [sp, #128]
   4aab8:	ldp	x26, x25, [sp, #112]
   4aabc:	ldp	x28, x27, [sp, #96]
   4aac0:	ldp	x29, x30, [sp, #80]
   4aac4:	cmp	w0, #0x0
   4aac8:	cset	w0, eq  // eq = none
   4aacc:	add	sp, sp, #0xb0
   4aad0:	b	c030 <__gmpn_cnd_sub_n@plt>
   4aad4:	adrp	x0, 54000 <__gmpn_bases@@Base+0x2938>
   4aad8:	adrp	x2, 54000 <__gmpn_bases@@Base+0x2938>
   4aadc:	add	x0, x0, #0x970
   4aae0:	add	x2, x2, #0x97b
   4aae4:	mov	w1, #0x12a                 	// #298
   4aae8:	bl	c6e0 <__gmp_assert_fail@plt>
   4aaec:	stp	x29, x30, [sp, #-64]!
   4aaf0:	stp	x24, x23, [sp, #16]
   4aaf4:	stp	x22, x21, [sp, #32]
   4aaf8:	stp	x20, x19, [sp, #48]
   4aafc:	mov	x20, x5
   4ab00:	mov	x19, x4
   4ab04:	mov	x22, x3
   4ab08:	mov	x23, x2
   4ab0c:	mov	x24, x1
   4ab10:	mov	x21, x0
   4ab14:	mov	x29, sp
   4ab18:	cbz	x4, 4ab2c <__gmpn_sec_powm@@Base+0x4a4>
   4ab1c:	lsl	x2, x19, #3
   4ab20:	mov	x0, x20
   4ab24:	mov	w1, wzr
   4ab28:	bl	c610 <memset@plt>
   4ab2c:	add	x0, x20, x19, lsl #3
   4ab30:	mov	x1, x24
   4ab34:	mov	x2, x23
   4ab38:	bl	ca70 <__gmpn_copyi@plt>
   4ab3c:	add	x8, x20, x23, lsl #3
   4ab40:	add	x1, x19, x23
   4ab44:	add	x4, x8, x19, lsl #3
   4ab48:	mov	x0, x20
   4ab4c:	mov	x2, x22
   4ab50:	mov	x3, x19
   4ab54:	bl	c150 <__gmpn_sec_div_r@plt>
   4ab58:	mov	x0, x21
   4ab5c:	mov	x1, x20
   4ab60:	mov	x2, x19
   4ab64:	ldp	x20, x19, [sp, #48]
   4ab68:	ldp	x22, x21, [sp, #32]
   4ab6c:	ldp	x24, x23, [sp, #16]
   4ab70:	ldp	x29, x30, [sp], #64
   4ab74:	b	ca70 <__gmpn_copyi@plt>

000000000004ab78 <__gmpn_sec_powm_itch@@Base>:
   4ab78:	adrp	x9, 54000 <__gmpn_bases@@Base+0x2938>
   4ab7c:	mov	x8, xzr
   4ab80:	add	x9, x9, #0x990
   4ab84:	add	x10, x9, x8, lsl #3
   4ab88:	ldr	x10, [x10, #8]
   4ab8c:	add	x8, x8, #0x1
   4ab90:	cmp	x10, x1
   4ab94:	b.cc	4ab84 <__gmpn_sec_powm_itch@@Base+0xc>  // b.lo, b.ul, b.last
   4ab98:	add	x9, x2, x0
   4ab9c:	add	x9, x9, x2, lsl #1
   4aba0:	lsl	x8, x2, x8
   4aba4:	lsl	x9, x9, #1
   4aba8:	add	x9, x9, #0x2
   4abac:	add	x8, x8, x2, lsl #2
   4abb0:	cmp	x8, x9
   4abb4:	csel	x0, x8, x9, gt
   4abb8:	ret

000000000004abbc <__gmpn_sec_mul@@Base>:
   4abbc:	b	c570 <__gmpn_mul_basecase@plt>

000000000004abc0 <__gmpn_sec_mul_itch@@Base>:
   4abc0:	mov	x0, xzr
   4abc4:	ret

000000000004abc8 <__gmpn_sec_sqr@@Base>:
   4abc8:	mov	x3, x1
   4abcc:	mov	x4, x2
   4abd0:	b	c570 <__gmpn_mul_basecase@plt>

000000000004abd4 <__gmpn_sec_sqr_itch@@Base>:
   4abd4:	mov	x0, xzr
   4abd8:	ret

000000000004abdc <__gmpn_sec_div_qr_itch@@Base>:
   4abdc:	add	x8, x0, x0, lsl #1
   4abe0:	add	x0, x8, #0x4
   4abe4:	ret

000000000004abe8 <__gmpn_sec_div_qr@@Base>:
   4abe8:	stp	x29, x30, [sp, #-96]!
   4abec:	stp	x26, x25, [sp, #32]
   4abf0:	stp	x24, x23, [sp, #48]
   4abf4:	stp	x22, x21, [sp, #64]
   4abf8:	stp	x20, x19, [sp, #80]
   4abfc:	sub	x26, x4, #0x1
   4ac00:	ldr	x8, [x3, x26, lsl #3]
   4ac04:	mov	x22, x5
   4ac08:	mov	x19, x4
   4ac0c:	mov	x25, x3
   4ac10:	mov	x21, x2
   4ac14:	mov	x20, x1
   4ac18:	clz	x23, x8
   4ac1c:	mov	x24, x0
   4ac20:	str	x27, [sp, #16]
   4ac24:	mov	x29, sp
   4ac28:	cbz	w23, 4ace0 <__gmpn_sec_div_qr@@Base+0xf8>
   4ac2c:	mov	x0, x22
   4ac30:	mov	x1, x25
   4ac34:	mov	x2, x19
   4ac38:	mov	w3, w23
   4ac3c:	bl	c190 <__gmpn_lshift@plt>
   4ac40:	add	x25, x22, x19, lsl #3
   4ac44:	mov	x0, x25
   4ac48:	mov	x1, x20
   4ac4c:	mov	x2, x21
   4ac50:	mov	w3, w23
   4ac54:	bl	c190 <__gmpn_lshift@plt>
   4ac58:	str	x0, [x25, x21, lsl #3]
   4ac5c:	ldr	x8, [x22, x26, lsl #3]
   4ac60:	add	x26, x21, #0x1
   4ac64:	cmn	x8, #0x1
   4ac68:	cinc	x0, x8, ne  // ne = any
   4ac6c:	bl	d410 <__gmpn_invert_limb@plt>
   4ac70:	add	x27, x25, x19, lsl #3
   4ac74:	add	x8, x22, x26, lsl #3
   4ac78:	mov	x5, x0
   4ac7c:	add	x6, x8, x19, lsl #3
   4ac80:	mov	x0, x27
   4ac84:	mov	x1, x25
   4ac88:	mov	x2, x26
   4ac8c:	mov	x3, x22
   4ac90:	mov	x4, x19
   4ac94:	bl	cf10 <__gmpn_sec_pi1_div_qr@plt>
   4ac98:	sub	x2, x21, x19
   4ac9c:	mov	x0, x24
   4aca0:	mov	x1, x27
   4aca4:	bl	ca70 <__gmpn_copyi@plt>
   4aca8:	ldr	x21, [x25, x21, lsl #3]
   4acac:	mov	x0, x20
   4acb0:	mov	x1, x25
   4acb4:	mov	x2, x19
   4acb8:	mov	w3, w23
   4acbc:	bl	c1b0 <__gmpn_rshift@plt>
   4acc0:	mov	x0, x21
   4acc4:	ldp	x20, x19, [sp, #80]
   4acc8:	ldp	x22, x21, [sp, #64]
   4accc:	ldp	x24, x23, [sp, #48]
   4acd0:	ldp	x26, x25, [sp, #32]
   4acd4:	ldr	x27, [sp, #16]
   4acd8:	ldp	x29, x30, [sp], #96
   4acdc:	ret
   4ace0:	cmn	x8, #0x1
   4ace4:	cinc	x0, x8, ne  // ne = any
   4ace8:	bl	d410 <__gmpn_invert_limb@plt>
   4acec:	mov	x5, x0
   4acf0:	mov	x0, x24
   4acf4:	mov	x1, x20
   4acf8:	mov	x2, x21
   4acfc:	mov	x3, x25
   4ad00:	mov	x4, x19
   4ad04:	mov	x6, x22
   4ad08:	ldp	x20, x19, [sp, #80]
   4ad0c:	ldp	x22, x21, [sp, #64]
   4ad10:	ldp	x24, x23, [sp, #48]
   4ad14:	ldp	x26, x25, [sp, #32]
   4ad18:	ldr	x27, [sp, #16]
   4ad1c:	ldp	x29, x30, [sp], #96
   4ad20:	b	cf10 <__gmpn_sec_pi1_div_qr@plt>

000000000004ad24 <__gmpn_sec_div_r_itch@@Base>:
   4ad24:	add	x8, x0, x1, lsl #1
   4ad28:	add	x0, x8, #0x2
   4ad2c:	ret

000000000004ad30 <__gmpn_sec_div_r@@Base>:
   4ad30:	stp	x29, x30, [sp, #-80]!
   4ad34:	str	x25, [sp, #16]
   4ad38:	stp	x24, x23, [sp, #32]
   4ad3c:	stp	x22, x21, [sp, #48]
   4ad40:	stp	x20, x19, [sp, #64]
   4ad44:	sub	x25, x3, #0x1
   4ad48:	ldr	x8, [x2, x25, lsl #3]
   4ad4c:	mov	x20, x4
   4ad50:	mov	x19, x3
   4ad54:	mov	x24, x2
   4ad58:	mov	x23, x1
   4ad5c:	clz	x22, x8
   4ad60:	mov	x21, x0
   4ad64:	mov	x29, sp
   4ad68:	cbz	w22, 4adf8 <__gmpn_sec_div_r@@Base+0xc8>
   4ad6c:	mov	x0, x20
   4ad70:	mov	x1, x24
   4ad74:	mov	x2, x19
   4ad78:	mov	w3, w22
   4ad7c:	bl	c190 <__gmpn_lshift@plt>
   4ad80:	add	x24, x20, x19, lsl #3
   4ad84:	mov	x0, x24
   4ad88:	mov	x1, x21
   4ad8c:	mov	x2, x23
   4ad90:	mov	w3, w22
   4ad94:	bl	c190 <__gmpn_lshift@plt>
   4ad98:	str	x0, [x24, x23, lsl #3]
   4ad9c:	ldr	x8, [x20, x25, lsl #3]
   4ada0:	add	x23, x23, #0x1
   4ada4:	cmn	x8, #0x1
   4ada8:	cinc	x0, x8, ne  // ne = any
   4adac:	bl	d410 <__gmpn_invert_limb@plt>
   4adb0:	add	x8, x20, x23, lsl #3
   4adb4:	mov	x4, x0
   4adb8:	add	x5, x8, x19, lsl #3
   4adbc:	mov	x0, x24
   4adc0:	mov	x1, x23
   4adc4:	mov	x2, x20
   4adc8:	mov	x3, x19
   4adcc:	bl	c820 <__gmpn_sec_pi1_div_r@plt>
   4add0:	mov	x0, x21
   4add4:	mov	x1, x24
   4add8:	mov	x2, x19
   4addc:	mov	w3, w22
   4ade0:	ldp	x20, x19, [sp, #64]
   4ade4:	ldp	x22, x21, [sp, #48]
   4ade8:	ldp	x24, x23, [sp, #32]
   4adec:	ldr	x25, [sp, #16]
   4adf0:	ldp	x29, x30, [sp], #80
   4adf4:	b	c1b0 <__gmpn_rshift@plt>
   4adf8:	cmn	x8, #0x1
   4adfc:	cinc	x0, x8, ne  // ne = any
   4ae00:	bl	d410 <__gmpn_invert_limb@plt>
   4ae04:	mov	x4, x0
   4ae08:	mov	x0, x21
   4ae0c:	mov	x1, x23
   4ae10:	mov	x2, x24
   4ae14:	mov	x3, x19
   4ae18:	mov	x5, x20
   4ae1c:	ldp	x20, x19, [sp, #64]
   4ae20:	ldp	x22, x21, [sp, #48]
   4ae24:	ldp	x24, x23, [sp, #32]
   4ae28:	ldr	x25, [sp, #16]
   4ae2c:	ldp	x29, x30, [sp], #80
   4ae30:	b	c820 <__gmpn_sec_pi1_div_r@plt>

000000000004ae34 <__gmpn_sec_pi1_div_qr@@Base>:
   4ae34:	sub	sp, sp, #0xa0
   4ae38:	stp	x29, x30, [sp, #64]
   4ae3c:	stp	x26, x25, [sp, #96]
   4ae40:	stp	x22, x21, [sp, #128]
   4ae44:	stp	x20, x19, [sp, #144]
   4ae48:	add	x29, sp, #0x40
   4ae4c:	mov	x26, x3
   4ae50:	mov	x21, x2
   4ae54:	mov	x20, x1
   4ae58:	subs	x22, x2, x4
   4ae5c:	stp	x28, x27, [sp, #80]
   4ae60:	stp	x24, x23, [sp, #112]
   4ae64:	stur	x6, [x29, #-8]
   4ae68:	b.ne	4aea4 <__gmpn_sec_pi1_div_qr@@Base+0x70>  // b.any
   4ae6c:	mov	x0, x20
   4ae70:	mov	x1, x20
   4ae74:	mov	x2, x26
   4ae78:	mov	x3, x21
   4ae7c:	bl	c2e0 <__gmpn_sub_n@plt>
   4ae80:	mov	x1, x20
   4ae84:	mov	x2, x1
   4ae88:	mov	x3, x26
   4ae8c:	mov	x4, x21
   4ae90:	mov	x20, x0
   4ae94:	bl	d4f0 <__gmpn_cnd_add_n@plt>
   4ae98:	mov	w8, #0x1                   	// #1
   4ae9c:	sub	x0, x8, x20
   4aea0:	b	4b09c <__gmpn_sec_pi1_div_qr@@Base+0x268>
   4aea4:	ldur	x19, [x29, #-8]
   4aea8:	mov	x24, x0
   4aeac:	mov	w3, #0x20                  	// #32
   4aeb0:	mov	x1, x26
   4aeb4:	mov	x0, x19
   4aeb8:	mov	x2, x4
   4aebc:	mov	x27, x5
   4aec0:	mov	x28, x4
   4aec4:	bl	c190 <__gmpn_lshift@plt>
   4aec8:	add	x11, x28, #0x1
   4aecc:	add	x8, x19, x21, lsl #3
   4aed0:	cmp	x22, #0x1
   4aed4:	add	x23, x19, x11, lsl #3
   4aed8:	add	x25, x8, #0x8
   4aedc:	add	x10, x20, x22, lsl #3
   4aee0:	str	x0, [x19, x28, lsl #3]
   4aee4:	b.lt	4afc0 <__gmpn_sec_pi1_div_qr@@Base+0x18c>  // b.tstop
   4aee8:	ldur	x9, [x29, #-8]
   4aeec:	stur	x8, [x29, #-16]
   4aef0:	lsl	x8, x21, #1
   4aef4:	sub	x8, x8, x28
   4aef8:	mov	x12, x20
   4aefc:	add	x8, x9, x8, lsl #3
   4af00:	stp	x24, x22, [sp, #16]
   4af04:	mov	x24, xzr
   4af08:	mov	x20, xzr
   4af0c:	add	x19, x22, #0x1
   4af10:	stur	x8, [x29, #-24]
   4af14:	add	x8, x12, x21, lsl #3
   4af18:	stp	x25, x23, [sp]
   4af1c:	str	x8, [sp, #32]
   4af20:	ldr	x8, [sp, #32]
   4af24:	mov	x23, x28
   4af28:	mov	x28, x26
   4af2c:	add	x9, x10, x24
   4af30:	add	x26, x8, x24
   4af34:	ldur	x8, [x26, #-8]
   4af38:	sub	x21, x9, #0x8
   4af3c:	ldur	x1, [x29, #-8]
   4af40:	mov	x0, x21
   4af44:	extr	x8, x20, x8, #32
   4af48:	umulh	x9, x8, x27
   4af4c:	add	x3, x8, x9
   4af50:	ldur	x8, [x29, #-24]
   4af54:	mov	x2, x11
   4af58:	mov	x22, x10
   4af5c:	mov	x25, x11
   4af60:	str	x3, [x8, x24]
   4af64:	bl	ca00 <__gmpn_submul_1@plt>
   4af68:	ldur	x20, [x26, #-8]
   4af6c:	umulh	x8, x20, x27
   4af70:	mov	x26, x28
   4af74:	mov	x0, x21
   4af78:	add	x3, x8, x20
   4af7c:	ldur	x8, [x29, #-16]
   4af80:	mov	x1, x26
   4af84:	mov	x2, x23
   4af88:	mov	x28, x23
   4af8c:	str	x3, [x8, x24]
   4af90:	bl	ca00 <__gmpn_submul_1@plt>
   4af94:	sub	x19, x19, #0x1
   4af98:	mov	x11, x25
   4af9c:	mov	x10, x22
   4afa0:	sub	x20, x20, x0
   4afa4:	cmp	x19, #0x1
   4afa8:	sub	x24, x24, #0x8
   4afac:	b.gt	4af20 <__gmpn_sec_pi1_div_qr@@Base+0xec>
   4afb0:	add	x10, x10, x24
   4afb4:	ldp	x24, x22, [sp, #16]
   4afb8:	ldp	x25, x23, [sp]
   4afbc:	b	4afc4 <__gmpn_sec_pi1_div_qr@@Base+0x190>
   4afc0:	mov	x20, xzr
   4afc4:	ldr	x8, [x23]
   4afc8:	cmp	x20, #0x0
   4afcc:	cset	w0, ne  // ne = any
   4afd0:	mov	x1, x10
   4afd4:	cinc	x8, x8, ne  // ne = any
   4afd8:	mov	x2, x10
   4afdc:	mov	x3, x26
   4afe0:	mov	x4, x28
   4afe4:	str	x8, [x23]
   4afe8:	mov	x19, x10
   4afec:	bl	c030 <__gmpn_cnd_sub_n@plt>
   4aff0:	mov	x21, x0
   4aff4:	mov	x0, x19
   4aff8:	mov	x1, x19
   4affc:	mov	x2, x26
   4b000:	mov	x3, x28
   4b004:	bl	c2e0 <__gmpn_sub_n@plt>
   4b008:	ldr	x8, [x23]
   4b00c:	sub	x9, x21, x20
   4b010:	add	x0, x0, x9
   4b014:	mov	x1, x19
   4b018:	sub	x8, x8, x0
   4b01c:	add	x8, x8, #0x1
   4b020:	mov	x2, x19
   4b024:	mov	x3, x26
   4b028:	mov	x4, x28
   4b02c:	str	x8, [x23]
   4b030:	bl	d4f0 <__gmpn_cnd_add_n@plt>
   4b034:	mov	x0, x19
   4b038:	mov	x1, x19
   4b03c:	mov	x2, x26
   4b040:	mov	x3, x28
   4b044:	bl	c2e0 <__gmpn_sub_n@plt>
   4b048:	ldr	x8, [x23]
   4b04c:	mov	x1, x19
   4b050:	mov	x2, x19
   4b054:	mov	x3, x26
   4b058:	sub	x8, x8, x0
   4b05c:	add	x8, x8, #0x1
   4b060:	mov	x4, x28
   4b064:	str	x8, [x23]
   4b068:	bl	d4f0 <__gmpn_cnd_add_n@plt>
   4b06c:	mov	w3, #0x20                  	// #32
   4b070:	mov	x0, x25
   4b074:	mov	x1, x25
   4b078:	mov	x2, x22
   4b07c:	bl	c190 <__gmpn_lshift@plt>
   4b080:	mov	x19, x0
   4b084:	mov	x0, x24
   4b088:	mov	x1, x25
   4b08c:	mov	x2, x23
   4b090:	mov	x3, x22
   4b094:	bl	ca90 <__gmpn_add_n@plt>
   4b098:	add	x0, x0, x19
   4b09c:	ldp	x20, x19, [sp, #144]
   4b0a0:	ldp	x22, x21, [sp, #128]
   4b0a4:	ldp	x24, x23, [sp, #112]
   4b0a8:	ldp	x26, x25, [sp, #96]
   4b0ac:	ldp	x28, x27, [sp, #80]
   4b0b0:	ldp	x29, x30, [sp, #64]
   4b0b4:	add	sp, sp, #0xa0
   4b0b8:	ret

000000000004b0bc <__gmpn_sec_pi1_div_r@@Base>:
   4b0bc:	stp	x29, x30, [sp, #-96]!
   4b0c0:	stp	x28, x27, [sp, #16]
   4b0c4:	stp	x26, x25, [sp, #32]
   4b0c8:	stp	x24, x23, [sp, #48]
   4b0cc:	stp	x20, x19, [sp, #80]
   4b0d0:	mov	x19, x2
   4b0d4:	mov	x24, x1
   4b0d8:	subs	x28, x1, x3
   4b0dc:	mov	x25, x0
   4b0e0:	stp	x22, x21, [sp, #64]
   4b0e4:	mov	x29, sp
   4b0e8:	b.ne	4b114 <__gmpn_sec_pi1_div_r@@Base+0x58>  // b.any
   4b0ec:	mov	x0, x25
   4b0f0:	mov	x1, x25
   4b0f4:	mov	x2, x19
   4b0f8:	mov	x3, x24
   4b0fc:	bl	c2e0 <__gmpn_sub_n@plt>
   4b100:	mov	x1, x25
   4b104:	mov	x2, x25
   4b108:	mov	x3, x19
   4b10c:	mov	x4, x24
   4b110:	b	4b228 <__gmpn_sec_pi1_div_r@@Base+0x16c>
   4b114:	mov	x20, x3
   4b118:	mov	w3, #0x20                  	// #32
   4b11c:	mov	x0, x5
   4b120:	mov	x1, x19
   4b124:	mov	x2, x20
   4b128:	mov	x21, x5
   4b12c:	mov	x22, x4
   4b130:	bl	c190 <__gmpn_lshift@plt>
   4b134:	cmp	x28, #0x1
   4b138:	mov	x26, xzr
   4b13c:	str	x0, [x21, x20, lsl #3]
   4b140:	b.lt	4b1b0 <__gmpn_sec_pi1_div_r@@Base+0xf4>  // b.tstop
   4b144:	add	x23, x20, #0x1
   4b148:	add	x25, x25, x24, lsl #3
   4b14c:	neg	x27, x20, lsl #3
   4b150:	add	x28, x28, #0x1
   4b154:	add	x8, x25, x27
   4b158:	ldr	x9, [x25, #-8]!
   4b15c:	sub	x24, x8, #0x8
   4b160:	mov	x0, x24
   4b164:	mov	x1, x21
   4b168:	extr	x8, x26, x9, #32
   4b16c:	umulh	x9, x8, x22
   4b170:	add	x3, x8, x9
   4b174:	mov	x2, x23
   4b178:	bl	ca00 <__gmpn_submul_1@plt>
   4b17c:	ldr	x26, [x25]
   4b180:	umulh	x8, x26, x22
   4b184:	mov	x0, x24
   4b188:	mov	x1, x19
   4b18c:	add	x3, x8, x26
   4b190:	mov	x2, x20
   4b194:	bl	ca00 <__gmpn_submul_1@plt>
   4b198:	sub	x28, x28, #0x1
   4b19c:	cmp	x28, #0x1
   4b1a0:	sub	x26, x26, x0
   4b1a4:	b.gt	4b154 <__gmpn_sec_pi1_div_r@@Base+0x98>
   4b1a8:	sub	x21, x25, x20, lsl #3
   4b1ac:	b	4b1b4 <__gmpn_sec_pi1_div_r@@Base+0xf8>
   4b1b0:	add	x21, x25, x28, lsl #3
   4b1b4:	cmp	x26, #0x0
   4b1b8:	cset	w0, ne  // ne = any
   4b1bc:	mov	x1, x21
   4b1c0:	mov	x2, x21
   4b1c4:	mov	x3, x19
   4b1c8:	mov	x4, x20
   4b1cc:	bl	c030 <__gmpn_cnd_sub_n@plt>
   4b1d0:	mov	x22, x0
   4b1d4:	mov	x0, x21
   4b1d8:	mov	x1, x21
   4b1dc:	mov	x2, x19
   4b1e0:	mov	x3, x20
   4b1e4:	bl	c2e0 <__gmpn_sub_n@plt>
   4b1e8:	sub	x8, x22, x26
   4b1ec:	add	x0, x8, x0
   4b1f0:	mov	x1, x21
   4b1f4:	mov	x2, x21
   4b1f8:	mov	x3, x19
   4b1fc:	mov	x4, x20
   4b200:	bl	d4f0 <__gmpn_cnd_add_n@plt>
   4b204:	mov	x0, x21
   4b208:	mov	x1, x21
   4b20c:	mov	x2, x19
   4b210:	mov	x3, x20
   4b214:	bl	c2e0 <__gmpn_sub_n@plt>
   4b218:	mov	x1, x21
   4b21c:	mov	x2, x21
   4b220:	mov	x3, x19
   4b224:	mov	x4, x20
   4b228:	ldp	x20, x19, [sp, #80]
   4b22c:	ldp	x22, x21, [sp, #64]
   4b230:	ldp	x24, x23, [sp, #48]
   4b234:	ldp	x26, x25, [sp, #32]
   4b238:	ldp	x28, x27, [sp, #16]
   4b23c:	ldp	x29, x30, [sp], #96
   4b240:	b	d4f0 <__gmpn_cnd_add_n@plt>

000000000004b244 <__gmpn_sec_add_1_itch@@Base>:
   4b244:	ret

000000000004b248 <__gmpn_sec_add_1@@Base>:
   4b248:	stp	x29, x30, [sp, #-48]!
   4b24c:	stp	x22, x21, [sp, #16]
   4b250:	stp	x20, x19, [sp, #32]
   4b254:	mov	x19, x4
   4b258:	mov	x20, x2
   4b25c:	mov	x21, x1
   4b260:	mov	x22, x0
   4b264:	cmp	x2, #0x1
   4b268:	mov	x29, sp
   4b26c:	str	x3, [x4]
   4b270:	b.eq	4b288 <__gmpn_sec_add_1@@Base+0x40>  // b.none
   4b274:	lsl	x8, x20, #3
   4b278:	add	x0, x19, #0x8
   4b27c:	sub	x2, x8, #0x8
   4b280:	mov	w1, wzr
   4b284:	bl	c610 <memset@plt>
   4b288:	mov	x0, x22
   4b28c:	mov	x1, x21
   4b290:	mov	x2, x19
   4b294:	mov	x3, x20
   4b298:	ldp	x20, x19, [sp, #32]
   4b29c:	ldp	x22, x21, [sp, #16]
   4b2a0:	ldp	x29, x30, [sp], #48
   4b2a4:	b	ca90 <__gmpn_add_n@plt>

000000000004b2a8 <__gmpn_sec_sub_1_itch@@Base>:
   4b2a8:	ret

000000000004b2ac <__gmpn_sec_sub_1@@Base>:
   4b2ac:	stp	x29, x30, [sp, #-48]!
   4b2b0:	stp	x22, x21, [sp, #16]
   4b2b4:	stp	x20, x19, [sp, #32]
   4b2b8:	mov	x19, x4
   4b2bc:	mov	x20, x2
   4b2c0:	mov	x21, x1
   4b2c4:	mov	x22, x0
   4b2c8:	cmp	x2, #0x1
   4b2cc:	mov	x29, sp
   4b2d0:	str	x3, [x4]
   4b2d4:	b.eq	4b2ec <__gmpn_sec_sub_1@@Base+0x40>  // b.none
   4b2d8:	lsl	x8, x20, #3
   4b2dc:	add	x0, x19, #0x8
   4b2e0:	sub	x2, x8, #0x8
   4b2e4:	mov	w1, wzr
   4b2e8:	bl	c610 <memset@plt>
   4b2ec:	mov	x0, x22
   4b2f0:	mov	x1, x21
   4b2f4:	mov	x2, x19
   4b2f8:	mov	x3, x20
   4b2fc:	ldp	x20, x19, [sp, #32]
   4b300:	ldp	x22, x21, [sp, #16]
   4b304:	ldp	x29, x30, [sp], #48
   4b308:	b	c2e0 <__gmpn_sub_n@plt>

000000000004b30c <__gmpn_sec_invert_itch@@Base>:
   4b30c:	lsl	x0, x0, #2
   4b310:	ret

000000000004b314 <__gmpn_sec_invert@@Base>:
   4b314:	sub	sp, sp, #0x70
   4b318:	stp	x26, x25, [sp, #48]
   4b31c:	add	x25, x5, x3, lsl #4
   4b320:	stp	x20, x19, [sp, #96]
   4b324:	mov	x19, x0
   4b328:	mov	w8, #0x1                   	// #1
   4b32c:	mov	x0, x25
   4b330:	stp	x29, x30, [sp, #16]
   4b334:	stp	x28, x27, [sp, #32]
   4b338:	stp	x24, x23, [sp, #64]
   4b33c:	stp	x22, x21, [sp, #80]
   4b340:	mov	x23, x1
   4b344:	str	x8, [x0], #8
   4b348:	sub	x1, x3, #0x1
   4b34c:	add	x29, sp, #0x10
   4b350:	mov	x24, x5
   4b354:	mov	x21, x4
   4b358:	mov	x20, x3
   4b35c:	mov	x27, x2
   4b360:	bl	cf50 <__gmpn_zero@plt>
   4b364:	add	x26, x24, x20, lsl #3
   4b368:	mov	x0, x26
   4b36c:	mov	x1, x27
   4b370:	mov	x2, x20
   4b374:	bl	ca70 <__gmpn_copyi@plt>
   4b378:	mov	x0, x19
   4b37c:	mov	x1, x20
   4b380:	str	x19, [sp]
   4b384:	bl	cf50 <__gmpn_zero@plt>
   4b388:	mov	w8, #0x18                  	// #24
   4b38c:	madd	x19, x20, x8, x24
   4b390:	mov	w3, #0x1                   	// #1
   4b394:	mov	x0, x19
   4b398:	mov	x1, x27
   4b39c:	mov	x2, x20
   4b3a0:	bl	c1b0 <__gmpn_rshift@plt>
   4b3a4:	mov	w3, #0x1                   	// #1
   4b3a8:	mov	x0, x19
   4b3ac:	mov	x1, x19
   4b3b0:	mov	x2, x20
   4b3b4:	mov	x4, x24
   4b3b8:	str	x24, [sp, #8]
   4b3bc:	bl	c3a0 <__gmpn_sec_add_1@plt>
   4b3c0:	cbz	x21, 4b4b4 <__gmpn_sec_invert@@Base+0x1a0>
   4b3c4:	ldr	x8, [x23]
   4b3c8:	mov	x1, x23
   4b3cc:	mov	x2, x23
   4b3d0:	mov	x3, x26
   4b3d4:	and	x28, x8, #0x1
   4b3d8:	mov	x0, x28
   4b3dc:	mov	x4, x20
   4b3e0:	sub	x21, x21, #0x1
   4b3e4:	bl	c030 <__gmpn_cnd_sub_n@plt>
   4b3e8:	mov	x1, x26
   4b3ec:	mov	x2, x26
   4b3f0:	mov	x3, x23
   4b3f4:	mov	x4, x20
   4b3f8:	mov	x22, x0
   4b3fc:	bl	d4f0 <__gmpn_cnd_add_n@plt>
   4b400:	ldr	x24, [sp, #8]
   4b404:	mov	w3, #0x1                   	// #1
   4b408:	mov	x1, x23
   4b40c:	mov	x2, x20
   4b410:	mov	x0, x24
   4b414:	bl	c190 <__gmpn_lshift@plt>
   4b418:	sxtw	x0, w22
   4b41c:	mov	x1, x23
   4b420:	mov	x2, x23
   4b424:	mov	x3, x24
   4b428:	mov	x4, x20
   4b42c:	bl	c030 <__gmpn_cnd_sub_n@plt>
   4b430:	ldr	x24, [sp]
   4b434:	mov	x0, x22
   4b438:	mov	x1, x25
   4b43c:	mov	x3, x20
   4b440:	mov	x2, x24
   4b444:	bl	c680 <__gmpn_cnd_swap@plt>
   4b448:	mov	x0, x28
   4b44c:	mov	x1, x25
   4b450:	mov	x2, x25
   4b454:	mov	x3, x24
   4b458:	mov	x4, x20
   4b45c:	bl	c030 <__gmpn_cnd_sub_n@plt>
   4b460:	mov	x1, x25
   4b464:	mov	x2, x25
   4b468:	mov	x3, x27
   4b46c:	mov	x4, x20
   4b470:	bl	d4f0 <__gmpn_cnd_add_n@plt>
   4b474:	mov	w3, #0x1                   	// #1
   4b478:	mov	x0, x23
   4b47c:	mov	x1, x23
   4b480:	mov	x2, x20
   4b484:	bl	c1b0 <__gmpn_rshift@plt>
   4b488:	mov	w3, #0x1                   	// #1
   4b48c:	mov	x0, x25
   4b490:	mov	x1, x25
   4b494:	mov	x2, x20
   4b498:	bl	c1b0 <__gmpn_rshift@plt>
   4b49c:	mov	x1, x25
   4b4a0:	mov	x2, x25
   4b4a4:	mov	x3, x19
   4b4a8:	mov	x4, x20
   4b4ac:	bl	d4f0 <__gmpn_cnd_add_n@plt>
   4b4b0:	cbnz	x21, 4b3c4 <__gmpn_sec_invert@@Base+0xb0>
   4b4b4:	ldr	x8, [x26]
   4b4b8:	ldr	x24, [sp, #8]
   4b4bc:	cmp	x20, #0x2
   4b4c0:	eor	x8, x8, #0x1
   4b4c4:	b.lt	4b4e8 <__gmpn_sec_invert@@Base+0x1d4>  // b.tstop
   4b4c8:	add	x10, x24, x20, lsl #4
   4b4cc:	add	x9, x20, #0x1
   4b4d0:	sub	x10, x10, #0x8
   4b4d4:	ldr	x11, [x10], #-8
   4b4d8:	sub	x9, x9, #0x1
   4b4dc:	cmp	x9, #0x2
   4b4e0:	orr	x8, x11, x8
   4b4e4:	b.gt	4b4d4 <__gmpn_sec_invert@@Base+0x1c0>
   4b4e8:	ldp	x20, x19, [sp, #96]
   4b4ec:	ldp	x22, x21, [sp, #80]
   4b4f0:	ldp	x24, x23, [sp, #64]
   4b4f4:	ldp	x26, x25, [sp, #48]
   4b4f8:	ldp	x28, x27, [sp, #32]
   4b4fc:	ldp	x29, x30, [sp, #16]
   4b500:	cmp	x8, #0x0
   4b504:	cset	w0, eq  // eq = none
   4b508:	add	sp, sp, #0x70
   4b50c:	ret

000000000004b510 <__gmpn_trialdiv@@Base>:
   4b510:	stp	x29, x30, [sp, #-96]!
   4b514:	stp	x26, x25, [sp, #32]
   4b518:	stp	x24, x23, [sp, #48]
   4b51c:	stp	x22, x21, [sp, #64]
   4b520:	stp	x20, x19, [sp, #80]
   4b524:	ldr	w23, [x3]
   4b528:	str	x27, [sp, #16]
   4b52c:	mov	x29, sp
   4b530:	cmp	w23, #0xc6
   4b534:	b.hi	4b5d0 <__gmpn_trialdiv@@Base+0xc0>  // b.pmore
   4b538:	adrp	x25, 58000 <__gmp_jacobi_table@@Base+0x3879>
   4b53c:	adrp	x26, 54000 <__gmpn_bases@@Base+0x2938>
   4b540:	mov	x19, x3
   4b544:	mov	x20, x2
   4b548:	mov	x21, x1
   4b54c:	mov	x22, x0
   4b550:	mov	w24, #0x48                  	// #72
   4b554:	add	x25, x25, #0x878
   4b558:	add	x26, x26, #0x9c8
   4b55c:	madd	x27, x23, x24, x25
   4b560:	ldr	x8, [x27]
   4b564:	ldr	x9, [x27, #16]
   4b568:	add	x3, x27, #0x8
   4b56c:	mov	x0, x22
   4b570:	mov	x1, x21
   4b574:	lsl	x2, x8, x9
   4b578:	bl	d430 <__gmpn_mod_1s_4p@plt>
   4b57c:	ldr	w8, [x27, #64]
   4b580:	lsr	x9, x8, #24
   4b584:	cbz	w9, 4b5b8 <__gmpn_trialdiv@@Base+0xa8>
   4b588:	and	x8, x8, #0xffffff
   4b58c:	add	x8, x26, x8, lsl #4
   4b590:	mvn	x10, x9
   4b594:	add	x11, x8, #0x8
   4b598:	ldp	x8, x12, [x11, #-8]
   4b59c:	mul	x13, x8, x0
   4b5a0:	cmp	x13, x12
   4b5a4:	b.ls	4b5d8 <__gmpn_trialdiv@@Base+0xc8>  // b.plast
   4b5a8:	add	x10, x10, #0x1
   4b5ac:	cmn	x10, #0x2
   4b5b0:	add	x11, x11, #0x10
   4b5b4:	b.le	4b598 <__gmpn_trialdiv@@Base+0x88>
   4b5b8:	sub	x20, x20, x9
   4b5bc:	cmp	x20, #0x1
   4b5c0:	b.lt	4b5d0 <__gmpn_trialdiv@@Base+0xc0>  // b.tstop
   4b5c4:	cmp	x23, #0xc6
   4b5c8:	add	x23, x23, #0x1
   4b5cc:	b.cc	4b55c <__gmpn_trialdiv@@Base+0x4c>  // b.lo, b.ul, b.last
   4b5d0:	mov	x8, xzr
   4b5d4:	b	4b5dc <__gmpn_trialdiv@@Base+0xcc>
   4b5d8:	str	w23, [x19]
   4b5dc:	ldp	x20, x19, [sp, #80]
   4b5e0:	ldp	x22, x21, [sp, #64]
   4b5e4:	ldp	x24, x23, [sp, #48]
   4b5e8:	ldp	x26, x25, [sp, #32]
   4b5ec:	ldr	x27, [sp, #16]
   4b5f0:	mov	x0, x8
   4b5f4:	ldp	x29, x30, [sp], #96
   4b5f8:	ret

000000000004b5fc <__gmpn_remove@@Base>:
   4b5fc:	stp	x29, x30, [sp, #-96]!
   4b600:	stp	x28, x27, [sp, #16]
   4b604:	stp	x26, x25, [sp, #32]
   4b608:	stp	x24, x23, [sp, #48]
   4b60c:	stp	x22, x21, [sp, #64]
   4b610:	stp	x20, x19, [sp, #80]
   4b614:	mov	x29, sp
   4b618:	sub	sp, sp, #0x370
   4b61c:	add	x22, x3, #0x1
   4b620:	add	x8, x22, x5
   4b624:	cmp	x8, #0x0
   4b628:	cinc	x8, x8, lt  // lt = tstop
   4b62c:	lsr	x8, x8, #1
   4b630:	add	x8, x8, x22, lsl #1
   4b634:	mov	x25, x1
   4b638:	lsl	x1, x8, #3
   4b63c:	mov	w8, #0x7f00                	// #32512
   4b640:	mov	x19, sp
   4b644:	mov	x20, x5
   4b648:	mov	x21, x4
   4b64c:	mov	x27, x3
   4b650:	mov	x23, x2
   4b654:	cmp	x1, x8
   4b658:	stp	x6, xzr, [x19, #56]
   4b65c:	str	x0, [x19, #8]
   4b660:	b.hi	4b9f0 <__gmpn_remove@@Base+0x3f4>  // b.pmore
   4b664:	add	x9, x1, #0xf
   4b668:	mov	x8, sp
   4b66c:	and	x9, x9, #0xfffffffffffffff0
   4b670:	sub	x24, x8, x9
   4b674:	mov	sp, x24
   4b678:	mov	x0, x24
   4b67c:	mov	x1, x23
   4b680:	mov	x2, x27
   4b684:	bl	ca70 <__gmpn_copyi@plt>
   4b688:	cmp	x27, x20
   4b68c:	str	x25, [x19, #16]
   4b690:	b.ge	4b6a0 <__gmpn_remove@@Base+0xa4>  // b.tcont
   4b694:	mov	x22, xzr
   4b698:	mov	x21, x24
   4b69c:	b	4b9ac <__gmpn_remove@@Base+0x3b0>
   4b6a0:	add	x9, x24, x22, lsl #3
   4b6a4:	add	x8, x24, x27, lsl #4
   4b6a8:	mov	x25, xzr
   4b6ac:	stp	x27, x9, [x19, #40]
   4b6b0:	add	x9, x9, x22, lsl #3
   4b6b4:	add	x26, x8, #0x8
   4b6b8:	stp	x9, x24, [x19, #24]
   4b6bc:	ldr	x22, [x19, #48]
   4b6c0:	ldr	x1, [x19, #24]
   4b6c4:	add	x3, x27, #0x1
   4b6c8:	mov	x2, x24
   4b6cc:	mov	x0, x22
   4b6d0:	mov	x4, x21
   4b6d4:	mov	x5, x20
   4b6d8:	mov	x28, x25
   4b6dc:	str	xzr, [x24, x27, lsl #3]
   4b6e0:	str	x24, [x19, #48]
   4b6e4:	bl	4ba08 <__gmpn_remove@@Base+0x40c>
   4b6e8:	mov	x12, x22
   4b6ec:	mov	x8, x20
   4b6f0:	ldr	x9, [x26, x8, lsl #3]
   4b6f4:	cbnz	x9, 4b7a4 <__gmpn_remove@@Base+0x1a8>
   4b6f8:	sub	x8, x8, #0x1
   4b6fc:	cbnz	x8, 4b6f0 <__gmpn_remove@@Base+0xf4>
   4b700:	ldr	x10, [x12]
   4b704:	sub	x22, x27, x20
   4b708:	add	x8, x22, #0x1
   4b70c:	mov	x9, x12
   4b710:	cbnz	x10, 4b728 <__gmpn_remove@@Base+0x12c>
   4b714:	subs	x8, x8, #0x1
   4b718:	str	xzr, [x9]
   4b71c:	b.eq	4b74c <__gmpn_remove@@Base+0x150>  // b.none
   4b720:	ldr	x10, [x9, #8]!
   4b724:	cbz	x10, 4b714 <__gmpn_remove@@Base+0x118>
   4b728:	neg	x10, x10
   4b72c:	subs	x2, x8, #0x1
   4b730:	str	x10, [x9]
   4b734:	b.eq	4b74c <__gmpn_remove@@Base+0x150>  // b.none
   4b738:	add	x0, x9, #0x8
   4b73c:	mov	x1, x0
   4b740:	mov	x24, x12
   4b744:	bl	c2a0 <__gmpn_com@plt>
   4b748:	mov	x12, x24
   4b74c:	ldr	x8, [x12, x22, lsl #3]
   4b750:	add	x9, x19, #0x1d8
   4b754:	str	x21, [x9, x28, lsl #3]
   4b758:	add	x9, x19, #0x48
   4b75c:	cmp	x8, #0x0
   4b760:	ldr	x8, [x19, #56]
   4b764:	str	x20, [x9, x28, lsl #3]
   4b768:	mov	w9, #0x4                   	// #4
   4b76c:	lsl	x9, x9, x28
   4b770:	sub	x9, x9, #0x1
   4b774:	cinc	x27, x22, ne  // ne = any
   4b778:	cmp	x9, x8
   4b77c:	add	x25, x28, #0x1
   4b780:	b.hi	4b860 <__gmpn_remove@@Base+0x264>  // b.pmore
   4b784:	lsl	x8, x20, #1
   4b788:	sub	x22, x8, #0x1
   4b78c:	cmp	x22, x27
   4b790:	b.gt	4b860 <__gmpn_remove@@Base+0x264>
   4b794:	cbz	x28, 4b7cc <__gmpn_remove@@Base+0x1d0>
   4b798:	mov	x24, x12
   4b79c:	add	x23, x23, x20, lsl #3
   4b7a0:	b	4b7f8 <__gmpn_remove@@Base+0x1fc>
   4b7a4:	sub	x8, x21, #0x8
   4b7a8:	mov	x9, x20
   4b7ac:	subs	x10, x9, #0x1
   4b7b0:	b.lt	4b700 <__gmpn_remove@@Base+0x104>  // b.tstop
   4b7b4:	ldr	x11, [x26, x9, lsl #3]
   4b7b8:	ldr	x9, [x8, x9, lsl #3]
   4b7bc:	cmp	x11, x9
   4b7c0:	mov	x9, x10
   4b7c4:	b.eq	4b7ac <__gmpn_remove@@Base+0x1b0>  // b.none
   4b7c8:	b	4b840 <__gmpn_remove@@Base+0x244>
   4b7cc:	lsl	x8, x27, #3
   4b7d0:	add	x1, x8, #0x190
   4b7d4:	mov	w8, #0x7f00                	// #32512
   4b7d8:	cmp	x1, x8
   4b7dc:	b.hi	4b828 <__gmpn_remove@@Base+0x22c>  // b.pmore
   4b7e0:	add	x9, x1, #0xf
   4b7e4:	mov	x8, sp
   4b7e8:	and	x9, x9, #0xfffffffffffffff0
   4b7ec:	sub	x23, x8, x9
   4b7f0:	mov	sp, x23
   4b7f4:	mov	x24, x12
   4b7f8:	mov	x0, x23
   4b7fc:	mov	x1, x21
   4b800:	mov	x2, x20
   4b804:	bl	c900 <__gmpn_sqr@plt>
   4b808:	ldr	x8, [x23, x22, lsl #3]
   4b80c:	mov	x12, x24
   4b810:	mov	x21, x23
   4b814:	cmp	x8, #0x0
   4b818:	cinc	x20, x22, ne  // ne = any
   4b81c:	cmp	x27, x20
   4b820:	b.ge	4b6bc <__gmpn_remove@@Base+0xc0>  // b.tcont
   4b824:	b	4b860 <__gmpn_remove@@Base+0x264>
   4b828:	add	x0, x19, #0x40
   4b82c:	mov	x23, x12
   4b830:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   4b834:	mov	x12, x23
   4b838:	mov	x23, x0
   4b83c:	b	4b7f4 <__gmpn_remove@@Base+0x1f8>
   4b840:	ldr	x21, [x19, #48]
   4b844:	mov	x8, #0xffffffffffffffff    	// #-1
   4b848:	lsl	x8, x8, x28
   4b84c:	mvn	x22, x8
   4b850:	mov	x25, x28
   4b854:	mov	x8, x21
   4b858:	cbnz	x28, 4b874 <__gmpn_remove@@Base+0x278>
   4b85c:	b	4b9ac <__gmpn_remove@@Base+0x3b0>
   4b860:	mov	x8, #0xfffffffffffffffe    	// #-2
   4b864:	lsl	x8, x8, x28
   4b868:	mvn	x22, x8
   4b86c:	mov	x8, x12
   4b870:	ldr	x12, [x19, #48]
   4b874:	ldp	x10, x9, [x19, #32]
   4b878:	add	x13, x19, #0x48
   4b87c:	add	x9, x10, x9, lsl #4
   4b880:	add	x28, x9, #0x8
   4b884:	mov	x21, x12
   4b888:	mov	x20, x22
   4b88c:	mov	x12, x8
   4b890:	add	x8, x27, #0x1
   4b894:	stp	x8, x12, [x19, #32]
   4b898:	mov	x22, x25
   4b89c:	sub	x25, x25, #0x1
   4b8a0:	ldr	x23, [x13, x25, lsl #3]
   4b8a4:	subs	x24, x27, x23
   4b8a8:	b.lt	4b8c8 <__gmpn_remove@@Base+0x2cc>  // b.tstop
   4b8ac:	mov	w8, #0x1                   	// #1
   4b8b0:	lsl	x8, x8, x25
   4b8b4:	add	x9, x8, x20
   4b8b8:	ldr	x8, [x19, #56]
   4b8bc:	str	x9, [x19, #48]
   4b8c0:	cmp	x9, x8
   4b8c4:	b.ls	4b8d4 <__gmpn_remove@@Base+0x2d8>  // b.plast
   4b8c8:	cmp	x22, #0x1
   4b8cc:	b.gt	4b898 <__gmpn_remove@@Base+0x29c>
   4b8d0:	b	4b9a4 <__gmpn_remove@@Base+0x3a8>
   4b8d4:	add	x8, x19, #0x1d8
   4b8d8:	ldr	x26, [x8, x25, lsl #3]
   4b8dc:	ldp	x1, x3, [x19, #24]
   4b8e0:	mov	x0, x21
   4b8e4:	mov	x2, x12
   4b8e8:	mov	x4, x26
   4b8ec:	mov	x5, x23
   4b8f0:	str	xzr, [x12, x27, lsl #3]
   4b8f4:	bl	4ba08 <__gmpn_remove@@Base+0x40c>
   4b8f8:	ldr	x12, [x19, #40]
   4b8fc:	add	x13, x19, #0x48
   4b900:	mov	x8, x23
   4b904:	ldr	x9, [x28, x8, lsl #3]
   4b908:	cbnz	x9, 4b918 <__gmpn_remove@@Base+0x31c>
   4b90c:	sub	x8, x8, #0x1
   4b910:	cbnz	x8, 4b904 <__gmpn_remove@@Base+0x308>
   4b914:	b	4b93c <__gmpn_remove@@Base+0x340>
   4b918:	sub	x8, x26, #0x8
   4b91c:	subs	x9, x23, #0x1
   4b920:	b.lt	4b93c <__gmpn_remove@@Base+0x340>  // b.tstop
   4b924:	ldr	x10, [x28, x23, lsl #3]
   4b928:	ldr	x11, [x8, x23, lsl #3]
   4b92c:	mov	x23, x9
   4b930:	cmp	x10, x11
   4b934:	b.eq	4b91c <__gmpn_remove@@Base+0x320>  // b.none
   4b938:	b	4b8c8 <__gmpn_remove@@Base+0x2cc>
   4b93c:	ldr	x10, [x21]
   4b940:	add	x8, x24, #0x1
   4b944:	mov	x9, x21
   4b948:	cbnz	x10, 4b960 <__gmpn_remove@@Base+0x364>
   4b94c:	subs	x8, x8, #0x1
   4b950:	str	xzr, [x9]
   4b954:	b.eq	4b984 <__gmpn_remove@@Base+0x388>  // b.none
   4b958:	ldr	x10, [x9, #8]!
   4b95c:	cbz	x10, 4b94c <__gmpn_remove@@Base+0x350>
   4b960:	neg	x10, x10
   4b964:	subs	x2, x8, #0x1
   4b968:	str	x10, [x9]
   4b96c:	b.eq	4b984 <__gmpn_remove@@Base+0x388>  // b.none
   4b970:	add	x0, x9, #0x8
   4b974:	mov	x1, x0
   4b978:	bl	c2a0 <__gmpn_com@plt>
   4b97c:	ldr	x12, [x19, #40]
   4b980:	add	x13, x19, #0x48
   4b984:	ldr	x8, [x21, x24, lsl #3]
   4b988:	cmp	x8, #0x0
   4b98c:	cinc	x27, x24, ne  // ne = any
   4b990:	cmp	x22, #0x1
   4b994:	ldr	x22, [x19, #48]
   4b998:	mov	x8, x21
   4b99c:	b.gt	4b884 <__gmpn_remove@@Base+0x288>
   4b9a0:	b	4b9ac <__gmpn_remove@@Base+0x3b0>
   4b9a4:	mov	x22, x20
   4b9a8:	mov	x21, x12
   4b9ac:	ldr	x0, [x19, #8]
   4b9b0:	mov	x1, x21
   4b9b4:	mov	x2, x27
   4b9b8:	bl	ca70 <__gmpn_copyi@plt>
   4b9bc:	ldr	x8, [x19, #16]
   4b9c0:	str	x27, [x8]
   4b9c4:	ldr	x0, [x19, #64]
   4b9c8:	cbnz	x0, 4ba00 <__gmpn_remove@@Base+0x404>
   4b9cc:	mov	x0, x22
   4b9d0:	mov	sp, x29
   4b9d4:	ldp	x20, x19, [sp, #80]
   4b9d8:	ldp	x22, x21, [sp, #64]
   4b9dc:	ldp	x24, x23, [sp, #48]
   4b9e0:	ldp	x26, x25, [sp, #32]
   4b9e4:	ldp	x28, x27, [sp, #16]
   4b9e8:	ldp	x29, x30, [sp], #96
   4b9ec:	ret
   4b9f0:	add	x0, x19, #0x40
   4b9f4:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   4b9f8:	mov	x24, x0
   4b9fc:	b	4b678 <__gmpn_remove@@Base+0x7c>
   4ba00:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   4ba04:	b	4b9cc <__gmpn_remove@@Base+0x3d0>
   4ba08:	stp	x29, x30, [sp, #-64]!
   4ba0c:	stp	x24, x23, [sp, #16]
   4ba10:	stp	x22, x21, [sp, #32]
   4ba14:	stp	x20, x19, [sp, #48]
   4ba18:	mov	x29, sp
   4ba1c:	sub	sp, sp, #0x10
   4ba20:	mov	x23, x1
   4ba24:	mov	x24, x0
   4ba28:	mov	x0, x3
   4ba2c:	mov	x1, x5
   4ba30:	mov	x19, x5
   4ba34:	mov	x20, x4
   4ba38:	mov	x21, x3
   4ba3c:	mov	x22, x2
   4ba40:	stur	xzr, [x29, #-8]
   4ba44:	bl	c8e0 <__gmpn_bdiv_qr_itch@plt>
   4ba48:	lsl	x1, x0, #3
   4ba4c:	mov	w8, #0x7f00                	// #32512
   4ba50:	cmp	x1, x8
   4ba54:	b.hi	4baa8 <__gmpn_remove@@Base+0x4ac>  // b.pmore
   4ba58:	add	x9, x1, #0xf
   4ba5c:	mov	x8, sp
   4ba60:	and	x9, x9, #0xfffffffffffffff0
   4ba64:	sub	x6, x8, x9
   4ba68:	mov	sp, x6
   4ba6c:	mov	x0, x24
   4ba70:	mov	x1, x23
   4ba74:	mov	x2, x22
   4ba78:	mov	x3, x21
   4ba7c:	mov	x4, x20
   4ba80:	mov	x5, x19
   4ba84:	bl	cf70 <__gmpn_bdiv_qr@plt>
   4ba88:	ldur	x0, [x29, #-8]
   4ba8c:	cbnz	x0, 4bab8 <__gmpn_remove@@Base+0x4bc>
   4ba90:	mov	sp, x29
   4ba94:	ldp	x20, x19, [sp, #48]
   4ba98:	ldp	x22, x21, [sp, #32]
   4ba9c:	ldp	x24, x23, [sp, #16]
   4baa0:	ldp	x29, x30, [sp], #64
   4baa4:	ret
   4baa8:	sub	x0, x29, #0x8
   4baac:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   4bab0:	mov	x6, x0
   4bab4:	b	4ba6c <__gmpn_remove@@Base+0x470>
   4bab8:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   4babc:	b	4ba90 <__gmpn_remove@@Base+0x494>

000000000004bac0 <__gmpn_and_n@@Base>:
   4bac0:	lsr	x18, x3, #2
   4bac4:	tbz	w3, #0, 4bb0c <__gmpn_and_n@@Base+0x4c>
   4bac8:	ldr	x7, [x1]
   4bacc:	ldr	x11, [x2]
   4bad0:	and	x15, x7, x11
   4bad4:	str	x15, [x0], #8
   4bad8:	tbnz	w3, #1, 4baf4 <__gmpn_and_n@@Base+0x34>
   4badc:	cbz	x18, 4bb6c <__gmpn_and_n@@Base+0xac>
   4bae0:	ldp	x4, x5, [x1, #8]
   4bae4:	ldp	x8, x9, [x2, #8]
   4bae8:	sub	x1, x1, #0x8
   4baec:	sub	x2, x2, #0x8
   4baf0:	b	4bb44 <__gmpn_and_n@@Base+0x84>
   4baf4:	ldp	x6, x7, [x1, #8]
   4baf8:	ldp	x10, x11, [x2, #8]
   4bafc:	add	x1, x1, #0x8
   4bb00:	add	x2, x2, #0x8
   4bb04:	cbz	x18, 4bb60 <__gmpn_and_n@@Base+0xa0>
   4bb08:	b	4bb30 <__gmpn_and_n@@Base+0x70>
   4bb0c:	tbnz	w3, #1, 4bb1c <__gmpn_and_n@@Base+0x5c>
   4bb10:	ldp	x4, x5, [x1], #-16
   4bb14:	ldp	x8, x9, [x2], #-16
   4bb18:	b	4bb44 <__gmpn_and_n@@Base+0x84>
   4bb1c:	ldp	x6, x7, [x1]
   4bb20:	ldp	x10, x11, [x2]
   4bb24:	cbz	x18, 4bb60 <__gmpn_and_n@@Base+0xa0>
   4bb28:	nop
   4bb2c:	nop
   4bb30:	ldp	x4, x5, [x1, #16]
   4bb34:	ldp	x8, x9, [x2, #16]
   4bb38:	and	x12, x6, x10
   4bb3c:	and	x13, x7, x11
   4bb40:	stp	x12, x13, [x0], #16
   4bb44:	ldp	x6, x7, [x1, #32]!
   4bb48:	ldp	x10, x11, [x2, #32]!
   4bb4c:	and	x12, x4, x8
   4bb50:	and	x13, x5, x9
   4bb54:	stp	x12, x13, [x0], #16
   4bb58:	sub	x18, x18, #0x1
   4bb5c:	cbnz	x18, 4bb30 <__gmpn_and_n@@Base+0x70>
   4bb60:	and	x12, x6, x10
   4bb64:	and	x13, x7, x11
   4bb68:	stp	x12, x13, [x0]
   4bb6c:	ret

000000000004bb70 <__gmpn_andn_n@@Base>:
   4bb70:	lsr	x18, x3, #2
   4bb74:	tbz	w3, #0, 4bbbc <__gmpn_andn_n@@Base+0x4c>
   4bb78:	ldr	x7, [x1]
   4bb7c:	ldr	x11, [x2]
   4bb80:	bic	x15, x7, x11
   4bb84:	str	x15, [x0], #8
   4bb88:	tbnz	w3, #1, 4bba4 <__gmpn_andn_n@@Base+0x34>
   4bb8c:	cbz	x18, 4bc1c <__gmpn_andn_n@@Base+0xac>
   4bb90:	ldp	x4, x5, [x1, #8]
   4bb94:	ldp	x8, x9, [x2, #8]
   4bb98:	sub	x1, x1, #0x8
   4bb9c:	sub	x2, x2, #0x8
   4bba0:	b	4bbf4 <__gmpn_andn_n@@Base+0x84>
   4bba4:	ldp	x6, x7, [x1, #8]
   4bba8:	ldp	x10, x11, [x2, #8]
   4bbac:	add	x1, x1, #0x8
   4bbb0:	add	x2, x2, #0x8
   4bbb4:	cbz	x18, 4bc10 <__gmpn_andn_n@@Base+0xa0>
   4bbb8:	b	4bbe0 <__gmpn_andn_n@@Base+0x70>
   4bbbc:	tbnz	w3, #1, 4bbcc <__gmpn_andn_n@@Base+0x5c>
   4bbc0:	ldp	x4, x5, [x1], #-16
   4bbc4:	ldp	x8, x9, [x2], #-16
   4bbc8:	b	4bbf4 <__gmpn_andn_n@@Base+0x84>
   4bbcc:	ldp	x6, x7, [x1]
   4bbd0:	ldp	x10, x11, [x2]
   4bbd4:	cbz	x18, 4bc10 <__gmpn_andn_n@@Base+0xa0>
   4bbd8:	nop
   4bbdc:	nop
   4bbe0:	ldp	x4, x5, [x1, #16]
   4bbe4:	ldp	x8, x9, [x2, #16]
   4bbe8:	bic	x12, x6, x10
   4bbec:	bic	x13, x7, x11
   4bbf0:	stp	x12, x13, [x0], #16
   4bbf4:	ldp	x6, x7, [x1, #32]!
   4bbf8:	ldp	x10, x11, [x2, #32]!
   4bbfc:	bic	x12, x4, x8
   4bc00:	bic	x13, x5, x9
   4bc04:	stp	x12, x13, [x0], #16
   4bc08:	sub	x18, x18, #0x1
   4bc0c:	cbnz	x18, 4bbe0 <__gmpn_andn_n@@Base+0x70>
   4bc10:	bic	x12, x6, x10
   4bc14:	bic	x13, x7, x11
   4bc18:	stp	x12, x13, [x0]
   4bc1c:	ret

000000000004bc20 <__gmpn_nand_n@@Base>:
   4bc20:	lsr	x18, x3, #2
   4bc24:	tbz	w3, #0, 4bc70 <__gmpn_nand_n@@Base+0x50>
   4bc28:	ldr	x7, [x1]
   4bc2c:	ldr	x11, [x2]
   4bc30:	and	x15, x7, x11
   4bc34:	mvn	x15, x15
   4bc38:	str	x15, [x0], #8
   4bc3c:	tbnz	w3, #1, 4bc58 <__gmpn_nand_n@@Base+0x38>
   4bc40:	cbz	x18, 4bce4 <__gmpn_nand_n@@Base+0xc4>
   4bc44:	ldp	x4, x5, [x1, #8]
   4bc48:	ldp	x8, x9, [x2, #8]
   4bc4c:	sub	x1, x1, #0x8
   4bc50:	sub	x2, x2, #0x8
   4bc54:	b	4bcac <__gmpn_nand_n@@Base+0x8c>
   4bc58:	ldp	x6, x7, [x1, #8]
   4bc5c:	ldp	x10, x11, [x2, #8]
   4bc60:	add	x1, x1, #0x8
   4bc64:	add	x2, x2, #0x8
   4bc68:	cbz	x18, 4bcd0 <__gmpn_nand_n@@Base+0xb0>
   4bc6c:	b	4bc90 <__gmpn_nand_n@@Base+0x70>
   4bc70:	tbnz	w3, #1, 4bc80 <__gmpn_nand_n@@Base+0x60>
   4bc74:	ldp	x4, x5, [x1], #-16
   4bc78:	ldp	x8, x9, [x2], #-16
   4bc7c:	b	4bcac <__gmpn_nand_n@@Base+0x8c>
   4bc80:	ldp	x6, x7, [x1]
   4bc84:	ldp	x10, x11, [x2]
   4bc88:	cbz	x18, 4bcd0 <__gmpn_nand_n@@Base+0xb0>
   4bc8c:	nop
   4bc90:	ldp	x4, x5, [x1, #16]
   4bc94:	ldp	x8, x9, [x2, #16]
   4bc98:	and	x12, x6, x10
   4bc9c:	and	x13, x7, x11
   4bca0:	mvn	x12, x12
   4bca4:	mvn	x13, x13
   4bca8:	stp	x12, x13, [x0], #16
   4bcac:	ldp	x6, x7, [x1, #32]!
   4bcb0:	ldp	x10, x11, [x2, #32]!
   4bcb4:	and	x12, x4, x8
   4bcb8:	and	x13, x5, x9
   4bcbc:	mvn	x12, x12
   4bcc0:	mvn	x13, x13
   4bcc4:	stp	x12, x13, [x0], #16
   4bcc8:	sub	x18, x18, #0x1
   4bccc:	cbnz	x18, 4bc90 <__gmpn_nand_n@@Base+0x70>
   4bcd0:	and	x12, x6, x10
   4bcd4:	and	x13, x7, x11
   4bcd8:	mvn	x12, x12
   4bcdc:	mvn	x13, x13
   4bce0:	stp	x12, x13, [x0]
   4bce4:	ret
   4bce8:	nop
   4bcec:	nop

000000000004bcf0 <__gmpn_ior_n@@Base>:
   4bcf0:	lsr	x18, x3, #2
   4bcf4:	tbz	w3, #0, 4bd3c <__gmpn_ior_n@@Base+0x4c>
   4bcf8:	ldr	x7, [x1]
   4bcfc:	ldr	x11, [x2]
   4bd00:	orr	x15, x7, x11
   4bd04:	str	x15, [x0], #8
   4bd08:	tbnz	w3, #1, 4bd24 <__gmpn_ior_n@@Base+0x34>
   4bd0c:	cbz	x18, 4bd9c <__gmpn_ior_n@@Base+0xac>
   4bd10:	ldp	x4, x5, [x1, #8]
   4bd14:	ldp	x8, x9, [x2, #8]
   4bd18:	sub	x1, x1, #0x8
   4bd1c:	sub	x2, x2, #0x8
   4bd20:	b	4bd74 <__gmpn_ior_n@@Base+0x84>
   4bd24:	ldp	x6, x7, [x1, #8]
   4bd28:	ldp	x10, x11, [x2, #8]
   4bd2c:	add	x1, x1, #0x8
   4bd30:	add	x2, x2, #0x8
   4bd34:	cbz	x18, 4bd90 <__gmpn_ior_n@@Base+0xa0>
   4bd38:	b	4bd60 <__gmpn_ior_n@@Base+0x70>
   4bd3c:	tbnz	w3, #1, 4bd4c <__gmpn_ior_n@@Base+0x5c>
   4bd40:	ldp	x4, x5, [x1], #-16
   4bd44:	ldp	x8, x9, [x2], #-16
   4bd48:	b	4bd74 <__gmpn_ior_n@@Base+0x84>
   4bd4c:	ldp	x6, x7, [x1]
   4bd50:	ldp	x10, x11, [x2]
   4bd54:	cbz	x18, 4bd90 <__gmpn_ior_n@@Base+0xa0>
   4bd58:	nop
   4bd5c:	nop
   4bd60:	ldp	x4, x5, [x1, #16]
   4bd64:	ldp	x8, x9, [x2, #16]
   4bd68:	orr	x12, x6, x10
   4bd6c:	orr	x13, x7, x11
   4bd70:	stp	x12, x13, [x0], #16
   4bd74:	ldp	x6, x7, [x1, #32]!
   4bd78:	ldp	x10, x11, [x2, #32]!
   4bd7c:	orr	x12, x4, x8
   4bd80:	orr	x13, x5, x9
   4bd84:	stp	x12, x13, [x0], #16
   4bd88:	sub	x18, x18, #0x1
   4bd8c:	cbnz	x18, 4bd60 <__gmpn_ior_n@@Base+0x70>
   4bd90:	orr	x12, x6, x10
   4bd94:	orr	x13, x7, x11
   4bd98:	stp	x12, x13, [x0]
   4bd9c:	ret

000000000004bda0 <__gmpn_iorn_n@@Base>:
   4bda0:	lsr	x18, x3, #2
   4bda4:	tbz	w3, #0, 4bdec <__gmpn_iorn_n@@Base+0x4c>
   4bda8:	ldr	x7, [x1]
   4bdac:	ldr	x11, [x2]
   4bdb0:	orn	x15, x7, x11
   4bdb4:	str	x15, [x0], #8
   4bdb8:	tbnz	w3, #1, 4bdd4 <__gmpn_iorn_n@@Base+0x34>
   4bdbc:	cbz	x18, 4be4c <__gmpn_iorn_n@@Base+0xac>
   4bdc0:	ldp	x4, x5, [x1, #8]
   4bdc4:	ldp	x8, x9, [x2, #8]
   4bdc8:	sub	x1, x1, #0x8
   4bdcc:	sub	x2, x2, #0x8
   4bdd0:	b	4be24 <__gmpn_iorn_n@@Base+0x84>
   4bdd4:	ldp	x6, x7, [x1, #8]
   4bdd8:	ldp	x10, x11, [x2, #8]
   4bddc:	add	x1, x1, #0x8
   4bde0:	add	x2, x2, #0x8
   4bde4:	cbz	x18, 4be40 <__gmpn_iorn_n@@Base+0xa0>
   4bde8:	b	4be10 <__gmpn_iorn_n@@Base+0x70>
   4bdec:	tbnz	w3, #1, 4bdfc <__gmpn_iorn_n@@Base+0x5c>
   4bdf0:	ldp	x4, x5, [x1], #-16
   4bdf4:	ldp	x8, x9, [x2], #-16
   4bdf8:	b	4be24 <__gmpn_iorn_n@@Base+0x84>
   4bdfc:	ldp	x6, x7, [x1]
   4be00:	ldp	x10, x11, [x2]
   4be04:	cbz	x18, 4be40 <__gmpn_iorn_n@@Base+0xa0>
   4be08:	nop
   4be0c:	nop
   4be10:	ldp	x4, x5, [x1, #16]
   4be14:	ldp	x8, x9, [x2, #16]
   4be18:	orn	x12, x6, x10
   4be1c:	orn	x13, x7, x11
   4be20:	stp	x12, x13, [x0], #16
   4be24:	ldp	x6, x7, [x1, #32]!
   4be28:	ldp	x10, x11, [x2, #32]!
   4be2c:	orn	x12, x4, x8
   4be30:	orn	x13, x5, x9
   4be34:	stp	x12, x13, [x0], #16
   4be38:	sub	x18, x18, #0x1
   4be3c:	cbnz	x18, 4be10 <__gmpn_iorn_n@@Base+0x70>
   4be40:	orn	x12, x6, x10
   4be44:	orn	x13, x7, x11
   4be48:	stp	x12, x13, [x0]
   4be4c:	ret

000000000004be50 <__gmpn_nior_n@@Base>:
   4be50:	lsr	x18, x3, #2
   4be54:	tbz	w3, #0, 4bea0 <__gmpn_nior_n@@Base+0x50>
   4be58:	ldr	x7, [x1]
   4be5c:	ldr	x11, [x2]
   4be60:	orr	x15, x7, x11
   4be64:	mvn	x15, x15
   4be68:	str	x15, [x0], #8
   4be6c:	tbnz	w3, #1, 4be88 <__gmpn_nior_n@@Base+0x38>
   4be70:	cbz	x18, 4bf14 <__gmpn_nior_n@@Base+0xc4>
   4be74:	ldp	x4, x5, [x1, #8]
   4be78:	ldp	x8, x9, [x2, #8]
   4be7c:	sub	x1, x1, #0x8
   4be80:	sub	x2, x2, #0x8
   4be84:	b	4bedc <__gmpn_nior_n@@Base+0x8c>
   4be88:	ldp	x6, x7, [x1, #8]
   4be8c:	ldp	x10, x11, [x2, #8]
   4be90:	add	x1, x1, #0x8
   4be94:	add	x2, x2, #0x8
   4be98:	cbz	x18, 4bf00 <__gmpn_nior_n@@Base+0xb0>
   4be9c:	b	4bec0 <__gmpn_nior_n@@Base+0x70>
   4bea0:	tbnz	w3, #1, 4beb0 <__gmpn_nior_n@@Base+0x60>
   4bea4:	ldp	x4, x5, [x1], #-16
   4bea8:	ldp	x8, x9, [x2], #-16
   4beac:	b	4bedc <__gmpn_nior_n@@Base+0x8c>
   4beb0:	ldp	x6, x7, [x1]
   4beb4:	ldp	x10, x11, [x2]
   4beb8:	cbz	x18, 4bf00 <__gmpn_nior_n@@Base+0xb0>
   4bebc:	nop
   4bec0:	ldp	x4, x5, [x1, #16]
   4bec4:	ldp	x8, x9, [x2, #16]
   4bec8:	orr	x12, x6, x10
   4becc:	orr	x13, x7, x11
   4bed0:	mvn	x12, x12
   4bed4:	mvn	x13, x13
   4bed8:	stp	x12, x13, [x0], #16
   4bedc:	ldp	x6, x7, [x1, #32]!
   4bee0:	ldp	x10, x11, [x2, #32]!
   4bee4:	orr	x12, x4, x8
   4bee8:	orr	x13, x5, x9
   4beec:	mvn	x12, x12
   4bef0:	mvn	x13, x13
   4bef4:	stp	x12, x13, [x0], #16
   4bef8:	sub	x18, x18, #0x1
   4befc:	cbnz	x18, 4bec0 <__gmpn_nior_n@@Base+0x70>
   4bf00:	orr	x12, x6, x10
   4bf04:	orr	x13, x7, x11
   4bf08:	mvn	x12, x12
   4bf0c:	mvn	x13, x13
   4bf10:	stp	x12, x13, [x0]
   4bf14:	ret
   4bf18:	nop
   4bf1c:	nop

000000000004bf20 <__gmpn_xor_n@@Base>:
   4bf20:	lsr	x18, x3, #2
   4bf24:	tbz	w3, #0, 4bf6c <__gmpn_xor_n@@Base+0x4c>
   4bf28:	ldr	x7, [x1]
   4bf2c:	ldr	x11, [x2]
   4bf30:	eor	x15, x7, x11
   4bf34:	str	x15, [x0], #8
   4bf38:	tbnz	w3, #1, 4bf54 <__gmpn_xor_n@@Base+0x34>
   4bf3c:	cbz	x18, 4bfcc <__gmpn_xor_n@@Base+0xac>
   4bf40:	ldp	x4, x5, [x1, #8]
   4bf44:	ldp	x8, x9, [x2, #8]
   4bf48:	sub	x1, x1, #0x8
   4bf4c:	sub	x2, x2, #0x8
   4bf50:	b	4bfa4 <__gmpn_xor_n@@Base+0x84>
   4bf54:	ldp	x6, x7, [x1, #8]
   4bf58:	ldp	x10, x11, [x2, #8]
   4bf5c:	add	x1, x1, #0x8
   4bf60:	add	x2, x2, #0x8
   4bf64:	cbz	x18, 4bfc0 <__gmpn_xor_n@@Base+0xa0>
   4bf68:	b	4bf90 <__gmpn_xor_n@@Base+0x70>
   4bf6c:	tbnz	w3, #1, 4bf7c <__gmpn_xor_n@@Base+0x5c>
   4bf70:	ldp	x4, x5, [x1], #-16
   4bf74:	ldp	x8, x9, [x2], #-16
   4bf78:	b	4bfa4 <__gmpn_xor_n@@Base+0x84>
   4bf7c:	ldp	x6, x7, [x1]
   4bf80:	ldp	x10, x11, [x2]
   4bf84:	cbz	x18, 4bfc0 <__gmpn_xor_n@@Base+0xa0>
   4bf88:	nop
   4bf8c:	nop
   4bf90:	ldp	x4, x5, [x1, #16]
   4bf94:	ldp	x8, x9, [x2, #16]
   4bf98:	eor	x12, x6, x10
   4bf9c:	eor	x13, x7, x11
   4bfa0:	stp	x12, x13, [x0], #16
   4bfa4:	ldp	x6, x7, [x1, #32]!
   4bfa8:	ldp	x10, x11, [x2, #32]!
   4bfac:	eor	x12, x4, x8
   4bfb0:	eor	x13, x5, x9
   4bfb4:	stp	x12, x13, [x0], #16
   4bfb8:	sub	x18, x18, #0x1
   4bfbc:	cbnz	x18, 4bf90 <__gmpn_xor_n@@Base+0x70>
   4bfc0:	eor	x12, x6, x10
   4bfc4:	eor	x13, x7, x11
   4bfc8:	stp	x12, x13, [x0]
   4bfcc:	ret

000000000004bfd0 <__gmpn_xnor_n@@Base>:
   4bfd0:	lsr	x18, x3, #2
   4bfd4:	tbz	w3, #0, 4c01c <__gmpn_xnor_n@@Base+0x4c>
   4bfd8:	ldr	x7, [x1]
   4bfdc:	ldr	x11, [x2]
   4bfe0:	eon	x15, x7, x11
   4bfe4:	str	x15, [x0], #8
   4bfe8:	tbnz	w3, #1, 4c004 <__gmpn_xnor_n@@Base+0x34>
   4bfec:	cbz	x18, 4c07c <__gmpn_xnor_n@@Base+0xac>
   4bff0:	ldp	x4, x5, [x1, #8]
   4bff4:	ldp	x8, x9, [x2, #8]
   4bff8:	sub	x1, x1, #0x8
   4bffc:	sub	x2, x2, #0x8
   4c000:	b	4c054 <__gmpn_xnor_n@@Base+0x84>
   4c004:	ldp	x6, x7, [x1, #8]
   4c008:	ldp	x10, x11, [x2, #8]
   4c00c:	add	x1, x1, #0x8
   4c010:	add	x2, x2, #0x8
   4c014:	cbz	x18, 4c070 <__gmpn_xnor_n@@Base+0xa0>
   4c018:	b	4c040 <__gmpn_xnor_n@@Base+0x70>
   4c01c:	tbnz	w3, #1, 4c02c <__gmpn_xnor_n@@Base+0x5c>
   4c020:	ldp	x4, x5, [x1], #-16
   4c024:	ldp	x8, x9, [x2], #-16
   4c028:	b	4c054 <__gmpn_xnor_n@@Base+0x84>
   4c02c:	ldp	x6, x7, [x1]
   4c030:	ldp	x10, x11, [x2]
   4c034:	cbz	x18, 4c070 <__gmpn_xnor_n@@Base+0xa0>
   4c038:	nop
   4c03c:	nop
   4c040:	ldp	x4, x5, [x1, #16]
   4c044:	ldp	x8, x9, [x2, #16]
   4c048:	eon	x12, x6, x10
   4c04c:	eon	x13, x7, x11
   4c050:	stp	x12, x13, [x0], #16
   4c054:	ldp	x6, x7, [x1, #32]!
   4c058:	ldp	x10, x11, [x2, #32]!
   4c05c:	eon	x12, x4, x8
   4c060:	eon	x13, x5, x9
   4c064:	stp	x12, x13, [x0], #16
   4c068:	sub	x18, x18, #0x1
   4c06c:	cbnz	x18, 4c040 <__gmpn_xnor_n@@Base+0x70>
   4c070:	eon	x12, x6, x10
   4c074:	eon	x13, x7, x11
   4c078:	stp	x12, x13, [x0]
   4c07c:	ret

000000000004c080 <__gmpn_copyi@@Base>:
   4c080:	cmp	x2, #0x3
   4c084:	b.le	4c0cc <__gmpn_copyi@@Base+0x4c>
   4c088:	tbz	w0, #3, 4c098 <__gmpn_copyi@@Base+0x18>
   4c08c:	ld1	{v22.1d}, [x1], #8
   4c090:	sub	x2, x2, #0x1
   4c094:	st1	{v22.1d}, [x0], #8
   4c098:	ld1	{v26.2d}, [x1], #16
   4c09c:	sub	x2, x2, #0x6
   4c0a0:	tbnz	x2, #63, 4c0c8 <__gmpn_copyi@@Base+0x48>
   4c0a4:	nop
   4c0a8:	nop
   4c0ac:	nop
   4c0b0:	ld1	{v22.2d}, [x1], #16
   4c0b4:	st1	{v26.2d}, [x0], #16
   4c0b8:	ld1	{v26.2d}, [x1], #16
   4c0bc:	st1	{v22.2d}, [x0], #16
   4c0c0:	sub	x2, x2, #0x4
   4c0c4:	tbz	x2, #63, 4c0b0 <__gmpn_copyi@@Base+0x30>
   4c0c8:	st1	{v26.2d}, [x0], #16
   4c0cc:	tbz	w2, #1, 4c0d8 <__gmpn_copyi@@Base+0x58>
   4c0d0:	ld1	{v22.2d}, [x1], #16
   4c0d4:	st1	{v22.2d}, [x0], #16
   4c0d8:	tbz	w2, #0, 4c0e4 <__gmpn_copyi@@Base+0x64>
   4c0dc:	ld1	{v22.1d}, [x1]
   4c0e0:	st1	{v22.1d}, [x0]
   4c0e4:	ret
   4c0e8:	nop
   4c0ec:	nop

000000000004c0f0 <__gmpn_copyd@@Base>:
   4c0f0:	add	x0, x0, x2, lsl #3
   4c0f4:	add	x1, x1, x2, lsl #3
   4c0f8:	cmp	x2, #0x3
   4c0fc:	b.le	4c160 <__gmpn_copyd@@Base+0x70>
   4c100:	tbz	w0, #3, 4c118 <__gmpn_copyd@@Base+0x28>
   4c104:	sub	x1, x1, #0x8
   4c108:	ld1	{v22.1d}, [x1]
   4c10c:	sub	x2, x2, #0x1
   4c110:	sub	x0, x0, #0x8
   4c114:	st1	{v22.1d}, [x0]
   4c118:	sub	x1, x1, #0x10
   4c11c:	ld1	{v26.2d}, [x1]
   4c120:	sub	x2, x2, #0x6
   4c124:	sub	x0, x0, #0x10
   4c128:	tbnz	x2, #63, 4c15c <__gmpn_copyd@@Base+0x6c>
   4c12c:	sub	x1, x1, #0x10
   4c130:	mov	x12, #0xfffffffffffffff0    	// #-16
   4c134:	nop
   4c138:	nop
   4c13c:	nop
   4c140:	ld1	{v22.2d}, [x1], x12
   4c144:	st1	{v26.2d}, [x0], x12
   4c148:	ld1	{v26.2d}, [x1], x12
   4c14c:	st1	{v22.2d}, [x0], x12
   4c150:	sub	x2, x2, #0x4
   4c154:	tbz	x2, #63, 4c140 <__gmpn_copyd@@Base+0x50>
   4c158:	add	x1, x1, #0x10
   4c15c:	st1	{v26.2d}, [x0]
   4c160:	tbz	w2, #1, 4c174 <__gmpn_copyd@@Base+0x84>
   4c164:	sub	x1, x1, #0x10
   4c168:	ld1	{v22.2d}, [x1]
   4c16c:	sub	x0, x0, #0x10
   4c170:	st1	{v22.2d}, [x0]
   4c174:	tbz	w2, #0, 4c188 <__gmpn_copyd@@Base+0x98>
   4c178:	sub	x1, x1, #0x8
   4c17c:	ld1	{v22.1d}, [x1]
   4c180:	sub	x0, x0, #0x8
   4c184:	st1	{v22.1d}, [x0]
   4c188:	ret

000000000004c18c <__gmpn_zero@@Base>:
   4c18c:	cbz	x1, 4c1a8 <__gmpn_zero@@Base+0x1c>
   4c190:	stp	x29, x30, [sp, #-16]!
   4c194:	lsl	x2, x1, #3
   4c198:	mov	w1, wzr
   4c19c:	mov	x29, sp
   4c1a0:	bl	c610 <memset@plt>
   4c1a4:	ldp	x29, x30, [sp], #16
   4c1a8:	ret
   4c1ac:	nop

000000000004c1b0 <__gmpn_sec_tabselect@@Base>:
   4c1b0:	dup	v7.2d, x4
   4c1b4:	mov	x10, #0x1                   	// #1
   4c1b8:	dup	v6.2d, x10
   4c1bc:	subs	x6, x2, #0x4
   4c1c0:	b.mi	4c210 <__gmpn_sec_tabselect@@Base+0x60>  // b.first
   4c1c4:	mov	x5, x3
   4c1c8:	mov	x12, x1
   4c1cc:	movi	v5.16b, #0x0
   4c1d0:	movi	v2.16b, #0x0
   4c1d4:	movi	v3.16b, #0x0
   4c1d8:	nop
   4c1dc:	nop
   4c1e0:	cmeq	v4.2d, v5.2d, v7.2d
   4c1e4:	ld1	{v0.2d, v1.2d}, [x1]
   4c1e8:	add	v5.2d, v5.2d, v6.2d
   4c1ec:	bit	v2.16b, v0.16b, v4.16b
   4c1f0:	bit	v3.16b, v1.16b, v4.16b
   4c1f4:	add	x1, x1, x2, lsl #3
   4c1f8:	sub	x5, x5, #0x1
   4c1fc:	cbnz	x5, 4c1e0 <__gmpn_sec_tabselect@@Base+0x30>
   4c200:	st1	{v2.2d, v3.2d}, [x0], #32
   4c204:	add	x1, x12, #0x20
   4c208:	subs	x6, x6, #0x4
   4c20c:	b.pl	4c1c4 <__gmpn_sec_tabselect@@Base+0x14>  // b.nfrst
   4c210:	tbz	w2, #1, 4c254 <__gmpn_sec_tabselect@@Base+0xa4>
   4c214:	mov	x5, x3
   4c218:	mov	x12, x1
   4c21c:	movi	v5.16b, #0x0
   4c220:	movi	v2.16b, #0x0
   4c224:	nop
   4c228:	nop
   4c22c:	nop
   4c230:	cmeq	v4.2d, v5.2d, v7.2d
   4c234:	ld1	{v0.2d}, [x1]
   4c238:	add	v5.2d, v5.2d, v6.2d
   4c23c:	bit	v2.16b, v0.16b, v4.16b
   4c240:	add	x1, x1, x2, lsl #3
   4c244:	sub	x5, x5, #0x1
   4c248:	cbnz	x5, 4c230 <__gmpn_sec_tabselect@@Base+0x80>
   4c24c:	st1	{v2.2d}, [x0], #16
   4c250:	add	x1, x12, #0x10
   4c254:	tbz	w2, #0, 4c294 <__gmpn_sec_tabselect@@Base+0xe4>
   4c258:	mov	x5, x3
   4c25c:	mov	x12, x1
   4c260:	movi	v5.16b, #0x0
   4c264:	movi	v2.16b, #0x0
   4c268:	nop
   4c26c:	nop
   4c270:	cmeq	v4.2d, v5.2d, v7.2d
   4c274:	ld1	{v0.1d}, [x1]
   4c278:	add	v5.2d, v5.2d, v6.2d
   4c27c:	bit	v2.8b, v0.8b, v4.8b
   4c280:	add	x1, x1, x2, lsl #3
   4c284:	sub	x5, x5, #0x1
   4c288:	cbnz	x5, 4c270 <__gmpn_sec_tabselect@@Base+0xc0>
   4c28c:	st1	{v2.1d}, [x0], #8
   4c290:	add	x1, x12, #0x8
   4c294:	ret

000000000004c298 <__gmpn_invert_limb@@Base>:
   4c298:	lsr	x2, x0, #54
   4c29c:	adrp	x1, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4c2a0:	and	x2, x2, #0x1fe
   4c2a4:	add	x1, x1, #0x380
   4c2a8:	ldrh	w3, [x1, x2]
   4c2ac:	lsr	x4, x0, #24
   4c2b0:	add	x4, x4, #0x1
   4c2b4:	ubfiz	x2, x3, #11, #16
   4c2b8:	umull	x3, w3, w3
   4c2bc:	mul	x3, x3, x4
   4c2c0:	sub	x2, x2, #0x1
   4c2c4:	sub	x2, x2, x3, lsr #40
   4c2c8:	lsl	x3, x2, #60
   4c2cc:	mul	x1, x2, x2
   4c2d0:	msub	x1, x1, x4, x3
   4c2d4:	lsl	x2, x2, #13
   4c2d8:	add	x1, x2, x1, lsr #47
   4c2dc:	and	x2, x0, #0x1
   4c2e0:	neg	x3, x2
   4c2e4:	and	x3, x3, x1, lsr #1
   4c2e8:	add	x2, x2, x0, lsr #1
   4c2ec:	msub	x2, x1, x2, x3
   4c2f0:	umulh	x2, x2, x1
   4c2f4:	lsl	x1, x1, #31
   4c2f8:	add	x1, x1, x2, lsr #1
   4c2fc:	mul	x3, x1, x0
   4c300:	umulh	x2, x1, x0
   4c304:	adds	x4, x3, x0
   4c308:	adc	x0, x2, x0
   4c30c:	sub	x0, x1, x0
   4c310:	ret
   4c314:	nop
   4c318:	nop
   4c31c:	nop

000000000004c320 <__gmpn_sqr_diag_addlsh1@@Base>:
   4c320:	ldr	x15, [x2], #8
   4c324:	lsr	x18, x3, #1
   4c328:	tbz	w3, #0, 4c344 <__gmpn_sqr_diag_addlsh1@@Base+0x24>
   4c32c:	adds	x7, xzr, xzr
   4c330:	mul	x12, x15, x15
   4c334:	ldr	x16, [x2], #8
   4c338:	ldp	x4, x5, [x1], #16
   4c33c:	umulh	x11, x15, x15
   4c340:	b	4c384 <__gmpn_sqr_diag_addlsh1@@Base+0x64>
   4c344:	adds	x5, xzr, xzr
   4c348:	mul	x12, x15, x15
   4c34c:	ldr	x17, [x2], #16
   4c350:	ldp	x6, x7, [x1], #32
   4c354:	umulh	x11, x15, x15
   4c358:	sub	x18, x18, #0x1
   4c35c:	cbz	x18, 4c3b0 <__gmpn_sqr_diag_addlsh1@@Base+0x90>
   4c360:	extr	x9, x6, x5, #63
   4c364:	mul	x10, x17, x17
   4c368:	ldur	x16, [x2, #-8]
   4c36c:	adcs	x13, x9, x11
   4c370:	ldp	x4, x5, [x1, #-16]
   4c374:	umulh	x11, x17, x17
   4c378:	extr	x8, x7, x6, #63
   4c37c:	stp	x12, x13, [x0], #16
   4c380:	adcs	x12, x8, x10
   4c384:	extr	x9, x4, x7, #63
   4c388:	mul	x10, x16, x16
   4c38c:	ldr	x17, [x2], #16
   4c390:	adcs	x13, x9, x11
   4c394:	ldp	x6, x7, [x1], #32
   4c398:	umulh	x11, x16, x16
   4c39c:	extr	x8, x5, x4, #63
   4c3a0:	stp	x12, x13, [x0], #16
   4c3a4:	adcs	x12, x8, x10
   4c3a8:	sub	x18, x18, #0x1
   4c3ac:	cbnz	x18, 4c360 <__gmpn_sqr_diag_addlsh1@@Base+0x40>
   4c3b0:	extr	x9, x6, x5, #63
   4c3b4:	mul	x10, x17, x17
   4c3b8:	adcs	x13, x9, x11
   4c3bc:	umulh	x11, x17, x17
   4c3c0:	extr	x8, x7, x6, #63
   4c3c4:	stp	x12, x13, [x0]
   4c3c8:	adcs	x12, x8, x10
   4c3cc:	extr	x9, xzr, x7, #63
   4c3d0:	adcs	x13, x9, x11
   4c3d4:	stp	x12, x13, [x0, #16]
   4c3d8:	ret
   4c3dc:	nop

000000000004c3e0 <__gmpn_addlsh1_n@@Base>:
   4c3e0:	lsr	x18, x3, #2
   4c3e4:	tbz	w3, #0, 4c44c <__gmpn_addlsh1_n@@Base+0x6c>
   4c3e8:	ldr	x5, [x1]
   4c3ec:	tbnz	w3, #1, 4c42c <__gmpn_addlsh1_n@@Base+0x4c>
   4c3f0:	ldr	x11, [x2]
   4c3f4:	cbz	x18, 4c414 <__gmpn_addlsh1_n@@Base+0x34>
   4c3f8:	ldp	x8, x9, [x2, #8]
   4c3fc:	lsl	x13, x11, #1
   4c400:	adds	x15, x13, x5
   4c404:	str	x15, [x0], #8
   4c408:	sub	x1, x1, #0x18
   4c40c:	sub	x2, x2, #0x8
   4c410:	b	4c48c <__gmpn_addlsh1_n@@Base+0xac>
   4c414:	lsl	x13, x11, #1
   4c418:	adds	x15, x13, x5
   4c41c:	str	x15, [x0]
   4c420:	lsr	x0, x11, #63
   4c424:	adc	x0, x0, xzr
   4c428:	ret
   4c42c:	ldr	x9, [x2]
   4c430:	ldp	x10, x11, [x2, #8]!
   4c434:	lsl	x13, x9, #1
   4c438:	adds	x17, x13, x5
   4c43c:	str	x17, [x0], #8
   4c440:	sub	x1, x1, #0x8
   4c444:	cbz	x18, 4c4b0 <__gmpn_addlsh1_n@@Base+0xd0>
   4c448:	b	4c470 <__gmpn_addlsh1_n@@Base+0x90>
   4c44c:	tbnz	w3, #1, 4c460 <__gmpn_addlsh1_n@@Base+0x80>
   4c450:	adds	x11, xzr, xzr
   4c454:	ldp	x8, x9, [x2], #-16
   4c458:	sub	x1, x1, #0x20
   4c45c:	b	4c48c <__gmpn_addlsh1_n@@Base+0xac>
   4c460:	adds	x9, xzr, xzr
   4c464:	ldp	x10, x11, [x2]
   4c468:	sub	x1, x1, #0x10
   4c46c:	cbz	x18, 4c4b0 <__gmpn_addlsh1_n@@Base+0xd0>
   4c470:	ldp	x4, x5, [x1, #16]
   4c474:	extr	x12, x10, x9, #63
   4c478:	ldp	x8, x9, [x2, #16]
   4c47c:	extr	x13, x11, x10, #63
   4c480:	adcs	x14, x12, x4
   4c484:	adcs	x15, x13, x5
   4c488:	stp	x14, x15, [x0], #16
   4c48c:	ldp	x4, x5, [x1, #32]!
   4c490:	extr	x12, x8, x11, #63
   4c494:	ldp	x10, x11, [x2, #32]!
   4c498:	extr	x13, x9, x8, #63
   4c49c:	adcs	x16, x12, x4
   4c4a0:	adcs	x17, x13, x5
   4c4a4:	stp	x16, x17, [x0], #16
   4c4a8:	sub	x18, x18, #0x1
   4c4ac:	cbnz	x18, 4c470 <__gmpn_addlsh1_n@@Base+0x90>
   4c4b0:	ldp	x4, x5, [x1, #16]
   4c4b4:	extr	x12, x10, x9, #63
   4c4b8:	extr	x13, x11, x10, #63
   4c4bc:	adcs	x14, x12, x4
   4c4c0:	adcs	x15, x13, x5
   4c4c4:	stp	x14, x15, [x0]
   4c4c8:	lsr	x0, x11, #63
   4c4cc:	adc	x0, x0, xzr
   4c4d0:	ret
   4c4d4:	nop
   4c4d8:	nop
   4c4dc:	nop

000000000004c4e0 <__gmpn_sublsh1_n@@Base>:
   4c4e0:	lsr	x18, x3, #2
   4c4e4:	tbz	w3, #0, 4c54c <__gmpn_sublsh1_n@@Base+0x6c>
   4c4e8:	ldr	x5, [x1]
   4c4ec:	tbnz	w3, #1, 4c52c <__gmpn_sublsh1_n@@Base+0x4c>
   4c4f0:	ldr	x11, [x2]
   4c4f4:	cbz	x18, 4c514 <__gmpn_sublsh1_n@@Base+0x34>
   4c4f8:	ldp	x8, x9, [x2, #8]
   4c4fc:	lsl	x13, x11, #1
   4c500:	subs	x15, x5, x13
   4c504:	str	x15, [x0], #8
   4c508:	sub	x1, x1, #0x18
   4c50c:	sub	x2, x2, #0x8
   4c510:	b	4c58c <__gmpn_sublsh1_n@@Base+0xac>
   4c514:	lsl	x13, x11, #1
   4c518:	subs	x15, x5, x13
   4c51c:	str	x15, [x0]
   4c520:	lsr	x0, x11, #63
   4c524:	cinc	x0, x0, cc  // cc = lo, ul, last
   4c528:	ret
   4c52c:	ldr	x9, [x2]
   4c530:	ldp	x10, x11, [x2, #8]!
   4c534:	lsl	x13, x9, #1
   4c538:	subs	x17, x5, x13
   4c53c:	str	x17, [x0], #8
   4c540:	sub	x1, x1, #0x8
   4c544:	cbz	x18, 4c5b0 <__gmpn_sublsh1_n@@Base+0xd0>
   4c548:	b	4c570 <__gmpn_sublsh1_n@@Base+0x90>
   4c54c:	tbnz	w3, #1, 4c560 <__gmpn_sublsh1_n@@Base+0x80>
   4c550:	negs	x11, xzr
   4c554:	ldp	x8, x9, [x2], #-16
   4c558:	sub	x1, x1, #0x20
   4c55c:	b	4c58c <__gmpn_sublsh1_n@@Base+0xac>
   4c560:	negs	x9, xzr
   4c564:	ldp	x10, x11, [x2]
   4c568:	sub	x1, x1, #0x10
   4c56c:	cbz	x18, 4c5b0 <__gmpn_sublsh1_n@@Base+0xd0>
   4c570:	ldp	x4, x5, [x1, #16]
   4c574:	extr	x12, x10, x9, #63
   4c578:	ldp	x8, x9, [x2, #16]
   4c57c:	extr	x13, x11, x10, #63
   4c580:	sbcs	x14, x4, x12
   4c584:	sbcs	x15, x5, x13
   4c588:	stp	x14, x15, [x0], #16
   4c58c:	ldp	x4, x5, [x1, #32]!
   4c590:	extr	x12, x8, x11, #63
   4c594:	ldp	x10, x11, [x2, #32]!
   4c598:	extr	x13, x9, x8, #63
   4c59c:	sbcs	x16, x4, x12
   4c5a0:	sbcs	x17, x5, x13
   4c5a4:	stp	x16, x17, [x0], #16
   4c5a8:	sub	x18, x18, #0x1
   4c5ac:	cbnz	x18, 4c570 <__gmpn_sublsh1_n@@Base+0x90>
   4c5b0:	ldp	x4, x5, [x1, #16]
   4c5b4:	extr	x12, x10, x9, #63
   4c5b8:	extr	x13, x11, x10, #63
   4c5bc:	sbcs	x14, x4, x12
   4c5c0:	sbcs	x15, x5, x13
   4c5c4:	stp	x14, x15, [x0]
   4c5c8:	lsr	x0, x11, #63
   4c5cc:	cinc	x0, x0, cc  // cc = lo, ul, last
   4c5d0:	ret
   4c5d4:	nop
   4c5d8:	nop
   4c5dc:	nop

000000000004c5e0 <__gmpn_rsblsh1_n@@Base>:
   4c5e0:	lsr	x18, x3, #2
   4c5e4:	tbz	w3, #0, 4c64c <__gmpn_rsblsh1_n@@Base+0x6c>
   4c5e8:	ldr	x5, [x1]
   4c5ec:	tbnz	w3, #1, 4c62c <__gmpn_rsblsh1_n@@Base+0x4c>
   4c5f0:	ldr	x11, [x2]
   4c5f4:	cbz	x18, 4c614 <__gmpn_rsblsh1_n@@Base+0x34>
   4c5f8:	ldp	x8, x9, [x2, #8]
   4c5fc:	lsl	x13, x11, #1
   4c600:	subs	x15, x13, x5
   4c604:	str	x15, [x0], #8
   4c608:	sub	x1, x1, #0x18
   4c60c:	sub	x2, x2, #0x8
   4c610:	b	4c68c <__gmpn_rsblsh1_n@@Base+0xac>
   4c614:	lsl	x13, x11, #1
   4c618:	subs	x15, x13, x5
   4c61c:	str	x15, [x0]
   4c620:	lsr	x0, x11, #63
   4c624:	sbc	x0, x0, xzr
   4c628:	ret
   4c62c:	ldr	x9, [x2]
   4c630:	ldp	x10, x11, [x2, #8]!
   4c634:	lsl	x13, x9, #1
   4c638:	subs	x17, x13, x5
   4c63c:	str	x17, [x0], #8
   4c640:	sub	x1, x1, #0x8
   4c644:	cbz	x18, 4c6b0 <__gmpn_rsblsh1_n@@Base+0xd0>
   4c648:	b	4c670 <__gmpn_rsblsh1_n@@Base+0x90>
   4c64c:	tbnz	w3, #1, 4c660 <__gmpn_rsblsh1_n@@Base+0x80>
   4c650:	negs	x11, xzr
   4c654:	ldp	x8, x9, [x2], #-16
   4c658:	sub	x1, x1, #0x20
   4c65c:	b	4c68c <__gmpn_rsblsh1_n@@Base+0xac>
   4c660:	negs	x9, xzr
   4c664:	ldp	x10, x11, [x2]
   4c668:	sub	x1, x1, #0x10
   4c66c:	cbz	x18, 4c6b0 <__gmpn_rsblsh1_n@@Base+0xd0>
   4c670:	ldp	x4, x5, [x1, #16]
   4c674:	extr	x12, x10, x9, #63
   4c678:	ldp	x8, x9, [x2, #16]
   4c67c:	extr	x13, x11, x10, #63
   4c680:	sbcs	x14, x12, x4
   4c684:	sbcs	x15, x13, x5
   4c688:	stp	x14, x15, [x0], #16
   4c68c:	ldp	x4, x5, [x1, #32]!
   4c690:	extr	x12, x8, x11, #63
   4c694:	ldp	x10, x11, [x2, #32]!
   4c698:	extr	x13, x9, x8, #63
   4c69c:	sbcs	x16, x12, x4
   4c6a0:	sbcs	x17, x13, x5
   4c6a4:	stp	x16, x17, [x0], #16
   4c6a8:	sub	x18, x18, #0x1
   4c6ac:	cbnz	x18, 4c670 <__gmpn_rsblsh1_n@@Base+0x90>
   4c6b0:	ldp	x4, x5, [x1, #16]
   4c6b4:	extr	x12, x10, x9, #63
   4c6b8:	extr	x13, x11, x10, #63
   4c6bc:	sbcs	x14, x12, x4
   4c6c0:	sbcs	x15, x13, x5
   4c6c4:	stp	x14, x15, [x0]
   4c6c8:	lsr	x0, x11, #63
   4c6cc:	sbc	x0, x0, xzr
   4c6d0:	ret
   4c6d4:	nop
   4c6d8:	nop
   4c6dc:	nop

000000000004c6e0 <__gmpn_rsh1add_n@@Base>:
   4c6e0:	lsr	x18, x3, #2
   4c6e4:	tbz	w3, #0, 4c78c <__gmpn_rsh1add_n@@Base+0xac>
   4c6e8:	ldr	x5, [x1], #8
   4c6ec:	ldr	x9, [x2], #8
   4c6f0:	tbnz	w3, #1, 4c748 <__gmpn_rsh1add_n@@Base+0x68>
   4c6f4:	adds	x13, x5, x9
   4c6f8:	and	x10, x13, #0x1
   4c6fc:	cbz	x18, 4c734 <__gmpn_rsh1add_n@@Base+0x54>
   4c700:	ldp	x4, x5, [x1], #48
   4c704:	ldp	x8, x9, [x2], #48
   4c708:	adcs	x14, x4, x8
   4c70c:	adcs	x15, x5, x9
   4c710:	ldp	x4, x5, [x1, #-32]
   4c714:	ldp	x8, x9, [x2, #-32]
   4c718:	extr	x17, x14, x13, #1
   4c71c:	adcs	x12, x4, x8
   4c720:	adcs	x13, x5, x9
   4c724:	str	x17, [x0], #24
   4c728:	sub	x18, x18, #0x1
   4c72c:	cbz	x18, 4c830 <__gmpn_rsh1add_n@@Base+0x150>
   4c730:	b	4c7f0 <__gmpn_rsh1add_n@@Base+0x110>
   4c734:	cset	x14, cs  // cs = hs, nlast
   4c738:	extr	x17, x14, x13, #1
   4c73c:	str	x17, [x0]
   4c740:	mov	x0, x10
   4c744:	ret
   4c748:	adds	x15, x5, x9
   4c74c:	and	x10, x15, #0x1
   4c750:	ldp	x4, x5, [x1], #32
   4c754:	ldp	x8, x9, [x2], #32
   4c758:	adcs	x12, x4, x8
   4c75c:	adcs	x13, x5, x9
   4c760:	cbz	x18, 4c780 <__gmpn_rsh1add_n@@Base+0xa0>
   4c764:	ldp	x4, x5, [x1, #-16]
   4c768:	ldp	x8, x9, [x2, #-16]
   4c76c:	extr	x17, x12, x15, #1
   4c770:	adcs	x14, x4, x8
   4c774:	adcs	x15, x5, x9
   4c778:	str	x17, [x0], #8
   4c77c:	b	4c80c <__gmpn_rsh1add_n@@Base+0x12c>
   4c780:	extr	x17, x12, x15, #1
   4c784:	str	x17, [x0], #8
   4c788:	b	4c83c <__gmpn_rsh1add_n@@Base+0x15c>
   4c78c:	tbz	w3, #1, 4c7bc <__gmpn_rsh1add_n@@Base+0xdc>
   4c790:	ldp	x4, x5, [x1], #32
   4c794:	ldp	x8, x9, [x2], #32
   4c798:	adds	x12, x4, x8
   4c79c:	adcs	x13, x5, x9
   4c7a0:	and	x10, x12, #0x1
   4c7a4:	cbz	x18, 4c83c <__gmpn_rsh1add_n@@Base+0x15c>
   4c7a8:	ldp	x4, x5, [x1, #-16]
   4c7ac:	ldp	x8, x9, [x2, #-16]
   4c7b0:	adcs	x14, x4, x8
   4c7b4:	adcs	x15, x5, x9
   4c7b8:	b	4c80c <__gmpn_rsh1add_n@@Base+0x12c>
   4c7bc:	ldp	x4, x5, [x1], #48
   4c7c0:	ldp	x8, x9, [x2], #48
   4c7c4:	adds	x14, x4, x8
   4c7c8:	adcs	x15, x5, x9
   4c7cc:	and	x10, x14, #0x1
   4c7d0:	ldp	x4, x5, [x1, #-32]
   4c7d4:	ldp	x8, x9, [x2, #-32]
   4c7d8:	adcs	x12, x4, x8
   4c7dc:	adcs	x13, x5, x9
   4c7e0:	add	x0, x0, #0x10
   4c7e4:	sub	x18, x18, #0x1
   4c7e8:	cbz	x18, 4c830 <__gmpn_rsh1add_n@@Base+0x150>
   4c7ec:	nop
   4c7f0:	ldp	x4, x5, [x1, #-16]
   4c7f4:	ldp	x8, x9, [x2, #-16]
   4c7f8:	extr	x16, x15, x14, #1
   4c7fc:	extr	x17, x12, x15, #1
   4c800:	adcs	x14, x4, x8
   4c804:	adcs	x15, x5, x9
   4c808:	stp	x16, x17, [x0, #-16]
   4c80c:	ldp	x4, x5, [x1], #32
   4c810:	ldp	x8, x9, [x2], #32
   4c814:	extr	x16, x13, x12, #1
   4c818:	extr	x17, x14, x13, #1
   4c81c:	adcs	x12, x4, x8
   4c820:	adcs	x13, x5, x9
   4c824:	stp	x16, x17, [x0], #32
   4c828:	sub	x18, x18, #0x1
   4c82c:	cbnz	x18, 4c7f0 <__gmpn_rsh1add_n@@Base+0x110>
   4c830:	extr	x16, x15, x14, #1
   4c834:	extr	x17, x12, x15, #1
   4c838:	stp	x16, x17, [x0, #-16]
   4c83c:	cset	x14, cs  // cs = hs, nlast
   4c840:	extr	x16, x13, x12, #1
   4c844:	extr	x17, x14, x13, #1
   4c848:	stp	x16, x17, [x0]
   4c84c:	mov	x0, x10
   4c850:	ret
   4c854:	nop
   4c858:	nop
   4c85c:	nop

000000000004c860 <__gmpn_rsh1sub_n@@Base>:
   4c860:	lsr	x18, x3, #2
   4c864:	tbz	w3, #0, 4c90c <__gmpn_rsh1sub_n@@Base+0xac>
   4c868:	ldr	x5, [x1], #8
   4c86c:	ldr	x9, [x2], #8
   4c870:	tbnz	w3, #1, 4c8c8 <__gmpn_rsh1sub_n@@Base+0x68>
   4c874:	subs	x13, x5, x9
   4c878:	and	x10, x13, #0x1
   4c87c:	cbz	x18, 4c8b4 <__gmpn_rsh1sub_n@@Base+0x54>
   4c880:	ldp	x4, x5, [x1], #48
   4c884:	ldp	x8, x9, [x2], #48
   4c888:	sbcs	x14, x4, x8
   4c88c:	sbcs	x15, x5, x9
   4c890:	ldp	x4, x5, [x1, #-32]
   4c894:	ldp	x8, x9, [x2, #-32]
   4c898:	extr	x17, x14, x13, #1
   4c89c:	sbcs	x12, x4, x8
   4c8a0:	sbcs	x13, x5, x9
   4c8a4:	str	x17, [x0], #24
   4c8a8:	sub	x18, x18, #0x1
   4c8ac:	cbz	x18, 4c9b0 <__gmpn_rsh1sub_n@@Base+0x150>
   4c8b0:	b	4c970 <__gmpn_rsh1sub_n@@Base+0x110>
   4c8b4:	cset	x14, cc  // cc = lo, ul, last
   4c8b8:	extr	x17, x14, x13, #1
   4c8bc:	str	x17, [x0]
   4c8c0:	mov	x0, x10
   4c8c4:	ret
   4c8c8:	subs	x15, x5, x9
   4c8cc:	and	x10, x15, #0x1
   4c8d0:	ldp	x4, x5, [x1], #32
   4c8d4:	ldp	x8, x9, [x2], #32
   4c8d8:	sbcs	x12, x4, x8
   4c8dc:	sbcs	x13, x5, x9
   4c8e0:	cbz	x18, 4c900 <__gmpn_rsh1sub_n@@Base+0xa0>
   4c8e4:	ldp	x4, x5, [x1, #-16]
   4c8e8:	ldp	x8, x9, [x2, #-16]
   4c8ec:	extr	x17, x12, x15, #1
   4c8f0:	sbcs	x14, x4, x8
   4c8f4:	sbcs	x15, x5, x9
   4c8f8:	str	x17, [x0], #8
   4c8fc:	b	4c98c <__gmpn_rsh1sub_n@@Base+0x12c>
   4c900:	extr	x17, x12, x15, #1
   4c904:	str	x17, [x0], #8
   4c908:	b	4c9bc <__gmpn_rsh1sub_n@@Base+0x15c>
   4c90c:	tbz	w3, #1, 4c93c <__gmpn_rsh1sub_n@@Base+0xdc>
   4c910:	ldp	x4, x5, [x1], #32
   4c914:	ldp	x8, x9, [x2], #32
   4c918:	subs	x12, x4, x8
   4c91c:	sbcs	x13, x5, x9
   4c920:	and	x10, x12, #0x1
   4c924:	cbz	x18, 4c9bc <__gmpn_rsh1sub_n@@Base+0x15c>
   4c928:	ldp	x4, x5, [x1, #-16]
   4c92c:	ldp	x8, x9, [x2, #-16]
   4c930:	sbcs	x14, x4, x8
   4c934:	sbcs	x15, x5, x9
   4c938:	b	4c98c <__gmpn_rsh1sub_n@@Base+0x12c>
   4c93c:	ldp	x4, x5, [x1], #48
   4c940:	ldp	x8, x9, [x2], #48
   4c944:	subs	x14, x4, x8
   4c948:	sbcs	x15, x5, x9
   4c94c:	and	x10, x14, #0x1
   4c950:	ldp	x4, x5, [x1, #-32]
   4c954:	ldp	x8, x9, [x2, #-32]
   4c958:	sbcs	x12, x4, x8
   4c95c:	sbcs	x13, x5, x9
   4c960:	add	x0, x0, #0x10
   4c964:	sub	x18, x18, #0x1
   4c968:	cbz	x18, 4c9b0 <__gmpn_rsh1sub_n@@Base+0x150>
   4c96c:	nop
   4c970:	ldp	x4, x5, [x1, #-16]
   4c974:	ldp	x8, x9, [x2, #-16]
   4c978:	extr	x16, x15, x14, #1
   4c97c:	extr	x17, x12, x15, #1
   4c980:	sbcs	x14, x4, x8
   4c984:	sbcs	x15, x5, x9
   4c988:	stp	x16, x17, [x0, #-16]
   4c98c:	ldp	x4, x5, [x1], #32
   4c990:	ldp	x8, x9, [x2], #32
   4c994:	extr	x16, x13, x12, #1
   4c998:	extr	x17, x14, x13, #1
   4c99c:	sbcs	x12, x4, x8
   4c9a0:	sbcs	x13, x5, x9
   4c9a4:	stp	x16, x17, [x0], #32
   4c9a8:	sub	x18, x18, #0x1
   4c9ac:	cbnz	x18, 4c970 <__gmpn_rsh1sub_n@@Base+0x110>
   4c9b0:	extr	x16, x15, x14, #1
   4c9b4:	extr	x17, x12, x15, #1
   4c9b8:	stp	x16, x17, [x0, #-16]
   4c9bc:	cset	x14, cc  // cc = lo, ul, last
   4c9c0:	extr	x16, x13, x12, #1
   4c9c4:	extr	x17, x14, x13, #1
   4c9c8:	stp	x16, x17, [x0]
   4c9cc:	mov	x0, x10
   4c9d0:	ret
   4c9d4:	nop
   4c9d8:	nop
   4c9dc:	nop

000000000004c9e0 <__gmpn_addlsh2_n@@Base>:
   4c9e0:	lsr	x18, x3, #2
   4c9e4:	tbz	w3, #0, 4ca4c <__gmpn_addlsh2_n@@Base+0x6c>
   4c9e8:	ldr	x5, [x1]
   4c9ec:	tbnz	w3, #1, 4ca2c <__gmpn_addlsh2_n@@Base+0x4c>
   4c9f0:	ldr	x11, [x2]
   4c9f4:	cbz	x18, 4ca14 <__gmpn_addlsh2_n@@Base+0x34>
   4c9f8:	ldp	x8, x9, [x2, #8]
   4c9fc:	lsl	x13, x11, #2
   4ca00:	adds	x15, x13, x5
   4ca04:	str	x15, [x0], #8
   4ca08:	sub	x1, x1, #0x18
   4ca0c:	sub	x2, x2, #0x8
   4ca10:	b	4ca8c <__gmpn_addlsh2_n@@Base+0xac>
   4ca14:	lsl	x13, x11, #2
   4ca18:	adds	x15, x13, x5
   4ca1c:	str	x15, [x0]
   4ca20:	lsr	x0, x11, #62
   4ca24:	adc	x0, x0, xzr
   4ca28:	ret
   4ca2c:	ldr	x9, [x2]
   4ca30:	ldp	x10, x11, [x2, #8]!
   4ca34:	lsl	x13, x9, #2
   4ca38:	adds	x17, x13, x5
   4ca3c:	str	x17, [x0], #8
   4ca40:	sub	x1, x1, #0x8
   4ca44:	cbz	x18, 4cab0 <__gmpn_addlsh2_n@@Base+0xd0>
   4ca48:	b	4ca70 <__gmpn_addlsh2_n@@Base+0x90>
   4ca4c:	tbnz	w3, #1, 4ca60 <__gmpn_addlsh2_n@@Base+0x80>
   4ca50:	adds	x11, xzr, xzr
   4ca54:	ldp	x8, x9, [x2], #-16
   4ca58:	sub	x1, x1, #0x20
   4ca5c:	b	4ca8c <__gmpn_addlsh2_n@@Base+0xac>
   4ca60:	adds	x9, xzr, xzr
   4ca64:	ldp	x10, x11, [x2]
   4ca68:	sub	x1, x1, #0x10
   4ca6c:	cbz	x18, 4cab0 <__gmpn_addlsh2_n@@Base+0xd0>
   4ca70:	ldp	x4, x5, [x1, #16]
   4ca74:	extr	x12, x10, x9, #62
   4ca78:	ldp	x8, x9, [x2, #16]
   4ca7c:	extr	x13, x11, x10, #62
   4ca80:	adcs	x14, x12, x4
   4ca84:	adcs	x15, x13, x5
   4ca88:	stp	x14, x15, [x0], #16
   4ca8c:	ldp	x4, x5, [x1, #32]!
   4ca90:	extr	x12, x8, x11, #62
   4ca94:	ldp	x10, x11, [x2, #32]!
   4ca98:	extr	x13, x9, x8, #62
   4ca9c:	adcs	x16, x12, x4
   4caa0:	adcs	x17, x13, x5
   4caa4:	stp	x16, x17, [x0], #16
   4caa8:	sub	x18, x18, #0x1
   4caac:	cbnz	x18, 4ca70 <__gmpn_addlsh2_n@@Base+0x90>
   4cab0:	ldp	x4, x5, [x1, #16]
   4cab4:	extr	x12, x10, x9, #62
   4cab8:	extr	x13, x11, x10, #62
   4cabc:	adcs	x14, x12, x4
   4cac0:	adcs	x15, x13, x5
   4cac4:	stp	x14, x15, [x0]
   4cac8:	lsr	x0, x11, #62
   4cacc:	adc	x0, x0, xzr
   4cad0:	ret
   4cad4:	nop
   4cad8:	nop
   4cadc:	nop

000000000004cae0 <__gmpn_sublsh2_n@@Base>:
   4cae0:	lsr	x18, x3, #2
   4cae4:	tbz	w3, #0, 4cb4c <__gmpn_sublsh2_n@@Base+0x6c>
   4cae8:	ldr	x5, [x1]
   4caec:	tbnz	w3, #1, 4cb2c <__gmpn_sublsh2_n@@Base+0x4c>
   4caf0:	ldr	x11, [x2]
   4caf4:	cbz	x18, 4cb14 <__gmpn_sublsh2_n@@Base+0x34>
   4caf8:	ldp	x8, x9, [x2, #8]
   4cafc:	lsl	x13, x11, #2
   4cb00:	subs	x15, x5, x13
   4cb04:	str	x15, [x0], #8
   4cb08:	sub	x1, x1, #0x18
   4cb0c:	sub	x2, x2, #0x8
   4cb10:	b	4cb8c <__gmpn_sublsh2_n@@Base+0xac>
   4cb14:	lsl	x13, x11, #2
   4cb18:	subs	x15, x5, x13
   4cb1c:	str	x15, [x0]
   4cb20:	lsr	x0, x11, #62
   4cb24:	cinc	x0, x0, cc  // cc = lo, ul, last
   4cb28:	ret
   4cb2c:	ldr	x9, [x2]
   4cb30:	ldp	x10, x11, [x2, #8]!
   4cb34:	lsl	x13, x9, #2
   4cb38:	subs	x17, x5, x13
   4cb3c:	str	x17, [x0], #8
   4cb40:	sub	x1, x1, #0x8
   4cb44:	cbz	x18, 4cbb0 <__gmpn_sublsh2_n@@Base+0xd0>
   4cb48:	b	4cb70 <__gmpn_sublsh2_n@@Base+0x90>
   4cb4c:	tbnz	w3, #1, 4cb60 <__gmpn_sublsh2_n@@Base+0x80>
   4cb50:	negs	x11, xzr
   4cb54:	ldp	x8, x9, [x2], #-16
   4cb58:	sub	x1, x1, #0x20
   4cb5c:	b	4cb8c <__gmpn_sublsh2_n@@Base+0xac>
   4cb60:	negs	x9, xzr
   4cb64:	ldp	x10, x11, [x2]
   4cb68:	sub	x1, x1, #0x10
   4cb6c:	cbz	x18, 4cbb0 <__gmpn_sublsh2_n@@Base+0xd0>
   4cb70:	ldp	x4, x5, [x1, #16]
   4cb74:	extr	x12, x10, x9, #62
   4cb78:	ldp	x8, x9, [x2, #16]
   4cb7c:	extr	x13, x11, x10, #62
   4cb80:	sbcs	x14, x4, x12
   4cb84:	sbcs	x15, x5, x13
   4cb88:	stp	x14, x15, [x0], #16
   4cb8c:	ldp	x4, x5, [x1, #32]!
   4cb90:	extr	x12, x8, x11, #62
   4cb94:	ldp	x10, x11, [x2, #32]!
   4cb98:	extr	x13, x9, x8, #62
   4cb9c:	sbcs	x16, x4, x12
   4cba0:	sbcs	x17, x5, x13
   4cba4:	stp	x16, x17, [x0], #16
   4cba8:	sub	x18, x18, #0x1
   4cbac:	cbnz	x18, 4cb70 <__gmpn_sublsh2_n@@Base+0x90>
   4cbb0:	ldp	x4, x5, [x1, #16]
   4cbb4:	extr	x12, x10, x9, #62
   4cbb8:	extr	x13, x11, x10, #62
   4cbbc:	sbcs	x14, x4, x12
   4cbc0:	sbcs	x15, x5, x13
   4cbc4:	stp	x14, x15, [x0]
   4cbc8:	lsr	x0, x11, #62
   4cbcc:	cinc	x0, x0, cc  // cc = lo, ul, last
   4cbd0:	ret
   4cbd4:	nop
   4cbd8:	nop
   4cbdc:	nop

000000000004cbe0 <__gmpn_rsblsh2_n@@Base>:
   4cbe0:	lsr	x18, x3, #2
   4cbe4:	tbz	w3, #0, 4cc4c <__gmpn_rsblsh2_n@@Base+0x6c>
   4cbe8:	ldr	x5, [x1]
   4cbec:	tbnz	w3, #1, 4cc2c <__gmpn_rsblsh2_n@@Base+0x4c>
   4cbf0:	ldr	x11, [x2]
   4cbf4:	cbz	x18, 4cc14 <__gmpn_rsblsh2_n@@Base+0x34>
   4cbf8:	ldp	x8, x9, [x2, #8]
   4cbfc:	lsl	x13, x11, #2
   4cc00:	subs	x15, x13, x5
   4cc04:	str	x15, [x0], #8
   4cc08:	sub	x1, x1, #0x18
   4cc0c:	sub	x2, x2, #0x8
   4cc10:	b	4cc8c <__gmpn_rsblsh2_n@@Base+0xac>
   4cc14:	lsl	x13, x11, #2
   4cc18:	subs	x15, x13, x5
   4cc1c:	str	x15, [x0]
   4cc20:	lsr	x0, x11, #62
   4cc24:	sbc	x0, x0, xzr
   4cc28:	ret
   4cc2c:	ldr	x9, [x2]
   4cc30:	ldp	x10, x11, [x2, #8]!
   4cc34:	lsl	x13, x9, #2
   4cc38:	subs	x17, x13, x5
   4cc3c:	str	x17, [x0], #8
   4cc40:	sub	x1, x1, #0x8
   4cc44:	cbz	x18, 4ccb0 <__gmpn_rsblsh2_n@@Base+0xd0>
   4cc48:	b	4cc70 <__gmpn_rsblsh2_n@@Base+0x90>
   4cc4c:	tbnz	w3, #1, 4cc60 <__gmpn_rsblsh2_n@@Base+0x80>
   4cc50:	negs	x11, xzr
   4cc54:	ldp	x8, x9, [x2], #-16
   4cc58:	sub	x1, x1, #0x20
   4cc5c:	b	4cc8c <__gmpn_rsblsh2_n@@Base+0xac>
   4cc60:	negs	x9, xzr
   4cc64:	ldp	x10, x11, [x2]
   4cc68:	sub	x1, x1, #0x10
   4cc6c:	cbz	x18, 4ccb0 <__gmpn_rsblsh2_n@@Base+0xd0>
   4cc70:	ldp	x4, x5, [x1, #16]
   4cc74:	extr	x12, x10, x9, #62
   4cc78:	ldp	x8, x9, [x2, #16]
   4cc7c:	extr	x13, x11, x10, #62
   4cc80:	sbcs	x14, x12, x4
   4cc84:	sbcs	x15, x13, x5
   4cc88:	stp	x14, x15, [x0], #16
   4cc8c:	ldp	x4, x5, [x1, #32]!
   4cc90:	extr	x12, x8, x11, #62
   4cc94:	ldp	x10, x11, [x2, #32]!
   4cc98:	extr	x13, x9, x8, #62
   4cc9c:	sbcs	x16, x12, x4
   4cca0:	sbcs	x17, x13, x5
   4cca4:	stp	x16, x17, [x0], #16
   4cca8:	sub	x18, x18, #0x1
   4ccac:	cbnz	x18, 4cc70 <__gmpn_rsblsh2_n@@Base+0x90>
   4ccb0:	ldp	x4, x5, [x1, #16]
   4ccb4:	extr	x12, x10, x9, #62
   4ccb8:	extr	x13, x11, x10, #62
   4ccbc:	sbcs	x14, x12, x4
   4ccc0:	sbcs	x15, x13, x5
   4ccc4:	stp	x14, x15, [x0]
   4ccc8:	lsr	x0, x11, #62
   4cccc:	sbc	x0, x0, xzr
   4ccd0:	ret

000000000004ccd4 <__gmpn_add_n_sub_n@@Base>:
   4ccd4:	stp	x29, x30, [sp, #-96]!
   4ccd8:	stp	x28, x27, [sp, #16]
   4ccdc:	stp	x26, x25, [sp, #32]
   4cce0:	stp	x24, x23, [sp, #48]
   4cce4:	stp	x22, x21, [sp, #64]
   4cce8:	stp	x20, x19, [sp, #80]
   4ccec:	mov	x29, sp
   4ccf0:	sub	sp, sp, #0x560
   4ccf4:	mov	x19, x4
   4ccf8:	mov	x20, x3
   4ccfc:	mov	x21, x2
   4cd00:	mov	x22, x0
   4cd04:	cmp	x0, x2
   4cd08:	mov	x23, x1
   4cd0c:	b.eq	4cd98 <__gmpn_add_n_sub_n@@Base+0xc4>  // b.none
   4cd10:	cmp	x22, x20
   4cd14:	b.eq	4cd98 <__gmpn_add_n_sub_n@@Base+0xc4>  // b.none
   4cd18:	cmp	x19, #0x1
   4cd1c:	b.lt	4ceb8 <__gmpn_add_n_sub_n@@Base+0x1e4>  // b.tstop
   4cd20:	mov	x27, xzr
   4cd24:	mov	x25, xzr
   4cd28:	mov	x24, xzr
   4cd2c:	mov	x8, x19
   4cd30:	subs	x28, x8, #0xaa
   4cd34:	mov	w9, #0xaa                  	// #170
   4cd38:	csel	x26, x8, x9, lt  // lt = tstop
   4cd3c:	mov	x0, x22
   4cd40:	mov	x1, x21
   4cd44:	mov	x2, x20
   4cd48:	mov	x3, x26
   4cd4c:	mov	x4, x24
   4cd50:	bl	ceb0 <__gmpn_add_nc@plt>
   4cd54:	mov	x24, x0
   4cd58:	mov	x0, x23
   4cd5c:	mov	x1, x21
   4cd60:	mov	x2, x20
   4cd64:	mov	x3, x26
   4cd68:	mov	x4, x25
   4cd6c:	bl	c780 <__gmpn_sub_nc@plt>
   4cd70:	add	x27, x27, #0xaa
   4cd74:	mov	x25, x0
   4cd78:	add	x23, x23, #0x550
   4cd7c:	add	x20, x20, #0x550
   4cd80:	add	x21, x21, #0x550
   4cd84:	cmp	x27, x19
   4cd88:	add	x22, x22, #0x550
   4cd8c:	mov	x8, x28
   4cd90:	b.lt	4cd30 <__gmpn_add_n_sub_n@@Base+0x5c>  // b.tstop
   4cd94:	b	4cec0 <__gmpn_add_n_sub_n@@Base+0x1ec>
   4cd98:	cmp	x23, x21
   4cd9c:	b.eq	4ce28 <__gmpn_add_n_sub_n@@Base+0x154>  // b.none
   4cda0:	cmp	x23, x20
   4cda4:	b.eq	4ce28 <__gmpn_add_n_sub_n@@Base+0x154>  // b.none
   4cda8:	cmp	x19, #0x1
   4cdac:	b.lt	4ceb8 <__gmpn_add_n_sub_n@@Base+0x1e4>  // b.tstop
   4cdb0:	mov	x27, xzr
   4cdb4:	mov	x25, xzr
   4cdb8:	mov	x24, xzr
   4cdbc:	mov	x8, x19
   4cdc0:	subs	x28, x8, #0xaa
   4cdc4:	mov	w9, #0xaa                  	// #170
   4cdc8:	csel	x26, x8, x9, lt  // lt = tstop
   4cdcc:	mov	x0, x23
   4cdd0:	mov	x1, x21
   4cdd4:	mov	x2, x20
   4cdd8:	mov	x3, x26
   4cddc:	mov	x4, x25
   4cde0:	bl	c780 <__gmpn_sub_nc@plt>
   4cde4:	mov	x25, x0
   4cde8:	mov	x0, x22
   4cdec:	mov	x1, x21
   4cdf0:	mov	x2, x20
   4cdf4:	mov	x3, x26
   4cdf8:	mov	x4, x24
   4cdfc:	bl	ceb0 <__gmpn_add_nc@plt>
   4ce00:	add	x27, x27, #0xaa
   4ce04:	mov	x24, x0
   4ce08:	add	x22, x22, #0x550
   4ce0c:	add	x20, x20, #0x550
   4ce10:	add	x21, x21, #0x550
   4ce14:	cmp	x27, x19
   4ce18:	add	x23, x23, #0x550
   4ce1c:	mov	x8, x28
   4ce20:	b.lt	4cdc0 <__gmpn_add_n_sub_n@@Base+0xec>  // b.tstop
   4ce24:	b	4cec0 <__gmpn_add_n_sub_n@@Base+0x1ec>
   4ce28:	cmp	x19, #0x1
   4ce2c:	b.lt	4ceb8 <__gmpn_add_n_sub_n@@Base+0x1e4>  // b.tstop
   4ce30:	mov	x27, xzr
   4ce34:	mov	x25, xzr
   4ce38:	mov	x24, xzr
   4ce3c:	mov	x8, x19
   4ce40:	subs	x28, x8, #0xaa
   4ce44:	mov	w9, #0xaa                  	// #170
   4ce48:	csel	x26, x8, x9, lt  // lt = tstop
   4ce4c:	add	x0, sp, #0x8
   4ce50:	mov	x1, x21
   4ce54:	mov	x2, x20
   4ce58:	mov	x3, x26
   4ce5c:	mov	x4, x24
   4ce60:	bl	ceb0 <__gmpn_add_nc@plt>
   4ce64:	mov	x24, x0
   4ce68:	mov	x0, x23
   4ce6c:	mov	x1, x21
   4ce70:	mov	x2, x20
   4ce74:	mov	x3, x26
   4ce78:	mov	x4, x25
   4ce7c:	bl	c780 <__gmpn_sub_nc@plt>
   4ce80:	mov	x25, x0
   4ce84:	add	x1, sp, #0x8
   4ce88:	mov	x0, x22
   4ce8c:	mov	x2, x26
   4ce90:	bl	ca70 <__gmpn_copyi@plt>
   4ce94:	add	x27, x27, #0xaa
   4ce98:	add	x22, x22, #0x550
   4ce9c:	add	x23, x23, #0x550
   4cea0:	add	x20, x20, #0x550
   4cea4:	cmp	x27, x19
   4cea8:	add	x21, x21, #0x550
   4ceac:	mov	x8, x28
   4ceb0:	b.lt	4ce40 <__gmpn_add_n_sub_n@@Base+0x16c>  // b.tstop
   4ceb4:	b	4cec0 <__gmpn_add_n_sub_n@@Base+0x1ec>
   4ceb8:	mov	x24, xzr
   4cebc:	mov	x25, xzr
   4cec0:	add	x0, x25, x24, lsl #1
   4cec4:	add	sp, sp, #0x560
   4cec8:	ldp	x20, x19, [sp, #80]
   4cecc:	ldp	x22, x21, [sp, #64]
   4ced0:	ldp	x24, x23, [sp, #48]
   4ced4:	ldp	x26, x25, [sp, #32]
   4ced8:	ldp	x28, x27, [sp, #16]
   4cedc:	ldp	x29, x30, [sp], #96
   4cee0:	ret

000000000004cee4 <__gmp_asprintf@@Base>:
   4cee4:	sub	sp, sp, #0x100
   4cee8:	stp	x29, x30, [sp, #240]
   4ceec:	add	x29, sp, #0xf0
   4cef0:	mov	x8, #0xffffffffffffffd0    	// #-48
   4cef4:	mov	x9, sp
   4cef8:	sub	x10, x29, #0x70
   4cefc:	movk	x8, #0xff80, lsl #32
   4cf00:	add	x11, x29, #0x10
   4cf04:	add	x9, x9, #0x80
   4cf08:	add	x10, x10, #0x30
   4cf0c:	stp	x9, x8, [x29, #-16]
   4cf10:	stp	x11, x10, [x29, #-32]
   4cf14:	stp	x2, x3, [x29, #-112]
   4cf18:	stp	x4, x5, [x29, #-96]
   4cf1c:	stp	x6, x7, [x29, #-80]
   4cf20:	stp	q1, q2, [sp, #16]
   4cf24:	str	q0, [sp]
   4cf28:	ldp	q0, q1, [x29, #-32]
   4cf2c:	sub	x2, x29, #0x40
   4cf30:	stp	q3, q4, [sp, #48]
   4cf34:	stp	q5, q6, [sp, #80]
   4cf38:	str	q7, [sp, #112]
   4cf3c:	stp	q0, q1, [x29, #-64]
   4cf40:	bl	c520 <__gmp_vasprintf@plt>
   4cf44:	ldp	x29, x30, [sp, #240]
   4cf48:	add	sp, sp, #0x100
   4cf4c:	ret

000000000004cf50 <__gmp_asprintf_memory@@Base>:
   4cf50:	stp	x29, x30, [sp, #-48]!
   4cf54:	str	x21, [sp, #16]
   4cf58:	stp	x20, x19, [sp, #32]
   4cf5c:	ldp	x9, x8, [x0, #16]
   4cf60:	mov	x19, x0
   4cf64:	mov	x20, x2
   4cf68:	mov	x21, x1
   4cf6c:	add	x10, x9, x2
   4cf70:	cmp	x8, x10
   4cf74:	mov	x29, sp
   4cf78:	b.ls	4cf84 <__gmp_asprintf_memory@@Base+0x34>  // b.plast
   4cf7c:	ldr	x0, [x19, #8]
   4cf80:	b	4cfac <__gmp_asprintf_memory@@Base+0x5c>
   4cf84:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4cf88:	ldr	x9, [x9, #3792]
   4cf8c:	lsl	x2, x10, #1
   4cf90:	str	x2, [x19, #24]
   4cf94:	ldr	x0, [x19, #8]
   4cf98:	ldr	x9, [x9]
   4cf9c:	mov	x1, x8
   4cfa0:	blr	x9
   4cfa4:	ldr	x9, [x19, #16]
   4cfa8:	str	x0, [x19, #8]
   4cfac:	add	x0, x0, x9
   4cfb0:	mov	x1, x21
   4cfb4:	mov	x2, x20
   4cfb8:	bl	bee0 <memcpy@plt>
   4cfbc:	ldr	x8, [x19, #16]
   4cfc0:	mov	w0, w20
   4cfc4:	ldr	x21, [sp, #16]
   4cfc8:	add	x8, x8, x20
   4cfcc:	str	x8, [x19, #16]
   4cfd0:	ldp	x20, x19, [sp, #32]
   4cfd4:	ldp	x29, x30, [sp], #48
   4cfd8:	ret

000000000004cfdc <__gmp_asprintf_reps@@Base>:
   4cfdc:	stp	x29, x30, [sp, #-48]!
   4cfe0:	stp	x22, x21, [sp, #16]
   4cfe4:	stp	x20, x19, [sp, #32]
   4cfe8:	mov	w21, w1
   4cfec:	ldp	x8, x1, [x0, #16]
   4cff0:	mov	w19, w2
   4cff4:	mov	x20, x0
   4cff8:	sxtw	x22, w19
   4cffc:	add	x9, x8, w2, sxtw
   4d000:	cmp	x1, x9
   4d004:	mov	x29, sp
   4d008:	b.ls	4d014 <__gmp_asprintf_reps@@Base+0x38>  // b.plast
   4d00c:	ldr	x0, [x20, #8]
   4d010:	b	4d038 <__gmp_asprintf_reps@@Base+0x5c>
   4d014:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4d018:	ldr	x8, [x8, #3792]
   4d01c:	lsl	x2, x9, #1
   4d020:	str	x2, [x20, #24]
   4d024:	ldr	x0, [x20, #8]
   4d028:	ldr	x8, [x8]
   4d02c:	blr	x8
   4d030:	ldr	x8, [x20, #16]
   4d034:	str	x0, [x20, #8]
   4d038:	add	x0, x0, x8
   4d03c:	mov	w1, w21
   4d040:	mov	x2, x22
   4d044:	bl	c610 <memset@plt>
   4d048:	ldr	x8, [x20, #16]
   4d04c:	mov	w0, w19
   4d050:	add	x8, x8, x22
   4d054:	str	x8, [x20, #16]
   4d058:	ldp	x20, x19, [sp, #32]
   4d05c:	ldp	x22, x21, [sp, #16]
   4d060:	ldp	x29, x30, [sp], #48
   4d064:	ret

000000000004d068 <__gmp_asprintf_final@@Base>:
   4d068:	stp	x29, x30, [sp, #-32]!
   4d06c:	str	x19, [sp, #16]
   4d070:	mov	x19, x0
   4d074:	ldr	x0, [x0, #8]
   4d078:	ldr	x8, [x19, #16]
   4d07c:	mov	x29, sp
   4d080:	strb	wzr, [x0, x8]
   4d084:	ldp	x8, x1, [x19, #16]
   4d088:	add	x2, x8, #0x1
   4d08c:	cmp	x1, x2
   4d090:	b.eq	4d0a4 <__gmp_asprintf_final@@Base+0x3c>  // b.none
   4d094:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4d098:	ldr	x8, [x8, #3792]
   4d09c:	ldr	x8, [x8]
   4d0a0:	blr	x8
   4d0a4:	ldr	x8, [x19]
   4d0a8:	ldr	x19, [sp, #16]
   4d0ac:	str	x0, [x8]
   4d0b0:	mov	w0, wzr
   4d0b4:	ldp	x29, x30, [sp], #32
   4d0b8:	ret

000000000004d0bc <__gmp_doprnt@@Base>:
   4d0bc:	sub	sp, sp, #0x1a0
   4d0c0:	str	d8, [sp, #304]
   4d0c4:	stp	x29, x30, [sp, #320]
   4d0c8:	stp	x28, x27, [sp, #336]
   4d0cc:	stp	x26, x25, [sp, #352]
   4d0d0:	stp	x24, x23, [sp, #368]
   4d0d4:	stp	x22, x21, [sp, #384]
   4d0d8:	stp	x20, x19, [sp, #400]
   4d0dc:	stp	x1, x0, [sp, #24]
   4d0e0:	ldp	q1, q0, [x3]
   4d0e4:	add	x29, sp, #0x130
   4d0e8:	mov	x0, x2
   4d0ec:	mov	x23, x2
   4d0f0:	stp	q1, q0, [x29, #-48]
   4d0f4:	bl	bf70 <strlen@plt>
   4d0f8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4d0fc:	ldr	x8, [x8, #3840]
   4d100:	add	x19, x0, #0x1
   4d104:	mov	x0, x19
   4d108:	ldr	x8, [x8]
   4d10c:	blr	x8
   4d110:	mov	x1, x23
   4d114:	mov	x2, x19
   4d118:	mov	x20, x0
   4d11c:	str	x19, [sp, #16]
   4d120:	bl	bee0 <memcpy@plt>
   4d124:	ldp	q0, q1, [x29, #-48]
   4d128:	mov	w1, #0x25                  	// #37
   4d12c:	mov	x0, x20
   4d130:	stp	q0, q1, [x29, #-112]
   4d134:	bl	cdc0 <strchr@plt>
   4d138:	str	x20, [sp, #8]
   4d13c:	cbz	x0, 4d994 <__gmp_doprnt@@Base+0x8d8>
   4d140:	adrp	x9, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4d144:	adrp	x10, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4d148:	ldr	d8, [x9, #1408]
   4d14c:	ldr	q0, [x10, #1424]
   4d150:	add	x8, sp, #0x88
   4d154:	adrp	x28, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4d158:	mov	x26, x0
   4d15c:	add	x21, x8, #0x30
   4d160:	add	x8, x8, #0x1c
   4d164:	add	x28, x28, #0x5a0
   4d168:	str	xzr, [sp, #72]
   4d16c:	str	x8, [x29, #8]
   4d170:	str	q0, [sp, #48]
   4d174:	str	x20, [sp, #40]
   4d178:	ldp	q0, q1, [x29, #-48]
   4d17c:	adrp	x8, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4d180:	add	x8, x8, #0x66c
   4d184:	str	x8, [sp, #144]
   4d188:	stp	q0, q1, [x29, #-80]
   4d18c:	ldr	q0, [sp, #48]
   4d190:	mov	w8, #0x20                  	// #32
   4d194:	mov	w20, wzr
   4d198:	mov	w22, wzr
   4d19c:	add	x25, x26, #0x1
   4d1a0:	strb	w8, [sp, #156]
   4d1a4:	mov	w8, #0x1                   	// #1
   4d1a8:	str	d8, [sp, #136]
   4d1ac:	str	wzr, [sp, #152]
   4d1b0:	stur	q0, [sp, #160]
   4d1b4:	str	w8, [sp, #176]
   4d1b8:	strb	wzr, [sp, #180]
   4d1bc:	str	wzr, [sp, #184]
   4d1c0:	mov	x27, x21
   4d1c4:	mov	x8, x25
   4d1c8:	ldrb	w23, [x25], #1
   4d1cc:	sub	w9, w23, #0x20
   4d1d0:	cmp	w9, #0x5a
   4d1d4:	b.hi	4d878 <__gmp_doprnt@@Base+0x7bc>  // b.pmore
   4d1d8:	adr	x10, 4d1c4 <__gmp_doprnt@@Base+0x108>
   4d1dc:	ldrh	w11, [x28, x9, lsl #1]
   4d1e0:	add	x10, x10, x11, lsl #2
   4d1e4:	br	x10
   4d1e8:	mov	w19, wzr
   4d1ec:	mov	x24, x25
   4d1f0:	mov	w8, #0xa                   	// #10
   4d1f4:	madd	w8, w19, w8, w23
   4d1f8:	ldrb	w23, [x24]
   4d1fc:	mov	x25, x24
   4d200:	sub	w19, w8, #0x30
   4d204:	tbnz	w23, #7, 4d21c <__gmp_doprnt@@Base+0x160>
   4d208:	add	x24, x25, #0x1
   4d20c:	bl	cb00 <__ctype_b_loc@plt>
   4d210:	ldr	x8, [x0]
   4d214:	ldrh	w8, [x8, x23, lsl #1]
   4d218:	tbnz	w8, #11, 4d1f0 <__gmp_doprnt@@Base+0x134>
   4d21c:	str	w19, [x27]
   4d220:	b	4d1c4 <__gmp_doprnt@@Base+0x108>
   4d224:	strb	w23, [sp, #180]
   4d228:	b	4d1c4 <__gmp_doprnt@@Base+0x108>
   4d22c:	mov	w8, #0x3                   	// #3
   4d230:	str	w8, [sp, #168]
   4d234:	b	4d1c4 <__gmp_doprnt@@Base+0x108>
   4d238:	ldursw	x8, [x29, #-24]
   4d23c:	tbz	w8, #31, 4d2bc <__gmp_doprnt@@Base+0x200>
   4d240:	add	w9, w8, #0x8
   4d244:	cmn	w8, #0x8
   4d248:	stur	w9, [x29, #-24]
   4d24c:	b.gt	4d2bc <__gmp_doprnt@@Base+0x200>
   4d250:	ldur	x9, [x29, #-40]
   4d254:	add	x8, x9, x8
   4d258:	b	4d2c8 <__gmp_doprnt@@Base+0x20c>
   4d25c:	mov	w8, #0x1                   	// #1
   4d260:	str	w8, [sp, #160]
   4d264:	b	4d1c4 <__gmp_doprnt@@Base+0x108>
   4d268:	ldr	x27, [x29, #8]
   4d26c:	mov	w8, #0xffffffff            	// #-1
   4d270:	str	w8, [sp, #164]
   4d274:	mov	w20, #0x1                   	// #1
   4d278:	b	4d1c4 <__gmp_doprnt@@Base+0x108>
   4d27c:	cmp	x27, x21
   4d280:	b.eq	4d2e0 <__gmp_doprnt@@Base+0x224>  // b.none
   4d284:	str	wzr, [x27]
   4d288:	b	4d1c4 <__gmp_doprnt@@Base+0x108>
   4d28c:	mov	w22, #0x6c                  	// #108
   4d290:	strb	w22, [x8]
   4d294:	b	4d1c4 <__gmp_doprnt@@Base+0x108>
   4d298:	cmp	w22, #0x68
   4d29c:	mov	w22, #0x48                  	// #72
   4d2a0:	b.eq	4d1c4 <__gmp_doprnt@@Base+0x108>  // b.none
   4d2a4:	b	4d2b4 <__gmp_doprnt@@Base+0x1f8>
   4d2a8:	cmp	w22, #0x6c
   4d2ac:	mov	w22, #0x4c                  	// #76
   4d2b0:	b.eq	4d1c4 <__gmp_doprnt@@Base+0x108>  // b.none
   4d2b4:	mov	w22, w23
   4d2b8:	b	4d1c4 <__gmp_doprnt@@Base+0x108>
   4d2bc:	ldur	x8, [x29, #-48]
   4d2c0:	add	x9, x8, #0x8
   4d2c4:	stur	x9, [x29, #-48]
   4d2c8:	ldr	w8, [x8]
   4d2cc:	cmp	x27, x21
   4d2d0:	b.eq	4d304 <__gmp_doprnt@@Base+0x248>  // b.none
   4d2d4:	bic	w8, w8, w8, asr #31
   4d2d8:	str	w8, [sp, #164]
   4d2dc:	b	4d1c4 <__gmp_doprnt@@Base+0x108>
   4d2e0:	ldr	w8, [sp, #160]
   4d2e4:	mov	w9, #0x30                  	// #48
   4d2e8:	mov	x27, x21
   4d2ec:	strb	w9, [sp, #156]
   4d2f0:	cmp	w8, #0x2
   4d2f4:	b.ne	4d1c4 <__gmp_doprnt@@Base+0x108>  // b.any
   4d2f8:	mov	w8, #0x3                   	// #3
   4d2fc:	str	w8, [sp, #160]
   4d300:	b	4d1c0 <__gmp_doprnt@@Base+0x104>
   4d304:	tbz	w8, #31, 4d314 <__gmp_doprnt@@Base+0x258>
   4d308:	mov	w9, #0x1                   	// #1
   4d30c:	neg	w8, w8
   4d310:	str	w9, [sp, #160]
   4d314:	str	w8, [sp, #184]
   4d318:	b	4d1c0 <__gmp_doprnt@@Base+0x104>
   4d31c:	adrp	x8, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4d320:	add	x8, x8, #0x67c
   4d324:	mov	w9, #0xfffffff0            	// #-16
   4d328:	b	4d380 <__gmp_doprnt@@Base+0x2c4>
   4d32c:	adrp	x9, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4d330:	mov	w8, #0xfffffff6            	// #-10
   4d334:	add	x9, x9, #0x683
   4d338:	str	w8, [sp, #136]
   4d33c:	str	x9, [sp, #144]
   4d340:	mov	w8, #0x2                   	// #2
   4d344:	b	4d3ac <__gmp_doprnt@@Base+0x2f0>
   4d348:	adrp	x9, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4d34c:	mov	w8, #0xfffffff6            	// #-10
   4d350:	add	x9, x9, #0x683
   4d354:	str	w8, [sp, #136]
   4d358:	str	x9, [sp, #144]
   4d35c:	mov	w8, #0x3                   	// #3
   4d360:	str	w8, [sp, #140]
   4d364:	str	wzr, [sp, #176]
   4d368:	b	4d3b0 <__gmp_doprnt@@Base+0x2f4>
   4d36c:	mov	w8, #0xfffffff0            	// #-16
   4d370:	b	4d540 <__gmp_doprnt@@Base+0x484>
   4d374:	adrp	x8, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4d378:	add	x8, x8, #0x675
   4d37c:	mov	w9, #0x10                  	// #16
   4d380:	str	x8, [sp, #144]
   4d384:	mov	w10, #0x2                   	// #2
   4d388:	mov	w8, #0x1                   	// #1
   4d38c:	stp	w9, w10, [sp, #136]
   4d390:	str	w8, [sp, #152]
   4d394:	cbnz	w20, 4d3a0 <__gmp_doprnt@@Base+0x2e4>
   4d398:	mov	w9, #0xffffffff            	// #-1
   4d39c:	str	w9, [sp, #164]
   4d3a0:	str	w8, [sp, #168]
   4d3a4:	b	4d3c4 <__gmp_doprnt@@Base+0x308>
   4d3a8:	mov	w8, #0x1                   	// #1
   4d3ac:	str	w8, [sp, #140]
   4d3b0:	ldr	w8, [sp, #168]
   4d3b4:	cmp	w8, #0x3
   4d3b8:	b.ne	4d3cc <__gmp_doprnt@@Base+0x310>  // b.any
   4d3bc:	mov	w8, #0x1                   	// #1
   4d3c0:	str	w8, [sp, #172]
   4d3c4:	mov	w8, #0x1                   	// #1
   4d3c8:	str	w8, [sp, #176]
   4d3cc:	and	w8, w22, #0xff
   4d3d0:	cmp	w8, #0x4c
   4d3d4:	b.eq	4d44c <__gmp_doprnt@@Base+0x390>  // b.none
   4d3d8:	cmp	w8, #0x46
   4d3dc:	b.ne	4d478 <__gmp_doprnt@@Base+0x3bc>  // b.any
   4d3e0:	ldr	x1, [sp, #40]
   4d3e4:	cmp	x26, x1
   4d3e8:	b.eq	4d41c <__gmp_doprnt@@Base+0x360>  // b.none
   4d3ec:	strb	wzr, [x26]
   4d3f0:	ldp	x0, x8, [sp, #24]
   4d3f4:	ldp	q0, q1, [x29, #-112]
   4d3f8:	add	x2, sp, #0x50
   4d3fc:	ldr	x8, [x8]
   4d400:	stp	q0, q1, [sp, #80]
   4d404:	blr	x8
   4d408:	cmn	w0, #0x1
   4d40c:	b.eq	4d9f0 <__gmp_doprnt@@Base+0x934>  // b.none
   4d410:	ldr	x8, [sp, #72]
   4d414:	add	w8, w0, w8
   4d418:	str	x8, [sp, #72]
   4d41c:	mov	w0, #0x10000               	// #65536
   4d420:	bl	c420 <nl_langinfo@plt>
   4d424:	ldursw	x8, [x29, #-24]
   4d428:	mov	x3, x0
   4d42c:	tbz	w8, #31, 4d494 <__gmp_doprnt@@Base+0x3d8>
   4d430:	add	w9, w8, #0x8
   4d434:	cmn	w8, #0x8
   4d438:	stur	w9, [x29, #-24]
   4d43c:	b.gt	4d494 <__gmp_doprnt@@Base+0x3d8>
   4d440:	ldur	x9, [x29, #-40]
   4d444:	add	x8, x9, x8
   4d448:	b	4d4a0 <__gmp_doprnt@@Base+0x3e4>
   4d44c:	ldur	w8, [x29, #-20]
   4d450:	tbz	w8, #31, 4d464 <__gmp_doprnt@@Base+0x3a8>
   4d454:	add	w9, w8, #0x10
   4d458:	cmn	w8, #0xf
   4d45c:	stur	w9, [x29, #-20]
   4d460:	b.lt	4d878 <__gmp_doprnt@@Base+0x7bc>  // b.tstop
   4d464:	ldur	x8, [x29, #-48]
   4d468:	add	x8, x8, #0xf
   4d46c:	and	x8, x8, #0xfffffffffffffff0
   4d470:	add	x8, x8, #0x10
   4d474:	b	4d62c <__gmp_doprnt@@Base+0x570>
   4d478:	ldur	w8, [x29, #-20]
   4d47c:	tbz	w8, #31, 4d624 <__gmp_doprnt@@Base+0x568>
   4d480:	add	w9, w8, #0x10
   4d484:	cmn	w8, #0xf
   4d488:	stur	w9, [x29, #-20]
   4d48c:	b.ge	4d624 <__gmp_doprnt@@Base+0x568>  // b.tcont
   4d490:	b	4d878 <__gmp_doprnt@@Base+0x7bc>
   4d494:	ldur	x8, [x29, #-48]
   4d498:	add	x9, x8, #0x8
   4d49c:	stur	x9, [x29, #-48]
   4d4a0:	ldr	x4, [x8]
   4d4a4:	ldp	x1, x0, [sp, #24]
   4d4a8:	add	x2, sp, #0x88
   4d4ac:	bl	d250 <__gmp_doprnt_mpf2@plt>
   4d4b0:	cmn	w0, #0x1
   4d4b4:	b.eq	4d9f0 <__gmp_doprnt@@Base+0x934>  // b.none
   4d4b8:	ldr	x8, [sp, #72]
   4d4bc:	ldp	q0, q1, [x29, #-48]
   4d4c0:	add	w8, w0, w8
   4d4c4:	b	4d86c <__gmp_doprnt@@Base+0x7b0>
   4d4c8:	ldr	x1, [sp, #40]
   4d4cc:	cmp	x26, x1
   4d4d0:	b.eq	4d508 <__gmp_doprnt@@Base+0x44c>  // b.none
   4d4d4:	strb	wzr, [x26]
   4d4d8:	ldp	x0, x8, [sp, #24]
   4d4dc:	ldp	q0, q1, [x29, #-112]
   4d4e0:	add	x2, sp, #0x50
   4d4e4:	ldr	x8, [x8]
   4d4e8:	stp	q0, q1, [sp, #80]
   4d4ec:	blr	x8
   4d4f0:	cmn	w0, #0x1
   4d4f4:	csel	w8, wzr, w0, eq  // eq = none
   4d4f8:	b.eq	4d9f0 <__gmp_doprnt@@Base+0x934>  // b.none
   4d4fc:	ldr	x9, [sp, #72]
   4d500:	add	w9, w8, w9
   4d504:	str	x9, [sp, #72]
   4d508:	ldur	w9, [x29, #-24]
   4d50c:	mov	w8, w9
   4d510:	tbz	w9, #31, 4d6a8 <__gmp_doprnt@@Base+0x5ec>
   4d514:	add	w8, w9, #0x8
   4d518:	cmn	w9, #0x8
   4d51c:	stur	w8, [x29, #-24]
   4d520:	b.gt	4d6a8 <__gmp_doprnt@@Base+0x5ec>
   4d524:	ldur	x10, [x29, #-40]
   4d528:	sxtw	x9, w9
   4d52c:	add	x9, x10, x9
   4d530:	b	4d6b4 <__gmp_doprnt@@Base+0x5f8>
   4d534:	mov	w8, #0x8                   	// #8
   4d538:	b	4d540 <__gmp_doprnt@@Base+0x484>
   4d53c:	mov	w8, #0x10                  	// #16
   4d540:	str	w8, [sp, #136]
   4d544:	cbnz	w20, 4d550 <__gmp_doprnt@@Base+0x494>
   4d548:	mov	w8, #0xffffffff            	// #-1
   4d54c:	str	w8, [sp, #164]
   4d550:	and	w8, w22, #0xff
   4d554:	cmp	w8, #0x69
   4d558:	b.le	4d57c <__gmp_doprnt@@Base+0x4c0>
   4d55c:	cmp	w8, #0x70
   4d560:	b.le	4d600 <__gmp_doprnt@@Base+0x544>
   4d564:	cmp	w8, #0x71
   4d568:	b.eq	4d60c <__gmp_doprnt@@Base+0x550>  // b.none
   4d56c:	cmp	w8, #0x74
   4d570:	b.eq	4d60c <__gmp_doprnt@@Base+0x550>  // b.none
   4d574:	cmp	w8, #0x7a
   4d578:	b	4d60c <__gmp_doprnt@@Base+0x550>
   4d57c:	cmp	w8, #0x50
   4d580:	b.gt	4d634 <__gmp_doprnt@@Base+0x578>
   4d584:	cmp	w8, #0x4c
   4d588:	b.eq	4d60c <__gmp_doprnt@@Base+0x550>  // b.none
   4d58c:	cmp	w8, #0x4e
   4d590:	b.ne	4d60c <__gmp_doprnt@@Base+0x550>  // b.any
   4d594:	ldr	x1, [sp, #40]
   4d598:	cmp	x26, x1
   4d59c:	b.eq	4d5d4 <__gmp_doprnt@@Base+0x518>  // b.none
   4d5a0:	strb	wzr, [x26]
   4d5a4:	ldp	x0, x8, [sp, #24]
   4d5a8:	ldp	q0, q1, [x29, #-112]
   4d5ac:	add	x2, sp, #0x50
   4d5b0:	ldr	x8, [x8]
   4d5b4:	stp	q0, q1, [sp, #80]
   4d5b8:	blr	x8
   4d5bc:	cmn	w0, #0x1
   4d5c0:	csel	w8, wzr, w0, eq  // eq = none
   4d5c4:	b.eq	4d9f0 <__gmp_doprnt@@Base+0x934>  // b.none
   4d5c8:	ldr	x9, [sp, #72]
   4d5cc:	add	w9, w8, w9
   4d5d0:	str	x9, [sp, #72]
   4d5d4:	ldur	w9, [x29, #-24]
   4d5d8:	mov	w8, w9
   4d5dc:	tbz	w9, #31, 4d75c <__gmp_doprnt@@Base+0x6a0>
   4d5e0:	add	w8, w9, #0x8
   4d5e4:	cmn	w9, #0x8
   4d5e8:	stur	w8, [x29, #-24]
   4d5ec:	b.gt	4d75c <__gmp_doprnt@@Base+0x6a0>
   4d5f0:	ldur	x10, [x29, #-40]
   4d5f4:	sxtw	x9, w9
   4d5f8:	add	x9, x10, x9
   4d5fc:	b	4d768 <__gmp_doprnt@@Base+0x6ac>
   4d600:	cmp	w8, #0x6a
   4d604:	b.eq	4d60c <__gmp_doprnt@@Base+0x550>  // b.none
   4d608:	cmp	w8, #0x6c
   4d60c:	ldur	w8, [x29, #-24]
   4d610:	tbz	w8, #31, 4d624 <__gmp_doprnt@@Base+0x568>
   4d614:	add	w9, w8, #0x8
   4d618:	cmn	w8, #0x7
   4d61c:	stur	w9, [x29, #-24]
   4d620:	b.lt	4d878 <__gmp_doprnt@@Base+0x7bc>  // b.tstop
   4d624:	ldur	x8, [x29, #-48]
   4d628:	add	x8, x8, #0x8
   4d62c:	stur	x8, [x29, #-48]
   4d630:	b	4d878 <__gmp_doprnt@@Base+0x7bc>
   4d634:	cmp	w8, #0x51
   4d638:	b.eq	4d6f8 <__gmp_doprnt@@Base+0x63c>  // b.none
   4d63c:	cmp	w8, #0x5a
   4d640:	b.ne	4d60c <__gmp_doprnt@@Base+0x550>  // b.any
   4d644:	ldr	x1, [sp, #40]
   4d648:	cmp	x26, x1
   4d64c:	b.eq	4d680 <__gmp_doprnt@@Base+0x5c4>  // b.none
   4d650:	strb	wzr, [x26]
   4d654:	ldp	x0, x8, [sp, #24]
   4d658:	ldp	q0, q1, [x29, #-112]
   4d65c:	add	x2, sp, #0x50
   4d660:	ldr	x8, [x8]
   4d664:	stp	q0, q1, [sp, #80]
   4d668:	blr	x8
   4d66c:	cmn	w0, #0x1
   4d670:	b.eq	4d9f0 <__gmp_doprnt@@Base+0x934>  // b.none
   4d674:	ldr	x8, [sp, #72]
   4d678:	add	w8, w0, w8
   4d67c:	str	x8, [sp, #72]
   4d680:	ldursw	x8, [x29, #-24]
   4d684:	ldr	w1, [sp, #136]
   4d688:	tbz	w8, #31, 4d790 <__gmp_doprnt@@Base+0x6d4>
   4d68c:	add	w9, w8, #0x8
   4d690:	cmn	w8, #0x8
   4d694:	stur	w9, [x29, #-24]
   4d698:	b.gt	4d790 <__gmp_doprnt@@Base+0x6d4>
   4d69c:	ldur	x9, [x29, #-40]
   4d6a0:	add	x8, x9, x8
   4d6a4:	b	4d79c <__gmp_doprnt@@Base+0x6e0>
   4d6a8:	ldur	x9, [x29, #-48]
   4d6ac:	add	x10, x9, #0x8
   4d6b0:	stur	x10, [x29, #-48]
   4d6b4:	ldr	x0, [x9]
   4d6b8:	and	w9, w22, #0xff
   4d6bc:	cmp	w9, #0x67
   4d6c0:	b.gt	4d890 <__gmp_doprnt@@Base+0x7d4>
   4d6c4:	sub	w10, w9, #0x46
   4d6c8:	cmp	w10, #0xb
   4d6cc:	b.hi	4d8c0 <__gmp_doprnt@@Base+0x804>  // b.pmore
   4d6d0:	adrp	x9, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4d6d4:	add	x9, x9, #0x656
   4d6d8:	adr	x11, 4d6e8 <__gmp_doprnt@@Base+0x62c>
   4d6dc:	ldrb	w12, [x9, x10]
   4d6e0:	add	x11, x11, x12, lsl #2
   4d6e4:	br	x11
   4d6e8:	ldr	x8, [sp, #72]
   4d6ec:	sxtw	x1, w8
   4d6f0:	bl	c640 <__gmpf_set_si@plt>
   4d6f4:	b	4d8f8 <__gmp_doprnt@@Base+0x83c>
   4d6f8:	ldr	x1, [sp, #40]
   4d6fc:	cmp	x26, x1
   4d700:	b.eq	4d734 <__gmp_doprnt@@Base+0x678>  // b.none
   4d704:	strb	wzr, [x26]
   4d708:	ldp	x0, x8, [sp, #24]
   4d70c:	ldp	q0, q1, [x29, #-112]
   4d710:	add	x2, sp, #0x50
   4d714:	ldr	x8, [x8]
   4d718:	stp	q0, q1, [sp, #80]
   4d71c:	blr	x8
   4d720:	cmn	w0, #0x1
   4d724:	b.eq	4d9f0 <__gmp_doprnt@@Base+0x934>  // b.none
   4d728:	ldr	x8, [sp, #72]
   4d72c:	add	w8, w0, w8
   4d730:	str	x8, [sp, #72]
   4d734:	ldursw	x8, [x29, #-24]
   4d738:	ldr	w1, [sp, #136]
   4d73c:	tbz	w8, #31, 4d7a4 <__gmp_doprnt@@Base+0x6e8>
   4d740:	add	w9, w8, #0x8
   4d744:	cmn	w8, #0x8
   4d748:	stur	w9, [x29, #-24]
   4d74c:	b.gt	4d7a4 <__gmp_doprnt@@Base+0x6e8>
   4d750:	ldur	x9, [x29, #-40]
   4d754:	add	x8, x9, x8
   4d758:	b	4d7b0 <__gmp_doprnt@@Base+0x6f4>
   4d75c:	ldur	x9, [x29, #-48]
   4d760:	add	x10, x9, #0x8
   4d764:	stur	x10, [x29, #-48]
   4d768:	ldr	x9, [x9]
   4d76c:	str	x9, [sp, #128]
   4d770:	tbz	w8, #31, 4d7c0 <__gmp_doprnt@@Base+0x704>
   4d774:	add	w10, w8, #0x8
   4d778:	cmn	w8, #0x8
   4d77c:	stur	w10, [x29, #-24]
   4d780:	b.gt	4d7c0 <__gmp_doprnt@@Base+0x704>
   4d784:	ldur	x10, [x29, #-40]
   4d788:	add	x8, x10, w8, sxtw
   4d78c:	b	4d7cc <__gmp_doprnt@@Base+0x710>
   4d790:	ldur	x8, [x29, #-48]
   4d794:	add	x9, x8, #0x8
   4d798:	stur	x9, [x29, #-48]
   4d79c:	ldr	x2, [x8]
   4d7a0:	b	4d818 <__gmp_doprnt@@Base+0x75c>
   4d7a4:	ldur	x8, [x29, #-48]
   4d7a8:	add	x9, x8, #0x8
   4d7ac:	stur	x9, [x29, #-48]
   4d7b0:	ldr	x2, [x8]
   4d7b4:	mov	x0, xzr
   4d7b8:	bl	c140 <__gmpq_get_str@plt>
   4d7bc:	b	4d820 <__gmp_doprnt@@Base+0x764>
   4d7c0:	ldur	x8, [x29, #-48]
   4d7c4:	add	x10, x8, #0x8
   4d7c8:	stur	x10, [x29, #-48]
   4d7cc:	ldr	x10, [x8]
   4d7d0:	mov	x11, #0xffffffff00000000    	// #-4294967296
   4d7d4:	lsl	x8, x10, #32
   4d7d8:	sxtw	x10, w10
   4d7dc:	cmp	x8, x11
   4d7e0:	cneg	x10, x10, le
   4d7e4:	sub	x11, x9, #0x8
   4d7e8:	mov	x9, x10
   4d7ec:	subs	x10, x10, #0x1
   4d7f0:	b.lt	4d7fc <__gmp_doprnt@@Base+0x740>  // b.tstop
   4d7f4:	ldr	x12, [x11, x9, lsl #3]
   4d7f8:	cbz	x12, 4d7e8 <__gmp_doprnt@@Base+0x72c>
   4d7fc:	mov	x11, #0xffffffff00000000    	// #-4294967296
   4d800:	ldr	w1, [sp, #136]
   4d804:	neg	w10, w9
   4d808:	cmp	x8, x11
   4d80c:	csel	x8, x9, x10, gt
   4d810:	str	w8, [sp, #124]
   4d814:	add	x2, sp, #0x78
   4d818:	mov	x0, xzr
   4d81c:	bl	c3c0 <__gmpz_get_str@plt>
   4d820:	mov	x19, x0
   4d824:	ldp	x1, x0, [sp, #24]
   4d828:	add	x2, sp, #0x88
   4d82c:	mov	x3, x19
   4d830:	bl	cd30 <__gmp_doprnt_integer@plt>
   4d834:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4d838:	ldr	x8, [x8, #4016]
   4d83c:	mov	w26, w0
   4d840:	mov	x0, x19
   4d844:	ldr	x20, [x8]
   4d848:	bl	bf70 <strlen@plt>
   4d84c:	add	x1, x0, #0x1
   4d850:	mov	x0, x19
   4d854:	blr	x20
   4d858:	cmn	w26, #0x1
   4d85c:	b.eq	4d9f0 <__gmp_doprnt@@Base+0x934>  // b.none
   4d860:	ldr	x8, [sp, #72]
   4d864:	ldp	q0, q1, [x29, #-48]
   4d868:	add	w8, w26, w8
   4d86c:	str	x8, [sp, #72]
   4d870:	stp	q0, q1, [x29, #-112]
   4d874:	str	x25, [sp, #40]
   4d878:	mov	w1, #0x25                  	// #37
   4d87c:	mov	x0, x25
   4d880:	bl	cdc0 <strchr@plt>
   4d884:	mov	x26, x0
   4d888:	cbnz	x0, 4d178 <__gmp_doprnt@@Base+0xbc>
   4d88c:	b	4d99c <__gmp_doprnt@@Base+0x8e0>
   4d890:	sub	w8, w9, #0x68
   4d894:	cmp	w8, #0x9
   4d898:	b.hi	4d8dc <__gmp_doprnt@@Base+0x820>  // b.pmore
   4d89c:	adrp	x9, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4d8a0:	add	x9, x9, #0x662
   4d8a4:	adr	x10, 4d8b4 <__gmp_doprnt@@Base+0x7f8>
   4d8a8:	ldrb	w11, [x9, x8]
   4d8ac:	add	x10, x10, x11, lsl #2
   4d8b0:	br	x10
   4d8b4:	ldr	x8, [sp, #72]
   4d8b8:	strh	w8, [x0]
   4d8bc:	b	4d8f8 <__gmp_doprnt@@Base+0x83c>
   4d8c0:	cbz	w9, 4d940 <__gmp_doprnt@@Base+0x884>
   4d8c4:	cmp	w9, #0x5a
   4d8c8:	b.ne	4d8f8 <__gmp_doprnt@@Base+0x83c>  // b.any
   4d8cc:	ldr	x8, [sp, #72]
   4d8d0:	sxtw	x1, w8
   4d8d4:	bl	d290 <__gmpz_set_si@plt>
   4d8d8:	b	4d8f8 <__gmp_doprnt@@Base+0x83c>
   4d8dc:	cmp	w9, #0x74
   4d8e0:	b.eq	4d8ec <__gmp_doprnt@@Base+0x830>  // b.none
   4d8e4:	cmp	w9, #0x7a
   4d8e8:	b.ne	4d8f8 <__gmp_doprnt@@Base+0x83c>  // b.any
   4d8ec:	ldr	x8, [sp, #72]
   4d8f0:	sxtw	x8, w8
   4d8f4:	str	x8, [x0]
   4d8f8:	ldp	q0, q1, [x29, #-48]
   4d8fc:	b	4d870 <__gmp_doprnt@@Base+0x7b4>
   4d900:	ldr	x8, [sp, #72]
   4d904:	strb	w8, [x0]
   4d908:	b	4d8f8 <__gmp_doprnt@@Base+0x83c>
   4d90c:	tbz	w8, #31, 4d94c <__gmp_doprnt@@Base+0x890>
   4d910:	add	w9, w8, #0x8
   4d914:	cmn	w8, #0x8
   4d918:	stur	w9, [x29, #-24]
   4d91c:	b.gt	4d94c <__gmp_doprnt@@Base+0x890>
   4d920:	ldur	x9, [x29, #-40]
   4d924:	add	x8, x9, w8, sxtw
   4d928:	b	4d958 <__gmp_doprnt@@Base+0x89c>
   4d92c:	ldr	x8, [sp, #72]
   4d930:	mov	w2, #0x1                   	// #1
   4d934:	sxtw	x1, w8
   4d938:	bl	cb90 <__gmpq_set_si@plt>
   4d93c:	b	4d8f8 <__gmp_doprnt@@Base+0x83c>
   4d940:	ldr	x8, [sp, #72]
   4d944:	str	w8, [x0]
   4d948:	b	4d8f8 <__gmp_doprnt@@Base+0x83c>
   4d94c:	ldur	x8, [x29, #-48]
   4d950:	add	x9, x8, #0x8
   4d954:	stur	x9, [x29, #-48]
   4d958:	ldr	x8, [x8]
   4d95c:	cbz	x8, 4d8f8 <__gmp_doprnt@@Base+0x83c>
   4d960:	ldr	x9, [sp, #72]
   4d964:	cmp	x8, #0x0
   4d968:	cneg	x8, x8, mi  // mi = first
   4d96c:	cmp	x8, #0x1
   4d970:	sxtw	x9, w9
   4d974:	str	x9, [x0]
   4d978:	b.eq	4d8f8 <__gmp_doprnt@@Base+0x83c>  // b.none
   4d97c:	lsl	x8, x8, #3
   4d980:	add	x0, x0, #0x8
   4d984:	sub	x2, x8, #0x8
   4d988:	mov	w1, wzr
   4d98c:	bl	c610 <memset@plt>
   4d990:	b	4d8f8 <__gmp_doprnt@@Base+0x83c>
   4d994:	str	xzr, [sp, #72]
   4d998:	str	x20, [sp, #40]
   4d99c:	ldr	x1, [sp, #40]
   4d9a0:	ldrb	w8, [x1]
   4d9a4:	cbz	w8, 4d9d4 <__gmp_doprnt@@Base+0x918>
   4d9a8:	ldp	x0, x8, [sp, #24]
   4d9ac:	ldp	q0, q1, [x29, #-112]
   4d9b0:	add	x2, sp, #0x50
   4d9b4:	ldr	x8, [x8]
   4d9b8:	stp	q0, q1, [sp, #80]
   4d9bc:	blr	x8
   4d9c0:	cmn	w0, #0x1
   4d9c4:	b.eq	4d9f0 <__gmp_doprnt@@Base+0x934>  // b.none
   4d9c8:	ldr	x8, [sp, #72]
   4d9cc:	add	w8, w0, w8
   4d9d0:	str	x8, [sp, #72]
   4d9d4:	ldr	x8, [sp, #32]
   4d9d8:	ldr	x8, [x8, #24]
   4d9dc:	cbz	x8, 4d9f8 <__gmp_doprnt@@Base+0x93c>
   4d9e0:	ldr	x0, [sp, #24]
   4d9e4:	blr	x8
   4d9e8:	cmn	w0, #0x1
   4d9ec:	b.ne	4d9f8 <__gmp_doprnt@@Base+0x93c>  // b.any
   4d9f0:	mov	w8, #0xffffffff            	// #-1
   4d9f4:	str	x8, [sp, #72]
   4d9f8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4d9fc:	ldr	x8, [x8, #4016]
   4da00:	ldp	x0, x1, [sp, #8]
   4da04:	ldr	x8, [x8]
   4da08:	blr	x8
   4da0c:	ldp	x20, x19, [sp, #400]
   4da10:	ldp	x22, x21, [sp, #384]
   4da14:	ldp	x24, x23, [sp, #368]
   4da18:	ldp	x26, x25, [sp, #352]
   4da1c:	ldp	x28, x27, [sp, #336]
   4da20:	ldp	x29, x30, [sp, #320]
   4da24:	ldr	d8, [sp, #304]
   4da28:	ldr	x0, [sp, #72]
   4da2c:	add	sp, sp, #0x1a0
   4da30:	ret

000000000004da34 <__gmp_doprnt_mpf2@@Base>:
   4da34:	sub	sp, sp, #0x110
   4da38:	stp	x29, x30, [sp, #176]
   4da3c:	stp	x28, x27, [sp, #192]
   4da40:	stp	x26, x25, [sp, #208]
   4da44:	stp	x24, x23, [sp, #224]
   4da48:	stp	x22, x21, [sp, #240]
   4da4c:	stp	x20, x19, [sp, #256]
   4da50:	stp	x0, x1, [sp, #64]
   4da54:	ldr	w19, [x2, #28]
   4da58:	ldr	w8, [x2, #4]
   4da5c:	mov	x24, x3
   4da60:	mov	x20, x2
   4da64:	add	x29, sp, #0xb0
   4da68:	tbnz	w19, #31, 4dac0 <__gmp_doprnt_mpf2@@Base+0x8c>
   4da6c:	cmp	w8, #0x2
   4da70:	b.eq	4db04 <__gmp_doprnt_mpf2@@Base+0xd0>  // b.none
   4da74:	cmp	w8, #0x1
   4da78:	b.ne	4db0c <__gmp_doprnt_mpf2@@Base+0xd8>  // b.any
   4da7c:	ldr	w8, [x20]
   4da80:	mov	w10, #0x28                  	// #40
   4da84:	ldr	x9, [x4, #8]
   4da88:	cmp	w8, #0x0
   4da8c:	cneg	w8, w8, mi  // mi = first
   4da90:	umull	x8, w8, w10
   4da94:	adrp	x10, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4da98:	ldr	x10, [x10, #3936]
   4da9c:	ldr	w8, [x10, x8]
   4daa0:	lsr	x10, x9, #63
   4daa4:	eor	w10, w10, #0x1
   4daa8:	add	w8, w10, w8
   4daac:	madd	w8, w8, w9, w19
   4dab0:	add	w8, w8, #0x3
   4dab4:	cmp	w8, #0x1
   4dab8:	csinc	w8, w8, wzr, gt
   4dabc:	b	4db1c <__gmp_doprnt_mpf2@@Base+0xe8>
   4dac0:	cmp	w8, #0x3
   4dac4:	b.ne	4db18 <__gmp_doprnt_mpf2@@Base+0xe4>  // b.any
   4dac8:	ldr	w11, [x20]
   4dacc:	adrp	x12, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4dad0:	ldrsw	x9, [x4]
   4dad4:	ldr	x12, [x12, #3936]
   4dad8:	mov	w10, #0x28                  	// #40
   4dadc:	cmp	w11, #0x0
   4dae0:	mov	w8, wzr
   4dae4:	madd	x9, x9, x10, x12
   4dae8:	cneg	w10, w11, mi  // mi = first
   4daec:	ldr	x9, [x9, #8]
   4daf0:	sub	w10, w10, #0x1
   4daf4:	sbfiz	x10, x10, #6, #32
   4daf8:	umulh	x9, x9, x10
   4dafc:	add	w19, w9, #0x2
   4db00:	b	4db1c <__gmp_doprnt_mpf2@@Base+0xe8>
   4db04:	add	w8, w19, #0x1
   4db08:	b	4db1c <__gmp_doprnt_mpf2@@Base+0xe8>
   4db0c:	cmp	w19, #0x1
   4db10:	csinc	w8, w19, wzr, gt
   4db14:	b	4db1c <__gmp_doprnt_mpf2@@Base+0xe8>
   4db18:	mov	w8, wzr
   4db1c:	ldr	w2, [x20]
   4db20:	mov	w3, w8
   4db24:	sub	x1, x29, #0x10
   4db28:	mov	x0, xzr
   4db2c:	bl	ce40 <__gmpf_get_str@plt>
   4db30:	mov	x21, x0
   4db34:	bl	bf70 <strlen@plt>
   4db38:	mov	x10, x21
   4db3c:	ldrb	w9, [x20, #44]
   4db40:	ldrb	w11, [x10], #1
   4db44:	ldr	w8, [x20, #4]
   4db48:	stp	x0, x21, [sp, #48]
   4db4c:	cmp	w11, #0x2d
   4db50:	cset	w23, eq  // eq = none
   4db54:	csel	x10, x10, x21, eq  // eq = none
   4db58:	csel	w21, w11, w9, eq  // eq = none
   4db5c:	cmp	w8, #0x2
   4db60:	sub	w28, w0, w23
   4db64:	str	x10, [sp, #40]
   4db68:	b.eq	4db80 <__gmp_doprnt_mpf2@@Base+0x14c>  // b.none
   4db6c:	cmp	w8, #0x1
   4db70:	b.ne	4db94 <__gmp_doprnt_mpf2@@Base+0x160>  // b.any
   4db74:	tbnz	w19, #31, 4dc0c <__gmp_doprnt_mpf2@@Base+0x1d8>
   4db78:	ldur	x22, [x29, #-16]
   4db7c:	b	4dc20 <__gmp_doprnt_mpf2@@Base+0x1ec>
   4db80:	tbz	w19, #31, 4dbb0 <__gmp_doprnt_mpf2@@Base+0x17c>
   4db84:	sub	w8, w28, #0x1
   4db88:	cmp	w28, #0x0
   4db8c:	csel	w19, w8, wzr, gt
   4db90:	b	4dbb0 <__gmp_doprnt_mpf2@@Base+0x17c>
   4db94:	ldur	x22, [x29, #-16]
   4db98:	cmn	x22, #0x3
   4db9c:	b.lt	4dbb0 <__gmp_doprnt_mpf2@@Base+0x17c>  // b.tstop
   4dba0:	cmp	w19, #0x1
   4dba4:	csinc	w8, w19, wzr, gt
   4dba8:	cmp	x22, x8
   4dbac:	b.le	4dd7c <__gmp_doprnt_mpf2@@Base+0x348>
   4dbb0:	ldur	x8, [x29, #-16]
   4dbb4:	ldr	w9, [x20, #16]
   4dbb8:	cmp	w28, #0x1
   4dbbc:	csinc	w27, w28, wzr, lt  // lt = tstop
   4dbc0:	cmp	w27, #0x0
   4dbc4:	sub	x8, x8, w27, sxtw
   4dbc8:	ldr	x2, [x20, #8]
   4dbcc:	cset	w25, eq  // eq = none
   4dbd0:	cmp	w9, #0x0
   4dbd4:	lsl	x9, x8, #2
   4dbd8:	csel	x8, x8, x9, eq  // eq = none
   4dbdc:	mov	w10, #0x2d                  	// #45
   4dbe0:	mov	w9, #0x2b                  	// #43
   4dbe4:	cmp	x8, #0x0
   4dbe8:	cneg	x4, x8, mi  // mi = first
   4dbec:	csel	w3, w9, w10, ge  // ge = tcont
   4dbf0:	add	x0, sp, #0x54
   4dbf4:	mov	w1, #0x4a                  	// #74
   4dbf8:	sub	w28, w28, w27
   4dbfc:	bl	c300 <snprintf@plt>
   4dc00:	mov	w23, w0
   4dc04:	mov	w22, wzr
   4dc08:	b	4ddb4 <__gmp_doprnt_mpf2@@Base+0x380>
   4dc0c:	ldur	x22, [x29, #-16]
   4dc10:	sxtw	x8, w28
   4dc14:	sub	x8, x8, x22
   4dc18:	cmp	x8, #0x0
   4dc1c:	csel	w19, w8, wzr, gt
   4dc20:	adds	w26, w19, w22
   4dc24:	b.mi	4dd3c <__gmp_doprnt_mpf2@@Base+0x308>  // b.first
   4dc28:	cmp	w28, w26
   4dc2c:	b.le	4dd7c <__gmp_doprnt_mpf2@@Base+0x348>
   4dc30:	ldr	w8, [x20]
   4dc34:	adrp	x9, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4dc38:	adrp	x10, 50000 <__gmp_randinit_lc_2exp@@Base+0x24c>
   4dc3c:	add	x9, x9, #0x68c
   4dc40:	add	x10, x10, #0xded
   4dc44:	cmp	w8, #0x0
   4dc48:	mov	x27, x24
   4dc4c:	csel	x24, x10, x9, ge  // ge = tcont
   4dc50:	cneg	w25, w8, mi  // mi = first
   4dc54:	bl	cb00 <__ctype_b_loc@plt>
   4dc58:	ldr	x8, [sp, #40]
   4dc5c:	ldr	x9, [x0]
   4dc60:	ldrb	w8, [x8, w26, uxtw]
   4dc64:	ldrh	w10, [x9, x8, lsl #1]
   4dc68:	tbnz	w10, #11, 4dc84 <__gmp_doprnt_mpf2@@Base+0x250>
   4dc6c:	tst	w10, #0x200
   4dc70:	mov	w10, #0xffffffa9            	// #-87
   4dc74:	mov	w11, #0xffffffc9            	// #-55
   4dc78:	csel	w10, w11, w10, eq  // eq = none
   4dc7c:	add	w8, w10, w8
   4dc80:	b	4dc88 <__gmp_doprnt_mpf2@@Base+0x254>
   4dc84:	sub	w8, w8, #0x30
   4dc88:	add	w10, w25, #0x1
   4dc8c:	cmp	w8, w10, lsr #1
   4dc90:	mov	w8, w26
   4dc94:	b.ge	4dcc4 <__gmp_doprnt_mpf2@@Base+0x290>  // b.tcont
   4dc98:	ldr	x9, [sp, #40]
   4dc9c:	mov	x24, x27
   4dca0:	sub	x9, x9, #0x1
   4dca4:	subs	x10, x8, #0x1
   4dca8:	b.lt	4dd3c <__gmp_doprnt_mpf2@@Base+0x308>  // b.tstop
   4dcac:	ldrb	w8, [x9, x8]
   4dcb0:	cmp	w8, #0x30
   4dcb4:	mov	x8, x10
   4dcb8:	b.eq	4dca4 <__gmp_doprnt_mpf2@@Base+0x270>  // b.none
   4dcbc:	add	w28, w10, #0x1
   4dcc0:	b	4dd7c <__gmp_doprnt_mpf2@@Base+0x348>
   4dcc4:	ldr	x11, [sp, #40]
   4dcc8:	mov	x10, xzr
   4dccc:	mov	w13, #0xffffffc9            	// #-55
   4dcd0:	add	x12, x8, x11
   4dcd4:	mov	w11, #0xffffffa9            	// #-87
   4dcd8:	sub	x12, x12, #0x1
   4dcdc:	cmn	x8, x10
   4dce0:	b.eq	4dd4c <__gmp_doprnt_mpf2@@Base+0x318>  // b.none
   4dce4:	ldrb	w14, [x12, x10]
   4dce8:	ldrh	w15, [x9, x14, lsl #1]
   4dcec:	tbnz	w15, #11, 4dd00 <__gmp_doprnt_mpf2@@Base+0x2cc>
   4dcf0:	tst	w15, #0x200
   4dcf4:	csel	w15, w13, w11, eq  // eq = none
   4dcf8:	add	w14, w15, w14
   4dcfc:	b	4dd04 <__gmp_doprnt_mpf2@@Base+0x2d0>
   4dd00:	sub	w14, w14, #0x30
   4dd04:	sxtw	x14, w14
   4dd08:	add	x14, x14, #0x1
   4dd0c:	cmp	w14, w25
   4dd10:	sub	x10, x10, #0x1
   4dd14:	b.eq	4dcdc <__gmp_doprnt_mpf2@@Base+0x2a8>  // b.none
   4dd18:	ldr	x9, [sp, #40]
   4dd1c:	ldrb	w11, [x24, x14]
   4dd20:	add	w12, w19, w22
   4dd24:	mvn	w12, w12
   4dd28:	add	x9, x8, x9
   4dd2c:	cmp	w12, w10
   4dd30:	mov	x24, x27
   4dd34:	strb	w11, [x9, x10]
   4dd38:	b.ne	4dd70 <__gmp_doprnt_mpf2@@Base+0x33c>  // b.any
   4dd3c:	mov	w28, wzr
   4dd40:	mov	x22, xzr
   4dd44:	stur	xzr, [x29, #-16]
   4dd48:	b	4dda4 <__gmp_doprnt_mpf2@@Base+0x370>
   4dd4c:	ldr	x9, [sp, #56]
   4dd50:	mov	w8, #0x31                  	// #49
   4dd54:	mov	w28, #0x1                   	// #1
   4dd58:	mov	x24, x27
   4dd5c:	strb	w8, [x9, x23]
   4dd60:	ldur	x8, [x29, #-16]
   4dd64:	add	x22, x8, #0x1
   4dd68:	stur	x22, [x29, #-16]
   4dd6c:	b	4dd7c <__gmp_doprnt_mpf2@@Base+0x348>
   4dd70:	ldur	x22, [x29, #-16]
   4dd74:	add	x8, x8, x10
   4dd78:	add	x28, x8, #0x1
   4dd7c:	cmp	x22, #0x0
   4dd80:	b.le	4dda4 <__gmp_doprnt_mpf2@@Base+0x370>
   4dd84:	cmp	x22, w28, sxtw
   4dd88:	mov	w8, wzr
   4dd8c:	csel	w27, w28, w22, gt
   4dd90:	mov	w23, wzr
   4dd94:	sub	w25, w22, w27
   4dd98:	mov	w22, w8
   4dd9c:	sub	w28, w28, w27
   4dda0:	b	4ddb4 <__gmp_doprnt_mpf2@@Base+0x380>
   4dda4:	mov	w27, wzr
   4dda8:	mov	w23, wzr
   4ddac:	neg	w22, w22
   4ddb0:	mov	w25, #0x1                   	// #1
   4ddb4:	ldr	w8, [x20, #40]
   4ddb8:	cbz	w8, 4dde0 <__gmp_doprnt_mpf2@@Base+0x3ac>
   4ddbc:	ldr	w9, [x20, #4]
   4ddc0:	add	w10, w27, w25
   4ddc4:	add	w8, w22, w28
   4ddc8:	cmp	w9, #0x3
   4ddcc:	csneg	w9, wzr, w10, ne  // ne = any
   4ddd0:	sub	w10, w19, w8
   4ddd4:	add	w9, w10, w9
   4ddd8:	bic	w10, w9, w9, asr #31
   4dddc:	b	4dde8 <__gmp_doprnt_mpf2@@Base+0x3b4>
   4dde0:	mov	w10, wzr
   4dde4:	add	w8, w22, w28
   4dde8:	cmn	w8, w10
   4ddec:	b.ne	4ddf8 <__gmp_doprnt_mpf2@@Base+0x3c4>  // b.any
   4ddf0:	ldr	w8, [x20, #36]
   4ddf4:	cbz	w8, 4e0c4 <__gmp_doprnt_mpf2@@Base+0x690>
   4ddf8:	mov	x0, x24
   4ddfc:	mov	w19, w10
   4de00:	bl	bf70 <strlen@plt>
   4de04:	mov	w10, w19
   4de08:	ldr	w8, [x20, #32]
   4de0c:	and	w19, w21, #0xff
   4de10:	str	x24, [sp, #16]
   4de14:	cmp	w8, #0x1
   4de18:	b.eq	4de2c <__gmp_doprnt_mpf2@@Base+0x3f8>  // b.none
   4de1c:	cmp	w8, #0x3
   4de20:	b.ne	4de58 <__gmp_doprnt_mpf2@@Base+0x424>  // b.any
   4de24:	orr	w8, w27, w28
   4de28:	cbz	w8, 4de58 <__gmp_doprnt_mpf2@@Base+0x424>
   4de2c:	ldr	w8, [x20]
   4de30:	cmn	w8, #0x10
   4de34:	b.eq	4e0cc <__gmp_doprnt_mpf2@@Base+0x698>  // b.none
   4de38:	cmp	w8, #0x8
   4de3c:	b.eq	4e0dc <__gmp_doprnt_mpf2@@Base+0x6a8>  // b.none
   4de40:	cmp	w8, #0x10
   4de44:	b.ne	4de58 <__gmp_doprnt_mpf2@@Base+0x424>  // b.any
   4de48:	adrp	x26, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4de4c:	mov	w21, #0x2                   	// #2
   4de50:	add	x26, x26, #0x6b1
   4de54:	b	4de60 <__gmp_doprnt_mpf2@@Base+0x42c>
   4de58:	mov	x26, xzr
   4de5c:	mov	w21, wzr
   4de60:	cmp	w19, #0x0
   4de64:	csetm	w9, ne  // ne = any
   4de68:	sub	w9, w9, w28
   4de6c:	sub	w9, w9, w22
   4de70:	sub	w9, w9, w25
   4de74:	sub	w9, w9, w27
   4de78:	ldr	w8, [x20, #48]
   4de7c:	sub	w9, w9, w23
   4de80:	sub	w9, w9, w10
   4de84:	str	w10, [sp, #12]
   4de88:	sub	w9, w9, w0
   4de8c:	ldr	w10, [x20, #24]
   4de90:	sub	w9, w9, w21
   4de94:	add	w24, w9, w8
   4de98:	cmp	w24, #0x0
   4de9c:	str	x23, [sp]
   4dea0:	csel	w23, w10, wzr, gt
   4dea4:	str	w22, [sp, #28]
   4dea8:	cmp	w23, #0x2
   4deac:	mov	w22, wzr
   4deb0:	str	x0, [sp, #32]
   4deb4:	b.ne	4ded8 <__gmp_doprnt_mpf2@@Base+0x4a4>  // b.any
   4deb8:	ldp	x8, x0, [sp, #64]
   4debc:	ldrb	w1, [x20, #20]
   4dec0:	mov	w2, w24
   4dec4:	ldr	x8, [x8, #16]
   4dec8:	blr	x8
   4decc:	mov	w22, w0
   4ded0:	cmn	w0, #0x1
   4ded4:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4ded8:	cbz	w19, 4defc <__gmp_doprnt_mpf2@@Base+0x4c8>
   4dedc:	ldp	x8, x0, [sp, #64]
   4dee0:	mov	w2, #0x1                   	// #1
   4dee4:	mov	w1, w19
   4dee8:	ldr	x8, [x8, #16]
   4deec:	blr	x8
   4def0:	cmn	w0, #0x1
   4def4:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4def8:	add	w22, w0, w22
   4defc:	cbz	w21, 4df20 <__gmp_doprnt_mpf2@@Base+0x4ec>
   4df00:	ldp	x8, x0, [sp, #64]
   4df04:	mov	x1, x26
   4df08:	mov	x2, x21
   4df0c:	ldr	x8, [x8, #8]
   4df10:	blr	x8
   4df14:	cmn	w0, #0x1
   4df18:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4df1c:	add	w22, w0, w22
   4df20:	cmp	w23, #0x3
   4df24:	b.ne	4df48 <__gmp_doprnt_mpf2@@Base+0x514>  // b.any
   4df28:	ldp	x8, x0, [sp, #64]
   4df2c:	ldrb	w1, [x20, #20]
   4df30:	mov	w2, w24
   4df34:	ldr	x8, [x8, #16]
   4df38:	blr	x8
   4df3c:	cmn	w0, #0x1
   4df40:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4df44:	add	w22, w0, w22
   4df48:	ldp	x8, x0, [sp, #64]
   4df4c:	ldr	x1, [sp, #40]
   4df50:	sxtw	x21, w27
   4df54:	mov	x2, x21
   4df58:	ldr	x8, [x8, #8]
   4df5c:	blr	x8
   4df60:	add	w19, w0, w22
   4df64:	cmn	w0, #0x1
   4df68:	csel	w22, w22, w19, eq  // eq = none
   4df6c:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4df70:	cbz	w25, 4df94 <__gmp_doprnt_mpf2@@Base+0x560>
   4df74:	ldp	x8, x0, [sp, #64]
   4df78:	mov	w1, #0x30                  	// #48
   4df7c:	mov	w2, w25
   4df80:	ldr	x8, [x8, #16]
   4df84:	blr	x8
   4df88:	cmn	w0, #0x1
   4df8c:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4df90:	add	w19, w0, w22
   4df94:	ldr	x9, [sp, #32]
   4df98:	cbz	w9, 4dfbc <__gmp_doprnt_mpf2@@Base+0x588>
   4df9c:	ldp	x8, x0, [sp, #64]
   4dfa0:	ldr	x1, [sp, #16]
   4dfa4:	sxtw	x2, w9
   4dfa8:	ldr	x8, [x8, #8]
   4dfac:	blr	x8
   4dfb0:	cmn	w0, #0x1
   4dfb4:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4dfb8:	add	w19, w0, w19
   4dfbc:	ldr	w2, [sp, #28]
   4dfc0:	cbz	w2, 4dfe0 <__gmp_doprnt_mpf2@@Base+0x5ac>
   4dfc4:	ldp	x8, x0, [sp, #64]
   4dfc8:	mov	w1, #0x30                  	// #48
   4dfcc:	ldr	x8, [x8, #16]
   4dfd0:	blr	x8
   4dfd4:	cmn	w0, #0x1
   4dfd8:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4dfdc:	add	w19, w0, w19
   4dfe0:	cbz	w28, 4e008 <__gmp_doprnt_mpf2@@Base+0x5d4>
   4dfe4:	ldp	x8, x0, [sp, #64]
   4dfe8:	ldr	x9, [sp, #40]
   4dfec:	sxtw	x2, w28
   4dff0:	ldr	x8, [x8, #8]
   4dff4:	add	x1, x9, x21
   4dff8:	blr	x8
   4dffc:	cmn	w0, #0x1
   4e000:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4e004:	add	w19, w0, w19
   4e008:	ldr	w2, [sp, #12]
   4e00c:	cbz	w2, 4e02c <__gmp_doprnt_mpf2@@Base+0x5f8>
   4e010:	ldp	x8, x0, [sp, #64]
   4e014:	mov	w1, #0x30                  	// #48
   4e018:	ldr	x8, [x8, #16]
   4e01c:	blr	x8
   4e020:	cmn	w0, #0x1
   4e024:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4e028:	add	w19, w0, w19
   4e02c:	ldr	x9, [sp]
   4e030:	cbz	w9, 4e054 <__gmp_doprnt_mpf2@@Base+0x620>
   4e034:	ldp	x8, x0, [sp, #64]
   4e038:	sxtw	x2, w9
   4e03c:	add	x1, sp, #0x54
   4e040:	ldr	x8, [x8, #8]
   4e044:	blr	x8
   4e048:	cmn	w0, #0x1
   4e04c:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4e050:	add	w19, w0, w19
   4e054:	cmp	w23, #0x1
   4e058:	b.ne	4e084 <__gmp_doprnt_mpf2@@Base+0x650>  // b.any
   4e05c:	ldp	x8, x0, [sp, #64]
   4e060:	ldrb	w1, [x20, #20]
   4e064:	mov	w2, w24
   4e068:	ldr	x8, [x8, #16]
   4e06c:	blr	x8
   4e070:	cmn	w0, #0x1
   4e074:	b.eq	4e080 <__gmp_doprnt_mpf2@@Base+0x64c>  // b.none
   4e078:	add	w19, w0, w19
   4e07c:	b	4e084 <__gmp_doprnt_mpf2@@Base+0x650>
   4e080:	mov	w19, #0xffffffff            	// #-1
   4e084:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4e088:	ldp	x9, x0, [sp, #48]
   4e08c:	ldr	x8, [x8, #4016]
   4e090:	add	w9, w9, #0x1
   4e094:	ldr	x8, [x8]
   4e098:	sxtw	x1, w9
   4e09c:	blr	x8
   4e0a0:	mov	w0, w19
   4e0a4:	ldp	x20, x19, [sp, #256]
   4e0a8:	ldp	x22, x21, [sp, #240]
   4e0ac:	ldp	x24, x23, [sp, #224]
   4e0b0:	ldp	x26, x25, [sp, #208]
   4e0b4:	ldp	x28, x27, [sp, #192]
   4e0b8:	ldp	x29, x30, [sp, #176]
   4e0bc:	add	sp, sp, #0x110
   4e0c0:	ret
   4e0c4:	mov	x0, xzr
   4e0c8:	b	4de08 <__gmp_doprnt_mpf2@@Base+0x3d4>
   4e0cc:	adrp	x26, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4e0d0:	mov	w21, #0x2                   	// #2
   4e0d4:	add	x26, x26, #0x6b4
   4e0d8:	b	4de60 <__gmp_doprnt_mpf2@@Base+0x42c>
   4e0dc:	adrp	x26, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4e0e0:	mov	w21, #0x1                   	// #1
   4e0e4:	add	x26, x26, #0x8fa
   4e0e8:	b	4de60 <__gmp_doprnt_mpf2@@Base+0x42c>

000000000004e0ec <__gmp_doprnt_integer@@Base>:
   4e0ec:	sub	sp, sp, #0x90
   4e0f0:	stp	x29, x30, [sp, #48]
   4e0f4:	add	x29, sp, #0x30
   4e0f8:	stp	x28, x27, [sp, #64]
   4e0fc:	stp	x26, x25, [sp, #80]
   4e100:	stp	x24, x23, [sp, #96]
   4e104:	stp	x22, x21, [sp, #112]
   4e108:	stp	x20, x19, [sp, #128]
   4e10c:	stur	x1, [x29, #-8]
   4e110:	mov	x9, x3
   4e114:	ldrb	w8, [x2, #44]
   4e118:	ldrb	w10, [x9], #1
   4e11c:	mov	x20, x2
   4e120:	stur	x0, [x29, #-16]
   4e124:	cmp	w10, #0x2d
   4e128:	csel	w19, w10, w8, eq  // eq = none
   4e12c:	csel	x8, x3, x9, ne  // ne = any
   4e130:	ldrb	w8, [x8]
   4e134:	csel	x22, x9, x3, eq  // eq = none
   4e138:	tst	w19, #0xff
   4e13c:	cset	w23, ne  // ne = any
   4e140:	cmp	w8, #0x30
   4e144:	b.ne	4e154 <__gmp_doprnt_integer@@Base+0x68>  // b.any
   4e148:	ldr	w8, [x20, #28]
   4e14c:	cmp	w8, #0x0
   4e150:	cinc	x22, x22, eq  // eq = none
   4e154:	mov	x0, x22
   4e158:	bl	bf70 <strlen@plt>
   4e15c:	mov	x21, x0
   4e160:	mov	w1, #0x2f                  	// #47
   4e164:	mov	x0, x22
   4e168:	bl	cdc0 <strchr@plt>
   4e16c:	ldr	w8, [x20, #32]
   4e170:	stur	w23, [x29, #-20]
   4e174:	cmp	w8, #0x2
   4e178:	b.ne	4e188 <__gmp_doprnt_integer@@Base+0x9c>  // b.any
   4e17c:	str	xzr, [sp, #16]
   4e180:	mov	w27, wzr
   4e184:	b	4e1d4 <__gmp_doprnt_integer@@Base+0xe8>
   4e188:	ldr	w9, [x20]
   4e18c:	cmn	w9, #0x10
   4e190:	b.eq	4e1b4 <__gmp_doprnt_integer@@Base+0xc8>  // b.none
   4e194:	cmp	w9, #0x8
   4e198:	b.eq	4e1c4 <__gmp_doprnt_integer@@Base+0xd8>  // b.none
   4e19c:	cmp	w9, #0x10
   4e1a0:	b.ne	4e17c <__gmp_doprnt_integer@@Base+0x90>  // b.any
   4e1a4:	adrp	x9, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4e1a8:	mov	w27, #0x2                   	// #2
   4e1ac:	add	x9, x9, #0x6b1
   4e1b0:	b	4e1d0 <__gmp_doprnt_integer@@Base+0xe4>
   4e1b4:	adrp	x9, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4e1b8:	mov	w27, #0x2                   	// #2
   4e1bc:	add	x9, x9, #0x6b4
   4e1c0:	b	4e1d0 <__gmp_doprnt_integer@@Base+0xe4>
   4e1c4:	adrp	x9, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4e1c8:	mov	w27, #0x1                   	// #1
   4e1cc:	add	x9, x9, #0x8fa
   4e1d0:	str	x9, [sp, #16]
   4e1d4:	and	w19, w19, #0xff
   4e1d8:	cmp	w8, #0x3
   4e1dc:	str	x0, [sp, #8]
   4e1e0:	cbz	x0, 4e1f8 <__gmp_doprnt_integer@@Base+0x10c>
   4e1e4:	b.ne	4e210 <__gmp_doprnt_integer@@Base+0x124>  // b.any
   4e1e8:	ldrb	w8, [x0, #1]
   4e1ec:	cmp	w8, #0x30
   4e1f0:	csel	w28, wzr, w27, eq  // eq = none
   4e1f4:	b	4e200 <__gmp_doprnt_integer@@Base+0x114>
   4e1f8:	mov	w28, wzr
   4e1fc:	b.ne	4e214 <__gmp_doprnt_integer@@Base+0x128>  // b.any
   4e200:	ldrb	w8, [x22]
   4e204:	cmp	w8, #0x30
   4e208:	csel	w27, wzr, w27, eq  // eq = none
   4e20c:	b	4e214 <__gmp_doprnt_integer@@Base+0x128>
   4e210:	mov	w28, w27
   4e214:	ldp	w10, w9, [x20, #24]
   4e218:	cmp	w19, #0x0
   4e21c:	ldr	w8, [x20, #48]
   4e220:	cinc	w11, w21, ne  // ne = any
   4e224:	add	w11, w28, w11
   4e228:	add	w11, w11, w27
   4e22c:	sub	w23, w9, w21
   4e230:	bic	w24, w23, w23, asr #31
   4e234:	sub	w8, w8, w11
   4e238:	sub	w26, w8, w24
   4e23c:	cmp	w26, #0x0
   4e240:	str	x21, [sp]
   4e244:	csel	w21, w10, wzr, gt
   4e248:	cmp	w21, #0x2
   4e24c:	mov	w25, wzr
   4e250:	b.ne	4e274 <__gmp_doprnt_integer@@Base+0x188>  // b.any
   4e254:	ldp	x8, x0, [x29, #-16]
   4e258:	ldrb	w1, [x20, #20]
   4e25c:	mov	w2, w26
   4e260:	ldr	x8, [x8, #16]
   4e264:	blr	x8
   4e268:	mov	w25, w0
   4e26c:	cmn	w0, #0x1
   4e270:	b.eq	4e3cc <__gmp_doprnt_integer@@Base+0x2e0>  // b.none
   4e274:	cbz	w19, 4e298 <__gmp_doprnt_integer@@Base+0x1ac>
   4e278:	ldp	x8, x0, [x29, #-16]
   4e27c:	ldur	w2, [x29, #-20]
   4e280:	mov	w1, w19
   4e284:	ldr	x8, [x8, #16]
   4e288:	blr	x8
   4e28c:	cmn	w0, #0x1
   4e290:	b.eq	4e3cc <__gmp_doprnt_integer@@Base+0x2e0>  // b.none
   4e294:	add	w25, w0, w25
   4e298:	cbz	w27, 4e2bc <__gmp_doprnt_integer@@Base+0x1d0>
   4e29c:	ldp	x8, x0, [x29, #-16]
   4e2a0:	ldr	x1, [sp, #16]
   4e2a4:	mov	x2, x27
   4e2a8:	ldr	x8, [x8, #8]
   4e2ac:	blr	x8
   4e2b0:	cmn	w0, #0x1
   4e2b4:	b.eq	4e3cc <__gmp_doprnt_integer@@Base+0x2e0>  // b.none
   4e2b8:	add	w25, w0, w25
   4e2bc:	cmp	w23, #0x1
   4e2c0:	b.lt	4e2e4 <__gmp_doprnt_integer@@Base+0x1f8>  // b.tstop
   4e2c4:	ldp	x8, x0, [x29, #-16]
   4e2c8:	mov	w1, #0x30                  	// #48
   4e2cc:	mov	w2, w24
   4e2d0:	ldr	x8, [x8, #16]
   4e2d4:	blr	x8
   4e2d8:	cmn	w0, #0x1
   4e2dc:	b.eq	4e3cc <__gmp_doprnt_integer@@Base+0x2e0>  // b.none
   4e2e0:	add	w25, w0, w25
   4e2e4:	cmp	w21, #0x3
   4e2e8:	b.ne	4e30c <__gmp_doprnt_integer@@Base+0x220>  // b.any
   4e2ec:	ldp	x8, x0, [x29, #-16]
   4e2f0:	ldrb	w1, [x20, #20]
   4e2f4:	mov	w2, w26
   4e2f8:	ldr	x8, [x8, #16]
   4e2fc:	blr	x8
   4e300:	cmn	w0, #0x1
   4e304:	b.eq	4e3cc <__gmp_doprnt_integer@@Base+0x2e0>  // b.none
   4e308:	add	w25, w0, w25
   4e30c:	cbz	w28, 4e374 <__gmp_doprnt_integer@@Base+0x288>
   4e310:	ldp	x8, x0, [x29, #-16]
   4e314:	ldr	x9, [sp, #8]
   4e318:	mov	x1, x22
   4e31c:	ldr	x8, [x8, #8]
   4e320:	sub	x9, x9, x22
   4e324:	add	x23, x9, #0x1
   4e328:	sxtw	x19, w23
   4e32c:	mov	x2, x19
   4e330:	blr	x8
   4e334:	cmn	w0, #0x1
   4e338:	b.eq	4e3cc <__gmp_doprnt_integer@@Base+0x2e0>  // b.none
   4e33c:	mov	w24, w0
   4e340:	ldp	x8, x0, [x29, #-16]
   4e344:	ldr	x1, [sp, #16]
   4e348:	mov	x2, x28
   4e34c:	ldr	x8, [x8, #8]
   4e350:	blr	x8
   4e354:	cmn	w0, #0x1
   4e358:	b.eq	4e3cc <__gmp_doprnt_integer@@Base+0x2e0>  // b.none
   4e35c:	ldr	x9, [sp]
   4e360:	add	w8, w24, w25
   4e364:	add	x22, x22, x19
   4e368:	add	w25, w8, w0
   4e36c:	sub	x9, x9, x23
   4e370:	b	4e378 <__gmp_doprnt_integer@@Base+0x28c>
   4e374:	ldr	x9, [sp]
   4e378:	ldp	x8, x0, [x29, #-16]
   4e37c:	sxtw	x2, w9
   4e380:	mov	x1, x22
   4e384:	ldr	x8, [x8, #8]
   4e388:	blr	x8
   4e38c:	mov	w8, w0
   4e390:	add	w0, w0, w25
   4e394:	cmn	w8, #0x1
   4e398:	csel	w19, w25, w0, eq  // eq = none
   4e39c:	b.eq	4e3cc <__gmp_doprnt_integer@@Base+0x2e0>  // b.none
   4e3a0:	cmp	w21, #0x1
   4e3a4:	b.ne	4e3d0 <__gmp_doprnt_integer@@Base+0x2e4>  // b.any
   4e3a8:	ldp	x8, x0, [x29, #-16]
   4e3ac:	ldrb	w1, [x20, #20]
   4e3b0:	mov	w2, w26
   4e3b4:	ldr	x8, [x8, #16]
   4e3b8:	blr	x8
   4e3bc:	cmn	w0, #0x1
   4e3c0:	b.eq	4e3cc <__gmp_doprnt_integer@@Base+0x2e0>  // b.none
   4e3c4:	add	w0, w0, w19
   4e3c8:	b	4e3d0 <__gmp_doprnt_integer@@Base+0x2e4>
   4e3cc:	mov	w0, #0xffffffff            	// #-1
   4e3d0:	ldp	x20, x19, [sp, #128]
   4e3d4:	ldp	x22, x21, [sp, #112]
   4e3d8:	ldp	x24, x23, [sp, #96]
   4e3dc:	ldp	x26, x25, [sp, #80]
   4e3e0:	ldp	x28, x27, [sp, #64]
   4e3e4:	ldp	x29, x30, [sp, #48]
   4e3e8:	add	sp, sp, #0x90
   4e3ec:	ret

000000000004e3f0 <__gmp_fprintf@@Base>:
   4e3f0:	sub	sp, sp, #0x100
   4e3f4:	stp	x29, x30, [sp, #240]
   4e3f8:	add	x29, sp, #0xf0
   4e3fc:	mov	x9, #0xffffffffffffffd0    	// #-48
   4e400:	mov	x10, sp
   4e404:	sub	x11, x29, #0x70
   4e408:	movk	x9, #0xff80, lsl #32
   4e40c:	add	x12, x29, #0x10
   4e410:	add	x10, x10, #0x80
   4e414:	add	x11, x11, #0x30
   4e418:	stp	x10, x9, [x29, #-16]
   4e41c:	stp	x12, x11, [x29, #-32]
   4e420:	stp	x2, x3, [x29, #-112]
   4e424:	stp	x4, x5, [x29, #-96]
   4e428:	stp	x6, x7, [x29, #-80]
   4e42c:	stp	q1, q2, [sp, #16]
   4e430:	str	q0, [sp]
   4e434:	ldp	q0, q1, [x29, #-32]
   4e438:	mov	x8, x1
   4e43c:	mov	x1, x0
   4e440:	stp	q3, q4, [sp, #48]
   4e444:	stp	q5, q6, [sp, #80]
   4e448:	str	q7, [sp, #112]
   4e44c:	stp	q0, q1, [x29, #-64]
   4e450:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4e454:	ldr	x0, [x0, #3816]
   4e458:	sub	x3, x29, #0x40
   4e45c:	mov	x2, x8
   4e460:	bl	d050 <__gmp_doprnt@plt>
   4e464:	ldp	x29, x30, [sp, #240]
   4e468:	add	sp, sp, #0x100
   4e46c:	ret

000000000004e470 <__gmp_obstack_printf@@Base>:
   4e470:	sub	sp, sp, #0x100
   4e474:	stp	x29, x30, [sp, #240]
   4e478:	add	x29, sp, #0xf0
   4e47c:	mov	x9, #0xffffffffffffffd0    	// #-48
   4e480:	mov	x10, sp
   4e484:	sub	x11, x29, #0x70
   4e488:	movk	x9, #0xff80, lsl #32
   4e48c:	add	x12, x29, #0x10
   4e490:	add	x10, x10, #0x80
   4e494:	add	x11, x11, #0x30
   4e498:	stp	x10, x9, [x29, #-16]
   4e49c:	stp	x12, x11, [x29, #-32]
   4e4a0:	stp	x2, x3, [x29, #-112]
   4e4a4:	stp	x4, x5, [x29, #-96]
   4e4a8:	stp	x6, x7, [x29, #-80]
   4e4ac:	stp	q1, q2, [sp, #16]
   4e4b0:	str	q0, [sp]
   4e4b4:	ldp	q0, q1, [x29, #-32]
   4e4b8:	mov	x8, x1
   4e4bc:	mov	x1, x0
   4e4c0:	stp	q3, q4, [sp, #48]
   4e4c4:	stp	q5, q6, [sp, #80]
   4e4c8:	str	q7, [sp, #112]
   4e4cc:	stp	q0, q1, [x29, #-64]
   4e4d0:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4e4d4:	ldr	x0, [x0, #4048]
   4e4d8:	sub	x3, x29, #0x40
   4e4dc:	mov	x2, x8
   4e4e0:	bl	d050 <__gmp_doprnt@plt>
   4e4e4:	ldp	x29, x30, [sp, #240]
   4e4e8:	add	sp, sp, #0x100
   4e4ec:	ret

000000000004e4f0 <__gmp_obstack_vprintf@@Base>:
   4e4f0:	sub	sp, sp, #0x30
   4e4f4:	stp	x29, x30, [sp, #32]
   4e4f8:	ldp	q1, q0, [x2]
   4e4fc:	mov	x8, x1
   4e500:	mov	x1, x0
   4e504:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4e508:	stp	q1, q0, [sp]
   4e50c:	ldr	x0, [x0, #4048]
   4e510:	mov	x3, sp
   4e514:	mov	x2, x8
   4e518:	add	x29, sp, #0x20
   4e51c:	bl	d050 <__gmp_doprnt@plt>
   4e520:	ldp	x29, x30, [sp, #32]
   4e524:	add	sp, sp, #0x30
   4e528:	ret
   4e52c:	stp	x29, x30, [sp, #-48]!
   4e530:	stp	x22, x21, [sp, #16]
   4e534:	stp	x20, x19, [sp, #32]
   4e538:	mov	x20, x0
   4e53c:	ldr	x0, [x0, #24]
   4e540:	ldr	x8, [x20, #32]
   4e544:	mov	x19, x2
   4e548:	mov	x21, x1
   4e54c:	add	x9, x0, w19, sxtw
   4e550:	cmp	x9, x8
   4e554:	sxtw	x22, w2
   4e558:	mov	x29, sp
   4e55c:	b.ls	4e570 <__gmp_obstack_vprintf@@Base+0x80>  // b.plast
   4e560:	mov	x0, x20
   4e564:	mov	w1, w19
   4e568:	bl	d060 <_obstack_newchunk@plt>
   4e56c:	ldr	x0, [x20, #24]
   4e570:	mov	x1, x21
   4e574:	mov	x2, x22
   4e578:	bl	bee0 <memcpy@plt>
   4e57c:	ldr	x8, [x20, #24]
   4e580:	mov	w0, w19
   4e584:	add	x8, x8, x22
   4e588:	str	x8, [x20, #24]
   4e58c:	ldp	x20, x19, [sp, #32]
   4e590:	ldp	x22, x21, [sp, #16]
   4e594:	ldp	x29, x30, [sp], #48
   4e598:	ret
   4e59c:	stp	x29, x30, [sp, #-48]!
   4e5a0:	stp	x22, x21, [sp, #16]
   4e5a4:	stp	x20, x19, [sp, #32]
   4e5a8:	mov	x21, x0
   4e5ac:	ldp	x0, x8, [x0, #24]
   4e5b0:	mov	w19, w2
   4e5b4:	mov	w20, w1
   4e5b8:	sxtw	x22, w19
   4e5bc:	sub	x8, x8, x0
   4e5c0:	cmp	x8, w2, sxtw
   4e5c4:	mov	x29, sp
   4e5c8:	b.ge	4e5dc <__gmp_obstack_vprintf@@Base+0xec>  // b.tcont
   4e5cc:	mov	x0, x21
   4e5d0:	mov	w1, w19
   4e5d4:	bl	d060 <_obstack_newchunk@plt>
   4e5d8:	ldr	x0, [x21, #24]
   4e5dc:	add	x8, x0, x22
   4e5e0:	mov	w1, w20
   4e5e4:	mov	x2, x22
   4e5e8:	str	x8, [x21, #24]
   4e5ec:	bl	c610 <memset@plt>
   4e5f0:	mov	w0, w19
   4e5f4:	ldp	x20, x19, [sp, #32]
   4e5f8:	ldp	x22, x21, [sp, #16]
   4e5fc:	ldp	x29, x30, [sp], #48
   4e600:	ret

000000000004e604 <__gmp_printf@@Base>:
   4e604:	sub	sp, sp, #0x120
   4e608:	stp	x29, x30, [sp, #256]
   4e60c:	add	x29, sp, #0x100
   4e610:	mov	x9, #0xffffffffffffffc8    	// #-56
   4e614:	mov	x10, sp
   4e618:	sub	x11, x29, #0x78
   4e61c:	str	x28, [sp, #272]
   4e620:	stp	x1, x2, [x29, #-120]
   4e624:	stp	x3, x4, [x29, #-104]
   4e628:	stp	x5, x6, [x29, #-88]
   4e62c:	stur	x7, [x29, #-72]
   4e630:	stp	q0, q1, [sp]
   4e634:	stp	q2, q3, [sp, #32]
   4e638:	stp	q4, q5, [sp, #64]
   4e63c:	movk	x9, #0xff80, lsl #32
   4e640:	add	x12, x29, #0x20
   4e644:	adrp	x13, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4e648:	add	x10, x10, #0x80
   4e64c:	add	x11, x11, #0x38
   4e650:	ldr	x13, [x13, #3856]
   4e654:	stp	x10, x9, [x29, #-16]
   4e658:	stp	x12, x11, [x29, #-32]
   4e65c:	ldp	q0, q1, [x29, #-32]
   4e660:	mov	x8, x0
   4e664:	stp	q6, q7, [sp, #96]
   4e668:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4e66c:	stp	q0, q1, [x29, #-64]
   4e670:	ldr	x1, [x13]
   4e674:	ldr	x0, [x0, #3816]
   4e678:	sub	x3, x29, #0x40
   4e67c:	mov	x2, x8
   4e680:	bl	d050 <__gmp_doprnt@plt>
   4e684:	ldr	x28, [sp, #272]
   4e688:	ldp	x29, x30, [sp, #256]
   4e68c:	add	sp, sp, #0x120
   4e690:	ret
   4e694:	stp	x29, x30, [sp, #-16]!
   4e698:	mov	x8, x1
   4e69c:	mov	x3, x0
   4e6a0:	mov	w1, #0x1                   	// #1
   4e6a4:	mov	x0, x8
   4e6a8:	mov	x29, sp
   4e6ac:	bl	ce50 <fwrite@plt>
   4e6b0:	ldp	x29, x30, [sp], #16
   4e6b4:	ret
   4e6b8:	sub	sp, sp, #0x140
   4e6bc:	stp	x20, x19, [sp, #304]
   4e6c0:	mov	w19, w2
   4e6c4:	sxtw	x8, w19
   4e6c8:	stp	x22, x21, [sp, #288]
   4e6cc:	cmp	x8, #0x100
   4e6d0:	mov	w21, #0x100                 	// #256
   4e6d4:	mov	x20, x0
   4e6d8:	csel	x2, x8, x21, cc  // cc = lo, ul, last
   4e6dc:	mov	x0, sp
   4e6e0:	stp	x29, x30, [sp, #256]
   4e6e4:	stp	x28, x23, [sp, #272]
   4e6e8:	add	x29, sp, #0x100
   4e6ec:	bl	c610 <memset@plt>
   4e6f0:	cmp	w19, #0x1
   4e6f4:	b.lt	4e730 <__gmp_printf@@Base+0x12c>  // b.tstop
   4e6f8:	mov	w22, w19
   4e6fc:	subs	w23, w22, #0x100
   4e700:	csel	w2, w22, w21, cc  // cc = lo, ul, last
   4e704:	mov	x0, sp
   4e708:	mov	w1, #0x1                   	// #1
   4e70c:	mov	x3, x20
   4e710:	bl	ce50 <fwrite@plt>
   4e714:	cmn	w0, #0x1
   4e718:	b.eq	4e72c <__gmp_printf@@Base+0x128>  // b.none
   4e71c:	cmp	w22, #0x101
   4e720:	mov	w22, w23
   4e724:	b.ge	4e6fc <__gmp_printf@@Base+0xf8>  // b.tcont
   4e728:	b	4e730 <__gmp_printf@@Base+0x12c>
   4e72c:	mov	w19, #0xffffffff            	// #-1
   4e730:	mov	w0, w19
   4e734:	ldp	x20, x19, [sp, #304]
   4e738:	ldp	x22, x21, [sp, #288]
   4e73c:	ldp	x28, x23, [sp, #272]
   4e740:	ldp	x29, x30, [sp, #256]
   4e744:	add	sp, sp, #0x140
   4e748:	ret

000000000004e74c <__gmp_snprintf@@Base>:
   4e74c:	sub	sp, sp, #0x120
   4e750:	stp	x29, x30, [sp, #256]
   4e754:	add	x29, sp, #0x100
   4e758:	mov	x8, #0xffffffffffffffd8    	// #-40
   4e75c:	mov	x9, sp
   4e760:	sub	x10, x29, #0x78
   4e764:	movk	x8, #0xff80, lsl #32
   4e768:	add	x11, x29, #0x20
   4e76c:	add	x9, x9, #0x80
   4e770:	add	x10, x10, #0x28
   4e774:	stp	x9, x8, [x29, #-32]
   4e778:	stp	x11, x10, [x29, #-48]
   4e77c:	stp	x3, x4, [x29, #-120]
   4e780:	stp	x5, x6, [x29, #-104]
   4e784:	stur	x7, [x29, #-88]
   4e788:	stp	q1, q2, [sp, #16]
   4e78c:	str	q0, [sp]
   4e790:	ldp	q0, q1, [x29, #-48]
   4e794:	str	x28, [sp, #272]
   4e798:	stp	q3, q4, [sp, #48]
   4e79c:	stp	q5, q6, [sp, #80]
   4e7a0:	str	q7, [sp, #112]
   4e7a4:	stp	x0, x1, [x29, #-16]
   4e7a8:	stp	q0, q1, [x29, #-80]
   4e7ac:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4e7b0:	ldr	x0, [x0, #4024]
   4e7b4:	sub	x1, x29, #0x10
   4e7b8:	sub	x3, x29, #0x50
   4e7bc:	bl	d050 <__gmp_doprnt@plt>
   4e7c0:	ldr	x28, [sp, #272]
   4e7c4:	ldp	x29, x30, [sp, #256]
   4e7c8:	add	sp, sp, #0x120
   4e7cc:	ret
   4e7d0:	sub	sp, sp, #0x90
   4e7d4:	stp	x29, x30, [sp, #64]
   4e7d8:	stp	x24, x23, [sp, #96]
   4e7dc:	stp	x22, x21, [sp, #112]
   4e7e0:	stp	x20, x19, [sp, #128]
   4e7e4:	ldr	x23, [x0, #8]
   4e7e8:	mov	x19, x2
   4e7ec:	mov	x20, x1
   4e7f0:	str	x25, [sp, #80]
   4e7f4:	cmp	x23, #0x2
   4e7f8:	add	x29, sp, #0x40
   4e7fc:	b.cc	4e868 <__gmp_snprintf@@Base+0x11c>  // b.lo, b.ul, b.last
   4e800:	ldp	q1, q0, [x19]
   4e804:	mov	x21, x0
   4e808:	mov	x3, sp
   4e80c:	mov	x1, x23
   4e810:	stp	q1, q0, [sp, #32]
   4e814:	ldr	x0, [x0]
   4e818:	mov	x2, x20
   4e81c:	stp	q1, q0, [sp]
   4e820:	bl	d130 <vsnprintf@plt>
   4e824:	cmn	w0, #0x1
   4e828:	b.eq	4e8d4 <__gmp_snprintf@@Base+0x188>  // b.none
   4e82c:	ldp	x11, x10, [x21]
   4e830:	mov	w22, w0
   4e834:	sub	x9, x23, #0x1
   4e838:	sxtw	x8, w22
   4e83c:	cmp	x9, w0, sxtw
   4e840:	csel	x8, x8, x9, hi  // hi = pmore
   4e844:	cmp	x9, w0, sxtw
   4e848:	sub	x9, x10, x8
   4e84c:	add	x8, x11, x8
   4e850:	stp	x8, x9, [x21]
   4e854:	b.ne	4e8d8 <__gmp_snprintf@@Base+0x18c>  // b.any
   4e858:	cmp	w22, #0x80
   4e85c:	mov	w8, #0x80                  	// #128
   4e860:	csel	w21, w22, w8, gt
   4e864:	b	4e86c <__gmp_snprintf@@Base+0x120>
   4e868:	mov	w21, #0x80                  	// #128
   4e86c:	adrp	x24, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4e870:	adrp	x25, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4e874:	ldr	x24, [x24, #3840]
   4e878:	ldr	x25, [x25, #4016]
   4e87c:	ldr	x8, [x24]
   4e880:	lsl	x21, x21, #1
   4e884:	mov	x0, x21
   4e888:	blr	x8
   4e88c:	ldp	q0, q1, [x19]
   4e890:	mov	x3, sp
   4e894:	mov	x1, x21
   4e898:	mov	x2, x20
   4e89c:	stp	q0, q1, [sp, #32]
   4e8a0:	ldp	q0, q1, [sp, #32]
   4e8a4:	mov	x23, x0
   4e8a8:	stp	q0, q1, [sp]
   4e8ac:	bl	d130 <vsnprintf@plt>
   4e8b0:	ldr	x8, [x25]
   4e8b4:	mov	w22, w0
   4e8b8:	mov	x0, x23
   4e8bc:	mov	x1, x21
   4e8c0:	blr	x8
   4e8c4:	sub	x8, x21, #0x1
   4e8c8:	cmp	x8, w22, sxtw
   4e8cc:	b.eq	4e87c <__gmp_snprintf@@Base+0x130>  // b.none
   4e8d0:	b	4e8d8 <__gmp_snprintf@@Base+0x18c>
   4e8d4:	mov	w22, #0xffffffff            	// #-1
   4e8d8:	mov	w0, w22
   4e8dc:	ldp	x20, x19, [sp, #128]
   4e8e0:	ldp	x22, x21, [sp, #112]
   4e8e4:	ldp	x24, x23, [sp, #96]
   4e8e8:	ldr	x25, [sp, #80]
   4e8ec:	ldp	x29, x30, [sp, #64]
   4e8f0:	add	sp, sp, #0x90
   4e8f4:	ret
   4e8f8:	stp	x29, x30, [sp, #-48]!
   4e8fc:	stp	x20, x19, [sp, #32]
   4e900:	ldr	x8, [x0, #8]
   4e904:	mov	x19, x2
   4e908:	str	x21, [sp, #16]
   4e90c:	mov	x29, sp
   4e910:	cmp	x8, #0x2
   4e914:	b.cc	4e944 <__gmp_snprintf@@Base+0x1f8>  // b.lo, b.ul, b.last
   4e918:	mov	x20, x0
   4e91c:	ldr	x0, [x0]
   4e920:	sub	x8, x8, #0x1
   4e924:	cmp	x8, x19
   4e928:	csel	x21, x8, x19, cc  // cc = lo, ul, last
   4e92c:	mov	x2, x21
   4e930:	bl	bee0 <memcpy@plt>
   4e934:	ldp	x8, x9, [x20]
   4e938:	add	x8, x8, x21
   4e93c:	sub	x9, x9, x21
   4e940:	stp	x8, x9, [x20]
   4e944:	mov	w0, w19
   4e948:	ldp	x20, x19, [sp, #32]
   4e94c:	ldr	x21, [sp, #16]
   4e950:	ldp	x29, x30, [sp], #48
   4e954:	ret
   4e958:	stp	x29, x30, [sp, #-48]!
   4e95c:	stp	x20, x19, [sp, #32]
   4e960:	ldr	x8, [x0, #8]
   4e964:	mov	w19, w2
   4e968:	str	x21, [sp, #16]
   4e96c:	mov	x29, sp
   4e970:	cmp	x8, #0x2
   4e974:	b.cc	4e9a8 <__gmp_snprintf@@Base+0x25c>  // b.lo, b.ul, b.last
   4e978:	mov	x20, x0
   4e97c:	sub	x8, x8, #0x1
   4e980:	ldr	x0, [x0]
   4e984:	sxtw	x9, w19
   4e988:	cmp	x8, w19, sxtw
   4e98c:	csel	x21, x8, x9, cc  // cc = lo, ul, last
   4e990:	mov	x2, x21
   4e994:	bl	c610 <memset@plt>
   4e998:	ldp	x8, x9, [x20]
   4e99c:	add	x8, x8, x21
   4e9a0:	sub	x9, x9, x21
   4e9a4:	stp	x8, x9, [x20]
   4e9a8:	mov	w0, w19
   4e9ac:	ldp	x20, x19, [sp, #32]
   4e9b0:	ldr	x21, [sp, #16]
   4e9b4:	ldp	x29, x30, [sp], #48
   4e9b8:	ret
   4e9bc:	ldr	x8, [x0, #8]
   4e9c0:	cbz	x8, 4e9cc <__gmp_snprintf@@Base+0x280>
   4e9c4:	ldr	x8, [x0]
   4e9c8:	strb	wzr, [x8]
   4e9cc:	mov	w0, wzr
   4e9d0:	ret

000000000004e9d4 <__gmp_sprintf@@Base>:
   4e9d4:	sub	sp, sp, #0x120
   4e9d8:	stp	x29, x30, [sp, #256]
   4e9dc:	add	x29, sp, #0x100
   4e9e0:	mov	x10, #0xffffffffffffffd0    	// #-48
   4e9e4:	mov	x11, sp
   4e9e8:	add	x12, sp, #0x80
   4e9ec:	movk	x10, #0xff80, lsl #32
   4e9f0:	add	x13, x29, #0x20
   4e9f4:	add	x11, x11, #0x80
   4e9f8:	add	x12, x12, #0x30
   4e9fc:	sub	x9, x29, #0x28
   4ea00:	stp	x11, x10, [x29, #-24]
   4ea04:	stp	x13, x12, [x29, #-40]
   4ea08:	stp	q1, q2, [sp, #16]
   4ea0c:	str	q0, [sp]
   4ea10:	ldp	q0, q1, [x9]
   4ea14:	str	x28, [sp, #272]
   4ea18:	stp	x2, x3, [sp, #128]
   4ea1c:	stp	x4, x5, [sp, #144]
   4ea20:	stp	x6, x7, [sp, #160]
   4ea24:	stp	q3, q4, [sp, #48]
   4ea28:	stp	q5, q6, [sp, #80]
   4ea2c:	str	q7, [sp, #112]
   4ea30:	stur	x0, [x29, #-8]
   4ea34:	stp	q0, q1, [x29, #-80]
   4ea38:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4ea3c:	ldr	x0, [x0, #3944]
   4ea40:	mov	x8, x1
   4ea44:	sub	x1, x29, #0x8
   4ea48:	sub	x3, x29, #0x50
   4ea4c:	mov	x2, x8
   4ea50:	bl	d050 <__gmp_doprnt@plt>
   4ea54:	ldr	x28, [sp, #272]
   4ea58:	ldp	x29, x30, [sp, #256]
   4ea5c:	add	sp, sp, #0x120
   4ea60:	ret
   4ea64:	sub	sp, sp, #0x40
   4ea68:	stp	x29, x30, [sp, #32]
   4ea6c:	stp	x20, x19, [sp, #48]
   4ea70:	ldr	x20, [x0]
   4ea74:	ldp	q1, q0, [x2]
   4ea78:	mov	x19, x0
   4ea7c:	mov	x2, sp
   4ea80:	mov	x0, x20
   4ea84:	add	x29, sp, #0x20
   4ea88:	stp	q1, q0, [sp]
   4ea8c:	bl	cf30 <vsprintf@plt>
   4ea90:	mov	x0, x20
   4ea94:	bl	bf70 <strlen@plt>
   4ea98:	add	x8, x20, w0, sxtw
   4ea9c:	str	x8, [x19]
   4eaa0:	ldp	x20, x19, [sp, #48]
   4eaa4:	ldp	x29, x30, [sp, #32]
   4eaa8:	add	sp, sp, #0x40
   4eaac:	ret
   4eab0:	stp	x29, x30, [sp, #-32]!
   4eab4:	ldr	x8, [x0]
   4eab8:	str	x19, [sp, #16]
   4eabc:	mov	x29, sp
   4eac0:	mov	x19, x2
   4eac4:	add	x9, x8, x2
   4eac8:	str	x9, [x0]
   4eacc:	mov	x0, x8
   4ead0:	bl	bee0 <memcpy@plt>
   4ead4:	mov	w0, w19
   4ead8:	ldr	x19, [sp, #16]
   4eadc:	ldp	x29, x30, [sp], #32
   4eae0:	ret
   4eae4:	stp	x29, x30, [sp, #-32]!
   4eae8:	ldr	x8, [x0]
   4eaec:	str	x19, [sp, #16]
   4eaf0:	mov	w19, w2
   4eaf4:	sxtw	x2, w19
   4eaf8:	add	x9, x8, w19, sxtw
   4eafc:	str	x9, [x0]
   4eb00:	mov	x0, x8
   4eb04:	mov	x29, sp
   4eb08:	bl	c610 <memset@plt>
   4eb0c:	mov	w0, w19
   4eb10:	ldr	x19, [sp, #16]
   4eb14:	ldp	x29, x30, [sp], #32
   4eb18:	ret
   4eb1c:	ldr	x8, [x0]
   4eb20:	mov	w0, wzr
   4eb24:	strb	wzr, [x8]
   4eb28:	ret
   4eb2c:	sub	sp, sp, #0x80
   4eb30:	stp	x29, x30, [sp, #64]
   4eb34:	str	x23, [sp, #80]
   4eb38:	stp	x22, x21, [sp, #96]
   4eb3c:	stp	x20, x19, [sp, #112]
   4eb40:	adrp	x23, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4eb44:	ldr	x23, [x23, #3792]
   4eb48:	mov	x20, x2
   4eb4c:	mov	x21, x1
   4eb50:	mov	x19, x0
   4eb54:	mov	w9, #0x100                 	// #256
   4eb58:	add	x29, sp, #0x40
   4eb5c:	ldp	x8, x1, [x19, #16]
   4eb60:	add	x9, x8, x9
   4eb64:	cmp	x1, x9
   4eb68:	b.hi	4eb88 <__gmp_sprintf@@Base+0x1b4>  // b.pmore
   4eb6c:	lsl	x2, x9, #1
   4eb70:	str	x2, [x19, #24]
   4eb74:	ldr	x8, [x23]
   4eb78:	ldr	x0, [x19, #8]
   4eb7c:	blr	x8
   4eb80:	ldp	x8, x1, [x19, #16]
   4eb84:	str	x0, [x19, #8]
   4eb88:	ldp	q1, q0, [x20]
   4eb8c:	sub	x22, x1, x8
   4eb90:	mov	x3, sp
   4eb94:	mov	x1, x22
   4eb98:	stp	q1, q0, [sp, #32]
   4eb9c:	ldp	x9, x10, [x19, #8]
   4eba0:	mov	x2, x21
   4eba4:	stp	q1, q0, [sp]
   4eba8:	add	x0, x9, x10
   4ebac:	bl	d130 <vsnprintf@plt>
   4ebb0:	sub	w8, w22, #0x1
   4ebb4:	cmn	w0, #0x1
   4ebb8:	csel	w9, w8, w0, eq  // eq = none
   4ebbc:	sub	x8, x22, #0x1
   4ebc0:	cmp	x8, w9, sxtw
   4ebc4:	sxtw	x0, w9
   4ebc8:	b.hi	4ebe4 <__gmp_sprintf@@Base+0x210>  // b.pmore
   4ebcc:	add	w10, w0, #0x2
   4ebd0:	lsl	x9, x22, #1
   4ebd4:	sxtw	x10, w10
   4ebd8:	cmp	x8, x0
   4ebdc:	csel	x9, x9, x10, eq  // eq = none
   4ebe0:	b	4eb5c <__gmp_sprintf@@Base+0x188>
   4ebe4:	ldr	x8, [x19, #16]
   4ebe8:	ldr	x23, [sp, #80]
   4ebec:	add	x8, x8, x0
   4ebf0:	str	x8, [x19, #16]
   4ebf4:	ldp	x20, x19, [sp, #112]
   4ebf8:	ldp	x22, x21, [sp, #96]
   4ebfc:	ldp	x29, x30, [sp, #64]
   4ec00:	add	sp, sp, #0x80
   4ec04:	ret

000000000004ec08 <__gmp_vasprintf@@Base>:
   4ec08:	sub	sp, sp, #0x60
   4ec0c:	stp	x29, x30, [sp, #64]
   4ec10:	stp	x20, x19, [sp, #80]
   4ec14:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4ec18:	ldr	x8, [x8, #3840]
   4ec1c:	mov	w9, #0x100                 	// #256
   4ec20:	str	x0, [sp, #32]
   4ec24:	mov	w0, #0x100                 	// #256
   4ec28:	ldr	x8, [x8]
   4ec2c:	add	x29, sp, #0x40
   4ec30:	mov	x19, x2
   4ec34:	mov	x20, x1
   4ec38:	str	x9, [sp, #56]
   4ec3c:	blr	x8
   4ec40:	stp	x0, xzr, [sp, #40]
   4ec44:	ldp	q1, q0, [x19]
   4ec48:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4ec4c:	add	x1, sp, #0x20
   4ec50:	mov	x3, sp
   4ec54:	stp	q1, q0, [sp]
   4ec58:	ldr	x0, [x0, #3864]
   4ec5c:	mov	x2, x20
   4ec60:	bl	d050 <__gmp_doprnt@plt>
   4ec64:	ldp	x20, x19, [sp, #80]
   4ec68:	ldp	x29, x30, [sp, #64]
   4ec6c:	add	sp, sp, #0x60
   4ec70:	ret

000000000004ec74 <__gmp_vfprintf@@Base>:
   4ec74:	sub	sp, sp, #0x30
   4ec78:	stp	x29, x30, [sp, #32]
   4ec7c:	ldp	q1, q0, [x2]
   4ec80:	mov	x8, x1
   4ec84:	mov	x1, x0
   4ec88:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4ec8c:	stp	q1, q0, [sp]
   4ec90:	ldr	x0, [x0, #3816]
   4ec94:	mov	x3, sp
   4ec98:	mov	x2, x8
   4ec9c:	add	x29, sp, #0x20
   4eca0:	bl	d050 <__gmp_doprnt@plt>
   4eca4:	ldp	x29, x30, [sp, #32]
   4eca8:	add	sp, sp, #0x30
   4ecac:	ret

000000000004ecb0 <__gmp_vprintf@@Base>:
   4ecb0:	sub	sp, sp, #0x30
   4ecb4:	stp	x29, x30, [sp, #32]
   4ecb8:	ldp	q0, q1, [x1]
   4ecbc:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4ecc0:	ldr	x8, [x8, #3856]
   4ecc4:	mov	x2, x0
   4ecc8:	stp	q0, q1, [sp]
   4eccc:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4ecd0:	ldr	x1, [x8]
   4ecd4:	ldr	x0, [x0, #3816]
   4ecd8:	mov	x3, sp
   4ecdc:	add	x29, sp, #0x20
   4ece0:	bl	d050 <__gmp_doprnt@plt>
   4ece4:	ldp	x29, x30, [sp, #32]
   4ece8:	add	sp, sp, #0x30
   4ecec:	ret

000000000004ecf0 <__gmp_vsnprintf@@Base>:
   4ecf0:	sub	sp, sp, #0x40
   4ecf4:	stp	x29, x30, [sp, #48]
   4ecf8:	add	x29, sp, #0x30
   4ecfc:	stp	x0, x1, [x29, #-16]
   4ed00:	ldp	q1, q0, [x3]
   4ed04:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4ed08:	sub	x1, x29, #0x10
   4ed0c:	mov	x3, sp
   4ed10:	stp	q1, q0, [sp]
   4ed14:	ldr	x0, [x0, #4024]
   4ed18:	bl	d050 <__gmp_doprnt@plt>
   4ed1c:	ldp	x29, x30, [sp, #48]
   4ed20:	add	sp, sp, #0x40
   4ed24:	ret

000000000004ed28 <__gmp_vsprintf@@Base>:
   4ed28:	sub	sp, sp, #0x40
   4ed2c:	stp	x29, x30, [sp, #48]
   4ed30:	add	x29, sp, #0x30
   4ed34:	stur	x0, [x29, #-8]
   4ed38:	ldp	q1, q0, [x2]
   4ed3c:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4ed40:	mov	x8, x1
   4ed44:	sub	x1, x29, #0x8
   4ed48:	stp	q1, q0, [sp]
   4ed4c:	ldr	x0, [x0, #3944]
   4ed50:	mov	x3, sp
   4ed54:	mov	x2, x8
   4ed58:	bl	d050 <__gmp_doprnt@plt>
   4ed5c:	ldp	x29, x30, [sp, #48]
   4ed60:	add	sp, sp, #0x40
   4ed64:	ret

000000000004ed68 <__gmp_doscan@@Base>:
   4ed68:	sub	sp, sp, #0x110
   4ed6c:	stp	x29, x30, [sp, #176]
   4ed70:	add	x29, sp, #0xb0
   4ed74:	stp	x28, x27, [sp, #192]
   4ed78:	stp	x26, x25, [sp, #208]
   4ed7c:	stp	x24, x23, [sp, #224]
   4ed80:	stp	x22, x21, [sp, #240]
   4ed84:	stp	x20, x19, [sp, #256]
   4ed88:	stp	x0, x1, [x29, #-72]
   4ed8c:	ldp	q1, q0, [x3]
   4ed90:	mov	x0, x2
   4ed94:	mov	x25, x2
   4ed98:	stp	q1, q0, [x29, #-48]
   4ed9c:	bl	bf70 <strlen@plt>
   4eda0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4eda4:	ldr	x8, [x8, #3840]
   4eda8:	add	x0, x0, #0x4
   4edac:	str	x0, [sp, #16]
   4edb0:	ldr	x8, [x8]
   4edb4:	blr	x8
   4edb8:	adrp	x28, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4edbc:	ldrb	w23, [x25]
   4edc0:	ldr	x28, [x28, #4016]
   4edc4:	mov	x21, x0
   4edc8:	cbz	w23, 4f7f4 <__gmp_doscan@@Base+0xa8c>
   4edcc:	bl	cb00 <__ctype_b_loc@plt>
   4edd0:	adrp	x26, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4edd4:	mov	w20, wzr
   4edd8:	mov	w27, wzr
   4eddc:	add	x26, x26, #0x6b8
   4ede0:	str	x0, [sp, #88]
   4ede4:	str	x21, [sp, #8]
   4ede8:	mov	x24, x25
   4edec:	sxtw	x19, w20
   4edf0:	mov	x25, x24
   4edf4:	ldr	x8, [sp, #88]
   4edf8:	and	x9, x23, #0xff
   4edfc:	add	x24, x25, #0x1
   4ee00:	ldr	x8, [x8]
   4ee04:	ldrh	w9, [x8, x9, lsl #1]
   4ee08:	tbnz	w9, #13, 4efd4 <__gmp_doscan@@Base+0x26c>
   4ee0c:	and	w9, w23, #0xff
   4ee10:	cmp	w9, #0x25
   4ee14:	b.ne	4efe4 <__gmp_doscan@@Base+0x27c>  // b.any
   4ee18:	mov	x1, x25
   4ee1c:	mov	w22, wzr
   4ee20:	str	xzr, [sp, #80]
   4ee24:	mov	x25, x24
   4ee28:	add	x9, x25, #0x1
   4ee2c:	mov	x24, x25
   4ee30:	mov	x25, x9
   4ee34:	ldurb	w23, [x25, #-1]
   4ee38:	sub	w9, w23, #0x25
   4ee3c:	cmp	w9, #0x55
   4ee40:	b.hi	4eec8 <__gmp_doscan@@Base+0x160>  // b.pmore
   4ee44:	adr	x10, 4ee54 <__gmp_doscan@@Base+0xec>
   4ee48:	ldrh	w11, [x26, x9, lsl #1]
   4ee4c:	add	x10, x10, x11, lsl #2
   4ee50:	br	x10
   4ee54:	add	x25, x25, #0x1
   4ee58:	add	x24, x24, #0x1
   4ee5c:	b	4ee34 <__gmp_doscan@@Base+0xcc>
   4ee60:	mov	w9, #0x1                   	// #1
   4ee64:	str	w9, [sp, #80]
   4ee68:	b	4ee28 <__gmp_doscan@@Base+0xc0>
   4ee6c:	ldr	w9, [sp, #84]
   4ee70:	and	w9, w9, #0xff
   4ee74:	cmp	w9, #0x68
   4ee78:	mov	w9, #0x48                  	// #72
   4ee7c:	b	4ee90 <__gmp_doscan@@Base+0x128>
   4ee80:	ldr	w9, [sp, #84]
   4ee84:	and	w9, w9, #0xff
   4ee88:	cmp	w9, #0x6c
   4ee8c:	mov	w9, #0x4c                  	// #76
   4ee90:	str	w9, [sp, #84]
   4ee94:	b.eq	4ee28 <__gmp_doscan@@Base+0xc0>  // b.none
   4ee98:	mov	w9, w23
   4ee9c:	str	w23, [sp, #84]
   4eea0:	b	4ee28 <__gmp_doscan@@Base+0xc0>
   4eea4:	mov	w22, wzr
   4eea8:	mov	w11, #0xa                   	// #10
   4eeac:	mul	w9, w22, w11
   4eeb0:	add	w9, w9, w23, uxtb
   4eeb4:	ldrb	w23, [x24, #1]!
   4eeb8:	sub	w22, w9, #0x30
   4eebc:	ldrh	w10, [x8, x23, lsl #1]
   4eec0:	tbnz	w10, #11, 4eeac <__gmp_doscan@@Base+0x144>
   4eec4:	b	4ee24 <__gmp_doscan@@Base+0xbc>
   4eec8:	cbz	w23, 4f7f8 <__gmp_doscan@@Base+0xa90>
   4eecc:	b	4efa4 <__gmp_doscan@@Base+0x23c>
   4eed0:	ldr	w8, [sp, #80]
   4eed4:	cbnz	w8, 4efa4 <__gmp_doscan@@Base+0x23c>
   4eed8:	ldursw	x8, [x29, #-24]
   4eedc:	tbz	w8, #31, 4eefc <__gmp_doscan@@Base+0x194>
   4eee0:	add	w9, w8, #0x8
   4eee4:	cmn	w8, #0x8
   4eee8:	stur	w9, [x29, #-24]
   4eeec:	b.gt	4eefc <__gmp_doscan@@Base+0x194>
   4eef0:	ldur	x9, [x29, #-40]
   4eef4:	add	x8, x9, x8
   4eef8:	b	4ef08 <__gmp_doscan@@Base+0x1a0>
   4eefc:	ldur	x8, [x29, #-48]
   4ef00:	add	x9, x8, #0x8
   4ef04:	stur	x9, [x29, #-48]
   4ef08:	ldr	x0, [x8]
   4ef0c:	ldr	w8, [sp, #84]
   4ef10:	and	w8, w8, #0xff
   4ef14:	cmp	w8, #0x67
   4ef18:	b.gt	4ef40 <__gmp_doscan@@Base+0x1d8>
   4ef1c:	cmp	w8, #0x4b
   4ef20:	b.gt	4ef6c <__gmp_doscan@@Base+0x204>
   4ef24:	cbz	w8, 4efb0 <__gmp_doscan@@Base+0x248>
   4ef28:	cmp	w8, #0x46
   4ef2c:	b.eq	4efb8 <__gmp_doscan@@Base+0x250>  // b.none
   4ef30:	cmp	w8, #0x48
   4ef34:	b.ne	4efa4 <__gmp_doscan@@Base+0x23c>  // b.any
   4ef38:	strb	w20, [x0]
   4ef3c:	b	4efa4 <__gmp_doscan@@Base+0x23c>
   4ef40:	sub	w9, w8, #0x68
   4ef44:	cmp	w9, #0x9
   4ef48:	b.hi	4ef90 <__gmp_doscan@@Base+0x228>  // b.pmore
   4ef4c:	adrp	x11, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4ef50:	add	x11, x11, #0x764
   4ef54:	adr	x8, 4ef64 <__gmp_doscan@@Base+0x1fc>
   4ef58:	ldrb	w10, [x11, x9]
   4ef5c:	add	x8, x8, x10, lsl #2
   4ef60:	br	x8
   4ef64:	strh	w20, [x0]
   4ef68:	b	4efa4 <__gmp_doscan@@Base+0x23c>
   4ef6c:	cmp	w8, #0x4c
   4ef70:	b.eq	4efa0 <__gmp_doscan@@Base+0x238>  // b.none
   4ef74:	cmp	w8, #0x51
   4ef78:	b.eq	4efc4 <__gmp_doscan@@Base+0x25c>  // b.none
   4ef7c:	cmp	w8, #0x5a
   4ef80:	b.ne	4efa4 <__gmp_doscan@@Base+0x23c>  // b.any
   4ef84:	mov	x1, x19
   4ef88:	bl	d290 <__gmpz_set_si@plt>
   4ef8c:	b	4efa4 <__gmp_doscan@@Base+0x23c>
   4ef90:	cmp	w8, #0x74
   4ef94:	b.eq	4efa0 <__gmp_doscan@@Base+0x238>  // b.none
   4ef98:	cmp	w8, #0x7a
   4ef9c:	b.ne	4efa4 <__gmp_doscan@@Base+0x23c>  // b.any
   4efa0:	str	x19, [x0]
   4efa4:	ldrb	w23, [x25]
   4efa8:	cbnz	w23, 4edf4 <__gmp_doscan@@Base+0x8c>
   4efac:	b	4f7f8 <__gmp_doscan@@Base+0xa90>
   4efb0:	str	w20, [x0]
   4efb4:	b	4efa4 <__gmp_doscan@@Base+0x23c>
   4efb8:	mov	x1, x19
   4efbc:	bl	c640 <__gmpf_set_si@plt>
   4efc0:	b	4efa4 <__gmp_doscan@@Base+0x23c>
   4efc4:	mov	w2, #0x1                   	// #1
   4efc8:	mov	x1, x19
   4efcc:	bl	cb90 <__gmpq_set_si@plt>
   4efd0:	b	4efa4 <__gmp_doscan@@Base+0x23c>
   4efd4:	ldp	x0, x1, [x29, #-72]
   4efd8:	bl	4f87c <__gmp_doscan@@Base+0xb14>
   4efdc:	add	w20, w0, w20
   4efe0:	b	4f004 <__gmp_doscan@@Base+0x29c>
   4efe4:	mov	x25, x24
   4efe8:	ldp	x8, x0, [x29, #-72]
   4efec:	ldr	x8, [x8, #16]
   4eff0:	blr	x8
   4eff4:	cmp	w0, w23, uxtb
   4eff8:	b.ne	4f85c <__gmp_doscan@@Base+0xaf4>  // b.any
   4effc:	add	w20, w20, #0x1
   4f000:	mov	x24, x25
   4f004:	ldrb	w23, [x24]
   4f008:	cbnz	w23, 4edec <__gmp_doscan@@Base+0x84>
   4f00c:	b	4f7f8 <__gmp_doscan@@Base+0xa90>
   4f010:	mov	w23, wzr
   4f014:	b	4f048 <__gmp_doscan@@Base+0x2e0>
   4f018:	mov	w23, #0x10                  	// #16
   4f01c:	b	4f048 <__gmp_doscan@@Base+0x2e0>
   4f020:	mov	w23, #0xa                   	// #10
   4f024:	b	4f048 <__gmp_doscan@@Base+0x2e0>
   4f028:	mov	x9, x25
   4f02c:	ldrb	w8, [x9], #1
   4f030:	cmp	w8, #0x5e
   4f034:	b.ne	4f618 <__gmp_doscan@@Base+0x8b0>  // b.any
   4f038:	ldrb	w8, [x25, #1]
   4f03c:	add	x25, x25, #0x2
   4f040:	b	4f61c <__gmp_doscan@@Base+0x8b4>
   4f044:	mov	w23, #0x8                   	// #8
   4f048:	ldr	w8, [sp, #84]
   4f04c:	and	w8, w8, #0xff
   4f050:	sub	w8, w8, #0x46
   4f054:	cmp	w8, #0x14
   4f058:	b.hi	4f720 <__gmp_doscan@@Base+0x9b8>  // b.pmore
   4f05c:	mov	w9, #0x1                   	// #1
   4f060:	lsl	w8, w9, w8
   4f064:	mov	w9, #0x801                 	// #2049
   4f068:	movk	w9, #0x10, lsl #16
   4f06c:	tst	w8, w9
   4f070:	b.eq	4f720 <__gmp_doscan@@Base+0x9b8>  // b.none
   4f074:	ldp	x0, x1, [x29, #-72]
   4f078:	bl	4f87c <__gmp_doscan@@Base+0xb14>
   4f07c:	ldr	w8, [sp, #80]
   4f080:	mov	w26, w0
   4f084:	str	w27, [sp, #76]
   4f088:	cbz	w8, 4f094 <__gmp_doscan@@Base+0x32c>
   4f08c:	mov	x19, xzr
   4f090:	b	4f0c8 <__gmp_doscan@@Base+0x360>
   4f094:	ldursw	x8, [x29, #-24]
   4f098:	tbz	w8, #31, 4f0b8 <__gmp_doscan@@Base+0x350>
   4f09c:	add	w9, w8, #0x8
   4f0a0:	cmn	w8, #0x8
   4f0a4:	stur	w9, [x29, #-24]
   4f0a8:	b.gt	4f0b8 <__gmp_doscan@@Base+0x350>
   4f0ac:	ldur	x9, [x29, #-40]
   4f0b0:	add	x8, x9, x8
   4f0b4:	b	4f0c4 <__gmp_doscan@@Base+0x35c>
   4f0b8:	ldur	x8, [x29, #-48]
   4f0bc:	add	x9, x8, #0x8
   4f0c0:	stur	x9, [x29, #-48]
   4f0c4:	ldr	x19, [x8]
   4f0c8:	ldp	x8, x0, [x29, #-72]
   4f0cc:	ldr	x8, [x8, #16]
   4f0d0:	blr	x8
   4f0d4:	cmn	w0, #0x1
   4f0d8:	b.eq	4f82c <__gmp_doscan@@Base+0xac4>  // b.none
   4f0dc:	str	x19, [sp, #48]
   4f0e0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f0e4:	ldr	x8, [x8, #3840]
   4f0e8:	add	w9, w26, w20
   4f0ec:	str	w9, [sp, #68]
   4f0f0:	cmp	w22, #0x0
   4f0f4:	ldr	x8, [x8]
   4f0f8:	mov	w9, #0x7ffffffe            	// #2147483646
   4f0fc:	mov	w28, w0
   4f100:	csel	w9, w9, w22, eq  // eq = none
   4f104:	mov	w0, #0x200                 	// #512
   4f108:	stur	w9, [x29, #-76]
   4f10c:	blr	x8
   4f110:	ldr	w8, [sp, #84]
   4f114:	mov	w9, #0x1                   	// #1
   4f118:	str	w9, [sp, #64]
   4f11c:	mov	w9, #0x8                   	// #8
   4f120:	and	w8, w8, #0xff
   4f124:	cmp	w8, #0x46
   4f128:	mov	w8, #0xa                   	// #10
   4f12c:	mov	x26, x0
   4f130:	mov	x19, xzr
   4f134:	mov	w27, #0x200                 	// #512
   4f138:	csel	w8, w8, w9, eq  // eq = none
   4f13c:	mov	w24, #0x1                   	// #1
   4f140:	str	xzr, [sp, #24]
   4f144:	stp	w23, wzr, [sp, #40]
   4f148:	str	wzr, [sp, #72]
   4f14c:	str	w8, [sp, #36]
   4f150:	cmp	w28, #0x2b
   4f154:	b.eq	4f1a0 <__gmp_doscan@@Base+0x438>  // b.none
   4f158:	cmp	w28, #0x2d
   4f15c:	b.ne	4f1c0 <__gmp_doscan@@Base+0x458>  // b.any
   4f160:	cmp	x19, x27
   4f164:	b.cc	4f190 <__gmp_doscan@@Base+0x428>  // b.lo, b.ul, b.last
   4f168:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f16c:	ldr	x8, [x8, #3792]
   4f170:	add	x20, x27, #0x200
   4f174:	mov	x0, x26
   4f178:	mov	x1, x27
   4f17c:	ldr	x8, [x8]
   4f180:	mov	x2, x20
   4f184:	blr	x8
   4f188:	mov	x26, x0
   4f18c:	mov	x27, x20
   4f190:	add	x8, x19, #0x1
   4f194:	mov	w9, #0x2d                  	// #45
   4f198:	strb	w9, [x26, x19]
   4f19c:	mov	x19, x8
   4f1a0:	ldur	w8, [x29, #-76]
   4f1a4:	cmp	w24, w8
   4f1a8:	add	w24, w24, #0x1
   4f1ac:	b.ge	4f6a0 <__gmp_doscan@@Base+0x938>  // b.tcont
   4f1b0:	ldp	x8, x0, [x29, #-72]
   4f1b4:	ldr	x8, [x8, #16]
   4f1b8:	blr	x8
   4f1bc:	mov	w28, w0
   4f1c0:	cbz	w23, 4f338 <__gmp_doscan@@Base+0x5d0>
   4f1c4:	mov	w9, wzr
   4f1c8:	ldr	x8, [sp, #88]
   4f1cc:	cmp	w23, #0x10
   4f1d0:	ldr	x8, [x8]
   4f1d4:	ldrh	w8, [x8, w28, sxtw #1]
   4f1d8:	b.ne	4f1e4 <__gmp_doscan@@Base+0x47c>  // b.any
   4f1dc:	tbnz	w8, #12, 4f1fc <__gmp_doscan@@Base+0x494>
   4f1e0:	b	4f260 <__gmp_doscan@@Base+0x4f8>
   4f1e4:	tbz	w8, #11, 4f260 <__gmp_doscan@@Base+0x4f8>
   4f1e8:	cmp	w23, #0x8
   4f1ec:	b.ne	4f1fc <__gmp_doscan@@Base+0x494>  // b.any
   4f1f0:	orr	w8, w28, #0x1
   4f1f4:	cmp	w8, #0x39
   4f1f8:	b.eq	4f260 <__gmp_doscan@@Base+0x4f8>  // b.none
   4f1fc:	cmp	x19, x27
   4f200:	b.cc	4f22c <__gmp_doscan@@Base+0x4c4>  // b.lo, b.ul, b.last
   4f204:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f208:	ldr	x8, [x8, #3792]
   4f20c:	add	x20, x27, #0x200
   4f210:	mov	x0, x26
   4f214:	mov	x1, x27
   4f218:	ldr	x8, [x8]
   4f21c:	mov	x2, x20
   4f220:	blr	x8
   4f224:	mov	x26, x0
   4f228:	mov	x27, x20
   4f22c:	ldur	w8, [x29, #-76]
   4f230:	add	x22, x19, #0x1
   4f234:	strb	w28, [x26, x19]
   4f238:	cmp	w24, w8
   4f23c:	add	w24, w24, #0x1
   4f240:	b.ge	4f548 <__gmp_doscan@@Base+0x7e0>  // b.tcont
   4f244:	ldp	x8, x0, [x29, #-72]
   4f248:	ldr	x8, [x8, #16]
   4f24c:	blr	x8
   4f250:	mov	w28, w0
   4f254:	mov	w9, #0x1                   	// #1
   4f258:	mov	x19, x22
   4f25c:	b	4f1c8 <__gmp_doscan@@Base+0x460>
   4f260:	ldr	w8, [sp, #64]
   4f264:	cbz	w8, 4f540 <__gmp_doscan@@Base+0x7d8>
   4f268:	ldr	w8, [sp, #84]
   4f26c:	str	w9, [sp, #60]
   4f270:	and	w8, w8, #0xff
   4f274:	cmp	w8, #0x46
   4f278:	b.ne	4f450 <__gmp_doscan@@Base+0x6e8>  // b.any
   4f27c:	ldr	w9, [sp, #72]
   4f280:	cbnz	w9, 4f450 <__gmp_doscan@@Base+0x6e8>
   4f284:	mov	w0, #0x10000               	// #65536
   4f288:	bl	c420 <nl_langinfo@plt>
   4f28c:	ldrb	w8, [x0]
   4f290:	cmp	w28, w8
   4f294:	b.ne	4f458 <__gmp_doscan@@Base+0x6f0>  // b.any
   4f298:	mov	x22, xzr
   4f29c:	add	x21, x0, #0x1
   4f2a0:	add	x8, x19, x22
   4f2a4:	cmp	x8, x27
   4f2a8:	b.cc	4f2d4 <__gmp_doscan@@Base+0x56c>  // b.lo, b.ul, b.last
   4f2ac:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f2b0:	ldr	x8, [x8, #3792]
   4f2b4:	add	x20, x27, #0x200
   4f2b8:	mov	x0, x26
   4f2bc:	mov	x1, x27
   4f2c0:	ldr	x8, [x8]
   4f2c4:	mov	x2, x20
   4f2c8:	blr	x8
   4f2cc:	mov	x26, x0
   4f2d0:	mov	x27, x20
   4f2d4:	ldur	w9, [x29, #-76]
   4f2d8:	add	x8, x26, x19
   4f2dc:	add	w20, w24, #0x1
   4f2e0:	strb	w28, [x8, x22]
   4f2e4:	cmp	w24, w9
   4f2e8:	b.ge	4f52c <__gmp_doscan@@Base+0x7c4>  // b.tcont
   4f2ec:	ldp	x8, x0, [x29, #-72]
   4f2f0:	ldr	x8, [x8, #16]
   4f2f4:	blr	x8
   4f2f8:	ldrb	w8, [x21, x22]
   4f2fc:	mov	w28, w0
   4f300:	cbz	w8, 4f318 <__gmp_doscan@@Base+0x5b0>
   4f304:	cmp	w28, w8
   4f308:	add	x22, x22, #0x1
   4f30c:	mov	w24, w20
   4f310:	b.eq	4f2a0 <__gmp_doscan@@Base+0x538>  // b.none
   4f314:	b	4f608 <__gmp_doscan@@Base+0x8a0>
   4f318:	ldr	x21, [sp, #8]
   4f31c:	ldr	w9, [sp, #60]
   4f320:	add	x8, x19, x22
   4f324:	add	w24, w24, #0x1
   4f328:	add	x19, x8, #0x1
   4f32c:	mov	w8, #0x1                   	// #1
   4f330:	str	w8, [sp, #72]
   4f334:	b	4f1c8 <__gmp_doscan@@Base+0x460>
   4f338:	cmp	w28, #0x30
   4f33c:	b.ne	4f3c4 <__gmp_doscan@@Base+0x65c>  // b.any
   4f340:	cmp	x19, x27
   4f344:	b.cc	4f370 <__gmp_doscan@@Base+0x608>  // b.lo, b.ul, b.last
   4f348:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f34c:	ldr	x8, [x8, #3792]
   4f350:	add	x20, x27, #0x200
   4f354:	mov	x0, x26
   4f358:	mov	x1, x27
   4f35c:	ldr	x8, [x8]
   4f360:	mov	x2, x20
   4f364:	blr	x8
   4f368:	mov	x26, x0
   4f36c:	mov	x27, x20
   4f370:	ldur	w8, [x29, #-76]
   4f374:	add	x22, x19, #0x1
   4f378:	mov	w28, #0x30                  	// #48
   4f37c:	add	w20, w24, #0x1
   4f380:	cmp	w24, w8
   4f384:	strb	w28, [x26, x19]
   4f388:	b.ge	4f688 <__gmp_doscan@@Base+0x920>  // b.tcont
   4f38c:	ldp	x8, x0, [x29, #-72]
   4f390:	ldr	x8, [x8, #16]
   4f394:	blr	x8
   4f398:	orr	w8, w0, #0x20
   4f39c:	mov	w28, w0
   4f3a0:	cmp	w8, #0x78
   4f3a4:	b.ne	4f3d0 <__gmp_doscan@@Base+0x668>  // b.any
   4f3a8:	ldr	w8, [sp, #84]
   4f3ac:	and	w8, w8, #0xff
   4f3b0:	cmp	w8, #0x46
   4f3b4:	b.ne	4f3e4 <__gmp_doscan@@Base+0x67c>  // b.any
   4f3b8:	mov	w8, #0x1                   	// #1
   4f3bc:	str	w8, [sp, #44]
   4f3c0:	b	4f420 <__gmp_doscan@@Base+0x6b8>
   4f3c4:	mov	w9, wzr
   4f3c8:	mov	w23, #0xa                   	// #10
   4f3cc:	b	4f1c8 <__gmp_doscan@@Base+0x460>
   4f3d0:	ldr	w23, [sp, #36]
   4f3d4:	mov	w9, #0x1                   	// #1
   4f3d8:	mov	x19, x22
   4f3dc:	mov	w24, w20
   4f3e0:	b	4f1c8 <__gmp_doscan@@Base+0x460>
   4f3e4:	cmp	x22, x27
   4f3e8:	b.cc	4f414 <__gmp_doscan@@Base+0x6ac>  // b.lo, b.ul, b.last
   4f3ec:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f3f0:	ldr	x8, [x8, #3792]
   4f3f4:	add	x20, x27, #0x200
   4f3f8:	mov	x0, x26
   4f3fc:	mov	x1, x27
   4f400:	ldr	x8, [x8]
   4f404:	mov	x2, x20
   4f408:	blr	x8
   4f40c:	mov	x26, x0
   4f410:	mov	x27, x20
   4f414:	add	x8, x19, #0x2
   4f418:	strb	w28, [x26, x22]
   4f41c:	mov	x22, x8
   4f420:	ldur	w8, [x29, #-76]
   4f424:	add	w24, w24, #0x2
   4f428:	cmp	w24, w8
   4f42c:	b.gt	4f6a0 <__gmp_doscan@@Base+0x938>
   4f430:	ldp	x8, x0, [x29, #-72]
   4f434:	ldr	x8, [x8, #16]
   4f438:	blr	x8
   4f43c:	mov	w28, w0
   4f440:	mov	w9, wzr
   4f444:	mov	w23, #0x10                  	// #16
   4f448:	mov	x19, x22
   4f44c:	b	4f1c8 <__gmp_doscan@@Base+0x460>
   4f450:	cmp	w8, #0x46
   4f454:	b.ne	4f498 <__gmp_doscan@@Base+0x730>  // b.any
   4f458:	ldr	w9, [sp, #44]
   4f45c:	orr	w8, w28, #0x20
   4f460:	cbz	w9, 4f47c <__gmp_doscan@@Base+0x714>
   4f464:	cmp	w8, #0x70
   4f468:	b.ne	4f47c <__gmp_doscan@@Base+0x714>  // b.any
   4f46c:	ldr	w9, [sp, #60]
   4f470:	mov	w23, #0xa                   	// #10
   4f474:	str	x19, [sp, #24]
   4f478:	b	4f490 <__gmp_doscan@@Base+0x728>
   4f47c:	cmp	w8, #0x65
   4f480:	b.ne	4f53c <__gmp_doscan@@Base+0x7d4>  // b.any
   4f484:	ldr	w8, [sp, #44]
   4f488:	ldr	w9, [sp, #60]
   4f48c:	cbnz	w8, 4f540 <__gmp_doscan@@Base+0x7d8>
   4f490:	cbnz	w9, 4f4c0 <__gmp_doscan@@Base+0x758>
   4f494:	b	4f6a0 <__gmp_doscan@@Base+0x938>
   4f498:	ldr	w8, [sp, #84]
   4f49c:	ldr	w9, [sp, #60]
   4f4a0:	and	w8, w8, #0xff
   4f4a4:	cmp	w8, #0x51
   4f4a8:	b.ne	4f540 <__gmp_doscan@@Base+0x7d8>  // b.any
   4f4ac:	cmp	w28, #0x2f
   4f4b0:	b.ne	4f540 <__gmp_doscan@@Base+0x7d8>  // b.any
   4f4b4:	cbz	w9, 4f69c <__gmp_doscan@@Base+0x934>
   4f4b8:	ldr	w23, [sp, #40]
   4f4bc:	mov	w9, wzr
   4f4c0:	cmp	x19, x27
   4f4c4:	b.cc	4f4f8 <__gmp_doscan@@Base+0x790>  // b.lo, b.ul, b.last
   4f4c8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f4cc:	ldr	x8, [x8, #3792]
   4f4d0:	add	x20, x27, #0x200
   4f4d4:	mov	x0, x26
   4f4d8:	mov	x1, x27
   4f4dc:	ldr	x8, [x8]
   4f4e0:	mov	x2, x20
   4f4e4:	mov	w22, w9
   4f4e8:	blr	x8
   4f4ec:	mov	w9, w22
   4f4f0:	mov	x26, x0
   4f4f4:	mov	x27, x20
   4f4f8:	ldur	w8, [x29, #-76]
   4f4fc:	add	x20, x19, #0x1
   4f500:	strb	w28, [x26, x19]
   4f504:	cmp	w24, w8
   4f508:	add	w24, w24, #0x1
   4f50c:	b.ge	4f690 <__gmp_doscan@@Base+0x928>  // b.tcont
   4f510:	ldp	x8, x0, [x29, #-72]
   4f514:	ldr	x8, [x8, #16]
   4f518:	blr	x8
   4f51c:	mov	w28, w0
   4f520:	str	wzr, [sp, #64]
   4f524:	mov	x19, x20
   4f528:	b	4f150 <__gmp_doscan@@Base+0x3e8>
   4f52c:	ldr	x21, [sp, #8]
   4f530:	add	x8, x19, x22
   4f534:	add	x19, x8, #0x1
   4f538:	mov	w24, w20
   4f53c:	ldr	w9, [sp, #60]
   4f540:	cbz	w9, 4f6a0 <__gmp_doscan@@Base+0x938>
   4f544:	mov	x22, x19
   4f548:	ldr	w8, [sp, #80]
   4f54c:	cbz	w8, 4f558 <__gmp_doscan@@Base+0x7f0>
   4f550:	mov	w19, wzr
   4f554:	b	4f6a4 <__gmp_doscan@@Base+0x93c>
   4f558:	cmp	x22, x27
   4f55c:	b.cc	4f588 <__gmp_doscan@@Base+0x820>  // b.lo, b.ul, b.last
   4f560:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f564:	ldr	x8, [x8, #3792]
   4f568:	add	x20, x27, #0x200
   4f56c:	mov	x0, x26
   4f570:	mov	x1, x27
   4f574:	ldr	x8, [x8]
   4f578:	mov	x2, x20
   4f57c:	blr	x8
   4f580:	mov	x26, x0
   4f584:	mov	x27, x20
   4f588:	ldr	w8, [sp, #84]
   4f58c:	strb	wzr, [x26, x22]
   4f590:	and	w8, w8, #0xff
   4f594:	cmp	w8, #0x5a
   4f598:	b.eq	4f628 <__gmp_doscan@@Base+0x8c0>  // b.none
   4f59c:	cmp	w8, #0x51
   4f5a0:	b.eq	4f63c <__gmp_doscan@@Base+0x8d4>  // b.none
   4f5a4:	cmp	w8, #0x46
   4f5a8:	b.ne	4f550 <__gmp_doscan@@Base+0x7e8>  // b.any
   4f5ac:	ldr	x8, [sp, #24]
   4f5b0:	cbz	x8, 4f650 <__gmp_doscan@@Base+0x8e8>
   4f5b4:	add	x20, x26, x8
   4f5b8:	ldr	w8, [sp, #44]
   4f5bc:	ldr	x19, [sp, #48]
   4f5c0:	mov	w9, #0x10                  	// #16
   4f5c4:	mov	x1, x26
   4f5c8:	cmp	w8, #0x0
   4f5cc:	mov	w8, #0xa                   	// #10
   4f5d0:	csel	w2, w8, w9, eq  // eq = none
   4f5d4:	mov	x0, x19
   4f5d8:	strb	wzr, [x20], #1
   4f5dc:	bl	c1d0 <__gmpf_set_str@plt>
   4f5e0:	sub	x1, x29, #0x10
   4f5e4:	mov	w2, #0xa                   	// #10
   4f5e8:	mov	x0, x20
   4f5ec:	bl	cb80 <strtol@plt>
   4f5f0:	mov	x2, x0
   4f5f4:	tbnz	x0, #63, 4f674 <__gmp_doscan@@Base+0x90c>
   4f5f8:	mov	x0, x19
   4f5fc:	mov	x1, x19
   4f600:	bl	cdb0 <__gmpf_mul_2exp@plt>
   4f604:	b	4f550 <__gmp_doscan@@Base+0x7e8>
   4f608:	ldr	x21, [sp, #8]
   4f60c:	mov	w19, #0x1                   	// #1
   4f610:	mov	w24, w20
   4f614:	b	4f6a4 <__gmp_doscan@@Base+0x93c>
   4f618:	mov	x25, x9
   4f61c:	cmp	w8, #0x5d
   4f620:	b.eq	4f70c <__gmp_doscan@@Base+0x9a4>  // b.none
   4f624:	b	4f710 <__gmp_doscan@@Base+0x9a8>
   4f628:	ldr	x0, [sp, #48]
   4f62c:	ldr	w2, [sp, #40]
   4f630:	mov	x1, x26
   4f634:	bl	c0e0 <__gmpz_set_str@plt>
   4f638:	b	4f550 <__gmp_doscan@@Base+0x7e8>
   4f63c:	ldr	x0, [sp, #48]
   4f640:	ldr	w2, [sp, #40]
   4f644:	mov	x1, x26
   4f648:	bl	bff0 <__gmpq_set_str@plt>
   4f64c:	b	4f550 <__gmp_doscan@@Base+0x7e8>
   4f650:	ldr	w8, [sp, #44]
   4f654:	ldr	x0, [sp, #48]
   4f658:	mov	w9, #0x10                  	// #16
   4f65c:	mov	x1, x26
   4f660:	cmp	w8, #0x0
   4f664:	mov	w8, #0xa                   	// #10
   4f668:	csel	w2, w8, w9, eq  // eq = none
   4f66c:	bl	c1d0 <__gmpf_set_str@plt>
   4f670:	b	4f550 <__gmp_doscan@@Base+0x7e8>
   4f674:	neg	x2, x2
   4f678:	mov	x0, x19
   4f67c:	mov	x1, x19
   4f680:	bl	d4e0 <__gmpf_div_2exp@plt>
   4f684:	b	4f550 <__gmp_doscan@@Base+0x7e8>
   4f688:	mov	w24, w20
   4f68c:	b	4f548 <__gmp_doscan@@Base+0x7e0>
   4f690:	mov	x19, x20
   4f694:	cbnz	w9, 4f544 <__gmp_doscan@@Base+0x7dc>
   4f698:	b	4f6a0 <__gmp_doscan@@Base+0x938>
   4f69c:	mov	w28, #0x2f                  	// #47
   4f6a0:	mov	w19, #0x1                   	// #1
   4f6a4:	ldur	w8, [x29, #-76]
   4f6a8:	add	w8, w8, #0x1
   4f6ac:	cmp	w24, w8
   4f6b0:	b.eq	4f6c4 <__gmp_doscan@@Base+0x95c>  // b.none
   4f6b4:	ldp	x8, x1, [x29, #-72]
   4f6b8:	mov	w0, w28
   4f6bc:	ldr	x8, [x8, #24]
   4f6c0:	blr	x8
   4f6c4:	adrp	x28, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f6c8:	ldr	x28, [x28, #4016]
   4f6cc:	mov	x0, x26
   4f6d0:	mov	x1, x27
   4f6d4:	ldr	x8, [x28]
   4f6d8:	blr	x8
   4f6dc:	cbnz	w19, 4f84c <__gmp_doscan@@Base+0xae4>
   4f6e0:	ldr	w27, [sp, #76]
   4f6e4:	adrp	x26, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4f6e8:	sub	w8, w24, #0x1
   4f6ec:	cmn	w24, #0x1
   4f6f0:	add	x26, x26, #0x6b8
   4f6f4:	stur	w8, [x29, #-52]
   4f6f8:	b.eq	4f840 <__gmp_doscan@@Base+0xad8>  // b.none
   4f6fc:	cbz	w24, 4f7f8 <__gmp_doscan@@Base+0xa90>
   4f700:	ldr	w9, [sp, #68]
   4f704:	add	w20, w9, w8
   4f708:	b	4f7dc <__gmp_doscan@@Base+0xa74>
   4f70c:	ldrb	w8, [x25], #1
   4f710:	cmp	w8, #0x5d
   4f714:	b.eq	4f720 <__gmp_doscan@@Base+0x9b8>  // b.none
   4f718:	cbnz	w8, 4f70c <__gmp_doscan@@Base+0x9a4>
   4f71c:	b	4f7f8 <__gmp_doscan@@Base+0xa90>
   4f720:	sub	x19, x25, x1
   4f724:	mov	x0, x21
   4f728:	mov	x2, x19
   4f72c:	bl	bee0 <memcpy@plt>
   4f730:	add	x8, x21, x19
   4f734:	mov	w9, #0x6e25                	// #28197
   4f738:	strh	w9, [x8]
   4f73c:	strb	wzr, [x8, #2]
   4f740:	mov	w8, #0xffffffff            	// #-1
   4f744:	stur	w8, [x29, #-52]
   4f748:	ldr	w8, [sp, #80]
   4f74c:	cbz	w8, 4f76c <__gmp_doscan@@Base+0xa04>
   4f750:	ldp	x8, x0, [x29, #-72]
   4f754:	sub	x2, x29, #0x34
   4f758:	mov	x1, x21
   4f75c:	mov	x3, xzr
   4f760:	ldr	x8, [x8]
   4f764:	blr	x8
   4f768:	b	4f7b8 <__gmp_doscan@@Base+0xa50>
   4f76c:	ldursw	x8, [x29, #-24]
   4f770:	tbz	w8, #31, 4f790 <__gmp_doscan@@Base+0xa28>
   4f774:	add	w9, w8, #0x8
   4f778:	cmn	w8, #0x8
   4f77c:	stur	w9, [x29, #-24]
   4f780:	b.gt	4f790 <__gmp_doscan@@Base+0xa28>
   4f784:	ldur	x9, [x29, #-40]
   4f788:	add	x8, x9, x8
   4f78c:	b	4f79c <__gmp_doscan@@Base+0xa34>
   4f790:	ldur	x8, [x29, #-48]
   4f794:	add	x9, x8, #0x8
   4f798:	stur	x9, [x29, #-48]
   4f79c:	ldr	x2, [x8]
   4f7a0:	ldp	x8, x0, [x29, #-72]
   4f7a4:	sub	x3, x29, #0x34
   4f7a8:	mov	x1, x21
   4f7ac:	ldr	x8, [x8]
   4f7b0:	blr	x8
   4f7b4:	cbz	w0, 4f7f8 <__gmp_doscan@@Base+0xa90>
   4f7b8:	cmn	w0, #0x1
   4f7bc:	b.eq	4f840 <__gmp_doscan@@Base+0xad8>  // b.none
   4f7c0:	ldur	w1, [x29, #-52]
   4f7c4:	cmn	w1, #0x1
   4f7c8:	b.eq	4f7f8 <__gmp_doscan@@Base+0xa90>  // b.none
   4f7cc:	ldp	x8, x0, [x29, #-72]
   4f7d0:	add	w20, w1, w20
   4f7d4:	ldr	x8, [x8, #8]
   4f7d8:	blr	x8
   4f7dc:	ldr	w8, [sp, #80]
   4f7e0:	ldrb	w23, [x25]
   4f7e4:	eor	w8, w8, #0x1
   4f7e8:	add	w27, w27, w8
   4f7ec:	cbnz	w23, 4ede8 <__gmp_doscan@@Base+0x80>
   4f7f0:	b	4f7f8 <__gmp_doscan@@Base+0xa90>
   4f7f4:	mov	w27, wzr
   4f7f8:	ldr	x8, [x28]
   4f7fc:	ldr	x1, [sp, #16]
   4f800:	mov	x0, x21
   4f804:	blr	x8
   4f808:	mov	w0, w27
   4f80c:	ldp	x20, x19, [sp, #256]
   4f810:	ldp	x22, x21, [sp, #240]
   4f814:	ldp	x24, x23, [sp, #224]
   4f818:	ldp	x26, x25, [sp, #208]
   4f81c:	ldp	x28, x27, [sp, #192]
   4f820:	ldp	x29, x30, [sp, #176]
   4f824:	add	sp, sp, #0x110
   4f828:	ret
   4f82c:	mov	w8, #0xfffffffe            	// #-2
   4f830:	stur	w8, [x29, #-52]
   4f834:	adrp	x28, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f838:	ldr	x28, [x28, #4016]
   4f83c:	ldr	w27, [sp, #76]
   4f840:	cbnz	w27, 4f7f8 <__gmp_doscan@@Base+0xa90>
   4f844:	mov	w27, #0xffffffff            	// #-1
   4f848:	b	4f7f8 <__gmp_doscan@@Base+0xa90>
   4f84c:	ldr	w27, [sp, #76]
   4f850:	mov	w8, #0xffffffff            	// #-1
   4f854:	stur	w8, [x29, #-52]
   4f858:	b	4f7f8 <__gmp_doscan@@Base+0xa90>
   4f85c:	ldp	x8, x1, [x29, #-72]
   4f860:	mov	w19, w0
   4f864:	ldr	x8, [x8, #24]
   4f868:	blr	x8
   4f86c:	cbnz	w27, 4f7f8 <__gmp_doscan@@Base+0xa90>
   4f870:	cmn	w19, #0x1
   4f874:	b.eq	4f844 <__gmp_doscan@@Base+0xadc>  // b.none
   4f878:	b	4f7f8 <__gmp_doscan@@Base+0xa90>
   4f87c:	stp	x29, x30, [sp, #-48]!
   4f880:	stp	x22, x21, [sp, #16]
   4f884:	stp	x20, x19, [sp, #32]
   4f888:	mov	x20, x1
   4f88c:	mov	x21, x0
   4f890:	mov	w19, #0xffffffff            	// #-1
   4f894:	mov	x29, sp
   4f898:	ldr	x8, [x21, #16]
   4f89c:	mov	x0, x20
   4f8a0:	blr	x8
   4f8a4:	mov	w22, w0
   4f8a8:	bl	cb00 <__ctype_b_loc@plt>
   4f8ac:	ldr	x8, [x0]
   4f8b0:	add	w19, w19, #0x1
   4f8b4:	ldrh	w8, [x8, w22, sxtw #1]
   4f8b8:	tbnz	w8, #13, 4f898 <__gmp_doscan@@Base+0xb30>
   4f8bc:	ldr	x8, [x21, #24]
   4f8c0:	mov	w0, w22
   4f8c4:	mov	x1, x20
   4f8c8:	blr	x8
   4f8cc:	mov	w0, w19
   4f8d0:	ldp	x20, x19, [sp, #32]
   4f8d4:	ldp	x22, x21, [sp, #16]
   4f8d8:	ldp	x29, x30, [sp], #48
   4f8dc:	ret

000000000004f8e0 <__gmp_fscanf@@Base>:
   4f8e0:	sub	sp, sp, #0x100
   4f8e4:	stp	x29, x30, [sp, #240]
   4f8e8:	add	x29, sp, #0xf0
   4f8ec:	mov	x9, #0xffffffffffffffd0    	// #-48
   4f8f0:	mov	x10, sp
   4f8f4:	sub	x11, x29, #0x70
   4f8f8:	movk	x9, #0xff80, lsl #32
   4f8fc:	add	x12, x29, #0x10
   4f900:	add	x10, x10, #0x80
   4f904:	add	x11, x11, #0x30
   4f908:	stp	x10, x9, [x29, #-16]
   4f90c:	stp	x12, x11, [x29, #-32]
   4f910:	stp	x2, x3, [x29, #-112]
   4f914:	stp	x4, x5, [x29, #-96]
   4f918:	stp	x6, x7, [x29, #-80]
   4f91c:	stp	q1, q2, [sp, #16]
   4f920:	str	q0, [sp]
   4f924:	ldp	q0, q1, [x29, #-32]
   4f928:	mov	x8, x1
   4f92c:	mov	x1, x0
   4f930:	stp	q3, q4, [sp, #48]
   4f934:	stp	q5, q6, [sp, #80]
   4f938:	str	q7, [sp, #112]
   4f93c:	stp	q0, q1, [x29, #-64]
   4f940:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f944:	ldr	x0, [x0, #4064]
   4f948:	sub	x3, x29, #0x40
   4f94c:	mov	x2, x8
   4f950:	bl	c100 <__gmp_doscan@plt>
   4f954:	ldp	x29, x30, [sp, #240]
   4f958:	add	sp, sp, #0x100
   4f95c:	ret
   4f960:	ret

000000000004f964 <__gmp_scanf@@Base>:
   4f964:	sub	sp, sp, #0x120
   4f968:	stp	x29, x30, [sp, #256]
   4f96c:	add	x29, sp, #0x100
   4f970:	mov	x9, #0xffffffffffffffc8    	// #-56
   4f974:	mov	x10, sp
   4f978:	sub	x11, x29, #0x78
   4f97c:	str	x28, [sp, #272]
   4f980:	stp	x1, x2, [x29, #-120]
   4f984:	stp	x3, x4, [x29, #-104]
   4f988:	stp	x5, x6, [x29, #-88]
   4f98c:	stur	x7, [x29, #-72]
   4f990:	stp	q0, q1, [sp]
   4f994:	stp	q2, q3, [sp, #32]
   4f998:	stp	q4, q5, [sp, #64]
   4f99c:	movk	x9, #0xff80, lsl #32
   4f9a0:	add	x12, x29, #0x20
   4f9a4:	adrp	x13, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f9a8:	add	x10, x10, #0x80
   4f9ac:	add	x11, x11, #0x38
   4f9b0:	ldr	x13, [x13, #3888]
   4f9b4:	stp	x10, x9, [x29, #-16]
   4f9b8:	stp	x12, x11, [x29, #-32]
   4f9bc:	ldp	q0, q1, [x29, #-32]
   4f9c0:	mov	x8, x0
   4f9c4:	stp	q6, q7, [sp, #96]
   4f9c8:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4f9cc:	stp	q0, q1, [x29, #-64]
   4f9d0:	ldr	x1, [x13]
   4f9d4:	ldr	x0, [x0, #4064]
   4f9d8:	sub	x3, x29, #0x40
   4f9dc:	mov	x2, x8
   4f9e0:	bl	c100 <__gmp_doscan@plt>
   4f9e4:	ldr	x28, [sp, #272]
   4f9e8:	ldp	x29, x30, [sp, #256]
   4f9ec:	add	sp, sp, #0x120
   4f9f0:	ret

000000000004f9f4 <__gmp_sscanf@@Base>:
   4f9f4:	sub	sp, sp, #0x120
   4f9f8:	stp	x29, x30, [sp, #256]
   4f9fc:	add	x29, sp, #0x100
   4fa00:	mov	x10, #0xffffffffffffffd0    	// #-48
   4fa04:	mov	x11, sp
   4fa08:	add	x12, sp, #0x80
   4fa0c:	movk	x10, #0xff80, lsl #32
   4fa10:	add	x13, x29, #0x20
   4fa14:	add	x11, x11, #0x80
   4fa18:	add	x12, x12, #0x30
   4fa1c:	sub	x9, x29, #0x28
   4fa20:	stp	x11, x10, [x29, #-24]
   4fa24:	stp	x13, x12, [x29, #-40]
   4fa28:	stp	q1, q2, [sp, #16]
   4fa2c:	str	q0, [sp]
   4fa30:	ldp	q0, q1, [x9]
   4fa34:	str	x28, [sp, #272]
   4fa38:	stp	x2, x3, [sp, #128]
   4fa3c:	stp	x4, x5, [sp, #144]
   4fa40:	stp	x6, x7, [sp, #160]
   4fa44:	stp	q3, q4, [sp, #48]
   4fa48:	stp	q5, q6, [sp, #80]
   4fa4c:	str	q7, [sp, #112]
   4fa50:	stur	x0, [x29, #-8]
   4fa54:	stp	q0, q1, [x29, #-80]
   4fa58:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4fa5c:	ldr	x0, [x0, #3984]
   4fa60:	mov	x8, x1
   4fa64:	sub	x1, x29, #0x8
   4fa68:	sub	x3, x29, #0x50
   4fa6c:	mov	x2, x8
   4fa70:	bl	c100 <__gmp_doscan@plt>
   4fa74:	ldr	x28, [sp, #272]
   4fa78:	ldp	x29, x30, [sp, #256]
   4fa7c:	add	sp, sp, #0x120
   4fa80:	ret
   4fa84:	sub	sp, sp, #0xe0
   4fa88:	stp	x29, x30, [sp, #208]
   4fa8c:	add	x29, sp, #0xd0
   4fa90:	mov	x8, #0xffffffffffffffd0    	// #-48
   4fa94:	mov	x10, sp
   4fa98:	movk	x8, #0xff80, lsl #32
   4fa9c:	sub	x11, x29, #0x50
   4faa0:	add	x10, x10, #0x80
   4faa4:	add	x12, x29, #0x10
   4faa8:	mov	w9, #0xffffffd0            	// #-48
   4faac:	add	x11, x11, #0x30
   4fab0:	stp	x10, x8, [x29, #-16]
   4fab4:	mov	w8, #0xffffffd0            	// #-48
   4fab8:	stp	x2, x3, [x29, #-80]
   4fabc:	stp	x4, x5, [x29, #-64]
   4fac0:	stp	x6, x7, [x29, #-48]
   4fac4:	stp	q1, q2, [sp, #16]
   4fac8:	stp	q3, q4, [sp, #48]
   4facc:	str	q0, [sp]
   4fad0:	stp	q5, q6, [sp, #80]
   4fad4:	str	q7, [sp, #112]
   4fad8:	stp	x12, x11, [x29, #-32]
   4fadc:	tbz	w9, #31, 4fb00 <__gmp_sscanf@@Base+0x10c>
   4fae0:	add	w8, w9, #0x8
   4fae4:	cmn	w9, #0x8
   4fae8:	stur	w8, [x29, #-8]
   4faec:	b.gt	4fb00 <__gmp_sscanf@@Base+0x10c>
   4faf0:	ldur	x9, [x29, #-24]
   4faf4:	mov	x10, #0xffffffffffffffd0    	// #-48
   4faf8:	add	x9, x9, x10
   4fafc:	b	4fb0c <__gmp_sscanf@@Base+0x118>
   4fb00:	ldur	x9, [x29, #-32]
   4fb04:	add	x10, x9, #0x8
   4fb08:	stur	x10, [x29, #-32]
   4fb0c:	ldr	x2, [x9]
   4fb10:	tbz	w8, #31, 4fb30 <__gmp_sscanf@@Base+0x13c>
   4fb14:	add	w9, w8, #0x8
   4fb18:	cmn	w8, #0x8
   4fb1c:	stur	w9, [x29, #-8]
   4fb20:	b.gt	4fb30 <__gmp_sscanf@@Base+0x13c>
   4fb24:	ldur	x9, [x29, #-24]
   4fb28:	add	x8, x9, w8, sxtw
   4fb2c:	b	4fb3c <__gmp_sscanf@@Base+0x148>
   4fb30:	ldur	x8, [x29, #-32]
   4fb34:	add	x9, x8, #0x8
   4fb38:	stur	x9, [x29, #-32]
   4fb3c:	ldr	x3, [x8]
   4fb40:	ldr	x0, [x0]
   4fb44:	bl	d120 <__isoc99_sscanf@plt>
   4fb48:	ldp	x29, x30, [sp, #208]
   4fb4c:	add	sp, sp, #0xe0
   4fb50:	ret
   4fb54:	ldr	x8, [x0]
   4fb58:	add	x8, x8, w1, sxtw
   4fb5c:	str	x8, [x0]
   4fb60:	ret
   4fb64:	ldr	x9, [x0]
   4fb68:	mov	x8, x0
   4fb6c:	ldrb	w0, [x9]
   4fb70:	cbz	w0, 4fb80 <__gmp_sscanf@@Base+0x18c>
   4fb74:	add	x9, x9, #0x1
   4fb78:	str	x9, [x8]
   4fb7c:	ret
   4fb80:	mov	w0, #0xffffffff            	// #-1
   4fb84:	ret
   4fb88:	cmn	w0, #0x1
   4fb8c:	b.eq	4fb9c <__gmp_sscanf@@Base+0x1a8>  // b.none
   4fb90:	ldr	x8, [x1]
   4fb94:	sub	x8, x8, #0x1
   4fb98:	str	x8, [x1]
   4fb9c:	ret

000000000004fba0 <__gmp_vfscanf@@Base>:
   4fba0:	sub	sp, sp, #0x30
   4fba4:	stp	x29, x30, [sp, #32]
   4fba8:	ldp	q1, q0, [x2]
   4fbac:	mov	x8, x1
   4fbb0:	mov	x1, x0
   4fbb4:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4fbb8:	stp	q1, q0, [sp]
   4fbbc:	ldr	x0, [x0, #4064]
   4fbc0:	mov	x3, sp
   4fbc4:	mov	x2, x8
   4fbc8:	add	x29, sp, #0x20
   4fbcc:	bl	c100 <__gmp_doscan@plt>
   4fbd0:	ldp	x29, x30, [sp, #32]
   4fbd4:	add	sp, sp, #0x30
   4fbd8:	ret

000000000004fbdc <__gmp_vscanf@@Base>:
   4fbdc:	sub	sp, sp, #0x30
   4fbe0:	stp	x29, x30, [sp, #32]
   4fbe4:	ldp	q0, q1, [x1]
   4fbe8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4fbec:	ldr	x8, [x8, #3888]
   4fbf0:	mov	x2, x0
   4fbf4:	stp	q0, q1, [sp]
   4fbf8:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4fbfc:	ldr	x1, [x8]
   4fc00:	ldr	x0, [x0, #4064]
   4fc04:	mov	x3, sp
   4fc08:	add	x29, sp, #0x20
   4fc0c:	bl	c100 <__gmp_doscan@plt>
   4fc10:	ldp	x29, x30, [sp, #32]
   4fc14:	add	sp, sp, #0x30
   4fc18:	ret

000000000004fc1c <__gmp_vsscanf@@Base>:
   4fc1c:	sub	sp, sp, #0x40
   4fc20:	stp	x29, x30, [sp, #48]
   4fc24:	add	x29, sp, #0x30
   4fc28:	stur	x0, [x29, #-8]
   4fc2c:	ldp	q1, q0, [x2]
   4fc30:	adrp	x0, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4fc34:	mov	x8, x1
   4fc38:	sub	x1, x29, #0x8
   4fc3c:	stp	q1, q0, [sp]
   4fc40:	ldr	x0, [x0, #3984]
   4fc44:	mov	x3, sp
   4fc48:	mov	x2, x8
   4fc4c:	bl	c100 <__gmp_doscan@plt>
   4fc50:	ldp	x29, x30, [sp, #48]
   4fc54:	add	sp, sp, #0x40
   4fc58:	ret

000000000004fc5c <__gmp_randinit@@Base>:
   4fc5c:	sub	sp, sp, #0xe0
   4fc60:	stp	x29, x30, [sp, #208]
   4fc64:	add	x29, sp, #0xd0
   4fc68:	mov	x8, #0xffffffffffffffd0    	// #-48
   4fc6c:	mov	x9, sp
   4fc70:	sub	x10, x29, #0x50
   4fc74:	movk	x8, #0xff80, lsl #32
   4fc78:	add	x11, x29, #0x10
   4fc7c:	add	x9, x9, #0x80
   4fc80:	add	x10, x10, #0x30
   4fc84:	stp	x2, x3, [x29, #-80]
   4fc88:	stp	x4, x5, [x29, #-64]
   4fc8c:	stp	x6, x7, [x29, #-48]
   4fc90:	stp	q1, q2, [sp, #16]
   4fc94:	stp	q3, q4, [sp, #48]
   4fc98:	str	q0, [sp]
   4fc9c:	stp	q5, q6, [sp, #80]
   4fca0:	str	q7, [sp, #112]
   4fca4:	stp	x9, x8, [x29, #-16]
   4fca8:	stp	x11, x10, [x29, #-32]
   4fcac:	cbz	w1, 4fccc <__gmp_randinit@@Base+0x70>
   4fcb0:	mov	w8, #0x1                   	// #1
   4fcb4:	adrp	x9, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4fcb8:	ldr	x9, [x9, #3896]
   4fcbc:	ldr	w10, [x9]
   4fcc0:	orr	w8, w10, w8
   4fcc4:	str	w8, [x9]
   4fcc8:	b	4fd08 <__gmp_randinit@@Base+0xac>
   4fccc:	ldursw	x8, [x29, #-8]
   4fcd0:	tbz	w8, #31, 4fcf0 <__gmp_randinit@@Base+0x94>
   4fcd4:	add	w9, w8, #0x8
   4fcd8:	cmn	w8, #0x8
   4fcdc:	stur	w9, [x29, #-8]
   4fce0:	b.gt	4fcf0 <__gmp_randinit@@Base+0x94>
   4fce4:	ldur	x9, [x29, #-24]
   4fce8:	add	x8, x9, x8
   4fcec:	b	4fcfc <__gmp_randinit@@Base+0xa0>
   4fcf0:	ldur	x8, [x29, #-32]
   4fcf4:	add	x9, x8, #0x8
   4fcf8:	stur	x9, [x29, #-32]
   4fcfc:	ldr	x1, [x8]
   4fd00:	bl	d1b0 <__gmp_randinit_lc_2exp_size@plt>
   4fd04:	cbz	w0, 4fd14 <__gmp_randinit@@Base+0xb8>
   4fd08:	ldp	x29, x30, [sp, #208]
   4fd0c:	add	sp, sp, #0xe0
   4fd10:	ret
   4fd14:	mov	w8, #0x8                   	// #8
   4fd18:	b	4fcb4 <__gmp_randinit@@Base+0x58>

000000000004fd1c <__gmp_randclear@@Base>:
   4fd1c:	ldr	x8, [x0, #24]
   4fd20:	ldr	x1, [x8, #16]
   4fd24:	br	x1

000000000004fd28 <__gmp_randinit_default@@Base>:
   4fd28:	b	cb20 <__gmp_randinit_mt@plt>

000000000004fd2c <__gmp_randinit_set@@Base>:
   4fd2c:	ldr	x8, [x1, #24]
   4fd30:	ldr	x2, [x8, #24]
   4fd34:	br	x2

000000000004fd38 <__gmp_randinit_lc_2exp_size@@Base>:
   4fd38:	sub	sp, sp, #0x30
   4fd3c:	stp	x20, x19, [sp, #32]
   4fd40:	adrp	x20, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4fd44:	mov	x19, x0
   4fd48:	add	x20, x20, #0xae0
   4fd4c:	mov	w8, #0x20                  	// #32
   4fd50:	stp	x29, x30, [sp, #16]
   4fd54:	add	x29, sp, #0x10
   4fd58:	cmp	x1, x8, lsr #1
   4fd5c:	b.ls	4fd74 <__gmp_randinit_lc_2exp_size@@Base+0x3c>  // b.plast
   4fd60:	ldr	x8, [x20, #8]
   4fd64:	add	x20, x20, #0x18
   4fd68:	cbnz	x8, 4fd58 <__gmp_randinit_lc_2exp_size@@Base+0x20>
   4fd6c:	mov	w0, wzr
   4fd70:	b	4fda4 <__gmp_randinit_lc_2exp_size@@Base+0x6c>
   4fd74:	ldur	x1, [x20, #-8]
   4fd78:	mov	x0, sp
   4fd7c:	mov	w2, #0x10                  	// #16
   4fd80:	bl	d0c0 <__gmpz_init_set_str@plt>
   4fd84:	ldr	x2, [x20]
   4fd88:	ldur	x3, [x20, #-16]
   4fd8c:	mov	x1, sp
   4fd90:	mov	x0, x19
   4fd94:	bl	cf60 <__gmp_randinit_lc_2exp@plt>
   4fd98:	mov	x0, sp
   4fd9c:	bl	cb70 <__gmpz_clear@plt>
   4fda0:	mov	w0, #0x1                   	// #1
   4fda4:	ldp	x20, x19, [sp, #32]
   4fda8:	ldp	x29, x30, [sp, #16]
   4fdac:	add	sp, sp, #0x30
   4fdb0:	ret

000000000004fdb4 <__gmp_randinit_lc_2exp@@Base>:
   4fdb4:	stp	x29, x30, [sp, #-64]!
   4fdb8:	stp	x24, x23, [sp, #16]
   4fdbc:	stp	x22, x21, [sp, #32]
   4fdc0:	stp	x20, x19, [sp, #48]
   4fdc4:	mov	x29, sp
   4fdc8:	cbz	x3, 4fea8 <__gmp_randinit_lc_2exp@@Base+0xf4>
   4fdcc:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4fdd0:	ldr	x8, [x8, #3840]
   4fdd4:	mov	x23, x0
   4fdd8:	add	x9, x3, #0x3f
   4fddc:	mov	w0, #0x38                  	// #56
   4fde0:	ldr	x8, [x8]
   4fde4:	mov	x19, x3
   4fde8:	mov	x20, x2
   4fdec:	mov	x22, x1
   4fdf0:	lsr	x24, x9, #6
   4fdf4:	blr	x8
   4fdf8:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   4fdfc:	add	x8, x8, #0xc80
   4fe00:	mov	x1, x19
   4fe04:	mov	x21, x0
   4fe08:	str	x0, [x23, #8]
   4fe0c:	str	x8, [x23, #24]
   4fe10:	bl	d150 <__gmpz_init2@plt>
   4fe14:	cbz	x24, 4fe28 <__gmp_randinit_lc_2exp@@Base+0x74>
   4fe18:	ldr	x0, [x21, #8]
   4fe1c:	lsl	x2, x24, #3
   4fe20:	mov	w1, wzr
   4fe24:	bl	c610 <memset@plt>
   4fe28:	ldr	x8, [x21, #8]
   4fe2c:	add	x23, x21, #0x10
   4fe30:	str	w24, [x21, #4]
   4fe34:	mov	w24, #0x1                   	// #1
   4fe38:	mov	x0, x23
   4fe3c:	str	x24, [x8]
   4fe40:	bl	d270 <__gmpz_init@plt>
   4fe44:	mov	x0, x23
   4fe48:	mov	x1, x22
   4fe4c:	mov	x2, x19
   4fe50:	bl	d0e0 <__gmpz_fdiv_r_2exp@plt>
   4fe54:	ldr	w8, [x21, #20]
   4fe58:	cbnz	w8, 4fe74 <__gmp_randinit_lc_2exp@@Base+0xc0>
   4fe5c:	ldr	w8, [x21, #16]
   4fe60:	str	w24, [x21, #20]
   4fe64:	cmp	w8, #0x0
   4fe68:	b.le	4fe98 <__gmp_randinit_lc_2exp@@Base+0xe4>
   4fe6c:	ldr	x0, [x21, #24]
   4fe70:	str	xzr, [x0]
   4fe74:	cmp	x20, #0x0
   4fe78:	cset	w8, ne  // ne = any
   4fe7c:	stp	x8, x20, [x21, #32]
   4fe80:	str	x19, [x21, #48]
   4fe84:	ldp	x20, x19, [sp, #48]
   4fe88:	ldp	x22, x21, [sp, #32]
   4fe8c:	ldp	x24, x23, [sp, #16]
   4fe90:	ldp	x29, x30, [sp], #64
   4fe94:	ret
   4fe98:	mov	w1, #0x1                   	// #1
   4fe9c:	mov	x0, x23
   4fea0:	bl	c090 <__gmpz_realloc@plt>
   4fea4:	b	4fe70 <__gmp_randinit_lc_2exp@@Base+0xbc>
   4fea8:	adrp	x0, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4feac:	adrp	x2, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   4feb0:	add	x0, x0, #0x8e6
   4feb4:	add	x2, x2, #0x8f1
   4feb8:	mov	w1, #0x12d                 	// #301
   4febc:	bl	c6e0 <__gmp_assert_fail@plt>
   4fec0:	stp	x29, x30, [sp, #-32]!
   4fec4:	stp	x20, x19, [sp, #16]
   4fec8:	ldr	x19, [x0, #8]
   4fecc:	mov	x29, sp
   4fed0:	ldr	x2, [x19, #48]
   4fed4:	mov	x0, x19
   4fed8:	add	x8, x2, #0x3f
   4fedc:	lsr	x20, x8, #6
   4fee0:	bl	d0e0 <__gmpz_fdiv_r_2exp@plt>
   4fee4:	ldrsw	x8, [x19, #4]
   4fee8:	subs	x9, x20, x8
   4feec:	b.eq	4ff04 <__gmp_randinit_lc_2exp@@Base+0x150>  // b.none
   4fef0:	ldr	x10, [x19, #8]
   4fef4:	lsl	x2, x9, #3
   4fef8:	mov	w1, wzr
   4fefc:	add	x0, x10, x8, lsl #3
   4ff00:	bl	c610 <memset@plt>
   4ff04:	str	w20, [x19, #4]
   4ff08:	ldp	x20, x19, [sp, #16]
   4ff0c:	ldp	x29, x30, [sp], #32
   4ff10:	ret
   4ff14:	stp	x29, x30, [sp, #-96]!
   4ff18:	stp	x28, x27, [sp, #16]
   4ff1c:	stp	x26, x25, [sp, #32]
   4ff20:	stp	x24, x23, [sp, #48]
   4ff24:	stp	x22, x21, [sp, #64]
   4ff28:	stp	x20, x19, [sp, #80]
   4ff2c:	mov	x29, sp
   4ff30:	sub	sp, sp, #0x10
   4ff34:	ldr	x8, [x0, #8]
   4ff38:	stp	x1, xzr, [x29, #-16]
   4ff3c:	mov	x19, x2
   4ff40:	mov	x21, x0
   4ff44:	ldr	x24, [x8, #48]
   4ff48:	lsr	x25, x24, #1
   4ff4c:	add	w8, w25, #0x3f
   4ff50:	add	w9, w25, #0x7e
   4ff54:	cmp	w8, #0x0
   4ff58:	csel	w23, w9, w8, lt  // lt = tstop
   4ff5c:	asr	w8, w23, #6
   4ff60:	sbfiz	x8, x8, #3, #32
   4ff64:	mov	w9, #0x7f00                	// #32512
   4ff68:	cmp	x8, x9
   4ff6c:	b.hi	50110 <__gmp_randinit_lc_2exp@@Base+0x35c>  // b.pmore
   4ff70:	add	x8, x8, #0xf
   4ff74:	mov	x9, sp
   4ff78:	and	x8, x8, #0xfffffffffffffff0
   4ff7c:	sub	x22, x9, x8
   4ff80:	mov	sp, x22
   4ff84:	cmp	x19, w25, sxtw
   4ff88:	b.cs	4ff94 <__gmp_randinit_lc_2exp@@Base+0x1e0>  // b.hs, b.nlast
   4ff8c:	mov	x26, xzr
   4ff90:	b	50030 <__gmp_randinit_lc_2exp@@Base+0x27c>
   4ff94:	add	w8, w25, #0x3f
   4ff98:	cmp	w25, #0x0
   4ff9c:	csel	w8, w8, w25, lt  // lt = tstop
   4ffa0:	and	w8, w8, #0xffffffc0
   4ffa4:	sub	w8, w25, w8
   4ffa8:	mov	x26, xzr
   4ffac:	sbfx	x23, x23, #6, #26
   4ffb0:	sxtw	x27, w8
   4ffb4:	sbfx	x28, x24, #1, #32
   4ffb8:	ldur	x9, [x29, #-16]
   4ffbc:	lsr	x8, x26, #3
   4ffc0:	and	x8, x8, #0x1ffffffffffffff8
   4ffc4:	ands	x25, x26, #0x3f
   4ffc8:	add	x24, x9, x8
   4ffcc:	b.eq	50014 <__gmp_randinit_lc_2exp@@Base+0x260>  // b.none
   4ffd0:	mov	x0, x22
   4ffd4:	mov	x1, x21
   4ffd8:	bl	501e8 <__gmp_randinit_lc_2exp@@Base+0x434>
   4ffdc:	ldr	x20, [x24]
   4ffe0:	mov	x0, x24
   4ffe4:	mov	x1, x22
   4ffe8:	mov	x2, x23
   4ffec:	mov	w3, w25
   4fff0:	bl	c190 <__gmpn_lshift@plt>
   4fff4:	ldr	x8, [x24]
   4fff8:	add	x9, x25, x27
   4fffc:	cmp	x9, #0x41
   50000:	orr	x8, x8, x20
   50004:	str	x8, [x24]
   50008:	b.cc	50020 <__gmp_randinit_lc_2exp@@Base+0x26c>  // b.lo, b.ul, b.last
   5000c:	str	x0, [x24, x23, lsl #3]
   50010:	b	50020 <__gmp_randinit_lc_2exp@@Base+0x26c>
   50014:	mov	x0, x24
   50018:	mov	x1, x21
   5001c:	bl	501e8 <__gmp_randinit_lc_2exp@@Base+0x434>
   50020:	add	x26, x26, x28
   50024:	add	x8, x28, x26
   50028:	cmp	x8, x19
   5002c:	b.ls	4ffb8 <__gmp_randinit_lc_2exp@@Base+0x204>  // b.plast
   50030:	cmp	x26, x19
   50034:	b.eq	500e8 <__gmp_randinit_lc_2exp@@Base+0x334>  // b.none
   50038:	ldur	x11, [x29, #-16]
   5003c:	sub	w9, w19, w26
   50040:	lsr	x8, x26, #3
   50044:	add	w10, w9, #0x3f
   50048:	and	x8, x8, #0x1ffffffffffffff8
   5004c:	add	w9, w9, #0x7e
   50050:	cmp	w10, #0x0
   50054:	add	x23, x11, x8
   50058:	csel	w8, w9, w10, lt  // lt = tstop
   5005c:	mov	x0, x22
   50060:	mov	x1, x21
   50064:	sbfx	x24, x8, #6, #26
   50068:	bl	501e8 <__gmp_randinit_lc_2exp@@Base+0x434>
   5006c:	ands	x21, x26, #0x3f
   50070:	b.eq	500b0 <__gmp_randinit_lc_2exp@@Base+0x2fc>  // b.none
   50074:	ldr	x20, [x23]
   50078:	mov	x0, x23
   5007c:	mov	x1, x22
   50080:	mov	x2, x24
   50084:	mov	w3, w21
   50088:	bl	c190 <__gmpn_lshift@plt>
   5008c:	ldr	x8, [x23]
   50090:	sub	x9, x26, x21
   50094:	add	x9, x9, x24, lsl #6
   50098:	cmp	x9, x19
   5009c:	orr	x8, x8, x20
   500a0:	str	x8, [x23]
   500a4:	b.cs	500c0 <__gmp_randinit_lc_2exp@@Base+0x30c>  // b.hs, b.nlast
   500a8:	str	x0, [x23, x24, lsl #3]
   500ac:	b	500c0 <__gmp_randinit_lc_2exp@@Base+0x30c>
   500b0:	mov	x0, x23
   500b4:	mov	x1, x22
   500b8:	mov	x2, x24
   500bc:	bl	ca70 <__gmpn_copyi@plt>
   500c0:	ands	x8, x19, #0x3f
   500c4:	b.eq	500e8 <__gmp_randinit_lc_2exp@@Base+0x334>  // b.none
   500c8:	ldur	x12, [x29, #-16]
   500cc:	lsr	x9, x19, #3
   500d0:	and	x9, x9, #0x1ffffffffffffff8
   500d4:	mov	x11, #0xffffffffffffffff    	// #-1
   500d8:	ldr	x10, [x12, x9]
   500dc:	lsl	x8, x11, x8
   500e0:	bic	x8, x10, x8
   500e4:	str	x8, [x12, x9]
   500e8:	ldur	x0, [x29, #-8]
   500ec:	cbnz	x0, 50124 <__gmp_randinit_lc_2exp@@Base+0x370>
   500f0:	mov	sp, x29
   500f4:	ldp	x20, x19, [sp, #80]
   500f8:	ldp	x22, x21, [sp, #64]
   500fc:	ldp	x24, x23, [sp, #48]
   50100:	ldp	x26, x25, [sp, #32]
   50104:	ldp	x28, x27, [sp, #16]
   50108:	ldp	x29, x30, [sp], #96
   5010c:	ret
   50110:	sub	x0, x29, #0x8
   50114:	mov	x1, x8
   50118:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   5011c:	mov	x22, x0
   50120:	b	4ff84 <__gmp_randinit_lc_2exp@@Base+0x1d0>
   50124:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   50128:	b	500f0 <__gmp_randinit_lc_2exp@@Base+0x33c>
   5012c:	stp	x29, x30, [sp, #-32]!
   50130:	str	x19, [sp, #16]
   50134:	ldr	x19, [x0, #8]
   50138:	mov	x29, sp
   5013c:	mov	x0, x19
   50140:	bl	cb70 <__gmpz_clear@plt>
   50144:	add	x0, x19, #0x10
   50148:	bl	cb70 <__gmpz_clear@plt>
   5014c:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   50150:	ldr	x8, [x8, #4016]
   50154:	mov	x0, x19
   50158:	ldr	x19, [sp, #16]
   5015c:	mov	w1, #0x38                  	// #56
   50160:	ldr	x2, [x8]
   50164:	ldp	x29, x30, [sp], #32
   50168:	br	x2
   5016c:	stp	x29, x30, [sp, #-48]!
   50170:	str	x21, [sp, #16]
   50174:	stp	x20, x19, [sp, #32]
   50178:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   5017c:	ldr	x19, [x1, #8]
   50180:	ldr	x8, [x8, #3840]
   50184:	mov	x20, x0
   50188:	mov	w0, #0x38                  	// #56
   5018c:	mov	x29, sp
   50190:	ldr	x8, [x8]
   50194:	blr	x8
   50198:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   5019c:	add	x8, x8, #0xc80
   501a0:	mov	x1, x19
   501a4:	mov	x21, x0
   501a8:	str	x0, [x20, #8]
   501ac:	str	x8, [x20, #24]
   501b0:	bl	bf90 <__gmpz_init_set@plt>
   501b4:	add	x0, x21, #0x10
   501b8:	add	x1, x19, #0x10
   501bc:	bl	bf90 <__gmpz_init_set@plt>
   501c0:	ldr	x8, [x19, #32]
   501c4:	str	x8, [x21, #32]
   501c8:	ldr	x8, [x19, #40]
   501cc:	str	x8, [x21, #40]
   501d0:	ldr	x8, [x19, #48]
   501d4:	str	x8, [x21, #48]
   501d8:	ldp	x20, x19, [sp, #32]
   501dc:	ldr	x21, [sp, #16]
   501e0:	ldp	x29, x30, [sp], #48
   501e4:	ret
   501e8:	stp	x29, x30, [sp, #-96]!
   501ec:	stp	x28, x27, [sp, #16]
   501f0:	stp	x26, x25, [sp, #32]
   501f4:	stp	x24, x23, [sp, #48]
   501f8:	stp	x22, x21, [sp, #64]
   501fc:	stp	x20, x19, [sp, #80]
   50200:	mov	x29, sp
   50204:	sub	sp, sp, #0x10
   50208:	ldr	x27, [x1, #8]
   5020c:	ldr	x26, [x27, #48]
   50210:	ldrsw	x22, [x27, #4]
   50214:	ldrsw	x23, [x27, #20]
   50218:	ldr	x25, [x27, #8]
   5021c:	ldr	x24, [x27, #24]
   50220:	add	x8, x26, #0x3f
   50224:	add	x28, x23, x22
   50228:	cmp	x28, x8, lsr #6
   5022c:	lsr	x20, x8, #6
   50230:	stp	x0, xzr, [x29, #-16]
   50234:	b.ge	5027c <__gmp_randinit_lc_2exp@@Base+0x4c8>  // b.tcont
   50238:	add	x19, x20, #0x1
   5023c:	lsr	x8, x8, #11
   50240:	cmp	x8, #0x7e
   50244:	lsl	x1, x19, #3
   50248:	b.hi	50394 <__gmp_randinit_lc_2exp@@Base+0x5e0>  // b.pmore
   5024c:	add	x9, x1, #0xf
   50250:	mov	x8, sp
   50254:	and	x9, x9, #0x7ffffffffffffff0
   50258:	sub	x21, x8, x9
   5025c:	mov	sp, x21
   50260:	subs	x8, x19, x28
   50264:	b.eq	502a4 <__gmp_randinit_lc_2exp@@Base+0x4f0>  // b.none
   50268:	add	x0, x21, x28, lsl #3
   5026c:	lsl	x2, x8, #3
   50270:	mov	w1, wzr
   50274:	bl	c610 <memset@plt>
   50278:	b	502a4 <__gmp_randinit_lc_2exp@@Base+0x4f0>
   5027c:	lsl	x8, x28, #3
   50280:	add	x1, x8, #0x8
   50284:	mov	w8, #0x7f00                	// #32512
   50288:	cmp	x1, x8
   5028c:	b.hi	503a4 <__gmp_randinit_lc_2exp@@Base+0x5f0>  // b.pmore
   50290:	add	x9, x1, #0xf
   50294:	mov	x8, sp
   50298:	and	x9, x9, #0xfffffffffffffff0
   5029c:	sub	x21, x8, x9
   502a0:	mov	sp, x21
   502a4:	mov	x0, x21
   502a8:	mov	x1, x25
   502ac:	mov	x2, x22
   502b0:	mov	x3, x24
   502b4:	mov	x4, x23
   502b8:	bl	ccf0 <__gmpn_mul@plt>
   502bc:	ldr	x22, [x27, #32]
   502c0:	cbz	x22, 502fc <__gmp_randinit_lc_2exp@@Base+0x548>
   502c4:	add	x2, x27, #0x28
   502c8:	mov	x0, x21
   502cc:	mov	x1, x21
   502d0:	mov	x3, x22
   502d4:	bl	ca90 <__gmpn_add_n@plt>
   502d8:	cbz	x0, 502fc <__gmp_randinit_lc_2exp@@Base+0x548>
   502dc:	cmp	x22, x20
   502e0:	b.ge	502fc <__gmp_randinit_lc_2exp@@Base+0x548>  // b.tcont
   502e4:	ldr	x8, [x21, x22, lsl #3]
   502e8:	add	x9, x22, #0x1
   502ec:	adds	x8, x8, #0x1
   502f0:	str	x8, [x21, x22, lsl #3]
   502f4:	mov	x22, x9
   502f8:	b.cs	502dc <__gmp_randinit_lc_2exp@@Base+0x528>  // b.hs, b.nlast
   502fc:	lsr	x8, x26, #3
   50300:	and	x8, x8, #0x1ffffffffffffff8
   50304:	ldr	x9, [x21, x8]
   50308:	mov	x10, #0xffffffffffffffff    	// #-1
   5030c:	lsl	x10, x10, x26
   50310:	mov	x1, x21
   50314:	bic	x9, x9, x10
   50318:	str	x9, [x21, x8]
   5031c:	ldr	x0, [x27, #8]
   50320:	mov	x2, x20
   50324:	bl	ca70 <__gmpn_copyi@plt>
   50328:	sub	x2, x20, x26, lsr #7
   5032c:	cmp	x2, #0x1
   50330:	b.lt	50364 <__gmp_randinit_lc_2exp@@Base+0x5b0>  // b.tstop
   50334:	lsr	x19, x26, #7
   50338:	ubfx	w3, w26, #1, #6
   5033c:	add	x1, x21, x19, lsl #3
   50340:	cbz	w3, 5035c <__gmp_randinit_lc_2exp@@Base+0x5a8>
   50344:	mov	x0, x21
   50348:	bl	c1b0 <__gmpn_rshift@plt>
   5034c:	ldur	x0, [x29, #-16]
   50350:	add	x2, x19, #0x1
   50354:	mov	x1, x21
   50358:	b	50360 <__gmp_randinit_lc_2exp@@Base+0x5ac>
   5035c:	ldur	x0, [x29, #-16]
   50360:	bl	ca70 <__gmpn_copyi@plt>
   50364:	ldur	x0, [x29, #-8]
   50368:	cbnz	x0, 5038c <__gmp_randinit_lc_2exp@@Base+0x5d8>
   5036c:	mov	sp, x29
   50370:	ldp	x20, x19, [sp, #80]
   50374:	ldp	x22, x21, [sp, #64]
   50378:	ldp	x24, x23, [sp, #48]
   5037c:	ldp	x26, x25, [sp, #32]
   50380:	ldp	x28, x27, [sp, #16]
   50384:	ldp	x29, x30, [sp], #96
   50388:	ret
   5038c:	bl	bf00 <__gmp_tmp_reentrant_free@plt>
   50390:	b	5036c <__gmp_randinit_lc_2exp@@Base+0x5b8>
   50394:	sub	x0, x29, #0x8
   50398:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   5039c:	mov	x21, x0
   503a0:	b	50260 <__gmp_randinit_lc_2exp@@Base+0x4ac>
   503a4:	sub	x0, x29, #0x8
   503a8:	bl	cbe0 <__gmp_tmp_reentrant_alloc@plt>
   503ac:	mov	x21, x0
   503b0:	b	502a4 <__gmp_randinit_lc_2exp@@Base+0x4f0>

00000000000503b4 <__gmp_mt_recalc_buffer@@Base>:
   503b4:	ldr	w10, [x0]
   503b8:	mov	w8, #0xb0df                	// #45279
   503bc:	mov	x9, xzr
   503c0:	movk	w8, #0x9908, lsl #16
   503c4:	add	x11, x0, x9
   503c8:	and	w12, w10, #0x80000000
   503cc:	ldr	w10, [x11, #4]
   503d0:	ldr	w13, [x11, #1588]
   503d4:	add	x9, x9, #0x4
   503d8:	cmp	x9, #0x38c
   503dc:	and	w14, w10, #0x7ffffffe
   503e0:	sbfx	w15, w10, #0, #1
   503e4:	orr	w12, w14, w12
   503e8:	and	w14, w15, w8
   503ec:	eor	w12, w13, w12, lsr #1
   503f0:	eor	w12, w12, w14
   503f4:	str	w12, [x11]
   503f8:	b.ne	503c4 <__gmp_mt_recalc_buffer@@Base+0x10>  // b.any
   503fc:	add	x10, x0, #0x38c
   50400:	ld1r	{v4.4s}, [x10]
   50404:	mov	w10, #0xb0df                	// #45279
   50408:	mov	w11, #0x7ffffffe            	// #2147483646
   5040c:	movk	w10, #0x9908, lsl #16
   50410:	mov	x9, xzr
   50414:	movi	v0.4s, #0x80, lsl #24
   50418:	dup	v1.4s, w11
   5041c:	movi	v2.4s, #0x1
   50420:	dup	v3.4s, w10
   50424:	add	x10, x0, x9
   50428:	ldr	q5, [x10, #912]
   5042c:	add	x9, x9, #0x10
   50430:	cmp	x9, #0x630
   50434:	ext	v4.16b, v4.16b, v5.16b, #12
   50438:	and	v6.16b, v5.16b, v1.16b
   5043c:	and	v4.16b, v4.16b, v0.16b
   50440:	orr	v4.16b, v6.16b, v4.16b
   50444:	ldr	q6, [x10]
   50448:	ushr	v4.4s, v4.4s, #1
   5044c:	add	x10, x10, #0x38c
   50450:	eor	v4.16b, v4.16b, v6.16b
   50454:	and	v6.16b, v5.16b, v2.16b
   50458:	cmeq	v6.4s, v6.4s, #0
   5045c:	bic	v6.16b, v3.16b, v6.16b
   50460:	eor	v4.16b, v4.16b, v6.16b
   50464:	str	q4, [x10]
   50468:	mov	v4.16b, v5.16b
   5046c:	b.ne	50424 <__gmp_mt_recalc_buffer@@Base+0x70>  // b.any
   50470:	ldr	w9, [x0, #2492]
   50474:	ldr	w10, [x0]
   50478:	ldr	w11, [x0, #1584]
   5047c:	and	w9, w9, #0x80000000
   50480:	and	w12, w10, #0x7ffffffe
   50484:	sbfx	w10, w10, #0, #1
   50488:	orr	w9, w12, w9
   5048c:	eor	w9, w11, w9, lsr #1
   50490:	and	w8, w10, w8
   50494:	eor	w8, w9, w8
   50498:	str	w8, [x0, #2492]
   5049c:	ret

00000000000504a0 <__gmp_randget_mt@@Base>:
   504a0:	stp	x29, x30, [sp, #-80]!
   504a4:	stp	x26, x25, [sp, #16]
   504a8:	stp	x24, x23, [sp, #32]
   504ac:	stp	x22, x21, [sp, #48]
   504b0:	stp	x20, x19, [sp, #64]
   504b4:	ldr	x20, [x0, #8]
   504b8:	mov	w23, #0x5680                	// #22144
   504bc:	mov	x19, x1
   504c0:	mov	w22, #0xefc60000            	// #-272236544
   504c4:	movk	w23, #0x9d2c, lsl #16
   504c8:	lsr	x21, x2, #6
   504cc:	and	w24, w2, #0x3f
   504d0:	mov	x29, sp
   504d4:	cbz	x21, 50574 <__gmp_randget_mt@@Base+0xd4>
   504d8:	ldr	w8, [x20, #2496]
   504dc:	mov	x25, x19
   504e0:	mov	x26, x21
   504e4:	cmp	w8, #0x26f
   504e8:	b.le	504fc <__gmp_randget_mt@@Base+0x5c>
   504ec:	mov	x0, x20
   504f0:	bl	d480 <__gmp_mt_recalc_buffer@plt>
   504f4:	mov	w8, wzr
   504f8:	str	wzr, [x20, #2496]
   504fc:	add	w10, w8, #0x1
   50500:	str	w10, [x20, #2496]
   50504:	ldr	w9, [x20, w8, sxtw #2]
   50508:	cmp	w8, #0x26f
   5050c:	eor	w9, w9, w9, lsr #11
   50510:	and	w11, w23, w9, lsl #7
   50514:	eor	w9, w11, w9
   50518:	and	w11, w22, w9, lsl #15
   5051c:	eor	w9, w11, w9
   50520:	eor	w9, w9, w9, lsr #18
   50524:	str	x9, [x25]
   50528:	b.lt	50540 <__gmp_randget_mt@@Base+0xa0>  // b.tstop
   5052c:	mov	x0, x20
   50530:	bl	d480 <__gmp_mt_recalc_buffer@plt>
   50534:	str	wzr, [x20, #2496]
   50538:	ldr	x9, [x25]
   5053c:	mov	w10, wzr
   50540:	add	w8, w10, #0x1
   50544:	str	w8, [x20, #2496]
   50548:	ldr	w10, [x20, w10, sxtw #2]
   5054c:	subs	x26, x26, #0x1
   50550:	eor	w10, w10, w10, lsr #11
   50554:	and	w11, w23, w10, lsl #7
   50558:	eor	w10, w11, w10
   5055c:	and	w11, w22, w10, lsl #15
   50560:	eor	w10, w11, w10
   50564:	eor	w10, w10, w10, lsr #18
   50568:	orr	x9, x9, x10, lsl #32
   5056c:	str	x9, [x25], #8
   50570:	b.ne	504e4 <__gmp_randget_mt@@Base+0x44>  // b.any
   50574:	cbz	w24, 50670 <__gmp_randget_mt@@Base+0x1d0>
   50578:	ldr	w8, [x20, #2496]
   5057c:	cmp	w24, #0x1f
   50580:	b.hi	505d0 <__gmp_randget_mt@@Base+0x130>  // b.pmore
   50584:	cmp	w8, #0x270
   50588:	b.lt	5059c <__gmp_randget_mt@@Base+0xfc>  // b.tstop
   5058c:	mov	x0, x20
   50590:	bl	d480 <__gmp_mt_recalc_buffer@plt>
   50594:	mov	w8, wzr
   50598:	str	wzr, [x20, #2496]
   5059c:	add	w9, w8, #0x1
   505a0:	str	w9, [x20, #2496]
   505a4:	ldr	w8, [x20, w8, sxtw #2]
   505a8:	mov	x9, #0xffffffffffffffff    	// #-1
   505ac:	lsl	x9, x9, x24
   505b0:	eor	w8, w8, w8, lsr #11
   505b4:	and	w10, w23, w8, lsl #7
   505b8:	eor	w8, w10, w8
   505bc:	and	w10, w22, w8, lsl #15
   505c0:	eor	w8, w10, w8
   505c4:	eor	w8, w8, w8, lsr #18
   505c8:	bic	x8, x8, x9
   505cc:	b	5066c <__gmp_randget_mt@@Base+0x1cc>
   505d0:	cmp	w8, #0x270
   505d4:	b.lt	505e8 <__gmp_randget_mt@@Base+0x148>  // b.tstop
   505d8:	mov	x0, x20
   505dc:	bl	d480 <__gmp_mt_recalc_buffer@plt>
   505e0:	mov	w8, wzr
   505e4:	str	wzr, [x20, #2496]
   505e8:	add	w10, w8, #0x1
   505ec:	str	w10, [x20, #2496]
   505f0:	ldr	w9, [x20, w8, sxtw #2]
   505f4:	cmp	w24, #0x21
   505f8:	eor	w9, w9, w9, lsr #11
   505fc:	and	w11, w23, w9, lsl #7
   50600:	eor	w9, w11, w9
   50604:	and	w11, w22, w9, lsl #15
   50608:	eor	w9, w11, w9
   5060c:	eor	w9, w9, w9, lsr #18
   50610:	str	x9, [x19, x21, lsl #3]
   50614:	b.cc	50670 <__gmp_randget_mt@@Base+0x1d0>  // b.lo, b.ul, b.last
   50618:	cmp	w8, #0x26f
   5061c:	b.lt	50634 <__gmp_randget_mt@@Base+0x194>  // b.tstop
   50620:	mov	x0, x20
   50624:	bl	d480 <__gmp_mt_recalc_buffer@plt>
   50628:	str	wzr, [x20, #2496]
   5062c:	ldr	x9, [x19, x21, lsl #3]
   50630:	mov	w10, wzr
   50634:	add	w8, w10, #0x1
   50638:	str	w8, [x20, #2496]
   5063c:	ldr	w8, [x20, w10, sxtw #2]
   50640:	sub	w10, w24, #0x20
   50644:	mov	x11, #0xffffffffffffffff    	// #-1
   50648:	lsl	x10, x11, x10
   5064c:	eor	w8, w8, w8, lsr #11
   50650:	and	w12, w23, w8, lsl #7
   50654:	eor	w8, w12, w8
   50658:	and	w12, w22, w8, lsl #15
   5065c:	eor	w8, w12, w8
   50660:	eor	w8, w8, w8, lsr #18
   50664:	bic	w8, w8, w10
   50668:	orr	x8, x9, x8, lsl #32
   5066c:	str	x8, [x19, x21, lsl #3]
   50670:	ldp	x20, x19, [sp, #64]
   50674:	ldp	x22, x21, [sp, #48]
   50678:	ldp	x24, x23, [sp, #32]
   5067c:	ldp	x26, x25, [sp, #16]
   50680:	ldp	x29, x30, [sp], #80
   50684:	ret

0000000000050688 <__gmp_randclear_mt@@Base>:
   50688:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   5068c:	ldr	x8, [x8, #4016]
   50690:	ldrsw	x9, [x0]
   50694:	ldr	x0, [x0, #8]
   50698:	ldr	x2, [x8]
   5069c:	lsl	x1, x9, #3
   506a0:	br	x2

00000000000506a4 <__gmp_randiset_mt@@Base>:
   506a4:	stp	x29, x30, [sp, #-32]!
   506a8:	stp	x20, x19, [sp, #16]
   506ac:	ldr	x8, [x1, #24]
   506b0:	mov	x20, x0
   506b4:	mov	x29, sp
   506b8:	mov	x19, x1
   506bc:	str	x8, [x0, #24]
   506c0:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   506c4:	ldr	x8, [x8, #3840]
   506c8:	mov	w0, #0x9c8                 	// #2504
   506cc:	ldr	x8, [x8]
   506d0:	blr	x8
   506d4:	mov	w8, #0x139                 	// #313
   506d8:	str	x0, [x20, #8]
   506dc:	str	w8, [x20]
   506e0:	ldr	x8, [x19, #8]
   506e4:	mov	x9, xzr
   506e8:	ldr	w10, [x8, x9]
   506ec:	str	w10, [x0, x9]
   506f0:	add	x9, x9, #0x4
   506f4:	cmp	x9, #0x9c0
   506f8:	b.ne	506e8 <__gmp_randiset_mt@@Base+0x44>  // b.any
   506fc:	ldr	w8, [x8, #2496]
   50700:	str	w8, [x0, #2496]
   50704:	ldp	x20, x19, [sp, #16]
   50708:	ldp	x29, x30, [sp], #32
   5070c:	ret

0000000000050710 <__gmp_randinit_mt_noseed@@Base>:
   50710:	stp	x29, x30, [sp, #-32]!
   50714:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   50718:	add	x8, x8, #0xca0
   5071c:	stp	x20, x19, [sp, #16]
   50720:	str	x8, [x0, #24]
   50724:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   50728:	ldr	x8, [x8, #3840]
   5072c:	mov	x19, x0
   50730:	mov	w0, #0x9c8                 	// #2504
   50734:	mov	x29, sp
   50738:	ldr	x8, [x8]
   5073c:	blr	x8
   50740:	adrp	x1, 5c000 <__gmp_jacobi_table@@Base+0x7879>
   50744:	mov	w8, #0x139                 	// #313
   50748:	add	x1, x1, #0x8fc
   5074c:	mov	w2, #0x9c0                 	// #2496
   50750:	mov	x20, x0
   50754:	str	x0, [x19, #8]
   50758:	str	w8, [x19]
   5075c:	bl	bee0 <memcpy@plt>
   50760:	mov	w8, #0x80                  	// #128
   50764:	str	w8, [x20, #2496]
   50768:	ldp	x20, x19, [sp, #16]
   5076c:	ldp	x29, x30, [sp], #32
   50770:	ret

0000000000050774 <__gmp_randinit_mt@@Base>:
   50774:	stp	x29, x30, [sp, #-32]!
   50778:	str	x19, [sp, #16]
   5077c:	mov	x29, sp
   50780:	mov	x19, x0
   50784:	bl	bf40 <__gmp_randinit_mt_noseed@plt>
   50788:	adrp	x8, 6d000 <__gmp_limbroots_table@@Base+0x10cc0>
   5078c:	add	x8, x8, #0xcc0
   50790:	str	x8, [x19, #24]
   50794:	ldr	x19, [sp, #16]
   50798:	ldp	x29, x30, [sp], #32
   5079c:	ret
   507a0:	sub	sp, sp, #0x70
   507a4:	stp	x29, x30, [sp, #64]
   507a8:	stp	x20, x19, [sp, #96]
   507ac:	ldr	x19, [x0, #8]
   507b0:	mov	x20, x1
   507b4:	add	x0, sp, #0x10
   507b8:	mov	w1, #0x4de2                	// #19938
   507bc:	str	x21, [sp, #80]
   507c0:	add	x29, sp, #0x40
   507c4:	bl	d150 <__gmpz_init2@plt>
   507c8:	mov	x0, sp
   507cc:	mov	w1, #0x4de1                	// #19937
   507d0:	bl	d150 <__gmpz_init2@plt>
   507d4:	add	x0, sp, #0x10
   507d8:	mov	w1, #0x4de1                	// #19937
   507dc:	bl	c330 <__gmpz_setbit@plt>
   507e0:	add	x0, sp, #0x10
   507e4:	add	x1, sp, #0x10
   507e8:	mov	w2, #0x4e3b                	// #20027
   507ec:	bl	c130 <__gmpz_sub_ui@plt>
   507f0:	mov	x0, sp
   507f4:	add	x2, sp, #0x10
   507f8:	mov	x1, x20
   507fc:	bl	ce10 <__gmpz_mod@plt>
   50800:	add	x0, sp, #0x10
   50804:	bl	cb70 <__gmpz_clear@plt>
   50808:	mov	x0, sp
   5080c:	mov	x1, sp
   50810:	mov	w2, #0x2                   	// #2
   50814:	bl	c8d0 <__gmpz_add_ui@plt>
   50818:	sub	x0, x29, #0x10
   5081c:	mov	w1, #0x4de1                	// #19937
   50820:	bl	d150 <__gmpz_init2@plt>
   50824:	add	x0, sp, #0x20
   50828:	mov	x1, sp
   5082c:	bl	bf90 <__gmpz_init_set@plt>
   50830:	mov	w21, #0x8124                	// #33060
   50834:	mov	w20, #0x20000000            	// #536870912
   50838:	movk	w21, #0x4011, lsl #16
   5083c:	mov	x2, sp
   50840:	mov	x0, sp
   50844:	mov	x1, sp
   50848:	bl	c4d0 <__gmpz_mul@plt>
   5084c:	sub	x0, x29, #0x10
   50850:	mov	x1, sp
   50854:	mov	w2, #0x4de1                	// #19937
   50858:	bl	cc90 <__gmpz_tdiv_q_2exp@plt>
   5085c:	ldur	w8, [x29, #-12]
   50860:	cbz	w8, 50888 <__gmp_randinit_mt@@Base+0x114>
   50864:	mov	x0, sp
   50868:	mov	x1, sp
   5086c:	mov	w2, #0x4de1                	// #19937
   50870:	bl	bef0 <__gmpz_tdiv_r_2exp@plt>
   50874:	mov	x0, sp
   50878:	sub	x1, x29, #0x10
   5087c:	mov	w2, #0x4e37                	// #20023
   50880:	bl	d340 <__gmpz_addmul_ui@plt>
   50884:	b	5084c <__gmp_randinit_mt@@Base+0xd8>
   50888:	tst	x21, x20
   5088c:	b.eq	5089c <__gmp_randinit_mt@@Base+0x128>  // b.none
   50890:	add	x2, sp, #0x20
   50894:	eor	x21, x21, x20
   50898:	b	50840 <__gmp_randinit_mt@@Base+0xcc>
   5089c:	lsr	x20, x20, #1
   508a0:	cbnz	x20, 5083c <__gmp_randinit_mt@@Base+0xc8>
   508a4:	sub	x0, x29, #0x10
   508a8:	bl	cb70 <__gmpz_clear@plt>
   508ac:	add	x0, sp, #0x20
   508b0:	bl	cb70 <__gmpz_clear@plt>
   508b4:	mov	x0, sp
   508b8:	mov	w1, #0x4de0                	// #19936
   508bc:	bl	c4a0 <__gmpz_tstbit@plt>
   508c0:	cmp	w0, #0x0
   508c4:	cset	w8, ne  // ne = any
   508c8:	lsl	w8, w8, #31
   508cc:	mov	x20, x19
   508d0:	mov	x0, sp
   508d4:	mov	w1, #0x4de0                	// #19936
   508d8:	str	w8, [x20], #4
   508dc:	bl	c960 <__gmpz_clrbit@plt>
   508e0:	sub	x1, x29, #0x10
   508e4:	mov	x6, sp
   508e8:	mov	w2, #0xffffffff            	// #-1
   508ec:	mov	w3, #0x4                   	// #4
   508f0:	mov	x0, x20
   508f4:	mov	w4, wzr
   508f8:	mov	x5, xzr
   508fc:	bl	d240 <__gmpz_export@plt>
   50900:	mov	x0, sp
   50904:	bl	cb70 <__gmpz_clear@plt>
   50908:	ldur	x20, [x29, #-16]
   5090c:	add	x8, x20, #0x1
   50910:	cmp	x8, #0x270
   50914:	stur	x8, [x29, #-16]
   50918:	b.cs	50944 <__gmp_randinit_mt@@Base+0x1d0>  // b.hs, b.nlast
   5091c:	add	x0, x19, x8, lsl #2
   50920:	mov	w8, #0x9bc                 	// #2492
   50924:	sub	x2, x8, x20, lsl #2
   50928:	mov	w1, wzr
   5092c:	bl	c610 <memset@plt>
   50930:	add	x20, x20, #0x1
   50934:	cmp	x20, #0x26f
   50938:	b.cc	50930 <__gmp_randinit_mt@@Base+0x1bc>  // b.lo, b.ul, b.last
   5093c:	add	x8, x20, #0x1
   50940:	stur	x8, [x29, #-16]
   50944:	mov	w20, #0x3                   	// #3
   50948:	mov	x0, x19
   5094c:	bl	d480 <__gmp_mt_recalc_buffer@plt>
   50950:	subs	w20, w20, #0x1
   50954:	b.ne	50948 <__gmp_randinit_mt@@Base+0x1d4>  // b.any
   50958:	mov	w8, #0x80                  	// #128
   5095c:	str	w8, [x19, #2496]
   50960:	ldp	x20, x19, [sp, #96]
   50964:	ldr	x21, [sp, #80]
   50968:	ldp	x29, x30, [sp, #64]
   5096c:	add	sp, sp, #0x70
   50970:	ret

0000000000050974 <__gmp_randseed@@Base>:
   50974:	ldr	x8, [x0, #24]
   50978:	ldr	x2, [x8]
   5097c:	br	x2

0000000000050980 <__gmp_randseed_ui@@Base>:
   50980:	sub	sp, sp, #0x30
   50984:	add	x8, sp, #0x8
   50988:	cmp	x1, #0x0
   5098c:	str	x1, [sp, #8]
   50990:	str	x8, [sp, #24]
   50994:	cset	w8, ne  // ne = any
   50998:	add	x1, sp, #0x10
   5099c:	stp	x29, x30, [sp, #32]
   509a0:	add	x29, sp, #0x20
   509a4:	str	w8, [sp, #20]
   509a8:	bl	cfd0 <__gmp_randseed@plt>
   509ac:	ldp	x29, x30, [sp, #32]
   509b0:	add	sp, sp, #0x30
   509b4:	ret

00000000000509b8 <__gmp_urandomb_ui@@Base>:
   509b8:	sub	sp, sp, #0x20
   509bc:	stp	x29, x30, [sp, #16]
   509c0:	str	xzr, [sp, #8]
   509c4:	ldr	x8, [x0, #24]
   509c8:	cmp	x1, #0x40
   509cc:	mov	w9, #0x40                  	// #64
   509d0:	csel	x2, x1, x9, cc  // cc = lo, ul, last
   509d4:	ldr	x8, [x8, #8]
   509d8:	add	x1, sp, #0x8
   509dc:	add	x29, sp, #0x10
   509e0:	blr	x8
   509e4:	ldr	x0, [sp, #8]
   509e8:	ldp	x29, x30, [sp, #16]
   509ec:	add	sp, sp, #0x20
   509f0:	ret

00000000000509f4 <__gmp_urandomm_ui@@Base>:
   509f4:	sub	sp, sp, #0x40
   509f8:	stp	x29, x30, [sp, #16]
   509fc:	stp	x22, x21, [sp, #32]
   50a00:	stp	x20, x19, [sp, #48]
   50a04:	add	x29, sp, #0x10
   50a08:	cbz	x1, 50a78 <__gmp_urandomm_ui@@Base+0x84>
   50a0c:	sub	x9, x1, #0x1
   50a10:	tst	x1, x9
   50a14:	clz	x8, x1
   50a18:	csetm	x9, eq  // eq = none
   50a1c:	sub	x8, x9, x8
   50a20:	mov	x19, x1
   50a24:	mov	x20, x0
   50a28:	str	xzr, [sp, #8]
   50a2c:	add	x21, x8, #0x40
   50a30:	mov	w22, #0x50                  	// #80
   50a34:	ldr	x8, [x20, #24]
   50a38:	add	x1, sp, #0x8
   50a3c:	mov	x0, x20
   50a40:	mov	x2, x21
   50a44:	ldr	x8, [x8, #8]
   50a48:	blr	x8
   50a4c:	ldr	x0, [sp, #8]
   50a50:	subs	x8, x0, x19
   50a54:	b.cc	50a64 <__gmp_urandomm_ui@@Base+0x70>  // b.lo, b.ul, b.last
   50a58:	subs	w22, w22, #0x1
   50a5c:	b.ne	50a34 <__gmp_urandomm_ui@@Base+0x40>  // b.any
   50a60:	mov	x0, x8
   50a64:	ldp	x20, x19, [sp, #48]
   50a68:	ldp	x22, x21, [sp, #32]
   50a6c:	ldp	x29, x30, [sp, #16]
   50a70:	add	sp, sp, #0x40
   50a74:	ret
   50a78:	bl	bfe0 <__gmp_divide_by_zero@plt>

Disassembly of section .fini:

0000000000050a7c <.fini>:
   50a7c:	stp	x29, x30, [sp, #-16]!
   50a80:	mov	x29, sp
   50a84:	ldp	x29, x30, [sp], #16
   50a88:	ret
