In archive /home/anony/Documents/anonymous--anonymous/pizzolotto-binaries//libclang_rt.builtins-aarch64.a_clang_-O0:

comparetf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__cmptf2>:
   0:	sub	sp, sp, #0x90
   4:	stp	x29, x30, [sp, #128]
   8:	add	x29, sp, #0x80
   c:	mov	x8, #0xffffffffffffffff    	// #-1
  10:	mov	x9, #0x7fff000000000000    	// #9223090561878065152
  14:	stur	q0, [x29, #-32]
  18:	stur	q1, [x29, #-48]
  1c:	ldur	q0, [x29, #-32]
  20:	str	x8, [sp, #8]
  24:	str	x9, [sp]
  28:	bl	304 <toRep>
  2c:	mov	v0.d[0], x0
  30:	mov	v0.d[1], x1
  34:	str	q0, [sp, #64]
  38:	ldur	q0, [x29, #-48]
  3c:	bl	304 <toRep>
  40:	mov	v0.d[0], x0
  44:	mov	v0.d[1], x1
  48:	str	q0, [sp, #48]
  4c:	ldr	q0, [sp, #64]
  50:	mov	v2.16b, v0.16b
  54:	mov	d3, v0.d[1]
  58:	fmov	x8, d2
  5c:	ldr	x9, [sp, #8]
  60:	and	x8, x8, x9
  64:	fmov	x10, d3
  68:	and	x10, x10, #0x7fffffffffffffff
  6c:	mov	v0.d[0], x8
  70:	mov	v0.d[1], x10
  74:	str	q0, [sp, #32]
  78:	ldr	q0, [sp, #48]
  7c:	mov	v2.16b, v0.16b
  80:	mov	d3, v0.d[1]
  84:	fmov	x8, d2
  88:	and	x8, x8, x9
  8c:	fmov	x10, d3
  90:	and	x10, x10, #0x7fffffffffffffff
  94:	mov	v0.d[0], x8
  98:	mov	v0.d[1], x10
  9c:	str	q0, [sp, #16]
  a0:	ldr	q0, [sp, #32]
  a4:	mov	v2.16b, v0.16b
  a8:	mov	d3, v0.d[1]
  ac:	fmov	x8, d3
  b0:	ldr	x10, [sp]
  b4:	cmp	x8, x10
  b8:	cset	w11, hi  // hi = pmore
  bc:	fmov	x8, d3
  c0:	fmov	x12, d2
  c4:	cmp	x12, #0x0
  c8:	cset	w13, hi  // hi = pmore
  cc:	cmp	x8, x10
  d0:	csel	w11, w13, w11, eq  // eq = none
  d4:	tbnz	w11, #0, 110 <__cmptf2+0x110>
  d8:	ldr	q0, [sp, #16]
  dc:	mov	v1.16b, v0.16b
  e0:	mov	d2, v0.d[1]
  e4:	fmov	x8, d2
  e8:	mov	x9, #0x7fff000000000000    	// #9223090561878065152
  ec:	cmp	x8, x9
  f0:	cset	w10, ls  // ls = plast
  f4:	fmov	x8, d2
  f8:	fmov	x11, d1
  fc:	cmp	x11, #0x0
 100:	cset	w12, ls  // ls = plast
 104:	cmp	x8, x9
 108:	csel	w10, w12, w10, eq  // eq = none
 10c:	tbnz	w10, #0, 11c <__cmptf2+0x11c>
 110:	mov	w8, #0x1                   	// #1
 114:	stur	w8, [x29, #-4]
 118:	b	2f4 <__cmptf2+0x2f4>
 11c:	ldr	q0, [sp, #32]
 120:	ldr	q1, [sp, #16]
 124:	mov	v2.16b, v0.16b
 128:	mov	d3, v0.d[1]
 12c:	mov	v4.16b, v1.16b
 130:	mov	d5, v1.d[1]
 134:	fmov	x8, d2
 138:	fmov	x9, d4
 13c:	orr	x8, x8, x9
 140:	fmov	x9, d3
 144:	fmov	x10, d5
 148:	orr	x9, x9, x10
 14c:	mov	x10, xzr
 150:	eor	x8, x8, x10
 154:	eor	x9, x9, x10
 158:	orr	x8, x8, x9
 15c:	cbnz	x8, 168 <__cmptf2+0x168>
 160:	stur	wzr, [x29, #-4]
 164:	b	2f4 <__cmptf2+0x2f4>
 168:	ldr	q0, [sp, #64]
 16c:	ldr	q1, [sp, #48]
 170:	mov	v2.16b, v0.16b
 174:	mov	d3, v0.d[1]
 178:	mov	v4.16b, v1.16b
 17c:	mov	d5, v1.d[1]
 180:	fmov	x8, d2
 184:	fmov	x9, d4
 188:	and	x8, x8, x9
 18c:	fmov	x9, d3
 190:	fmov	x10, d5
 194:	tst	x9, x10
 198:	cset	w11, lt  // lt = tstop
 19c:	cmp	x8, #0x0
 1a0:	cset	w12, cc  // cc = lo, ul, last
 1a4:	tst	x9, x10
 1a8:	csel	w11, w12, w11, eq  // eq = none
 1ac:	tbnz	w11, #0, 254 <__cmptf2+0x254>
 1b0:	ldr	q0, [sp, #64]
 1b4:	ldr	q1, [sp, #48]
 1b8:	mov	v2.16b, v0.16b
 1bc:	mov	d3, v0.d[1]
 1c0:	mov	v4.16b, v1.16b
 1c4:	mov	d5, v1.d[1]
 1c8:	fmov	x8, d3
 1cc:	fmov	x9, d5
 1d0:	cmp	x8, x9
 1d4:	cset	w10, ge  // ge = tcont
 1d8:	fmov	x8, d3
 1dc:	fmov	x9, d5
 1e0:	fmov	x11, d2
 1e4:	fmov	x12, d4
 1e8:	cmp	x11, x12
 1ec:	cset	w13, cs  // cs = hs, nlast
 1f0:	cmp	x8, x9
 1f4:	csel	w10, w13, w10, eq  // eq = none
 1f8:	tbnz	w10, #0, 208 <__cmptf2+0x208>
 1fc:	mov	w8, #0xffffffff            	// #-1
 200:	stur	w8, [x29, #-4]
 204:	b	2f4 <__cmptf2+0x2f4>
 208:	ldr	q0, [sp, #64]
 20c:	ldr	q1, [sp, #48]
 210:	mov	v2.16b, v0.16b
 214:	mov	d3, v0.d[1]
 218:	mov	v4.16b, v1.16b
 21c:	mov	d5, v1.d[1]
 220:	fmov	x8, d2
 224:	fmov	x9, d4
 228:	eor	x8, x8, x9
 22c:	fmov	x9, d3
 230:	fmov	x10, d5
 234:	eor	x9, x9, x10
 238:	orr	x8, x8, x9
 23c:	cbnz	x8, 248 <__cmptf2+0x248>
 240:	stur	wzr, [x29, #-4]
 244:	b	2f4 <__cmptf2+0x2f4>
 248:	mov	w8, #0x1                   	// #1
 24c:	stur	w8, [x29, #-4]
 250:	b	2f4 <__cmptf2+0x2f4>
 254:	ldr	q0, [sp, #64]
 258:	ldr	q1, [sp, #48]
 25c:	mov	v2.16b, v0.16b
 260:	mov	d3, v0.d[1]
 264:	mov	v4.16b, v1.16b
 268:	mov	d5, v1.d[1]
 26c:	fmov	x8, d3
 270:	fmov	x9, d5
 274:	cmp	x8, x9
 278:	cset	w10, le
 27c:	fmov	x8, d3
 280:	fmov	x9, d5
 284:	fmov	x11, d2
 288:	fmov	x12, d4
 28c:	cmp	x11, x12
 290:	cset	w13, ls  // ls = plast
 294:	cmp	x8, x9
 298:	csel	w10, w13, w10, eq  // eq = none
 29c:	tbnz	w10, #0, 2ac <__cmptf2+0x2ac>
 2a0:	mov	w8, #0xffffffff            	// #-1
 2a4:	stur	w8, [x29, #-4]
 2a8:	b	2f4 <__cmptf2+0x2f4>
 2ac:	ldr	q0, [sp, #64]
 2b0:	ldr	q1, [sp, #48]
 2b4:	mov	v2.16b, v0.16b
 2b8:	mov	d3, v0.d[1]
 2bc:	mov	v4.16b, v1.16b
 2c0:	mov	d5, v1.d[1]
 2c4:	fmov	x8, d2
 2c8:	fmov	x9, d4
 2cc:	eor	x8, x8, x9
 2d0:	fmov	x9, d3
 2d4:	fmov	x10, d5
 2d8:	eor	x9, x9, x10
 2dc:	orr	x8, x8, x9
 2e0:	cbnz	x8, 2ec <__cmptf2+0x2ec>
 2e4:	stur	wzr, [x29, #-4]
 2e8:	b	2f4 <__cmptf2+0x2f4>
 2ec:	mov	w8, #0x1                   	// #1
 2f0:	stur	w8, [x29, #-4]
 2f4:	ldur	w0, [x29, #-4]
 2f8:	ldp	x29, x30, [sp, #128]
 2fc:	add	sp, sp, #0x90
 300:	ret

0000000000000304 <toRep>:
 304:	sub	sp, sp, #0x20
 308:	str	q0, [sp, #16]
 30c:	ldr	q0, [sp, #16]
 310:	str	q0, [sp]
 314:	ldr	x0, [sp]
 318:	ldr	x1, [sp, #8]
 31c:	add	sp, sp, #0x20
 320:	ret

0000000000000324 <__getf2>:
 324:	sub	sp, sp, #0x90
 328:	stp	x29, x30, [sp, #128]
 32c:	add	x29, sp, #0x80
 330:	mov	x8, #0xffffffffffffffff    	// #-1
 334:	mov	x9, #0x7fff000000000000    	// #9223090561878065152
 338:	stur	q0, [x29, #-32]
 33c:	stur	q1, [x29, #-48]
 340:	ldur	q0, [x29, #-32]
 344:	str	x8, [sp, #8]
 348:	str	x9, [sp]
 34c:	bl	304 <toRep>
 350:	mov	v0.d[0], x0
 354:	mov	v0.d[1], x1
 358:	str	q0, [sp, #64]
 35c:	ldur	q0, [x29, #-48]
 360:	bl	304 <toRep>
 364:	mov	v0.d[0], x0
 368:	mov	v0.d[1], x1
 36c:	str	q0, [sp, #48]
 370:	ldr	q0, [sp, #64]
 374:	mov	v2.16b, v0.16b
 378:	mov	d3, v0.d[1]
 37c:	fmov	x8, d2
 380:	ldr	x9, [sp, #8]
 384:	and	x8, x8, x9
 388:	fmov	x10, d3
 38c:	and	x10, x10, #0x7fffffffffffffff
 390:	mov	v0.d[0], x8
 394:	mov	v0.d[1], x10
 398:	str	q0, [sp, #32]
 39c:	ldr	q0, [sp, #48]
 3a0:	mov	v2.16b, v0.16b
 3a4:	mov	d3, v0.d[1]
 3a8:	fmov	x8, d2
 3ac:	and	x8, x8, x9
 3b0:	fmov	x10, d3
 3b4:	and	x10, x10, #0x7fffffffffffffff
 3b8:	mov	v0.d[0], x8
 3bc:	mov	v0.d[1], x10
 3c0:	str	q0, [sp, #16]
 3c4:	ldr	q0, [sp, #32]
 3c8:	mov	v2.16b, v0.16b
 3cc:	mov	d3, v0.d[1]
 3d0:	fmov	x8, d3
 3d4:	ldr	x10, [sp]
 3d8:	cmp	x8, x10
 3dc:	cset	w11, hi  // hi = pmore
 3e0:	fmov	x8, d3
 3e4:	fmov	x12, d2
 3e8:	cmp	x12, #0x0
 3ec:	cset	w13, hi  // hi = pmore
 3f0:	cmp	x8, x10
 3f4:	csel	w11, w13, w11, eq  // eq = none
 3f8:	tbnz	w11, #0, 434 <__getf2+0x110>
 3fc:	ldr	q0, [sp, #16]
 400:	mov	v1.16b, v0.16b
 404:	mov	d2, v0.d[1]
 408:	fmov	x8, d2
 40c:	mov	x9, #0x7fff000000000000    	// #9223090561878065152
 410:	cmp	x8, x9
 414:	cset	w10, ls  // ls = plast
 418:	fmov	x8, d2
 41c:	fmov	x11, d1
 420:	cmp	x11, #0x0
 424:	cset	w12, ls  // ls = plast
 428:	cmp	x8, x9
 42c:	csel	w10, w12, w10, eq  // eq = none
 430:	tbnz	w10, #0, 440 <__getf2+0x11c>
 434:	mov	w8, #0xffffffff            	// #-1
 438:	stur	w8, [x29, #-4]
 43c:	b	618 <__getf2+0x2f4>
 440:	ldr	q0, [sp, #32]
 444:	ldr	q1, [sp, #16]
 448:	mov	v2.16b, v0.16b
 44c:	mov	d3, v0.d[1]
 450:	mov	v4.16b, v1.16b
 454:	mov	d5, v1.d[1]
 458:	fmov	x8, d2
 45c:	fmov	x9, d4
 460:	orr	x8, x8, x9
 464:	fmov	x9, d3
 468:	fmov	x10, d5
 46c:	orr	x9, x9, x10
 470:	mov	x10, xzr
 474:	eor	x8, x8, x10
 478:	eor	x9, x9, x10
 47c:	orr	x8, x8, x9
 480:	cbnz	x8, 48c <__getf2+0x168>
 484:	stur	wzr, [x29, #-4]
 488:	b	618 <__getf2+0x2f4>
 48c:	ldr	q0, [sp, #64]
 490:	ldr	q1, [sp, #48]
 494:	mov	v2.16b, v0.16b
 498:	mov	d3, v0.d[1]
 49c:	mov	v4.16b, v1.16b
 4a0:	mov	d5, v1.d[1]
 4a4:	fmov	x8, d2
 4a8:	fmov	x9, d4
 4ac:	and	x8, x8, x9
 4b0:	fmov	x9, d3
 4b4:	fmov	x10, d5
 4b8:	tst	x9, x10
 4bc:	cset	w11, lt  // lt = tstop
 4c0:	cmp	x8, #0x0
 4c4:	cset	w12, cc  // cc = lo, ul, last
 4c8:	tst	x9, x10
 4cc:	csel	w11, w12, w11, eq  // eq = none
 4d0:	tbnz	w11, #0, 578 <__getf2+0x254>
 4d4:	ldr	q0, [sp, #64]
 4d8:	ldr	q1, [sp, #48]
 4dc:	mov	v2.16b, v0.16b
 4e0:	mov	d3, v0.d[1]
 4e4:	mov	v4.16b, v1.16b
 4e8:	mov	d5, v1.d[1]
 4ec:	fmov	x8, d3
 4f0:	fmov	x9, d5
 4f4:	cmp	x8, x9
 4f8:	cset	w10, ge  // ge = tcont
 4fc:	fmov	x8, d3
 500:	fmov	x9, d5
 504:	fmov	x11, d2
 508:	fmov	x12, d4
 50c:	cmp	x11, x12
 510:	cset	w13, cs  // cs = hs, nlast
 514:	cmp	x8, x9
 518:	csel	w10, w13, w10, eq  // eq = none
 51c:	tbnz	w10, #0, 52c <__getf2+0x208>
 520:	mov	w8, #0xffffffff            	// #-1
 524:	stur	w8, [x29, #-4]
 528:	b	618 <__getf2+0x2f4>
 52c:	ldr	q0, [sp, #64]
 530:	ldr	q1, [sp, #48]
 534:	mov	v2.16b, v0.16b
 538:	mov	d3, v0.d[1]
 53c:	mov	v4.16b, v1.16b
 540:	mov	d5, v1.d[1]
 544:	fmov	x8, d2
 548:	fmov	x9, d4
 54c:	eor	x8, x8, x9
 550:	fmov	x9, d3
 554:	fmov	x10, d5
 558:	eor	x9, x9, x10
 55c:	orr	x8, x8, x9
 560:	cbnz	x8, 56c <__getf2+0x248>
 564:	stur	wzr, [x29, #-4]
 568:	b	618 <__getf2+0x2f4>
 56c:	mov	w8, #0x1                   	// #1
 570:	stur	w8, [x29, #-4]
 574:	b	618 <__getf2+0x2f4>
 578:	ldr	q0, [sp, #64]
 57c:	ldr	q1, [sp, #48]
 580:	mov	v2.16b, v0.16b
 584:	mov	d3, v0.d[1]
 588:	mov	v4.16b, v1.16b
 58c:	mov	d5, v1.d[1]
 590:	fmov	x8, d3
 594:	fmov	x9, d5
 598:	cmp	x8, x9
 59c:	cset	w10, le
 5a0:	fmov	x8, d3
 5a4:	fmov	x9, d5
 5a8:	fmov	x11, d2
 5ac:	fmov	x12, d4
 5b0:	cmp	x11, x12
 5b4:	cset	w13, ls  // ls = plast
 5b8:	cmp	x8, x9
 5bc:	csel	w10, w13, w10, eq  // eq = none
 5c0:	tbnz	w10, #0, 5d0 <__getf2+0x2ac>
 5c4:	mov	w8, #0xffffffff            	// #-1
 5c8:	stur	w8, [x29, #-4]
 5cc:	b	618 <__getf2+0x2f4>
 5d0:	ldr	q0, [sp, #64]
 5d4:	ldr	q1, [sp, #48]
 5d8:	mov	v2.16b, v0.16b
 5dc:	mov	d3, v0.d[1]
 5e0:	mov	v4.16b, v1.16b
 5e4:	mov	d5, v1.d[1]
 5e8:	fmov	x8, d2
 5ec:	fmov	x9, d4
 5f0:	eor	x8, x8, x9
 5f4:	fmov	x9, d3
 5f8:	fmov	x10, d5
 5fc:	eor	x9, x9, x10
 600:	orr	x8, x8, x9
 604:	cbnz	x8, 610 <__getf2+0x2ec>
 608:	stur	wzr, [x29, #-4]
 60c:	b	618 <__getf2+0x2f4>
 610:	mov	w8, #0x1                   	// #1
 614:	stur	w8, [x29, #-4]
 618:	ldur	w0, [x29, #-4]
 61c:	ldp	x29, x30, [sp, #128]
 620:	add	sp, sp, #0x90
 624:	ret

0000000000000628 <__unordtf2>:
 628:	sub	sp, sp, #0x70
 62c:	stp	x29, x30, [sp, #96]
 630:	add	x29, sp, #0x60
 634:	mov	x8, #0xffffffffffffffff    	// #-1
 638:	mov	x9, #0x7fff000000000000    	// #9223090561878065152
 63c:	stur	q0, [x29, #-16]
 640:	stur	q1, [x29, #-32]
 644:	ldur	q0, [x29, #-16]
 648:	str	x8, [sp, #24]
 64c:	str	x9, [sp, #16]
 650:	bl	304 <toRep>
 654:	ldr	x8, [sp, #24]
 658:	and	x9, x0, x8
 65c:	and	x10, x1, #0x7fffffffffffffff
 660:	mov	v0.d[0], x9
 664:	mov	v0.d[1], x10
 668:	str	q0, [sp, #48]
 66c:	ldur	q0, [x29, #-32]
 670:	bl	304 <toRep>
 674:	ldr	x8, [sp, #24]
 678:	and	x9, x0, x8
 67c:	and	x10, x1, #0x7fffffffffffffff
 680:	mov	v0.d[0], x9
 684:	mov	v0.d[1], x10
 688:	str	q0, [sp, #32]
 68c:	ldr	q0, [sp, #48]
 690:	mov	v2.16b, v0.16b
 694:	mov	d3, v0.d[1]
 698:	fmov	x9, d3
 69c:	ldr	x10, [sp, #16]
 6a0:	cmp	x9, x10
 6a4:	cset	w11, hi  // hi = pmore
 6a8:	fmov	x9, d3
 6ac:	fmov	x12, d2
 6b0:	cmp	x12, #0x0
 6b4:	cset	w13, hi  // hi = pmore
 6b8:	cmp	x9, x10
 6bc:	csel	w11, w13, w11, eq  // eq = none
 6c0:	mov	w13, #0x1                   	// #1
 6c4:	str	w13, [sp, #12]
 6c8:	tbnz	w11, #0, 704 <__unordtf2+0xdc>
 6cc:	ldr	q0, [sp, #32]
 6d0:	mov	v1.16b, v0.16b
 6d4:	mov	d2, v0.d[1]
 6d8:	fmov	x8, d2
 6dc:	mov	x9, #0x7fff000000000000    	// #9223090561878065152
 6e0:	cmp	x8, x9
 6e4:	cset	w10, hi  // hi = pmore
 6e8:	fmov	x8, d2
 6ec:	fmov	x11, d1
 6f0:	cmp	x11, #0x0
 6f4:	cset	w12, hi  // hi = pmore
 6f8:	cmp	x8, x9
 6fc:	csel	w10, w12, w10, eq  // eq = none
 700:	str	w10, [sp, #12]
 704:	ldr	w8, [sp, #12]
 708:	and	w0, w8, #0x1
 70c:	ldp	x29, x30, [sp, #96]
 710:	add	sp, sp, #0x70
 714:	ret

extenddftf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__extenddftf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp, #8]
  10:	ldr	d0, [sp, #8]
  14:	bl	24 <__extendXfYf2__>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__extendXfYf2__>:
  24:	sub	sp, sp, #0xe0
  28:	stp	x29, x30, [sp, #208]
  2c:	add	x29, sp, #0xd0
  30:	stur	d0, [x29, #-8]
  34:	mov	w8, #0x40                  	// #64
  38:	stur	w8, [x29, #-12]
  3c:	mov	w8, #0xb                   	// #11
  40:	stur	w8, [x29, #-16]
  44:	mov	w8, #0x7ff                 	// #2047
  48:	stur	w8, [x29, #-20]
  4c:	mov	w8, #0x3ff                 	// #1023
  50:	stur	w8, [x29, #-24]
  54:	mov	x9, #0x10000000000000      	// #4503599627370496
  58:	stur	x9, [x29, #-32]
  5c:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
  60:	stur	x9, [x29, #-40]
  64:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
  68:	stur	x9, [x29, #-48]
  6c:	mov	x9, #0x7fffffffffffffff    	// #9223372036854775807
  70:	stur	x9, [x29, #-56]
  74:	mov	x9, #0x8000000000000       	// #2251799813685248
  78:	stur	x9, [x29, #-64]
  7c:	mov	x9, #0x7ffffffffffff       	// #2251799813685247
  80:	stur	x9, [x29, #-72]
  84:	mov	w8, #0x80                  	// #128
  88:	stur	w8, [x29, #-76]
  8c:	mov	w8, #0xf                   	// #15
  90:	stur	w8, [x29, #-80]
  94:	mov	w8, #0x7fff                	// #32767
  98:	stur	w8, [x29, #-84]
  9c:	mov	w8, #0x3fff                	// #16383
  a0:	stur	w8, [x29, #-88]
  a4:	mov	x9, #0x1000000000000       	// #281474976710656
  a8:	str	x9, [sp, #104]
  ac:	mov	x9, xzr
  b0:	str	x9, [sp, #96]
  b4:	ldur	d0, [x29, #-8]
  b8:	bl	27c <srcToRep>
  bc:	str	x0, [sp, #88]
  c0:	ldr	x9, [sp, #88]
  c4:	and	x9, x9, #0x7fffffffffffffff
  c8:	str	x9, [sp, #80]
  cc:	ldr	x9, [sp, #88]
  d0:	and	x9, x9, #0x8000000000000000
  d4:	str	x9, [sp, #72]
  d8:	ldr	x9, [sp, #80]
  dc:	mov	x10, #0xfff0000000000000    	// #-4503599627370496
  e0:	add	x9, x9, x10
  e4:	lsr	x9, x9, #53
  e8:	subs	x9, x9, #0x3fe
  ec:	b.hi	11c <__extendXfYf2__+0xf8>  // b.pmore
  f0:	b	f4 <__extendXfYf2__+0xd0>
  f4:	ldr	x8, [sp, #80]
  f8:	lsl	x9, x8, #60
  fc:	lsr	x8, x8, #4
 100:	str	x8, [sp, #56]
 104:	str	x9, [sp, #48]
 108:	ldr	x8, [sp, #56]
 10c:	mov	x9, #0x3c00000000000000    	// #4323455642275676160
 110:	add	x8, x8, x9
 114:	str	x8, [sp, #56]
 118:	b	24c <__extendXfYf2__+0x228>
 11c:	ldr	x8, [sp, #80]
 120:	lsr	x8, x8, #52
 124:	subs	x8, x8, #0x7ff
 128:	b.cc	180 <__extendXfYf2__+0x15c>  // b.lo, b.ul, b.last
 12c:	b	130 <__extendXfYf2__+0x10c>
 130:	mov	x8, #0x7fff000000000000    	// #9223090561878065152
 134:	str	x8, [sp, #56]
 138:	mov	x8, xzr
 13c:	str	x8, [sp, #48]
 140:	ldr	x8, [sp, #80]
 144:	and	x8, x8, #0x8000000000000
 148:	ldr	x9, [sp, #48]
 14c:	ldr	x10, [sp, #56]
 150:	orr	x8, x10, x8, lsr #4
 154:	str	x9, [sp, #48]
 158:	str	x8, [sp, #56]
 15c:	ldr	x8, [sp, #80]
 160:	and	x8, x8, #0x7ffffffffffff
 164:	ldr	x9, [sp, #56]
 168:	ldr	x10, [sp, #48]
 16c:	orr	x10, x10, x8, lsl #60
 170:	orr	x8, x9, x8, lsr #4
 174:	str	x8, [sp, #56]
 178:	str	x10, [sp, #48]
 17c:	b	248 <__extendXfYf2__+0x224>
 180:	ldr	x8, [sp, #80]
 184:	cbz	x8, 234 <__extendXfYf2__+0x210>
 188:	b	18c <__extendXfYf2__+0x168>
 18c:	ldr	x0, [sp, #80]
 190:	bl	298 <src_rep_t_clz>
 194:	mov	x8, #0x10000000000000      	// #4503599627370496
 198:	str	w0, [sp, #12]
 19c:	mov	x0, x8
 1a0:	bl	298 <src_rep_t_clz>
 1a4:	ldr	w9, [sp, #12]
 1a8:	subs	w10, w9, w0
 1ac:	str	w10, [sp, #44]
 1b0:	ldr	x8, [sp, #80]
 1b4:	ldr	w10, [sp, #44]
 1b8:	add	w10, w10, #0x3c
 1bc:	mov	w11, w10
 1c0:	mov	x12, xzr
 1c4:	sub	x13, x12, x11
 1c8:	lsr	x13, x8, x13
 1cc:	subs	x14, x11, #0x0
 1d0:	csel	x13, x12, x13, eq  // eq = none
 1d4:	lsl	x15, x8, x11
 1d8:	subs	x11, x11, #0x40
 1dc:	subs	x11, x11, #0x0
 1e0:	csel	x13, x15, x13, ge  // ge = tcont
 1e4:	mov	w15, w10
 1e8:	lsl	x8, x8, x15
 1ec:	csel	x8, x12, x8, ge  // ge = tcont
 1f0:	str	x8, [sp, #48]
 1f4:	str	x13, [sp, #56]
 1f8:	ldr	x8, [sp, #56]
 1fc:	eor	x8, x8, #0x1000000000000
 200:	str	x8, [sp, #56]
 204:	ldr	w10, [sp, #44]
 208:	mov	w16, #0x3c01                	// #15361
 20c:	subs	w10, w16, w10
 210:	str	w10, [sp, #40]
 214:	ldr	w10, [sp, #40]
 218:	mov	w8, w10
 21c:	ldr	x12, [sp, #48]
 220:	ldr	x13, [sp, #56]
 224:	orr	x8, x13, x8, lsl #48
 228:	str	x12, [sp, #48]
 22c:	str	x8, [sp, #56]
 230:	b	244 <__extendXfYf2__+0x220>
 234:	mov	x8, xzr
 238:	str	x8, [sp, #56]
 23c:	str	x8, [sp, #48]
 240:	b	244 <__extendXfYf2__+0x220>
 244:	b	248 <__extendXfYf2__+0x224>
 248:	b	24c <__extendXfYf2__+0x228>
 24c:	ldr	x8, [sp, #48]
 250:	ldr	x9, [sp, #56]
 254:	ldr	x10, [sp, #72]
 258:	orr	x9, x9, x10
 25c:	str	x8, [sp, #16]
 260:	str	x9, [sp, #24]
 264:	ldr	x1, [sp, #24]
 268:	ldr	x0, [sp, #16]
 26c:	bl	2b4 <dstFromRep>
 270:	ldp	x29, x30, [sp, #208]
 274:	add	sp, sp, #0xe0
 278:	ret

000000000000027c <srcToRep>:
 27c:	sub	sp, sp, #0x10
 280:	str	d0, [sp, #8]
 284:	ldr	x8, [sp, #8]
 288:	str	x8, [sp]
 28c:	ldr	x0, [sp]
 290:	add	sp, sp, #0x10
 294:	ret

0000000000000298 <src_rep_t_clz>:
 298:	sub	sp, sp, #0x10
 29c:	str	x0, [sp, #8]
 2a0:	ldr	x8, [sp, #8]
 2a4:	clz	x8, x8
 2a8:	mov	w0, w8
 2ac:	add	sp, sp, #0x10
 2b0:	ret

00000000000002b4 <dstFromRep>:
 2b4:	sub	sp, sp, #0x20
 2b8:	mov	v0.d[0], x0
 2bc:	mov	v0.d[1], x1
 2c0:	str	q0, [sp, #16]
 2c4:	ldr	q0, [sp, #16]
 2c8:	str	q0, [sp]
 2cc:	ldr	q0, [sp]
 2d0:	add	sp, sp, #0x20
 2d4:	ret

extendsftf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__extendsftf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	ldur	s0, [x29, #-4]
  14:	bl	24 <__extendXfYf2__>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__extendXfYf2__>:
  24:	sub	sp, sp, #0xa0
  28:	stp	x29, x30, [sp, #144]
  2c:	add	x29, sp, #0x90
  30:	stur	s0, [x29, #-4]
  34:	mov	w8, #0x20                  	// #32
  38:	stur	w8, [x29, #-8]
  3c:	mov	w8, #0x8                   	// #8
  40:	stur	w8, [x29, #-12]
  44:	mov	w8, #0xff                  	// #255
  48:	stur	w8, [x29, #-16]
  4c:	mov	w8, #0x7f                  	// #127
  50:	stur	w8, [x29, #-20]
  54:	mov	w8, #0x800000              	// #8388608
  58:	stur	w8, [x29, #-24]
  5c:	mov	w8, #0x7f800000            	// #2139095040
  60:	stur	w8, [x29, #-28]
  64:	mov	w8, #0x80000000            	// #-2147483648
  68:	stur	w8, [x29, #-32]
  6c:	mov	w8, #0x7fffffff            	// #2147483647
  70:	stur	w8, [x29, #-36]
  74:	mov	w8, #0x400000              	// #4194304
  78:	stur	w8, [x29, #-40]
  7c:	mov	w8, #0x3fffff              	// #4194303
  80:	stur	w8, [x29, #-44]
  84:	mov	w8, #0x80                  	// #128
  88:	stur	w8, [x29, #-48]
  8c:	mov	w8, #0xf                   	// #15
  90:	stur	w8, [x29, #-52]
  94:	mov	w8, #0x7fff                	// #32767
  98:	stur	w8, [x29, #-56]
  9c:	mov	w8, #0x3fff                	// #16383
  a0:	stur	w8, [x29, #-60]
  a4:	mov	x9, #0x1000000000000       	// #281474976710656
  a8:	str	x9, [sp, #72]
  ac:	mov	x9, xzr
  b0:	str	x9, [sp, #64]
  b4:	ldur	s0, [x29, #-4]
  b8:	bl	274 <srcToRep>
  bc:	str	w0, [sp, #60]
  c0:	ldr	w8, [sp, #60]
  c4:	and	w8, w8, #0x7fffffff
  c8:	str	w8, [sp, #56]
  cc:	ldr	w8, [sp, #60]
  d0:	and	w8, w8, #0x80000000
  d4:	str	w8, [sp, #52]
  d8:	ldr	w8, [sp, #56]
  dc:	subs	w8, w8, #0x800, lsl #12
  e0:	lsr	w8, w8, #24
  e4:	subs	w8, w8, #0x7e
  e8:	b.hi	11c <__extendXfYf2__+0xf8>  // b.pmore
  ec:	b	f0 <__extendXfYf2__+0xcc>
  f0:	ldr	w8, [sp, #56]
  f4:	mov	w9, w8
  f8:	lsl	x9, x9, #25
  fc:	mov	x10, xzr
 100:	str	x10, [sp, #32]
 104:	str	x9, [sp, #40]
 108:	ldr	x9, [sp, #40]
 10c:	mov	x10, #0x3f80000000000000    	// #4575657221408423936
 110:	add	x9, x9, x10
 114:	str	x9, [sp, #40]
 118:	b	240 <__extendXfYf2__+0x21c>
 11c:	ldr	w8, [sp, #56]
 120:	lsr	w8, w8, #23
 124:	subs	w8, w8, #0xff
 128:	b.cc	184 <__extendXfYf2__+0x160>  // b.lo, b.ul, b.last
 12c:	b	130 <__extendXfYf2__+0x10c>
 130:	mov	x8, #0x7fff000000000000    	// #9223090561878065152
 134:	str	x8, [sp, #40]
 138:	mov	x8, xzr
 13c:	str	x8, [sp, #32]
 140:	ldr	w9, [sp, #56]
 144:	mov	w8, w9
 148:	and	x8, x8, #0x400000
 14c:	ldr	x10, [sp, #32]
 150:	ldr	x11, [sp, #40]
 154:	orr	x8, x11, x8, lsl #25
 158:	str	x10, [sp, #32]
 15c:	str	x8, [sp, #40]
 160:	ldr	w9, [sp, #56]
 164:	mov	w8, w9
 168:	and	x8, x8, #0x3fffff
 16c:	ldr	x10, [sp, #32]
 170:	ldr	x11, [sp, #40]
 174:	orr	x8, x11, x8, lsl #25
 178:	str	x10, [sp, #32]
 17c:	str	x8, [sp, #40]
 180:	b	23c <__extendXfYf2__+0x218>
 184:	ldr	w8, [sp, #56]
 188:	cbz	w8, 228 <__extendXfYf2__+0x204>
 18c:	b	190 <__extendXfYf2__+0x16c>
 190:	ldr	w8, [sp, #56]
 194:	clz	w8, w8
 198:	subs	w8, w8, #0x8
 19c:	str	w8, [sp, #28]
 1a0:	ldr	w8, [sp, #56]
 1a4:	mov	w9, w8
 1a8:	ldr	w8, [sp, #28]
 1ac:	add	w8, w8, #0x59
 1b0:	mov	w10, w8
 1b4:	mov	x11, xzr
 1b8:	sub	x12, x11, x10
 1bc:	lsr	x12, x9, x12
 1c0:	subs	x13, x10, #0x0
 1c4:	csel	x12, x11, x12, eq  // eq = none
 1c8:	lsl	x14, x9, x10
 1cc:	subs	x10, x10, #0x40
 1d0:	subs	x10, x10, #0x0
 1d4:	csel	x12, x14, x12, ge  // ge = tcont
 1d8:	mov	w14, w8
 1dc:	lsl	x9, x9, x14
 1e0:	csel	x9, x11, x9, ge  // ge = tcont
 1e4:	str	x9, [sp, #32]
 1e8:	str	x12, [sp, #40]
 1ec:	ldr	x9, [sp, #40]
 1f0:	eor	x9, x9, #0x1000000000000
 1f4:	str	x9, [sp, #40]
 1f8:	ldr	w8, [sp, #28]
 1fc:	mov	w15, #0x3f81                	// #16257
 200:	subs	w8, w15, w8
 204:	str	w8, [sp, #24]
 208:	ldr	w8, [sp, #24]
 20c:	mov	w9, w8
 210:	ldr	x11, [sp, #32]
 214:	ldr	x12, [sp, #40]
 218:	orr	x9, x12, x9, lsl #48
 21c:	str	x11, [sp, #32]
 220:	str	x9, [sp, #40]
 224:	b	238 <__extendXfYf2__+0x214>
 228:	mov	x8, xzr
 22c:	str	x8, [sp, #40]
 230:	str	x8, [sp, #32]
 234:	b	238 <__extendXfYf2__+0x214>
 238:	b	23c <__extendXfYf2__+0x218>
 23c:	b	240 <__extendXfYf2__+0x21c>
 240:	ldr	x8, [sp, #32]
 244:	ldr	x9, [sp, #40]
 248:	ldr	w10, [sp, #52]
 24c:	mov	w11, w10
 250:	orr	x9, x9, x11, lsl #32
 254:	str	x8, [sp]
 258:	str	x9, [sp, #8]
 25c:	ldr	x1, [sp, #8]
 260:	ldr	x0, [sp]
 264:	bl	290 <dstFromRep>
 268:	ldp	x29, x30, [sp, #144]
 26c:	add	sp, sp, #0xa0
 270:	ret

0000000000000274 <srcToRep>:
 274:	sub	sp, sp, #0x10
 278:	str	s0, [sp, #12]
 27c:	ldr	w8, [sp, #12]
 280:	str	w8, [sp, #8]
 284:	ldr	w0, [sp, #8]
 288:	add	sp, sp, #0x10
 28c:	ret

0000000000000290 <dstFromRep>:
 290:	sub	sp, sp, #0x20
 294:	mov	v0.d[0], x0
 298:	mov	v0.d[1], x1
 29c:	str	q0, [sp, #16]
 2a0:	ldr	q0, [sp, #16]
 2a4:	str	q0, [sp]
 2a8:	ldr	q0, [sp]
 2ac:	add	sp, sp, #0x20
 2b0:	ret

fixtfdi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixtfdi>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	q0, [sp]
  10:	ldr	q0, [sp]
  14:	bl	24 <__fixint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixint>:
  24:	sub	sp, sp, #0x80
  28:	stp	x29, x30, [sp, #112]
  2c:	add	x29, sp, #0x70
  30:	stur	q0, [x29, #-32]
  34:	mov	x8, #0x7fffffffffffffff    	// #9223372036854775807
  38:	stur	x8, [x29, #-40]
  3c:	mov	x8, #0x8000000000000000    	// #-9223372036854775808
  40:	stur	x8, [x29, #-48]
  44:	ldur	q0, [x29, #-32]
  48:	bl	180 <toRep>
  4c:	str	x1, [sp, #56]
  50:	str	x0, [sp, #48]
  54:	ldr	x8, [sp, #48]
  58:	ldr	x9, [sp, #56]
  5c:	and	x9, x9, #0x7fffffffffffffff
  60:	str	x8, [sp, #32]
  64:	str	x9, [sp, #40]
  68:	ldr	x8, [sp, #56]
  6c:	ands	x8, x8, #0x8000000000000000
  70:	mov	x9, #0xffffffffffffffff    	// #-1
  74:	cneg	x9, x9, eq  // eq = none
  78:	str	x9, [sp, #24]
  7c:	ldrh	w10, [sp, #46]
  80:	mov	w11, #0xffffc001            	// #-16383
  84:	add	w10, w10, w11
  88:	str	w10, [sp, #20]
  8c:	ldr	x9, [sp, #32]
  90:	ldr	x12, [sp, #40]
  94:	mov	x13, #0x1000000000000       	// #281474976710656
  98:	bfxil	x13, x12, #0, #48
  9c:	str	x9, [sp]
  a0:	str	x13, [sp, #8]
  a4:	ldr	w10, [sp, #20]
  a8:	tbz	w10, #31, bc <__fixint+0x98>
  ac:	b	b0 <__fixint+0x8c>
  b0:	mov	x8, xzr
  b4:	stur	x8, [x29, #-8]
  b8:	b	170 <__fixint+0x14c>
  bc:	ldr	w8, [sp, #20]
  c0:	subs	w8, w8, #0x40
  c4:	b.cc	e4 <__fixint+0xc0>  // b.lo, b.ul, b.last
  c8:	b	cc <__fixint+0xa8>
  cc:	ldr	x8, [sp, #24]
  d0:	subs	x8, x8, #0x1
  d4:	mov	x9, #0x7fffffffffffffff    	// #9223372036854775807
  d8:	cinv	x9, x9, ne  // ne = any
  dc:	stur	x9, [x29, #-8]
  e0:	b	170 <__fixint+0x14c>
  e4:	ldr	w8, [sp, #20]
  e8:	subs	w8, w8, #0x6f
  ec:	b.gt	14c <__fixint+0x128>
  f0:	b	f4 <__fixint+0xd0>
  f4:	ldr	x8, [sp, #24]
  f8:	ldr	x9, [sp]
  fc:	ldr	x10, [sp, #8]
 100:	ldr	w11, [sp, #20]
 104:	mov	w12, #0x70                  	// #112
 108:	subs	w11, w12, w11
 10c:	mov	w13, w11
 110:	mov	x14, xzr
 114:	sub	x15, x14, x13
 118:	lsl	x15, x10, x15
 11c:	subs	x16, x13, #0x0
 120:	csel	x14, x14, x15, eq  // eq = none
 124:	mov	w15, w11
 128:	lsr	x9, x9, x15
 12c:	orr	x9, x9, x14
 130:	lsr	x10, x10, x13
 134:	subs	x13, x13, #0x40
 138:	subs	x13, x13, #0x0
 13c:	csel	x9, x10, x9, ge  // ge = tcont
 140:	mul	x8, x8, x9
 144:	stur	x8, [x29, #-8]
 148:	b	170 <__fixint+0x14c>
 14c:	ldr	x8, [sp, #24]
 150:	ldr	x9, [sp]
 154:	ldr	w10, [sp, #20]
 158:	subs	w10, w10, #0x70
 15c:	mov	w11, w10
 160:	lsl	x9, x9, x11
 164:	mul	x8, x8, x9
 168:	stur	x8, [x29, #-8]
 16c:	b	170 <__fixint+0x14c>
 170:	ldur	x0, [x29, #-8]
 174:	ldp	x29, x30, [sp, #112]
 178:	add	sp, sp, #0x80
 17c:	ret

0000000000000180 <toRep>:
 180:	sub	sp, sp, #0x20
 184:	str	q0, [sp, #16]
 188:	ldr	q0, [sp, #16]
 18c:	str	q0, [sp]
 190:	ldr	x0, [sp]
 194:	ldr	x1, [sp, #8]
 198:	add	sp, sp, #0x20
 19c:	ret

fixtfsi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixtfsi>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	q0, [sp]
  10:	ldr	q0, [sp]
  14:	bl	24 <__fixint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixint>:
  24:	sub	sp, sp, #0x80
  28:	stp	x29, x30, [sp, #112]
  2c:	add	x29, sp, #0x70
  30:	stur	q0, [x29, #-32]
  34:	mov	w8, #0x7fffffff            	// #2147483647
  38:	stur	w8, [x29, #-36]
  3c:	mov	w8, #0x80000000            	// #-2147483648
  40:	stur	w8, [x29, #-40]
  44:	ldur	q0, [x29, #-32]
  48:	bl	17c <toRep>
  4c:	str	x1, [sp, #56]
  50:	str	x0, [sp, #48]
  54:	ldr	x9, [sp, #48]
  58:	ldr	x10, [sp, #56]
  5c:	and	x10, x10, #0x7fffffffffffffff
  60:	str	x9, [sp, #32]
  64:	str	x10, [sp, #40]
  68:	ldr	x9, [sp, #56]
  6c:	ands	x9, x9, #0x8000000000000000
  70:	mov	w8, #0xffffffff            	// #-1
  74:	cneg	w8, w8, eq  // eq = none
  78:	str	w8, [sp, #28]
  7c:	ldrh	w8, [sp, #46]
  80:	mov	w11, #0xffffc001            	// #-16383
  84:	add	w8, w8, w11
  88:	str	w8, [sp, #24]
  8c:	ldr	x10, [sp, #32]
  90:	ldr	x12, [sp, #40]
  94:	mov	x13, #0x1000000000000       	// #281474976710656
  98:	bfxil	x13, x12, #0, #48
  9c:	str	x10, [sp]
  a0:	str	x13, [sp, #8]
  a4:	ldr	w8, [sp, #24]
  a8:	tbz	w8, #31, bc <__fixint+0x98>
  ac:	b	b0 <__fixint+0x8c>
  b0:	mov	w8, wzr
  b4:	stur	w8, [x29, #-4]
  b8:	b	16c <__fixint+0x148>
  bc:	ldr	w8, [sp, #24]
  c0:	subs	w8, w8, #0x20
  c4:	b.cc	e4 <__fixint+0xc0>  // b.lo, b.ul, b.last
  c8:	b	cc <__fixint+0xa8>
  cc:	ldr	w8, [sp, #28]
  d0:	subs	w8, w8, #0x1
  d4:	mov	w9, #0x7fffffff            	// #2147483647
  d8:	cinv	w9, w9, ne  // ne = any
  dc:	stur	w9, [x29, #-4]
  e0:	b	16c <__fixint+0x148>
  e4:	ldr	w8, [sp, #24]
  e8:	subs	w8, w8, #0x6f
  ec:	b.gt	14c <__fixint+0x128>
  f0:	b	f4 <__fixint+0xd0>
  f4:	ldr	w8, [sp, #28]
  f8:	ldr	x9, [sp]
  fc:	ldr	x10, [sp, #8]
 100:	ldr	w11, [sp, #24]
 104:	mov	w12, #0x70                  	// #112
 108:	subs	w11, w12, w11
 10c:	mov	w13, w11
 110:	mov	x14, xzr
 114:	sub	x15, x14, x13
 118:	lsl	x15, x10, x15
 11c:	subs	x16, x13, #0x0
 120:	csel	x14, x14, x15, eq  // eq = none
 124:	mov	w15, w11
 128:	lsr	x9, x9, x15
 12c:	orr	x9, x9, x14
 130:	lsr	x10, x10, x13
 134:	subs	x13, x13, #0x40
 138:	subs	x13, x13, #0x0
 13c:	csel	x9, x10, x9, ge  // ge = tcont
 140:	mul	w8, w8, w9
 144:	stur	w8, [x29, #-4]
 148:	b	16c <__fixint+0x148>
 14c:	ldr	w8, [sp, #28]
 150:	ldr	w9, [sp]
 154:	ldr	w10, [sp, #24]
 158:	subs	w10, w10, #0x70
 15c:	lsl	w9, w9, w10
 160:	mul	w8, w8, w9
 164:	stur	w8, [x29, #-4]
 168:	b	16c <__fixint+0x148>
 16c:	ldur	w0, [x29, #-4]
 170:	ldp	x29, x30, [sp, #112]
 174:	add	sp, sp, #0x80
 178:	ret

000000000000017c <toRep>:
 17c:	sub	sp, sp, #0x20
 180:	str	q0, [sp, #16]
 184:	ldr	q0, [sp, #16]
 188:	str	q0, [sp]
 18c:	ldr	x0, [sp]
 190:	ldr	x1, [sp, #8]
 194:	add	sp, sp, #0x20
 198:	ret

fixtfti.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixtfti>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	q0, [sp]
  10:	ldr	q0, [sp]
  14:	bl	24 <__fixint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixint>:
  24:	sub	sp, sp, #0xb0
  28:	stp	x29, x30, [sp, #160]
  2c:	add	x29, sp, #0xa0
  30:	stur	q0, [x29, #-32]
  34:	mov	x8, #0x7fffffffffffffff    	// #9223372036854775807
  38:	stur	x8, [x29, #-40]
  3c:	mov	x8, #0xffffffffffffffff    	// #-1
  40:	stur	x8, [x29, #-48]
  44:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
  48:	stur	x9, [x29, #-56]
  4c:	mov	x9, xzr
  50:	stur	x9, [x29, #-64]
  54:	ldur	q0, [x29, #-32]
  58:	str	x8, [sp, #8]
  5c:	bl	230 <toRep>
  60:	str	x1, [sp, #88]
  64:	str	x0, [sp, #80]
  68:	ldr	x8, [sp, #80]
  6c:	ldr	x9, [sp, #88]
  70:	and	x9, x9, #0x7fffffffffffffff
  74:	str	x8, [sp, #64]
  78:	str	x9, [sp, #72]
  7c:	ldr	x8, [sp, #88]
  80:	ands	x8, x8, #0x8000000000000000
  84:	ldr	x9, [sp, #8]
  88:	cneg	x10, x9, eq  // eq = none
  8c:	csetm	x11, ne  // ne = any
  90:	str	x11, [sp, #56]
  94:	str	x10, [sp, #48]
  98:	ldrh	w12, [sp, #78]
  9c:	mov	w13, #0xffffc001            	// #-16383
  a0:	add	w12, w12, w13
  a4:	str	w12, [sp, #44]
  a8:	ldr	x10, [sp, #64]
  ac:	ldr	x11, [sp, #72]
  b0:	mov	x14, #0x1000000000000       	// #281474976710656
  b4:	bfxil	x14, x11, #0, #48
  b8:	str	x10, [sp, #16]
  bc:	str	x14, [sp, #24]
  c0:	ldr	w12, [sp, #44]
  c4:	tbz	w12, #31, dc <__fixint+0xb8>
  c8:	b	cc <__fixint+0xa8>
  cc:	mov	x8, xzr
  d0:	stur	x8, [x29, #-8]
  d4:	stur	x8, [x29, #-16]
  d8:	b	21c <__fixint+0x1f8>
  dc:	ldr	w8, [sp, #44]
  e0:	subs	w8, w8, #0x80
  e4:	b.cc	118 <__fixint+0xf4>  // b.lo, b.ul, b.last
  e8:	b	ec <__fixint+0xc8>
  ec:	ldr	x8, [sp, #56]
  f0:	ldr	x9, [sp, #48]
  f4:	eor	x9, x9, #0x1
  f8:	orr	x8, x9, x8
  fc:	subs	x8, x8, #0x0
 100:	csetm	x9, eq  // eq = none
 104:	mov	x10, #0x7fffffffffffffff    	// #9223372036854775807
 108:	cinv	x10, x10, ne  // ne = any
 10c:	stur	x10, [x29, #-8]
 110:	stur	x9, [x29, #-16]
 114:	b	21c <__fixint+0x1f8>
 118:	ldr	w8, [sp, #44]
 11c:	subs	w8, w8, #0x6f
 120:	b.gt	1a4 <__fixint+0x180>
 124:	b	128 <__fixint+0x104>
 128:	ldr	x8, [sp, #56]
 12c:	ldr	x9, [sp, #48]
 130:	ldr	x10, [sp, #16]
 134:	ldr	x11, [sp, #24]
 138:	ldr	w12, [sp, #44]
 13c:	mov	w13, #0x70                  	// #112
 140:	subs	w12, w13, w12
 144:	mov	w14, w12
 148:	mov	x15, xzr
 14c:	sub	x16, x15, x14
 150:	lsl	x16, x11, x16
 154:	subs	x17, x14, #0x0
 158:	csel	x16, x15, x16, eq  // eq = none
 15c:	mov	w18, w12
 160:	lsr	x10, x10, x18
 164:	orr	x10, x10, x16
 168:	lsr	x16, x11, x14
 16c:	subs	x14, x14, #0x40
 170:	subs	x14, x14, #0x0
 174:	csel	x10, x16, x10, ge  // ge = tcont
 178:	lsr	x11, x11, x18
 17c:	csel	x11, x15, x11, ge  // ge = tcont
 180:	mul	x11, x9, x11
 184:	umulh	x15, x9, x10
 188:	add	x11, x15, x11
 18c:	mul	x8, x8, x10
 190:	add	x8, x11, x8
 194:	mul	x9, x9, x10
 198:	stur	x9, [x29, #-16]
 19c:	stur	x8, [x29, #-8]
 1a0:	b	21c <__fixint+0x1f8>
 1a4:	ldr	x8, [sp, #56]
 1a8:	ldr	x9, [sp, #48]
 1ac:	ldr	x10, [sp, #24]
 1b0:	ldr	x11, [sp, #16]
 1b4:	ldr	w12, [sp, #44]
 1b8:	subs	w12, w12, #0x70
 1bc:	mov	w13, w12
 1c0:	mov	x14, xzr
 1c4:	sub	x15, x14, x13
 1c8:	lsr	x15, x11, x15
 1cc:	subs	x16, x13, #0x0
 1d0:	csel	x15, x14, x15, eq  // eq = none
 1d4:	mov	w17, w12
 1d8:	lsl	x10, x10, x17
 1dc:	orr	x10, x15, x10
 1e0:	lsl	x15, x11, x13
 1e4:	subs	x13, x13, #0x40
 1e8:	subs	x13, x13, #0x0
 1ec:	csel	x10, x15, x10, ge  // ge = tcont
 1f0:	lsl	x11, x11, x17
 1f4:	csel	x11, x14, x11, ge  // ge = tcont
 1f8:	mul	x10, x9, x10
 1fc:	umulh	x14, x9, x11
 200:	add	x10, x14, x10
 204:	mul	x8, x8, x11
 208:	add	x8, x10, x8
 20c:	mul	x9, x9, x11
 210:	stur	x9, [x29, #-16]
 214:	stur	x8, [x29, #-8]
 218:	b	21c <__fixint+0x1f8>
 21c:	ldur	x0, [x29, #-16]
 220:	ldur	x1, [x29, #-8]
 224:	ldp	x29, x30, [sp, #160]
 228:	add	sp, sp, #0xb0
 22c:	ret

0000000000000230 <toRep>:
 230:	sub	sp, sp, #0x20
 234:	str	q0, [sp, #16]
 238:	ldr	q0, [sp, #16]
 23c:	str	q0, [sp]
 240:	ldr	x0, [sp]
 244:	ldr	x1, [sp, #8]
 248:	add	sp, sp, #0x20
 24c:	ret

fixunstfdi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunstfdi>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	q0, [sp]
  10:	ldr	q0, [sp]
  14:	bl	24 <__fixuint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixuint>:
  24:	sub	sp, sp, #0x70
  28:	stp	x29, x30, [sp, #96]
  2c:	add	x29, sp, #0x60
  30:	stur	q0, [x29, #-32]
  34:	ldur	q0, [x29, #-32]
  38:	bl	164 <toRep>
  3c:	str	x1, [sp, #56]
  40:	str	x0, [sp, #48]
  44:	ldr	x8, [sp, #48]
  48:	ldr	x9, [sp, #56]
  4c:	and	x9, x9, #0x7fffffffffffffff
  50:	str	x8, [sp, #32]
  54:	str	x9, [sp, #40]
  58:	ldr	x8, [sp, #56]
  5c:	ands	x8, x8, #0x8000000000000000
  60:	mov	w10, #0xffffffff            	// #-1
  64:	cneg	w10, w10, eq  // eq = none
  68:	str	w10, [sp, #28]
  6c:	ldrh	w10, [sp, #46]
  70:	mov	w11, #0xffffc001            	// #-16383
  74:	add	w10, w10, w11
  78:	str	w10, [sp, #24]
  7c:	ldr	x9, [sp, #32]
  80:	ldr	x12, [sp, #40]
  84:	mov	x13, #0x1000000000000       	// #281474976710656
  88:	bfxil	x13, x12, #0, #48
  8c:	str	x9, [sp]
  90:	str	x13, [sp, #8]
  94:	ldr	w10, [sp, #28]
  98:	adds	w10, w10, #0x1
  9c:	b.eq	b0 <__fixuint+0x8c>  // b.none
  a0:	b	a4 <__fixuint+0x80>
  a4:	ldr	w8, [sp, #24]
  a8:	tbz	w8, #31, bc <__fixuint+0x98>
  ac:	b	b0 <__fixuint+0x8c>
  b0:	mov	x8, xzr
  b4:	stur	x8, [x29, #-8]
  b8:	b	154 <__fixuint+0x130>
  bc:	ldr	w8, [sp, #24]
  c0:	subs	w8, w8, #0x40
  c4:	b.cc	d8 <__fixuint+0xb4>  // b.lo, b.ul, b.last
  c8:	b	cc <__fixuint+0xa8>
  cc:	mov	x8, #0xffffffffffffffff    	// #-1
  d0:	stur	x8, [x29, #-8]
  d4:	b	154 <__fixuint+0x130>
  d8:	ldr	w8, [sp, #24]
  dc:	subs	w8, w8, #0x6f
  e0:	b.gt	138 <__fixuint+0x114>
  e4:	b	e8 <__fixuint+0xc4>
  e8:	ldr	x8, [sp]
  ec:	ldr	x9, [sp, #8]
  f0:	ldr	w10, [sp, #24]
  f4:	mov	w11, #0x70                  	// #112
  f8:	subs	w10, w11, w10
  fc:	mov	w12, w10
 100:	mov	x13, xzr
 104:	sub	x14, x13, x12
 108:	lsl	x14, x9, x14
 10c:	subs	x15, x12, #0x0
 110:	csel	x13, x13, x14, eq  // eq = none
 114:	mov	w14, w10
 118:	lsr	x8, x8, x14
 11c:	orr	x8, x8, x13
 120:	lsr	x9, x9, x12
 124:	subs	x12, x12, #0x40
 128:	subs	x12, x12, #0x0
 12c:	csel	x8, x9, x8, ge  // ge = tcont
 130:	stur	x8, [x29, #-8]
 134:	b	154 <__fixuint+0x130>
 138:	ldr	x8, [sp]
 13c:	ldr	w9, [sp, #24]
 140:	subs	w9, w9, #0x70
 144:	mov	w10, w9
 148:	lsl	x8, x8, x10
 14c:	stur	x8, [x29, #-8]
 150:	b	154 <__fixuint+0x130>
 154:	ldur	x0, [x29, #-8]
 158:	ldp	x29, x30, [sp, #96]
 15c:	add	sp, sp, #0x70
 160:	ret

0000000000000164 <toRep>:
 164:	sub	sp, sp, #0x20
 168:	str	q0, [sp, #16]
 16c:	ldr	q0, [sp, #16]
 170:	str	q0, [sp]
 174:	ldr	x0, [sp]
 178:	ldr	x1, [sp, #8]
 17c:	add	sp, sp, #0x20
 180:	ret

fixunstfsi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunstfsi>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	q0, [sp]
  10:	ldr	q0, [sp]
  14:	bl	24 <__fixuint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixuint>:
  24:	sub	sp, sp, #0x70
  28:	stp	x29, x30, [sp, #96]
  2c:	add	x29, sp, #0x60
  30:	stur	q0, [x29, #-32]
  34:	ldur	q0, [x29, #-32]
  38:	bl	160 <toRep>
  3c:	str	x1, [sp, #56]
  40:	str	x0, [sp, #48]
  44:	ldr	x8, [sp, #48]
  48:	ldr	x9, [sp, #56]
  4c:	and	x9, x9, #0x7fffffffffffffff
  50:	str	x8, [sp, #32]
  54:	str	x9, [sp, #40]
  58:	ldr	x8, [sp, #56]
  5c:	ands	x8, x8, #0x8000000000000000
  60:	mov	w10, #0xffffffff            	// #-1
  64:	cneg	w10, w10, eq  // eq = none
  68:	str	w10, [sp, #28]
  6c:	ldrh	w10, [sp, #46]
  70:	mov	w11, #0xffffc001            	// #-16383
  74:	add	w10, w10, w11
  78:	str	w10, [sp, #24]
  7c:	ldr	x9, [sp, #32]
  80:	ldr	x12, [sp, #40]
  84:	mov	x13, #0x1000000000000       	// #281474976710656
  88:	bfxil	x13, x12, #0, #48
  8c:	str	x9, [sp]
  90:	str	x13, [sp, #8]
  94:	ldr	w10, [sp, #28]
  98:	adds	w10, w10, #0x1
  9c:	b.eq	b0 <__fixuint+0x8c>  // b.none
  a0:	b	a4 <__fixuint+0x80>
  a4:	ldr	w8, [sp, #24]
  a8:	tbz	w8, #31, bc <__fixuint+0x98>
  ac:	b	b0 <__fixuint+0x8c>
  b0:	mov	w8, wzr
  b4:	stur	w8, [x29, #-4]
  b8:	b	150 <__fixuint+0x12c>
  bc:	ldr	w8, [sp, #24]
  c0:	subs	w8, w8, #0x20
  c4:	b.cc	d8 <__fixuint+0xb4>  // b.lo, b.ul, b.last
  c8:	b	cc <__fixuint+0xa8>
  cc:	mov	w8, #0xffffffff            	// #-1
  d0:	stur	w8, [x29, #-4]
  d4:	b	150 <__fixuint+0x12c>
  d8:	ldr	w8, [sp, #24]
  dc:	subs	w8, w8, #0x6f
  e0:	b.gt	138 <__fixuint+0x114>
  e4:	b	e8 <__fixuint+0xc4>
  e8:	ldr	x8, [sp]
  ec:	ldr	x9, [sp, #8]
  f0:	ldr	w10, [sp, #24]
  f4:	mov	w11, #0x70                  	// #112
  f8:	subs	w10, w11, w10
  fc:	mov	w12, w10
 100:	mov	x13, xzr
 104:	sub	x14, x13, x12
 108:	lsl	x14, x9, x14
 10c:	subs	x15, x12, #0x0
 110:	csel	x13, x13, x14, eq  // eq = none
 114:	mov	w14, w10
 118:	lsr	x8, x8, x14
 11c:	orr	x8, x8, x13
 120:	lsr	x9, x9, x12
 124:	subs	x12, x12, #0x40
 128:	subs	x12, x12, #0x0
 12c:	csel	x8, x9, x8, ge  // ge = tcont
 130:	stur	w8, [x29, #-4]
 134:	b	150 <__fixuint+0x12c>
 138:	ldr	w8, [sp]
 13c:	ldr	w9, [sp, #24]
 140:	subs	w9, w9, #0x70
 144:	lsl	w8, w8, w9
 148:	stur	w8, [x29, #-4]
 14c:	b	150 <__fixuint+0x12c>
 150:	ldur	w0, [x29, #-4]
 154:	ldp	x29, x30, [sp, #96]
 158:	add	sp, sp, #0x70
 15c:	ret

0000000000000160 <toRep>:
 160:	sub	sp, sp, #0x20
 164:	str	q0, [sp, #16]
 168:	ldr	q0, [sp, #16]
 16c:	str	q0, [sp]
 170:	ldr	x0, [sp]
 174:	ldr	x1, [sp, #8]
 178:	add	sp, sp, #0x20
 17c:	ret

fixunstfti.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunstfti>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	q0, [sp]
  10:	ldr	q0, [sp]
  14:	bl	24 <__fixuint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixuint>:
  24:	sub	sp, sp, #0x70
  28:	stp	x29, x30, [sp, #96]
  2c:	add	x29, sp, #0x60
  30:	stur	q0, [x29, #-32]
  34:	ldur	q0, [x29, #-32]
  38:	bl	1b8 <toRep>
  3c:	str	x1, [sp, #56]
  40:	str	x0, [sp, #48]
  44:	ldr	x8, [sp, #48]
  48:	ldr	x9, [sp, #56]
  4c:	and	x9, x9, #0x7fffffffffffffff
  50:	str	x8, [sp, #32]
  54:	str	x9, [sp, #40]
  58:	ldr	x8, [sp, #56]
  5c:	ands	x8, x8, #0x8000000000000000
  60:	mov	w10, #0xffffffff            	// #-1
  64:	cneg	w10, w10, eq  // eq = none
  68:	str	w10, [sp, #28]
  6c:	ldrh	w10, [sp, #46]
  70:	mov	w11, #0xffffc001            	// #-16383
  74:	add	w10, w10, w11
  78:	str	w10, [sp, #24]
  7c:	ldr	x9, [sp, #32]
  80:	ldr	x12, [sp, #40]
  84:	mov	x13, #0x1000000000000       	// #281474976710656
  88:	bfxil	x13, x12, #0, #48
  8c:	str	x9, [sp]
  90:	str	x13, [sp, #8]
  94:	ldr	w10, [sp, #28]
  98:	adds	w10, w10, #0x1
  9c:	b.eq	b0 <__fixuint+0x8c>  // b.none
  a0:	b	a4 <__fixuint+0x80>
  a4:	ldr	w8, [sp, #24]
  a8:	tbz	w8, #31, c0 <__fixuint+0x9c>
  ac:	b	b0 <__fixuint+0x8c>
  b0:	mov	x8, xzr
  b4:	stur	x8, [x29, #-8]
  b8:	stur	x8, [x29, #-16]
  bc:	b	1a4 <__fixuint+0x180>
  c0:	ldr	w8, [sp, #24]
  c4:	subs	w8, w8, #0x80
  c8:	b.cc	e0 <__fixuint+0xbc>  // b.lo, b.ul, b.last
  cc:	b	d0 <__fixuint+0xac>
  d0:	mov	x8, #0xffffffffffffffff    	// #-1
  d4:	stur	x8, [x29, #-8]
  d8:	stur	x8, [x29, #-16]
  dc:	b	1a4 <__fixuint+0x180>
  e0:	ldr	w8, [sp, #24]
  e4:	subs	w8, w8, #0x6f
  e8:	b.gt	14c <__fixuint+0x128>
  ec:	b	f0 <__fixuint+0xcc>
  f0:	ldr	x8, [sp]
  f4:	ldr	x9, [sp, #8]
  f8:	ldr	w10, [sp, #24]
  fc:	mov	w11, #0x70                  	// #112
 100:	subs	w10, w11, w10
 104:	mov	w12, w10
 108:	mov	x13, xzr
 10c:	sub	x14, x13, x12
 110:	lsl	x14, x9, x14
 114:	subs	x15, x12, #0x0
 118:	csel	x14, x13, x14, eq  // eq = none
 11c:	mov	w16, w10
 120:	lsr	x8, x8, x16
 124:	orr	x8, x8, x14
 128:	lsr	x14, x9, x12
 12c:	subs	x12, x12, #0x40
 130:	subs	x12, x12, #0x0
 134:	csel	x8, x14, x8, ge  // ge = tcont
 138:	lsr	x9, x9, x16
 13c:	csel	x9, x13, x9, ge  // ge = tcont
 140:	stur	x9, [x29, #-8]
 144:	stur	x8, [x29, #-16]
 148:	b	1a4 <__fixuint+0x180>
 14c:	ldr	x8, [sp, #8]
 150:	ldr	x9, [sp]
 154:	ldr	w10, [sp, #24]
 158:	subs	w10, w10, #0x70
 15c:	mov	w11, w10
 160:	mov	x12, xzr
 164:	sub	x13, x12, x11
 168:	lsr	x13, x9, x13
 16c:	subs	x14, x11, #0x0
 170:	csel	x13, x12, x13, eq  // eq = none
 174:	mov	w15, w10
 178:	lsl	x8, x8, x15
 17c:	orr	x8, x13, x8
 180:	lsl	x13, x9, x11
 184:	subs	x11, x11, #0x40
 188:	subs	x11, x11, #0x0
 18c:	csel	x8, x13, x8, ge  // ge = tcont
 190:	lsl	x9, x9, x15
 194:	csel	x9, x12, x9, ge  // ge = tcont
 198:	stur	x9, [x29, #-16]
 19c:	stur	x8, [x29, #-8]
 1a0:	b	1a4 <__fixuint+0x180>
 1a4:	ldur	x0, [x29, #-16]
 1a8:	ldur	x1, [x29, #-8]
 1ac:	ldp	x29, x30, [sp, #96]
 1b0:	add	sp, sp, #0x70
 1b4:	ret

00000000000001b8 <toRep>:
 1b8:	sub	sp, sp, #0x20
 1bc:	str	q0, [sp, #16]
 1c0:	ldr	q0, [sp, #16]
 1c4:	str	q0, [sp]
 1c8:	ldr	x0, [sp]
 1cc:	ldr	x1, [sp, #8]
 1d0:	add	sp, sp, #0x20
 1d4:	ret

floatditf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatditf>:
   0:	sub	sp, sp, #0x80
   4:	stp	x29, x30, [sp, #112]
   8:	add	x29, sp, #0x70
   c:	stur	x0, [x29, #-24]
  10:	mov	w8, #0x40                  	// #64
  14:	stur	w8, [x29, #-28]
  18:	ldur	x9, [x29, #-24]
  1c:	cbnz	x9, 3c <__floatditf+0x3c>
  20:	b	24 <__floatditf+0x24>
  24:	mov	x0, xzr
  28:	str	x0, [sp, #16]
  2c:	ldr	x1, [sp, #16]
  30:	bl	140 <fromRep>
  34:	stur	q0, [x29, #-16]
  38:	b	130 <__floatditf+0x130>
  3c:	mov	x8, xzr
  40:	stur	x8, [x29, #-40]
  44:	stur	x8, [x29, #-48]
  48:	ldur	x8, [x29, #-24]
  4c:	str	x8, [sp, #56]
  50:	ldur	x8, [x29, #-24]
  54:	tbz	x8, #63, 7c <__floatditf+0x7c>
  58:	b	5c <__floatditf+0x5c>
  5c:	mov	x8, #0x8000000000000000    	// #-9223372036854775808
  60:	stur	x8, [x29, #-40]
  64:	mov	x8, xzr
  68:	stur	x8, [x29, #-48]
  6c:	ldur	x9, [x29, #-24]
  70:	subs	x8, x8, x9
  74:	str	x8, [sp, #56]
  78:	b	7c <__floatditf+0x7c>
  7c:	ldr	x8, [sp, #56]
  80:	clz	x8, x8
  84:	mov	w9, #0x3f                  	// #63
  88:	subs	w8, w9, w8
  8c:	str	w8, [sp, #52]
  90:	ldr	w8, [sp, #52]
  94:	mov	w9, #0x70                  	// #112
  98:	subs	w8, w9, w8
  9c:	str	w8, [sp, #28]
  a0:	ldr	x10, [sp, #56]
  a4:	ldr	w8, [sp, #28]
  a8:	mov	w11, w8
  ac:	mov	x12, xzr
  b0:	sub	x13, x12, x11
  b4:	lsr	x13, x10, x13
  b8:	subs	x14, x11, #0x0
  bc:	csel	x13, x12, x13, eq  // eq = none
  c0:	lsl	x10, x10, x11
  c4:	subs	x11, x11, #0x40
  c8:	subs	x11, x11, #0x0
  cc:	csel	x13, x10, x13, ge  // ge = tcont
  d0:	csel	x10, x12, x10, ge  // ge = tcont
  d4:	eor	x12, x13, #0x1000000000000
  d8:	str	x10, [sp, #32]
  dc:	str	x12, [sp, #40]
  e0:	ldr	w8, [sp, #52]
  e4:	mov	w9, #0x3fff                	// #16383
  e8:	add	w8, w8, w9
  ec:	mov	w0, w8
  f0:	ldr	x10, [sp, #32]
  f4:	ldr	x12, [sp, #40]
  f8:	add	x12, x12, x0, lsl #48
  fc:	str	x10, [sp, #32]
 100:	str	x12, [sp, #40]
 104:	ldr	x10, [sp, #40]
 108:	ldr	x12, [sp, #32]
 10c:	ldur	x13, [x29, #-40]
 110:	ldur	x15, [x29, #-48]
 114:	orr	x0, x12, x15
 118:	orr	x1, x10, x13
 11c:	str	x14, [sp, #8]
 120:	str	x11, [sp]
 124:	bl	140 <fromRep>
 128:	stur	q0, [x29, #-16]
 12c:	b	130 <__floatditf+0x130>
 130:	ldur	q0, [x29, #-16]
 134:	ldp	x29, x30, [sp, #112]
 138:	add	sp, sp, #0x80
 13c:	ret

0000000000000140 <fromRep>:
 140:	sub	sp, sp, #0x20
 144:	mov	v0.d[0], x0
 148:	mov	v0.d[1], x1
 14c:	str	q0, [sp, #16]
 150:	ldr	q0, [sp, #16]
 154:	str	q0, [sp]
 158:	ldr	q0, [sp]
 15c:	add	sp, sp, #0x20
 160:	ret

floatsitf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatsitf>:
   0:	sub	sp, sp, #0x80
   4:	stp	x29, x30, [sp, #112]
   8:	add	x29, sp, #0x70
   c:	stur	w0, [x29, #-20]
  10:	mov	w8, #0x20                  	// #32
  14:	stur	w8, [x29, #-24]
  18:	ldur	w8, [x29, #-20]
  1c:	cbnz	w8, 3c <__floatsitf+0x3c>
  20:	b	24 <__floatsitf+0x24>
  24:	mov	x0, xzr
  28:	str	x0, [sp, #16]
  2c:	ldr	x1, [sp, #16]
  30:	bl	148 <fromRep>
  34:	stur	q0, [x29, #-16]
  38:	b	138 <__floatsitf+0x138>
  3c:	mov	x8, xzr
  40:	stur	x8, [x29, #-40]
  44:	stur	x8, [x29, #-48]
  48:	ldur	w9, [x29, #-20]
  4c:	stur	w9, [x29, #-52]
  50:	ldur	w9, [x29, #-20]
  54:	tbz	w9, #31, 80 <__floatsitf+0x80>
  58:	b	5c <__floatsitf+0x5c>
  5c:	mov	x8, #0x8000000000000000    	// #-9223372036854775808
  60:	stur	x8, [x29, #-40]
  64:	mov	x8, xzr
  68:	stur	x8, [x29, #-48]
  6c:	ldur	w9, [x29, #-20]
  70:	mov	w10, wzr
  74:	subs	w9, w10, w9
  78:	stur	w9, [x29, #-52]
  7c:	b	80 <__floatsitf+0x80>
  80:	ldur	w8, [x29, #-52]
  84:	clz	w8, w8
  88:	mov	w9, #0x1f                  	// #31
  8c:	subs	w8, w9, w8
  90:	str	w8, [sp, #56]
  94:	ldr	w8, [sp, #56]
  98:	mov	w9, #0x70                  	// #112
  9c:	subs	w8, w9, w8
  a0:	str	w8, [sp, #28]
  a4:	ldur	w8, [x29, #-52]
  a8:	mov	w10, w8
  ac:	ldr	w8, [sp, #28]
  b0:	mov	w11, w8
  b4:	mov	x12, xzr
  b8:	sub	x13, x12, x11
  bc:	lsr	x13, x10, x13
  c0:	subs	x14, x11, #0x0
  c4:	csel	x13, x12, x13, eq  // eq = none
  c8:	lsl	x10, x10, x11
  cc:	subs	x11, x11, #0x40
  d0:	subs	x11, x11, #0x0
  d4:	csel	x13, x10, x13, ge  // ge = tcont
  d8:	csel	x10, x12, x10, ge  // ge = tcont
  dc:	eor	x12, x13, #0x1000000000000
  e0:	str	x10, [sp, #32]
  e4:	str	x12, [sp, #40]
  e8:	ldr	w8, [sp, #56]
  ec:	mov	w9, #0x3fff                	// #16383
  f0:	add	w8, w8, w9
  f4:	mov	w0, w8
  f8:	ldr	x10, [sp, #32]
  fc:	ldr	x12, [sp, #40]
 100:	add	x12, x12, x0, lsl #48
 104:	str	x10, [sp, #32]
 108:	str	x12, [sp, #40]
 10c:	ldr	x10, [sp, #40]
 110:	ldr	x12, [sp, #32]
 114:	ldur	x13, [x29, #-40]
 118:	ldur	x15, [x29, #-48]
 11c:	orr	x0, x12, x15
 120:	orr	x1, x10, x13
 124:	str	x14, [sp, #8]
 128:	str	x11, [sp]
 12c:	bl	148 <fromRep>
 130:	stur	q0, [x29, #-16]
 134:	b	138 <__floatsitf+0x138>
 138:	ldur	q0, [x29, #-16]
 13c:	ldp	x29, x30, [sp, #112]
 140:	add	sp, sp, #0x80
 144:	ret

0000000000000148 <fromRep>:
 148:	sub	sp, sp, #0x20
 14c:	mov	v0.d[0], x0
 150:	mov	v0.d[1], x1
 154:	str	q0, [sp, #16]
 158:	ldr	q0, [sp, #16]
 15c:	str	q0, [sp]
 160:	ldr	q0, [sp]
 164:	add	sp, sp, #0x20
 168:	ret

floattitf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floattitf>:
   0:	sub	sp, sp, #0x80
   4:	stp	x29, x30, [sp, #112]
   8:	add	x29, sp, #0x70
   c:	stur	x1, [x29, #-24]
  10:	stur	x0, [x29, #-32]
  14:	ldur	x8, [x29, #-24]
  18:	ldur	x9, [x29, #-32]
  1c:	orr	x8, x9, x8
  20:	cbnz	x8, 38 <__floattitf+0x38>
  24:	b	28 <__floattitf+0x28>
  28:	adrp	x8, 0 <__floattitf>
  2c:	ldr	q0, [x8]
  30:	stur	q0, [x29, #-16]
  34:	b	2b8 <__floattitf+0x2b8>
  38:	mov	w8, #0x80                  	// #128
  3c:	stur	w8, [x29, #-36]
  40:	ldur	x9, [x29, #-24]
  44:	asr	x9, x9, #63
  48:	str	x9, [sp, #56]
  4c:	str	x9, [sp, #48]
  50:	ldur	x9, [x29, #-32]
  54:	ldur	x10, [x29, #-24]
  58:	ldr	x11, [sp, #48]
  5c:	ldr	x12, [sp, #56]
  60:	eor	x10, x10, x12
  64:	eor	x9, x9, x11
  68:	subs	x9, x9, x11
  6c:	sbcs	x10, x10, x12
  70:	stur	x9, [x29, #-32]
  74:	stur	x10, [x29, #-24]
  78:	ldur	x1, [x29, #-24]
  7c:	ldur	x0, [x29, #-32]
  80:	str	w8, [sp, #12]
  84:	bl	0 <__clzti2>
  88:	ldr	w8, [sp, #12]
  8c:	subs	w13, w8, w0
  90:	str	w13, [sp, #44]
  94:	ldr	w13, [sp, #44]
  98:	subs	w13, w13, #0x1
  9c:	str	w13, [sp, #40]
  a0:	ldr	w13, [sp, #44]
  a4:	subs	w13, w13, #0x72
  a8:	b.lt	220 <__floattitf+0x220>  // b.tstop
  ac:	b	b0 <__floattitf+0xb0>
  b0:	ldr	w8, [sp, #44]
  b4:	mov	w9, w8
  b8:	subs	w8, w8, #0x72
  bc:	str	w9, [sp, #8]
  c0:	b.eq	d8 <__floattitf+0xd8>  // b.none
  c4:	b	c8 <__floattitf+0xc8>
  c8:	ldr	w8, [sp, #8]
  cc:	subs	w9, w8, #0x73
  d0:	b.eq	f4 <__floattitf+0xf4>  // b.none
  d4:	b	f8 <__floattitf+0xf8>
  d8:	ldur	x8, [x29, #-32]
  dc:	ldur	x9, [x29, #-24]
  e0:	extr	x9, x9, x8, #63
  e4:	lsl	x8, x8, #1
  e8:	stur	x9, [x29, #-24]
  ec:	stur	x8, [x29, #-32]
  f0:	b	1a4 <__floattitf+0x1a4>
  f4:	b	1a4 <__floattitf+0x1a4>
  f8:	ldur	x8, [x29, #-32]
  fc:	ldur	x9, [x29, #-24]
 100:	ldr	w10, [sp, #44]
 104:	subs	w11, w10, #0x73
 108:	mov	w12, w11
 10c:	mov	x13, xzr
 110:	sub	x14, x13, x12
 114:	lsl	x14, x9, x14
 118:	subs	x15, x12, #0x0
 11c:	csel	x14, x13, x14, eq  // eq = none
 120:	mov	w16, w11
 124:	lsr	x17, x8, x16
 128:	orr	x14, x17, x14
 12c:	lsr	x17, x9, x12
 130:	subs	x12, x12, #0x40
 134:	subs	x12, x12, #0x0
 138:	csel	x14, x17, x14, ge  // ge = tcont
 13c:	lsr	x16, x9, x16
 140:	csel	x16, x13, x16, ge  // ge = tcont
 144:	mov	w11, #0xf3                  	// #243
 148:	subs	w10, w11, w10
 14c:	mov	w17, w10
 150:	sub	x18, x13, x17
 154:	lsr	x18, x8, x18
 158:	subs	x0, x17, #0x0
 15c:	csel	x18, x13, x18, eq  // eq = none
 160:	mov	w1, w10
 164:	lsl	x2, x8, x1
 168:	subs	x3, x17, #0x40
 16c:	subs	x3, x3, #0x0
 170:	csel	x13, x13, x2, ge  // ge = tcont
 174:	lsl	x9, x9, x1
 178:	orr	x9, x18, x9
 17c:	lsl	x8, x8, x17
 180:	csel	x8, x8, x9, ge  // ge = tcont
 184:	orr	x8, x13, x8
 188:	subs	x8, x8, #0x0
 18c:	cset	w10, ne  // ne = any
 190:	mov	w9, w10
 194:	orr	x9, x14, x9
 198:	stur	x16, [x29, #-24]
 19c:	stur	x9, [x29, #-32]
 1a0:	b	1a4 <__floattitf+0x1a4>
 1a4:	ldur	x8, [x29, #-32]
 1a8:	and	x9, x8, #0x4
 1ac:	orr	x8, x8, x9, lsr #2
 1b0:	stur	x8, [x29, #-32]
 1b4:	ldur	x8, [x29, #-24]
 1b8:	ldur	x9, [x29, #-32]
 1bc:	adds	x9, x9, #0x1
 1c0:	mov	x10, xzr
 1c4:	adcs	x8, x8, x10
 1c8:	stur	x9, [x29, #-32]
 1cc:	stur	x8, [x29, #-24]
 1d0:	ldur	x8, [x29, #-32]
 1d4:	ldur	x9, [x29, #-24]
 1d8:	extr	x8, x9, x8, #2
 1dc:	asr	x9, x9, #2
 1e0:	stur	x9, [x29, #-24]
 1e4:	stur	x8, [x29, #-32]
 1e8:	ldurb	w11, [x29, #-18]
 1ec:	tbz	w11, #1, 21c <__floattitf+0x21c>
 1f0:	b	1f4 <__floattitf+0x1f4>
 1f4:	ldur	x8, [x29, #-32]
 1f8:	ldur	x9, [x29, #-24]
 1fc:	extr	x8, x9, x8, #1
 200:	asr	x9, x9, #1
 204:	stur	x9, [x29, #-24]
 208:	stur	x8, [x29, #-32]
 20c:	ldr	w10, [sp, #40]
 210:	add	w10, w10, #0x1
 214:	str	w10, [sp, #40]
 218:	b	21c <__floattitf+0x21c>
 21c:	b	27c <__floattitf+0x27c>
 220:	ldr	w8, [sp, #44]
 224:	mov	w9, #0x71                  	// #113
 228:	subs	w8, w9, w8
 22c:	ldur	x10, [x29, #-24]
 230:	ldur	x11, [x29, #-32]
 234:	mov	w12, w8
 238:	mov	x13, xzr
 23c:	sub	x14, x13, x12
 240:	lsr	x14, x11, x14
 244:	subs	x15, x12, #0x0
 248:	csel	x14, x13, x14, eq  // eq = none
 24c:	mov	w16, w8
 250:	lsl	x10, x10, x16
 254:	orr	x10, x14, x10
 258:	lsl	x14, x11, x12
 25c:	subs	x12, x12, #0x40
 260:	subs	x12, x12, #0x0
 264:	csel	x10, x14, x10, ge  // ge = tcont
 268:	lsl	x11, x11, x16
 26c:	csel	x11, x13, x11, ge  // ge = tcont
 270:	stur	x11, [x29, #-32]
 274:	stur	x10, [x29, #-24]
 278:	b	27c <__floattitf+0x27c>
 27c:	ldr	x8, [sp, #48]
 280:	and	x8, x8, #0x8000000000000000
 284:	ldr	w9, [sp, #40]
 288:	mov	w10, #0x3fff                	// #16383
 28c:	add	w9, w9, w10
 290:	mov	w0, w9
 294:	orr	x8, x8, x0, lsl #48
 298:	ldur	x11, [x29, #-24]
 29c:	bfxil	x8, x11, #0, #48
 2a0:	str	x8, [sp, #24]
 2a4:	ldur	x8, [x29, #-32]
 2a8:	str	x8, [sp, #16]
 2ac:	ldr	q0, [sp, #16]
 2b0:	stur	q0, [x29, #-16]
 2b4:	b	2b8 <__floattitf+0x2b8>
 2b8:	ldur	q0, [x29, #-16]
 2bc:	ldp	x29, x30, [sp, #112]
 2c0:	add	sp, sp, #0x80
 2c4:	ret

floatunditf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatunditf>:
   0:	sub	sp, sp, #0x60
   4:	stp	x29, x30, [sp, #80]
   8:	add	x29, sp, #0x50
   c:	stur	x0, [x29, #-24]
  10:	mov	w8, #0x40                  	// #64
  14:	stur	w8, [x29, #-28]
  18:	ldur	x9, [x29, #-24]
  1c:	cbnz	x9, 3c <__floatunditf+0x3c>
  20:	b	24 <__floatunditf+0x24>
  24:	mov	x0, xzr
  28:	str	x0, [sp, #16]
  2c:	ldr	x1, [sp, #16]
  30:	bl	f0 <fromRep>
  34:	stur	q0, [x29, #-16]
  38:	b	e0 <__floatunditf+0xe0>
  3c:	ldur	x8, [x29, #-24]
  40:	clz	x8, x8
  44:	mov	w9, #0x3f                  	// #63
  48:	subs	w8, w9, w8
  4c:	stur	w8, [x29, #-32]
  50:	ldur	w8, [x29, #-32]
  54:	mov	w9, #0x70                  	// #112
  58:	subs	w8, w9, w8
  5c:	str	w8, [sp, #28]
  60:	ldur	x10, [x29, #-24]
  64:	ldr	w8, [sp, #28]
  68:	mov	w11, w8
  6c:	mov	x12, xzr
  70:	sub	x13, x12, x11
  74:	lsr	x13, x10, x13
  78:	subs	x14, x11, #0x0
  7c:	csel	x13, x12, x13, eq  // eq = none
  80:	lsl	x10, x10, x11
  84:	subs	x11, x11, #0x40
  88:	subs	x11, x11, #0x0
  8c:	csel	x13, x10, x13, ge  // ge = tcont
  90:	csel	x10, x12, x10, ge  // ge = tcont
  94:	eor	x12, x13, #0x1000000000000
  98:	str	x10, [sp, #32]
  9c:	str	x12, [sp, #40]
  a0:	ldur	w8, [x29, #-32]
  a4:	mov	w9, #0x3fff                	// #16383
  a8:	add	w8, w8, w9
  ac:	mov	w0, w8
  b0:	ldr	x10, [sp, #32]
  b4:	ldr	x12, [sp, #40]
  b8:	add	x12, x12, x0, lsl #48
  bc:	str	x10, [sp, #32]
  c0:	str	x12, [sp, #40]
  c4:	ldr	x1, [sp, #40]
  c8:	ldr	x0, [sp, #32]
  cc:	str	x14, [sp, #8]
  d0:	str	x11, [sp]
  d4:	bl	f0 <fromRep>
  d8:	stur	q0, [x29, #-16]
  dc:	b	e0 <__floatunditf+0xe0>
  e0:	ldur	q0, [x29, #-16]
  e4:	ldp	x29, x30, [sp, #80]
  e8:	add	sp, sp, #0x60
  ec:	ret

00000000000000f0 <fromRep>:
  f0:	sub	sp, sp, #0x20
  f4:	mov	v0.d[0], x0
  f8:	mov	v0.d[1], x1
  fc:	str	q0, [sp, #16]
 100:	ldr	q0, [sp, #16]
 104:	str	q0, [sp]
 108:	ldr	q0, [sp]
 10c:	add	sp, sp, #0x20
 110:	ret

floatunsitf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatunsitf>:
   0:	sub	sp, sp, #0x60
   4:	stp	x29, x30, [sp, #80]
   8:	add	x29, sp, #0x50
   c:	stur	w0, [x29, #-20]
  10:	mov	w8, #0x20                  	// #32
  14:	stur	w8, [x29, #-24]
  18:	ldur	w8, [x29, #-20]
  1c:	cbnz	w8, 3c <__floatunsitf+0x3c>
  20:	b	24 <__floatunsitf+0x24>
  24:	mov	x0, xzr
  28:	str	x0, [sp, #16]
  2c:	ldr	x1, [sp, #16]
  30:	bl	f4 <fromRep>
  34:	stur	q0, [x29, #-16]
  38:	b	e4 <__floatunsitf+0xe4>
  3c:	ldur	w8, [x29, #-20]
  40:	clz	w8, w8
  44:	mov	w9, #0x1f                  	// #31
  48:	subs	w8, w9, w8
  4c:	stur	w8, [x29, #-28]
  50:	ldur	w8, [x29, #-28]
  54:	mov	w9, #0x70                  	// #112
  58:	subs	w8, w9, w8
  5c:	str	w8, [sp, #28]
  60:	ldur	w8, [x29, #-20]
  64:	mov	w10, w8
  68:	ldr	w8, [sp, #28]
  6c:	mov	w11, w8
  70:	mov	x12, xzr
  74:	sub	x13, x12, x11
  78:	lsr	x13, x10, x13
  7c:	subs	x14, x11, #0x0
  80:	csel	x13, x12, x13, eq  // eq = none
  84:	lsl	x10, x10, x11
  88:	subs	x11, x11, #0x40
  8c:	subs	x11, x11, #0x0
  90:	csel	x13, x10, x13, ge  // ge = tcont
  94:	csel	x10, x12, x10, ge  // ge = tcont
  98:	eor	x12, x13, #0x1000000000000
  9c:	str	x10, [sp, #32]
  a0:	str	x12, [sp, #40]
  a4:	ldur	w8, [x29, #-28]
  a8:	mov	w9, #0x3fff                	// #16383
  ac:	add	w8, w8, w9
  b0:	mov	w0, w8
  b4:	ldr	x10, [sp, #32]
  b8:	ldr	x12, [sp, #40]
  bc:	add	x12, x12, x0, lsl #48
  c0:	str	x10, [sp, #32]
  c4:	str	x12, [sp, #40]
  c8:	ldr	x1, [sp, #40]
  cc:	ldr	x0, [sp, #32]
  d0:	str	x14, [sp, #8]
  d4:	str	x11, [sp]
  d8:	bl	f4 <fromRep>
  dc:	stur	q0, [x29, #-16]
  e0:	b	e4 <__floatunsitf+0xe4>
  e4:	ldur	q0, [x29, #-16]
  e8:	ldp	x29, x30, [sp, #80]
  ec:	add	sp, sp, #0x60
  f0:	ret

00000000000000f4 <fromRep>:
  f4:	sub	sp, sp, #0x20
  f8:	mov	v0.d[0], x0
  fc:	mov	v0.d[1], x1
 100:	str	q0, [sp, #16]
 104:	ldr	q0, [sp, #16]
 108:	str	q0, [sp]
 10c:	ldr	q0, [sp]
 110:	add	sp, sp, #0x20
 114:	ret

floatuntitf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatuntitf>:
   0:	sub	sp, sp, #0x60
   4:	stp	x29, x30, [sp, #80]
   8:	add	x29, sp, #0x50
   c:	stur	x1, [x29, #-24]
  10:	stur	x0, [x29, #-32]
  14:	ldur	x8, [x29, #-24]
  18:	ldur	x9, [x29, #-32]
  1c:	orr	x8, x9, x8
  20:	cbnz	x8, 38 <__floatuntitf+0x38>
  24:	b	28 <__floatuntitf+0x28>
  28:	adrp	x8, 0 <__floatuntitf>
  2c:	ldr	q0, [x8]
  30:	stur	q0, [x29, #-16]
  34:	b	274 <__floatuntitf+0x274>
  38:	mov	w8, #0x80                  	// #128
  3c:	stur	w8, [x29, #-36]
  40:	ldur	x1, [x29, #-24]
  44:	ldur	x0, [x29, #-32]
  48:	str	w8, [sp, #12]
  4c:	bl	0 <__clzti2>
  50:	ldr	w8, [sp, #12]
  54:	subs	w9, w8, w0
  58:	str	w9, [sp, #40]
  5c:	ldr	w9, [sp, #40]
  60:	subs	w9, w9, #0x1
  64:	str	w9, [sp, #36]
  68:	ldr	w9, [sp, #40]
  6c:	subs	w9, w9, #0x72
  70:	b.lt	1e8 <__floatuntitf+0x1e8>  // b.tstop
  74:	b	78 <__floatuntitf+0x78>
  78:	ldr	w8, [sp, #40]
  7c:	mov	w9, w8
  80:	subs	w8, w8, #0x72
  84:	str	w9, [sp, #8]
  88:	b.eq	a0 <__floatuntitf+0xa0>  // b.none
  8c:	b	90 <__floatuntitf+0x90>
  90:	ldr	w8, [sp, #8]
  94:	subs	w9, w8, #0x73
  98:	b.eq	bc <__floatuntitf+0xbc>  // b.none
  9c:	b	c0 <__floatuntitf+0xc0>
  a0:	ldur	x8, [x29, #-32]
  a4:	ldur	x9, [x29, #-24]
  a8:	extr	x9, x9, x8, #63
  ac:	lsl	x8, x8, #1
  b0:	stur	x9, [x29, #-24]
  b4:	stur	x8, [x29, #-32]
  b8:	b	16c <__floatuntitf+0x16c>
  bc:	b	16c <__floatuntitf+0x16c>
  c0:	ldur	x8, [x29, #-32]
  c4:	ldur	x9, [x29, #-24]
  c8:	ldr	w10, [sp, #40]
  cc:	subs	w11, w10, #0x73
  d0:	mov	w12, w11
  d4:	mov	x13, xzr
  d8:	sub	x14, x13, x12
  dc:	lsl	x14, x9, x14
  e0:	subs	x15, x12, #0x0
  e4:	csel	x14, x13, x14, eq  // eq = none
  e8:	mov	w16, w11
  ec:	lsr	x17, x8, x16
  f0:	orr	x14, x17, x14
  f4:	lsr	x17, x9, x12
  f8:	subs	x12, x12, #0x40
  fc:	subs	x12, x12, #0x0
 100:	csel	x14, x17, x14, ge  // ge = tcont
 104:	lsr	x16, x9, x16
 108:	csel	x16, x13, x16, ge  // ge = tcont
 10c:	mov	w11, #0xf3                  	// #243
 110:	subs	w10, w11, w10
 114:	mov	w17, w10
 118:	sub	x18, x13, x17
 11c:	lsr	x18, x8, x18
 120:	subs	x0, x17, #0x0
 124:	csel	x18, x13, x18, eq  // eq = none
 128:	mov	w1, w10
 12c:	lsl	x2, x8, x1
 130:	subs	x3, x17, #0x40
 134:	subs	x3, x3, #0x0
 138:	csel	x13, x13, x2, ge  // ge = tcont
 13c:	lsl	x9, x9, x1
 140:	orr	x9, x18, x9
 144:	lsl	x8, x8, x17
 148:	csel	x8, x8, x9, ge  // ge = tcont
 14c:	orr	x8, x13, x8
 150:	subs	x8, x8, #0x0
 154:	cset	w10, ne  // ne = any
 158:	mov	w9, w10
 15c:	orr	x9, x14, x9
 160:	stur	x16, [x29, #-24]
 164:	stur	x9, [x29, #-32]
 168:	b	16c <__floatuntitf+0x16c>
 16c:	ldur	x8, [x29, #-32]
 170:	and	x9, x8, #0x4
 174:	orr	x8, x8, x9, lsr #2
 178:	stur	x8, [x29, #-32]
 17c:	ldur	x8, [x29, #-24]
 180:	ldur	x9, [x29, #-32]
 184:	adds	x9, x9, #0x1
 188:	mov	x10, xzr
 18c:	adcs	x8, x8, x10
 190:	stur	x9, [x29, #-32]
 194:	stur	x8, [x29, #-24]
 198:	ldur	x8, [x29, #-32]
 19c:	ldur	x9, [x29, #-24]
 1a0:	extr	x8, x9, x8, #2
 1a4:	lsr	x9, x9, #2
 1a8:	stur	x9, [x29, #-24]
 1ac:	stur	x8, [x29, #-32]
 1b0:	ldurb	w11, [x29, #-18]
 1b4:	tbz	w11, #1, 1e4 <__floatuntitf+0x1e4>
 1b8:	b	1bc <__floatuntitf+0x1bc>
 1bc:	ldur	x8, [x29, #-32]
 1c0:	ldur	x9, [x29, #-24]
 1c4:	extr	x8, x9, x8, #1
 1c8:	lsr	x9, x9, #1
 1cc:	stur	x9, [x29, #-24]
 1d0:	stur	x8, [x29, #-32]
 1d4:	ldr	w10, [sp, #36]
 1d8:	add	w10, w10, #0x1
 1dc:	str	w10, [sp, #36]
 1e0:	b	1e4 <__floatuntitf+0x1e4>
 1e4:	b	244 <__floatuntitf+0x244>
 1e8:	ldr	w8, [sp, #40]
 1ec:	mov	w9, #0x71                  	// #113
 1f0:	subs	w8, w9, w8
 1f4:	ldur	x10, [x29, #-24]
 1f8:	ldur	x11, [x29, #-32]
 1fc:	mov	w12, w8
 200:	mov	x13, xzr
 204:	sub	x14, x13, x12
 208:	lsr	x14, x11, x14
 20c:	subs	x15, x12, #0x0
 210:	csel	x14, x13, x14, eq  // eq = none
 214:	mov	w16, w8
 218:	lsl	x10, x10, x16
 21c:	orr	x10, x14, x10
 220:	lsl	x14, x11, x12
 224:	subs	x12, x12, #0x40
 228:	subs	x12, x12, #0x0
 22c:	csel	x10, x14, x10, ge  // ge = tcont
 230:	lsl	x11, x11, x16
 234:	csel	x11, x13, x11, ge  // ge = tcont
 238:	stur	x11, [x29, #-32]
 23c:	stur	x10, [x29, #-24]
 240:	b	244 <__floatuntitf+0x244>
 244:	ldr	w8, [sp, #36]
 248:	mov	w9, #0x3fff                	// #16383
 24c:	add	w8, w8, w9
 250:	mov	w0, w8
 254:	ldur	x10, [x29, #-24]
 258:	bfi	x10, x0, #48, #16
 25c:	str	x10, [sp, #24]
 260:	ldur	x10, [x29, #-32]
 264:	str	x10, [sp, #16]
 268:	ldr	q0, [sp, #16]
 26c:	stur	q0, [x29, #-16]
 270:	b	274 <__floatuntitf+0x274>
 274:	ldur	q0, [x29, #-16]
 278:	ldp	x29, x30, [sp, #80]
 27c:	add	sp, sp, #0x60
 280:	ret

multc3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__multc3>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	str	x28, [sp, #16]
   8:	mov	x29, sp
   c:	sub	sp, sp, #0x4a0
  10:	stur	q0, [x29, #-48]
  14:	stur	q1, [x29, #-64]
  18:	stur	q2, [x29, #-80]
  1c:	stur	q3, [x29, #-96]
  20:	ldur	q0, [x29, #-48]
  24:	ldur	q1, [x29, #-80]
  28:	bl	0 <__multf3>
  2c:	stur	q0, [x29, #-112]
  30:	ldur	q0, [x29, #-64]
  34:	ldur	q1, [x29, #-96]
  38:	bl	0 <__multf3>
  3c:	stur	q0, [x29, #-128]
  40:	ldur	q0, [x29, #-48]
  44:	ldur	q1, [x29, #-96]
  48:	bl	0 <__multf3>
  4c:	stur	q0, [x29, #-144]
  50:	ldur	q0, [x29, #-64]
  54:	ldur	q1, [x29, #-80]
  58:	bl	0 <__multf3>
  5c:	stur	q0, [x29, #-160]
  60:	ldur	q0, [x29, #-112]
  64:	ldur	q1, [x29, #-128]
  68:	bl	0 <__subtf3>
  6c:	stur	q0, [x29, #-192]
  70:	ldur	q0, [x29, #-144]
  74:	ldur	q1, [x29, #-160]
  78:	bl	0 <__addtf3>
  7c:	stur	q0, [x29, #-176]
  80:	ldur	q0, [x29, #-192]
  84:	str	q0, [sp, #384]
  88:	ldr	q1, [sp, #384]
  8c:	bl	0 <__unordtf2>
  90:	cbz	w0, 6d4 <__multc3+0x6d4>
  94:	b	98 <__multc3+0x98>
  98:	ldur	q0, [x29, #-176]
  9c:	str	q0, [sp, #368]
  a0:	ldr	q1, [sp, #368]
  a4:	bl	0 <__unordtf2>
  a8:	cbz	w0, 6d4 <__multc3+0x6d4>
  ac:	b	b0 <__multc3+0xb0>
  b0:	mov	w8, wzr
  b4:	stur	w8, [x29, #-196]
  b8:	ldur	q0, [x29, #-48]
  bc:	stur	q0, [x29, #-224]
  c0:	ldurb	w8, [x29, #-209]
  c4:	and	w8, w8, #0x7f
  c8:	sturb	w8, [x29, #-209]
  cc:	ldur	q0, [x29, #-224]
  d0:	adrp	x9, 0 <__multc3>
  d4:	ldr	q1, [x9]
  d8:	bl	0 <__eqtf2>
  dc:	cbz	w0, 110 <__multc3+0x110>
  e0:	b	e4 <__multc3+0xe4>
  e4:	ldur	q0, [x29, #-64]
  e8:	stur	q0, [x29, #-240]
  ec:	ldurb	w8, [x29, #-225]
  f0:	and	w8, w8, #0x7f
  f4:	sturb	w8, [x29, #-225]
  f8:	ldur	q0, [x29, #-240]
  fc:	adrp	x9, 0 <__multc3>
 100:	ldr	q1, [x9]
 104:	bl	0 <__netf2>
 108:	cbnz	w0, 280 <__multc3+0x280>
 10c:	b	110 <__multc3+0x110>
 110:	ldur	q0, [x29, #-48]
 114:	str	q0, [sp, #848]
 118:	ldrb	w8, [sp, #863]
 11c:	and	w8, w8, #0x7f
 120:	strb	w8, [sp, #863]
 124:	ldr	q1, [sp, #848]
 128:	adrp	x9, 0 <__multc3>
 12c:	ldr	q2, [x9]
 130:	str	q0, [sp, #352]
 134:	mov	v0.16b, v1.16b
 138:	mov	v1.16b, v2.16b
 13c:	str	q2, [sp, #336]
 140:	bl	0 <__eqtf2>
 144:	subs	w8, w0, #0x0
 148:	cset	w10, eq  // eq = none
 14c:	adrp	x9, 0 <__multc3>
 150:	add	x9, x9, #0x0
 154:	ldr	q0, [x9, w10, uxtw #4]
 158:	ldr	q1, [sp, #352]
 15c:	str	q1, [sp, #880]
 160:	str	q0, [sp, #864]
 164:	ldrb	w10, [sp, #895]
 168:	ldrb	w11, [sp, #879]
 16c:	bfxil	w10, w11, #0, #7
 170:	strb	w10, [sp, #879]
 174:	ldr	q0, [sp, #864]
 178:	stur	q0, [x29, #-48]
 17c:	ldur	q0, [x29, #-64]
 180:	str	q0, [sp, #896]
 184:	ldrb	w10, [sp, #911]
 188:	and	w10, w10, #0x7f
 18c:	strb	w10, [sp, #911]
 190:	ldr	q2, [sp, #896]
 194:	str	q0, [sp, #320]
 198:	mov	v0.16b, v2.16b
 19c:	ldr	q1, [sp, #336]
 1a0:	str	w8, [sp, #316]
 1a4:	str	x9, [sp, #304]
 1a8:	bl	0 <__eqtf2>
 1ac:	subs	w8, w0, #0x0
 1b0:	cset	w10, eq  // eq = none
 1b4:	ldr	x9, [sp, #304]
 1b8:	ldr	q0, [x9, w10, uxtw #4]
 1bc:	ldr	q1, [sp, #320]
 1c0:	stur	q1, [x29, #-256]
 1c4:	str	q0, [sp, #912]
 1c8:	ldurb	w10, [x29, #-241]
 1cc:	ldrb	w11, [sp, #927]
 1d0:	bfxil	w10, w11, #0, #7
 1d4:	strb	w10, [sp, #927]
 1d8:	ldr	q0, [sp, #912]
 1dc:	stur	q0, [x29, #-64]
 1e0:	ldur	q0, [x29, #-80]
 1e4:	str	q0, [sp, #288]
 1e8:	ldr	q1, [sp, #288]
 1ec:	str	w8, [sp, #284]
 1f0:	bl	0 <__unordtf2>
 1f4:	cbz	w0, 22c <__multc3+0x22c>
 1f8:	b	1fc <__multc3+0x1fc>
 1fc:	ldur	q0, [x29, #-80]
 200:	str	q0, [sp, #832]
 204:	adrp	x8, 0 <__multc3>
 208:	ldr	q0, [x8]
 20c:	str	q0, [sp, #816]
 210:	ldrb	w9, [sp, #847]
 214:	ldrb	w10, [sp, #831]
 218:	bfxil	w9, w10, #0, #7
 21c:	strb	w9, [sp, #831]
 220:	ldr	q0, [sp, #816]
 224:	stur	q0, [x29, #-80]
 228:	b	22c <__multc3+0x22c>
 22c:	ldur	q0, [x29, #-96]
 230:	str	q0, [sp, #256]
 234:	ldr	q1, [sp, #256]
 238:	bl	0 <__unordtf2>
 23c:	cbz	w0, 274 <__multc3+0x274>
 240:	b	244 <__multc3+0x244>
 244:	ldur	q0, [x29, #-96]
 248:	str	q0, [sp, #800]
 24c:	adrp	x8, 0 <__multc3>
 250:	ldr	q0, [x8]
 254:	str	q0, [sp, #784]
 258:	ldrb	w9, [sp, #815]
 25c:	ldrb	w10, [sp, #799]
 260:	bfxil	w9, w10, #0, #7
 264:	strb	w9, [sp, #799]
 268:	ldr	q0, [sp, #784]
 26c:	stur	q0, [x29, #-96]
 270:	b	274 <__multc3+0x274>
 274:	mov	w8, #0x1                   	// #1
 278:	stur	w8, [x29, #-196]
 27c:	b	280 <__multc3+0x280>
 280:	ldur	q0, [x29, #-80]
 284:	str	q0, [sp, #768]
 288:	ldrb	w8, [sp, #783]
 28c:	and	w8, w8, #0x7f
 290:	strb	w8, [sp, #783]
 294:	ldr	q0, [sp, #768]
 298:	adrp	x9, 0 <__multc3>
 29c:	ldr	q1, [x9]
 2a0:	bl	0 <__eqtf2>
 2a4:	cbz	w0, 2d8 <__multc3+0x2d8>
 2a8:	b	2ac <__multc3+0x2ac>
 2ac:	ldur	q0, [x29, #-96]
 2b0:	str	q0, [sp, #752]
 2b4:	ldrb	w8, [sp, #767]
 2b8:	and	w8, w8, #0x7f
 2bc:	strb	w8, [sp, #767]
 2c0:	ldr	q0, [sp, #752]
 2c4:	adrp	x9, 0 <__multc3>
 2c8:	ldr	q1, [x9]
 2cc:	bl	0 <__netf2>
 2d0:	cbnz	w0, 448 <__multc3+0x448>
 2d4:	b	2d8 <__multc3+0x2d8>
 2d8:	ldur	q0, [x29, #-80]
 2dc:	str	q0, [sp, #656]
 2e0:	ldrb	w8, [sp, #671]
 2e4:	and	w8, w8, #0x7f
 2e8:	strb	w8, [sp, #671]
 2ec:	ldr	q1, [sp, #656]
 2f0:	adrp	x9, 0 <__multc3>
 2f4:	ldr	q2, [x9]
 2f8:	str	q0, [sp, #240]
 2fc:	mov	v0.16b, v1.16b
 300:	mov	v1.16b, v2.16b
 304:	str	q2, [sp, #224]
 308:	bl	0 <__eqtf2>
 30c:	subs	w8, w0, #0x0
 310:	cset	w10, eq  // eq = none
 314:	adrp	x9, 0 <__multc3>
 318:	add	x9, x9, #0x0
 31c:	ldr	q0, [x9, w10, uxtw #4]
 320:	ldr	q1, [sp, #240]
 324:	str	q1, [sp, #688]
 328:	str	q0, [sp, #672]
 32c:	ldrb	w10, [sp, #703]
 330:	ldrb	w11, [sp, #687]
 334:	bfxil	w10, w11, #0, #7
 338:	strb	w10, [sp, #687]
 33c:	ldr	q0, [sp, #672]
 340:	stur	q0, [x29, #-80]
 344:	ldur	q0, [x29, #-96]
 348:	str	q0, [sp, #704]
 34c:	ldrb	w10, [sp, #719]
 350:	and	w10, w10, #0x7f
 354:	strb	w10, [sp, #719]
 358:	ldr	q2, [sp, #704]
 35c:	str	q0, [sp, #208]
 360:	mov	v0.16b, v2.16b
 364:	ldr	q1, [sp, #224]
 368:	str	w8, [sp, #204]
 36c:	str	x9, [sp, #192]
 370:	bl	0 <__eqtf2>
 374:	subs	w8, w0, #0x0
 378:	cset	w10, eq  // eq = none
 37c:	ldr	x9, [sp, #192]
 380:	ldr	q0, [x9, w10, uxtw #4]
 384:	ldr	q1, [sp, #208]
 388:	str	q1, [sp, #736]
 38c:	str	q0, [sp, #720]
 390:	ldrb	w10, [sp, #751]
 394:	ldrb	w11, [sp, #735]
 398:	bfxil	w10, w11, #0, #7
 39c:	strb	w10, [sp, #735]
 3a0:	ldr	q0, [sp, #720]
 3a4:	stur	q0, [x29, #-96]
 3a8:	ldur	q0, [x29, #-48]
 3ac:	str	q0, [sp, #176]
 3b0:	ldr	q1, [sp, #176]
 3b4:	str	w8, [sp, #172]
 3b8:	bl	0 <__unordtf2>
 3bc:	cbz	w0, 3f4 <__multc3+0x3f4>
 3c0:	b	3c4 <__multc3+0x3c4>
 3c4:	ldur	q0, [x29, #-48]
 3c8:	str	q0, [sp, #640]
 3cc:	adrp	x8, 0 <__multc3>
 3d0:	ldr	q0, [x8]
 3d4:	str	q0, [sp, #624]
 3d8:	ldrb	w9, [sp, #655]
 3dc:	ldrb	w10, [sp, #639]
 3e0:	bfxil	w9, w10, #0, #7
 3e4:	strb	w9, [sp, #639]
 3e8:	ldr	q0, [sp, #624]
 3ec:	stur	q0, [x29, #-48]
 3f0:	b	3f4 <__multc3+0x3f4>
 3f4:	ldur	q0, [x29, #-64]
 3f8:	str	q0, [sp, #144]
 3fc:	ldr	q1, [sp, #144]
 400:	bl	0 <__unordtf2>
 404:	cbz	w0, 43c <__multc3+0x43c>
 408:	b	40c <__multc3+0x40c>
 40c:	ldur	q0, [x29, #-64]
 410:	str	q0, [sp, #608]
 414:	adrp	x8, 0 <__multc3>
 418:	ldr	q0, [x8]
 41c:	str	q0, [sp, #592]
 420:	ldrb	w9, [sp, #623]
 424:	ldrb	w10, [sp, #607]
 428:	bfxil	w9, w10, #0, #7
 42c:	strb	w9, [sp, #607]
 430:	ldr	q0, [sp, #592]
 434:	stur	q0, [x29, #-64]
 438:	b	43c <__multc3+0x43c>
 43c:	mov	w8, #0x1                   	// #1
 440:	stur	w8, [x29, #-196]
 444:	b	448 <__multc3+0x448>
 448:	ldur	w8, [x29, #-196]
 44c:	cbnz	w8, 630 <__multc3+0x630>
 450:	b	454 <__multc3+0x454>
 454:	ldur	q0, [x29, #-112]
 458:	str	q0, [sp, #576]
 45c:	ldrb	w8, [sp, #591]
 460:	and	w8, w8, #0x7f
 464:	strb	w8, [sp, #591]
 468:	ldr	q0, [sp, #576]
 46c:	adrp	x9, 0 <__multc3>
 470:	ldr	q1, [x9]
 474:	bl	0 <__eqtf2>
 478:	cbz	w0, 504 <__multc3+0x504>
 47c:	b	480 <__multc3+0x480>
 480:	ldur	q0, [x29, #-128]
 484:	str	q0, [sp, #560]
 488:	ldrb	w8, [sp, #575]
 48c:	and	w8, w8, #0x7f
 490:	strb	w8, [sp, #575]
 494:	ldr	q0, [sp, #560]
 498:	adrp	x9, 0 <__multc3>
 49c:	ldr	q1, [x9]
 4a0:	bl	0 <__eqtf2>
 4a4:	cbz	w0, 504 <__multc3+0x504>
 4a8:	b	4ac <__multc3+0x4ac>
 4ac:	ldur	q0, [x29, #-144]
 4b0:	str	q0, [sp, #544]
 4b4:	ldrb	w8, [sp, #559]
 4b8:	and	w8, w8, #0x7f
 4bc:	strb	w8, [sp, #559]
 4c0:	ldr	q0, [sp, #544]
 4c4:	adrp	x9, 0 <__multc3>
 4c8:	ldr	q1, [x9]
 4cc:	bl	0 <__eqtf2>
 4d0:	cbz	w0, 504 <__multc3+0x504>
 4d4:	b	4d8 <__multc3+0x4d8>
 4d8:	ldur	q0, [x29, #-160]
 4dc:	str	q0, [sp, #528]
 4e0:	ldrb	w8, [sp, #543]
 4e4:	and	w8, w8, #0x7f
 4e8:	strb	w8, [sp, #543]
 4ec:	ldr	q0, [sp, #528]
 4f0:	adrp	x9, 0 <__multc3>
 4f4:	ldr	q1, [x9]
 4f8:	bl	0 <__netf2>
 4fc:	cbnz	w0, 630 <__multc3+0x630>
 500:	b	504 <__multc3+0x504>
 504:	ldur	q0, [x29, #-48]
 508:	str	q0, [sp, #128]
 50c:	ldr	q1, [sp, #128]
 510:	bl	0 <__unordtf2>
 514:	cbz	w0, 54c <__multc3+0x54c>
 518:	b	51c <__multc3+0x51c>
 51c:	ldur	q0, [x29, #-48]
 520:	str	q0, [sp, #512]
 524:	adrp	x8, 0 <__multc3>
 528:	ldr	q0, [x8]
 52c:	str	q0, [sp, #496]
 530:	ldrb	w9, [sp, #527]
 534:	ldrb	w10, [sp, #511]
 538:	bfxil	w9, w10, #0, #7
 53c:	strb	w9, [sp, #511]
 540:	ldr	q0, [sp, #496]
 544:	stur	q0, [x29, #-48]
 548:	b	54c <__multc3+0x54c>
 54c:	ldur	q0, [x29, #-64]
 550:	str	q0, [sp, #112]
 554:	ldr	q1, [sp, #112]
 558:	bl	0 <__unordtf2>
 55c:	cbz	w0, 594 <__multc3+0x594>
 560:	b	564 <__multc3+0x564>
 564:	ldur	q0, [x29, #-64]
 568:	str	q0, [sp, #480]
 56c:	adrp	x8, 0 <__multc3>
 570:	ldr	q0, [x8]
 574:	str	q0, [sp, #464]
 578:	ldrb	w9, [sp, #495]
 57c:	ldrb	w10, [sp, #479]
 580:	bfxil	w9, w10, #0, #7
 584:	strb	w9, [sp, #479]
 588:	ldr	q0, [sp, #464]
 58c:	stur	q0, [x29, #-64]
 590:	b	594 <__multc3+0x594>
 594:	ldur	q0, [x29, #-80]
 598:	str	q0, [sp, #96]
 59c:	ldr	q1, [sp, #96]
 5a0:	bl	0 <__unordtf2>
 5a4:	cbz	w0, 5dc <__multc3+0x5dc>
 5a8:	b	5ac <__multc3+0x5ac>
 5ac:	ldur	q0, [x29, #-80]
 5b0:	str	q0, [sp, #448]
 5b4:	adrp	x8, 0 <__multc3>
 5b8:	ldr	q0, [x8]
 5bc:	str	q0, [sp, #432]
 5c0:	ldrb	w9, [sp, #463]
 5c4:	ldrb	w10, [sp, #447]
 5c8:	bfxil	w9, w10, #0, #7
 5cc:	strb	w9, [sp, #447]
 5d0:	ldr	q0, [sp, #432]
 5d4:	stur	q0, [x29, #-80]
 5d8:	b	5dc <__multc3+0x5dc>
 5dc:	ldur	q0, [x29, #-96]
 5e0:	str	q0, [sp, #80]
 5e4:	ldr	q1, [sp, #80]
 5e8:	bl	0 <__unordtf2>
 5ec:	cbz	w0, 624 <__multc3+0x624>
 5f0:	b	5f4 <__multc3+0x5f4>
 5f4:	ldur	q0, [x29, #-96]
 5f8:	str	q0, [sp, #416]
 5fc:	adrp	x8, 0 <__multc3>
 600:	ldr	q0, [x8]
 604:	str	q0, [sp, #400]
 608:	ldrb	w9, [sp, #431]
 60c:	ldrb	w10, [sp, #415]
 610:	bfxil	w9, w10, #0, #7
 614:	strb	w9, [sp, #415]
 618:	ldr	q0, [sp, #400]
 61c:	stur	q0, [x29, #-96]
 620:	b	624 <__multc3+0x624>
 624:	mov	w8, #0x1                   	// #1
 628:	stur	w8, [x29, #-196]
 62c:	b	630 <__multc3+0x630>
 630:	ldur	w8, [x29, #-196]
 634:	cbz	w8, 6d0 <__multc3+0x6d0>
 638:	b	63c <__multc3+0x63c>
 63c:	ldur	q0, [x29, #-48]
 640:	ldur	q1, [x29, #-80]
 644:	bl	0 <__multf3>
 648:	ldur	q1, [x29, #-64]
 64c:	ldur	q2, [x29, #-96]
 650:	str	q0, [sp, #64]
 654:	mov	v0.16b, v1.16b
 658:	mov	v1.16b, v2.16b
 65c:	bl	0 <__multf3>
 660:	ldr	q1, [sp, #64]
 664:	str	q0, [sp, #48]
 668:	mov	v0.16b, v1.16b
 66c:	ldr	q1, [sp, #48]
 670:	bl	0 <__subtf3>
 674:	adrp	x8, 0 <__multc3>
 678:	ldr	q1, [x8]
 67c:	str	q1, [sp, #32]
 680:	bl	0 <__multf3>
 684:	stur	q0, [x29, #-192]
 688:	ldur	q0, [x29, #-48]
 68c:	ldur	q1, [x29, #-96]
 690:	bl	0 <__multf3>
 694:	ldur	q1, [x29, #-64]
 698:	ldur	q2, [x29, #-80]
 69c:	str	q0, [sp, #16]
 6a0:	mov	v0.16b, v1.16b
 6a4:	mov	v1.16b, v2.16b
 6a8:	bl	0 <__multf3>
 6ac:	ldr	q1, [sp, #16]
 6b0:	str	q0, [sp]
 6b4:	mov	v0.16b, v1.16b
 6b8:	ldr	q1, [sp]
 6bc:	bl	0 <__addtf3>
 6c0:	ldr	q1, [sp, #32]
 6c4:	bl	0 <__multf3>
 6c8:	stur	q0, [x29, #-176]
 6cc:	b	6d0 <__multc3+0x6d0>
 6d0:	b	6d4 <__multc3+0x6d4>
 6d4:	ldur	q0, [x29, #-192]
 6d8:	ldur	q1, [x29, #-176]
 6dc:	stur	q0, [x29, #-32]
 6e0:	stur	q1, [x29, #-16]
 6e4:	ldur	q0, [x29, #-32]
 6e8:	ldur	q1, [x29, #-16]
 6ec:	add	sp, sp, #0x4a0
 6f0:	ldr	x28, [sp, #16]
 6f4:	ldp	x29, x30, [sp], #32
 6f8:	ret

trunctfdf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__trunctfdf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	q0, [sp]
  10:	ldr	q0, [sp]
  14:	bl	24 <__truncXfYf2__>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__truncXfYf2__>:
  24:	sub	sp, sp, #0x1d0
  28:	stp	x29, x30, [sp, #432]
  2c:	str	x28, [sp, #448]
  30:	add	x29, sp, #0x1b0
  34:	sub	x8, x29, #0x10
  38:	str	q0, [x8]
  3c:	mov	w9, #0x80                  	// #128
  40:	stur	w9, [x29, #-20]
  44:	mov	w9, #0xf                   	// #15
  48:	stur	w9, [x29, #-24]
  4c:	mov	w9, #0x7fff                	// #32767
  50:	stur	w9, [x29, #-28]
  54:	mov	w9, #0x3fff                	// #16383
  58:	stur	w9, [x29, #-32]
  5c:	mov	x10, #0x1000000000000       	// #281474976710656
  60:	stur	x10, [x29, #-40]
  64:	mov	x10, xzr
  68:	stur	x10, [x29, #-48]
  6c:	mov	x11, #0xffffffffffff        	// #281474976710655
  70:	stur	x11, [x29, #-56]
  74:	mov	x11, #0xffffffffffffffff    	// #-1
  78:	stur	x11, [x29, #-64]
  7c:	mov	x12, #0x7fff000000000000    	// #9223090561878065152
  80:	stur	x12, [x29, #-72]
  84:	stur	x10, [x29, #-80]
  88:	mov	x12, #0x8000000000000000    	// #-9223372036854775808
  8c:	stur	x12, [x29, #-88]
  90:	stur	x10, [x29, #-96]
  94:	mov	x12, #0x7fffffffffffffff    	// #9223372036854775807
  98:	stur	x12, [x29, #-104]
  9c:	stur	x11, [x29, #-112]
  a0:	stur	x10, [x29, #-120]
  a4:	mov	x12, #0xfffffffffffffff     	// #1152921504606846975
  a8:	stur	x12, [x29, #-128]
  ac:	stur	x10, [x29, #-136]
  b0:	mov	x12, #0x800000000000000     	// #576460752303423488
  b4:	stur	x12, [x29, #-144]
  b8:	mov	x12, #0x800000000000        	// #140737488355328
  bc:	stur	x12, [x29, #-152]
  c0:	stur	x10, [x29, #-160]
  c4:	mov	x12, #0x7fffffffffff        	// #140737488355327
  c8:	stur	x12, [x29, #-168]
  cc:	stur	x11, [x29, #-176]
  d0:	mov	w9, #0x40                  	// #64
  d4:	stur	w9, [x29, #-180]
  d8:	mov	w9, #0xb                   	// #11
  dc:	stur	w9, [x29, #-184]
  e0:	mov	w9, #0x7ff                 	// #2047
  e4:	stur	w9, [x29, #-188]
  e8:	mov	w9, #0x3ff                 	// #1023
  ec:	stur	w9, [x29, #-192]
  f0:	mov	w9, #0x3c01                	// #15361
  f4:	stur	w9, [x29, #-196]
  f8:	mov	w9, #0x43ff                	// #17407
  fc:	stur	w9, [x29, #-200]
 100:	mov	x11, #0x3c01000000000000    	// #4323737117252386816
 104:	str	x11, [sp, #216]
 108:	str	x10, [sp, #208]
 10c:	mov	x11, #0x43ff000000000000    	// #4899634919602388992
 110:	str	x11, [sp, #200]
 114:	str	x10, [sp, #192]
 118:	mov	x11, #0x8000000000000       	// #2251799813685248
 11c:	str	x11, [sp, #184]
 120:	mov	x11, #0x7ffffffffffff       	// #2251799813685247
 124:	str	x11, [sp, #176]
 128:	ldr	q0, [x8]
 12c:	str	x10, [sp]
 130:	bl	46c <srcToRep>
 134:	str	x1, [sp, #168]
 138:	str	x0, [sp, #160]
 13c:	ldr	x8, [sp, #160]
 140:	ldr	x10, [sp, #168]
 144:	and	x10, x10, #0x7fffffffffffffff
 148:	str	x8, [sp, #144]
 14c:	str	x10, [sp, #152]
 150:	ldr	x8, [sp, #168]
 154:	and	x8, x8, #0x8000000000000000
 158:	ldr	x10, [sp]
 15c:	str	x10, [sp, #128]
 160:	str	x8, [sp, #136]
 164:	ldr	x8, [sp, #152]
 168:	mov	x11, #0xc3ff000000000000    	// #-4323737117252386816
 16c:	add	x11, x8, x11
 170:	mov	x12, #0xbc01000000000000    	// #-4899634919602388992
 174:	add	x8, x8, x12
 178:	subs	x8, x11, x8
 17c:	b.cs	228 <__truncXfYf2__+0x204>  // b.hs, b.nlast
 180:	b	184 <__truncXfYf2__+0x160>
 184:	ldr	x8, [sp, #144]
 188:	ldr	x9, [sp, #152]
 18c:	extr	x8, x9, x8, #60
 190:	str	x8, [sp, #120]
 194:	ldr	x8, [sp, #120]
 198:	mov	x9, #0x4000000000000000    	// #4611686018427387904
 19c:	add	x8, x8, x9
 1a0:	str	x8, [sp, #120]
 1a4:	ldr	x8, [sp, #144]
 1a8:	and	x8, x8, #0xfffffffffffffff
 1ac:	mov	x9, xzr
 1b0:	str	x9, [sp, #104]
 1b4:	str	x8, [sp, #96]
 1b8:	ldr	x8, [sp, #104]
 1bc:	ldr	x9, [sp, #96]
 1c0:	mov	x10, #0x1                   	// #1
 1c4:	movk	x10, #0x800, lsl #48
 1c8:	subs	x9, x9, x10
 1cc:	cset	w11, cc  // cc = lo, ul, last
 1d0:	subs	x8, x8, #0x0
 1d4:	mov	w12, wzr
 1d8:	csel	w11, w11, w12, eq  // eq = none
 1dc:	tbnz	w11, #0, 1f4 <__truncXfYf2__+0x1d0>
 1e0:	b	1e4 <__truncXfYf2__+0x1c0>
 1e4:	ldr	x8, [sp, #120]
 1e8:	add	x8, x8, #0x1
 1ec:	str	x8, [sp, #120]
 1f0:	b	224 <__truncXfYf2__+0x200>
 1f4:	ldr	x8, [sp, #104]
 1f8:	ldr	x9, [sp, #96]
 1fc:	eor	x9, x9, #0x800000000000000
 200:	orr	x8, x9, x8
 204:	cbnz	x8, 220 <__truncXfYf2__+0x1fc>
 208:	b	20c <__truncXfYf2__+0x1e8>
 20c:	ldr	x8, [sp, #120]
 210:	and	x9, x8, #0x1
 214:	add	x8, x8, x9
 218:	str	x8, [sp, #120]
 21c:	b	220 <__truncXfYf2__+0x1fc>
 220:	b	224 <__truncXfYf2__+0x200>
 224:	b	444 <__truncXfYf2__+0x420>
 228:	ldr	x8, [sp, #152]
 22c:	ldr	x9, [sp, #144]
 230:	subs	x9, x9, #0x0
 234:	cset	w10, eq  // eq = none
 238:	mov	x11, #0x7fff000000000000    	// #9223090561878065152
 23c:	subs	x8, x8, x11
 240:	cset	w12, cc  // cc = lo, ul, last
 244:	csel	w10, w10, w12, eq  // eq = none
 248:	tbnz	w10, #0, 284 <__truncXfYf2__+0x260>
 24c:	b	250 <__truncXfYf2__+0x22c>
 250:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 254:	str	x8, [sp, #120]
 258:	ldr	x8, [sp, #120]
 25c:	orr	x8, x8, #0x8000000000000
 260:	str	x8, [sp, #120]
 264:	ldr	x8, [sp, #144]
 268:	ldr	x9, [sp, #152]
 26c:	and	x9, x9, #0x7fffffffffff
 270:	extr	x8, x9, x8, #60
 274:	ldr	x9, [sp, #120]
 278:	orr	x8, x9, x8
 27c:	str	x8, [sp, #120]
 280:	b	440 <__truncXfYf2__+0x41c>
 284:	ldr	x8, [sp, #152]
 288:	mov	x9, #0x43ff000000000000    	// #4899634919602388992
 28c:	subs	x8, x8, x9
 290:	b.cc	2a4 <__truncXfYf2__+0x280>  // b.lo, b.ul, b.last
 294:	b	298 <__truncXfYf2__+0x274>
 298:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 29c:	str	x8, [sp, #120]
 2a0:	b	43c <__truncXfYf2__+0x418>
 2a4:	ldrh	w8, [sp, #158]
 2a8:	str	w8, [sp, #92]
 2ac:	ldr	w8, [sp, #92]
 2b0:	mov	w9, #0x3c01                	// #15361
 2b4:	subs	w8, w9, w8
 2b8:	str	w8, [sp, #88]
 2bc:	ldr	x10, [sp, #160]
 2c0:	ldr	x11, [sp, #168]
 2c4:	mov	x12, #0x1000000000000       	// #281474976710656
 2c8:	bfxil	x12, x11, #0, #48
 2cc:	str	x10, [sp, #64]
 2d0:	str	x12, [sp, #72]
 2d4:	ldr	w8, [sp, #88]
 2d8:	subs	w8, w8, #0x71
 2dc:	b.lt	2f0 <__truncXfYf2__+0x2cc>  // b.tstop
 2e0:	b	2e4 <__truncXfYf2__+0x2c0>
 2e4:	mov	x8, xzr
 2e8:	str	x8, [sp, #120]
 2ec:	b	438 <__truncXfYf2__+0x414>
 2f0:	ldr	x8, [sp, #72]
 2f4:	ldr	x9, [sp, #64]
 2f8:	ldr	w10, [sp, #88]
 2fc:	mov	w11, #0x80                  	// #128
 300:	subs	w11, w11, w10
 304:	mov	w12, w11
 308:	mov	x13, xzr
 30c:	sub	x14, x13, x12
 310:	lsr	x14, x9, x14
 314:	subs	x15, x12, #0x0
 318:	csel	x14, x13, x14, eq  // eq = none
 31c:	mov	w11, wzr
 320:	sub	w10, w11, w10
 324:	mov	w16, w10
 328:	lsl	x17, x9, x16
 32c:	subs	x18, x12, #0x40
 330:	subs	x18, x18, #0x0
 334:	csel	x17, x13, x17, ge  // ge = tcont
 338:	lsl	x8, x8, x16
 33c:	orr	x8, x14, x8
 340:	lsl	x9, x9, x12
 344:	csel	x8, x9, x8, ge  // ge = tcont
 348:	orr	x8, x17, x8
 34c:	subs	x8, x8, #0x0
 350:	cset	w10, ne  // ne = any
 354:	strb	w10, [sp, #60]
 358:	ldr	x9, [sp, #64]
 35c:	ldr	x12, [sp, #72]
 360:	ldr	w10, [sp, #88]
 364:	mov	w14, w10
 368:	sub	x16, x13, x14
 36c:	lsl	x16, x12, x16
 370:	subs	x17, x14, #0x0
 374:	csel	x16, x13, x16, eq  // eq = none
 378:	lsr	x9, x9, x14
 37c:	orr	x9, x9, x16
 380:	lsr	x12, x12, x14
 384:	subs	x14, x14, #0x40
 388:	subs	x14, x14, #0x0
 38c:	csel	x9, x12, x9, ge  // ge = tcont
 390:	csel	x12, x13, x12, ge  // ge = tcont
 394:	ldrb	w10, [sp, #60]
 398:	mov	w16, w10
 39c:	and	x16, x16, #0x1
 3a0:	orr	x9, x9, x16
 3a4:	str	x12, [sp, #40]
 3a8:	str	x9, [sp, #32]
 3ac:	ldr	x9, [sp, #32]
 3b0:	ldr	x12, [sp, #40]
 3b4:	extr	x9, x12, x9, #60
 3b8:	str	x9, [sp, #120]
 3bc:	ldr	x9, [sp, #32]
 3c0:	and	x9, x9, #0xfffffffffffffff
 3c4:	str	x13, [sp, #24]
 3c8:	str	x9, [sp, #16]
 3cc:	ldr	x9, [sp, #24]
 3d0:	ldr	x12, [sp, #16]
 3d4:	mov	x13, #0x1                   	// #1
 3d8:	movk	x13, #0x800, lsl #48
 3dc:	subs	x12, x12, x13
 3e0:	cset	w10, cc  // cc = lo, ul, last
 3e4:	subs	x9, x9, #0x0
 3e8:	csel	w10, w10, w11, eq  // eq = none
 3ec:	tbnz	w10, #0, 404 <__truncXfYf2__+0x3e0>
 3f0:	b	3f4 <__truncXfYf2__+0x3d0>
 3f4:	ldr	x8, [sp, #120]
 3f8:	add	x8, x8, #0x1
 3fc:	str	x8, [sp, #120]
 400:	b	434 <__truncXfYf2__+0x410>
 404:	ldr	x8, [sp, #24]
 408:	ldr	x9, [sp, #16]
 40c:	eor	x9, x9, #0x800000000000000
 410:	orr	x8, x9, x8
 414:	cbnz	x8, 430 <__truncXfYf2__+0x40c>
 418:	b	41c <__truncXfYf2__+0x3f8>
 41c:	ldr	x8, [sp, #120]
 420:	and	x9, x8, #0x1
 424:	add	x8, x8, x9
 428:	str	x8, [sp, #120]
 42c:	b	430 <__truncXfYf2__+0x40c>
 430:	b	434 <__truncXfYf2__+0x410>
 434:	b	438 <__truncXfYf2__+0x414>
 438:	b	43c <__truncXfYf2__+0x418>
 43c:	b	440 <__truncXfYf2__+0x41c>
 440:	b	444 <__truncXfYf2__+0x420>
 444:	ldr	x8, [sp, #120]
 448:	ldr	x9, [sp, #136]
 44c:	orr	x8, x8, x9
 450:	str	x8, [sp, #8]
 454:	ldr	x0, [sp, #8]
 458:	bl	48c <dstFromRep>
 45c:	ldr	x28, [sp, #448]
 460:	ldp	x29, x30, [sp, #432]
 464:	add	sp, sp, #0x1d0
 468:	ret

000000000000046c <srcToRep>:
 46c:	sub	sp, sp, #0x20
 470:	str	q0, [sp, #16]
 474:	ldr	q0, [sp, #16]
 478:	str	q0, [sp]
 47c:	ldr	x0, [sp]
 480:	ldr	x1, [sp, #8]
 484:	add	sp, sp, #0x20
 488:	ret

000000000000048c <dstFromRep>:
 48c:	sub	sp, sp, #0x10
 490:	str	x0, [sp, #8]
 494:	ldr	x8, [sp, #8]
 498:	str	x8, [sp]
 49c:	ldr	d0, [sp]
 4a0:	add	sp, sp, #0x10
 4a4:	ret

trunctfsf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__trunctfsf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	q0, [sp]
  10:	ldr	q0, [sp]
  14:	bl	24 <__truncXfYf2__>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__truncXfYf2__>:
  24:	sub	sp, sp, #0x1e0
  28:	stp	x29, x30, [sp, #448]
  2c:	str	x28, [sp, #464]
  30:	add	x29, sp, #0x1c0
  34:	add	x8, sp, #0xa0
  38:	str	q0, [x8, #272]
  3c:	mov	w9, #0x80                  	// #128
  40:	stur	w9, [x29, #-20]
  44:	mov	w9, #0xf                   	// #15
  48:	stur	w9, [x29, #-24]
  4c:	mov	w9, #0x7fff                	// #32767
  50:	stur	w9, [x29, #-28]
  54:	mov	w9, #0x3fff                	// #16383
  58:	stur	w9, [x29, #-32]
  5c:	mov	x10, #0x1000000000000       	// #281474976710656
  60:	str	x10, [x8, #248]
  64:	mov	x10, xzr
  68:	str	x10, [x8, #240]
  6c:	mov	x11, #0xffffffffffff        	// #281474976710655
  70:	str	x11, [x8, #232]
  74:	mov	x11, #0xffffffffffffffff    	// #-1
  78:	str	x11, [x8, #224]
  7c:	mov	x12, #0x7fff000000000000    	// #9223090561878065152
  80:	str	x12, [x8, #216]
  84:	str	x10, [x8, #208]
  88:	mov	x12, #0x8000000000000000    	// #-9223372036854775808
  8c:	str	x12, [x8, #200]
  90:	str	x10, [x8, #192]
  94:	mov	x12, #0x7fffffffffffffff    	// #9223372036854775807
  98:	str	x12, [x8, #184]
  9c:	str	x11, [x8, #176]
  a0:	mov	w9, #0x1ffffff             	// #33554431
  a4:	mov	w12, w9
  a8:	str	x12, [x8, #168]
  ac:	str	x11, [x8, #160]
  b0:	mov	w9, #0x1000000             	// #16777216
  b4:	mov	w12, w9
  b8:	str	x12, [x8, #152]
  bc:	str	x10, [x8, #144]
  c0:	mov	x12, #0x800000000000        	// #140737488355328
  c4:	str	x12, [x8, #136]
  c8:	str	x10, [x8, #128]
  cc:	mov	x12, #0x7fffffffffff        	// #140737488355327
  d0:	str	x12, [x8, #120]
  d4:	str	x11, [x8, #112]
  d8:	mov	w9, #0x20                  	// #32
  dc:	stur	w9, [x29, #-180]
  e0:	mov	w9, #0x8                   	// #8
  e4:	stur	w9, [x29, #-184]
  e8:	mov	w9, #0xff                  	// #255
  ec:	stur	w9, [x29, #-188]
  f0:	mov	w9, #0x7f                  	// #127
  f4:	stur	w9, [x29, #-192]
  f8:	mov	w9, #0x3f81                	// #16257
  fc:	stur	w9, [x29, #-196]
 100:	mov	w9, #0x407f                	// #16511
 104:	stur	w9, [x29, #-200]
 108:	mov	x11, #0x3f81000000000000    	// #4575938696385134592
 10c:	str	x11, [x8, #72]
 110:	str	x10, [x8, #64]
 114:	mov	x11, #0x407f000000000000    	// #4647433340469641216
 118:	str	x11, [x8, #56]
 11c:	str	x10, [x8, #48]
 120:	mov	w9, #0x400000              	// #4194304
 124:	str	w9, [sp, #204]
 128:	mov	w9, #0x3fffff              	// #4194303
 12c:	str	w9, [sp, #200]
 130:	ldr	q0, [x8, #272]
 134:	str	x8, [sp, #16]
 138:	str	x10, [sp, #8]
 13c:	bl	498 <srcToRep>
 140:	ldr	x8, [sp, #16]
 144:	str	x1, [x8, #24]
 148:	str	x0, [x8, #16]
 14c:	ldr	x10, [x8, #16]
 150:	ldr	x11, [x8, #24]
 154:	and	x11, x11, #0x7fffffffffffffff
 158:	str	x10, [x8]
 15c:	str	x11, [x8, #8]
 160:	ldr	x10, [x8, #24]
 164:	and	x10, x10, #0x8000000000000000
 168:	ldr	x11, [sp, #8]
 16c:	str	x11, [sp, #144]
 170:	str	x10, [sp, #152]
 174:	ldr	x10, [x8, #8]
 178:	mov	x12, #0xc07f000000000000    	// #-4575938696385134592
 17c:	add	x12, x10, x12
 180:	mov	x13, #0xbf81000000000000    	// #-4647433340469641216
 184:	add	x10, x10, x13
 188:	subs	x10, x12, x10
 18c:	b.cs	240 <__truncXfYf2__+0x21c>  // b.hs, b.nlast
 190:	b	194 <__truncXfYf2__+0x170>
 194:	ldr	x8, [sp, #16]
 198:	ldr	x9, [x8, #8]
 19c:	lsr	x9, x9, #25
 1a0:	str	w9, [sp, #140]
 1a4:	ldr	w9, [sp, #140]
 1a8:	mov	w10, #0x40000000            	// #1073741824
 1ac:	add	w9, w9, w10
 1b0:	str	w9, [sp, #140]
 1b4:	ldr	x11, [x8]
 1b8:	ldr	x12, [x8, #8]
 1bc:	and	x12, x12, #0x1ffffff
 1c0:	str	x11, [sp, #112]
 1c4:	str	x12, [sp, #120]
 1c8:	ldr	x11, [sp, #120]
 1cc:	ldr	x12, [sp, #112]
 1d0:	subs	x12, x12, #0x0
 1d4:	cset	w9, eq  // eq = none
 1d8:	lsr	x13, x11, #24
 1dc:	subs	x13, x13, #0x0
 1e0:	cset	w10, eq  // eq = none
 1e4:	mov	w14, #0x1000000             	// #16777216
 1e8:	mov	w15, w14
 1ec:	subs	x11, x11, x15
 1f0:	csel	w9, w9, w10, eq  // eq = none
 1f4:	tbnz	w9, #0, 20c <__truncXfYf2__+0x1e8>
 1f8:	b	1fc <__truncXfYf2__+0x1d8>
 1fc:	ldr	w8, [sp, #140]
 200:	add	w8, w8, #0x1
 204:	str	w8, [sp, #140]
 208:	b	23c <__truncXfYf2__+0x218>
 20c:	ldr	x8, [sp, #112]
 210:	ldr	x9, [sp, #120]
 214:	eor	x9, x9, #0x1000000
 218:	orr	x8, x8, x9
 21c:	cbnz	x8, 238 <__truncXfYf2__+0x214>
 220:	b	224 <__truncXfYf2__+0x200>
 224:	ldr	w8, [sp, #140]
 228:	and	w9, w8, #0x1
 22c:	add	w8, w8, w9
 230:	str	w8, [sp, #140]
 234:	b	238 <__truncXfYf2__+0x214>
 238:	b	23c <__truncXfYf2__+0x218>
 23c:	b	470 <__truncXfYf2__+0x44c>
 240:	ldr	x8, [sp, #16]
 244:	ldr	x9, [x8, #8]
 248:	ldr	x10, [x8]
 24c:	subs	x10, x10, #0x0
 250:	cset	w11, eq  // eq = none
 254:	mov	x12, #0x7fff000000000000    	// #9223090561878065152
 258:	subs	x9, x9, x12
 25c:	cset	w13, cc  // cc = lo, ul, last
 260:	csel	w11, w11, w13, eq  // eq = none
 264:	tbnz	w11, #0, 29c <__truncXfYf2__+0x278>
 268:	b	26c <__truncXfYf2__+0x248>
 26c:	mov	w8, #0x7f800000            	// #2139095040
 270:	str	w8, [sp, #140]
 274:	ldr	w8, [sp, #140]
 278:	orr	w8, w8, #0x400000
 27c:	str	w8, [sp, #140]
 280:	ldr	x9, [sp, #16]
 284:	ldr	x10, [x9, #8]
 288:	ubfx	x10, x10, #25, #22
 28c:	ldr	w8, [sp, #140]
 290:	orr	w8, w8, w10
 294:	str	w8, [sp, #140]
 298:	b	46c <__truncXfYf2__+0x448>
 29c:	ldr	x8, [sp, #16]
 2a0:	ldr	x9, [x8, #8]
 2a4:	mov	x10, #0x407f000000000000    	// #4647433340469641216
 2a8:	subs	x9, x9, x10
 2ac:	b.cc	2c0 <__truncXfYf2__+0x29c>  // b.lo, b.ul, b.last
 2b0:	b	2b4 <__truncXfYf2__+0x290>
 2b4:	mov	w8, #0x7f800000            	// #2139095040
 2b8:	str	w8, [sp, #140]
 2bc:	b	468 <__truncXfYf2__+0x444>
 2c0:	ldrh	w8, [sp, #174]
 2c4:	str	w8, [sp, #108]
 2c8:	ldr	w8, [sp, #108]
 2cc:	mov	w9, #0x3f81                	// #16257
 2d0:	subs	w8, w9, w8
 2d4:	str	w8, [sp, #104]
 2d8:	ldr	x10, [sp, #16]
 2dc:	ldr	x11, [x10, #16]
 2e0:	ldr	x12, [x10, #24]
 2e4:	mov	x13, #0x1000000000000       	// #281474976710656
 2e8:	bfxil	x13, x12, #0, #48
 2ec:	str	x11, [sp, #80]
 2f0:	str	x13, [sp, #88]
 2f4:	ldr	w8, [sp, #104]
 2f8:	subs	w8, w8, #0x71
 2fc:	b.lt	310 <__truncXfYf2__+0x2ec>  // b.tstop
 300:	b	304 <__truncXfYf2__+0x2e0>
 304:	mov	w8, wzr
 308:	str	w8, [sp, #140]
 30c:	b	464 <__truncXfYf2__+0x440>
 310:	ldr	x8, [sp, #88]
 314:	ldr	x9, [sp, #80]
 318:	ldr	w10, [sp, #104]
 31c:	mov	w11, #0x80                  	// #128
 320:	subs	w11, w11, w10
 324:	mov	w12, w11
 328:	mov	x13, xzr
 32c:	sub	x14, x13, x12
 330:	lsr	x14, x9, x14
 334:	subs	x15, x12, #0x0
 338:	csel	x14, x13, x14, eq  // eq = none
 33c:	mov	w11, wzr
 340:	sub	w10, w11, w10
 344:	mov	w16, w10
 348:	lsl	x17, x9, x16
 34c:	subs	x18, x12, #0x40
 350:	subs	x18, x18, #0x0
 354:	csel	x17, x13, x17, ge  // ge = tcont
 358:	lsl	x8, x8, x16
 35c:	orr	x8, x14, x8
 360:	lsl	x9, x9, x12
 364:	csel	x8, x9, x8, ge  // ge = tcont
 368:	orr	x8, x17, x8
 36c:	subs	x8, x8, #0x0
 370:	cset	w10, ne  // ne = any
 374:	strb	w10, [sp, #76]
 378:	ldr	x9, [sp, #80]
 37c:	ldr	x12, [sp, #88]
 380:	ldr	w10, [sp, #104]
 384:	mov	w14, w10
 388:	sub	x16, x13, x14
 38c:	lsl	x16, x12, x16
 390:	subs	x17, x14, #0x0
 394:	csel	x16, x13, x16, eq  // eq = none
 398:	lsr	x9, x9, x14
 39c:	orr	x9, x9, x16
 3a0:	lsr	x12, x12, x14
 3a4:	subs	x14, x14, #0x40
 3a8:	subs	x14, x14, #0x0
 3ac:	csel	x9, x12, x9, ge  // ge = tcont
 3b0:	csel	x12, x13, x12, ge  // ge = tcont
 3b4:	ldrb	w10, [sp, #76]
 3b8:	mov	w13, w10
 3bc:	and	x13, x13, #0x1
 3c0:	orr	x9, x9, x13
 3c4:	str	x12, [sp, #56]
 3c8:	str	x9, [sp, #48]
 3cc:	ldr	x9, [sp, #56]
 3d0:	lsr	x9, x9, #25
 3d4:	str	w9, [sp, #140]
 3d8:	ldr	x12, [sp, #48]
 3dc:	ldr	x13, [sp, #56]
 3e0:	and	x13, x13, #0x1ffffff
 3e4:	str	x12, [sp, #32]
 3e8:	str	x13, [sp, #40]
 3ec:	ldr	x12, [sp, #40]
 3f0:	ldr	x13, [sp, #32]
 3f4:	subs	x13, x13, #0x0
 3f8:	cset	w9, eq  // eq = none
 3fc:	lsr	x16, x12, #24
 400:	subs	x16, x16, #0x0
 404:	cset	w10, eq  // eq = none
 408:	mov	w11, #0x1000000             	// #16777216
 40c:	mov	w0, w11
 410:	subs	x12, x12, x0
 414:	csel	w9, w9, w10, eq  // eq = none
 418:	tbnz	w9, #0, 430 <__truncXfYf2__+0x40c>
 41c:	b	420 <__truncXfYf2__+0x3fc>
 420:	ldr	w8, [sp, #140]
 424:	add	w8, w8, #0x1
 428:	str	w8, [sp, #140]
 42c:	b	460 <__truncXfYf2__+0x43c>
 430:	ldr	x8, [sp, #32]
 434:	ldr	x9, [sp, #40]
 438:	eor	x9, x9, #0x1000000
 43c:	orr	x8, x8, x9
 440:	cbnz	x8, 45c <__truncXfYf2__+0x438>
 444:	b	448 <__truncXfYf2__+0x424>
 448:	ldr	w8, [sp, #140]
 44c:	and	w9, w8, #0x1
 450:	add	w8, w8, w9
 454:	str	w8, [sp, #140]
 458:	b	45c <__truncXfYf2__+0x438>
 45c:	b	460 <__truncXfYf2__+0x43c>
 460:	b	464 <__truncXfYf2__+0x440>
 464:	b	468 <__truncXfYf2__+0x444>
 468:	b	46c <__truncXfYf2__+0x448>
 46c:	b	470 <__truncXfYf2__+0x44c>
 470:	ldr	w8, [sp, #140]
 474:	ldr	w9, [sp, #156]
 478:	orr	w8, w8, w9
 47c:	str	w8, [sp, #28]
 480:	ldr	w0, [sp, #28]
 484:	bl	4b8 <dstFromRep>
 488:	ldr	x28, [sp, #464]
 48c:	ldp	x29, x30, [sp, #448]
 490:	add	sp, sp, #0x1e0
 494:	ret

0000000000000498 <srcToRep>:
 498:	sub	sp, sp, #0x20
 49c:	str	q0, [sp, #16]
 4a0:	ldr	q0, [sp, #16]
 4a4:	str	q0, [sp]
 4a8:	ldr	x0, [sp]
 4ac:	ldr	x1, [sp, #8]
 4b0:	add	sp, sp, #0x20
 4b4:	ret

00000000000004b8 <dstFromRep>:
 4b8:	sub	sp, sp, #0x10
 4bc:	str	w0, [sp, #12]
 4c0:	ldr	w8, [sp, #12]
 4c4:	str	w8, [sp, #8]
 4c8:	ldr	s0, [sp, #8]
 4cc:	add	sp, sp, #0x10
 4d0:	ret

absvdi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__absvdi2>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	mov	w8, #0x40                  	// #64
  10:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
  14:	stur	x0, [x29, #-8]
  18:	stur	w8, [x29, #-12]
  1c:	ldur	x10, [x29, #-8]
  20:	cmp	x10, x9
  24:	b.ne	40 <__absvdi2+0x40>  // b.any
  28:	adrp	x0, 0 <__absvdi2>
  2c:	add	x0, x0, #0x0
  30:	mov	w1, #0x16                  	// #22
  34:	adrp	x2, 0 <__absvdi2>
  38:	add	x2, x2, #0x0
  3c:	bl	0 <__compilerrt_abort_impl>
  40:	ldur	x8, [x29, #-8]
  44:	asr	x8, x8, #63
  48:	str	x8, [sp, #8]
  4c:	ldur	x8, [x29, #-8]
  50:	ldr	x9, [sp, #8]
  54:	eor	x8, x8, x9
  58:	ldr	x9, [sp, #8]
  5c:	subs	x0, x8, x9
  60:	ldp	x29, x30, [sp, #32]
  64:	add	sp, sp, #0x30
  68:	ret

absvsi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__absvsi2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	mov	w8, #0x20                  	// #32
  10:	mov	w9, #0x80000000            	// #-2147483648
  14:	stur	w0, [x29, #-4]
  18:	str	w8, [sp, #8]
  1c:	ldur	w8, [x29, #-4]
  20:	cmp	w8, w9
  24:	b.ne	40 <__absvsi2+0x40>  // b.any
  28:	adrp	x0, 0 <__absvsi2>
  2c:	add	x0, x0, #0x0
  30:	mov	w1, #0x16                  	// #22
  34:	adrp	x2, 0 <__absvsi2>
  38:	add	x2, x2, #0x0
  3c:	bl	0 <__compilerrt_abort_impl>
  40:	ldur	w8, [x29, #-4]
  44:	asr	w8, w8, #31
  48:	str	w8, [sp, #4]
  4c:	ldur	w8, [x29, #-4]
  50:	ldr	w9, [sp, #4]
  54:	eor	w8, w8, w9
  58:	ldr	w9, [sp, #4]
  5c:	subs	w0, w8, w9
  60:	ldp	x29, x30, [sp, #16]
  64:	add	sp, sp, #0x20
  68:	ret

absvti2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__absvti2>:
   0:	sub	sp, sp, #0x40
   4:	stp	x29, x30, [sp, #48]
   8:	add	x29, sp, #0x30
   c:	stur	x1, [x29, #-8]
  10:	stur	x0, [x29, #-16]
  14:	mov	w8, #0x80                  	// #128
  18:	stur	w8, [x29, #-20]
  1c:	ldur	x9, [x29, #-16]
  20:	ldur	x10, [x29, #-8]
  24:	eor	x10, x10, #0x8000000000000000
  28:	orr	x9, x9, x10
  2c:	cbnz	x9, 4c <__absvti2+0x4c>
  30:	b	34 <__absvti2+0x34>
  34:	adrp	x0, 0 <__absvti2>
  38:	add	x0, x0, #0x0
  3c:	adrp	x2, 0 <__absvti2>
  40:	add	x2, x2, #0x0
  44:	mov	w1, #0x18                  	// #24
  48:	bl	0 <__compilerrt_abort_impl>
  4c:	ldur	x8, [x29, #-8]
  50:	asr	x8, x8, #63
  54:	str	x8, [sp, #8]
  58:	str	x8, [sp]
  5c:	ldur	x8, [x29, #-16]
  60:	ldur	x9, [x29, #-8]
  64:	ldr	x10, [sp]
  68:	ldr	x11, [sp, #8]
  6c:	eor	x9, x9, x11
  70:	eor	x8, x8, x10
  74:	subs	x0, x8, x10
  78:	sbcs	x1, x9, x11
  7c:	ldp	x29, x30, [sp, #48]
  80:	add	sp, sp, #0x40
  84:	ret

adddf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__adddf3>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp, #8]
  10:	str	d1, [sp]
  14:	ldr	d0, [sp, #8]
  18:	ldr	d1, [sp]
  1c:	bl	2c <__addXf3__>
  20:	ldp	x29, x30, [sp, #16]
  24:	add	sp, sp, #0x20
  28:	ret

000000000000002c <__addXf3__>:
  2c:	sub	sp, sp, #0xd0
  30:	stp	x29, x30, [sp, #192]
  34:	add	x29, sp, #0xc0
  38:	mov	x8, #0x7fefffffffffffff    	// #9218868437227405311
  3c:	adrp	x9, 0 <__fe_getround>
  40:	ldr	x9, [x9]
  44:	adrp	x10, 0 <__fe_raise_inexact>
  48:	ldr	x10, [x10]
  4c:	stur	d0, [x29, #-16]
  50:	stur	d1, [x29, #-24]
  54:	ldur	d0, [x29, #-16]
  58:	str	x8, [sp, #48]
  5c:	str	x9, [sp, #40]
  60:	str	x10, [sp, #32]
  64:	bl	5b4 <toRep>
  68:	stur	x0, [x29, #-32]
  6c:	ldur	d0, [x29, #-24]
  70:	bl	5b4 <toRep>
  74:	stur	x0, [x29, #-40]
  78:	ldur	x8, [x29, #-32]
  7c:	and	x8, x8, #0x7fffffffffffffff
  80:	stur	x8, [x29, #-48]
  84:	ldur	x8, [x29, #-40]
  88:	and	x8, x8, #0x7fffffffffffffff
  8c:	stur	x8, [x29, #-56]
  90:	ldur	x8, [x29, #-48]
  94:	subs	x8, x8, #0x1
  98:	ldr	x9, [sp, #48]
  9c:	cmp	x8, x9
  a0:	b.cs	b8 <__addXf3__+0x8c>  // b.hs, b.nlast
  a4:	ldur	x8, [x29, #-56]
  a8:	subs	x8, x8, #0x1
  ac:	mov	x9, #0x7fefffffffffffff    	// #9218868437227405311
  b0:	cmp	x8, x9
  b4:	b.cc	1d0 <__addXf3__+0x1a4>  // b.lo, b.ul, b.last
  b8:	ldur	x8, [x29, #-48]
  bc:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
  c0:	cmp	x8, x9
  c4:	b.ls	e0 <__addXf3__+0xb4>  // b.plast
  c8:	ldur	d0, [x29, #-16]
  cc:	bl	5b4 <toRep>
  d0:	orr	x0, x0, #0x8000000000000
  d4:	bl	5d0 <fromRep>
  d8:	stur	d0, [x29, #-8]
  dc:	b	5a4 <__addXf3__+0x578>
  e0:	ldur	x8, [x29, #-56]
  e4:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
  e8:	cmp	x8, x9
  ec:	b.ls	108 <__addXf3__+0xdc>  // b.plast
  f0:	ldur	d0, [x29, #-24]
  f4:	bl	5b4 <toRep>
  f8:	orr	x0, x0, #0x8000000000000
  fc:	bl	5d0 <fromRep>
 100:	stur	d0, [x29, #-8]
 104:	b	5a4 <__addXf3__+0x578>
 108:	ldur	x8, [x29, #-48]
 10c:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 110:	cmp	x8, x9
 114:	b.ne	15c <__addXf3__+0x130>  // b.any
 118:	ldur	d0, [x29, #-16]
 11c:	bl	5b4 <toRep>
 120:	ldur	d0, [x29, #-24]
 124:	str	x0, [sp, #24]
 128:	bl	5b4 <toRep>
 12c:	ldr	x8, [sp, #24]
 130:	eor	x9, x8, x0
 134:	mov	x10, #0x8000000000000000    	// #-9223372036854775808
 138:	cmp	x9, x10
 13c:	b.ne	150 <__addXf3__+0x124>  // b.any
 140:	mov	x0, #0x7ff8000000000000    	// #9221120237041090560
 144:	bl	5d0 <fromRep>
 148:	stur	d0, [x29, #-8]
 14c:	b	5a4 <__addXf3__+0x578>
 150:	ldur	x8, [x29, #-16]
 154:	stur	x8, [x29, #-8]
 158:	b	5a4 <__addXf3__+0x578>
 15c:	ldur	x8, [x29, #-56]
 160:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 164:	cmp	x8, x9
 168:	b.ne	178 <__addXf3__+0x14c>  // b.any
 16c:	ldur	x8, [x29, #-24]
 170:	stur	x8, [x29, #-8]
 174:	b	5a4 <__addXf3__+0x578>
 178:	ldur	x8, [x29, #-48]
 17c:	cbnz	x8, 1bc <__addXf3__+0x190>
 180:	ldur	x8, [x29, #-56]
 184:	cbnz	x8, 1b0 <__addXf3__+0x184>
 188:	ldur	d0, [x29, #-16]
 18c:	bl	5b4 <toRep>
 190:	ldur	d0, [x29, #-24]
 194:	str	x0, [sp, #16]
 198:	bl	5b4 <toRep>
 19c:	ldr	x8, [sp, #16]
 1a0:	and	x0, x8, x0
 1a4:	bl	5d0 <fromRep>
 1a8:	stur	d0, [x29, #-8]
 1ac:	b	5a4 <__addXf3__+0x578>
 1b0:	ldur	x8, [x29, #-24]
 1b4:	stur	x8, [x29, #-8]
 1b8:	b	5a4 <__addXf3__+0x578>
 1bc:	ldur	x8, [x29, #-56]
 1c0:	cbnz	x8, 1d0 <__addXf3__+0x1a4>
 1c4:	ldur	x8, [x29, #-16]
 1c8:	stur	x8, [x29, #-8]
 1cc:	b	5a4 <__addXf3__+0x578>
 1d0:	ldur	x8, [x29, #-56]
 1d4:	ldur	x9, [x29, #-48]
 1d8:	cmp	x8, x9
 1dc:	b.ls	1f8 <__addXf3__+0x1cc>  // b.plast
 1e0:	ldur	x8, [x29, #-32]
 1e4:	stur	x8, [x29, #-64]
 1e8:	ldur	x8, [x29, #-40]
 1ec:	stur	x8, [x29, #-32]
 1f0:	ldur	x8, [x29, #-64]
 1f4:	stur	x8, [x29, #-40]
 1f8:	ldur	x8, [x29, #-32]
 1fc:	lsr	x8, x8, #52
 200:	and	x8, x8, #0x7ff
 204:	stur	w8, [x29, #-68]
 208:	ldur	x9, [x29, #-40]
 20c:	lsr	x9, x9, #52
 210:	and	x9, x9, #0x7ff
 214:	stur	w9, [x29, #-72]
 218:	ldur	x10, [x29, #-32]
 21c:	and	x10, x10, #0xfffffffffffff
 220:	stur	x10, [x29, #-80]
 224:	ldur	x10, [x29, #-40]
 228:	and	x10, x10, #0xfffffffffffff
 22c:	stur	x10, [x29, #-88]
 230:	ldur	w8, [x29, #-68]
 234:	cbnz	w8, 244 <__addXf3__+0x218>
 238:	sub	x0, x29, #0x50
 23c:	bl	5ec <normalize>
 240:	stur	w0, [x29, #-68]
 244:	ldur	w8, [x29, #-72]
 248:	cbnz	w8, 258 <__addXf3__+0x22c>
 24c:	sub	x0, x29, #0x58
 250:	bl	5ec <normalize>
 254:	stur	w0, [x29, #-72]
 258:	ldur	x8, [x29, #-32]
 25c:	and	x8, x8, #0x8000000000000000
 260:	str	x8, [sp, #96]
 264:	ldur	x8, [x29, #-32]
 268:	ldur	x9, [x29, #-40]
 26c:	eor	x8, x8, x9
 270:	tst	x8, #0x8000000000000000
 274:	cset	w10, ne  // ne = any
 278:	and	w10, w10, #0x1
 27c:	strb	w10, [sp, #95]
 280:	ldur	x8, [x29, #-80]
 284:	orr	x8, x8, #0x10000000000000
 288:	lsl	x8, x8, #3
 28c:	stur	x8, [x29, #-80]
 290:	ldur	x8, [x29, #-88]
 294:	orr	x8, x8, #0x10000000000000
 298:	lsl	x8, x8, #3
 29c:	stur	x8, [x29, #-88]
 2a0:	ldur	w10, [x29, #-68]
 2a4:	ldur	w11, [x29, #-72]
 2a8:	subs	w10, w10, w11
 2ac:	str	w10, [sp, #88]
 2b0:	ldr	w10, [sp, #88]
 2b4:	cbz	w10, 320 <__addXf3__+0x2f4>
 2b8:	ldr	w8, [sp, #88]
 2bc:	mov	w9, w8
 2c0:	cmp	x9, #0x40
 2c4:	b.cs	318 <__addXf3__+0x2ec>  // b.hs, b.nlast
 2c8:	ldur	x8, [x29, #-88]
 2cc:	ldr	w9, [sp, #88]
 2d0:	mov	w10, w9
 2d4:	mov	x11, #0x40                  	// #64
 2d8:	subs	x10, x11, x10
 2dc:	lsl	x8, x8, x10
 2e0:	cmp	x8, #0x0
 2e4:	cset	w9, ne  // ne = any
 2e8:	and	w9, w9, #0x1
 2ec:	strb	w9, [sp, #87]
 2f0:	ldur	x8, [x29, #-88]
 2f4:	ldr	w9, [sp, #88]
 2f8:	mov	w10, w9
 2fc:	lsr	x8, x8, x10
 300:	ldrb	w9, [sp, #87]
 304:	mov	w0, w9
 308:	and	x10, x0, #0x1
 30c:	orr	x8, x8, x10
 310:	stur	x8, [x29, #-88]
 314:	b	320 <__addXf3__+0x2f4>
 318:	mov	x8, #0x1                   	// #1
 31c:	stur	x8, [x29, #-88]
 320:	ldrb	w8, [sp, #95]
 324:	tbnz	w8, #0, 32c <__addXf3__+0x300>
 328:	b	3b4 <__addXf3__+0x388>
 32c:	ldur	x8, [x29, #-88]
 330:	ldur	x9, [x29, #-80]
 334:	subs	x8, x9, x8
 338:	stur	x8, [x29, #-80]
 33c:	ldur	x8, [x29, #-80]
 340:	cbnz	x8, 358 <__addXf3__+0x32c>
 344:	mov	x8, xzr
 348:	mov	x0, x8
 34c:	bl	5d0 <fromRep>
 350:	stur	d0, [x29, #-8]
 354:	b	5a4 <__addXf3__+0x578>
 358:	ldur	x8, [x29, #-80]
 35c:	mov	x9, #0x80000000000000      	// #36028797018963968
 360:	cmp	x8, x9
 364:	b.cs	3b0 <__addXf3__+0x384>  // b.hs, b.nlast
 368:	ldur	x0, [x29, #-80]
 36c:	bl	664 <rep_clz>
 370:	mov	x8, #0x80000000000000      	// #36028797018963968
 374:	str	w0, [sp, #12]
 378:	mov	x0, x8
 37c:	bl	664 <rep_clz>
 380:	ldr	w9, [sp, #12]
 384:	subs	w10, w9, w0
 388:	str	w10, [sp, #80]
 38c:	ldr	w10, [sp, #80]
 390:	mov	w8, w10
 394:	ldur	x11, [x29, #-80]
 398:	lsl	x8, x11, x8
 39c:	stur	x8, [x29, #-80]
 3a0:	ldr	w10, [sp, #80]
 3a4:	ldur	w12, [x29, #-68]
 3a8:	subs	w10, w12, w10
 3ac:	stur	w10, [x29, #-68]
 3b0:	b	408 <__addXf3__+0x3dc>
 3b4:	ldur	x8, [x29, #-88]
 3b8:	ldur	x9, [x29, #-80]
 3bc:	add	x8, x9, x8
 3c0:	stur	x8, [x29, #-80]
 3c4:	ldur	x8, [x29, #-80]
 3c8:	and	x8, x8, #0x100000000000000
 3cc:	cbz	x8, 408 <__addXf3__+0x3dc>
 3d0:	ldur	x8, [x29, #-80]
 3d4:	tst	x8, #0x1
 3d8:	cset	w9, ne  // ne = any
 3dc:	and	w9, w9, #0x1
 3e0:	strb	w9, [sp, #79]
 3e4:	ldur	x8, [x29, #-80]
 3e8:	ldrb	w9, [sp, #79]
 3ec:	mov	w0, w9
 3f0:	and	x10, x0, #0x1
 3f4:	orr	x8, x10, x8, lsr #1
 3f8:	stur	x8, [x29, #-80]
 3fc:	ldur	w9, [x29, #-68]
 400:	add	w9, w9, #0x1
 404:	stur	w9, [x29, #-68]
 408:	ldur	w8, [x29, #-68]
 40c:	cmp	w8, #0x7ff
 410:	b.lt	42c <__addXf3__+0x400>  // b.tstop
 414:	ldr	x8, [sp, #96]
 418:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 41c:	orr	x0, x9, x8
 420:	bl	5d0 <fromRep>
 424:	stur	d0, [x29, #-8]
 428:	b	5a4 <__addXf3__+0x578>
 42c:	ldur	w8, [x29, #-68]
 430:	cmp	w8, #0x0
 434:	cset	w8, gt
 438:	tbnz	w8, #0, 498 <__addXf3__+0x46c>
 43c:	ldur	w8, [x29, #-68]
 440:	mov	w9, #0x1                   	// #1
 444:	subs	w8, w9, w8
 448:	str	w8, [sp, #72]
 44c:	ldur	x10, [x29, #-80]
 450:	ldrsw	x11, [sp, #72]
 454:	mov	x12, #0x40                  	// #64
 458:	subs	x11, x12, x11
 45c:	lsl	x10, x10, x11
 460:	cmp	x10, #0x0
 464:	cset	w8, ne  // ne = any
 468:	and	w8, w8, #0x1
 46c:	strb	w8, [sp, #71]
 470:	ldur	x10, [x29, #-80]
 474:	ldr	w8, [sp, #72]
 478:	mov	w11, w8
 47c:	lsr	x10, x10, x11
 480:	ldrb	w8, [sp, #71]
 484:	mov	w0, w8
 488:	and	x11, x0, #0x1
 48c:	orr	x10, x10, x11
 490:	stur	x10, [x29, #-80]
 494:	stur	wzr, [x29, #-68]
 498:	ldur	x8, [x29, #-80]
 49c:	and	x8, x8, #0x7
 4a0:	str	w8, [sp, #64]
 4a4:	ldur	x9, [x29, #-80]
 4a8:	lsr	x9, x9, #3
 4ac:	and	x9, x9, #0xfffffffffffff
 4b0:	str	x9, [sp, #56]
 4b4:	ldursw	x9, [x29, #-68]
 4b8:	ldr	x10, [sp, #56]
 4bc:	orr	x9, x10, x9, lsl #52
 4c0:	str	x9, [sp, #56]
 4c4:	ldr	x9, [sp, #96]
 4c8:	ldr	x10, [sp, #56]
 4cc:	orr	x9, x10, x9
 4d0:	str	x9, [sp, #56]
 4d4:	ldr	x9, [sp, #40]
 4d8:	blr	x9
 4dc:	subs	w8, w0, #0x0
 4e0:	mov	w9, w8
 4e4:	ubfx	x9, x9, #0, #32
 4e8:	cmp	x9, #0x3
 4ec:	str	x9, [sp]
 4f0:	b.hi	588 <__addXf3__+0x55c>  // b.pmore
 4f4:	adrp	x8, 0 <__adddf3>
 4f8:	add	x8, x8, #0x0
 4fc:	ldr	x11, [sp]
 500:	ldrsw	x10, [x8, x11, lsl #2]
 504:	add	x9, x8, x10
 508:	br	x9
 50c:	ldr	w8, [sp, #64]
 510:	cmp	w8, #0x4
 514:	b.le	524 <__addXf3__+0x4f8>
 518:	ldr	x8, [sp, #56]
 51c:	add	x8, x8, #0x1
 520:	str	x8, [sp, #56]
 524:	ldr	w8, [sp, #64]
 528:	cmp	w8, #0x4
 52c:	b.ne	544 <__addXf3__+0x518>  // b.any
 530:	ldr	x8, [sp, #56]
 534:	and	x8, x8, #0x1
 538:	ldr	x9, [sp, #56]
 53c:	add	x8, x9, x8
 540:	str	x8, [sp, #56]
 544:	b	588 <__addXf3__+0x55c>
 548:	ldr	x8, [sp, #96]
 54c:	cbz	x8, 564 <__addXf3__+0x538>
 550:	ldr	w8, [sp, #64]
 554:	cbz	w8, 564 <__addXf3__+0x538>
 558:	ldr	x8, [sp, #56]
 55c:	add	x8, x8, #0x1
 560:	str	x8, [sp, #56]
 564:	b	588 <__addXf3__+0x55c>
 568:	ldr	x8, [sp, #96]
 56c:	cbnz	x8, 584 <__addXf3__+0x558>
 570:	ldr	w8, [sp, #64]
 574:	cbz	w8, 584 <__addXf3__+0x558>
 578:	ldr	x8, [sp, #56]
 57c:	add	x8, x8, #0x1
 580:	str	x8, [sp, #56]
 584:	b	588 <__addXf3__+0x55c>
 588:	ldr	w8, [sp, #64]
 58c:	cbz	w8, 598 <__addXf3__+0x56c>
 590:	ldr	x8, [sp, #32]
 594:	blr	x8
 598:	ldr	x0, [sp, #56]
 59c:	bl	5d0 <fromRep>
 5a0:	stur	d0, [x29, #-8]
 5a4:	ldur	d0, [x29, #-8]
 5a8:	ldp	x29, x30, [sp, #192]
 5ac:	add	sp, sp, #0xd0
 5b0:	ret

00000000000005b4 <toRep>:
 5b4:	sub	sp, sp, #0x10
 5b8:	str	d0, [sp, #8]
 5bc:	ldr	x8, [sp, #8]
 5c0:	str	x8, [sp]
 5c4:	ldr	x0, [sp]
 5c8:	add	sp, sp, #0x10
 5cc:	ret

00000000000005d0 <fromRep>:
 5d0:	sub	sp, sp, #0x10
 5d4:	str	x0, [sp, #8]
 5d8:	ldr	x8, [sp, #8]
 5dc:	str	x8, [sp]
 5e0:	ldr	d0, [sp]
 5e4:	add	sp, sp, #0x10
 5e8:	ret

00000000000005ec <normalize>:
 5ec:	sub	sp, sp, #0x30
 5f0:	stp	x29, x30, [sp, #32]
 5f4:	add	x29, sp, #0x20
 5f8:	mov	x8, #0x10000000000000      	// #4503599627370496
 5fc:	mov	w9, #0x1                   	// #1
 600:	stur	x0, [x29, #-8]
 604:	ldur	x10, [x29, #-8]
 608:	ldr	x0, [x10]
 60c:	str	x8, [sp, #8]
 610:	str	w9, [sp, #4]
 614:	bl	664 <rep_clz>
 618:	ldr	x8, [sp, #8]
 61c:	str	w0, [sp]
 620:	mov	x0, x8
 624:	bl	664 <rep_clz>
 628:	ldr	w9, [sp]
 62c:	subs	w11, w9, w0
 630:	stur	w11, [x29, #-12]
 634:	ldur	w11, [x29, #-12]
 638:	mov	w8, w11
 63c:	ldur	x10, [x29, #-8]
 640:	ldr	x12, [x10]
 644:	lsl	x8, x12, x8
 648:	str	x8, [x10]
 64c:	ldur	w11, [x29, #-12]
 650:	ldr	w13, [sp, #4]
 654:	subs	w0, w13, w11
 658:	ldp	x29, x30, [sp, #32]
 65c:	add	sp, sp, #0x30
 660:	ret

0000000000000664 <rep_clz>:
 664:	sub	sp, sp, #0x10
 668:	str	x0, [sp, #8]
 66c:	ldr	x8, [sp, #8]
 670:	clz	x8, x8
 674:	mov	w0, w8
 678:	add	sp, sp, #0x10
 67c:	ret

addsf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__addsf3>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	str	s1, [sp, #8]
  14:	ldur	s0, [x29, #-4]
  18:	ldr	s1, [sp, #8]
  1c:	bl	2c <__addXf3__>
  20:	ldp	x29, x30, [sp, #16]
  24:	add	sp, sp, #0x20
  28:	ret

000000000000002c <__addXf3__>:
  2c:	sub	sp, sp, #0xa0
  30:	stp	x29, x30, [sp, #144]
  34:	add	x29, sp, #0x90
  38:	mov	w8, #0x7f7fffff            	// #2139095039
  3c:	adrp	x9, 0 <__fe_getround>
  40:	ldr	x9, [x9]
  44:	adrp	x10, 0 <__fe_raise_inexact>
  48:	ldr	x10, [x10]
  4c:	stur	s0, [x29, #-8]
  50:	stur	s1, [x29, #-12]
  54:	ldur	s0, [x29, #-8]
  58:	str	w8, [sp, #52]
  5c:	str	x9, [sp, #40]
  60:	str	x10, [sp, #32]
  64:	bl	5b0 <toRep>
  68:	stur	w0, [x29, #-16]
  6c:	ldur	s0, [x29, #-12]
  70:	bl	5b0 <toRep>
  74:	stur	w0, [x29, #-20]
  78:	ldur	w8, [x29, #-16]
  7c:	and	w8, w8, #0x7fffffff
  80:	stur	w8, [x29, #-24]
  84:	ldur	w8, [x29, #-20]
  88:	and	w8, w8, #0x7fffffff
  8c:	stur	w8, [x29, #-28]
  90:	ldur	w8, [x29, #-24]
  94:	subs	w8, w8, #0x1
  98:	ldr	w11, [sp, #52]
  9c:	cmp	w8, w11
  a0:	b.cs	b8 <__addXf3__+0x8c>  // b.hs, b.nlast
  a4:	ldur	w8, [x29, #-28]
  a8:	subs	w8, w8, #0x1
  ac:	mov	w9, #0x7f7fffff            	// #2139095039
  b0:	cmp	w8, w9
  b4:	b.cc	1d0 <__addXf3__+0x1a4>  // b.lo, b.ul, b.last
  b8:	ldur	w8, [x29, #-24]
  bc:	mov	w9, #0x7f800000            	// #2139095040
  c0:	cmp	w8, w9
  c4:	b.ls	e0 <__addXf3__+0xb4>  // b.plast
  c8:	ldur	s0, [x29, #-8]
  cc:	bl	5b0 <toRep>
  d0:	orr	w0, w0, #0x400000
  d4:	bl	5cc <fromRep>
  d8:	stur	s0, [x29, #-4]
  dc:	b	5a0 <__addXf3__+0x574>
  e0:	ldur	w8, [x29, #-28]
  e4:	mov	w9, #0x7f800000            	// #2139095040
  e8:	cmp	w8, w9
  ec:	b.ls	108 <__addXf3__+0xdc>  // b.plast
  f0:	ldur	s0, [x29, #-12]
  f4:	bl	5b0 <toRep>
  f8:	orr	w0, w0, #0x400000
  fc:	bl	5cc <fromRep>
 100:	stur	s0, [x29, #-4]
 104:	b	5a0 <__addXf3__+0x574>
 108:	ldur	w8, [x29, #-24]
 10c:	mov	w9, #0x7f800000            	// #2139095040
 110:	cmp	w8, w9
 114:	b.ne	15c <__addXf3__+0x130>  // b.any
 118:	ldur	s0, [x29, #-8]
 11c:	bl	5b0 <toRep>
 120:	ldur	s0, [x29, #-12]
 124:	str	w0, [sp, #28]
 128:	bl	5b0 <toRep>
 12c:	ldr	w8, [sp, #28]
 130:	eor	w9, w8, w0
 134:	mov	w10, #0x80000000            	// #-2147483648
 138:	cmp	w9, w10
 13c:	b.ne	150 <__addXf3__+0x124>  // b.any
 140:	mov	w0, #0x7fc00000            	// #2143289344
 144:	bl	5cc <fromRep>
 148:	stur	s0, [x29, #-4]
 14c:	b	5a0 <__addXf3__+0x574>
 150:	ldur	w8, [x29, #-8]
 154:	stur	w8, [x29, #-4]
 158:	b	5a0 <__addXf3__+0x574>
 15c:	ldur	w8, [x29, #-28]
 160:	mov	w9, #0x7f800000            	// #2139095040
 164:	cmp	w8, w9
 168:	b.ne	178 <__addXf3__+0x14c>  // b.any
 16c:	ldur	w8, [x29, #-12]
 170:	stur	w8, [x29, #-4]
 174:	b	5a0 <__addXf3__+0x574>
 178:	ldur	w8, [x29, #-24]
 17c:	cbnz	w8, 1bc <__addXf3__+0x190>
 180:	ldur	w8, [x29, #-28]
 184:	cbnz	w8, 1b0 <__addXf3__+0x184>
 188:	ldur	s0, [x29, #-8]
 18c:	bl	5b0 <toRep>
 190:	ldur	s0, [x29, #-12]
 194:	str	w0, [sp, #24]
 198:	bl	5b0 <toRep>
 19c:	ldr	w8, [sp, #24]
 1a0:	and	w0, w8, w0
 1a4:	bl	5cc <fromRep>
 1a8:	stur	s0, [x29, #-4]
 1ac:	b	5a0 <__addXf3__+0x574>
 1b0:	ldur	w8, [x29, #-12]
 1b4:	stur	w8, [x29, #-4]
 1b8:	b	5a0 <__addXf3__+0x574>
 1bc:	ldur	w8, [x29, #-28]
 1c0:	cbnz	w8, 1d0 <__addXf3__+0x1a4>
 1c4:	ldur	w8, [x29, #-8]
 1c8:	stur	w8, [x29, #-4]
 1cc:	b	5a0 <__addXf3__+0x574>
 1d0:	ldur	w8, [x29, #-28]
 1d4:	ldur	w9, [x29, #-24]
 1d8:	cmp	w8, w9
 1dc:	b.ls	1f8 <__addXf3__+0x1cc>  // b.plast
 1e0:	ldur	w8, [x29, #-16]
 1e4:	stur	w8, [x29, #-32]
 1e8:	ldur	w8, [x29, #-20]
 1ec:	stur	w8, [x29, #-16]
 1f0:	ldur	w8, [x29, #-32]
 1f4:	stur	w8, [x29, #-20]
 1f8:	ldur	w8, [x29, #-16]
 1fc:	mov	x9, #0x17                  	// #23
 200:	lsr	w8, w8, #23
 204:	and	w8, w8, #0xff
 208:	stur	w8, [x29, #-36]
 20c:	ldur	w8, [x29, #-20]
 210:	lsr	w8, w8, w9
 214:	and	w8, w8, #0xff
 218:	stur	w8, [x29, #-40]
 21c:	ldur	w8, [x29, #-16]
 220:	and	w8, w8, #0x7fffff
 224:	stur	w8, [x29, #-44]
 228:	ldur	w8, [x29, #-20]
 22c:	and	w8, w8, #0x7fffff
 230:	stur	w8, [x29, #-48]
 234:	ldur	w8, [x29, #-36]
 238:	cbnz	w8, 248 <__addXf3__+0x21c>
 23c:	sub	x0, x29, #0x2c
 240:	bl	5e8 <normalize>
 244:	stur	w0, [x29, #-36]
 248:	ldur	w8, [x29, #-40]
 24c:	cbnz	w8, 25c <__addXf3__+0x230>
 250:	sub	x0, x29, #0x30
 254:	bl	5e8 <normalize>
 258:	stur	w0, [x29, #-40]
 25c:	ldur	w8, [x29, #-16]
 260:	mov	w9, #0x80000000            	// #-2147483648
 264:	and	w8, w8, #0x80000000
 268:	stur	w8, [x29, #-52]
 26c:	ldur	w8, [x29, #-16]
 270:	ldur	w10, [x29, #-20]
 274:	eor	w8, w8, w10
 278:	tst	w8, w9
 27c:	cset	w8, ne  // ne = any
 280:	and	w8, w8, #0x1
 284:	sturb	w8, [x29, #-53]
 288:	ldur	w8, [x29, #-44]
 28c:	orr	w8, w8, #0x800000
 290:	lsl	w8, w8, #3
 294:	stur	w8, [x29, #-44]
 298:	ldur	w8, [x29, #-48]
 29c:	orr	w8, w8, #0x800000
 2a0:	lsl	w8, w8, #3
 2a4:	stur	w8, [x29, #-48]
 2a8:	ldur	w8, [x29, #-36]
 2ac:	ldur	w9, [x29, #-40]
 2b0:	subs	w8, w8, w9
 2b4:	stur	w8, [x29, #-60]
 2b8:	ldur	w8, [x29, #-60]
 2bc:	cbz	w8, 324 <__addXf3__+0x2f8>
 2c0:	ldur	w8, [x29, #-60]
 2c4:	mov	w9, w8
 2c8:	cmp	x9, #0x20
 2cc:	b.cs	31c <__addXf3__+0x2f0>  // b.hs, b.nlast
 2d0:	ldur	w8, [x29, #-48]
 2d4:	ldur	w9, [x29, #-60]
 2d8:	mov	w10, w9
 2dc:	mov	x11, #0x20                  	// #32
 2e0:	subs	x10, x11, x10
 2e4:	lsl	w8, w8, w10
 2e8:	cmp	w8, #0x0
 2ec:	cset	w8, ne  // ne = any
 2f0:	mov	w9, #0x1                   	// #1
 2f4:	and	w8, w8, w9
 2f8:	sturb	w8, [x29, #-61]
 2fc:	ldur	w8, [x29, #-48]
 300:	ldur	w9, [x29, #-60]
 304:	lsr	w8, w8, w9
 308:	ldurb	w9, [x29, #-61]
 30c:	and	w9, w9, #0x1
 310:	orr	w8, w8, w9
 314:	stur	w8, [x29, #-48]
 318:	b	324 <__addXf3__+0x2f8>
 31c:	mov	w8, #0x1                   	// #1
 320:	stur	w8, [x29, #-48]
 324:	ldurb	w8, [x29, #-53]
 328:	tbnz	w8, #0, 330 <__addXf3__+0x304>
 32c:	b	3b4 <__addXf3__+0x388>
 330:	ldur	w8, [x29, #-48]
 334:	ldur	w9, [x29, #-44]
 338:	subs	w8, w9, w8
 33c:	stur	w8, [x29, #-44]
 340:	ldur	w8, [x29, #-44]
 344:	cbnz	w8, 35c <__addXf3__+0x330>
 348:	mov	w8, wzr
 34c:	mov	w0, w8
 350:	bl	5cc <fromRep>
 354:	stur	s0, [x29, #-4]
 358:	b	5a0 <__addXf3__+0x574>
 35c:	ldur	w8, [x29, #-44]
 360:	mov	w9, #0x4000000             	// #67108864
 364:	cmp	w8, w9
 368:	b.cs	3b0 <__addXf3__+0x384>  // b.hs, b.nlast
 36c:	ldur	w0, [x29, #-44]
 370:	bl	65c <rep_clz>
 374:	mov	w8, #0x4000000             	// #67108864
 378:	str	w0, [sp, #20]
 37c:	mov	w0, w8
 380:	bl	65c <rep_clz>
 384:	ldr	w8, [sp, #20]
 388:	subs	w9, w8, w0
 38c:	stur	w9, [x29, #-68]
 390:	ldur	w9, [x29, #-68]
 394:	ldur	w10, [x29, #-44]
 398:	lsl	w9, w10, w9
 39c:	stur	w9, [x29, #-44]
 3a0:	ldur	w9, [x29, #-68]
 3a4:	ldur	w10, [x29, #-36]
 3a8:	subs	w9, w10, w9
 3ac:	stur	w9, [x29, #-36]
 3b0:	b	408 <__addXf3__+0x3dc>
 3b4:	ldur	w8, [x29, #-48]
 3b8:	ldur	w9, [x29, #-44]
 3bc:	add	w8, w9, w8
 3c0:	stur	w8, [x29, #-44]
 3c4:	ldur	w8, [x29, #-44]
 3c8:	and	w8, w8, #0x8000000
 3cc:	cbz	w8, 408 <__addXf3__+0x3dc>
 3d0:	ldur	w8, [x29, #-44]
 3d4:	tst	w8, #0x1
 3d8:	cset	w8, ne  // ne = any
 3dc:	mov	w9, #0x1                   	// #1
 3e0:	and	w8, w8, w9
 3e4:	sturb	w8, [x29, #-69]
 3e8:	ldur	w8, [x29, #-44]
 3ec:	ldurb	w9, [x29, #-69]
 3f0:	and	w9, w9, #0x1
 3f4:	orr	w8, w9, w8, lsr #1
 3f8:	stur	w8, [x29, #-44]
 3fc:	ldur	w8, [x29, #-36]
 400:	add	w8, w8, #0x1
 404:	stur	w8, [x29, #-36]
 408:	ldur	w8, [x29, #-36]
 40c:	cmp	w8, #0xff
 410:	b.lt	42c <__addXf3__+0x400>  // b.tstop
 414:	ldur	w8, [x29, #-52]
 418:	mov	w9, #0x7f800000            	// #2139095040
 41c:	orr	w0, w9, w8
 420:	bl	5cc <fromRep>
 424:	stur	s0, [x29, #-4]
 428:	b	5a0 <__addXf3__+0x574>
 42c:	ldur	w8, [x29, #-36]
 430:	cmp	w8, #0x0
 434:	cset	w8, gt
 438:	tbnz	w8, #0, 494 <__addXf3__+0x468>
 43c:	ldur	w8, [x29, #-36]
 440:	mov	w9, #0x1                   	// #1
 444:	subs	w8, w9, w8
 448:	str	w8, [sp, #68]
 44c:	ldur	w8, [x29, #-44]
 450:	ldrsw	x10, [sp, #68]
 454:	mov	x11, #0x20                  	// #32
 458:	subs	x10, x11, x10
 45c:	lsl	w8, w8, w10
 460:	cmp	w8, #0x0
 464:	cset	w8, ne  // ne = any
 468:	mov	w9, #0x1                   	// #1
 46c:	and	w8, w8, w9
 470:	strb	w8, [sp, #67]
 474:	ldur	w8, [x29, #-44]
 478:	ldr	w9, [sp, #68]
 47c:	lsr	w8, w8, w9
 480:	ldrb	w9, [sp, #67]
 484:	and	w9, w9, #0x1
 488:	orr	w8, w8, w9
 48c:	stur	w8, [x29, #-44]
 490:	stur	wzr, [x29, #-36]
 494:	ldur	w8, [x29, #-44]
 498:	and	w8, w8, #0x7
 49c:	str	w8, [sp, #60]
 4a0:	ldur	w8, [x29, #-44]
 4a4:	lsr	w8, w8, #3
 4a8:	and	w8, w8, #0x7fffff
 4ac:	str	w8, [sp, #56]
 4b0:	ldur	w8, [x29, #-36]
 4b4:	ldr	w9, [sp, #56]
 4b8:	orr	w8, w9, w8, lsl #23
 4bc:	str	w8, [sp, #56]
 4c0:	ldur	w8, [x29, #-52]
 4c4:	ldr	w9, [sp, #56]
 4c8:	orr	w8, w9, w8
 4cc:	str	w8, [sp, #56]
 4d0:	ldr	x10, [sp, #40]
 4d4:	blr	x10
 4d8:	subs	w8, w0, #0x0
 4dc:	mov	w10, w8
 4e0:	ubfx	x10, x10, #0, #32
 4e4:	cmp	x10, #0x3
 4e8:	str	x10, [sp, #8]
 4ec:	b.hi	584 <__addXf3__+0x558>  // b.pmore
 4f0:	adrp	x8, 0 <__addsf3>
 4f4:	add	x8, x8, #0x0
 4f8:	ldr	x11, [sp, #8]
 4fc:	ldrsw	x10, [x8, x11, lsl #2]
 500:	add	x9, x8, x10
 504:	br	x9
 508:	ldr	w8, [sp, #60]
 50c:	cmp	w8, #0x4
 510:	b.le	520 <__addXf3__+0x4f4>
 514:	ldr	w8, [sp, #56]
 518:	add	w8, w8, #0x1
 51c:	str	w8, [sp, #56]
 520:	ldr	w8, [sp, #60]
 524:	cmp	w8, #0x4
 528:	b.ne	540 <__addXf3__+0x514>  // b.any
 52c:	ldr	w8, [sp, #56]
 530:	and	w8, w8, #0x1
 534:	ldr	w9, [sp, #56]
 538:	add	w8, w9, w8
 53c:	str	w8, [sp, #56]
 540:	b	584 <__addXf3__+0x558>
 544:	ldur	w8, [x29, #-52]
 548:	cbz	w8, 560 <__addXf3__+0x534>
 54c:	ldr	w8, [sp, #60]
 550:	cbz	w8, 560 <__addXf3__+0x534>
 554:	ldr	w8, [sp, #56]
 558:	add	w8, w8, #0x1
 55c:	str	w8, [sp, #56]
 560:	b	584 <__addXf3__+0x558>
 564:	ldur	w8, [x29, #-52]
 568:	cbnz	w8, 580 <__addXf3__+0x554>
 56c:	ldr	w8, [sp, #60]
 570:	cbz	w8, 580 <__addXf3__+0x554>
 574:	ldr	w8, [sp, #56]
 578:	add	w8, w8, #0x1
 57c:	str	w8, [sp, #56]
 580:	b	584 <__addXf3__+0x558>
 584:	ldr	w8, [sp, #60]
 588:	cbz	w8, 594 <__addXf3__+0x568>
 58c:	ldr	x8, [sp, #32]
 590:	blr	x8
 594:	ldr	w0, [sp, #56]
 598:	bl	5cc <fromRep>
 59c:	stur	s0, [x29, #-4]
 5a0:	ldur	s0, [x29, #-4]
 5a4:	ldp	x29, x30, [sp, #144]
 5a8:	add	sp, sp, #0xa0
 5ac:	ret

00000000000005b0 <toRep>:
 5b0:	sub	sp, sp, #0x10
 5b4:	str	s0, [sp, #12]
 5b8:	ldr	w8, [sp, #12]
 5bc:	str	w8, [sp, #8]
 5c0:	ldr	w0, [sp, #8]
 5c4:	add	sp, sp, #0x10
 5c8:	ret

00000000000005cc <fromRep>:
 5cc:	sub	sp, sp, #0x10
 5d0:	str	w0, [sp, #12]
 5d4:	ldr	w8, [sp, #12]
 5d8:	str	w8, [sp, #8]
 5dc:	ldr	s0, [sp, #8]
 5e0:	add	sp, sp, #0x10
 5e4:	ret

00000000000005e8 <normalize>:
 5e8:	sub	sp, sp, #0x30
 5ec:	stp	x29, x30, [sp, #32]
 5f0:	add	x29, sp, #0x20
 5f4:	mov	w8, #0x800000              	// #8388608
 5f8:	mov	w9, #0x1                   	// #1
 5fc:	stur	x0, [x29, #-8]
 600:	ldur	x10, [x29, #-8]
 604:	ldr	w0, [x10]
 608:	str	w8, [sp, #16]
 60c:	str	w9, [sp, #12]
 610:	bl	65c <rep_clz>
 614:	ldr	w8, [sp, #16]
 618:	str	w0, [sp, #8]
 61c:	mov	w0, w8
 620:	bl	65c <rep_clz>
 624:	ldr	w8, [sp, #8]
 628:	subs	w9, w8, w0
 62c:	stur	w9, [x29, #-12]
 630:	ldur	w9, [x29, #-12]
 634:	ldur	x10, [x29, #-8]
 638:	ldr	w11, [x10]
 63c:	lsl	w9, w11, w9
 640:	str	w9, [x10]
 644:	ldur	w9, [x29, #-12]
 648:	ldr	w11, [sp, #12]
 64c:	subs	w0, w11, w9
 650:	ldp	x29, x30, [sp, #32]
 654:	add	sp, sp, #0x30
 658:	ret

000000000000065c <rep_clz>:
 65c:	sub	sp, sp, #0x10
 660:	str	w0, [sp, #12]
 664:	ldr	w8, [sp, #12]
 668:	clz	w0, w8
 66c:	add	sp, sp, #0x10
 670:	ret

addtf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__addtf3>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	str	q0, [sp, #16]
  10:	str	q1, [sp]
  14:	ldr	q0, [sp, #16]
  18:	ldr	q1, [sp]
  1c:	bl	2c <__addXf3__>
  20:	ldp	x29, x30, [sp, #32]
  24:	add	sp, sp, #0x30
  28:	ret

000000000000002c <__addXf3__>:
  2c:	sub	sp, sp, #0x150
  30:	stp	x29, x30, [sp, #304]
  34:	str	x28, [sp, #320]
  38:	add	x29, sp, #0x130
  3c:	stur	q0, [x29, #-32]
  40:	stur	q1, [x29, #-48]
  44:	ldur	q0, [x29, #-32]
  48:	bl	910 <toRep>
  4c:	stur	x1, [x29, #-56]
  50:	stur	x0, [x29, #-64]
  54:	ldur	q0, [x29, #-48]
  58:	bl	910 <toRep>
  5c:	stur	x1, [x29, #-72]
  60:	stur	x0, [x29, #-80]
  64:	ldur	x8, [x29, #-64]
  68:	ldur	x9, [x29, #-56]
  6c:	and	x9, x9, #0x7fffffffffffffff
  70:	stur	x8, [x29, #-96]
  74:	stur	x9, [x29, #-88]
  78:	ldur	x8, [x29, #-80]
  7c:	ldur	x9, [x29, #-72]
  80:	and	x9, x9, #0x7fffffffffffffff
  84:	stur	x8, [x29, #-112]
  88:	stur	x9, [x29, #-104]
  8c:	ldur	x8, [x29, #-88]
  90:	ldur	x9, [x29, #-96]
  94:	subs	x9, x9, #0x1
  98:	mov	x10, #0xffffffffffffffff    	// #-1
  9c:	adcs	x8, x8, x10
  a0:	adds	x9, x9, #0x1
  a4:	cset	w11, eq  // eq = none
  a8:	mov	x10, #0x7ffeffffffffffff    	// #9223090561878065151
  ac:	subs	x8, x8, x10
  b0:	cset	w12, hi  // hi = pmore
  b4:	csel	w11, w11, w12, eq  // eq = none
  b8:	tbnz	w11, #0, f4 <__addXf3__+0xc8>
  bc:	b	c0 <__addXf3__+0x94>
  c0:	ldur	x8, [x29, #-104]
  c4:	ldur	x9, [x29, #-112]
  c8:	subs	x9, x9, #0x1
  cc:	mov	x10, #0xffffffffffffffff    	// #-1
  d0:	adcs	x8, x8, x10
  d4:	adds	x9, x9, #0x1
  d8:	cset	w11, ne  // ne = any
  dc:	mov	x10, #0x7ffeffffffffffff    	// #9223090561878065151
  e0:	subs	x8, x8, x10
  e4:	cset	w12, cc  // cc = lo, ul, last
  e8:	csel	w11, w11, w12, eq  // eq = none
  ec:	tbnz	w11, #0, 294 <__addXf3__+0x268>
  f0:	b	f4 <__addXf3__+0xc8>
  f4:	ldur	x8, [x29, #-88]
  f8:	ldur	x9, [x29, #-96]
  fc:	subs	x9, x9, #0x0
 100:	cset	w10, eq  // eq = none
 104:	mov	x11, #0x7fff000000000000    	// #9223090561878065152
 108:	subs	x8, x8, x11
 10c:	cset	w12, cc  // cc = lo, ul, last
 110:	csel	w10, w10, w12, eq  // eq = none
 114:	tbnz	w10, #0, 134 <__addXf3__+0x108>
 118:	b	11c <__addXf3__+0xf0>
 11c:	ldur	q0, [x29, #-32]
 120:	bl	910 <toRep>
 124:	orr	x1, x1, #0x800000000000
 128:	bl	930 <fromRep>
 12c:	stur	q0, [x29, #-16]
 130:	b	8fc <__addXf3__+0x8d0>
 134:	ldur	x8, [x29, #-104]
 138:	ldur	x9, [x29, #-112]
 13c:	subs	x9, x9, #0x0
 140:	cset	w10, eq  // eq = none
 144:	mov	x11, #0x7fff000000000000    	// #9223090561878065152
 148:	subs	x8, x8, x11
 14c:	cset	w12, cc  // cc = lo, ul, last
 150:	csel	w10, w10, w12, eq  // eq = none
 154:	tbnz	w10, #0, 174 <__addXf3__+0x148>
 158:	b	15c <__addXf3__+0x130>
 15c:	ldur	q0, [x29, #-48]
 160:	bl	910 <toRep>
 164:	orr	x1, x1, #0x800000000000
 168:	bl	930 <fromRep>
 16c:	stur	q0, [x29, #-16]
 170:	b	8fc <__addXf3__+0x8d0>
 174:	ldur	x8, [x29, #-96]
 178:	ldur	x9, [x29, #-88]
 17c:	eor	x9, x9, #0x7fff000000000000
 180:	orr	x8, x8, x9
 184:	cbnz	x8, 1e4 <__addXf3__+0x1b8>
 188:	b	18c <__addXf3__+0x160>
 18c:	ldur	q0, [x29, #-32]
 190:	bl	910 <toRep>
 194:	ldur	q0, [x29, #-48]
 198:	str	x0, [sp, #56]
 19c:	str	x1, [sp, #48]
 1a0:	bl	910 <toRep>
 1a4:	ldr	x8, [sp, #56]
 1a8:	eor	x9, x8, x0
 1ac:	ldr	x10, [sp, #48]
 1b0:	eor	x11, x10, x1
 1b4:	eor	x11, x11, #0x8000000000000000
 1b8:	orr	x9, x9, x11
 1bc:	cbnz	x9, 1d8 <__addXf3__+0x1ac>
 1c0:	b	1c4 <__addXf3__+0x198>
 1c4:	mov	x0, xzr
 1c8:	mov	x1, #0x7fff800000000000    	// #9223231299366420480
 1cc:	bl	930 <fromRep>
 1d0:	stur	q0, [x29, #-16]
 1d4:	b	8fc <__addXf3__+0x8d0>
 1d8:	ldur	q0, [x29, #-32]
 1dc:	stur	q0, [x29, #-16]
 1e0:	b	8fc <__addXf3__+0x8d0>
 1e4:	ldur	x8, [x29, #-112]
 1e8:	ldur	x9, [x29, #-104]
 1ec:	eor	x9, x9, #0x7fff000000000000
 1f0:	orr	x8, x8, x9
 1f4:	cbnz	x8, 208 <__addXf3__+0x1dc>
 1f8:	b	1fc <__addXf3__+0x1d0>
 1fc:	ldur	q0, [x29, #-48]
 200:	stur	q0, [x29, #-16]
 204:	b	8fc <__addXf3__+0x8d0>
 208:	ldur	x8, [x29, #-88]
 20c:	ldur	x9, [x29, #-96]
 210:	orr	x8, x9, x8
 214:	cbnz	x8, 270 <__addXf3__+0x244>
 218:	b	21c <__addXf3__+0x1f0>
 21c:	ldur	x8, [x29, #-104]
 220:	ldur	x9, [x29, #-112]
 224:	orr	x8, x9, x8
 228:	cbnz	x8, 264 <__addXf3__+0x238>
 22c:	b	230 <__addXf3__+0x204>
 230:	ldur	q0, [x29, #-32]
 234:	bl	910 <toRep>
 238:	ldur	q0, [x29, #-48]
 23c:	str	x0, [sp, #40]
 240:	str	x1, [sp, #32]
 244:	bl	910 <toRep>
 248:	ldr	x8, [sp, #40]
 24c:	and	x0, x8, x0
 250:	ldr	x9, [sp, #32]
 254:	and	x1, x9, x1
 258:	bl	930 <fromRep>
 25c:	stur	q0, [x29, #-16]
 260:	b	8fc <__addXf3__+0x8d0>
 264:	ldur	q0, [x29, #-48]
 268:	stur	q0, [x29, #-16]
 26c:	b	8fc <__addXf3__+0x8d0>
 270:	ldur	x8, [x29, #-104]
 274:	ldur	x9, [x29, #-112]
 278:	orr	x8, x9, x8
 27c:	cbnz	x8, 290 <__addXf3__+0x264>
 280:	b	284 <__addXf3__+0x258>
 284:	ldur	q0, [x29, #-32]
 288:	stur	q0, [x29, #-16]
 28c:	b	8fc <__addXf3__+0x8d0>
 290:	b	294 <__addXf3__+0x268>
 294:	ldur	x8, [x29, #-104]
 298:	ldur	x9, [x29, #-112]
 29c:	ldur	x10, [x29, #-88]
 2a0:	ldur	x11, [x29, #-96]
 2a4:	subs	x9, x9, x11
 2a8:	cset	w12, ls  // ls = plast
 2ac:	subs	x8, x8, x10
 2b0:	cset	w13, ls  // ls = plast
 2b4:	csel	w12, w12, w13, eq  // eq = none
 2b8:	tbnz	w12, #0, 2f4 <__addXf3__+0x2c8>
 2bc:	b	2c0 <__addXf3__+0x294>
 2c0:	ldur	x8, [x29, #-64]
 2c4:	ldur	x9, [x29, #-56]
 2c8:	stur	x9, [x29, #-120]
 2cc:	stur	x8, [x29, #-128]
 2d0:	ldur	x8, [x29, #-80]
 2d4:	ldur	x9, [x29, #-72]
 2d8:	stur	x9, [x29, #-56]
 2dc:	stur	x8, [x29, #-64]
 2e0:	ldur	x8, [x29, #-128]
 2e4:	ldur	x9, [x29, #-120]
 2e8:	stur	x9, [x29, #-72]
 2ec:	stur	x8, [x29, #-80]
 2f0:	b	2f4 <__addXf3__+0x2c8>
 2f4:	ldurh	w8, [x29, #-50]
 2f8:	and	w8, w8, #0x7fff
 2fc:	stur	w8, [x29, #-132]
 300:	ldurh	w8, [x29, #-66]
 304:	and	w8, w8, #0x7fff
 308:	stur	w8, [x29, #-136]
 30c:	ldur	x9, [x29, #-64]
 310:	ldur	x10, [x29, #-56]
 314:	and	x10, x10, #0xffffffffffff
 318:	str	x9, [sp, #144]
 31c:	str	x10, [sp, #152]
 320:	ldur	x9, [x29, #-80]
 324:	ldur	x10, [x29, #-72]
 328:	and	x10, x10, #0xffffffffffff
 32c:	str	x9, [sp, #128]
 330:	str	x10, [sp, #136]
 334:	ldur	w8, [x29, #-132]
 338:	cbnz	w8, 350 <__addXf3__+0x324>
 33c:	b	340 <__addXf3__+0x314>
 340:	add	x0, sp, #0x90
 344:	bl	954 <normalize>
 348:	stur	w0, [x29, #-132]
 34c:	b	350 <__addXf3__+0x324>
 350:	ldur	w8, [x29, #-136]
 354:	cbnz	w8, 36c <__addXf3__+0x340>
 358:	b	35c <__addXf3__+0x330>
 35c:	add	x0, sp, #0x80
 360:	bl	954 <normalize>
 364:	stur	w0, [x29, #-136]
 368:	b	36c <__addXf3__+0x340>
 36c:	ldur	x8, [x29, #-56]
 370:	and	x8, x8, #0x8000000000000000
 374:	mov	x9, xzr
 378:	str	x9, [sp, #112]
 37c:	str	x8, [sp, #120]
 380:	ldur	x8, [x29, #-56]
 384:	ldur	x9, [x29, #-72]
 388:	eor	x8, x8, x9
 38c:	lsr	x8, x8, #63
 390:	strb	w8, [sp, #108]
 394:	ldr	x9, [sp, #144]
 398:	ldr	x10, [sp, #152]
 39c:	extr	x10, x10, x9, #61
 3a0:	lsl	x9, x9, #3
 3a4:	orr	x10, x10, #0x8000000000000
 3a8:	str	x9, [sp, #144]
 3ac:	str	x10, [sp, #152]
 3b0:	ldr	x9, [sp, #128]
 3b4:	ldr	x10, [sp, #136]
 3b8:	extr	x10, x10, x9, #61
 3bc:	lsl	x9, x9, #3
 3c0:	orr	x10, x10, #0x8000000000000
 3c4:	str	x9, [sp, #128]
 3c8:	str	x10, [sp, #136]
 3cc:	ldur	w8, [x29, #-132]
 3d0:	ldur	w11, [x29, #-136]
 3d4:	subs	w8, w8, w11
 3d8:	str	w8, [sp, #104]
 3dc:	ldr	w8, [sp, #104]
 3e0:	cbz	w8, 4d4 <__addXf3__+0x4a8>
 3e4:	b	3e8 <__addXf3__+0x3bc>
 3e8:	ldr	w8, [sp, #104]
 3ec:	subs	w8, w8, #0x7f
 3f0:	b.hi	4b8 <__addXf3__+0x48c>  // b.pmore
 3f4:	b	3f8 <__addXf3__+0x3cc>
 3f8:	ldr	x8, [sp, #136]
 3fc:	ldr	x9, [sp, #128]
 400:	ldr	w10, [sp, #104]
 404:	mov	w11, w10
 408:	mov	w10, #0x80                  	// #128
 40c:	mov	w12, w10
 410:	subs	x12, x12, x11
 414:	mov	x13, xzr
 418:	sub	x14, x13, x12
 41c:	lsr	x14, x9, x14
 420:	subs	x12, x12, #0x0
 424:	csel	x14, x13, x14, eq  // eq = none
 428:	sub	x15, x13, x11
 42c:	lsl	x9, x9, x15
 430:	mov	w10, #0x40                  	// #64
 434:	mov	w16, w10
 438:	subs	x11, x16, x11
 43c:	subs	x11, x11, #0x0
 440:	csel	x16, x13, x9, ge  // ge = tcont
 444:	lsl	x8, x8, x15
 448:	orr	x8, x14, x8
 44c:	csel	x8, x9, x8, ge  // ge = tcont
 450:	orr	x8, x16, x8
 454:	subs	x8, x8, #0x0
 458:	cset	w10, ne  // ne = any
 45c:	strb	w10, [sp, #100]
 460:	ldr	x9, [sp, #128]
 464:	ldr	x14, [sp, #136]
 468:	ldr	w10, [sp, #104]
 46c:	mov	w15, w10
 470:	sub	x16, x13, x15
 474:	lsl	x16, x14, x16
 478:	subs	x17, x15, #0x0
 47c:	csel	x16, x13, x16, eq  // eq = none
 480:	lsr	x9, x9, x15
 484:	orr	x9, x9, x16
 488:	lsr	x14, x14, x15
 48c:	subs	x15, x15, #0x40
 490:	subs	x15, x15, #0x0
 494:	csel	x9, x14, x9, ge  // ge = tcont
 498:	csel	x13, x13, x14, ge  // ge = tcont
 49c:	ldrb	w10, [sp, #100]
 4a0:	mov	w14, w10
 4a4:	and	x14, x14, #0x1
 4a8:	orr	x9, x9, x14
 4ac:	str	x13, [sp, #136]
 4b0:	str	x9, [sp, #128]
 4b4:	b	4d0 <__addXf3__+0x4a4>
 4b8:	mov	x8, xzr
 4bc:	str	x8, [sp, #136]
 4c0:	mov	w9, #0x1                   	// #1
 4c4:	mov	w8, w9
 4c8:	str	x8, [sp, #128]
 4cc:	b	4d0 <__addXf3__+0x4a4>
 4d0:	b	4d4 <__addXf3__+0x4a8>
 4d4:	ldrb	w8, [sp, #108]
 4d8:	tbz	w8, #0, 5cc <__addXf3__+0x5a0>
 4dc:	b	4e0 <__addXf3__+0x4b4>
 4e0:	ldr	x8, [sp, #136]
 4e4:	ldr	x9, [sp, #128]
 4e8:	ldr	x10, [sp, #152]
 4ec:	ldr	x11, [sp, #144]
 4f0:	subs	x9, x11, x9
 4f4:	sbcs	x8, x10, x8
 4f8:	str	x9, [sp, #144]
 4fc:	str	x8, [sp, #152]
 500:	ldr	x8, [sp, #152]
 504:	ldr	x9, [sp, #144]
 508:	orr	x8, x9, x8
 50c:	cbnz	x8, 52c <__addXf3__+0x500>
 510:	b	514 <__addXf3__+0x4e8>
 514:	mov	x0, xzr
 518:	str	x0, [sp, #24]
 51c:	ldr	x1, [sp, #24]
 520:	bl	930 <fromRep>
 524:	stur	q0, [x29, #-16]
 528:	b	8fc <__addXf3__+0x8d0>
 52c:	ldr	x8, [sp, #152]
 530:	lsr	x8, x8, #51
 534:	cbnz	x8, 5c8 <__addXf3__+0x59c>
 538:	b	53c <__addXf3__+0x510>
 53c:	ldr	x1, [sp, #152]
 540:	ldr	x0, [sp, #144]
 544:	bl	a6c <rep_clz>
 548:	mov	x8, xzr
 54c:	mov	x1, #0x8000000000000       	// #2251799813685248
 550:	str	w0, [sp, #20]
 554:	mov	x0, x8
 558:	str	x8, [sp, #8]
 55c:	bl	a6c <rep_clz>
 560:	ldr	w9, [sp, #20]
 564:	subs	w10, w9, w0
 568:	str	w10, [sp, #96]
 56c:	ldr	w10, [sp, #96]
 570:	mov	w8, w10
 574:	ldr	x11, [sp, #152]
 578:	ldr	x12, [sp, #144]
 57c:	ldr	x13, [sp, #8]
 580:	sub	x14, x13, x8
 584:	lsr	x14, x12, x14
 588:	subs	x15, x8, #0x0
 58c:	csel	x14, x13, x14, eq  // eq = none
 590:	lsl	x11, x11, x8
 594:	orr	x11, x14, x11
 598:	lsl	x12, x12, x8
 59c:	subs	x8, x8, #0x40
 5a0:	subs	x8, x8, #0x0
 5a4:	csel	x11, x12, x11, ge  // ge = tcont
 5a8:	csel	x12, x13, x12, ge  // ge = tcont
 5ac:	str	x12, [sp, #144]
 5b0:	str	x11, [sp, #152]
 5b4:	ldr	w10, [sp, #96]
 5b8:	ldur	w16, [x29, #-132]
 5bc:	subs	w10, w16, w10
 5c0:	stur	w10, [x29, #-132]
 5c4:	b	5c8 <__addXf3__+0x59c>
 5c8:	b	640 <__addXf3__+0x614>
 5cc:	ldr	x8, [sp, #136]
 5d0:	ldr	x9, [sp, #128]
 5d4:	ldr	x10, [sp, #152]
 5d8:	ldr	x11, [sp, #144]
 5dc:	adds	x9, x11, x9
 5e0:	adcs	x8, x10, x8
 5e4:	str	x9, [sp, #144]
 5e8:	str	x8, [sp, #152]
 5ec:	ldrb	w12, [sp, #158]
 5f0:	tbz	w12, #4, 63c <__addXf3__+0x610>
 5f4:	b	5f8 <__addXf3__+0x5cc>
 5f8:	ldrb	w8, [sp, #144]
 5fc:	and	w8, w8, #0x1
 600:	strb	w8, [sp, #92]
 604:	ldr	x9, [sp, #144]
 608:	ldr	x10, [sp, #152]
 60c:	extr	x9, x10, x9, #1
 610:	lsr	x10, x10, #1
 614:	ldrb	w8, [sp, #92]
 618:	mov	w11, w8
 61c:	and	x11, x11, #0x1
 620:	orr	x9, x9, x11
 624:	str	x10, [sp, #152]
 628:	str	x9, [sp, #144]
 62c:	ldur	w8, [x29, #-132]
 630:	add	w8, w8, #0x1
 634:	stur	w8, [x29, #-132]
 638:	b	63c <__addXf3__+0x610>
 63c:	b	640 <__addXf3__+0x614>
 640:	ldur	w8, [x29, #-132]
 644:	mov	w9, #0x7fff                	// #32767
 648:	subs	w8, w8, w9
 64c:	b.lt	66c <__addXf3__+0x640>  // b.tstop
 650:	b	654 <__addXf3__+0x628>
 654:	ldr	x0, [sp, #112]
 658:	ldr	x8, [sp, #120]
 65c:	orr	x1, x8, #0x7fff000000000000
 660:	bl	930 <fromRep>
 664:	stur	q0, [x29, #-16]
 668:	b	8fc <__addXf3__+0x8d0>
 66c:	ldur	w8, [x29, #-132]
 670:	subs	w8, w8, #0x0
 674:	b.gt	750 <__addXf3__+0x724>
 678:	b	67c <__addXf3__+0x650>
 67c:	ldur	w8, [x29, #-132]
 680:	mov	w9, #0x1                   	// #1
 684:	subs	w8, w9, w8
 688:	str	w8, [sp, #88]
 68c:	ldr	x10, [sp, #152]
 690:	ldr	x11, [sp, #144]
 694:	ldrsw	x12, [sp, #88]
 698:	mov	w8, #0x80                  	// #128
 69c:	mov	w13, w8
 6a0:	subs	x13, x13, x12
 6a4:	mov	x14, xzr
 6a8:	sub	x15, x14, x13
 6ac:	lsr	x15, x11, x15
 6b0:	subs	x13, x13, #0x0
 6b4:	csel	x15, x14, x15, eq  // eq = none
 6b8:	sub	x16, x14, x12
 6bc:	lsl	x11, x11, x16
 6c0:	mov	w8, #0x40                  	// #64
 6c4:	mov	w17, w8
 6c8:	subs	x12, x17, x12
 6cc:	subs	x12, x12, #0x0
 6d0:	csel	x17, x14, x11, ge  // ge = tcont
 6d4:	lsl	x10, x10, x16
 6d8:	orr	x10, x15, x10
 6dc:	csel	x10, x11, x10, ge  // ge = tcont
 6e0:	orr	x10, x17, x10
 6e4:	subs	x10, x10, #0x0
 6e8:	cset	w8, ne  // ne = any
 6ec:	strb	w8, [sp, #84]
 6f0:	ldr	x11, [sp, #144]
 6f4:	ldr	x15, [sp, #152]
 6f8:	ldr	w8, [sp, #88]
 6fc:	mov	w16, w8
 700:	sub	x17, x14, x16
 704:	lsl	x17, x15, x17
 708:	subs	x18, x16, #0x0
 70c:	csel	x17, x14, x17, eq  // eq = none
 710:	lsr	x11, x11, x16
 714:	orr	x11, x11, x17
 718:	lsr	x15, x15, x16
 71c:	subs	x16, x16, #0x40
 720:	subs	x16, x16, #0x0
 724:	csel	x11, x15, x11, ge  // ge = tcont
 728:	csel	x14, x14, x15, ge  // ge = tcont
 72c:	ldrb	w8, [sp, #84]
 730:	mov	w15, w8
 734:	and	x15, x15, #0x1
 738:	orr	x11, x11, x15
 73c:	str	x14, [sp, #152]
 740:	str	x11, [sp, #144]
 744:	mov	w8, wzr
 748:	stur	w8, [x29, #-132]
 74c:	b	750 <__addXf3__+0x724>
 750:	ldr	w8, [sp, #144]
 754:	and	w8, w8, #0x7
 758:	str	w8, [sp, #80]
 75c:	ldr	x9, [sp, #144]
 760:	ldr	x10, [sp, #152]
 764:	extr	x9, x10, x9, #3
 768:	ubfx	x10, x10, #3, #48
 76c:	str	x10, [sp, #72]
 770:	str	x9, [sp, #64]
 774:	ldur	w8, [x29, #-132]
 778:	mov	w9, w8
 77c:	ldr	x10, [sp, #64]
 780:	ldr	x11, [sp, #72]
 784:	orr	x9, x11, x9, lsl #48
 788:	str	x10, [sp, #64]
 78c:	str	x9, [sp, #72]
 790:	ldr	x9, [sp, #120]
 794:	ldr	x10, [sp, #112]
 798:	ldr	x11, [sp, #72]
 79c:	ldr	x12, [sp, #64]
 7a0:	orr	x10, x12, x10
 7a4:	orr	x9, x11, x9
 7a8:	str	x9, [sp, #72]
 7ac:	str	x10, [sp, #64]
 7b0:	bl	0 <__fe_getround>
 7b4:	mov	w8, w0
 7b8:	mov	w9, w8
 7bc:	subs	w8, w0, #0x3
 7c0:	str	x9, [sp]
 7c4:	b.hi	8d4 <__addXf3__+0x8a8>  // b.pmore
 7c8:	adrp	x8, 0 <__addtf3>
 7cc:	add	x8, x8, #0x0
 7d0:	ldr	x11, [sp]
 7d4:	ldrsw	x10, [x8, x11, lsl #2]
 7d8:	add	x9, x8, x10
 7dc:	br	x9
 7e0:	ldr	w8, [sp, #80]
 7e4:	subs	w8, w8, #0x5
 7e8:	b.lt	810 <__addXf3__+0x7e4>  // b.tstop
 7ec:	b	7f0 <__addXf3__+0x7c4>
 7f0:	ldr	x8, [sp, #72]
 7f4:	ldr	x9, [sp, #64]
 7f8:	adds	x9, x9, #0x1
 7fc:	mov	x10, xzr
 800:	adcs	x8, x8, x10
 804:	str	x9, [sp, #64]
 808:	str	x8, [sp, #72]
 80c:	b	810 <__addXf3__+0x7e4>
 810:	ldr	w8, [sp, #80]
 814:	subs	w8, w8, #0x4
 818:	b.ne	844 <__addXf3__+0x818>  // b.any
 81c:	b	820 <__addXf3__+0x7f4>
 820:	ldr	x8, [sp, #72]
 824:	ldr	x9, [sp, #64]
 828:	and	x10, x9, #0x1
 82c:	adds	x9, x9, x10
 830:	mov	x10, xzr
 834:	adcs	x8, x8, x10
 838:	str	x9, [sp, #64]
 83c:	str	x8, [sp, #72]
 840:	b	844 <__addXf3__+0x818>
 844:	b	8d4 <__addXf3__+0x8a8>
 848:	ldr	x8, [sp, #120]
 84c:	ldr	x9, [sp, #112]
 850:	orr	x8, x9, x8
 854:	cbz	x8, 888 <__addXf3__+0x85c>
 858:	b	85c <__addXf3__+0x830>
 85c:	ldr	w8, [sp, #80]
 860:	cbz	w8, 888 <__addXf3__+0x85c>
 864:	b	868 <__addXf3__+0x83c>
 868:	ldr	x8, [sp, #72]
 86c:	ldr	x9, [sp, #64]
 870:	adds	x9, x9, #0x1
 874:	mov	x10, xzr
 878:	adcs	x8, x8, x10
 87c:	str	x9, [sp, #64]
 880:	str	x8, [sp, #72]
 884:	b	888 <__addXf3__+0x85c>
 888:	b	8d4 <__addXf3__+0x8a8>
 88c:	ldr	x8, [sp, #120]
 890:	ldr	x9, [sp, #112]
 894:	orr	x8, x9, x8
 898:	cbnz	x8, 8cc <__addXf3__+0x8a0>
 89c:	b	8a0 <__addXf3__+0x874>
 8a0:	ldr	w8, [sp, #80]
 8a4:	cbz	w8, 8cc <__addXf3__+0x8a0>
 8a8:	b	8ac <__addXf3__+0x880>
 8ac:	ldr	x8, [sp, #72]
 8b0:	ldr	x9, [sp, #64]
 8b4:	adds	x9, x9, #0x1
 8b8:	mov	x10, xzr
 8bc:	adcs	x8, x8, x10
 8c0:	str	x9, [sp, #64]
 8c4:	str	x8, [sp, #72]
 8c8:	b	8cc <__addXf3__+0x8a0>
 8cc:	b	8d4 <__addXf3__+0x8a8>
 8d0:	b	8d4 <__addXf3__+0x8a8>
 8d4:	ldr	w8, [sp, #80]
 8d8:	cbz	w8, 8e8 <__addXf3__+0x8bc>
 8dc:	b	8e0 <__addXf3__+0x8b4>
 8e0:	bl	0 <__fe_raise_inexact>
 8e4:	b	8e8 <__addXf3__+0x8bc>
 8e8:	ldr	x1, [sp, #72]
 8ec:	ldr	x0, [sp, #64]
 8f0:	bl	930 <fromRep>
 8f4:	stur	q0, [x29, #-16]
 8f8:	b	8fc <__addXf3__+0x8d0>
 8fc:	ldur	q0, [x29, #-16]
 900:	ldr	x28, [sp, #320]
 904:	ldp	x29, x30, [sp, #304]
 908:	add	sp, sp, #0x150
 90c:	ret

0000000000000910 <toRep>:
 910:	sub	sp, sp, #0x20
 914:	str	q0, [sp, #16]
 918:	ldr	q0, [sp, #16]
 91c:	str	q0, [sp]
 920:	ldr	x0, [sp]
 924:	ldr	x1, [sp, #8]
 928:	add	sp, sp, #0x20
 92c:	ret

0000000000000930 <fromRep>:
 930:	sub	sp, sp, #0x20
 934:	mov	v0.d[0], x0
 938:	mov	v0.d[1], x1
 93c:	str	q0, [sp, #16]
 940:	ldr	q0, [sp, #16]
 944:	str	q0, [sp]
 948:	ldr	q0, [sp]
 94c:	add	sp, sp, #0x20
 950:	ret

0000000000000954 <normalize>:
 954:	sub	sp, sp, #0x40
 958:	stp	x29, x30, [sp, #48]
 95c:	add	x29, sp, #0x30
 960:	mov	x8, xzr
 964:	mov	x1, #0x1000000000000       	// #281474976710656
 968:	mov	w9, #0x1                   	// #1
 96c:	stur	x0, [x29, #-8]
 970:	ldur	x10, [x29, #-8]
 974:	ldr	q0, [x10]
 978:	mov	v1.16b, v0.16b
 97c:	mov	d2, v0.d[1]
 980:	fmov	x0, d1
 984:	str	x1, [sp, #24]
 988:	fmov	x1, d2
 98c:	str	x8, [sp, #16]
 990:	str	w9, [sp, #12]
 994:	bl	a6c <rep_clz>
 998:	ldr	x8, [sp, #16]
 99c:	str	w0, [sp, #8]
 9a0:	mov	x0, x8
 9a4:	ldr	x1, [sp, #24]
 9a8:	bl	a6c <rep_clz>
 9ac:	ldr	w9, [sp, #8]
 9b0:	subs	w11, w9, w0
 9b4:	stur	w11, [x29, #-12]
 9b8:	ldur	w11, [x29, #-12]
 9bc:	mov	w8, w11
 9c0:	mov	v0.d[0], x8
 9c4:	ldr	x8, [sp, #16]
 9c8:	mov	v0.d[1], x8
 9cc:	ldur	x10, [x29, #-8]
 9d0:	ldr	q3, [x10]
 9d4:	mov	x12, #0x40                  	// #64
 9d8:	mov	v1.16b, v3.16b
 9dc:	mov	d2, v3.d[1]
 9e0:	fmov	x13, d0
 9e4:	subs	x13, x13, #0x40
 9e8:	fmov	x14, d0
 9ec:	subs	x12, x12, x14
 9f0:	fmov	x14, d0
 9f4:	cmp	x14, #0x40
 9f8:	cset	w11, cc  // cc = lo, ul, last
 9fc:	fmov	x14, d0
 a00:	fmov	x15, d1
 a04:	fmov	x16, d0
 a08:	lsl	x15, x15, x16
 a0c:	fmov	x16, d1
 a10:	lsr	x12, x16, x12
 a14:	fmov	x16, d2
 a18:	fmov	x17, d0
 a1c:	lsl	x16, x16, x17
 a20:	orr	x12, x12, x16
 a24:	fmov	x16, d1
 a28:	lsl	x13, x16, x13
 a2c:	tst	w11, #0x1
 a30:	csel	x15, x15, x8, ne  // ne = any
 a34:	tst	w11, #0x1
 a38:	csel	x12, x12, x13, ne  // ne = any
 a3c:	fmov	x13, d2
 a40:	cmp	x14, #0x0
 a44:	csel	x12, x13, x12, eq  // eq = none
 a48:	mov	v3.d[0], x15
 a4c:	mov	v3.d[1], x12
 a50:	str	q3, [x10]
 a54:	ldur	w11, [x29, #-12]
 a58:	ldr	w18, [sp, #12]
 a5c:	subs	w0, w18, w11
 a60:	ldp	x29, x30, [sp, #48]
 a64:	add	sp, sp, #0x40
 a68:	ret

0000000000000a6c <rep_clz>:
 a6c:	sub	sp, sp, #0x30
 a70:	mov	v0.d[0], x0
 a74:	mov	v0.d[1], x1
 a78:	str	q0, [sp, #32]
 a7c:	ldr	q0, [sp, #32]
 a80:	str	q0, [sp, #16]
 a84:	ldr	x8, [sp, #24]
 a88:	cbz	x8, a9c <rep_clz+0x30>
 a8c:	ldr	x8, [sp, #24]
 a90:	str	x8, [sp, #8]
 a94:	str	xzr, [sp]
 a98:	b	aac <rep_clz+0x40>
 a9c:	ldr	x8, [sp, #16]
 aa0:	str	x8, [sp, #8]
 aa4:	mov	x8, #0x40                  	// #64
 aa8:	str	x8, [sp]
 aac:	ldr	x8, [sp, #8]
 ab0:	clz	x8, x8
 ab4:	lsl	x8, x8, #32
 ab8:	ldr	x9, [sp]
 abc:	add	x8, x9, x8, asr #32
 ac0:	mov	w0, w8
 ac4:	add	sp, sp, #0x30
 ac8:	ret

addvdi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__addvdi3>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	stur	x0, [x29, #-8]
  10:	str	x1, [sp, #16]
  14:	ldur	x8, [x29, #-8]
  18:	ldr	x9, [sp, #16]
  1c:	add	x8, x8, x9
  20:	str	x8, [sp, #8]
  24:	ldr	x8, [sp, #16]
  28:	cmp	x8, #0x0
  2c:	cset	w10, lt  // lt = tstop
  30:	tbnz	w10, #0, 60 <__addvdi3+0x60>
  34:	ldr	x8, [sp, #8]
  38:	ldur	x9, [x29, #-8]
  3c:	cmp	x8, x9
  40:	b.ge	5c <__addvdi3+0x5c>  // b.tcont
  44:	adrp	x0, 0 <__addvdi3>
  48:	add	x0, x0, #0x0
  4c:	mov	w1, #0x17                  	// #23
  50:	adrp	x2, 0 <__addvdi3>
  54:	add	x2, x2, #0x0
  58:	bl	0 <__compilerrt_abort_impl>
  5c:	b	88 <__addvdi3+0x88>
  60:	ldr	x8, [sp, #8]
  64:	ldur	x9, [x29, #-8]
  68:	cmp	x8, x9
  6c:	b.lt	88 <__addvdi3+0x88>  // b.tstop
  70:	adrp	x0, 0 <__addvdi3>
  74:	add	x0, x0, #0x0
  78:	mov	w1, #0x1a                  	// #26
  7c:	adrp	x2, 0 <__addvdi3>
  80:	add	x2, x2, #0x0
  84:	bl	0 <__compilerrt_abort_impl>
  88:	ldr	x0, [sp, #8]
  8c:	ldp	x29, x30, [sp, #32]
  90:	add	sp, sp, #0x30
  94:	ret

addvsi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__addvsi3>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	w0, [x29, #-4]
  10:	str	w1, [sp, #8]
  14:	ldur	w8, [x29, #-4]
  18:	ldr	w9, [sp, #8]
  1c:	add	w8, w8, w9
  20:	str	w8, [sp, #4]
  24:	ldr	w8, [sp, #8]
  28:	cmp	w8, #0x0
  2c:	cset	w8, lt  // lt = tstop
  30:	tbnz	w8, #0, 60 <__addvsi3+0x60>
  34:	ldr	w8, [sp, #4]
  38:	ldur	w9, [x29, #-4]
  3c:	cmp	w8, w9
  40:	b.ge	5c <__addvsi3+0x5c>  // b.tcont
  44:	adrp	x0, 0 <__addvsi3>
  48:	add	x0, x0, #0x0
  4c:	mov	w1, #0x17                  	// #23
  50:	adrp	x2, 0 <__addvsi3>
  54:	add	x2, x2, #0x0
  58:	bl	0 <__compilerrt_abort_impl>
  5c:	b	88 <__addvsi3+0x88>
  60:	ldr	w8, [sp, #4]
  64:	ldur	w9, [x29, #-4]
  68:	cmp	w8, w9
  6c:	b.lt	88 <__addvsi3+0x88>  // b.tstop
  70:	adrp	x0, 0 <__addvsi3>
  74:	add	x0, x0, #0x0
  78:	mov	w1, #0x1a                  	// #26
  7c:	adrp	x2, 0 <__addvsi3>
  80:	add	x2, x2, #0x0
  84:	bl	0 <__compilerrt_abort_impl>
  88:	ldr	w0, [sp, #4]
  8c:	ldp	x29, x30, [sp, #16]
  90:	add	sp, sp, #0x20
  94:	ret

addvti3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__addvti3>:
   0:	sub	sp, sp, #0x40
   4:	stp	x29, x30, [sp, #48]
   8:	add	x29, sp, #0x30
   c:	stur	x1, [x29, #-8]
  10:	stur	x0, [x29, #-16]
  14:	str	x3, [sp, #24]
  18:	str	x2, [sp, #16]
  1c:	ldur	x8, [x29, #-8]
  20:	ldur	x9, [x29, #-16]
  24:	ldr	x10, [sp, #24]
  28:	ldr	x11, [sp, #16]
  2c:	adds	x9, x9, x11
  30:	adcs	x8, x8, x10
  34:	str	x9, [sp]
  38:	str	x8, [sp, #8]
  3c:	ldr	x8, [sp, #24]
  40:	tbnz	x8, #63, 90 <__addvti3+0x90>
  44:	b	48 <__addvti3+0x48>
  48:	ldr	x8, [sp, #8]
  4c:	ldr	x9, [sp]
  50:	ldur	x10, [x29, #-8]
  54:	ldur	x11, [x29, #-16]
  58:	subs	x9, x9, x11
  5c:	cset	w12, cs  // cs = hs, nlast
  60:	subs	x8, x8, x10
  64:	cset	w13, ge  // ge = tcont
  68:	csel	w12, w12, w13, eq  // eq = none
  6c:	tbnz	w12, #0, 8c <__addvti3+0x8c>
  70:	b	74 <__addvti3+0x74>
  74:	adrp	x0, 0 <__addvti3>
  78:	add	x0, x0, #0x0
  7c:	adrp	x2, 0 <__addvti3>
  80:	add	x2, x2, #0x0
  84:	mov	w1, #0x19                  	// #25
  88:	bl	0 <__compilerrt_abort_impl>
  8c:	b	d8 <__addvti3+0xd8>
  90:	ldr	x8, [sp, #8]
  94:	ldr	x9, [sp]
  98:	ldur	x10, [x29, #-8]
  9c:	ldur	x11, [x29, #-16]
  a0:	subs	x9, x9, x11
  a4:	cset	w12, cc  // cc = lo, ul, last
  a8:	subs	x8, x8, x10
  ac:	cset	w13, lt  // lt = tstop
  b0:	csel	w12, w12, w13, eq  // eq = none
  b4:	tbnz	w12, #0, d4 <__addvti3+0xd4>
  b8:	b	bc <__addvti3+0xbc>
  bc:	adrp	x0, 0 <__addvti3>
  c0:	add	x0, x0, #0x0
  c4:	adrp	x2, 0 <__addvti3>
  c8:	add	x2, x2, #0x0
  cc:	mov	w1, #0x1c                  	// #28
  d0:	bl	0 <__compilerrt_abort_impl>
  d4:	b	d8 <__addvti3+0xd8>
  d8:	ldr	x0, [sp]
  dc:	ldr	x1, [sp, #8]
  e0:	ldp	x29, x30, [sp, #48]
  e4:	add	sp, sp, #0x40
  e8:	ret

apple_versioning.c.o:     file format elf64-littleaarch64


ashldi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ashldi3>:
   0:	sub	sp, sp, #0x30
   4:	mov	w8, #0x20                  	// #32
   8:	str	x0, [sp, #32]
   c:	str	w1, [sp, #28]
  10:	str	w8, [sp, #24]
  14:	ldr	x9, [sp, #32]
  18:	str	x9, [sp, #16]
  1c:	ldr	w8, [sp, #28]
  20:	and	w8, w8, #0x20
  24:	cbz	w8, 44 <__ashldi3+0x44>
  28:	str	wzr, [sp, #8]
  2c:	ldr	w8, [sp, #16]
  30:	ldr	w9, [sp, #28]
  34:	subs	w9, w9, #0x20
  38:	lsl	w8, w8, w9
  3c:	str	w8, [sp, #12]
  40:	b	90 <__ashldi3+0x90>
  44:	ldr	w8, [sp, #28]
  48:	cbnz	w8, 58 <__ashldi3+0x58>
  4c:	ldr	x8, [sp, #32]
  50:	str	x8, [sp, #40]
  54:	b	98 <__ashldi3+0x98>
  58:	ldr	w8, [sp, #16]
  5c:	ldr	w9, [sp, #28]
  60:	lsl	w8, w8, w9
  64:	str	w8, [sp, #8]
  68:	ldr	w8, [sp, #20]
  6c:	ldr	w9, [sp, #28]
  70:	lsl	w8, w8, w9
  74:	ldr	w9, [sp, #16]
  78:	ldr	w10, [sp, #28]
  7c:	mov	w11, #0x20                  	// #32
  80:	subs	w10, w11, w10
  84:	lsr	w9, w9, w10
  88:	orr	w8, w8, w9
  8c:	str	w8, [sp, #12]
  90:	ldr	x8, [sp, #8]
  94:	str	x8, [sp, #40]
  98:	ldr	x0, [sp, #40]
  9c:	add	sp, sp, #0x30
  a0:	ret

ashlti3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ashlti3>:
   0:	sub	sp, sp, #0x50
   4:	str	x1, [sp, #56]
   8:	str	x0, [sp, #48]
   c:	str	w2, [sp, #44]
  10:	mov	w8, #0x40                  	// #64
  14:	str	w8, [sp, #40]
  18:	ldr	x9, [sp, #48]
  1c:	ldr	x10, [sp, #56]
  20:	str	x10, [sp, #24]
  24:	str	x9, [sp, #16]
  28:	ldrb	w8, [sp, #44]
  2c:	tbz	w8, #6, 54 <__ashlti3+0x54>
  30:	b	34 <__ashlti3+0x34>
  34:	mov	x8, xzr
  38:	str	x8, [sp]
  3c:	ldr	x8, [sp, #16]
  40:	ldr	w9, [sp, #44]
  44:	mov	w10, w9
  48:	lsl	x8, x8, x10
  4c:	str	x8, [sp, #8]
  50:	b	bc <__ashlti3+0xbc>
  54:	ldr	w8, [sp, #44]
  58:	cbnz	w8, 74 <__ashlti3+0x74>
  5c:	b	60 <__ashlti3+0x60>
  60:	ldr	x8, [sp, #48]
  64:	ldr	x9, [sp, #56]
  68:	str	x9, [sp, #72]
  6c:	str	x8, [sp, #64]
  70:	b	d0 <__ashlti3+0xd0>
  74:	ldr	x8, [sp, #16]
  78:	ldr	w9, [sp, #44]
  7c:	mov	w10, w9
  80:	lsl	x8, x8, x10
  84:	str	x8, [sp]
  88:	ldr	x8, [sp, #24]
  8c:	ldr	w9, [sp, #44]
  90:	mov	w10, w9
  94:	mov	w9, w10
  98:	lsl	x8, x8, x10
  9c:	ldr	x10, [sp, #16]
  a0:	mov	w11, wzr
  a4:	sub	w9, w11, w9
  a8:	mov	w12, w9
  ac:	lsr	x10, x10, x12
  b0:	orr	x8, x8, x10
  b4:	str	x8, [sp, #8]
  b8:	b	bc <__ashlti3+0xbc>
  bc:	ldr	x8, [sp]
  c0:	ldr	x9, [sp, #8]
  c4:	str	x9, [sp, #72]
  c8:	str	x8, [sp, #64]
  cc:	b	d0 <__ashlti3+0xd0>
  d0:	ldr	x0, [sp, #64]
  d4:	ldr	x1, [sp, #72]
  d8:	add	sp, sp, #0x50
  dc:	ret

ashrdi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ashrdi3>:
   0:	sub	sp, sp, #0x30
   4:	mov	w8, #0x20                  	// #32
   8:	str	x0, [sp, #32]
   c:	str	w1, [sp, #28]
  10:	str	w8, [sp, #24]
  14:	ldr	x9, [sp, #32]
  18:	str	x9, [sp, #16]
  1c:	ldr	w8, [sp, #28]
  20:	and	w8, w8, #0x20
  24:	cbz	w8, 4c <__ashrdi3+0x4c>
  28:	ldr	w8, [sp, #20]
  2c:	asr	w8, w8, #31
  30:	str	w8, [sp, #12]
  34:	ldr	w8, [sp, #20]
  38:	ldr	w9, [sp, #28]
  3c:	subs	w9, w9, #0x20
  40:	asr	w8, w8, w9
  44:	str	w8, [sp, #8]
  48:	b	98 <__ashrdi3+0x98>
  4c:	ldr	w8, [sp, #28]
  50:	cbnz	w8, 60 <__ashrdi3+0x60>
  54:	ldr	x8, [sp, #32]
  58:	str	x8, [sp, #40]
  5c:	b	a0 <__ashrdi3+0xa0>
  60:	ldr	w8, [sp, #20]
  64:	ldr	w9, [sp, #28]
  68:	asr	w8, w8, w9
  6c:	str	w8, [sp, #12]
  70:	ldr	w8, [sp, #20]
  74:	ldr	w9, [sp, #28]
  78:	mov	w10, #0x20                  	// #32
  7c:	subs	w9, w10, w9
  80:	lsl	w8, w8, w9
  84:	ldr	w9, [sp, #16]
  88:	ldr	w10, [sp, #28]
  8c:	lsr	w9, w9, w10
  90:	orr	w8, w8, w9
  94:	str	w8, [sp, #8]
  98:	ldr	x8, [sp, #8]
  9c:	str	x8, [sp, #40]
  a0:	ldr	x0, [sp, #40]
  a4:	add	sp, sp, #0x30
  a8:	ret

ashrti3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ashrti3>:
   0:	sub	sp, sp, #0x50
   4:	str	x1, [sp, #56]
   8:	str	x0, [sp, #48]
   c:	str	w2, [sp, #44]
  10:	mov	w8, #0x40                  	// #64
  14:	str	w8, [sp, #40]
  18:	ldr	x9, [sp, #48]
  1c:	ldr	x10, [sp, #56]
  20:	str	x10, [sp, #24]
  24:	str	x9, [sp, #16]
  28:	ldrb	w8, [sp, #44]
  2c:	tbz	w8, #6, 58 <__ashrti3+0x58>
  30:	b	34 <__ashrti3+0x34>
  34:	ldr	x8, [sp, #24]
  38:	asr	x8, x8, #63
  3c:	str	x8, [sp, #8]
  40:	ldr	x8, [sp, #24]
  44:	ldr	w9, [sp, #44]
  48:	mov	w10, w9
  4c:	asr	x8, x8, x10
  50:	str	x8, [sp]
  54:	b	c0 <__ashrti3+0xc0>
  58:	ldr	w8, [sp, #44]
  5c:	cbnz	w8, 78 <__ashrti3+0x78>
  60:	b	64 <__ashrti3+0x64>
  64:	ldr	x8, [sp, #48]
  68:	ldr	x9, [sp, #56]
  6c:	str	x9, [sp, #72]
  70:	str	x8, [sp, #64]
  74:	b	d4 <__ashrti3+0xd4>
  78:	ldr	x8, [sp, #24]
  7c:	ldr	w9, [sp, #44]
  80:	mov	w10, w9
  84:	asr	x8, x8, x10
  88:	str	x8, [sp, #8]
  8c:	ldr	x8, [sp, #24]
  90:	ldr	w9, [sp, #44]
  94:	mov	w10, w9
  98:	mov	w9, w10
  9c:	mov	w11, wzr
  a0:	sub	w9, w11, w9
  a4:	mov	w12, w9
  a8:	lsl	x8, x8, x12
  ac:	ldr	x12, [sp, #16]
  b0:	lsr	x10, x12, x10
  b4:	orr	x8, x8, x10
  b8:	str	x8, [sp]
  bc:	b	c0 <__ashrti3+0xc0>
  c0:	ldr	x8, [sp]
  c4:	ldr	x9, [sp, #8]
  c8:	str	x9, [sp, #72]
  cc:	str	x8, [sp, #64]
  d0:	b	d4 <__ashrti3+0xd4>
  d4:	ldr	x0, [sp, #64]
  d8:	ldr	x1, [sp, #72]
  dc:	add	sp, sp, #0x50
  e0:	ret

bswapdi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__bswapdi2>:
   0:	sub	sp, sp, #0x10
   4:	str	x0, [sp, #8]
   8:	ldr	x8, [sp, #8]
   c:	and	x8, x8, #0xff00000000000000
  10:	ldr	x9, [sp, #8]
  14:	and	x9, x9, #0xff000000000000
  18:	lsr	x9, x9, #40
  1c:	orr	x8, x9, x8, lsr #56
  20:	ldr	x9, [sp, #8]
  24:	and	x9, x9, #0xff0000000000
  28:	orr	x8, x8, x9, lsr #24
  2c:	ldr	x9, [sp, #8]
  30:	and	x9, x9, #0xff00000000
  34:	orr	x8, x8, x9, lsr #8
  38:	ldr	x9, [sp, #8]
  3c:	and	x9, x9, #0xff000000
  40:	orr	x8, x8, x9, lsl #8
  44:	ldr	x9, [sp, #8]
  48:	and	x9, x9, #0xff0000
  4c:	orr	x8, x8, x9, lsl #24
  50:	ldr	x9, [sp, #8]
  54:	and	x9, x9, #0xff00
  58:	orr	x8, x8, x9, lsl #40
  5c:	ldr	x9, [sp, #8]
  60:	and	x9, x9, #0xff
  64:	orr	x0, x8, x9, lsl #56
  68:	add	sp, sp, #0x10
  6c:	ret

bswapsi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__bswapsi2>:
   0:	sub	sp, sp, #0x10
   4:	str	w0, [sp, #12]
   8:	ldr	w8, [sp, #12]
   c:	and	w8, w8, #0xff000000
  10:	ldr	w9, [sp, #12]
  14:	and	w9, w9, #0xff0000
  18:	lsr	w9, w9, #8
  1c:	orr	w8, w9, w8, lsr #24
  20:	ldr	w9, [sp, #12]
  24:	and	w9, w9, #0xff00
  28:	orr	w8, w8, w9, lsl #8
  2c:	ldr	w9, [sp, #12]
  30:	and	w9, w9, #0xff
  34:	orr	w0, w8, w9, lsl #24
  38:	add	sp, sp, #0x10
  3c:	ret

clzdi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__clzdi2>:
   0:	sub	sp, sp, #0x20
   4:	mov	w8, wzr
   8:	str	x0, [sp, #24]
   c:	ldr	x9, [sp, #24]
  10:	str	x9, [sp, #16]
  14:	ldr	w10, [sp, #20]
  18:	cmp	w10, #0x0
  1c:	cset	w10, eq  // eq = none
  20:	and	w10, w10, #0x1
  24:	subs	w8, w8, w10
  28:	str	w8, [sp, #12]
  2c:	ldr	w8, [sp, #20]
  30:	ldr	w10, [sp, #12]
  34:	bic	w8, w8, w10
  38:	ldr	w10, [sp, #16]
  3c:	ldr	w11, [sp, #12]
  40:	and	w10, w10, w11
  44:	orr	w8, w8, w10
  48:	clz	w8, w8
  4c:	ldr	w10, [sp, #12]
  50:	and	w10, w10, #0x20
  54:	add	w0, w8, w10
  58:	add	sp, sp, #0x20
  5c:	ret

clzsi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__clzsi2>:
   0:	sub	sp, sp, #0x10
   4:	mov	w8, #0xffff0000            	// #-65536
   8:	mov	w9, wzr
   c:	mov	w10, #0x4                   	// #4
  10:	mov	w11, #0x10                  	// #16
  14:	mov	w12, #0x8                   	// #8
  18:	mov	w13, #0x2                   	// #2
  1c:	str	w0, [sp, #12]
  20:	ldr	w14, [sp, #12]
  24:	str	w14, [sp, #8]
  28:	ldr	w14, [sp, #8]
  2c:	tst	w14, w8
  30:	cset	w8, eq  // eq = none
  34:	and	w8, w8, #0x1
  38:	lsl	w8, w8, #4
  3c:	str	w8, [sp, #4]
  40:	ldr	w8, [sp, #4]
  44:	subs	w8, w11, w8
  48:	ldr	w11, [sp, #8]
  4c:	lsr	w8, w11, w8
  50:	str	w8, [sp, #8]
  54:	ldr	w8, [sp, #4]
  58:	str	w8, [sp]
  5c:	ldr	w8, [sp, #8]
  60:	tst	w8, #0xff00
  64:	cset	w8, eq  // eq = none
  68:	and	w8, w8, #0x1
  6c:	lsl	w8, w8, #3
  70:	str	w8, [sp, #4]
  74:	ldr	w8, [sp, #4]
  78:	subs	w8, w12, w8
  7c:	ldr	w11, [sp, #8]
  80:	lsr	w8, w11, w8
  84:	str	w8, [sp, #8]
  88:	ldr	w8, [sp, #4]
  8c:	ldr	w11, [sp]
  90:	add	w8, w11, w8
  94:	str	w8, [sp]
  98:	ldr	w8, [sp, #8]
  9c:	tst	w8, #0xf0
  a0:	cset	w8, eq  // eq = none
  a4:	and	w8, w8, #0x1
  a8:	lsl	w8, w8, #2
  ac:	str	w8, [sp, #4]
  b0:	ldr	w8, [sp, #4]
  b4:	subs	w8, w10, w8
  b8:	ldr	w10, [sp, #8]
  bc:	lsr	w8, w10, w8
  c0:	str	w8, [sp, #8]
  c4:	ldr	w8, [sp, #4]
  c8:	ldr	w10, [sp]
  cc:	add	w8, w10, w8
  d0:	str	w8, [sp]
  d4:	ldr	w8, [sp, #8]
  d8:	tst	w8, #0xc
  dc:	cset	w8, eq  // eq = none
  e0:	and	w8, w8, #0x1
  e4:	lsl	w8, w8, #1
  e8:	str	w8, [sp, #4]
  ec:	ldr	w8, [sp, #4]
  f0:	subs	w8, w13, w8
  f4:	ldr	w10, [sp, #8]
  f8:	lsr	w8, w10, w8
  fc:	str	w8, [sp, #8]
 100:	ldr	w8, [sp, #4]
 104:	ldr	w10, [sp]
 108:	add	w8, w10, w8
 10c:	str	w8, [sp]
 110:	ldr	w8, [sp]
 114:	ldr	w10, [sp, #8]
 118:	subs	w10, w13, w10
 11c:	ldr	w11, [sp, #8]
 120:	tst	w11, #0x2
 124:	cset	w11, eq  // eq = none
 128:	and	w11, w11, #0x1
 12c:	subs	w9, w9, w11
 130:	and	w9, w10, w9
 134:	add	w0, w8, w9
 138:	add	sp, sp, #0x10
 13c:	ret

clzti2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__clzti2>:
   0:	sub	sp, sp, #0x30
   4:	mov	v0.d[0], x0
   8:	mov	v0.d[1], x1
   c:	mov	w8, wzr
  10:	str	q0, [sp, #32]
  14:	ldr	q0, [sp, #32]
  18:	str	q0, [sp, #16]
  1c:	ldr	x9, [sp, #24]
  20:	cmp	x9, #0x0
  24:	cset	w10, eq  // eq = none
  28:	and	w10, w10, #0x1
  2c:	subs	w8, w8, w10
  30:	mov	w0, w8
  34:	sxtw	x9, w0
  38:	str	x9, [sp, #8]
  3c:	ldr	x9, [sp, #24]
  40:	ldr	x11, [sp, #8]
  44:	bic	x9, x9, x11
  48:	ldr	x11, [sp, #16]
  4c:	ldr	x12, [sp, #8]
  50:	and	x11, x11, x12
  54:	orr	x9, x9, x11
  58:	clz	x9, x9
  5c:	ldr	x11, [sp, #8]
  60:	and	w8, w11, #0x40
  64:	add	w0, w9, w8
  68:	add	sp, sp, #0x30
  6c:	ret

cmpdi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__cmpdi2>:
   0:	sub	sp, sp, #0x30
   4:	str	x0, [sp, #32]
   8:	str	x1, [sp, #24]
   c:	ldr	x8, [sp, #32]
  10:	str	x8, [sp, #16]
  14:	ldr	x8, [sp, #24]
  18:	str	x8, [sp, #8]
  1c:	ldr	w9, [sp, #20]
  20:	ldr	w10, [sp, #12]
  24:	cmp	w9, w10
  28:	b.ge	34 <__cmpdi2+0x34>  // b.tcont
  2c:	str	wzr, [sp, #44]
  30:	b	8c <__cmpdi2+0x8c>
  34:	ldr	w8, [sp, #20]
  38:	ldr	w9, [sp, #12]
  3c:	cmp	w8, w9
  40:	b.le	50 <__cmpdi2+0x50>
  44:	mov	w8, #0x2                   	// #2
  48:	str	w8, [sp, #44]
  4c:	b	8c <__cmpdi2+0x8c>
  50:	ldr	w8, [sp, #16]
  54:	ldr	w9, [sp, #8]
  58:	cmp	w8, w9
  5c:	b.cs	68 <__cmpdi2+0x68>  // b.hs, b.nlast
  60:	str	wzr, [sp, #44]
  64:	b	8c <__cmpdi2+0x8c>
  68:	ldr	w8, [sp, #16]
  6c:	ldr	w9, [sp, #8]
  70:	cmp	w8, w9
  74:	b.ls	84 <__cmpdi2+0x84>  // b.plast
  78:	mov	w8, #0x2                   	// #2
  7c:	str	w8, [sp, #44]
  80:	b	8c <__cmpdi2+0x8c>
  84:	mov	w8, #0x1                   	// #1
  88:	str	w8, [sp, #44]
  8c:	ldr	w0, [sp, #44]
  90:	add	sp, sp, #0x30
  94:	ret

cmpti2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__cmpti2>:
   0:	sub	sp, sp, #0x50
   4:	mov	v0.d[0], x0
   8:	mov	v0.d[1], x1
   c:	mov	v1.d[0], x2
  10:	mov	v1.d[1], x3
  14:	str	q0, [sp, #48]
  18:	str	q1, [sp, #32]
  1c:	ldr	q0, [sp, #48]
  20:	str	q0, [sp, #16]
  24:	ldr	q0, [sp, #32]
  28:	str	q0, [sp]
  2c:	ldr	x8, [sp, #24]
  30:	ldr	x9, [sp, #8]
  34:	cmp	x8, x9
  38:	b.ge	44 <__cmpti2+0x44>  // b.tcont
  3c:	str	wzr, [sp, #76]
  40:	b	9c <__cmpti2+0x9c>
  44:	ldr	x8, [sp, #24]
  48:	ldr	x9, [sp, #8]
  4c:	cmp	x8, x9
  50:	b.le	60 <__cmpti2+0x60>
  54:	mov	w8, #0x2                   	// #2
  58:	str	w8, [sp, #76]
  5c:	b	9c <__cmpti2+0x9c>
  60:	ldr	x8, [sp, #16]
  64:	ldr	x9, [sp]
  68:	cmp	x8, x9
  6c:	b.cs	78 <__cmpti2+0x78>  // b.hs, b.nlast
  70:	str	wzr, [sp, #76]
  74:	b	9c <__cmpti2+0x9c>
  78:	ldr	x8, [sp, #16]
  7c:	ldr	x9, [sp]
  80:	cmp	x8, x9
  84:	b.ls	94 <__cmpti2+0x94>  // b.plast
  88:	mov	w8, #0x2                   	// #2
  8c:	str	w8, [sp, #76]
  90:	b	9c <__cmpti2+0x9c>
  94:	mov	w8, #0x1                   	// #1
  98:	str	w8, [sp, #76]
  9c:	ldr	w0, [sp, #76]
  a0:	add	sp, sp, #0x50
  a4:	ret

comparedf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__cmpdf2>:
   0:	sub	sp, sp, #0x50
   4:	stp	x29, x30, [sp, #64]
   8:	add	x29, sp, #0x40
   c:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
  10:	stur	d0, [x29, #-16]
  14:	stur	d1, [x29, #-24]
  18:	ldur	d0, [x29, #-16]
  1c:	str	x8, [sp]
  20:	bl	130 <toRep>
  24:	str	x0, [sp, #32]
  28:	ldur	d0, [x29, #-24]
  2c:	bl	130 <toRep>
  30:	str	x0, [sp, #24]
  34:	ldr	x8, [sp, #32]
  38:	and	x8, x8, #0x7fffffffffffffff
  3c:	str	x8, [sp, #16]
  40:	ldr	x8, [sp, #24]
  44:	and	x8, x8, #0x7fffffffffffffff
  48:	str	x8, [sp, #8]
  4c:	ldr	x8, [sp, #16]
  50:	ldr	x9, [sp]
  54:	cmp	x8, x9
  58:	b.hi	6c <__cmpdf2+0x6c>  // b.pmore
  5c:	ldr	x8, [sp, #8]
  60:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
  64:	cmp	x8, x9
  68:	b.ls	78 <__cmpdf2+0x78>  // b.plast
  6c:	mov	w8, #0x1                   	// #1
  70:	stur	w8, [x29, #-4]
  74:	b	120 <__cmpdf2+0x120>
  78:	ldr	x8, [sp, #16]
  7c:	ldr	x9, [sp, #8]
  80:	orr	x8, x8, x9
  84:	cbnz	x8, 90 <__cmpdf2+0x90>
  88:	stur	wzr, [x29, #-4]
  8c:	b	120 <__cmpdf2+0x120>
  90:	ldr	x8, [sp, #32]
  94:	ldr	x9, [sp, #24]
  98:	tst	x8, x9
  9c:	cset	w10, lt  // lt = tstop
  a0:	tbnz	w10, #0, e4 <__cmpdf2+0xe4>
  a4:	ldr	x8, [sp, #32]
  a8:	ldr	x9, [sp, #24]
  ac:	cmp	x8, x9
  b0:	b.ge	c0 <__cmpdf2+0xc0>  // b.tcont
  b4:	mov	w8, #0xffffffff            	// #-1
  b8:	stur	w8, [x29, #-4]
  bc:	b	120 <__cmpdf2+0x120>
  c0:	ldr	x8, [sp, #32]
  c4:	ldr	x9, [sp, #24]
  c8:	cmp	x8, x9
  cc:	b.ne	d8 <__cmpdf2+0xd8>  // b.any
  d0:	stur	wzr, [x29, #-4]
  d4:	b	120 <__cmpdf2+0x120>
  d8:	mov	w8, #0x1                   	// #1
  dc:	stur	w8, [x29, #-4]
  e0:	b	120 <__cmpdf2+0x120>
  e4:	ldr	x8, [sp, #32]
  e8:	ldr	x9, [sp, #24]
  ec:	cmp	x8, x9
  f0:	b.le	100 <__cmpdf2+0x100>
  f4:	mov	w8, #0xffffffff            	// #-1
  f8:	stur	w8, [x29, #-4]
  fc:	b	120 <__cmpdf2+0x120>
 100:	ldr	x8, [sp, #32]
 104:	ldr	x9, [sp, #24]
 108:	cmp	x8, x9
 10c:	b.ne	118 <__cmpdf2+0x118>  // b.any
 110:	stur	wzr, [x29, #-4]
 114:	b	120 <__cmpdf2+0x120>
 118:	mov	w8, #0x1                   	// #1
 11c:	stur	w8, [x29, #-4]
 120:	ldur	w0, [x29, #-4]
 124:	ldp	x29, x30, [sp, #64]
 128:	add	sp, sp, #0x50
 12c:	ret

0000000000000130 <toRep>:
 130:	sub	sp, sp, #0x10
 134:	str	d0, [sp, #8]
 138:	ldr	x8, [sp, #8]
 13c:	str	x8, [sp]
 140:	ldr	x0, [sp]
 144:	add	sp, sp, #0x10
 148:	ret

000000000000014c <__gedf2>:
 14c:	sub	sp, sp, #0x50
 150:	stp	x29, x30, [sp, #64]
 154:	add	x29, sp, #0x40
 158:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 15c:	stur	d0, [x29, #-16]
 160:	stur	d1, [x29, #-24]
 164:	ldur	d0, [x29, #-16]
 168:	str	x8, [sp]
 16c:	bl	130 <toRep>
 170:	str	x0, [sp, #32]
 174:	ldur	d0, [x29, #-24]
 178:	bl	130 <toRep>
 17c:	str	x0, [sp, #24]
 180:	ldr	x8, [sp, #32]
 184:	and	x8, x8, #0x7fffffffffffffff
 188:	str	x8, [sp, #16]
 18c:	ldr	x8, [sp, #24]
 190:	and	x8, x8, #0x7fffffffffffffff
 194:	str	x8, [sp, #8]
 198:	ldr	x8, [sp, #16]
 19c:	ldr	x9, [sp]
 1a0:	cmp	x8, x9
 1a4:	b.hi	1b8 <__gedf2+0x6c>  // b.pmore
 1a8:	ldr	x8, [sp, #8]
 1ac:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 1b0:	cmp	x8, x9
 1b4:	b.ls	1c4 <__gedf2+0x78>  // b.plast
 1b8:	mov	w8, #0xffffffff            	// #-1
 1bc:	stur	w8, [x29, #-4]
 1c0:	b	26c <__gedf2+0x120>
 1c4:	ldr	x8, [sp, #16]
 1c8:	ldr	x9, [sp, #8]
 1cc:	orr	x8, x8, x9
 1d0:	cbnz	x8, 1dc <__gedf2+0x90>
 1d4:	stur	wzr, [x29, #-4]
 1d8:	b	26c <__gedf2+0x120>
 1dc:	ldr	x8, [sp, #32]
 1e0:	ldr	x9, [sp, #24]
 1e4:	tst	x8, x9
 1e8:	cset	w10, lt  // lt = tstop
 1ec:	tbnz	w10, #0, 230 <__gedf2+0xe4>
 1f0:	ldr	x8, [sp, #32]
 1f4:	ldr	x9, [sp, #24]
 1f8:	cmp	x8, x9
 1fc:	b.ge	20c <__gedf2+0xc0>  // b.tcont
 200:	mov	w8, #0xffffffff            	// #-1
 204:	stur	w8, [x29, #-4]
 208:	b	26c <__gedf2+0x120>
 20c:	ldr	x8, [sp, #32]
 210:	ldr	x9, [sp, #24]
 214:	cmp	x8, x9
 218:	b.ne	224 <__gedf2+0xd8>  // b.any
 21c:	stur	wzr, [x29, #-4]
 220:	b	26c <__gedf2+0x120>
 224:	mov	w8, #0x1                   	// #1
 228:	stur	w8, [x29, #-4]
 22c:	b	26c <__gedf2+0x120>
 230:	ldr	x8, [sp, #32]
 234:	ldr	x9, [sp, #24]
 238:	cmp	x8, x9
 23c:	b.le	24c <__gedf2+0x100>
 240:	mov	w8, #0xffffffff            	// #-1
 244:	stur	w8, [x29, #-4]
 248:	b	26c <__gedf2+0x120>
 24c:	ldr	x8, [sp, #32]
 250:	ldr	x9, [sp, #24]
 254:	cmp	x8, x9
 258:	b.ne	264 <__gedf2+0x118>  // b.any
 25c:	stur	wzr, [x29, #-4]
 260:	b	26c <__gedf2+0x120>
 264:	mov	w8, #0x1                   	// #1
 268:	stur	w8, [x29, #-4]
 26c:	ldur	w0, [x29, #-4]
 270:	ldp	x29, x30, [sp, #64]
 274:	add	sp, sp, #0x50
 278:	ret

000000000000027c <__unorddf2>:
 27c:	sub	sp, sp, #0x40
 280:	stp	x29, x30, [sp, #48]
 284:	add	x29, sp, #0x30
 288:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 28c:	stur	d0, [x29, #-8]
 290:	stur	d1, [x29, #-16]
 294:	ldur	d0, [x29, #-8]
 298:	str	x8, [sp, #8]
 29c:	bl	130 <toRep>
 2a0:	and	x8, x0, #0x7fffffffffffffff
 2a4:	str	x8, [sp, #24]
 2a8:	ldur	d0, [x29, #-16]
 2ac:	bl	130 <toRep>
 2b0:	and	x8, x0, #0x7fffffffffffffff
 2b4:	str	x8, [sp, #16]
 2b8:	ldr	x8, [sp, #24]
 2bc:	mov	w9, #0x1                   	// #1
 2c0:	ldr	x10, [sp, #8]
 2c4:	cmp	x8, x10
 2c8:	str	w9, [sp, #4]
 2cc:	b.hi	2e4 <__unorddf2+0x68>  // b.pmore
 2d0:	ldr	x8, [sp, #16]
 2d4:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 2d8:	cmp	x8, x9
 2dc:	cset	w10, hi  // hi = pmore
 2e0:	str	w10, [sp, #4]
 2e4:	ldr	w8, [sp, #4]
 2e8:	and	w0, w8, #0x1
 2ec:	ldp	x29, x30, [sp, #48]
 2f0:	add	sp, sp, #0x40
 2f4:	ret

comparesf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__cmpsf2>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	mov	w8, #0x7f800000            	// #2139095040
  10:	stur	s0, [x29, #-8]
  14:	stur	s1, [x29, #-12]
  18:	ldur	s0, [x29, #-8]
  1c:	str	w8, [sp]
  20:	bl	130 <toRep>
  24:	str	w0, [sp, #16]
  28:	ldur	s0, [x29, #-12]
  2c:	bl	130 <toRep>
  30:	str	w0, [sp, #12]
  34:	ldr	w8, [sp, #16]
  38:	and	w8, w8, #0x7fffffff
  3c:	str	w8, [sp, #8]
  40:	ldr	w8, [sp, #12]
  44:	and	w8, w8, #0x7fffffff
  48:	str	w8, [sp, #4]
  4c:	ldr	w8, [sp, #8]
  50:	ldr	w9, [sp]
  54:	cmp	w8, w9
  58:	b.hi	6c <__cmpsf2+0x6c>  // b.pmore
  5c:	ldr	w8, [sp, #4]
  60:	mov	w9, #0x7f800000            	// #2139095040
  64:	cmp	w8, w9
  68:	b.ls	78 <__cmpsf2+0x78>  // b.plast
  6c:	mov	w8, #0x1                   	// #1
  70:	stur	w8, [x29, #-4]
  74:	b	120 <__cmpsf2+0x120>
  78:	ldr	w8, [sp, #8]
  7c:	ldr	w9, [sp, #4]
  80:	orr	w8, w8, w9
  84:	cbnz	w8, 90 <__cmpsf2+0x90>
  88:	stur	wzr, [x29, #-4]
  8c:	b	120 <__cmpsf2+0x120>
  90:	ldr	w8, [sp, #16]
  94:	ldr	w9, [sp, #12]
  98:	tst	w8, w9
  9c:	cset	w8, lt  // lt = tstop
  a0:	tbnz	w8, #0, e4 <__cmpsf2+0xe4>
  a4:	ldr	w8, [sp, #16]
  a8:	ldr	w9, [sp, #12]
  ac:	cmp	w8, w9
  b0:	b.ge	c0 <__cmpsf2+0xc0>  // b.tcont
  b4:	mov	w8, #0xffffffff            	// #-1
  b8:	stur	w8, [x29, #-4]
  bc:	b	120 <__cmpsf2+0x120>
  c0:	ldr	w8, [sp, #16]
  c4:	ldr	w9, [sp, #12]
  c8:	cmp	w8, w9
  cc:	b.ne	d8 <__cmpsf2+0xd8>  // b.any
  d0:	stur	wzr, [x29, #-4]
  d4:	b	120 <__cmpsf2+0x120>
  d8:	mov	w8, #0x1                   	// #1
  dc:	stur	w8, [x29, #-4]
  e0:	b	120 <__cmpsf2+0x120>
  e4:	ldr	w8, [sp, #16]
  e8:	ldr	w9, [sp, #12]
  ec:	cmp	w8, w9
  f0:	b.le	100 <__cmpsf2+0x100>
  f4:	mov	w8, #0xffffffff            	// #-1
  f8:	stur	w8, [x29, #-4]
  fc:	b	120 <__cmpsf2+0x120>
 100:	ldr	w8, [sp, #16]
 104:	ldr	w9, [sp, #12]
 108:	cmp	w8, w9
 10c:	b.ne	118 <__cmpsf2+0x118>  // b.any
 110:	stur	wzr, [x29, #-4]
 114:	b	120 <__cmpsf2+0x120>
 118:	mov	w8, #0x1                   	// #1
 11c:	stur	w8, [x29, #-4]
 120:	ldur	w0, [x29, #-4]
 124:	ldp	x29, x30, [sp, #32]
 128:	add	sp, sp, #0x30
 12c:	ret

0000000000000130 <toRep>:
 130:	sub	sp, sp, #0x10
 134:	str	s0, [sp, #12]
 138:	ldr	w8, [sp, #12]
 13c:	str	w8, [sp, #8]
 140:	ldr	w0, [sp, #8]
 144:	add	sp, sp, #0x10
 148:	ret

000000000000014c <__gesf2>:
 14c:	sub	sp, sp, #0x30
 150:	stp	x29, x30, [sp, #32]
 154:	add	x29, sp, #0x20
 158:	mov	w8, #0x7f800000            	// #2139095040
 15c:	stur	s0, [x29, #-8]
 160:	stur	s1, [x29, #-12]
 164:	ldur	s0, [x29, #-8]
 168:	str	w8, [sp]
 16c:	bl	130 <toRep>
 170:	str	w0, [sp, #16]
 174:	ldur	s0, [x29, #-12]
 178:	bl	130 <toRep>
 17c:	str	w0, [sp, #12]
 180:	ldr	w8, [sp, #16]
 184:	and	w8, w8, #0x7fffffff
 188:	str	w8, [sp, #8]
 18c:	ldr	w8, [sp, #12]
 190:	and	w8, w8, #0x7fffffff
 194:	str	w8, [sp, #4]
 198:	ldr	w8, [sp, #8]
 19c:	ldr	w9, [sp]
 1a0:	cmp	w8, w9
 1a4:	b.hi	1b8 <__gesf2+0x6c>  // b.pmore
 1a8:	ldr	w8, [sp, #4]
 1ac:	mov	w9, #0x7f800000            	// #2139095040
 1b0:	cmp	w8, w9
 1b4:	b.ls	1c4 <__gesf2+0x78>  // b.plast
 1b8:	mov	w8, #0xffffffff            	// #-1
 1bc:	stur	w8, [x29, #-4]
 1c0:	b	26c <__gesf2+0x120>
 1c4:	ldr	w8, [sp, #8]
 1c8:	ldr	w9, [sp, #4]
 1cc:	orr	w8, w8, w9
 1d0:	cbnz	w8, 1dc <__gesf2+0x90>
 1d4:	stur	wzr, [x29, #-4]
 1d8:	b	26c <__gesf2+0x120>
 1dc:	ldr	w8, [sp, #16]
 1e0:	ldr	w9, [sp, #12]
 1e4:	tst	w8, w9
 1e8:	cset	w8, lt  // lt = tstop
 1ec:	tbnz	w8, #0, 230 <__gesf2+0xe4>
 1f0:	ldr	w8, [sp, #16]
 1f4:	ldr	w9, [sp, #12]
 1f8:	cmp	w8, w9
 1fc:	b.ge	20c <__gesf2+0xc0>  // b.tcont
 200:	mov	w8, #0xffffffff            	// #-1
 204:	stur	w8, [x29, #-4]
 208:	b	26c <__gesf2+0x120>
 20c:	ldr	w8, [sp, #16]
 210:	ldr	w9, [sp, #12]
 214:	cmp	w8, w9
 218:	b.ne	224 <__gesf2+0xd8>  // b.any
 21c:	stur	wzr, [x29, #-4]
 220:	b	26c <__gesf2+0x120>
 224:	mov	w8, #0x1                   	// #1
 228:	stur	w8, [x29, #-4]
 22c:	b	26c <__gesf2+0x120>
 230:	ldr	w8, [sp, #16]
 234:	ldr	w9, [sp, #12]
 238:	cmp	w8, w9
 23c:	b.le	24c <__gesf2+0x100>
 240:	mov	w8, #0xffffffff            	// #-1
 244:	stur	w8, [x29, #-4]
 248:	b	26c <__gesf2+0x120>
 24c:	ldr	w8, [sp, #16]
 250:	ldr	w9, [sp, #12]
 254:	cmp	w8, w9
 258:	b.ne	264 <__gesf2+0x118>  // b.any
 25c:	stur	wzr, [x29, #-4]
 260:	b	26c <__gesf2+0x120>
 264:	mov	w8, #0x1                   	// #1
 268:	stur	w8, [x29, #-4]
 26c:	ldur	w0, [x29, #-4]
 270:	ldp	x29, x30, [sp, #32]
 274:	add	sp, sp, #0x30
 278:	ret

000000000000027c <__unordsf2>:
 27c:	sub	sp, sp, #0x30
 280:	stp	x29, x30, [sp, #32]
 284:	add	x29, sp, #0x20
 288:	mov	w8, #0x7f800000            	// #2139095040
 28c:	stur	s0, [x29, #-4]
 290:	stur	s1, [x29, #-8]
 294:	ldur	s0, [x29, #-4]
 298:	str	w8, [sp, #12]
 29c:	bl	130 <toRep>
 2a0:	and	w8, w0, #0x7fffffff
 2a4:	stur	w8, [x29, #-12]
 2a8:	ldur	s0, [x29, #-8]
 2ac:	bl	130 <toRep>
 2b0:	and	w8, w0, #0x7fffffff
 2b4:	str	w8, [sp, #16]
 2b8:	ldur	w8, [x29, #-12]
 2bc:	mov	w9, #0x1                   	// #1
 2c0:	ldr	w10, [sp, #12]
 2c4:	cmp	w8, w10
 2c8:	str	w9, [sp, #8]
 2cc:	b.hi	2e4 <__unordsf2+0x68>  // b.pmore
 2d0:	ldr	w8, [sp, #16]
 2d4:	mov	w9, #0x7f800000            	// #2139095040
 2d8:	cmp	w8, w9
 2dc:	cset	w8, hi  // hi = pmore
 2e0:	str	w8, [sp, #8]
 2e4:	ldr	w8, [sp, #8]
 2e8:	and	w0, w8, #0x1
 2ec:	ldp	x29, x30, [sp, #32]
 2f0:	add	sp, sp, #0x30
 2f4:	ret

ctzdi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ctzdi2>:
   0:	sub	sp, sp, #0x20
   4:	str	x0, [sp, #24]
   8:	ldr	x8, [sp, #24]
   c:	str	x8, [sp, #16]
  10:	ldr	w9, [sp, #16]
  14:	subs	w9, w9, #0x0
  18:	cset	w10, eq  // eq = none
  1c:	mov	w11, wzr
  20:	subs	w10, w11, w10
  24:	str	w10, [sp, #12]
  28:	ldr	w10, [sp, #20]
  2c:	ldr	w11, [sp, #12]
  30:	and	w10, w10, w11
  34:	ldr	w12, [sp, #16]
  38:	bic	w12, w12, w11
  3c:	orr	w10, w10, w12
  40:	rbit	w10, w10
  44:	clz	w10, w10
  48:	and	w11, w11, #0x20
  4c:	add	w0, w10, w11
  50:	add	sp, sp, #0x20
  54:	ret

ctzsi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ctzsi2>:
   0:	sub	sp, sp, #0x10
   4:	mov	w8, wzr
   8:	mov	w9, #0x2                   	// #2
   c:	str	w0, [sp, #12]
  10:	ldr	w10, [sp, #12]
  14:	str	w10, [sp, #8]
  18:	ldr	w10, [sp, #8]
  1c:	tst	w10, #0xffff
  20:	cset	w10, eq  // eq = none
  24:	and	w10, w10, #0x1
  28:	lsl	w10, w10, #4
  2c:	str	w10, [sp, #4]
  30:	ldr	w10, [sp, #4]
  34:	ldr	w11, [sp, #8]
  38:	lsr	w10, w11, w10
  3c:	str	w10, [sp, #8]
  40:	ldr	w10, [sp, #4]
  44:	str	w10, [sp]
  48:	ldr	w10, [sp, #8]
  4c:	tst	w10, #0xff
  50:	cset	w10, eq  // eq = none
  54:	and	w10, w10, #0x1
  58:	lsl	w10, w10, #3
  5c:	str	w10, [sp, #4]
  60:	ldr	w10, [sp, #4]
  64:	ldr	w11, [sp, #8]
  68:	lsr	w10, w11, w10
  6c:	str	w10, [sp, #8]
  70:	ldr	w10, [sp, #4]
  74:	ldr	w11, [sp]
  78:	add	w10, w11, w10
  7c:	str	w10, [sp]
  80:	ldr	w10, [sp, #8]
  84:	tst	w10, #0xf
  88:	cset	w10, eq  // eq = none
  8c:	and	w10, w10, #0x1
  90:	lsl	w10, w10, #2
  94:	str	w10, [sp, #4]
  98:	ldr	w10, [sp, #4]
  9c:	ldr	w11, [sp, #8]
  a0:	lsr	w10, w11, w10
  a4:	str	w10, [sp, #8]
  a8:	ldr	w10, [sp, #4]
  ac:	ldr	w11, [sp]
  b0:	add	w10, w11, w10
  b4:	str	w10, [sp]
  b8:	ldr	w10, [sp, #8]
  bc:	tst	w10, #0x3
  c0:	cset	w10, eq  // eq = none
  c4:	and	w10, w10, #0x1
  c8:	lsl	w10, w10, #1
  cc:	str	w10, [sp, #4]
  d0:	ldr	w10, [sp, #4]
  d4:	ldr	w11, [sp, #8]
  d8:	lsr	w10, w11, w10
  dc:	str	w10, [sp, #8]
  e0:	ldr	w10, [sp, #8]
  e4:	and	w10, w10, #0x3
  e8:	str	w10, [sp, #8]
  ec:	ldr	w10, [sp, #4]
  f0:	ldr	w11, [sp]
  f4:	add	w10, w11, w10
  f8:	str	w10, [sp]
  fc:	ldr	w10, [sp]
 100:	ldr	w11, [sp, #8]
 104:	subs	w9, w9, w11, lsr #1
 108:	ldr	w11, [sp, #8]
 10c:	tst	w11, #0x1
 110:	cset	w11, eq  // eq = none
 114:	and	w11, w11, #0x1
 118:	subs	w8, w8, w11
 11c:	and	w8, w9, w8
 120:	add	w0, w10, w8
 124:	add	sp, sp, #0x10
 128:	ret

ctzti2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ctzti2>:
   0:	sub	sp, sp, #0x30
   4:	str	x1, [sp, #40]
   8:	str	x0, [sp, #32]
   c:	ldr	x8, [sp, #32]
  10:	ldr	x9, [sp, #40]
  14:	str	x9, [sp, #24]
  18:	str	x8, [sp, #16]
  1c:	ldr	x8, [sp, #16]
  20:	subs	x8, x8, #0x0
  24:	cset	w10, eq  // eq = none
  28:	mov	w9, w10
  2c:	mov	x11, xzr
  30:	subs	x9, x11, x9
  34:	str	x9, [sp, #8]
  38:	ldr	x9, [sp, #24]
  3c:	ldr	x11, [sp, #8]
  40:	and	x9, x9, x11
  44:	ldr	x12, [sp, #16]
  48:	bic	x12, x12, x11
  4c:	orr	x9, x9, x12
  50:	rbit	x9, x9
  54:	clz	x9, x9
  58:	and	w10, w11, #0x40
  5c:	add	w0, w9, w10
  60:	add	sp, sp, #0x30
  64:	ret

divdc3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divdc3>:
   0:	sub	sp, sp, #0x70
   4:	stp	x29, x30, [sp, #96]
   8:	add	x29, sp, #0x60
   c:	stur	d0, [x29, #-24]
  10:	stur	d1, [x29, #-32]
  14:	stur	d2, [x29, #-40]
  18:	str	d3, [sp, #48]
  1c:	mov	w8, wzr
  20:	str	w8, [sp, #44]
  24:	ldur	d0, [x29, #-40]
  28:	fabs	d0, d0
  2c:	ldr	d1, [sp, #48]
  30:	fabs	d1, d1
  34:	fmaxnm	d0, d0, d1
  38:	bl	428 <__compiler_rt_logb>
  3c:	str	d0, [sp, #32]
  40:	ldr	d0, [sp, #32]
  44:	fabs	d0, d0
  48:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
  4c:	fmov	d1, x9
  50:	fcmp	d0, d1
  54:	b.eq	a4 <__divdc3+0xa4>  // b.none
  58:	b.vs	a4 <__divdc3+0xa4>
  5c:	b	60 <__divdc3+0x60>
  60:	ldr	d0, [sp, #32]
  64:	fcvtzs	w8, d0
  68:	str	w8, [sp, #44]
  6c:	ldur	d0, [x29, #-40]
  70:	ldr	w8, [sp, #44]
  74:	mov	w9, wzr
  78:	subs	w0, w9, w8
  7c:	str	w9, [sp, #4]
  80:	bl	0 <scalbn>
  84:	stur	d0, [x29, #-40]
  88:	ldr	d0, [sp, #48]
  8c:	ldr	w8, [sp, #44]
  90:	ldr	w9, [sp, #4]
  94:	subs	w0, w9, w8
  98:	bl	0 <scalbn>
  9c:	str	d0, [sp, #48]
  a0:	b	a4 <__divdc3+0xa4>
  a4:	ldur	d0, [x29, #-40]
  a8:	fmul	d0, d0, d0
  ac:	ldr	d1, [sp, #48]
  b0:	fmul	d1, d1, d1
  b4:	fadd	d0, d0, d1
  b8:	str	d0, [sp, #24]
  bc:	ldur	d0, [x29, #-24]
  c0:	ldur	d1, [x29, #-40]
  c4:	fmul	d0, d0, d1
  c8:	ldur	d1, [x29, #-32]
  cc:	ldr	d2, [sp, #48]
  d0:	fmul	d1, d1, d2
  d4:	fadd	d0, d0, d1
  d8:	ldr	d1, [sp, #24]
  dc:	fdiv	d0, d0, d1
  e0:	ldr	w8, [sp, #44]
  e4:	mov	w9, wzr
  e8:	subs	w0, w9, w8
  ec:	str	w9, [sp]
  f0:	bl	0 <scalbn>
  f4:	str	d0, [sp, #8]
  f8:	ldur	d0, [x29, #-32]
  fc:	ldur	d1, [x29, #-40]
 100:	fmul	d0, d0, d1
 104:	ldur	d1, [x29, #-24]
 108:	ldr	d2, [sp, #48]
 10c:	fmul	d1, d1, d2
 110:	fsub	d0, d0, d1
 114:	ldr	d1, [sp, #24]
 118:	fdiv	d0, d0, d1
 11c:	ldr	w8, [sp, #44]
 120:	ldr	w9, [sp]
 124:	subs	w0, w9, w8
 128:	bl	0 <scalbn>
 12c:	str	d0, [sp, #16]
 130:	ldr	d0, [sp, #8]
 134:	fcmp	d0, d0
 138:	b.vc	404 <__divdc3+0x404>
 13c:	b	140 <__divdc3+0x140>
 140:	ldr	d0, [sp, #16]
 144:	fcmp	d0, d0
 148:	b.vc	404 <__divdc3+0x404>
 14c:	b	150 <__divdc3+0x150>
 150:	ldr	d0, [sp, #24]
 154:	fcmp	d0, #0.0
 158:	b.ne	1cc <__divdc3+0x1cc>  // b.any
 15c:	b	160 <__divdc3+0x160>
 160:	ldur	d0, [x29, #-24]
 164:	fcmp	d0, d0
 168:	b.vc	180 <__divdc3+0x180>
 16c:	b	170 <__divdc3+0x170>
 170:	ldur	d0, [x29, #-32]
 174:	fcmp	d0, d0
 178:	b.vs	1cc <__divdc3+0x1cc>
 17c:	b	180 <__divdc3+0x180>
 180:	ldur	d0, [x29, #-40]
 184:	mov	v1.16b, v0.16b
 188:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 18c:	fmov	d0, x8
 190:	mov	v2.16b, v0.16b
 194:	movi	v3.2d, #0x0
 198:	fneg	v3.2d, v3.2d
 19c:	mov	v4.16b, v2.16b
 1a0:	bit	v4.16b, v1.16b, v3.16b
 1a4:	ldur	d0, [x29, #-24]
 1a8:	fmul	d0, d4, d0
 1ac:	str	d0, [sp, #8]
 1b0:	ldur	d0, [x29, #-40]
 1b4:	mov	v1.16b, v0.16b
 1b8:	bit	v2.16b, v1.16b, v3.16b
 1bc:	ldur	d0, [x29, #-32]
 1c0:	fmul	d0, d2, d0
 1c4:	str	d0, [sp, #16]
 1c8:	b	400 <__divdc3+0x400>
 1cc:	ldur	d0, [x29, #-24]
 1d0:	fabs	d0, d0
 1d4:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 1d8:	fmov	d1, x8
 1dc:	fcmp	d0, d1
 1e0:	b.eq	204 <__divdc3+0x204>  // b.none
 1e4:	b	1e8 <__divdc3+0x1e8>
 1e8:	ldur	d0, [x29, #-32]
 1ec:	fabs	d0, d0
 1f0:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 1f4:	fmov	d1, x8
 1f8:	fcmp	d0, d1
 1fc:	b.ne	2e8 <__divdc3+0x2e8>  // b.any
 200:	b	204 <__divdc3+0x204>
 204:	ldur	d0, [x29, #-40]
 208:	fabs	d0, d0
 20c:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 210:	fmov	d1, x8
 214:	fcmp	d0, d1
 218:	b.eq	2e8 <__divdc3+0x2e8>  // b.none
 21c:	b.vs	2e8 <__divdc3+0x2e8>
 220:	b	224 <__divdc3+0x224>
 224:	ldr	d0, [sp, #48]
 228:	fabs	d0, d0
 22c:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 230:	fmov	d1, x8
 234:	fcmp	d0, d1
 238:	b.eq	2e8 <__divdc3+0x2e8>  // b.none
 23c:	b.vs	2e8 <__divdc3+0x2e8>
 240:	b	244 <__divdc3+0x244>
 244:	ldur	d0, [x29, #-24]
 248:	fabs	d1, d0
 24c:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 250:	fmov	d2, x8
 254:	fcmp	d1, d2
 258:	fmov	d1, xzr
 25c:	fmov	d3, #1.000000000000000000e+00
 260:	fcsel	d4, d3, d1, eq  // eq = none
 264:	mov	v5.16b, v0.16b
 268:	mov	v6.16b, v4.16b
 26c:	movi	v7.2d, #0x0
 270:	fneg	v7.2d, v7.2d
 274:	bit	v6.16b, v5.16b, v7.16b
 278:	stur	d6, [x29, #-24]
 27c:	ldur	d0, [x29, #-32]
 280:	fabs	d4, d0
 284:	fcmp	d4, d2
 288:	fcsel	d1, d3, d1, eq  // eq = none
 28c:	mov	v5.16b, v0.16b
 290:	mov	v16.16b, v1.16b
 294:	bit	v16.16b, v5.16b, v7.16b
 298:	stur	d16, [x29, #-32]
 29c:	ldur	d0, [x29, #-24]
 2a0:	ldur	d1, [x29, #-40]
 2a4:	fmul	d0, d0, d1
 2a8:	ldur	d1, [x29, #-32]
 2ac:	ldr	d3, [sp, #48]
 2b0:	fmul	d1, d1, d3
 2b4:	fadd	d0, d0, d1
 2b8:	fmul	d0, d0, d2
 2bc:	str	d0, [sp, #8]
 2c0:	ldur	d0, [x29, #-32]
 2c4:	ldur	d1, [x29, #-40]
 2c8:	fmul	d0, d0, d1
 2cc:	ldur	d1, [x29, #-24]
 2d0:	ldr	d3, [sp, #48]
 2d4:	fmul	d1, d1, d3
 2d8:	fsub	d0, d0, d1
 2dc:	fmul	d0, d0, d2
 2e0:	str	d0, [sp, #16]
 2e4:	b	3fc <__divdc3+0x3fc>
 2e8:	ldr	d0, [sp, #32]
 2ec:	fabs	d0, d0
 2f0:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 2f4:	fmov	d1, x8
 2f8:	fcmp	d0, d1
 2fc:	b.ne	3f8 <__divdc3+0x3f8>  // b.any
 300:	b	304 <__divdc3+0x304>
 304:	ldr	d0, [sp, #32]
 308:	fcmp	d0, #0.0
 30c:	b.le	3f8 <__divdc3+0x3f8>
 310:	b	314 <__divdc3+0x314>
 314:	ldur	d0, [x29, #-24]
 318:	fabs	d0, d0
 31c:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 320:	fmov	d1, x8
 324:	fcmp	d0, d1
 328:	b.eq	3f8 <__divdc3+0x3f8>  // b.none
 32c:	b.vs	3f8 <__divdc3+0x3f8>
 330:	b	334 <__divdc3+0x334>
 334:	ldur	d0, [x29, #-32]
 338:	fabs	d0, d0
 33c:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 340:	fmov	d1, x8
 344:	fcmp	d0, d1
 348:	b.eq	3f8 <__divdc3+0x3f8>  // b.none
 34c:	b.vs	3f8 <__divdc3+0x3f8>
 350:	b	354 <__divdc3+0x354>
 354:	ldur	d0, [x29, #-40]
 358:	fabs	d1, d0
 35c:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 360:	fmov	d2, x8
 364:	fcmp	d1, d2
 368:	fmov	d1, xzr
 36c:	fmov	d3, #1.000000000000000000e+00
 370:	fcsel	d4, d3, d1, eq  // eq = none
 374:	mov	v5.16b, v0.16b
 378:	mov	v6.16b, v4.16b
 37c:	movi	v7.2d, #0x0
 380:	fneg	v7.2d, v7.2d
 384:	bit	v6.16b, v5.16b, v7.16b
 388:	stur	d6, [x29, #-40]
 38c:	ldr	d0, [sp, #48]
 390:	fabs	d4, d0
 394:	fcmp	d4, d2
 398:	fcsel	d2, d3, d1, eq  // eq = none
 39c:	mov	v5.16b, v0.16b
 3a0:	mov	v16.16b, v2.16b
 3a4:	bit	v16.16b, v5.16b, v7.16b
 3a8:	str	d16, [sp, #48]
 3ac:	ldur	d0, [x29, #-24]
 3b0:	ldur	d2, [x29, #-40]
 3b4:	fmul	d0, d0, d2
 3b8:	ldur	d2, [x29, #-32]
 3bc:	ldr	d3, [sp, #48]
 3c0:	fmul	d2, d2, d3
 3c4:	fadd	d0, d0, d2
 3c8:	fmul	d0, d0, d1
 3cc:	str	d0, [sp, #8]
 3d0:	ldur	d0, [x29, #-32]
 3d4:	ldur	d2, [x29, #-40]
 3d8:	fmul	d0, d0, d2
 3dc:	ldur	d2, [x29, #-24]
 3e0:	ldr	d3, [sp, #48]
 3e4:	fmul	d2, d2, d3
 3e8:	fsub	d0, d0, d2
 3ec:	fmul	d0, d0, d1
 3f0:	str	d0, [sp, #16]
 3f4:	b	3f8 <__divdc3+0x3f8>
 3f8:	b	3fc <__divdc3+0x3fc>
 3fc:	b	400 <__divdc3+0x400>
 400:	b	404 <__divdc3+0x404>
 404:	ldr	d0, [sp, #8]
 408:	ldr	d1, [sp, #16]
 40c:	stur	d0, [x29, #-16]
 410:	stur	d1, [x29, #-8]
 414:	ldur	d0, [x29, #-16]
 418:	ldur	d1, [x29, #-8]
 41c:	ldp	x29, x30, [sp, #96]
 420:	add	sp, sp, #0x70
 424:	ret

0000000000000428 <__compiler_rt_logb>:
 428:	sub	sp, sp, #0x20
 42c:	stp	x29, x30, [sp, #16]
 430:	add	x29, sp, #0x10
 434:	str	d0, [sp, #8]
 438:	ldr	d0, [sp, #8]
 43c:	bl	44c <__compiler_rt_logbX>
 440:	ldp	x29, x30, [sp, #16]
 444:	add	sp, sp, #0x20
 448:	ret

000000000000044c <__compiler_rt_logbX>:
 44c:	sub	sp, sp, #0x30
 450:	stp	x29, x30, [sp, #32]
 454:	add	x29, sp, #0x20
 458:	str	d0, [sp, #16]
 45c:	ldr	d0, [sp, #16]
 460:	bl	55c <toRep>
 464:	str	x0, [sp, #8]
 468:	ldr	x8, [sp, #8]
 46c:	and	x8, x8, #0x7ff0000000000000
 470:	lsr	x8, x8, #52
 474:	str	w8, [sp, #4]
 478:	ldr	w8, [sp, #4]
 47c:	cmp	w8, #0x7ff
 480:	b.ne	4c4 <__compiler_rt_logbX+0x78>  // b.any
 484:	ldr	x8, [sp, #8]
 488:	and	x8, x8, #0x8000000000000000
 48c:	cbz	x8, 4a8 <__compiler_rt_logbX+0x5c>
 490:	ldr	d0, [sp, #16]
 494:	ldr	d1, [sp, #16]
 498:	fcmp	d0, d1
 49c:	cset	w8, ne  // ne = any
 4a0:	tbnz	w8, #0, 4a8 <__compiler_rt_logbX+0x5c>
 4a4:	b	4b4 <__compiler_rt_logbX+0x68>
 4a8:	ldr	x8, [sp, #16]
 4ac:	stur	x8, [x29, #-8]
 4b0:	b	54c <__compiler_rt_logbX+0x100>
 4b4:	ldr	d0, [sp, #16]
 4b8:	fneg	d0, d0
 4bc:	stur	d0, [x29, #-8]
 4c0:	b	54c <__compiler_rt_logbX+0x100>
 4c4:	ldr	d0, [sp, #16]
 4c8:	fcmp	d0, #0.0
 4cc:	cset	w8, eq  // eq = none
 4d0:	tbnz	w8, #0, 4d8 <__compiler_rt_logbX+0x8c>
 4d4:	b	4e8 <__compiler_rt_logbX+0x9c>
 4d8:	mov	x0, #0xfff0000000000000    	// #-4503599627370496
 4dc:	bl	578 <fromRep>
 4e0:	stur	d0, [x29, #-8]
 4e4:	b	54c <__compiler_rt_logbX+0x100>
 4e8:	ldr	w8, [sp, #4]
 4ec:	cbz	w8, 504 <__compiler_rt_logbX+0xb8>
 4f0:	ldr	w8, [sp, #4]
 4f4:	subs	w8, w8, #0x3ff
 4f8:	scvtf	d0, w8
 4fc:	stur	d0, [x29, #-8]
 500:	b	54c <__compiler_rt_logbX+0x100>
 504:	add	x0, sp, #0x8
 508:	ldr	x8, [sp, #8]
 50c:	and	x8, x8, #0x7fffffffffffffff
 510:	str	x8, [sp, #8]
 514:	bl	594 <normalize>
 518:	mov	w9, #0x1                   	// #1
 51c:	subs	w9, w9, w0
 520:	str	w9, [sp]
 524:	ldr	x8, [sp, #8]
 528:	and	x8, x8, #0x7ff0000000000000
 52c:	lsr	x8, x8, #52
 530:	str	w8, [sp, #4]
 534:	ldr	w8, [sp, #4]
 538:	subs	w8, w8, #0x3ff
 53c:	ldr	w9, [sp]
 540:	subs	w8, w8, w9
 544:	scvtf	d0, w8
 548:	stur	d0, [x29, #-8]
 54c:	ldur	d0, [x29, #-8]
 550:	ldp	x29, x30, [sp, #32]
 554:	add	sp, sp, #0x30
 558:	ret

000000000000055c <toRep>:
 55c:	sub	sp, sp, #0x10
 560:	str	d0, [sp, #8]
 564:	ldr	x8, [sp, #8]
 568:	str	x8, [sp]
 56c:	ldr	x0, [sp]
 570:	add	sp, sp, #0x10
 574:	ret

0000000000000578 <fromRep>:
 578:	sub	sp, sp, #0x10
 57c:	str	x0, [sp, #8]
 580:	ldr	x8, [sp, #8]
 584:	str	x8, [sp]
 588:	ldr	d0, [sp]
 58c:	add	sp, sp, #0x10
 590:	ret

0000000000000594 <normalize>:
 594:	sub	sp, sp, #0x30
 598:	stp	x29, x30, [sp, #32]
 59c:	add	x29, sp, #0x20
 5a0:	mov	x8, #0x10000000000000      	// #4503599627370496
 5a4:	mov	w9, #0x1                   	// #1
 5a8:	stur	x0, [x29, #-8]
 5ac:	ldur	x10, [x29, #-8]
 5b0:	ldr	x0, [x10]
 5b4:	str	x8, [sp, #8]
 5b8:	str	w9, [sp, #4]
 5bc:	bl	60c <rep_clz>
 5c0:	ldr	x8, [sp, #8]
 5c4:	str	w0, [sp]
 5c8:	mov	x0, x8
 5cc:	bl	60c <rep_clz>
 5d0:	ldr	w9, [sp]
 5d4:	subs	w11, w9, w0
 5d8:	stur	w11, [x29, #-12]
 5dc:	ldur	w11, [x29, #-12]
 5e0:	mov	w8, w11
 5e4:	ldur	x10, [x29, #-8]
 5e8:	ldr	x12, [x10]
 5ec:	lsl	x8, x12, x8
 5f0:	str	x8, [x10]
 5f4:	ldur	w11, [x29, #-12]
 5f8:	ldr	w13, [sp, #4]
 5fc:	subs	w0, w13, w11
 600:	ldp	x29, x30, [sp, #32]
 604:	add	sp, sp, #0x30
 608:	ret

000000000000060c <rep_clz>:
 60c:	sub	sp, sp, #0x10
 610:	str	x0, [sp, #8]
 614:	ldr	x8, [sp, #8]
 618:	clz	x8, x8
 61c:	mov	w0, w8
 620:	add	sp, sp, #0x10
 624:	ret

divdf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divdf3>:
   0:	sub	sp, sp, #0xe0
   4:	stp	x29, x30, [sp, #208]
   8:	add	x29, sp, #0xd0
   c:	stur	d0, [x29, #-16]
  10:	stur	d1, [x29, #-24]
  14:	ldur	d0, [x29, #-16]
  18:	bl	55c <toRep>
  1c:	lsr	x8, x0, #52
  20:	and	x8, x8, #0x7ff
  24:	stur	w8, [x29, #-28]
  28:	ldur	d0, [x29, #-24]
  2c:	bl	55c <toRep>
  30:	lsr	x9, x0, #52
  34:	and	x9, x9, #0x7ff
  38:	stur	w9, [x29, #-32]
  3c:	ldur	d0, [x29, #-16]
  40:	bl	55c <toRep>
  44:	ldur	d0, [x29, #-24]
  48:	str	x0, [sp, #8]
  4c:	bl	55c <toRep>
  50:	ldr	x10, [sp, #8]
  54:	eor	x11, x10, x0
  58:	and	x11, x11, #0x8000000000000000
  5c:	stur	x11, [x29, #-40]
  60:	ldur	d0, [x29, #-16]
  64:	bl	55c <toRep>
  68:	and	x10, x0, #0xfffffffffffff
  6c:	stur	x10, [x29, #-48]
  70:	ldur	d0, [x29, #-24]
  74:	bl	55c <toRep>
  78:	and	x10, x0, #0xfffffffffffff
  7c:	stur	x10, [x29, #-56]
  80:	stur	wzr, [x29, #-60]
  84:	ldur	w8, [x29, #-28]
  88:	subs	w8, w8, #0x1
  8c:	cmp	w8, #0x7fe
  90:	b.cs	a4 <__divdf3+0xa4>  // b.hs, b.nlast
  94:	ldur	w8, [x29, #-32]
  98:	subs	w8, w8, #0x1
  9c:	cmp	w8, #0x7fe
  a0:	b.cc	214 <__divdf3+0x214>  // b.lo, b.ul, b.last
  a4:	ldur	d0, [x29, #-16]
  a8:	bl	55c <toRep>
  ac:	and	x8, x0, #0x7fffffffffffffff
  b0:	stur	x8, [x29, #-72]
  b4:	ldur	d0, [x29, #-24]
  b8:	bl	55c <toRep>
  bc:	and	x8, x0, #0x7fffffffffffffff
  c0:	stur	x8, [x29, #-80]
  c4:	ldur	x8, [x29, #-72]
  c8:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
  cc:	cmp	x8, x9
  d0:	b.ls	ec <__divdf3+0xec>  // b.plast
  d4:	ldur	d0, [x29, #-16]
  d8:	bl	55c <toRep>
  dc:	orr	x0, x0, #0x8000000000000
  e0:	bl	578 <fromRep>
  e4:	stur	d0, [x29, #-8]
  e8:	b	54c <__divdf3+0x54c>
  ec:	ldur	x8, [x29, #-80]
  f0:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
  f4:	cmp	x8, x9
  f8:	b.ls	114 <__divdf3+0x114>  // b.plast
  fc:	ldur	d0, [x29, #-24]
 100:	bl	55c <toRep>
 104:	orr	x0, x0, #0x8000000000000
 108:	bl	578 <fromRep>
 10c:	stur	d0, [x29, #-8]
 110:	b	54c <__divdf3+0x54c>
 114:	ldur	x8, [x29, #-72]
 118:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 11c:	cmp	x8, x9
 120:	b.ne	15c <__divdf3+0x15c>  // b.any
 124:	ldur	x8, [x29, #-80]
 128:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 12c:	cmp	x8, x9
 130:	b.ne	144 <__divdf3+0x144>  // b.any
 134:	mov	x0, #0x7ff8000000000000    	// #9221120237041090560
 138:	bl	578 <fromRep>
 13c:	stur	d0, [x29, #-8]
 140:	b	54c <__divdf3+0x54c>
 144:	ldur	x8, [x29, #-72]
 148:	ldur	x9, [x29, #-40]
 14c:	orr	x0, x8, x9
 150:	bl	578 <fromRep>
 154:	stur	d0, [x29, #-8]
 158:	b	54c <__divdf3+0x54c>
 15c:	ldur	x8, [x29, #-80]
 160:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 164:	cmp	x8, x9
 168:	b.ne	17c <__divdf3+0x17c>  // b.any
 16c:	ldur	x0, [x29, #-40]
 170:	bl	578 <fromRep>
 174:	stur	d0, [x29, #-8]
 178:	b	54c <__divdf3+0x54c>
 17c:	ldur	x8, [x29, #-72]
 180:	cbnz	x8, 1ac <__divdf3+0x1ac>
 184:	ldur	x8, [x29, #-80]
 188:	cbnz	x8, 19c <__divdf3+0x19c>
 18c:	mov	x0, #0x7ff8000000000000    	// #9221120237041090560
 190:	bl	578 <fromRep>
 194:	stur	d0, [x29, #-8]
 198:	b	54c <__divdf3+0x54c>
 19c:	ldur	x0, [x29, #-40]
 1a0:	bl	578 <fromRep>
 1a4:	stur	d0, [x29, #-8]
 1a8:	b	54c <__divdf3+0x54c>
 1ac:	ldur	x8, [x29, #-80]
 1b0:	cbnz	x8, 1cc <__divdf3+0x1cc>
 1b4:	ldur	x8, [x29, #-40]
 1b8:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 1bc:	orr	x0, x9, x8
 1c0:	bl	578 <fromRep>
 1c4:	stur	d0, [x29, #-8]
 1c8:	b	54c <__divdf3+0x54c>
 1cc:	ldur	x8, [x29, #-72]
 1d0:	mov	x9, #0x10000000000000      	// #4503599627370496
 1d4:	cmp	x8, x9
 1d8:	b.cs	1f0 <__divdf3+0x1f0>  // b.hs, b.nlast
 1dc:	sub	x0, x29, #0x30
 1e0:	bl	594 <normalize>
 1e4:	ldur	w8, [x29, #-60]
 1e8:	add	w8, w8, w0
 1ec:	stur	w8, [x29, #-60]
 1f0:	ldur	x8, [x29, #-80]
 1f4:	mov	x9, #0x10000000000000      	// #4503599627370496
 1f8:	cmp	x8, x9
 1fc:	b.cs	214 <__divdf3+0x214>  // b.hs, b.nlast
 200:	sub	x0, x29, #0x38
 204:	bl	594 <normalize>
 208:	ldur	w8, [x29, #-60]
 20c:	subs	w8, w8, w0
 210:	stur	w8, [x29, #-60]
 214:	ldur	x8, [x29, #-48]
 218:	orr	x8, x8, #0x10000000000000
 21c:	stur	x8, [x29, #-48]
 220:	ldur	x8, [x29, #-56]
 224:	orr	x8, x8, #0x10000000000000
 228:	stur	x8, [x29, #-56]
 22c:	ldur	w9, [x29, #-28]
 230:	ldur	w10, [x29, #-32]
 234:	subs	w9, w9, w10
 238:	ldur	w10, [x29, #-60]
 23c:	add	w9, w9, w10
 240:	stur	w9, [x29, #-84]
 244:	ldur	x8, [x29, #-56]
 248:	lsr	x8, x8, #21
 24c:	stur	w8, [x29, #-88]
 250:	ldur	w8, [x29, #-88]
 254:	mov	w9, #0xf333                	// #62259
 258:	movk	w9, #0x7504, lsl #16
 25c:	subs	w8, w9, w8
 260:	stur	w8, [x29, #-92]
 264:	ldur	w8, [x29, #-92]
 268:	mov	w11, w8
 26c:	ldur	w8, [x29, #-88]
 270:	mov	w12, w8
 274:	mul	x11, x11, x12
 278:	mov	x12, xzr
 27c:	subs	x11, x12, x11, lsr #32
 280:	stur	w11, [x29, #-96]
 284:	ldur	w8, [x29, #-92]
 288:	mov	w13, w8
 28c:	ldur	w8, [x29, #-96]
 290:	mov	w14, w8
 294:	mul	x13, x13, x14
 298:	lsr	x13, x13, #31
 29c:	stur	w13, [x29, #-92]
 2a0:	ldur	w8, [x29, #-92]
 2a4:	mov	w14, w8
 2a8:	ldur	w8, [x29, #-88]
 2ac:	mov	w15, w8
 2b0:	mul	x14, x14, x15
 2b4:	subs	x14, x12, x14, lsr #32
 2b8:	stur	w14, [x29, #-96]
 2bc:	ldur	w8, [x29, #-92]
 2c0:	mov	w15, w8
 2c4:	ldur	w8, [x29, #-96]
 2c8:	mov	w16, w8
 2cc:	mul	x15, x15, x16
 2d0:	lsr	x15, x15, #31
 2d4:	stur	w15, [x29, #-92]
 2d8:	ldur	w8, [x29, #-92]
 2dc:	mov	w16, w8
 2e0:	ldur	w8, [x29, #-88]
 2e4:	mov	w17, w8
 2e8:	mul	x16, x16, x17
 2ec:	subs	x16, x12, x16, lsr #32
 2f0:	stur	w16, [x29, #-96]
 2f4:	ldur	w8, [x29, #-92]
 2f8:	mov	w17, w8
 2fc:	ldur	w8, [x29, #-96]
 300:	mov	w18, w8
 304:	mul	x17, x17, x18
 308:	lsr	x17, x17, #31
 30c:	stur	w17, [x29, #-92]
 310:	ldur	w8, [x29, #-92]
 314:	subs	w8, w8, #0x1
 318:	stur	w8, [x29, #-92]
 31c:	ldur	x18, [x29, #-56]
 320:	lsl	x18, x18, #11
 324:	stur	w18, [x29, #-100]
 328:	ldur	w8, [x29, #-92]
 32c:	mov	w0, w8
 330:	ldur	w8, [x29, #-88]
 334:	mov	w1, w8
 338:	mul	x0, x0, x1
 33c:	ldur	w8, [x29, #-92]
 340:	mov	w1, w8
 344:	ldur	w8, [x29, #-100]
 348:	mov	w2, w8
 34c:	mul	x1, x1, x2
 350:	add	x0, x0, x1, lsr #32
 354:	subs	x12, x12, x0
 358:	str	x12, [sp, #96]
 35c:	ldr	x12, [sp, #96]
 360:	lsr	x12, x12, #32
 364:	str	w12, [sp, #84]
 368:	ldr	x0, [sp, #96]
 36c:	str	w0, [sp, #80]
 370:	ldur	w8, [x29, #-92]
 374:	mov	w1, w8
 378:	ldr	w8, [sp, #84]
 37c:	mov	w2, w8
 380:	mul	x1, x1, x2
 384:	ldur	w8, [x29, #-92]
 388:	mov	w2, w8
 38c:	ldr	w8, [sp, #80]
 390:	mov	w3, w8
 394:	mul	x2, x2, x3
 398:	add	x1, x1, x2, lsr #32
 39c:	str	x1, [sp, #88]
 3a0:	ldr	x1, [sp, #88]
 3a4:	subs	x1, x1, #0x2
 3a8:	str	x1, [sp, #88]
 3ac:	ldur	x1, [x29, #-48]
 3b0:	lsl	x0, x1, #2
 3b4:	ldr	x1, [sp, #88]
 3b8:	add	x2, sp, #0x48
 3bc:	add	x3, sp, #0x40
 3c0:	bl	60c <wideMultiply>
 3c4:	ldr	x0, [sp, #72]
 3c8:	mov	x1, #0x20000000000000      	// #9007199254740992
 3cc:	cmp	x0, x1
 3d0:	b.cs	400 <__divdf3+0x400>  // b.hs, b.nlast
 3d4:	ldur	x8, [x29, #-48]
 3d8:	lsl	x8, x8, #53
 3dc:	ldr	x9, [sp, #72]
 3e0:	ldur	x10, [x29, #-56]
 3e4:	mul	x9, x9, x10
 3e8:	subs	x8, x8, x9
 3ec:	str	x8, [sp, #56]
 3f0:	ldur	w11, [x29, #-84]
 3f4:	subs	w11, w11, #0x1
 3f8:	stur	w11, [x29, #-84]
 3fc:	b	428 <__divdf3+0x428>
 400:	ldr	x8, [sp, #72]
 404:	lsr	x8, x8, #1
 408:	str	x8, [sp, #72]
 40c:	ldur	x8, [x29, #-48]
 410:	lsl	x8, x8, #52
 414:	ldr	x9, [sp, #72]
 418:	ldur	x10, [x29, #-56]
 41c:	mul	x9, x9, x10
 420:	subs	x8, x8, x9
 424:	str	x8, [sp, #56]
 428:	ldur	w8, [x29, #-84]
 42c:	add	w8, w8, #0x3ff
 430:	str	w8, [sp, #52]
 434:	ldr	w8, [sp, #52]
 438:	cmp	w8, #0x7ff
 43c:	b.lt	458 <__divdf3+0x458>  // b.tstop
 440:	ldur	x8, [x29, #-40]
 444:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 448:	orr	x0, x9, x8
 44c:	bl	578 <fromRep>
 450:	stur	d0, [x29, #-8]
 454:	b	54c <__divdf3+0x54c>
 458:	ldr	w8, [sp, #52]
 45c:	cmp	w8, #0x1
 460:	b.ge	4e0 <__divdf3+0x4e0>  // b.tcont
 464:	ldr	w8, [sp, #52]
 468:	cbnz	w8, 4d0 <__divdf3+0x4d0>
 46c:	ldr	x8, [sp, #56]
 470:	lsl	x8, x8, #1
 474:	ldur	x9, [x29, #-56]
 478:	cmp	x8, x9
 47c:	cset	w10, hi  // hi = pmore
 480:	and	w10, w10, #0x1
 484:	strb	w10, [sp, #51]
 488:	ldr	x8, [sp, #72]
 48c:	and	x8, x8, #0xfffffffffffff
 490:	str	x8, [sp, #40]
 494:	ldrb	w10, [sp, #51]
 498:	mov	w0, w10
 49c:	and	x8, x0, #0x1
 4a0:	ldr	x9, [sp, #40]
 4a4:	add	x8, x9, x8
 4a8:	str	x8, [sp, #40]
 4ac:	ldr	x8, [sp, #40]
 4b0:	and	x8, x8, #0xfff0000000000000
 4b4:	cbz	x8, 4d0 <__divdf3+0x4d0>
 4b8:	ldr	x8, [sp, #40]
 4bc:	ldur	x9, [x29, #-40]
 4c0:	orr	x0, x8, x9
 4c4:	bl	578 <fromRep>
 4c8:	stur	d0, [x29, #-8]
 4cc:	b	54c <__divdf3+0x54c>
 4d0:	ldur	x0, [x29, #-40]
 4d4:	bl	578 <fromRep>
 4d8:	stur	d0, [x29, #-8]
 4dc:	b	54c <__divdf3+0x54c>
 4e0:	ldr	x8, [sp, #56]
 4e4:	lsl	x8, x8, #1
 4e8:	ldur	x9, [x29, #-56]
 4ec:	cmp	x8, x9
 4f0:	cset	w10, hi  // hi = pmore
 4f4:	and	w10, w10, #0x1
 4f8:	strb	w10, [sp, #39]
 4fc:	ldr	x8, [sp, #72]
 500:	and	x8, x8, #0xfffffffffffff
 504:	str	x8, [sp, #24]
 508:	ldrsw	x8, [sp, #52]
 50c:	ldr	x9, [sp, #24]
 510:	orr	x8, x9, x8, lsl #52
 514:	str	x8, [sp, #24]
 518:	ldrb	w10, [sp, #39]
 51c:	mov	w0, w10
 520:	and	x8, x0, #0x1
 524:	ldr	x9, [sp, #24]
 528:	add	x8, x9, x8
 52c:	str	x8, [sp, #24]
 530:	ldr	x8, [sp, #24]
 534:	ldur	x9, [x29, #-40]
 538:	orr	x0, x8, x9
 53c:	bl	578 <fromRep>
 540:	str	d0, [sp, #16]
 544:	ldr	x8, [sp, #16]
 548:	stur	x8, [x29, #-8]
 54c:	ldur	d0, [x29, #-8]
 550:	ldp	x29, x30, [sp, #208]
 554:	add	sp, sp, #0xe0
 558:	ret

000000000000055c <toRep>:
 55c:	sub	sp, sp, #0x10
 560:	str	d0, [sp, #8]
 564:	ldr	x8, [sp, #8]
 568:	str	x8, [sp]
 56c:	ldr	x0, [sp]
 570:	add	sp, sp, #0x10
 574:	ret

0000000000000578 <fromRep>:
 578:	sub	sp, sp, #0x10
 57c:	str	x0, [sp, #8]
 580:	ldr	x8, [sp, #8]
 584:	str	x8, [sp]
 588:	ldr	d0, [sp]
 58c:	add	sp, sp, #0x10
 590:	ret

0000000000000594 <normalize>:
 594:	sub	sp, sp, #0x30
 598:	stp	x29, x30, [sp, #32]
 59c:	add	x29, sp, #0x20
 5a0:	mov	x8, #0x10000000000000      	// #4503599627370496
 5a4:	mov	w9, #0x1                   	// #1
 5a8:	stur	x0, [x29, #-8]
 5ac:	ldur	x10, [x29, #-8]
 5b0:	ldr	x0, [x10]
 5b4:	str	x8, [sp, #8]
 5b8:	str	w9, [sp, #4]
 5bc:	bl	6ec <rep_clz>
 5c0:	ldr	x8, [sp, #8]
 5c4:	str	w0, [sp]
 5c8:	mov	x0, x8
 5cc:	bl	6ec <rep_clz>
 5d0:	ldr	w9, [sp]
 5d4:	subs	w11, w9, w0
 5d8:	stur	w11, [x29, #-12]
 5dc:	ldur	w11, [x29, #-12]
 5e0:	mov	w8, w11
 5e4:	ldur	x10, [x29, #-8]
 5e8:	ldr	x12, [x10]
 5ec:	lsl	x8, x12, x8
 5f0:	str	x8, [x10]
 5f4:	ldur	w11, [x29, #-12]
 5f8:	ldr	w13, [sp, #4]
 5fc:	subs	w0, w13, w11
 600:	ldp	x29, x30, [sp, #32]
 604:	add	sp, sp, #0x30
 608:	ret

000000000000060c <wideMultiply>:
 60c:	sub	sp, sp, #0x50
 610:	str	x0, [sp, #72]
 614:	str	x1, [sp, #64]
 618:	str	x2, [sp, #56]
 61c:	str	x3, [sp, #48]
 620:	ldr	x8, [sp, #72]
 624:	and	x8, x8, #0xffffffff
 628:	ldr	x9, [sp, #64]
 62c:	and	x9, x9, #0xffffffff
 630:	mul	x8, x8, x9
 634:	str	x8, [sp, #40]
 638:	ldr	x8, [sp, #72]
 63c:	and	x8, x8, #0xffffffff
 640:	ldr	x9, [sp, #64]
 644:	lsr	x9, x9, #32
 648:	mul	x8, x8, x9
 64c:	str	x8, [sp, #32]
 650:	ldr	x8, [sp, #72]
 654:	lsr	x8, x8, #32
 658:	ldr	x9, [sp, #64]
 65c:	and	x9, x9, #0xffffffff
 660:	mul	x8, x8, x9
 664:	str	x8, [sp, #24]
 668:	ldr	x8, [sp, #72]
 66c:	lsr	x8, x8, #32
 670:	ldr	x9, [sp, #64]
 674:	lsr	x9, x9, #32
 678:	mul	x8, x8, x9
 67c:	str	x8, [sp, #16]
 680:	ldr	x8, [sp, #40]
 684:	and	x8, x8, #0xffffffff
 688:	str	x8, [sp, #8]
 68c:	ldr	x8, [sp, #40]
 690:	lsr	x8, x8, #32
 694:	ldr	x9, [sp, #32]
 698:	add	x8, x8, w9, uxtw
 69c:	ldr	x10, [sp, #24]
 6a0:	add	x8, x8, w10, uxtw
 6a4:	str	x8, [sp]
 6a8:	ldr	x8, [sp, #8]
 6ac:	ldr	x11, [sp]
 6b0:	add	x8, x8, x11, lsl #32
 6b4:	ldr	x11, [sp, #48]
 6b8:	str	x8, [x11]
 6bc:	ldr	x8, [sp, #32]
 6c0:	ldr	x11, [sp, #24]
 6c4:	lsr	x11, x11, #32
 6c8:	add	x8, x11, x8, lsr #32
 6cc:	ldr	x11, [sp]
 6d0:	add	x8, x8, x11, lsr #32
 6d4:	ldr	x11, [sp, #16]
 6d8:	add	x8, x8, x11
 6dc:	ldr	x11, [sp, #56]
 6e0:	str	x8, [x11]
 6e4:	add	sp, sp, #0x50
 6e8:	ret

00000000000006ec <rep_clz>:
 6ec:	sub	sp, sp, #0x10
 6f0:	str	x0, [sp, #8]
 6f4:	ldr	x8, [sp, #8]
 6f8:	clz	x8, x8
 6fc:	mov	w0, w8
 700:	add	sp, sp, #0x10
 704:	ret

divdi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divdi3>:
   0:	sub	sp, sp, #0x40
   4:	stp	x29, x30, [sp, #48]
   8:	add	x29, sp, #0x30
   c:	mov	w8, #0x3f                  	// #63
  10:	mov	x9, xzr
  14:	stur	x0, [x29, #-8]
  18:	stur	x1, [x29, #-16]
  1c:	stur	w8, [x29, #-20]
  20:	ldur	x10, [x29, #-8]
  24:	asr	x10, x10, #63
  28:	str	x10, [sp, #16]
  2c:	ldur	x10, [x29, #-16]
  30:	asr	x10, x10, #63
  34:	str	x10, [sp, #8]
  38:	ldur	x10, [x29, #-8]
  3c:	ldr	x11, [sp, #16]
  40:	eor	x10, x10, x11
  44:	ldr	x11, [sp, #16]
  48:	subs	x10, x10, x11
  4c:	stur	x10, [x29, #-8]
  50:	ldur	x10, [x29, #-16]
  54:	ldr	x11, [sp, #8]
  58:	eor	x10, x10, x11
  5c:	ldr	x11, [sp, #8]
  60:	subs	x10, x10, x11
  64:	stur	x10, [x29, #-16]
  68:	ldr	x10, [sp, #8]
  6c:	ldr	x11, [sp, #16]
  70:	eor	x10, x11, x10
  74:	str	x10, [sp, #16]
  78:	ldur	x0, [x29, #-8]
  7c:	ldur	x1, [x29, #-16]
  80:	mov	x2, x9
  84:	bl	0 <__udivmoddi4>
  88:	ldr	x9, [sp, #16]
  8c:	eor	x9, x0, x9
  90:	ldr	x10, [sp, #16]
  94:	subs	x0, x9, x10
  98:	ldp	x29, x30, [sp, #48]
  9c:	add	sp, sp, #0x40
  a0:	ret

divmoddi4.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divmoddi4>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	stur	x0, [x29, #-8]
  10:	str	x1, [sp, #16]
  14:	str	x2, [sp, #8]
  18:	ldur	x0, [x29, #-8]
  1c:	ldr	x1, [sp, #16]
  20:	bl	0 <__divdi3>
  24:	str	x0, [sp]
  28:	ldur	x8, [x29, #-8]
  2c:	ldr	x9, [sp]
  30:	ldr	x10, [sp, #16]
  34:	mul	x9, x9, x10
  38:	subs	x8, x8, x9
  3c:	ldr	x9, [sp, #8]
  40:	str	x8, [x9]
  44:	ldr	x0, [sp]
  48:	ldp	x29, x30, [sp, #32]
  4c:	add	sp, sp, #0x30
  50:	ret

divmodsi4.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divmodsi4>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	stur	w0, [x29, #-4]
  10:	stur	w1, [x29, #-8]
  14:	str	x2, [sp, #16]
  18:	ldur	w0, [x29, #-4]
  1c:	ldur	w1, [x29, #-8]
  20:	bl	0 <__divsi3>
  24:	str	w0, [sp, #12]
  28:	ldur	w8, [x29, #-4]
  2c:	ldr	w9, [sp, #12]
  30:	ldur	w10, [x29, #-8]
  34:	mul	w9, w9, w10
  38:	subs	w8, w8, w9
  3c:	ldr	x11, [sp, #16]
  40:	str	w8, [x11]
  44:	ldr	w0, [sp, #12]
  48:	ldp	x29, x30, [sp, #32]
  4c:	add	sp, sp, #0x30
  50:	ret

divsc3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divsc3>:
   0:	sub	sp, sp, #0x50
   4:	stp	x29, x30, [sp, #64]
   8:	add	x29, sp, #0x40
   c:	stur	s0, [x29, #-12]
  10:	stur	s1, [x29, #-16]
  14:	stur	s2, [x29, #-20]
  18:	stur	s3, [x29, #-24]
  1c:	mov	w8, wzr
  20:	stur	w8, [x29, #-28]
  24:	ldur	s0, [x29, #-20]
  28:	fabs	s0, s0
  2c:	ldur	s1, [x29, #-24]
  30:	fabs	s1, s1
  34:	fmaxnm	s0, s0, s1
  38:	bl	41c <__compiler_rt_logbf>
  3c:	str	s0, [sp, #32]
  40:	ldr	s0, [sp, #32]
  44:	fabs	s0, s0
  48:	mov	w8, #0x7f800000            	// #2139095040
  4c:	fmov	s1, w8
  50:	fcmp	s0, s1
  54:	b.eq	a4 <__divsc3+0xa4>  // b.none
  58:	b.vs	a4 <__divsc3+0xa4>
  5c:	b	60 <__divsc3+0x60>
  60:	ldr	s0, [sp, #32]
  64:	fcvtzs	w8, s0
  68:	stur	w8, [x29, #-28]
  6c:	ldur	s0, [x29, #-20]
  70:	ldur	w8, [x29, #-28]
  74:	mov	w9, wzr
  78:	subs	w0, w9, w8
  7c:	str	w9, [sp, #12]
  80:	bl	0 <scalbnf>
  84:	stur	s0, [x29, #-20]
  88:	ldur	s0, [x29, #-24]
  8c:	ldur	w8, [x29, #-28]
  90:	ldr	w9, [sp, #12]
  94:	subs	w0, w9, w8
  98:	bl	0 <scalbnf>
  9c:	stur	s0, [x29, #-24]
  a0:	b	a4 <__divsc3+0xa4>
  a4:	ldur	s0, [x29, #-20]
  a8:	fmul	s0, s0, s0
  ac:	ldur	s1, [x29, #-24]
  b0:	fmul	s1, s1, s1
  b4:	fadd	s0, s0, s1
  b8:	str	s0, [sp, #28]
  bc:	ldur	s0, [x29, #-12]
  c0:	ldur	s1, [x29, #-20]
  c4:	fmul	s0, s0, s1
  c8:	ldur	s1, [x29, #-16]
  cc:	ldur	s2, [x29, #-24]
  d0:	fmul	s1, s1, s2
  d4:	fadd	s0, s0, s1
  d8:	ldr	s1, [sp, #28]
  dc:	fdiv	s0, s0, s1
  e0:	ldur	w8, [x29, #-28]
  e4:	mov	w9, wzr
  e8:	subs	w0, w9, w8
  ec:	str	w9, [sp, #8]
  f0:	bl	0 <scalbnf>
  f4:	str	s0, [sp, #16]
  f8:	ldur	s0, [x29, #-16]
  fc:	ldur	s1, [x29, #-20]
 100:	fmul	s0, s0, s1
 104:	ldur	s1, [x29, #-12]
 108:	ldur	s2, [x29, #-24]
 10c:	fmul	s1, s1, s2
 110:	fsub	s0, s0, s1
 114:	ldr	s1, [sp, #28]
 118:	fdiv	s0, s0, s1
 11c:	ldur	w8, [x29, #-28]
 120:	ldr	w9, [sp, #8]
 124:	subs	w0, w9, w8
 128:	bl	0 <scalbnf>
 12c:	str	s0, [sp, #20]
 130:	ldr	s0, [sp, #16]
 134:	fcmp	s0, s0
 138:	b.vc	3f8 <__divsc3+0x3f8>
 13c:	b	140 <__divsc3+0x140>
 140:	ldr	s0, [sp, #20]
 144:	fcmp	s0, s0
 148:	b.vc	3f8 <__divsc3+0x3f8>
 14c:	b	150 <__divsc3+0x150>
 150:	ldr	s0, [sp, #28]
 154:	fcmp	s0, #0.0
 158:	b.ne	1c8 <__divsc3+0x1c8>  // b.any
 15c:	b	160 <__divsc3+0x160>
 160:	ldur	s0, [x29, #-12]
 164:	fcmp	s0, s0
 168:	b.vc	180 <__divsc3+0x180>
 16c:	b	170 <__divsc3+0x170>
 170:	ldur	s0, [x29, #-16]
 174:	fcmp	s0, s0
 178:	b.vs	1c8 <__divsc3+0x1c8>
 17c:	b	180 <__divsc3+0x180>
 180:	ldur	s0, [x29, #-20]
 184:	mov	v1.16b, v0.16b
 188:	mov	w8, #0x7f800000            	// #2139095040
 18c:	fmov	s0, w8
 190:	mov	v2.16b, v0.16b
 194:	movi	v3.4s, #0x80, lsl #24
 198:	mov	v4.16b, v2.16b
 19c:	bit	v4.16b, v1.16b, v3.16b
 1a0:	ldur	s0, [x29, #-12]
 1a4:	fmul	s0, s4, s0
 1a8:	str	s0, [sp, #16]
 1ac:	ldur	s0, [x29, #-20]
 1b0:	mov	v1.16b, v0.16b
 1b4:	bit	v2.16b, v1.16b, v3.16b
 1b8:	ldur	s0, [x29, #-16]
 1bc:	fmul	s0, s2, s0
 1c0:	str	s0, [sp, #20]
 1c4:	b	3f4 <__divsc3+0x3f4>
 1c8:	ldur	s0, [x29, #-12]
 1cc:	fabs	s0, s0
 1d0:	mov	w8, #0x7f800000            	// #2139095040
 1d4:	fmov	s1, w8
 1d8:	fcmp	s0, s1
 1dc:	b.eq	200 <__divsc3+0x200>  // b.none
 1e0:	b	1e4 <__divsc3+0x1e4>
 1e4:	ldur	s0, [x29, #-16]
 1e8:	fabs	s0, s0
 1ec:	mov	w8, #0x7f800000            	// #2139095040
 1f0:	fmov	s1, w8
 1f4:	fcmp	s0, s1
 1f8:	b.ne	2e0 <__divsc3+0x2e0>  // b.any
 1fc:	b	200 <__divsc3+0x200>
 200:	ldur	s0, [x29, #-20]
 204:	fabs	s0, s0
 208:	mov	w8, #0x7f800000            	// #2139095040
 20c:	fmov	s1, w8
 210:	fcmp	s0, s1
 214:	b.eq	2e0 <__divsc3+0x2e0>  // b.none
 218:	b.vs	2e0 <__divsc3+0x2e0>
 21c:	b	220 <__divsc3+0x220>
 220:	ldur	s0, [x29, #-24]
 224:	fabs	s0, s0
 228:	mov	w8, #0x7f800000            	// #2139095040
 22c:	fmov	s1, w8
 230:	fcmp	s0, s1
 234:	b.eq	2e0 <__divsc3+0x2e0>  // b.none
 238:	b.vs	2e0 <__divsc3+0x2e0>
 23c:	b	240 <__divsc3+0x240>
 240:	ldur	s0, [x29, #-12]
 244:	fabs	s1, s0
 248:	mov	w8, #0x7f800000            	// #2139095040
 24c:	fmov	s2, w8
 250:	fcmp	s1, s2
 254:	fmov	s1, wzr
 258:	fmov	s3, #1.000000000000000000e+00
 25c:	fcsel	s4, s3, s1, eq  // eq = none
 260:	mov	v5.16b, v0.16b
 264:	mov	v6.16b, v4.16b
 268:	movi	v7.4s, #0x80, lsl #24
 26c:	bit	v6.16b, v5.16b, v7.16b
 270:	stur	s6, [x29, #-12]
 274:	ldur	s0, [x29, #-16]
 278:	fabs	s4, s0
 27c:	fcmp	s4, s2
 280:	fcsel	s1, s3, s1, eq  // eq = none
 284:	mov	v5.16b, v0.16b
 288:	mov	v16.16b, v1.16b
 28c:	bit	v16.16b, v5.16b, v7.16b
 290:	stur	s16, [x29, #-16]
 294:	ldur	s0, [x29, #-12]
 298:	ldur	s1, [x29, #-20]
 29c:	fmul	s0, s0, s1
 2a0:	ldur	s1, [x29, #-16]
 2a4:	ldur	s3, [x29, #-24]
 2a8:	fmul	s1, s1, s3
 2ac:	fadd	s0, s0, s1
 2b0:	fmul	s0, s0, s2
 2b4:	str	s0, [sp, #16]
 2b8:	ldur	s0, [x29, #-16]
 2bc:	ldur	s1, [x29, #-20]
 2c0:	fmul	s0, s0, s1
 2c4:	ldur	s1, [x29, #-12]
 2c8:	ldur	s3, [x29, #-24]
 2cc:	fmul	s1, s1, s3
 2d0:	fsub	s0, s0, s1
 2d4:	fmul	s0, s0, s2
 2d8:	str	s0, [sp, #20]
 2dc:	b	3f0 <__divsc3+0x3f0>
 2e0:	ldr	s0, [sp, #32]
 2e4:	fabs	s0, s0
 2e8:	mov	w8, #0x7f800000            	// #2139095040
 2ec:	fmov	s1, w8
 2f0:	fcmp	s0, s1
 2f4:	b.ne	3ec <__divsc3+0x3ec>  // b.any
 2f8:	b	2fc <__divsc3+0x2fc>
 2fc:	ldr	s0, [sp, #32]
 300:	fcmp	s0, #0.0
 304:	b.le	3ec <__divsc3+0x3ec>
 308:	b	30c <__divsc3+0x30c>
 30c:	ldur	s0, [x29, #-12]
 310:	fabs	s0, s0
 314:	mov	w8, #0x7f800000            	// #2139095040
 318:	fmov	s1, w8
 31c:	fcmp	s0, s1
 320:	b.eq	3ec <__divsc3+0x3ec>  // b.none
 324:	b.vs	3ec <__divsc3+0x3ec>
 328:	b	32c <__divsc3+0x32c>
 32c:	ldur	s0, [x29, #-16]
 330:	fabs	s0, s0
 334:	mov	w8, #0x7f800000            	// #2139095040
 338:	fmov	s1, w8
 33c:	fcmp	s0, s1
 340:	b.eq	3ec <__divsc3+0x3ec>  // b.none
 344:	b.vs	3ec <__divsc3+0x3ec>
 348:	b	34c <__divsc3+0x34c>
 34c:	ldur	s0, [x29, #-20]
 350:	fabs	s1, s0
 354:	mov	w8, #0x7f800000            	// #2139095040
 358:	fmov	s2, w8
 35c:	fcmp	s1, s2
 360:	fmov	s1, wzr
 364:	fmov	s3, #1.000000000000000000e+00
 368:	fcsel	s4, s3, s1, eq  // eq = none
 36c:	mov	v5.16b, v0.16b
 370:	mov	v6.16b, v4.16b
 374:	movi	v7.4s, #0x80, lsl #24
 378:	bit	v6.16b, v5.16b, v7.16b
 37c:	stur	s6, [x29, #-20]
 380:	ldur	s0, [x29, #-24]
 384:	fabs	s4, s0
 388:	fcmp	s4, s2
 38c:	fcsel	s2, s3, s1, eq  // eq = none
 390:	mov	v5.16b, v0.16b
 394:	mov	v16.16b, v2.16b
 398:	bit	v16.16b, v5.16b, v7.16b
 39c:	stur	s16, [x29, #-24]
 3a0:	ldur	s0, [x29, #-12]
 3a4:	ldur	s2, [x29, #-20]
 3a8:	fmul	s0, s0, s2
 3ac:	ldur	s2, [x29, #-16]
 3b0:	ldur	s3, [x29, #-24]
 3b4:	fmul	s2, s2, s3
 3b8:	fadd	s0, s0, s2
 3bc:	fmul	s0, s0, s1
 3c0:	str	s0, [sp, #16]
 3c4:	ldur	s0, [x29, #-16]
 3c8:	ldur	s2, [x29, #-20]
 3cc:	fmul	s0, s0, s2
 3d0:	ldur	s2, [x29, #-12]
 3d4:	ldur	s3, [x29, #-24]
 3d8:	fmul	s2, s2, s3
 3dc:	fsub	s0, s0, s2
 3e0:	fmul	s0, s0, s1
 3e4:	str	s0, [sp, #20]
 3e8:	b	3ec <__divsc3+0x3ec>
 3ec:	b	3f0 <__divsc3+0x3f0>
 3f0:	b	3f4 <__divsc3+0x3f4>
 3f4:	b	3f8 <__divsc3+0x3f8>
 3f8:	ldr	s0, [sp, #16]
 3fc:	ldr	s1, [sp, #20]
 400:	stur	s0, [x29, #-8]
 404:	stur	s1, [x29, #-4]
 408:	ldur	s0, [x29, #-8]
 40c:	ldur	s1, [x29, #-4]
 410:	ldp	x29, x30, [sp, #64]
 414:	add	sp, sp, #0x50
 418:	ret

000000000000041c <__compiler_rt_logbf>:
 41c:	sub	sp, sp, #0x20
 420:	stp	x29, x30, [sp, #16]
 424:	add	x29, sp, #0x10
 428:	stur	s0, [x29, #-4]
 42c:	ldur	s0, [x29, #-4]
 430:	bl	440 <__compiler_rt_logbX>
 434:	ldp	x29, x30, [sp, #16]
 438:	add	sp, sp, #0x20
 43c:	ret

0000000000000440 <__compiler_rt_logbX>:
 440:	sub	sp, sp, #0x30
 444:	stp	x29, x30, [sp, #32]
 448:	add	x29, sp, #0x20
 44c:	stur	s0, [x29, #-8]
 450:	ldur	s0, [x29, #-8]
 454:	bl	554 <toRep>
 458:	stur	w0, [x29, #-12]
 45c:	ldur	w8, [x29, #-12]
 460:	and	w8, w8, #0x7f800000
 464:	lsr	w8, w8, #23
 468:	str	w8, [sp, #16]
 46c:	ldr	w8, [sp, #16]
 470:	cmp	w8, #0xff
 474:	b.ne	4b8 <__compiler_rt_logbX+0x78>  // b.any
 478:	ldur	w8, [x29, #-12]
 47c:	and	w8, w8, #0x80000000
 480:	cbz	w8, 49c <__compiler_rt_logbX+0x5c>
 484:	ldur	s0, [x29, #-8]
 488:	ldur	s1, [x29, #-8]
 48c:	fcmp	s0, s1
 490:	cset	w8, ne  // ne = any
 494:	tbnz	w8, #0, 49c <__compiler_rt_logbX+0x5c>
 498:	b	4a8 <__compiler_rt_logbX+0x68>
 49c:	ldur	w8, [x29, #-8]
 4a0:	stur	w8, [x29, #-4]
 4a4:	b	544 <__compiler_rt_logbX+0x104>
 4a8:	ldur	s0, [x29, #-8]
 4ac:	fneg	s0, s0
 4b0:	stur	s0, [x29, #-4]
 4b4:	b	544 <__compiler_rt_logbX+0x104>
 4b8:	ldur	s0, [x29, #-8]
 4bc:	fcvt	d1, s0
 4c0:	fcmp	d1, #0.0
 4c4:	cset	w8, eq  // eq = none
 4c8:	tbnz	w8, #0, 4d0 <__compiler_rt_logbX+0x90>
 4cc:	b	4e0 <__compiler_rt_logbX+0xa0>
 4d0:	mov	w0, #0xff800000            	// #-8388608
 4d4:	bl	570 <fromRep>
 4d8:	stur	s0, [x29, #-4]
 4dc:	b	544 <__compiler_rt_logbX+0x104>
 4e0:	ldr	w8, [sp, #16]
 4e4:	cbz	w8, 4fc <__compiler_rt_logbX+0xbc>
 4e8:	ldr	w8, [sp, #16]
 4ec:	subs	w8, w8, #0x7f
 4f0:	scvtf	s0, w8
 4f4:	stur	s0, [x29, #-4]
 4f8:	b	544 <__compiler_rt_logbX+0x104>
 4fc:	sub	x0, x29, #0xc
 500:	ldur	w8, [x29, #-12]
 504:	and	w8, w8, #0x7fffffff
 508:	stur	w8, [x29, #-12]
 50c:	bl	58c <normalize>
 510:	mov	w8, #0x1                   	// #1
 514:	subs	w8, w8, w0
 518:	str	w8, [sp, #12]
 51c:	ldur	w8, [x29, #-12]
 520:	and	w8, w8, #0x7f800000
 524:	lsr	w8, w8, #23
 528:	str	w8, [sp, #16]
 52c:	ldr	w8, [sp, #16]
 530:	subs	w8, w8, #0x7f
 534:	ldr	w9, [sp, #12]
 538:	subs	w8, w8, w9
 53c:	scvtf	s0, w8
 540:	stur	s0, [x29, #-4]
 544:	ldur	s0, [x29, #-4]
 548:	ldp	x29, x30, [sp, #32]
 54c:	add	sp, sp, #0x30
 550:	ret

0000000000000554 <toRep>:
 554:	sub	sp, sp, #0x10
 558:	str	s0, [sp, #12]
 55c:	ldr	w8, [sp, #12]
 560:	str	w8, [sp, #8]
 564:	ldr	w0, [sp, #8]
 568:	add	sp, sp, #0x10
 56c:	ret

0000000000000570 <fromRep>:
 570:	sub	sp, sp, #0x10
 574:	str	w0, [sp, #12]
 578:	ldr	w8, [sp, #12]
 57c:	str	w8, [sp, #8]
 580:	ldr	s0, [sp, #8]
 584:	add	sp, sp, #0x10
 588:	ret

000000000000058c <normalize>:
 58c:	sub	sp, sp, #0x30
 590:	stp	x29, x30, [sp, #32]
 594:	add	x29, sp, #0x20
 598:	mov	w8, #0x800000              	// #8388608
 59c:	mov	w9, #0x1                   	// #1
 5a0:	stur	x0, [x29, #-8]
 5a4:	ldur	x10, [x29, #-8]
 5a8:	ldr	w0, [x10]
 5ac:	str	w8, [sp, #16]
 5b0:	str	w9, [sp, #12]
 5b4:	bl	600 <rep_clz>
 5b8:	ldr	w8, [sp, #16]
 5bc:	str	w0, [sp, #8]
 5c0:	mov	w0, w8
 5c4:	bl	600 <rep_clz>
 5c8:	ldr	w8, [sp, #8]
 5cc:	subs	w9, w8, w0
 5d0:	stur	w9, [x29, #-12]
 5d4:	ldur	w9, [x29, #-12]
 5d8:	ldur	x10, [x29, #-8]
 5dc:	ldr	w11, [x10]
 5e0:	lsl	w9, w11, w9
 5e4:	str	w9, [x10]
 5e8:	ldur	w9, [x29, #-12]
 5ec:	ldr	w11, [sp, #12]
 5f0:	subs	w0, w11, w9
 5f4:	ldp	x29, x30, [sp, #32]
 5f8:	add	sp, sp, #0x30
 5fc:	ret

0000000000000600 <rep_clz>:
 600:	sub	sp, sp, #0x10
 604:	str	w0, [sp, #12]
 608:	ldr	w8, [sp, #12]
 60c:	clz	w0, w8
 610:	add	sp, sp, #0x10
 614:	ret

divsf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divsf3>:
   0:	sub	sp, sp, #0x80
   4:	stp	x29, x30, [sp, #112]
   8:	add	x29, sp, #0x70
   c:	stur	s0, [x29, #-8]
  10:	stur	s1, [x29, #-12]
  14:	ldur	s0, [x29, #-8]
  18:	bl	4d4 <toRep>
  1c:	mov	x8, #0x17                  	// #23
  20:	lsr	w9, w0, #23
  24:	and	w9, w9, #0xff
  28:	stur	w9, [x29, #-16]
  2c:	ldur	s0, [x29, #-12]
  30:	str	x8, [sp, #16]
  34:	bl	4d4 <toRep>
  38:	ldr	x8, [sp, #16]
  3c:	lsr	w8, w0, w8
  40:	and	w8, w8, #0xff
  44:	stur	w8, [x29, #-20]
  48:	ldur	s0, [x29, #-8]
  4c:	bl	4d4 <toRep>
  50:	ldur	s0, [x29, #-12]
  54:	str	w0, [sp, #12]
  58:	bl	4d4 <toRep>
  5c:	ldr	w8, [sp, #12]
  60:	eor	w9, w8, w0
  64:	and	w9, w9, #0x80000000
  68:	stur	w9, [x29, #-24]
  6c:	ldur	s0, [x29, #-8]
  70:	bl	4d4 <toRep>
  74:	and	w8, w0, #0x7fffff
  78:	stur	w8, [x29, #-28]
  7c:	ldur	s0, [x29, #-12]
  80:	bl	4d4 <toRep>
  84:	and	w8, w0, #0x7fffff
  88:	stur	w8, [x29, #-32]
  8c:	stur	wzr, [x29, #-36]
  90:	ldur	w8, [x29, #-16]
  94:	subs	w8, w8, #0x1
  98:	cmp	w8, #0xfe
  9c:	b.cs	b0 <__divsf3+0xb0>  // b.hs, b.nlast
  a0:	ldur	w8, [x29, #-20]
  a4:	subs	w8, w8, #0x1
  a8:	cmp	w8, #0xfe
  ac:	b.cc	218 <__divsf3+0x218>  // b.lo, b.ul, b.last
  b0:	ldur	s0, [x29, #-8]
  b4:	bl	4d4 <toRep>
  b8:	and	w8, w0, #0x7fffffff
  bc:	stur	w8, [x29, #-40]
  c0:	ldur	s0, [x29, #-12]
  c4:	bl	4d4 <toRep>
  c8:	and	w8, w0, #0x7fffffff
  cc:	stur	w8, [x29, #-44]
  d0:	ldur	w8, [x29, #-40]
  d4:	mov	w9, #0x7f800000            	// #2139095040
  d8:	cmp	w8, w9
  dc:	b.ls	f8 <__divsf3+0xf8>  // b.plast
  e0:	ldur	s0, [x29, #-8]
  e4:	bl	4d4 <toRep>
  e8:	orr	w0, w0, #0x400000
  ec:	bl	4f0 <fromRep>
  f0:	stur	s0, [x29, #-4]
  f4:	b	4c4 <__divsf3+0x4c4>
  f8:	ldur	w8, [x29, #-44]
  fc:	mov	w9, #0x7f800000            	// #2139095040
 100:	cmp	w8, w9
 104:	b.ls	120 <__divsf3+0x120>  // b.plast
 108:	ldur	s0, [x29, #-12]
 10c:	bl	4d4 <toRep>
 110:	orr	w0, w0, #0x400000
 114:	bl	4f0 <fromRep>
 118:	stur	s0, [x29, #-4]
 11c:	b	4c4 <__divsf3+0x4c4>
 120:	ldur	w8, [x29, #-40]
 124:	mov	w9, #0x7f800000            	// #2139095040
 128:	cmp	w8, w9
 12c:	b.ne	168 <__divsf3+0x168>  // b.any
 130:	ldur	w8, [x29, #-44]
 134:	mov	w9, #0x7f800000            	// #2139095040
 138:	cmp	w8, w9
 13c:	b.ne	150 <__divsf3+0x150>  // b.any
 140:	mov	w0, #0x7fc00000            	// #2143289344
 144:	bl	4f0 <fromRep>
 148:	stur	s0, [x29, #-4]
 14c:	b	4c4 <__divsf3+0x4c4>
 150:	ldur	w8, [x29, #-40]
 154:	ldur	w9, [x29, #-24]
 158:	orr	w0, w8, w9
 15c:	bl	4f0 <fromRep>
 160:	stur	s0, [x29, #-4]
 164:	b	4c4 <__divsf3+0x4c4>
 168:	ldur	w8, [x29, #-44]
 16c:	mov	w9, #0x7f800000            	// #2139095040
 170:	cmp	w8, w9
 174:	b.ne	188 <__divsf3+0x188>  // b.any
 178:	ldur	w0, [x29, #-24]
 17c:	bl	4f0 <fromRep>
 180:	stur	s0, [x29, #-4]
 184:	b	4c4 <__divsf3+0x4c4>
 188:	ldur	w8, [x29, #-40]
 18c:	cbnz	w8, 1b8 <__divsf3+0x1b8>
 190:	ldur	w8, [x29, #-44]
 194:	cbnz	w8, 1a8 <__divsf3+0x1a8>
 198:	mov	w0, #0x7fc00000            	// #2143289344
 19c:	bl	4f0 <fromRep>
 1a0:	stur	s0, [x29, #-4]
 1a4:	b	4c4 <__divsf3+0x4c4>
 1a8:	ldur	w0, [x29, #-24]
 1ac:	bl	4f0 <fromRep>
 1b0:	stur	s0, [x29, #-4]
 1b4:	b	4c4 <__divsf3+0x4c4>
 1b8:	ldur	w8, [x29, #-44]
 1bc:	cbnz	w8, 1d8 <__divsf3+0x1d8>
 1c0:	ldur	w8, [x29, #-24]
 1c4:	mov	w9, #0x7f800000            	// #2139095040
 1c8:	orr	w0, w9, w8
 1cc:	bl	4f0 <fromRep>
 1d0:	stur	s0, [x29, #-4]
 1d4:	b	4c4 <__divsf3+0x4c4>
 1d8:	ldur	w8, [x29, #-40]
 1dc:	cmp	w8, #0x800, lsl #12
 1e0:	b.cs	1f8 <__divsf3+0x1f8>  // b.hs, b.nlast
 1e4:	sub	x0, x29, #0x1c
 1e8:	bl	50c <normalize>
 1ec:	ldur	w8, [x29, #-36]
 1f0:	add	w8, w8, w0
 1f4:	stur	w8, [x29, #-36]
 1f8:	ldur	w8, [x29, #-44]
 1fc:	cmp	w8, #0x800, lsl #12
 200:	b.cs	218 <__divsf3+0x218>  // b.hs, b.nlast
 204:	sub	x0, x29, #0x20
 208:	bl	50c <normalize>
 20c:	ldur	w8, [x29, #-36]
 210:	subs	w8, w8, w0
 214:	stur	w8, [x29, #-36]
 218:	ldur	w8, [x29, #-28]
 21c:	orr	w8, w8, #0x800000
 220:	stur	w8, [x29, #-28]
 224:	ldur	w8, [x29, #-32]
 228:	orr	w8, w8, #0x800000
 22c:	stur	w8, [x29, #-32]
 230:	ldur	w8, [x29, #-16]
 234:	ldur	w9, [x29, #-20]
 238:	subs	w8, w8, w9
 23c:	ldur	w9, [x29, #-36]
 240:	add	w8, w8, w9
 244:	stur	w8, [x29, #-48]
 248:	ldur	w8, [x29, #-32]
 24c:	lsl	w8, w8, #8
 250:	stur	w8, [x29, #-52]
 254:	ldur	w8, [x29, #-52]
 258:	mov	w9, #0xf333                	// #62259
 25c:	movk	w9, #0x7504, lsl #16
 260:	subs	w8, w9, w8
 264:	str	w8, [sp, #56]
 268:	ldr	w8, [sp, #56]
 26c:	mov	w10, w8
 270:	ldur	w8, [x29, #-52]
 274:	mov	w11, w8
 278:	mul	x10, x10, x11
 27c:	mov	x11, xzr
 280:	subs	x10, x11, x10, lsr #32
 284:	str	w10, [sp, #52]
 288:	ldr	w8, [sp, #56]
 28c:	mov	w12, w8
 290:	ldr	w8, [sp, #52]
 294:	mov	w13, w8
 298:	mul	x12, x12, x13
 29c:	lsr	x12, x12, #31
 2a0:	str	w12, [sp, #56]
 2a4:	ldr	w8, [sp, #56]
 2a8:	mov	w13, w8
 2ac:	ldur	w8, [x29, #-52]
 2b0:	mov	w14, w8
 2b4:	mul	x13, x13, x14
 2b8:	subs	x13, x11, x13, lsr #32
 2bc:	str	w13, [sp, #52]
 2c0:	ldr	w8, [sp, #56]
 2c4:	mov	w14, w8
 2c8:	ldr	w8, [sp, #52]
 2cc:	mov	w15, w8
 2d0:	mul	x14, x14, x15
 2d4:	lsr	x14, x14, #31
 2d8:	str	w14, [sp, #56]
 2dc:	ldr	w8, [sp, #56]
 2e0:	mov	w15, w8
 2e4:	ldur	w8, [x29, #-52]
 2e8:	mov	w16, w8
 2ec:	mul	x15, x15, x16
 2f0:	subs	x11, x11, x15, lsr #32
 2f4:	str	w11, [sp, #52]
 2f8:	ldr	w8, [sp, #56]
 2fc:	mov	w15, w8
 300:	ldr	w8, [sp, #52]
 304:	mov	w16, w8
 308:	mul	x15, x15, x16
 30c:	lsr	x15, x15, #31
 310:	str	w15, [sp, #56]
 314:	ldr	w8, [sp, #56]
 318:	subs	w8, w8, #0x2
 31c:	str	w8, [sp, #56]
 320:	ldr	w8, [sp, #56]
 324:	mov	w16, w8
 328:	ldur	w8, [x29, #-28]
 32c:	lsl	w8, w8, #1
 330:	mov	w17, w8
 334:	ubfx	x17, x17, #0, #32
 338:	mul	x16, x16, x17
 33c:	lsr	x16, x16, #32
 340:	str	w16, [sp, #48]
 344:	ldr	w8, [sp, #48]
 348:	mov	w9, #0x1000000             	// #16777216
 34c:	cmp	w8, w9
 350:	b.cs	380 <__divsf3+0x380>  // b.hs, b.nlast
 354:	ldur	w8, [x29, #-28]
 358:	lsl	w8, w8, #24
 35c:	ldr	w9, [sp, #48]
 360:	ldur	w10, [x29, #-32]
 364:	mul	w9, w9, w10
 368:	subs	w8, w8, w9
 36c:	str	w8, [sp, #44]
 370:	ldur	w8, [x29, #-48]
 374:	subs	w8, w8, #0x1
 378:	stur	w8, [x29, #-48]
 37c:	b	3a8 <__divsf3+0x3a8>
 380:	ldr	w8, [sp, #48]
 384:	lsr	w8, w8, #1
 388:	str	w8, [sp, #48]
 38c:	ldur	w8, [x29, #-28]
 390:	lsl	w8, w8, #23
 394:	ldr	w9, [sp, #48]
 398:	ldur	w10, [x29, #-32]
 39c:	mul	w9, w9, w10
 3a0:	subs	w8, w8, w9
 3a4:	str	w8, [sp, #44]
 3a8:	ldur	w8, [x29, #-48]
 3ac:	add	w8, w8, #0x7f
 3b0:	str	w8, [sp, #40]
 3b4:	ldr	w8, [sp, #40]
 3b8:	cmp	w8, #0xff
 3bc:	b.lt	3d8 <__divsf3+0x3d8>  // b.tstop
 3c0:	ldur	w8, [x29, #-24]
 3c4:	mov	w9, #0x7f800000            	// #2139095040
 3c8:	orr	w0, w9, w8
 3cc:	bl	4f0 <fromRep>
 3d0:	stur	s0, [x29, #-4]
 3d4:	b	4c4 <__divsf3+0x4c4>
 3d8:	ldr	w8, [sp, #40]
 3dc:	cmp	w8, #0x1
 3e0:	b.ge	460 <__divsf3+0x460>  // b.tcont
 3e4:	ldr	w8, [sp, #40]
 3e8:	cbnz	w8, 450 <__divsf3+0x450>
 3ec:	ldr	w8, [sp, #44]
 3f0:	lsl	w8, w8, #1
 3f4:	ldur	w9, [x29, #-32]
 3f8:	cmp	w8, w9
 3fc:	cset	w8, hi  // hi = pmore
 400:	mov	w9, #0x1                   	// #1
 404:	and	w8, w8, w9
 408:	strb	w8, [sp, #39]
 40c:	ldr	w8, [sp, #48]
 410:	and	w8, w8, #0x7fffff
 414:	str	w8, [sp, #32]
 418:	ldrb	w8, [sp, #39]
 41c:	and	w8, w8, #0x1
 420:	ldr	w9, [sp, #32]
 424:	add	w8, w9, w8
 428:	str	w8, [sp, #32]
 42c:	ldr	w8, [sp, #32]
 430:	and	w8, w8, #0xff800000
 434:	cbz	w8, 450 <__divsf3+0x450>
 438:	ldr	w8, [sp, #32]
 43c:	ldur	w9, [x29, #-24]
 440:	orr	w0, w8, w9
 444:	bl	4f0 <fromRep>
 448:	stur	s0, [x29, #-4]
 44c:	b	4c4 <__divsf3+0x4c4>
 450:	ldur	w0, [x29, #-24]
 454:	bl	4f0 <fromRep>
 458:	stur	s0, [x29, #-4]
 45c:	b	4c4 <__divsf3+0x4c4>
 460:	ldr	w8, [sp, #44]
 464:	lsl	w8, w8, #1
 468:	ldur	w9, [x29, #-32]
 46c:	cmp	w8, w9
 470:	cset	w8, hi  // hi = pmore
 474:	mov	w9, #0x1                   	// #1
 478:	and	w8, w8, w9
 47c:	strb	w8, [sp, #31]
 480:	ldr	w8, [sp, #48]
 484:	and	w8, w8, #0x7fffff
 488:	str	w8, [sp, #24]
 48c:	ldr	w8, [sp, #40]
 490:	ldr	w9, [sp, #24]
 494:	orr	w8, w9, w8, lsl #23
 498:	str	w8, [sp, #24]
 49c:	ldrb	w8, [sp, #31]
 4a0:	and	w8, w8, #0x1
 4a4:	ldr	w9, [sp, #24]
 4a8:	add	w8, w9, w8
 4ac:	str	w8, [sp, #24]
 4b0:	ldr	w8, [sp, #24]
 4b4:	ldur	w9, [x29, #-24]
 4b8:	orr	w0, w8, w9
 4bc:	bl	4f0 <fromRep>
 4c0:	stur	s0, [x29, #-4]
 4c4:	ldur	s0, [x29, #-4]
 4c8:	ldp	x29, x30, [sp, #112]
 4cc:	add	sp, sp, #0x80
 4d0:	ret

00000000000004d4 <toRep>:
 4d4:	sub	sp, sp, #0x10
 4d8:	str	s0, [sp, #12]
 4dc:	ldr	w8, [sp, #12]
 4e0:	str	w8, [sp, #8]
 4e4:	ldr	w0, [sp, #8]
 4e8:	add	sp, sp, #0x10
 4ec:	ret

00000000000004f0 <fromRep>:
 4f0:	sub	sp, sp, #0x10
 4f4:	str	w0, [sp, #12]
 4f8:	ldr	w8, [sp, #12]
 4fc:	str	w8, [sp, #8]
 500:	ldr	s0, [sp, #8]
 504:	add	sp, sp, #0x10
 508:	ret

000000000000050c <normalize>:
 50c:	sub	sp, sp, #0x30
 510:	stp	x29, x30, [sp, #32]
 514:	add	x29, sp, #0x20
 518:	mov	w8, #0x800000              	// #8388608
 51c:	mov	w9, #0x1                   	// #1
 520:	stur	x0, [x29, #-8]
 524:	ldur	x10, [x29, #-8]
 528:	ldr	w0, [x10]
 52c:	str	w8, [sp, #16]
 530:	str	w9, [sp, #12]
 534:	bl	580 <rep_clz>
 538:	ldr	w8, [sp, #16]
 53c:	str	w0, [sp, #8]
 540:	mov	w0, w8
 544:	bl	580 <rep_clz>
 548:	ldr	w8, [sp, #8]
 54c:	subs	w9, w8, w0
 550:	stur	w9, [x29, #-12]
 554:	ldur	w9, [x29, #-12]
 558:	ldur	x10, [x29, #-8]
 55c:	ldr	w11, [x10]
 560:	lsl	w9, w11, w9
 564:	str	w9, [x10]
 568:	ldur	w9, [x29, #-12]
 56c:	ldr	w11, [sp, #12]
 570:	subs	w0, w11, w9
 574:	ldp	x29, x30, [sp, #32]
 578:	add	sp, sp, #0x30
 57c:	ret

0000000000000580 <rep_clz>:
 580:	sub	sp, sp, #0x10
 584:	str	w0, [sp, #12]
 588:	ldr	w8, [sp, #12]
 58c:	clz	w0, w8
 590:	add	sp, sp, #0x10
 594:	ret

divsi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divsi3>:
   0:	sub	sp, sp, #0x20
   4:	mov	w8, #0x1f                  	// #31
   8:	str	w0, [sp, #28]
   c:	str	w1, [sp, #24]
  10:	str	w8, [sp, #20]
  14:	ldr	w8, [sp, #28]
  18:	mov	x9, #0x1f                  	// #31
  1c:	asr	w8, w8, #31
  20:	str	w8, [sp, #16]
  24:	ldr	w8, [sp, #24]
  28:	asr	w8, w8, w9
  2c:	str	w8, [sp, #12]
  30:	ldr	w8, [sp, #28]
  34:	ldr	w9, [sp, #16]
  38:	eor	w8, w8, w9
  3c:	ldr	w9, [sp, #16]
  40:	subs	w8, w8, w9
  44:	str	w8, [sp, #28]
  48:	ldr	w8, [sp, #24]
  4c:	ldr	w9, [sp, #12]
  50:	eor	w8, w8, w9
  54:	ldr	w9, [sp, #12]
  58:	subs	w8, w8, w9
  5c:	str	w8, [sp, #24]
  60:	ldr	w8, [sp, #12]
  64:	ldr	w9, [sp, #16]
  68:	eor	w8, w9, w8
  6c:	str	w8, [sp, #16]
  70:	ldr	w8, [sp, #28]
  74:	ldr	w9, [sp, #24]
  78:	udiv	w8, w8, w9
  7c:	ldr	w9, [sp, #16]
  80:	eor	w8, w8, w9
  84:	ldr	w9, [sp, #16]
  88:	subs	w0, w8, w9
  8c:	add	sp, sp, #0x20
  90:	ret

divtc3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divtc3>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	str	x28, [sp, #16]
   8:	mov	x29, sp
   c:	sub	sp, sp, #0x560
  10:	stur	q0, [x29, #-48]
  14:	stur	q1, [x29, #-64]
  18:	stur	q2, [x29, #-80]
  1c:	stur	q3, [x29, #-96]
  20:	mov	w8, wzr
  24:	stur	w8, [x29, #-100]
  28:	ldur	q0, [x29, #-80]
  2c:	stur	q0, [x29, #-208]
  30:	ldurb	w8, [x29, #-193]
  34:	and	w8, w8, #0x7f
  38:	sturb	w8, [x29, #-193]
  3c:	ldur	q0, [x29, #-208]
  40:	ldur	q1, [x29, #-96]
  44:	stur	q1, [x29, #-224]
  48:	ldurb	w8, [x29, #-209]
  4c:	and	w8, w8, #0x7f
  50:	sturb	w8, [x29, #-209]
  54:	ldur	q1, [x29, #-224]
  58:	bl	0 <fmaxl>
  5c:	bl	804 <__compiler_rt_logbl>
  60:	stur	q0, [x29, #-128]
  64:	ldur	q0, [x29, #-128]
  68:	stur	q0, [x29, #-192]
  6c:	ldurb	w8, [x29, #-177]
  70:	and	w8, w8, #0x7f
  74:	sturb	w8, [x29, #-177]
  78:	ldur	q0, [x29, #-192]
  7c:	adrp	x9, 0 <__divtc3>
  80:	ldr	q1, [x9]
  84:	str	q0, [sp, #768]
  88:	str	q1, [sp, #752]
  8c:	bl	0 <__eqtf2>
  90:	subs	w8, w0, #0x0
  94:	cset	w10, eq  // eq = none
  98:	ldr	q0, [sp, #768]
  9c:	ldr	q1, [sp, #752]
  a0:	str	w8, [sp, #748]
  a4:	str	w10, [sp, #744]
  a8:	bl	0 <__unordtf2>
  ac:	subs	w8, w0, #0x0
  b0:	cset	w10, ne  // ne = any
  b4:	ldr	w11, [sp, #744]
  b8:	orr	w10, w10, w11
  bc:	cbnz	w10, 108 <__divtc3+0x108>
  c0:	b	c4 <__divtc3+0xc4>
  c4:	ldur	q0, [x29, #-128]
  c8:	bl	0 <__fixtfsi>
  cc:	stur	w0, [x29, #-100]
  d0:	ldur	q0, [x29, #-80]
  d4:	ldur	w8, [x29, #-100]
  d8:	mov	w9, wzr
  dc:	subs	w0, w9, w8
  e0:	str	w9, [sp, #740]
  e4:	bl	0 <scalbnl>
  e8:	stur	q0, [x29, #-80]
  ec:	ldur	q0, [x29, #-96]
  f0:	ldur	w8, [x29, #-100]
  f4:	ldr	w9, [sp, #740]
  f8:	subs	w0, w9, w8
  fc:	bl	0 <scalbnl>
 100:	stur	q0, [x29, #-96]
 104:	b	108 <__divtc3+0x108>
 108:	ldur	q0, [x29, #-80]
 10c:	str	q0, [sp, #720]
 110:	ldr	q1, [sp, #720]
 114:	bl	0 <__multf3>
 118:	ldur	q1, [x29, #-96]
 11c:	str	q0, [sp, #704]
 120:	mov	v0.16b, v1.16b
 124:	bl	0 <__multf3>
 128:	ldr	q1, [sp, #704]
 12c:	str	q0, [sp, #688]
 130:	mov	v0.16b, v1.16b
 134:	ldr	q1, [sp, #688]
 138:	bl	0 <__addtf3>
 13c:	stur	q0, [x29, #-144]
 140:	ldur	q0, [x29, #-48]
 144:	ldur	q1, [x29, #-80]
 148:	bl	0 <__multf3>
 14c:	ldur	q1, [x29, #-64]
 150:	ldur	q2, [x29, #-96]
 154:	str	q0, [sp, #672]
 158:	mov	v0.16b, v1.16b
 15c:	mov	v1.16b, v2.16b
 160:	bl	0 <__multf3>
 164:	ldr	q1, [sp, #672]
 168:	str	q0, [sp, #656]
 16c:	mov	v0.16b, v1.16b
 170:	ldr	q1, [sp, #656]
 174:	bl	0 <__addtf3>
 178:	ldur	q1, [x29, #-144]
 17c:	bl	0 <__divtf3>
 180:	ldur	w8, [x29, #-100]
 184:	mov	w9, wzr
 188:	subs	w0, w9, w8
 18c:	str	w9, [sp, #652]
 190:	bl	0 <scalbnl>
 194:	stur	q0, [x29, #-176]
 198:	ldur	q0, [x29, #-64]
 19c:	ldur	q1, [x29, #-80]
 1a0:	bl	0 <__multf3>
 1a4:	ldur	q1, [x29, #-48]
 1a8:	ldur	q2, [x29, #-96]
 1ac:	str	q0, [sp, #624]
 1b0:	mov	v0.16b, v1.16b
 1b4:	mov	v1.16b, v2.16b
 1b8:	bl	0 <__multf3>
 1bc:	ldr	q1, [sp, #624]
 1c0:	str	q0, [sp, #608]
 1c4:	mov	v0.16b, v1.16b
 1c8:	ldr	q1, [sp, #608]
 1cc:	bl	0 <__subtf3>
 1d0:	ldur	q1, [x29, #-144]
 1d4:	bl	0 <__divtf3>
 1d8:	ldur	w8, [x29, #-100]
 1dc:	ldr	w9, [sp, #652]
 1e0:	subs	w0, w9, w8
 1e4:	bl	0 <scalbnl>
 1e8:	stur	q0, [x29, #-160]
 1ec:	ldur	q0, [x29, #-176]
 1f0:	str	q0, [sp, #592]
 1f4:	ldr	q1, [sp, #592]
 1f8:	bl	0 <__unordtf2>
 1fc:	cbz	w0, 7dc <__divtc3+0x7dc>
 200:	b	204 <__divtc3+0x204>
 204:	ldur	q0, [x29, #-160]
 208:	str	q0, [sp, #576]
 20c:	ldr	q1, [sp, #576]
 210:	bl	0 <__unordtf2>
 214:	cbz	w0, 7dc <__divtc3+0x7dc>
 218:	b	21c <__divtc3+0x21c>
 21c:	ldur	q0, [x29, #-144]
 220:	adrp	x8, 0 <__divtc3>
 224:	ldr	q1, [x8]
 228:	bl	0 <__netf2>
 22c:	cbnz	w0, 2d8 <__divtc3+0x2d8>
 230:	b	234 <__divtc3+0x234>
 234:	ldur	q0, [x29, #-48]
 238:	str	q0, [sp, #560]
 23c:	ldr	q1, [sp, #560]
 240:	bl	0 <__unordtf2>
 244:	cbz	w0, 264 <__divtc3+0x264>
 248:	b	24c <__divtc3+0x24c>
 24c:	ldur	q0, [x29, #-64]
 250:	str	q0, [sp, #544]
 254:	ldr	q1, [sp, #544]
 258:	bl	0 <__unordtf2>
 25c:	cbnz	w0, 2d8 <__divtc3+0x2d8>
 260:	b	264 <__divtc3+0x264>
 264:	ldur	q0, [x29, #-80]
 268:	str	q0, [sp, #1104]
 26c:	adrp	x8, 0 <__divtc3>
 270:	ldr	q0, [x8]
 274:	str	q0, [sp, #1088]
 278:	ldrb	w9, [sp, #1119]
 27c:	ldrb	w10, [sp, #1103]
 280:	bfxil	w9, w10, #0, #7
 284:	strb	w9, [sp, #1103]
 288:	ldr	q1, [sp, #1088]
 28c:	ldur	q2, [x29, #-48]
 290:	str	q0, [sp, #528]
 294:	mov	v0.16b, v1.16b
 298:	mov	v1.16b, v2.16b
 29c:	bl	0 <__multf3>
 2a0:	stur	q0, [x29, #-176]
 2a4:	ldur	q0, [x29, #-80]
 2a8:	ldr	q1, [sp, #528]
 2ac:	stur	q1, [x29, #-256]
 2b0:	stur	q0, [x29, #-240]
 2b4:	ldurb	w9, [x29, #-241]
 2b8:	ldurb	w10, [x29, #-225]
 2bc:	bfxil	w10, w9, #0, #7
 2c0:	sturb	w10, [x29, #-241]
 2c4:	ldur	q0, [x29, #-256]
 2c8:	ldur	q1, [x29, #-64]
 2cc:	bl	0 <__multf3>
 2d0:	stur	q0, [x29, #-160]
 2d4:	b	7d8 <__divtc3+0x7d8>
 2d8:	ldur	q0, [x29, #-48]
 2dc:	str	q0, [sp, #1072]
 2e0:	ldrb	w8, [sp, #1087]
 2e4:	and	w8, w8, #0x7f
 2e8:	strb	w8, [sp, #1087]
 2ec:	ldr	q0, [sp, #1072]
 2f0:	adrp	x9, 0 <__divtc3>
 2f4:	ldr	q1, [x9]
 2f8:	bl	0 <__eqtf2>
 2fc:	cbz	w0, 330 <__divtc3+0x330>
 300:	b	304 <__divtc3+0x304>
 304:	ldur	q0, [x29, #-64]
 308:	str	q0, [sp, #1056]
 30c:	ldrb	w8, [sp, #1071]
 310:	and	w8, w8, #0x7f
 314:	strb	w8, [sp, #1071]
 318:	ldr	q0, [sp, #1056]
 31c:	adrp	x9, 0 <__divtc3>
 320:	ldr	q1, [x9]
 324:	bl	0 <__netf2>
 328:	cbnz	w0, 558 <__divtc3+0x558>
 32c:	b	330 <__divtc3+0x330>
 330:	ldur	q0, [x29, #-80]
 334:	str	q0, [sp, #1040]
 338:	ldrb	w8, [sp, #1055]
 33c:	and	w8, w8, #0x7f
 340:	strb	w8, [sp, #1055]
 344:	ldr	q0, [sp, #1040]
 348:	adrp	x9, 0 <__divtc3>
 34c:	ldr	q1, [x9]
 350:	str	q0, [sp, #512]
 354:	str	q1, [sp, #496]
 358:	bl	0 <__eqtf2>
 35c:	subs	w8, w0, #0x0
 360:	cset	w10, eq  // eq = none
 364:	ldr	q0, [sp, #512]
 368:	ldr	q1, [sp, #496]
 36c:	str	w8, [sp, #492]
 370:	str	w10, [sp, #488]
 374:	bl	0 <__unordtf2>
 378:	subs	w8, w0, #0x0
 37c:	cset	w10, ne  // ne = any
 380:	ldr	w11, [sp, #488]
 384:	orr	w10, w10, w11
 388:	cbnz	w10, 558 <__divtc3+0x558>
 38c:	b	390 <__divtc3+0x390>
 390:	ldur	q0, [x29, #-96]
 394:	str	q0, [sp, #1024]
 398:	ldrb	w8, [sp, #1039]
 39c:	and	w8, w8, #0x7f
 3a0:	strb	w8, [sp, #1039]
 3a4:	ldr	q0, [sp, #1024]
 3a8:	adrp	x9, 0 <__divtc3>
 3ac:	ldr	q1, [x9]
 3b0:	str	q0, [sp, #464]
 3b4:	str	q1, [sp, #448]
 3b8:	bl	0 <__eqtf2>
 3bc:	subs	w8, w0, #0x0
 3c0:	cset	w10, eq  // eq = none
 3c4:	ldr	q0, [sp, #464]
 3c8:	ldr	q1, [sp, #448]
 3cc:	str	w8, [sp, #444]
 3d0:	str	w10, [sp, #440]
 3d4:	bl	0 <__unordtf2>
 3d8:	subs	w8, w0, #0x0
 3dc:	cset	w10, ne  // ne = any
 3e0:	ldr	w11, [sp, #440]
 3e4:	orr	w10, w10, w11
 3e8:	cbnz	w10, 558 <__divtc3+0x558>
 3ec:	b	3f0 <__divtc3+0x3f0>
 3f0:	ldur	q0, [x29, #-48]
 3f4:	str	q0, [sp, #784]
 3f8:	ldrb	w8, [sp, #799]
 3fc:	and	w8, w8, #0x7f
 400:	strb	w8, [sp, #799]
 404:	ldr	q1, [sp, #784]
 408:	adrp	x9, 0 <__divtc3>
 40c:	ldr	q2, [x9]
 410:	str	q0, [sp, #416]
 414:	mov	v0.16b, v1.16b
 418:	mov	v1.16b, v2.16b
 41c:	str	q2, [sp, #400]
 420:	bl	0 <__eqtf2>
 424:	subs	w8, w0, #0x0
 428:	fmov	d3, xzr
 42c:	fmov	d4, #1.000000000000000000e+00
 430:	fcsel	d0, d4, d3, eq  // eq = none
 434:	str	w8, [sp, #396]
 438:	str	d3, [sp, #384]
 43c:	str	d4, [sp, #376]
 440:	bl	0 <__extenddftf2>
 444:	ldr	q1, [sp, #416]
 448:	str	q1, [sp, #816]
 44c:	str	q0, [sp, #800]
 450:	ldrb	w8, [sp, #831]
 454:	ldrb	w10, [sp, #815]
 458:	bfxil	w8, w10, #0, #7
 45c:	strb	w8, [sp, #815]
 460:	ldr	q0, [sp, #800]
 464:	stur	q0, [x29, #-48]
 468:	ldur	q0, [x29, #-64]
 46c:	str	q0, [sp, #832]
 470:	ldrb	w8, [sp, #847]
 474:	and	w8, w8, #0x7f
 478:	strb	w8, [sp, #847]
 47c:	ldr	q2, [sp, #832]
 480:	str	q0, [sp, #352]
 484:	mov	v0.16b, v2.16b
 488:	ldr	q1, [sp, #400]
 48c:	bl	0 <__eqtf2>
 490:	subs	w8, w0, #0x0
 494:	ldr	d3, [sp, #376]
 498:	ldr	d4, [sp, #384]
 49c:	fcsel	d0, d3, d4, eq  // eq = none
 4a0:	str	w8, [sp, #348]
 4a4:	bl	0 <__extenddftf2>
 4a8:	ldr	q1, [sp, #352]
 4ac:	str	q1, [sp, #864]
 4b0:	str	q0, [sp, #848]
 4b4:	ldrb	w8, [sp, #879]
 4b8:	ldrb	w10, [sp, #863]
 4bc:	bfxil	w8, w10, #0, #7
 4c0:	strb	w8, [sp, #863]
 4c4:	ldr	q0, [sp, #848]
 4c8:	stur	q0, [x29, #-64]
 4cc:	ldur	q0, [x29, #-48]
 4d0:	ldur	q1, [x29, #-80]
 4d4:	bl	0 <__multf3>
 4d8:	ldur	q1, [x29, #-64]
 4dc:	ldur	q2, [x29, #-96]
 4e0:	str	q0, [sp, #320]
 4e4:	mov	v0.16b, v1.16b
 4e8:	mov	v1.16b, v2.16b
 4ec:	bl	0 <__multf3>
 4f0:	ldr	q1, [sp, #320]
 4f4:	str	q0, [sp, #304]
 4f8:	mov	v0.16b, v1.16b
 4fc:	ldr	q1, [sp, #304]
 500:	bl	0 <__addtf3>
 504:	ldr	q1, [sp, #400]
 508:	bl	0 <__multf3>
 50c:	stur	q0, [x29, #-176]
 510:	ldur	q0, [x29, #-64]
 514:	ldur	q1, [x29, #-80]
 518:	bl	0 <__multf3>
 51c:	ldur	q1, [x29, #-48]
 520:	ldur	q2, [x29, #-96]
 524:	str	q0, [sp, #288]
 528:	mov	v0.16b, v1.16b
 52c:	mov	v1.16b, v2.16b
 530:	bl	0 <__multf3>
 534:	ldr	q1, [sp, #288]
 538:	str	q0, [sp, #272]
 53c:	mov	v0.16b, v1.16b
 540:	ldr	q1, [sp, #272]
 544:	bl	0 <__subtf3>
 548:	ldr	q1, [sp, #400]
 54c:	bl	0 <__multf3>
 550:	stur	q0, [x29, #-160]
 554:	b	7d4 <__divtc3+0x7d4>
 558:	ldur	q0, [x29, #-128]
 55c:	str	q0, [sp, #1008]
 560:	ldrb	w8, [sp, #1023]
 564:	and	w8, w8, #0x7f
 568:	strb	w8, [sp, #1023]
 56c:	ldr	q0, [sp, #1008]
 570:	adrp	x9, 0 <__divtc3>
 574:	ldr	q1, [x9]
 578:	bl	0 <__netf2>
 57c:	cbnz	w0, 7d0 <__divtc3+0x7d0>
 580:	b	584 <__divtc3+0x584>
 584:	ldur	q0, [x29, #-128]
 588:	adrp	x8, 0 <__divtc3>
 58c:	ldr	q1, [x8]
 590:	bl	0 <__gttf2>
 594:	subs	w9, w0, #0x0
 598:	b.le	7d0 <__divtc3+0x7d0>
 59c:	b	5a0 <__divtc3+0x5a0>
 5a0:	ldur	q0, [x29, #-48]
 5a4:	str	q0, [sp, #992]
 5a8:	ldrb	w8, [sp, #1007]
 5ac:	and	w8, w8, #0x7f
 5b0:	strb	w8, [sp, #1007]
 5b4:	ldr	q0, [sp, #992]
 5b8:	adrp	x9, 0 <__divtc3>
 5bc:	ldr	q1, [x9]
 5c0:	str	q0, [sp, #256]
 5c4:	str	q1, [sp, #240]
 5c8:	bl	0 <__eqtf2>
 5cc:	subs	w8, w0, #0x0
 5d0:	cset	w10, eq  // eq = none
 5d4:	ldr	q0, [sp, #256]
 5d8:	ldr	q1, [sp, #240]
 5dc:	str	w8, [sp, #236]
 5e0:	str	w10, [sp, #232]
 5e4:	bl	0 <__unordtf2>
 5e8:	subs	w8, w0, #0x0
 5ec:	cset	w10, ne  // ne = any
 5f0:	ldr	w11, [sp, #232]
 5f4:	orr	w10, w10, w11
 5f8:	cbnz	w10, 7d0 <__divtc3+0x7d0>
 5fc:	b	600 <__divtc3+0x600>
 600:	ldur	q0, [x29, #-64]
 604:	str	q0, [sp, #976]
 608:	ldrb	w8, [sp, #991]
 60c:	and	w8, w8, #0x7f
 610:	strb	w8, [sp, #991]
 614:	ldr	q0, [sp, #976]
 618:	adrp	x9, 0 <__divtc3>
 61c:	ldr	q1, [x9]
 620:	str	q0, [sp, #208]
 624:	str	q1, [sp, #192]
 628:	bl	0 <__eqtf2>
 62c:	subs	w8, w0, #0x0
 630:	cset	w10, eq  // eq = none
 634:	ldr	q0, [sp, #208]
 638:	ldr	q1, [sp, #192]
 63c:	str	w8, [sp, #188]
 640:	str	w10, [sp, #184]
 644:	bl	0 <__unordtf2>
 648:	subs	w8, w0, #0x0
 64c:	cset	w10, ne  // ne = any
 650:	ldr	w11, [sp, #184]
 654:	orr	w10, w10, w11
 658:	cbnz	w10, 7d0 <__divtc3+0x7d0>
 65c:	b	660 <__divtc3+0x660>
 660:	ldur	q0, [x29, #-80]
 664:	str	q0, [sp, #880]
 668:	ldrb	w8, [sp, #895]
 66c:	and	w8, w8, #0x7f
 670:	strb	w8, [sp, #895]
 674:	ldr	q1, [sp, #880]
 678:	adrp	x9, 0 <__divtc3>
 67c:	ldr	q2, [x9]
 680:	str	q0, [sp, #160]
 684:	mov	v0.16b, v1.16b
 688:	mov	v1.16b, v2.16b
 68c:	str	q2, [sp, #144]
 690:	bl	0 <__eqtf2>
 694:	subs	w8, w0, #0x0
 698:	fmov	d3, xzr
 69c:	fmov	d4, #1.000000000000000000e+00
 6a0:	fcsel	d0, d4, d3, eq  // eq = none
 6a4:	str	w8, [sp, #140]
 6a8:	str	d3, [sp, #128]
 6ac:	str	d4, [sp, #120]
 6b0:	bl	0 <__extenddftf2>
 6b4:	ldr	q1, [sp, #160]
 6b8:	str	q1, [sp, #912]
 6bc:	str	q0, [sp, #896]
 6c0:	ldrb	w8, [sp, #927]
 6c4:	ldrb	w10, [sp, #911]
 6c8:	bfxil	w8, w10, #0, #7
 6cc:	strb	w8, [sp, #911]
 6d0:	ldr	q0, [sp, #896]
 6d4:	stur	q0, [x29, #-80]
 6d8:	ldur	q0, [x29, #-96]
 6dc:	str	q0, [sp, #928]
 6e0:	ldrb	w8, [sp, #943]
 6e4:	and	w8, w8, #0x7f
 6e8:	strb	w8, [sp, #943]
 6ec:	ldr	q2, [sp, #928]
 6f0:	str	q0, [sp, #96]
 6f4:	mov	v0.16b, v2.16b
 6f8:	ldr	q1, [sp, #144]
 6fc:	bl	0 <__eqtf2>
 700:	subs	w8, w0, #0x0
 704:	ldr	d3, [sp, #120]
 708:	ldr	d4, [sp, #128]
 70c:	fcsel	d0, d3, d4, eq  // eq = none
 710:	str	w8, [sp, #92]
 714:	bl	0 <__extenddftf2>
 718:	ldr	q1, [sp, #96]
 71c:	str	q1, [sp, #960]
 720:	str	q0, [sp, #944]
 724:	ldrb	w8, [sp, #975]
 728:	ldrb	w10, [sp, #959]
 72c:	bfxil	w8, w10, #0, #7
 730:	strb	w8, [sp, #959]
 734:	ldr	q0, [sp, #944]
 738:	stur	q0, [x29, #-96]
 73c:	ldur	q0, [x29, #-48]
 740:	ldur	q1, [x29, #-80]
 744:	bl	0 <__multf3>
 748:	ldur	q1, [x29, #-64]
 74c:	ldur	q2, [x29, #-96]
 750:	str	q0, [sp, #64]
 754:	mov	v0.16b, v1.16b
 758:	mov	v1.16b, v2.16b
 75c:	bl	0 <__multf3>
 760:	ldr	q1, [sp, #64]
 764:	str	q0, [sp, #48]
 768:	mov	v0.16b, v1.16b
 76c:	ldr	q1, [sp, #48]
 770:	bl	0 <__addtf3>
 774:	adrp	x9, 0 <__divtc3>
 778:	ldr	q1, [x9]
 77c:	str	q1, [sp, #32]
 780:	bl	0 <__multf3>
 784:	stur	q0, [x29, #-176]
 788:	ldur	q0, [x29, #-64]
 78c:	ldur	q1, [x29, #-80]
 790:	bl	0 <__multf3>
 794:	ldur	q1, [x29, #-48]
 798:	ldur	q2, [x29, #-96]
 79c:	str	q0, [sp, #16]
 7a0:	mov	v0.16b, v1.16b
 7a4:	mov	v1.16b, v2.16b
 7a8:	bl	0 <__multf3>
 7ac:	ldr	q1, [sp, #16]
 7b0:	str	q0, [sp]
 7b4:	mov	v0.16b, v1.16b
 7b8:	ldr	q1, [sp]
 7bc:	bl	0 <__subtf3>
 7c0:	ldr	q1, [sp, #32]
 7c4:	bl	0 <__multf3>
 7c8:	stur	q0, [x29, #-160]
 7cc:	b	7d0 <__divtc3+0x7d0>
 7d0:	b	7d4 <__divtc3+0x7d4>
 7d4:	b	7d8 <__divtc3+0x7d8>
 7d8:	b	7dc <__divtc3+0x7dc>
 7dc:	ldur	q0, [x29, #-176]
 7e0:	ldur	q1, [x29, #-160]
 7e4:	stur	q0, [x29, #-32]
 7e8:	stur	q1, [x29, #-16]
 7ec:	ldur	q0, [x29, #-32]
 7f0:	ldur	q1, [x29, #-16]
 7f4:	add	sp, sp, #0x560
 7f8:	ldr	x28, [sp, #16]
 7fc:	ldp	x29, x30, [sp], #32
 800:	ret

0000000000000804 <__compiler_rt_logbl>:
 804:	sub	sp, sp, #0x20
 808:	stp	x29, x30, [sp, #16]
 80c:	add	x29, sp, #0x10
 810:	str	q0, [sp]
 814:	ldr	q0, [sp]
 818:	bl	828 <__compiler_rt_logbX>
 81c:	ldp	x29, x30, [sp, #16]
 820:	add	sp, sp, #0x20
 824:	ret

0000000000000828 <__compiler_rt_logbX>:
 828:	sub	sp, sp, #0x60
 82c:	stp	x29, x30, [sp, #80]
 830:	add	x29, sp, #0x50
 834:	stur	q0, [x29, #-32]
 838:	ldur	q0, [x29, #-32]
 83c:	bl	960 <toRep>
 840:	str	x1, [sp, #40]
 844:	str	x0, [sp, #32]
 848:	ldr	x8, [sp, #40]
 84c:	ubfx	x8, x8, #48, #15
 850:	str	w8, [sp, #28]
 854:	ldr	w8, [sp, #28]
 858:	mov	w9, #0x7fff                	// #32767
 85c:	subs	w8, w8, w9
 860:	b.ne	8b0 <__compiler_rt_logbX+0x88>  // b.any
 864:	b	868 <__compiler_rt_logbX+0x40>
 868:	ldrb	w8, [sp, #47]
 86c:	tbz	w8, #7, 88c <__compiler_rt_logbX+0x64>
 870:	b	874 <__compiler_rt_logbX+0x4c>
 874:	ldur	q0, [x29, #-32]
 878:	str	q0, [sp]
 87c:	ldr	q1, [sp]
 880:	bl	0 <__unordtf2>
 884:	cbz	w0, 898 <__compiler_rt_logbX+0x70>
 888:	b	88c <__compiler_rt_logbX+0x64>
 88c:	ldur	q0, [x29, #-32]
 890:	stur	q0, [x29, #-16]
 894:	b	950 <__compiler_rt_logbX+0x128>
 898:	ldur	q1, [x29, #-32]
 89c:	adrp	x8, 0 <__divtc3>
 8a0:	ldr	q0, [x8]
 8a4:	bl	0 <__subtf3>
 8a8:	stur	q0, [x29, #-16]
 8ac:	b	950 <__compiler_rt_logbX+0x128>
 8b0:	ldur	q0, [x29, #-32]
 8b4:	adrp	x8, 0 <__divtc3>
 8b8:	ldr	q1, [x8]
 8bc:	bl	0 <__netf2>
 8c0:	cbnz	w0, 8dc <__compiler_rt_logbX+0xb4>
 8c4:	b	8c8 <__compiler_rt_logbX+0xa0>
 8c8:	mov	x0, xzr
 8cc:	mov	x1, #0xffff000000000000    	// #-281474976710656
 8d0:	bl	980 <fromRep>
 8d4:	stur	q0, [x29, #-16]
 8d8:	b	950 <__compiler_rt_logbX+0x128>
 8dc:	b	8e0 <__compiler_rt_logbX+0xb8>
 8e0:	ldr	w8, [sp, #28]
 8e4:	cbz	w8, 904 <__compiler_rt_logbX+0xdc>
 8e8:	b	8ec <__compiler_rt_logbX+0xc4>
 8ec:	ldr	w8, [sp, #28]
 8f0:	mov	w9, #0xffffc001            	// #-16383
 8f4:	add	w0, w8, w9
 8f8:	bl	0 <__floatsitf>
 8fc:	stur	q0, [x29, #-16]
 900:	b	950 <__compiler_rt_logbX+0x128>
 904:	ldr	x8, [sp, #40]
 908:	and	x8, x8, #0x7fffffffffffffff
 90c:	str	x8, [sp, #40]
 910:	add	x0, sp, #0x20
 914:	bl	9a4 <normalize>
 918:	mov	w9, #0x1                   	// #1
 91c:	subs	w9, w9, w0
 920:	str	w9, [sp, #24]
 924:	ldr	x8, [sp, #40]
 928:	ubfx	x8, x8, #48, #15
 92c:	str	w8, [sp, #28]
 930:	ldr	w8, [sp, #28]
 934:	ldr	w9, [sp, #24]
 938:	subs	w8, w8, w9
 93c:	mov	w9, #0xffffc001            	// #-16383
 940:	add	w0, w8, w9
 944:	bl	0 <__floatsitf>
 948:	stur	q0, [x29, #-16]
 94c:	b	950 <__compiler_rt_logbX+0x128>
 950:	ldur	q0, [x29, #-16]
 954:	ldp	x29, x30, [sp, #80]
 958:	add	sp, sp, #0x60
 95c:	ret

0000000000000960 <toRep>:
 960:	sub	sp, sp, #0x20
 964:	str	q0, [sp, #16]
 968:	ldr	q0, [sp, #16]
 96c:	str	q0, [sp]
 970:	ldr	x0, [sp]
 974:	ldr	x1, [sp, #8]
 978:	add	sp, sp, #0x20
 97c:	ret

0000000000000980 <fromRep>:
 980:	sub	sp, sp, #0x20
 984:	mov	v0.d[0], x0
 988:	mov	v0.d[1], x1
 98c:	str	q0, [sp, #16]
 990:	ldr	q0, [sp, #16]
 994:	str	q0, [sp]
 998:	ldr	q0, [sp]
 99c:	add	sp, sp, #0x20
 9a0:	ret

00000000000009a4 <normalize>:
 9a4:	sub	sp, sp, #0x40
 9a8:	stp	x29, x30, [sp, #48]
 9ac:	add	x29, sp, #0x30
 9b0:	mov	x8, xzr
 9b4:	mov	x1, #0x1000000000000       	// #281474976710656
 9b8:	mov	w9, #0x1                   	// #1
 9bc:	stur	x0, [x29, #-8]
 9c0:	ldur	x10, [x29, #-8]
 9c4:	ldr	q0, [x10]
 9c8:	mov	v1.16b, v0.16b
 9cc:	mov	d2, v0.d[1]
 9d0:	fmov	x0, d1
 9d4:	str	x1, [sp, #24]
 9d8:	fmov	x1, d2
 9dc:	str	x8, [sp, #16]
 9e0:	str	w9, [sp, #12]
 9e4:	bl	abc <rep_clz>
 9e8:	ldr	x8, [sp, #16]
 9ec:	str	w0, [sp, #8]
 9f0:	mov	x0, x8
 9f4:	ldr	x1, [sp, #24]
 9f8:	bl	abc <rep_clz>
 9fc:	ldr	w9, [sp, #8]
 a00:	subs	w11, w9, w0
 a04:	stur	w11, [x29, #-12]
 a08:	ldur	w11, [x29, #-12]
 a0c:	mov	w8, w11
 a10:	mov	v0.d[0], x8
 a14:	ldr	x8, [sp, #16]
 a18:	mov	v0.d[1], x8
 a1c:	ldur	x10, [x29, #-8]
 a20:	ldr	q3, [x10]
 a24:	mov	x12, #0x40                  	// #64
 a28:	mov	v1.16b, v3.16b
 a2c:	mov	d2, v3.d[1]
 a30:	fmov	x13, d0
 a34:	subs	x13, x13, #0x40
 a38:	fmov	x14, d0
 a3c:	subs	x12, x12, x14
 a40:	fmov	x14, d0
 a44:	cmp	x14, #0x40
 a48:	cset	w11, cc  // cc = lo, ul, last
 a4c:	fmov	x14, d0
 a50:	fmov	x15, d1
 a54:	fmov	x16, d0
 a58:	lsl	x15, x15, x16
 a5c:	fmov	x16, d1
 a60:	lsr	x12, x16, x12
 a64:	fmov	x16, d2
 a68:	fmov	x17, d0
 a6c:	lsl	x16, x16, x17
 a70:	orr	x12, x12, x16
 a74:	fmov	x16, d1
 a78:	lsl	x13, x16, x13
 a7c:	tst	w11, #0x1
 a80:	csel	x15, x15, x8, ne  // ne = any
 a84:	tst	w11, #0x1
 a88:	csel	x12, x12, x13, ne  // ne = any
 a8c:	fmov	x13, d2
 a90:	cmp	x14, #0x0
 a94:	csel	x12, x13, x12, eq  // eq = none
 a98:	mov	v3.d[0], x15
 a9c:	mov	v3.d[1], x12
 aa0:	str	q3, [x10]
 aa4:	ldur	w11, [x29, #-12]
 aa8:	ldr	w18, [sp, #12]
 aac:	subs	w0, w18, w11
 ab0:	ldp	x29, x30, [sp, #48]
 ab4:	add	sp, sp, #0x40
 ab8:	ret

0000000000000abc <rep_clz>:
 abc:	sub	sp, sp, #0x30
 ac0:	mov	v0.d[0], x0
 ac4:	mov	v0.d[1], x1
 ac8:	str	q0, [sp, #32]
 acc:	ldr	q0, [sp, #32]
 ad0:	str	q0, [sp, #16]
 ad4:	ldr	x8, [sp, #24]
 ad8:	cbz	x8, aec <rep_clz+0x30>
 adc:	ldr	x8, [sp, #24]
 ae0:	str	x8, [sp, #8]
 ae4:	str	xzr, [sp]
 ae8:	b	afc <rep_clz+0x40>
 aec:	ldr	x8, [sp, #16]
 af0:	str	x8, [sp, #8]
 af4:	mov	x8, #0x40                  	// #64
 af8:	str	x8, [sp]
 afc:	ldr	x8, [sp, #8]
 b00:	clz	x8, x8
 b04:	lsl	x8, x8, #32
 b08:	ldr	x9, [sp]
 b0c:	add	x8, x9, x8, asr #32
 b10:	mov	w0, w8
 b14:	add	sp, sp, #0x30
 b18:	ret

divti3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divti3>:
   0:	sub	sp, sp, #0x60
   4:	stp	x29, x30, [sp, #80]
   8:	add	x29, sp, #0x50
   c:	stur	x1, [x29, #-8]
  10:	stur	x0, [x29, #-16]
  14:	stur	x3, [x29, #-24]
  18:	stur	x2, [x29, #-32]
  1c:	mov	w8, #0x7f                  	// #127
  20:	stur	w8, [x29, #-36]
  24:	ldur	x9, [x29, #-8]
  28:	asr	x9, x9, #63
  2c:	str	x9, [sp, #24]
  30:	str	x9, [sp, #16]
  34:	ldur	x9, [x29, #-24]
  38:	asr	x9, x9, #63
  3c:	str	x9, [sp, #8]
  40:	str	x9, [sp]
  44:	ldur	x9, [x29, #-16]
  48:	ldur	x10, [x29, #-8]
  4c:	ldr	x11, [sp, #16]
  50:	ldr	x12, [sp, #24]
  54:	eor	x10, x10, x12
  58:	eor	x9, x9, x11
  5c:	subs	x9, x9, x11
  60:	sbcs	x10, x10, x12
  64:	stur	x9, [x29, #-16]
  68:	stur	x10, [x29, #-8]
  6c:	ldur	x9, [x29, #-32]
  70:	ldur	x10, [x29, #-24]
  74:	ldr	x11, [sp]
  78:	ldr	x12, [sp, #8]
  7c:	eor	x10, x10, x12
  80:	eor	x9, x9, x11
  84:	subs	x9, x9, x11
  88:	sbcs	x10, x10, x12
  8c:	stur	x9, [x29, #-32]
  90:	stur	x10, [x29, #-24]
  94:	ldr	x9, [sp, #8]
  98:	ldr	x10, [sp]
  9c:	ldr	x11, [sp, #24]
  a0:	ldr	x12, [sp, #16]
  a4:	eor	x10, x12, x10
  a8:	eor	x9, x11, x9
  ac:	str	x9, [sp, #24]
  b0:	str	x10, [sp, #16]
  b4:	ldur	x1, [x29, #-8]
  b8:	ldur	x0, [x29, #-16]
  bc:	ldur	x3, [x29, #-24]
  c0:	ldur	x2, [x29, #-32]
  c4:	mov	x4, xzr
  c8:	bl	0 <__udivmodti4>
  cc:	ldr	x9, [sp, #16]
  d0:	ldr	x10, [sp, #24]
  d4:	eor	x11, x1, x10
  d8:	eor	x12, x0, x9
  dc:	subs	x0, x12, x9
  e0:	sbcs	x1, x11, x10
  e4:	ldp	x29, x30, [sp, #80]
  e8:	add	sp, sp, #0x60
  ec:	ret

divtf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__divtf3>:
   0:	stp	x29, x30, [sp, #-32]!
   4:	str	x28, [sp, #16]
   8:	mov	x29, sp
   c:	sub	sp, sp, #0x230
  10:	stur	q0, [x29, #-32]
  14:	stur	q1, [x29, #-48]
  18:	ldur	q0, [x29, #-32]
  1c:	bl	7d8 <toRep>
  20:	ubfx	x8, x1, #48, #15
  24:	stur	w8, [x29, #-52]
  28:	ldur	q0, [x29, #-48]
  2c:	str	x0, [sp, #72]
  30:	bl	7d8 <toRep>
  34:	ubfx	x9, x1, #48, #15
  38:	stur	w9, [x29, #-56]
  3c:	ldur	q0, [x29, #-32]
  40:	str	x0, [sp, #64]
  44:	bl	7d8 <toRep>
  48:	ldur	q0, [x29, #-48]
  4c:	str	x0, [sp, #56]
  50:	str	x1, [sp, #48]
  54:	bl	7d8 <toRep>
  58:	ldr	x10, [sp, #48]
  5c:	eor	x11, x10, x1
  60:	and	x11, x11, #0x8000000000000000
  64:	mov	x12, xzr
  68:	stur	x12, [x29, #-80]
  6c:	stur	x11, [x29, #-72]
  70:	ldur	q0, [x29, #-32]
  74:	str	x0, [sp, #40]
  78:	bl	7d8 <toRep>
  7c:	and	x10, x1, #0xffffffffffff
  80:	stur	x0, [x29, #-96]
  84:	stur	x10, [x29, #-88]
  88:	ldur	q0, [x29, #-48]
  8c:	bl	7d8 <toRep>
  90:	and	x10, x1, #0xffffffffffff
  94:	stur	x0, [x29, #-112]
  98:	stur	x10, [x29, #-104]
  9c:	mov	w8, wzr
  a0:	stur	w8, [x29, #-116]
  a4:	ldur	w8, [x29, #-52]
  a8:	subs	w8, w8, #0x1
  ac:	mov	w9, #0x7ffd                	// #32765
  b0:	subs	w8, w8, w9
  b4:	b.hi	d4 <__divtf3+0xd4>  // b.pmore
  b8:	b	bc <__divtf3+0xbc>
  bc:	ldur	w8, [x29, #-56]
  c0:	subs	w8, w8, #0x1
  c4:	mov	w9, #0x7ffe                	// #32766
  c8:	subs	w8, w8, w9
  cc:	b.cc	2e0 <__divtf3+0x2e0>  // b.lo, b.ul, b.last
  d0:	b	d4 <__divtf3+0xd4>
  d4:	ldur	q0, [x29, #-32]
  d8:	bl	7d8 <toRep>
  dc:	and	x8, x1, #0x7fffffffffffffff
  e0:	stur	x0, [x29, #-144]
  e4:	stur	x8, [x29, #-136]
  e8:	ldur	q0, [x29, #-48]
  ec:	bl	7d8 <toRep>
  f0:	and	x8, x1, #0x7fffffffffffffff
  f4:	stur	x0, [x29, #-160]
  f8:	stur	x8, [x29, #-152]
  fc:	ldur	x8, [x29, #-136]
 100:	ldur	x9, [x29, #-144]
 104:	subs	x9, x9, #0x0
 108:	cset	w10, eq  // eq = none
 10c:	mov	x11, #0x7fff000000000000    	// #9223090561878065152
 110:	subs	x8, x8, x11
 114:	cset	w12, cc  // cc = lo, ul, last
 118:	csel	w10, w10, w12, eq  // eq = none
 11c:	tbnz	w10, #0, 13c <__divtf3+0x13c>
 120:	b	124 <__divtf3+0x124>
 124:	ldur	q0, [x29, #-32]
 128:	bl	7d8 <toRep>
 12c:	orr	x1, x1, #0x800000000000
 130:	bl	7f8 <fromRep>
 134:	stur	q0, [x29, #-16]
 138:	b	7c4 <__divtf3+0x7c4>
 13c:	ldur	x8, [x29, #-152]
 140:	ldur	x9, [x29, #-160]
 144:	subs	x9, x9, #0x0
 148:	cset	w10, eq  // eq = none
 14c:	mov	x11, #0x7fff000000000000    	// #9223090561878065152
 150:	subs	x8, x8, x11
 154:	cset	w12, cc  // cc = lo, ul, last
 158:	csel	w10, w10, w12, eq  // eq = none
 15c:	tbnz	w10, #0, 17c <__divtf3+0x17c>
 160:	b	164 <__divtf3+0x164>
 164:	ldur	q0, [x29, #-48]
 168:	bl	7d8 <toRep>
 16c:	orr	x1, x1, #0x800000000000
 170:	bl	7f8 <fromRep>
 174:	stur	q0, [x29, #-16]
 178:	b	7c4 <__divtf3+0x7c4>
 17c:	ldur	x8, [x29, #-144]
 180:	ldur	x9, [x29, #-136]
 184:	eor	x9, x9, #0x7fff000000000000
 188:	orr	x8, x8, x9
 18c:	cbnz	x8, 1e4 <__divtf3+0x1e4>
 190:	b	194 <__divtf3+0x194>
 194:	ldur	x8, [x29, #-160]
 198:	ldur	x9, [x29, #-152]
 19c:	eor	x9, x9, #0x7fff000000000000
 1a0:	orr	x8, x8, x9
 1a4:	cbnz	x8, 1c0 <__divtf3+0x1c0>
 1a8:	b	1ac <__divtf3+0x1ac>
 1ac:	mov	x0, xzr
 1b0:	mov	x1, #0x7fff800000000000    	// #9223231299366420480
 1b4:	bl	7f8 <fromRep>
 1b8:	stur	q0, [x29, #-16]
 1bc:	b	7c4 <__divtf3+0x7c4>
 1c0:	ldur	x8, [x29, #-136]
 1c4:	ldur	x9, [x29, #-144]
 1c8:	ldur	x10, [x29, #-72]
 1cc:	ldur	x11, [x29, #-80]
 1d0:	orr	x0, x9, x11
 1d4:	orr	x1, x8, x10
 1d8:	bl	7f8 <fromRep>
 1dc:	stur	q0, [x29, #-16]
 1e0:	b	7c4 <__divtf3+0x7c4>
 1e4:	ldur	x8, [x29, #-160]
 1e8:	ldur	x9, [x29, #-152]
 1ec:	eor	x9, x9, #0x7fff000000000000
 1f0:	orr	x8, x8, x9
 1f4:	cbnz	x8, 210 <__divtf3+0x210>
 1f8:	b	1fc <__divtf3+0x1fc>
 1fc:	ldur	x1, [x29, #-72]
 200:	ldur	x0, [x29, #-80]
 204:	bl	7f8 <fromRep>
 208:	stur	q0, [x29, #-16]
 20c:	b	7c4 <__divtf3+0x7c4>
 210:	ldur	x8, [x29, #-136]
 214:	ldur	x9, [x29, #-144]
 218:	orr	x8, x9, x8
 21c:	cbnz	x8, 260 <__divtf3+0x260>
 220:	b	224 <__divtf3+0x224>
 224:	ldur	x8, [x29, #-152]
 228:	ldur	x9, [x29, #-160]
 22c:	orr	x8, x9, x8
 230:	cbnz	x8, 24c <__divtf3+0x24c>
 234:	b	238 <__divtf3+0x238>
 238:	mov	x0, xzr
 23c:	mov	x1, #0x7fff800000000000    	// #9223231299366420480
 240:	bl	7f8 <fromRep>
 244:	stur	q0, [x29, #-16]
 248:	b	7c4 <__divtf3+0x7c4>
 24c:	ldur	x1, [x29, #-72]
 250:	ldur	x0, [x29, #-80]
 254:	bl	7f8 <fromRep>
 258:	stur	q0, [x29, #-16]
 25c:	b	7c4 <__divtf3+0x7c4>
 260:	ldur	x8, [x29, #-152]
 264:	ldur	x9, [x29, #-160]
 268:	orr	x8, x9, x8
 26c:	cbnz	x8, 28c <__divtf3+0x28c>
 270:	b	274 <__divtf3+0x274>
 274:	ldur	x0, [x29, #-80]
 278:	ldur	x8, [x29, #-72]
 27c:	orr	x1, x8, #0x7fff000000000000
 280:	bl	7f8 <fromRep>
 284:	stur	q0, [x29, #-16]
 288:	b	7c4 <__divtf3+0x7c4>
 28c:	ldurh	w8, [x29, #-130]
 290:	mov	w9, w8
 294:	cbnz	x9, 2b4 <__divtf3+0x2b4>
 298:	b	29c <__divtf3+0x29c>
 29c:	sub	x0, x29, #0x60
 2a0:	bl	81c <normalize>
 2a4:	ldur	w8, [x29, #-116]
 2a8:	add	w8, w8, w0
 2ac:	stur	w8, [x29, #-116]
 2b0:	b	2b4 <__divtf3+0x2b4>
 2b4:	ldurh	w8, [x29, #-146]
 2b8:	mov	w9, w8
 2bc:	cbnz	x9, 2dc <__divtf3+0x2dc>
 2c0:	b	2c4 <__divtf3+0x2c4>
 2c4:	sub	x0, x29, #0x70
 2c8:	bl	81c <normalize>
 2cc:	ldur	w8, [x29, #-116]
 2d0:	subs	w8, w8, w0
 2d4:	stur	w8, [x29, #-116]
 2d8:	b	2dc <__divtf3+0x2dc>
 2dc:	b	2e0 <__divtf3+0x2e0>
 2e0:	ldur	x8, [x29, #-88]
 2e4:	orr	x8, x8, #0x1000000000000
 2e8:	stur	x8, [x29, #-88]
 2ec:	ldur	x8, [x29, #-104]
 2f0:	orr	x8, x8, #0x1000000000000
 2f4:	stur	x8, [x29, #-104]
 2f8:	ldur	w9, [x29, #-52]
 2fc:	ldur	w10, [x29, #-56]
 300:	subs	w9, w9, w10
 304:	ldur	w10, [x29, #-116]
 308:	add	w9, w9, w10
 30c:	stur	w9, [x29, #-164]
 310:	ldur	x8, [x29, #-112]
 314:	ldur	x11, [x29, #-104]
 318:	extr	x8, x11, x8, #49
 31c:	stur	x8, [x29, #-176]
 320:	ldur	x8, [x29, #-176]
 324:	mov	x11, #0x6484                	// #25732
 328:	movk	x11, #0xf9de, lsl #16
 32c:	movk	x11, #0xf333, lsl #32
 330:	movk	x11, #0x7504, lsl #48
 334:	subs	x8, x11, x8
 338:	stur	x8, [x29, #-184]
 33c:	ldur	x8, [x29, #-184]
 340:	ldur	x11, [x29, #-176]
 344:	umulh	x8, x8, x11
 348:	mov	x11, xzr
 34c:	subs	x8, x11, x8
 350:	stur	x8, [x29, #-192]
 354:	ldur	x8, [x29, #-184]
 358:	ldur	x12, [x29, #-192]
 35c:	mul	x13, x8, x12
 360:	umulh	x8, x8, x12
 364:	extr	x8, x8, x13, #63
 368:	stur	x8, [x29, #-184]
 36c:	ldur	x8, [x29, #-184]
 370:	ldur	x12, [x29, #-176]
 374:	umulh	x8, x8, x12
 378:	subs	x8, x11, x8
 37c:	stur	x8, [x29, #-192]
 380:	ldur	x8, [x29, #-184]
 384:	ldur	x12, [x29, #-192]
 388:	mul	x13, x8, x12
 38c:	umulh	x8, x8, x12
 390:	extr	x8, x8, x13, #63
 394:	stur	x8, [x29, #-184]
 398:	ldur	x8, [x29, #-184]
 39c:	ldur	x12, [x29, #-176]
 3a0:	umulh	x8, x8, x12
 3a4:	subs	x8, x11, x8
 3a8:	stur	x8, [x29, #-192]
 3ac:	ldur	x8, [x29, #-184]
 3b0:	ldur	x12, [x29, #-192]
 3b4:	mul	x13, x8, x12
 3b8:	umulh	x8, x8, x12
 3bc:	extr	x8, x8, x13, #63
 3c0:	stur	x8, [x29, #-184]
 3c4:	ldur	x8, [x29, #-184]
 3c8:	ldur	x12, [x29, #-176]
 3cc:	umulh	x8, x8, x12
 3d0:	subs	x8, x11, x8
 3d4:	stur	x8, [x29, #-192]
 3d8:	ldur	x8, [x29, #-184]
 3dc:	ldur	x12, [x29, #-192]
 3e0:	mul	x13, x8, x12
 3e4:	umulh	x8, x8, x12
 3e8:	extr	x8, x8, x13, #63
 3ec:	stur	x8, [x29, #-184]
 3f0:	ldur	x8, [x29, #-184]
 3f4:	ldur	x12, [x29, #-176]
 3f8:	umulh	x8, x8, x12
 3fc:	subs	x8, x11, x8
 400:	stur	x8, [x29, #-192]
 404:	ldur	x8, [x29, #-184]
 408:	ldur	x12, [x29, #-192]
 40c:	mul	x13, x8, x12
 410:	umulh	x8, x8, x12
 414:	extr	x8, x8, x13, #63
 418:	stur	x8, [x29, #-184]
 41c:	ldur	x8, [x29, #-184]
 420:	subs	x8, x8, #0x1
 424:	stur	x8, [x29, #-184]
 428:	ldur	x8, [x29, #-112]
 42c:	lsl	x8, x8, #15
 430:	stur	x8, [x29, #-200]
 434:	ldur	x0, [x29, #-184]
 438:	ldur	x2, [x29, #-176]
 43c:	add	x8, sp, #0xf0
 440:	sub	x5, x29, #0x100
 444:	mov	x1, x11
 448:	mov	x3, x11
 44c:	mov	x4, x8
 450:	str	x11, [sp, #32]
 454:	str	x8, [sp, #24]
 458:	bl	934 <wideMultiply>
 45c:	ldur	x0, [x29, #-184]
 460:	ldur	x2, [x29, #-200]
 464:	add	x5, sp, #0x120
 468:	ldr	x1, [sp, #32]
 46c:	ldr	x3, [sp, #32]
 470:	ldr	x4, [sp, #24]
 474:	bl	934 <wideMultiply>
 478:	ldur	x8, [x29, #-248]
 47c:	ldur	x11, [x29, #-256]
 480:	ldr	x12, [sp, #296]
 484:	adds	x11, x11, x12
 488:	ldr	x12, [sp, #32]
 48c:	adcs	x8, x8, x12
 490:	subs	x11, x12, x11
 494:	sbcs	x8, x12, x8
 498:	stur	x11, [x29, #-224]
 49c:	stur	x8, [x29, #-216]
 4a0:	ldur	x8, [x29, #-216]
 4a4:	str	x8, [sp, #232]
 4a8:	ldur	x8, [x29, #-224]
 4ac:	str	x8, [sp, #224]
 4b0:	ldur	x0, [x29, #-184]
 4b4:	ldr	x2, [sp, #232]
 4b8:	add	x5, sp, #0x110
 4bc:	mov	x1, x12
 4c0:	mov	x3, x12
 4c4:	ldr	x4, [sp, #24]
 4c8:	bl	934 <wideMultiply>
 4cc:	ldur	x0, [x29, #-184]
 4d0:	ldr	x2, [sp, #224]
 4d4:	add	x5, sp, #0x100
 4d8:	ldr	x1, [sp, #32]
 4dc:	ldr	x3, [sp, #32]
 4e0:	ldr	x4, [sp, #24]
 4e4:	bl	934 <wideMultiply>
 4e8:	ldr	x8, [sp, #280]
 4ec:	ldr	x11, [sp, #272]
 4f0:	ldr	x12, [sp, #264]
 4f4:	adds	x11, x11, x12
 4f8:	ldr	x12, [sp, #32]
 4fc:	adcs	x8, x8, x12
 500:	stur	x11, [x29, #-240]
 504:	stur	x8, [x29, #-232]
 508:	ldur	x8, [x29, #-232]
 50c:	ldur	x11, [x29, #-240]
 510:	subs	x11, x11, #0x2
 514:	mov	x13, #0xffffffffffffffff    	// #-1
 518:	adcs	x8, x8, x13
 51c:	stur	x11, [x29, #-240]
 520:	stur	x8, [x29, #-232]
 524:	ldur	x8, [x29, #-96]
 528:	ldur	x11, [x29, #-88]
 52c:	extr	x1, x11, x8, #62
 530:	lsl	x0, x8, #2
 534:	ldur	x3, [x29, #-232]
 538:	ldur	x2, [x29, #-240]
 53c:	add	x4, sp, #0xd0
 540:	add	x5, sp, #0xc0
 544:	bl	934 <wideMultiply>
 548:	ldr	x8, [sp, #216]
 54c:	lsr	x8, x8, #49
 550:	cbnz	x8, 5a8 <__divtf3+0x5a8>
 554:	b	558 <__divtf3+0x558>
 558:	ldr	x1, [sp, #216]
 55c:	ldr	x0, [sp, #208]
 560:	ldur	x3, [x29, #-104]
 564:	ldur	x2, [x29, #-112]
 568:	add	x4, sp, #0xf0
 56c:	add	x5, sp, #0xa0
 570:	bl	934 <wideMultiply>
 574:	ldur	x8, [x29, #-96]
 578:	lsl	x8, x8, #49
 57c:	ldr	x9, [sp, #168]
 580:	ldr	x10, [sp, #160]
 584:	mov	x11, xzr
 588:	subs	x10, x11, x10
 58c:	sbcs	x8, x8, x9
 590:	str	x10, [sp, #176]
 594:	str	x8, [sp, #184]
 598:	ldur	w12, [x29, #-164]
 59c:	subs	w12, w12, #0x1
 5a0:	stur	w12, [x29, #-164]
 5a4:	b	604 <__divtf3+0x604>
 5a8:	ldr	x8, [sp, #208]
 5ac:	ldr	x9, [sp, #216]
 5b0:	extr	x8, x9, x8, #1
 5b4:	lsr	x9, x9, #1
 5b8:	str	x9, [sp, #216]
 5bc:	str	x8, [sp, #208]
 5c0:	ldr	x1, [sp, #216]
 5c4:	ldr	x0, [sp, #208]
 5c8:	ldur	x3, [x29, #-104]
 5cc:	ldur	x2, [x29, #-112]
 5d0:	add	x4, sp, #0xf0
 5d4:	add	x5, sp, #0xa0
 5d8:	bl	934 <wideMultiply>
 5dc:	ldur	x8, [x29, #-96]
 5e0:	lsl	x8, x8, #48
 5e4:	ldr	x9, [sp, #168]
 5e8:	ldr	x10, [sp, #160]
 5ec:	mov	x11, xzr
 5f0:	subs	x10, x11, x10
 5f4:	sbcs	x8, x8, x9
 5f8:	str	x10, [sp, #176]
 5fc:	str	x8, [sp, #184]
 600:	b	604 <__divtf3+0x604>
 604:	ldur	w8, [x29, #-164]
 608:	mov	w9, #0x3fff                	// #16383
 60c:	add	w8, w8, w9
 610:	str	w8, [sp, #156]
 614:	ldr	w8, [sp, #156]
 618:	mov	w9, #0x7fff                	// #32767
 61c:	subs	w8, w8, w9
 620:	b.lt	640 <__divtf3+0x640>  // b.tstop
 624:	b	628 <__divtf3+0x628>
 628:	ldur	x0, [x29, #-80]
 62c:	ldur	x8, [x29, #-72]
 630:	orr	x1, x8, #0x7fff000000000000
 634:	bl	7f8 <fromRep>
 638:	stur	q0, [x29, #-16]
 63c:	b	7c4 <__divtf3+0x7c4>
 640:	ldr	w8, [sp, #156]
 644:	subs	w8, w8, #0x0
 648:	b.gt	70c <__divtf3+0x70c>
 64c:	b	650 <__divtf3+0x650>
 650:	ldr	w8, [sp, #156]
 654:	cbnz	w8, 6f8 <__divtf3+0x6f8>
 658:	b	65c <__divtf3+0x65c>
 65c:	ldr	x8, [sp, #176]
 660:	ldr	x9, [sp, #184]
 664:	extr	x9, x9, x8, #63
 668:	ldur	x10, [x29, #-104]
 66c:	ldur	x11, [x29, #-112]
 670:	subs	x8, x11, x8, lsl #1
 674:	cset	w12, cc  // cc = lo, ul, last
 678:	subs	x9, x9, x10
 67c:	cset	w13, hi  // hi = pmore
 680:	csel	w12, w12, w13, eq  // eq = none
 684:	strb	w12, [sp, #152]
 688:	ldr	x10, [sp, #208]
 68c:	ldr	x11, [sp, #216]
 690:	and	x11, x11, #0xffffffffffff
 694:	str	x10, [sp, #128]
 698:	str	x11, [sp, #136]
 69c:	ldrb	w12, [sp, #152]
 6a0:	mov	w10, w12
 6a4:	and	x10, x10, #0x1
 6a8:	ldr	x11, [sp, #136]
 6ac:	ldr	x14, [sp, #128]
 6b0:	adds	x10, x14, x10
 6b4:	mov	x14, xzr
 6b8:	adcs	x11, x11, x14
 6bc:	str	x10, [sp, #128]
 6c0:	str	x11, [sp, #136]
 6c4:	ldrh	w12, [sp, #142]
 6c8:	cbz	w12, 6f4 <__divtf3+0x6f4>
 6cc:	b	6d0 <__divtf3+0x6d0>
 6d0:	ldr	x8, [sp, #136]
 6d4:	ldr	x9, [sp, #128]
 6d8:	ldur	x10, [x29, #-72]
 6dc:	ldur	x11, [x29, #-80]
 6e0:	orr	x0, x9, x11
 6e4:	orr	x1, x8, x10
 6e8:	bl	7f8 <fromRep>
 6ec:	stur	q0, [x29, #-16]
 6f0:	b	7c4 <__divtf3+0x7c4>
 6f4:	b	6f8 <__divtf3+0x6f8>
 6f8:	ldur	x1, [x29, #-72]
 6fc:	ldur	x0, [x29, #-80]
 700:	bl	7f8 <fromRep>
 704:	stur	q0, [x29, #-16]
 708:	b	7c4 <__divtf3+0x7c4>
 70c:	ldr	x8, [sp, #176]
 710:	ldr	x9, [sp, #184]
 714:	extr	x9, x9, x8, #63
 718:	ldur	x10, [x29, #-104]
 71c:	ldur	x11, [x29, #-112]
 720:	subs	x8, x11, x8, lsl #1
 724:	cset	w12, ls  // ls = plast
 728:	subs	x9, x9, x10
 72c:	cset	w13, cs  // cs = hs, nlast
 730:	csel	w12, w12, w13, eq  // eq = none
 734:	strb	w12, [sp, #124]
 738:	ldr	x10, [sp, #208]
 73c:	ldr	x11, [sp, #216]
 740:	and	x11, x11, #0xffffffffffff
 744:	str	x10, [sp, #96]
 748:	str	x11, [sp, #104]
 74c:	ldr	w12, [sp, #156]
 750:	mov	w10, w12
 754:	ldr	x11, [sp, #96]
 758:	ldr	x14, [sp, #104]
 75c:	orr	x10, x14, x10, lsl #48
 760:	str	x11, [sp, #96]
 764:	str	x10, [sp, #104]
 768:	ldrb	w12, [sp, #124]
 76c:	mov	w10, w12
 770:	and	x10, x10, #0x1
 774:	ldr	x11, [sp, #104]
 778:	ldr	x14, [sp, #96]
 77c:	adds	x10, x14, x10
 780:	mov	x14, xzr
 784:	adcs	x11, x11, x14
 788:	str	x10, [sp, #96]
 78c:	str	x11, [sp, #104]
 790:	ldr	x10, [sp, #104]
 794:	ldr	x11, [sp, #96]
 798:	ldur	x14, [x29, #-72]
 79c:	ldur	x15, [x29, #-80]
 7a0:	orr	x0, x11, x15
 7a4:	orr	x1, x10, x14
 7a8:	str	x8, [sp, #16]
 7ac:	str	x9, [sp, #8]
 7b0:	bl	7f8 <fromRep>
 7b4:	str	q0, [sp, #80]
 7b8:	ldr	q0, [sp, #80]
 7bc:	stur	q0, [x29, #-16]
 7c0:	b	7c4 <__divtf3+0x7c4>
 7c4:	ldur	q0, [x29, #-16]
 7c8:	add	sp, sp, #0x230
 7cc:	ldr	x28, [sp, #16]
 7d0:	ldp	x29, x30, [sp], #32
 7d4:	ret

00000000000007d8 <toRep>:
 7d8:	sub	sp, sp, #0x20
 7dc:	str	q0, [sp, #16]
 7e0:	ldr	q0, [sp, #16]
 7e4:	str	q0, [sp]
 7e8:	ldr	x0, [sp]
 7ec:	ldr	x1, [sp, #8]
 7f0:	add	sp, sp, #0x20
 7f4:	ret

00000000000007f8 <fromRep>:
 7f8:	sub	sp, sp, #0x20
 7fc:	mov	v0.d[0], x0
 800:	mov	v0.d[1], x1
 804:	str	q0, [sp, #16]
 808:	ldr	q0, [sp, #16]
 80c:	str	q0, [sp]
 810:	ldr	q0, [sp]
 814:	add	sp, sp, #0x20
 818:	ret

000000000000081c <normalize>:
 81c:	sub	sp, sp, #0x40
 820:	stp	x29, x30, [sp, #48]
 824:	add	x29, sp, #0x30
 828:	mov	x8, xzr
 82c:	mov	x1, #0x1000000000000       	// #281474976710656
 830:	mov	w9, #0x1                   	// #1
 834:	stur	x0, [x29, #-8]
 838:	ldur	x10, [x29, #-8]
 83c:	ldr	q0, [x10]
 840:	mov	v1.16b, v0.16b
 844:	mov	d2, v0.d[1]
 848:	fmov	x0, d1
 84c:	str	x1, [sp, #24]
 850:	fmov	x1, d2
 854:	str	x8, [sp, #16]
 858:	str	w9, [sp, #12]
 85c:	bl	c7c <rep_clz>
 860:	ldr	x8, [sp, #16]
 864:	str	w0, [sp, #8]
 868:	mov	x0, x8
 86c:	ldr	x1, [sp, #24]
 870:	bl	c7c <rep_clz>
 874:	ldr	w9, [sp, #8]
 878:	subs	w11, w9, w0
 87c:	stur	w11, [x29, #-12]
 880:	ldur	w11, [x29, #-12]
 884:	mov	w8, w11
 888:	mov	v0.d[0], x8
 88c:	ldr	x8, [sp, #16]
 890:	mov	v0.d[1], x8
 894:	ldur	x10, [x29, #-8]
 898:	ldr	q3, [x10]
 89c:	mov	x12, #0x40                  	// #64
 8a0:	mov	v1.16b, v3.16b
 8a4:	mov	d2, v3.d[1]
 8a8:	fmov	x13, d0
 8ac:	subs	x13, x13, #0x40
 8b0:	fmov	x14, d0
 8b4:	subs	x12, x12, x14
 8b8:	fmov	x14, d0
 8bc:	cmp	x14, #0x40
 8c0:	cset	w11, cc  // cc = lo, ul, last
 8c4:	fmov	x14, d0
 8c8:	fmov	x15, d1
 8cc:	fmov	x16, d0
 8d0:	lsl	x15, x15, x16
 8d4:	fmov	x16, d1
 8d8:	lsr	x12, x16, x12
 8dc:	fmov	x16, d2
 8e0:	fmov	x17, d0
 8e4:	lsl	x16, x16, x17
 8e8:	orr	x12, x12, x16
 8ec:	fmov	x16, d1
 8f0:	lsl	x13, x16, x13
 8f4:	tst	w11, #0x1
 8f8:	csel	x15, x15, x8, ne  // ne = any
 8fc:	tst	w11, #0x1
 900:	csel	x12, x12, x13, ne  // ne = any
 904:	fmov	x13, d2
 908:	cmp	x14, #0x0
 90c:	csel	x12, x13, x12, eq  // eq = none
 910:	mov	v3.d[0], x15
 914:	mov	v3.d[1], x12
 918:	str	q3, [x10]
 91c:	ldur	w11, [x29, #-12]
 920:	ldr	w18, [sp, #12]
 924:	subs	w0, w18, w11
 928:	ldp	x29, x30, [sp, #48]
 92c:	add	sp, sp, #0x40
 930:	ret

0000000000000934 <wideMultiply>:
 934:	sub	sp, sp, #0x150
 938:	str	x29, [sp, #320]
 93c:	str	x1, [sp, #312]
 940:	str	x0, [sp, #304]
 944:	str	x3, [sp, #296]
 948:	str	x2, [sp, #288]
 94c:	str	x4, [sp, #280]
 950:	str	x5, [sp, #272]
 954:	ldr	w8, [sp, #316]
 958:	mov	w9, w8
 95c:	ldr	w8, [sp, #300]
 960:	mov	w10, w8
 964:	mul	x9, x9, x10
 968:	str	x9, [sp, #264]
 96c:	ldr	w8, [sp, #316]
 970:	mov	w9, w8
 974:	ldr	w8, [sp, #296]
 978:	mov	w10, w8
 97c:	mul	x9, x9, x10
 980:	str	x9, [sp, #256]
 984:	ldr	w8, [sp, #316]
 988:	mov	w9, w8
 98c:	ldr	w8, [sp, #292]
 990:	mov	w10, w8
 994:	mul	x9, x9, x10
 998:	str	x9, [sp, #248]
 99c:	ldr	w8, [sp, #316]
 9a0:	mov	w9, w8
 9a4:	ldr	w8, [sp, #288]
 9a8:	mov	w10, w8
 9ac:	mul	x9, x9, x10
 9b0:	str	x9, [sp, #240]
 9b4:	ldr	w8, [sp, #312]
 9b8:	mov	w9, w8
 9bc:	ldr	w8, [sp, #300]
 9c0:	mov	w10, w8
 9c4:	mul	x9, x9, x10
 9c8:	str	x9, [sp, #232]
 9cc:	ldr	w8, [sp, #312]
 9d0:	mov	w9, w8
 9d4:	ldr	w8, [sp, #296]
 9d8:	mov	w10, w8
 9dc:	mul	x9, x9, x10
 9e0:	str	x9, [sp, #224]
 9e4:	ldr	w8, [sp, #312]
 9e8:	mov	w9, w8
 9ec:	ldr	w8, [sp, #292]
 9f0:	mov	w10, w8
 9f4:	mul	x9, x9, x10
 9f8:	str	x9, [sp, #216]
 9fc:	ldr	w8, [sp, #312]
 a00:	mov	w9, w8
 a04:	ldr	w8, [sp, #288]
 a08:	mov	w10, w8
 a0c:	mul	x9, x9, x10
 a10:	str	x9, [sp, #208]
 a14:	ldr	w8, [sp, #308]
 a18:	mov	w9, w8
 a1c:	ldr	w8, [sp, #300]
 a20:	mov	w10, w8
 a24:	mul	x9, x9, x10
 a28:	str	x9, [sp, #200]
 a2c:	ldr	w8, [sp, #308]
 a30:	mov	w9, w8
 a34:	ldr	w8, [sp, #296]
 a38:	mov	w10, w8
 a3c:	mul	x9, x9, x10
 a40:	str	x9, [sp, #192]
 a44:	ldr	w8, [sp, #308]
 a48:	mov	w9, w8
 a4c:	ldr	w8, [sp, #292]
 a50:	mov	w10, w8
 a54:	mul	x9, x9, x10
 a58:	str	x9, [sp, #184]
 a5c:	ldr	w8, [sp, #308]
 a60:	mov	w9, w8
 a64:	ldr	w8, [sp, #288]
 a68:	mov	w10, w8
 a6c:	mul	x9, x9, x10
 a70:	str	x9, [sp, #176]
 a74:	ldr	w8, [sp, #304]
 a78:	mov	w9, w8
 a7c:	ldr	w8, [sp, #300]
 a80:	mov	w10, w8
 a84:	mul	x9, x9, x10
 a88:	str	x9, [sp, #168]
 a8c:	ldr	w8, [sp, #304]
 a90:	mov	w9, w8
 a94:	ldr	w8, [sp, #296]
 a98:	mov	w10, w8
 a9c:	mul	x9, x9, x10
 aa0:	str	x9, [sp, #160]
 aa4:	ldr	w8, [sp, #304]
 aa8:	mov	w9, w8
 aac:	ldr	w8, [sp, #292]
 ab0:	mov	w10, w8
 ab4:	mul	x9, x9, x10
 ab8:	str	x9, [sp, #152]
 abc:	ldr	w8, [sp, #304]
 ac0:	mov	w9, w8
 ac4:	ldr	w8, [sp, #288]
 ac8:	mov	w10, w8
 acc:	mul	x9, x9, x10
 ad0:	str	x9, [sp, #144]
 ad4:	ldr	x9, [sp, #144]
 ad8:	mov	x10, xzr
 adc:	str	x10, [sp, #136]
 ae0:	str	x9, [sp, #128]
 ae4:	ldr	x9, [sp, #176]
 ae8:	ldr	x11, [sp, #152]
 aec:	adds	x9, x9, x11
 af0:	adcs	x11, x10, x10
 af4:	str	x9, [sp, #112]
 af8:	str	x11, [sp, #120]
 afc:	ldr	x9, [sp, #208]
 b00:	ldr	x11, [sp, #184]
 b04:	adds	x9, x9, x11
 b08:	adcs	x11, x10, x10
 b0c:	ldr	x12, [sp, #160]
 b10:	adds	x9, x9, x12
 b14:	adcs	x11, x11, x10
 b18:	str	x9, [sp, #96]
 b1c:	str	x11, [sp, #104]
 b20:	ldr	x9, [sp, #240]
 b24:	ldr	x11, [sp, #216]
 b28:	adds	x9, x9, x11
 b2c:	adcs	x11, x10, x10
 b30:	ldr	x12, [sp, #192]
 b34:	adds	x9, x9, x12
 b38:	adcs	x11, x11, x10
 b3c:	ldr	x12, [sp, #168]
 b40:	adds	x9, x9, x12
 b44:	adcs	x11, x11, x10
 b48:	str	x9, [sp, #80]
 b4c:	str	x11, [sp, #88]
 b50:	ldr	x9, [sp, #248]
 b54:	ldr	x11, [sp, #224]
 b58:	adds	x9, x9, x11
 b5c:	adcs	x11, x10, x10
 b60:	ldr	x12, [sp, #200]
 b64:	adds	x9, x9, x12
 b68:	adcs	x11, x11, x10
 b6c:	str	x9, [sp, #64]
 b70:	str	x11, [sp, #72]
 b74:	ldr	x9, [sp, #256]
 b78:	ldr	x11, [sp, #232]
 b7c:	adds	x9, x9, x11
 b80:	adcs	x11, x10, x10
 b84:	str	x9, [sp, #48]
 b88:	str	x11, [sp, #56]
 b8c:	ldr	x9, [sp, #264]
 b90:	str	x10, [sp, #40]
 b94:	str	x9, [sp, #32]
 b98:	ldr	x9, [sp, #128]
 b9c:	ldr	w8, [sp, #112]
 ba0:	mov	w11, w8
 ba4:	adds	x9, x9, x11, lsl #32
 ba8:	adcs	x11, x10, x10
 bac:	str	x9, [sp, #16]
 bb0:	str	x11, [sp, #24]
 bb4:	ldr	x9, [sp, #136]
 bb8:	ldur	x11, [sp, #116]
 bbc:	adds	x9, x9, x11
 bc0:	adcs	x11, x10, x10
 bc4:	ldr	x12, [sp, #96]
 bc8:	adds	x9, x9, x12
 bcc:	adcs	x11, x11, x10
 bd0:	ldr	x12, [sp, #80]
 bd4:	adds	x9, x9, x12, lsl #32
 bd8:	adcs	x11, x11, x10
 bdc:	str	x9, [sp]
 be0:	str	x11, [sp, #8]
 be4:	ldr	x9, [sp, #16]
 be8:	ldr	x11, [sp, #24]
 bec:	ldr	x12, [sp]
 bf0:	add	x11, x11, x12
 bf4:	ldr	x12, [sp, #272]
 bf8:	str	x9, [x12]
 bfc:	str	x11, [x12, #8]
 c00:	ldr	x9, [sp, #8]
 c04:	ldr	w8, [sp, #124]
 c08:	mov	w11, w8
 c0c:	adds	x9, x9, x11
 c10:	adcs	x11, x10, x10
 c14:	ldr	x12, [sp, #104]
 c18:	adds	x9, x9, x12
 c1c:	adcs	x10, x11, x10
 c20:	ldr	x11, [sp, #80]
 c24:	ldr	x12, [sp, #88]
 c28:	extr	x11, x12, x11, #32
 c2c:	lsr	x12, x12, #32
 c30:	adds	x9, x9, x11
 c34:	adcs	x10, x10, x12
 c38:	ldr	x11, [sp, #72]
 c3c:	ldr	x12, [sp, #64]
 c40:	adds	x9, x9, x12
 c44:	adcs	x10, x10, x11
 c48:	ldr	x11, [sp, #48]
 c4c:	ldr	x12, [sp, #56]
 c50:	extr	x12, x12, x11, #32
 c54:	adds	x9, x9, x11, lsl #32
 c58:	adcs	x10, x10, x12
 c5c:	ldr	x11, [sp, #32]
 c60:	add	x10, x10, x11
 c64:	ldr	x11, [sp, #280]
 c68:	str	x9, [x11]
 c6c:	str	x10, [x11, #8]
 c70:	ldr	x29, [sp, #320]
 c74:	add	sp, sp, #0x150
 c78:	ret

0000000000000c7c <rep_clz>:
 c7c:	sub	sp, sp, #0x30
 c80:	mov	v0.d[0], x0
 c84:	mov	v0.d[1], x1
 c88:	str	q0, [sp, #32]
 c8c:	ldr	q0, [sp, #32]
 c90:	str	q0, [sp, #16]
 c94:	ldr	x8, [sp, #24]
 c98:	cbz	x8, cac <rep_clz+0x30>
 c9c:	ldr	x8, [sp, #24]
 ca0:	str	x8, [sp, #8]
 ca4:	str	xzr, [sp]
 ca8:	b	cbc <rep_clz+0x40>
 cac:	ldr	x8, [sp, #16]
 cb0:	str	x8, [sp, #8]
 cb4:	mov	x8, #0x40                  	// #64
 cb8:	str	x8, [sp]
 cbc:	ldr	x8, [sp, #8]
 cc0:	clz	x8, x8
 cc4:	lsl	x8, x8, #32
 cc8:	ldr	x9, [sp]
 ccc:	add	x8, x9, x8, asr #32
 cd0:	mov	w0, w8
 cd4:	add	sp, sp, #0x30
 cd8:	ret

extendsfdf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__extendsfdf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	ldur	s0, [x29, #-4]
  14:	bl	24 <__extendXfYf2__>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__extendXfYf2__>:
  24:	sub	sp, sp, #0x90
  28:	stp	x29, x30, [sp, #128]
  2c:	add	x29, sp, #0x80
  30:	mov	w8, #0x20                  	// #32
  34:	mov	w9, #0x8                   	// #8
  38:	mov	w10, #0xff                  	// #255
  3c:	mov	w11, #0x7f                  	// #127
  40:	mov	w12, #0x800000              	// #8388608
  44:	mov	w13, #0x7f800000            	// #2139095040
  48:	mov	w14, #0x80000000            	// #-2147483648
  4c:	mov	w15, #0x7fffffff            	// #2147483647
  50:	mov	w16, #0x400000              	// #4194304
  54:	mov	w17, #0x3fffff              	// #4194303
  58:	mov	w18, #0x40                  	// #64
  5c:	mov	w0, #0xb                   	// #11
  60:	mov	w1, #0x7ff                 	// #2047
  64:	mov	w2, #0x3ff                 	// #1023
  68:	mov	x3, #0x10000000000000      	// #4503599627370496
  6c:	mov	w4, #0x7f000000            	// #2130706432
  70:	stur	s0, [x29, #-4]
  74:	stur	w8, [x29, #-8]
  78:	stur	w9, [x29, #-12]
  7c:	stur	w10, [x29, #-16]
  80:	stur	w11, [x29, #-20]
  84:	stur	w12, [x29, #-24]
  88:	stur	w13, [x29, #-28]
  8c:	stur	w14, [x29, #-32]
  90:	stur	w15, [x29, #-36]
  94:	stur	w16, [x29, #-40]
  98:	stur	w17, [x29, #-44]
  9c:	stur	w18, [x29, #-48]
  a0:	stur	w0, [x29, #-52]
  a4:	stur	w1, [x29, #-56]
  a8:	stur	w2, [x29, #-60]
  ac:	str	x3, [sp, #56]
  b0:	ldur	s0, [x29, #-4]
  b4:	str	w4, [sp, #12]
  b8:	bl	1f8 <srcToRep>
  bc:	str	w0, [sp, #52]
  c0:	ldr	w8, [sp, #52]
  c4:	and	w8, w8, #0x7fffffff
  c8:	str	w8, [sp, #48]
  cc:	ldr	w8, [sp, #52]
  d0:	and	w8, w8, #0x80000000
  d4:	str	w8, [sp, #44]
  d8:	ldr	w8, [sp, #48]
  dc:	subs	w8, w8, #0x800, lsl #12
  e0:	ldr	w9, [sp, #12]
  e4:	cmp	w8, w9
  e8:	b.cs	110 <__extendXfYf2__+0xec>  // b.hs, b.nlast
  ec:	ldr	w8, [sp, #48]
  f0:	mov	w9, w8
  f4:	lsl	x9, x9, #29
  f8:	str	x9, [sp, #32]
  fc:	ldr	x9, [sp, #32]
 100:	mov	x10, #0x3800000000000000    	// #4035225266123964416
 104:	add	x9, x9, x10
 108:	str	x9, [sp, #32]
 10c:	b	1d0 <__extendXfYf2__+0x1ac>
 110:	ldr	w8, [sp, #48]
 114:	mov	w9, #0x7f800000            	// #2139095040
 118:	cmp	w8, w9
 11c:	b.cc	164 <__extendXfYf2__+0x140>  // b.lo, b.ul, b.last
 120:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 124:	str	x8, [sp, #32]
 128:	ldr	w9, [sp, #48]
 12c:	and	w9, w9, #0x400000
 130:	mov	w8, w9
 134:	ubfx	x8, x8, #0, #32
 138:	ldr	x10, [sp, #32]
 13c:	orr	x8, x10, x8, lsl #29
 140:	str	x8, [sp, #32]
 144:	ldr	w9, [sp, #48]
 148:	and	w9, w9, #0x3fffff
 14c:	mov	w8, w9
 150:	ubfx	x8, x8, #0, #32
 154:	ldr	x10, [sp, #32]
 158:	orr	x8, x10, x8, lsl #29
 15c:	str	x8, [sp, #32]
 160:	b	1d0 <__extendXfYf2__+0x1ac>
 164:	ldr	w8, [sp, #48]
 168:	cbz	w8, 1cc <__extendXfYf2__+0x1a8>
 16c:	ldr	w8, [sp, #48]
 170:	clz	w8, w8
 174:	subs	w8, w8, #0x8
 178:	str	w8, [sp, #28]
 17c:	ldr	w8, [sp, #48]
 180:	mov	w9, w8
 184:	ldr	w8, [sp, #28]
 188:	add	w8, w8, #0x1d
 18c:	mov	w10, w8
 190:	lsl	x9, x9, x10
 194:	str	x9, [sp, #32]
 198:	ldr	x9, [sp, #32]
 19c:	eor	x9, x9, #0x10000000000000
 1a0:	str	x9, [sp, #32]
 1a4:	ldr	w8, [sp, #28]
 1a8:	mov	w11, #0x380                 	// #896
 1ac:	subs	w8, w11, w8
 1b0:	add	w8, w8, #0x1
 1b4:	str	w8, [sp, #24]
 1b8:	ldrsw	x9, [sp, #24]
 1bc:	ldr	x10, [sp, #32]
 1c0:	orr	x9, x10, x9, lsl #52
 1c4:	str	x9, [sp, #32]
 1c8:	b	1d0 <__extendXfYf2__+0x1ac>
 1cc:	str	xzr, [sp, #32]
 1d0:	ldr	x8, [sp, #32]
 1d4:	ldr	w9, [sp, #44]
 1d8:	mov	w10, w9
 1dc:	orr	x8, x8, x10, lsl #32
 1e0:	str	x8, [sp, #16]
 1e4:	ldr	x0, [sp, #16]
 1e8:	bl	214 <dstFromRep>
 1ec:	ldp	x29, x30, [sp, #128]
 1f0:	add	sp, sp, #0x90
 1f4:	ret

00000000000001f8 <srcToRep>:
 1f8:	sub	sp, sp, #0x10
 1fc:	str	s0, [sp, #12]
 200:	ldr	w8, [sp, #12]
 204:	str	w8, [sp, #8]
 208:	ldr	w0, [sp, #8]
 20c:	add	sp, sp, #0x10
 210:	ret

0000000000000214 <dstFromRep>:
 214:	sub	sp, sp, #0x10
 218:	str	x0, [sp, #8]
 21c:	ldr	x8, [sp, #8]
 220:	str	x8, [sp]
 224:	ldr	d0, [sp]
 228:	add	sp, sp, #0x10
 22c:	ret

extendhfsf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__extendhfsf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	sturh	w0, [x29, #-2]
  10:	ldurh	w0, [x29, #-2]
  14:	bl	24 <__extendXfYf2__>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__extendXfYf2__>:
  24:	sub	sp, sp, #0x60
  28:	stp	x29, x30, [sp, #80]
  2c:	add	x29, sp, #0x50
  30:	mov	w8, #0x10                  	// #16
  34:	mov	w9, #0x5                   	// #5
  38:	mov	w10, #0x1f                  	// #31
  3c:	mov	w11, #0xf                   	// #15
  40:	mov	w12, #0x400                 	// #1024
  44:	mov	w13, #0x7c00                	// #31744
  48:	mov	w14, #0x8000                	// #32768
  4c:	mov	w15, #0x7fff                	// #32767
  50:	mov	w16, #0x200                 	// #512
  54:	mov	w17, #0x1ff                 	// #511
  58:	mov	w18, #0x20                  	// #32
  5c:	mov	w1, #0x8                   	// #8
  60:	mov	w2, #0xff                  	// #255
  64:	mov	w3, #0x7f                  	// #127
  68:	mov	w4, #0x800000              	// #8388608
  6c:	mov	w5, #0x7800                	// #30720
  70:	sturh	w0, [x29, #-2]
  74:	stur	w8, [x29, #-8]
  78:	stur	w9, [x29, #-12]
  7c:	stur	w10, [x29, #-16]
  80:	stur	w11, [x29, #-20]
  84:	sturh	w12, [x29, #-22]
  88:	sturh	w13, [x29, #-24]
  8c:	sturh	w14, [x29, #-26]
  90:	sturh	w15, [x29, #-28]
  94:	sturh	w16, [x29, #-30]
  98:	sturh	w17, [x29, #-32]
  9c:	stur	w18, [x29, #-36]
  a0:	str	w1, [sp, #40]
  a4:	str	w2, [sp, #36]
  a8:	str	w3, [sp, #32]
  ac:	str	w4, [sp, #28]
  b0:	ldurh	w0, [x29, #-2]
  b4:	str	w5, [sp]
  b8:	bl	200 <srcToRep>
  bc:	strh	w0, [sp, #26]
  c0:	ldrh	w8, [sp, #26]
  c4:	and	w8, w8, #0x7fff
  c8:	strh	w8, [sp, #24]
  cc:	ldrh	w8, [sp, #26]
  d0:	and	w8, w8, #0x8000
  d4:	strh	w8, [sp, #22]
  d8:	ldrh	w8, [sp, #24]
  dc:	subs	w8, w8, #0x400
  e0:	and	w8, w8, #0xffff
  e4:	ldr	w9, [sp]
  e8:	cmp	w8, w9
  ec:	b.ge	110 <__extendXfYf2__+0xec>  // b.tcont
  f0:	ldrh	w8, [sp, #24]
  f4:	lsl	w8, w8, #13
  f8:	str	w8, [sp, #16]
  fc:	ldr	w8, [sp, #16]
 100:	mov	w9, #0x38000000            	// #939524096
 104:	add	w8, w8, w9
 108:	str	w8, [sp, #16]
 10c:	b	1b8 <__extendXfYf2__+0x194>
 110:	ldrh	w8, [sp, #24]
 114:	mov	w9, #0x7c00                	// #31744
 118:	cmp	w8, w9
 11c:	b.lt	154 <__extendXfYf2__+0x130>  // b.tstop
 120:	mov	w8, #0x7f800000            	// #2139095040
 124:	str	w8, [sp, #16]
 128:	ldrh	w8, [sp, #24]
 12c:	and	w8, w8, #0x200
 130:	ldr	w9, [sp, #16]
 134:	orr	w8, w9, w8, lsl #13
 138:	str	w8, [sp, #16]
 13c:	ldrh	w8, [sp, #24]
 140:	and	w8, w8, #0x1ff
 144:	ldr	w9, [sp, #16]
 148:	orr	w8, w9, w8, lsl #13
 14c:	str	w8, [sp, #16]
 150:	b	1b8 <__extendXfYf2__+0x194>
 154:	ldrh	w8, [sp, #24]
 158:	cbz	w8, 1b4 <__extendXfYf2__+0x190>
 15c:	ldrh	w8, [sp, #24]
 160:	clz	w8, w8
 164:	subs	w8, w8, #0x15
 168:	str	w8, [sp, #12]
 16c:	ldrh	w8, [sp, #24]
 170:	ldr	w9, [sp, #12]
 174:	add	w9, w9, #0xd
 178:	lsl	w8, w8, w9
 17c:	str	w8, [sp, #16]
 180:	ldr	w8, [sp, #16]
 184:	eor	w8, w8, #0x800000
 188:	str	w8, [sp, #16]
 18c:	ldr	w8, [sp, #12]
 190:	mov	w9, #0x70                  	// #112
 194:	subs	w8, w9, w8
 198:	add	w8, w8, #0x1
 19c:	str	w8, [sp, #8]
 1a0:	ldr	w8, [sp, #8]
 1a4:	ldr	w9, [sp, #16]
 1a8:	orr	w8, w9, w8, lsl #23
 1ac:	str	w8, [sp, #16]
 1b0:	b	1b8 <__extendXfYf2__+0x194>
 1b4:	str	wzr, [sp, #16]
 1b8:	ldr	w8, [sp, #16]
 1bc:	ldrh	w9, [sp, #22]
 1c0:	orr	w8, w8, w9, lsl #16
 1c4:	str	w8, [sp, #4]
 1c8:	ldr	w0, [sp, #4]
 1cc:	bl	21c <dstFromRep>
 1d0:	ldp	x29, x30, [sp, #80]
 1d4:	add	sp, sp, #0x60
 1d8:	ret

00000000000001dc <__gnu_h2f_ieee>:
 1dc:	sub	sp, sp, #0x20
 1e0:	stp	x29, x30, [sp, #16]
 1e4:	add	x29, sp, #0x10
 1e8:	sturh	w0, [x29, #-2]
 1ec:	ldurh	w0, [x29, #-2]
 1f0:	bl	0 <__extendhfsf2>
 1f4:	ldp	x29, x30, [sp, #16]
 1f8:	add	sp, sp, #0x20
 1fc:	ret

0000000000000200 <srcToRep>:
 200:	sub	sp, sp, #0x10
 204:	strh	w0, [sp, #14]
 208:	ldrh	w8, [sp, #14]
 20c:	strh	w8, [sp, #12]
 210:	ldrh	w0, [sp, #12]
 214:	add	sp, sp, #0x10
 218:	ret

000000000000021c <dstFromRep>:
 21c:	sub	sp, sp, #0x10
 220:	str	w0, [sp, #12]
 224:	ldr	w8, [sp, #12]
 228:	str	w8, [sp, #8]
 22c:	ldr	s0, [sp, #8]
 230:	add	sp, sp, #0x10
 234:	ret

ffsdi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ffsdi2>:
   0:	sub	sp, sp, #0x20
   4:	str	x0, [sp, #16]
   8:	ldr	x8, [sp, #16]
   c:	str	x8, [sp, #8]
  10:	ldr	w9, [sp, #8]
  14:	cbnz	w9, 50 <__ffsdi2+0x50>
  18:	b	1c <__ffsdi2+0x1c>
  1c:	ldr	w8, [sp, #12]
  20:	cbnz	w8, 34 <__ffsdi2+0x34>
  24:	b	28 <__ffsdi2+0x28>
  28:	mov	w8, wzr
  2c:	str	w8, [sp, #28]
  30:	b	68 <__ffsdi2+0x68>
  34:	ldr	w8, [sp, #12]
  38:	rbit	w8, w8
  3c:	clz	w8, w8
  40:	add	w8, w8, #0x21
  44:	mov	w0, w8
  48:	str	w0, [sp, #28]
  4c:	b	68 <__ffsdi2+0x68>
  50:	ldr	w8, [sp, #8]
  54:	rbit	w8, w8
  58:	clz	w8, w8
  5c:	add	w8, w8, #0x1
  60:	str	w8, [sp, #28]
  64:	b	68 <__ffsdi2+0x68>
  68:	ldr	w0, [sp, #28]
  6c:	add	sp, sp, #0x20
  70:	ret

ffssi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ffssi2>:
   0:	sub	sp, sp, #0x10
   4:	str	w0, [sp, #8]
   8:	ldr	w8, [sp, #8]
   c:	cbnz	w8, 20 <__ffssi2+0x20>
  10:	b	14 <__ffssi2+0x14>
  14:	mov	w8, wzr
  18:	str	w8, [sp, #12]
  1c:	b	38 <__ffssi2+0x38>
  20:	ldr	w8, [sp, #8]
  24:	rbit	w8, w8
  28:	clz	w8, w8
  2c:	add	w8, w8, #0x1
  30:	str	w8, [sp, #12]
  34:	b	38 <__ffssi2+0x38>
  38:	ldr	w0, [sp, #12]
  3c:	add	sp, sp, #0x10
  40:	ret

ffsti2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ffsti2>:
   0:	sub	sp, sp, #0x30
   4:	str	x1, [sp, #24]
   8:	str	x0, [sp, #16]
   c:	ldr	x8, [sp, #16]
  10:	ldr	x9, [sp, #24]
  14:	str	x9, [sp, #8]
  18:	str	x8, [sp]
  1c:	ldr	x8, [sp]
  20:	cbnz	x8, 5c <__ffsti2+0x5c>
  24:	b	28 <__ffsti2+0x28>
  28:	ldr	x8, [sp, #8]
  2c:	cbnz	x8, 40 <__ffsti2+0x40>
  30:	b	34 <__ffsti2+0x34>
  34:	mov	w8, wzr
  38:	str	w8, [sp, #44]
  3c:	b	74 <__ffsti2+0x74>
  40:	ldr	x8, [sp, #8]
  44:	rbit	x8, x8
  48:	clz	x8, x8
  4c:	add	w8, w8, #0x41
  50:	mov	w0, w8
  54:	str	w0, [sp, #44]
  58:	b	74 <__ffsti2+0x74>
  5c:	ldr	x8, [sp]
  60:	rbit	x8, x8
  64:	clz	x8, x8
  68:	add	w8, w8, #0x1
  6c:	str	w8, [sp, #44]
  70:	b	74 <__ffsti2+0x74>
  74:	ldr	w0, [sp, #44]
  78:	add	sp, sp, #0x30
  7c:	ret

fixdfdi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixdfdi>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp]
  10:	ldr	d0, [sp]
  14:	fcmp	d0, #0.0
  18:	cset	w8, mi  // mi = first
  1c:	tbnz	w8, #0, 24 <__fixdfdi+0x24>
  20:	b	40 <__fixdfdi+0x40>
  24:	ldr	d0, [sp]
  28:	fneg	d0, d0
  2c:	bl	0 <__fixunsdfdi>
  30:	mov	x8, xzr
  34:	subs	x8, x8, x0
  38:	str	x8, [sp, #8]
  3c:	b	4c <__fixdfdi+0x4c>
  40:	ldr	d0, [sp]
  44:	bl	0 <__fixunsdfdi>
  48:	str	x0, [sp, #8]
  4c:	ldr	x0, [sp, #8]
  50:	ldp	x29, x30, [sp, #16]
  54:	add	sp, sp, #0x20
  58:	ret

fixdfsi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixdfsi>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp, #8]
  10:	ldr	d0, [sp, #8]
  14:	bl	24 <__fixint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixint>:
  24:	sub	sp, sp, #0x50
  28:	stp	x29, x30, [sp, #64]
  2c:	add	x29, sp, #0x40
  30:	mov	w8, #0x7fffffff            	// #2147483647
  34:	mov	w9, #0x80000000            	// #-2147483648
  38:	mov	w10, #0xffffffff            	// #-1
  3c:	mov	w11, #0x1                   	// #1
  40:	stur	d0, [x29, #-16]
  44:	stur	w8, [x29, #-20]
  48:	stur	w9, [x29, #-24]
  4c:	ldur	d0, [x29, #-16]
  50:	str	w10, [sp, #4]
  54:	str	w11, [sp]
  58:	bl	148 <toRep>
  5c:	str	x0, [sp, #32]
  60:	ldr	x12, [sp, #32]
  64:	and	x12, x12, #0x7fffffffffffffff
  68:	str	x12, [sp, #24]
  6c:	ldr	x12, [sp, #32]
  70:	tst	x12, #0x8000000000000000
  74:	ldr	w8, [sp, #4]
  78:	ldr	w9, [sp]
  7c:	csel	w10, w8, w9, ne  // ne = any
  80:	str	w10, [sp, #20]
  84:	ldr	x12, [sp, #24]
  88:	lsr	x12, x12, #52
  8c:	subs	x12, x12, #0x3ff
  90:	str	w12, [sp, #16]
  94:	ldr	x13, [sp, #24]
  98:	and	x13, x13, #0xfffffffffffff
  9c:	orr	x13, x13, #0x10000000000000
  a0:	str	x13, [sp, #8]
  a4:	ldr	w10, [sp, #16]
  a8:	cmp	w10, #0x0
  ac:	cset	w10, ge  // ge = tcont
  b0:	tbnz	w10, #0, bc <__fixint+0x98>
  b4:	stur	wzr, [x29, #-4]
  b8:	b	138 <__fixint+0x114>
  bc:	ldr	w8, [sp, #16]
  c0:	mov	w9, w8
  c4:	cmp	x9, #0x20
  c8:	b.cc	e8 <__fixint+0xc4>  // b.lo, b.ul, b.last
  cc:	ldr	w8, [sp, #20]
  d0:	mov	w9, #0x80000000            	// #-2147483648
  d4:	mov	w10, #0x7fffffff            	// #2147483647
  d8:	cmp	w8, #0x1
  dc:	csel	w8, w10, w9, eq  // eq = none
  e0:	stur	w8, [x29, #-4]
  e4:	b	138 <__fixint+0x114>
  e8:	ldr	w8, [sp, #16]
  ec:	cmp	w8, #0x34
  f0:	b.ge	11c <__fixint+0xf8>  // b.tcont
  f4:	ldrsw	x8, [sp, #20]
  f8:	ldr	x9, [sp, #8]
  fc:	ldr	w10, [sp, #16]
 100:	mov	w11, #0x34                  	// #52
 104:	subs	w10, w11, w10
 108:	mov	w12, w10
 10c:	lsr	x9, x9, x12
 110:	mul	x8, x8, x9
 114:	stur	w8, [x29, #-4]
 118:	b	138 <__fixint+0x114>
 11c:	ldr	w8, [sp, #20]
 120:	ldr	x9, [sp, #8]
 124:	ldr	w10, [sp, #16]
 128:	subs	w10, w10, #0x34
 12c:	lsl	w9, w9, w10
 130:	mul	w8, w8, w9
 134:	stur	w8, [x29, #-4]
 138:	ldur	w0, [x29, #-4]
 13c:	ldp	x29, x30, [sp, #64]
 140:	add	sp, sp, #0x50
 144:	ret

0000000000000148 <toRep>:
 148:	sub	sp, sp, #0x10
 14c:	str	d0, [sp, #8]
 150:	ldr	x8, [sp, #8]
 154:	str	x8, [sp]
 158:	ldr	x0, [sp]
 15c:	add	sp, sp, #0x10
 160:	ret

fixdfti.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixdfti>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp, #8]
  10:	ldr	d0, [sp, #8]
  14:	bl	24 <__fixint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixint>:
  24:	sub	sp, sp, #0x90
  28:	stp	x29, x30, [sp, #128]
  2c:	add	x29, sp, #0x80
  30:	stur	d0, [x29, #-24]
  34:	mov	x8, #0x7fffffffffffffff    	// #9223372036854775807
  38:	stur	x8, [x29, #-40]
  3c:	mov	x8, #0xffffffffffffffff    	// #-1
  40:	stur	x8, [x29, #-48]
  44:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
  48:	str	x9, [sp, #72]
  4c:	mov	x9, xzr
  50:	str	x9, [sp, #64]
  54:	ldur	d0, [x29, #-24]
  58:	str	x8, [sp, #8]
  5c:	bl	1d4 <toRep>
  60:	str	x0, [sp, #56]
  64:	ldr	x8, [sp, #56]
  68:	and	x8, x8, #0x7fffffffffffffff
  6c:	str	x8, [sp, #48]
  70:	ldr	x8, [sp, #56]
  74:	ands	x8, x8, #0x8000000000000000
  78:	ldr	x9, [sp, #8]
  7c:	cneg	x10, x9, eq  // eq = none
  80:	csetm	x11, ne  // ne = any
  84:	str	x11, [sp, #40]
  88:	str	x10, [sp, #32]
  8c:	ldr	x10, [sp, #48]
  90:	lsr	x10, x10, #52
  94:	subs	w10, w10, #0x3ff
  98:	mov	w0, w10
  9c:	str	w0, [sp, #28]
  a0:	ldr	x11, [sp, #48]
  a4:	mov	x12, #0x10000000000000      	// #4503599627370496
  a8:	bfxil	x12, x11, #0, #52
  ac:	str	x12, [sp, #16]
  b0:	ldr	w10, [sp, #28]
  b4:	tbz	w10, #31, cc <__fixint+0xa8>
  b8:	b	bc <__fixint+0x98>
  bc:	mov	x8, xzr
  c0:	stur	x8, [x29, #-8]
  c4:	stur	x8, [x29, #-16]
  c8:	b	1c0 <__fixint+0x19c>
  cc:	ldr	w8, [sp, #28]
  d0:	subs	w8, w8, #0x80
  d4:	b.cc	108 <__fixint+0xe4>  // b.lo, b.ul, b.last
  d8:	b	dc <__fixint+0xb8>
  dc:	ldr	x8, [sp, #40]
  e0:	ldr	x9, [sp, #32]
  e4:	eor	x9, x9, #0x1
  e8:	orr	x8, x9, x8
  ec:	subs	x8, x8, #0x0
  f0:	csetm	x9, eq  // eq = none
  f4:	mov	x10, #0x7fffffffffffffff    	// #9223372036854775807
  f8:	cinv	x10, x10, ne  // ne = any
  fc:	stur	x10, [x29, #-8]
 100:	stur	x9, [x29, #-16]
 104:	b	1c0 <__fixint+0x19c>
 108:	ldr	w8, [sp, #28]
 10c:	subs	w8, w8, #0x33
 110:	b.gt	154 <__fixint+0x130>
 114:	b	118 <__fixint+0xf4>
 118:	ldr	x8, [sp, #32]
 11c:	ldr	x9, [sp, #40]
 120:	ldr	x10, [sp, #16]
 124:	ldr	w11, [sp, #28]
 128:	mov	w12, #0x34                  	// #52
 12c:	subs	w11, w12, w11
 130:	mov	w13, w11
 134:	lsr	x10, x10, x13
 138:	mul	x9, x9, x10
 13c:	umulh	x13, x8, x10
 140:	add	x9, x13, x9
 144:	mul	x8, x8, x10
 148:	stur	x8, [x29, #-16]
 14c:	stur	x9, [x29, #-8]
 150:	b	1c0 <__fixint+0x19c>
 154:	ldr	x8, [sp, #40]
 158:	ldr	x9, [sp, #32]
 15c:	ldr	x10, [sp, #16]
 160:	ldr	w11, [sp, #28]
 164:	subs	w11, w11, #0x34
 168:	mov	w12, w11
 16c:	mov	x13, xzr
 170:	sub	x14, x13, x12
 174:	lsr	x14, x10, x14
 178:	subs	x15, x12, #0x0
 17c:	csel	x14, x13, x14, eq  // eq = none
 180:	lsl	x16, x10, x12
 184:	subs	x12, x12, #0x40
 188:	subs	x12, x12, #0x0
 18c:	csel	x14, x16, x14, ge  // ge = tcont
 190:	mov	w16, w11
 194:	lsl	x10, x10, x16
 198:	csel	x10, x13, x10, ge  // ge = tcont
 19c:	mul	x13, x9, x14
 1a0:	umulh	x14, x9, x10
 1a4:	add	x13, x14, x13
 1a8:	mul	x8, x8, x10
 1ac:	add	x8, x13, x8
 1b0:	mul	x9, x9, x10
 1b4:	stur	x9, [x29, #-16]
 1b8:	stur	x8, [x29, #-8]
 1bc:	b	1c0 <__fixint+0x19c>
 1c0:	ldur	x0, [x29, #-16]
 1c4:	ldur	x1, [x29, #-8]
 1c8:	ldp	x29, x30, [sp, #128]
 1cc:	add	sp, sp, #0x90
 1d0:	ret

00000000000001d4 <toRep>:
 1d4:	sub	sp, sp, #0x10
 1d8:	str	d0, [sp, #8]
 1dc:	ldr	x8, [sp, #8]
 1e0:	str	x8, [sp]
 1e4:	ldr	x0, [sp]
 1e8:	add	sp, sp, #0x10
 1ec:	ret

fixsfdi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixsfdi>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	s0, [sp, #4]
  10:	ldr	s0, [sp, #4]
  14:	fcmp	s0, #0.0
  18:	cset	w8, mi  // mi = first
  1c:	tbnz	w8, #0, 24 <__fixsfdi+0x24>
  20:	b	40 <__fixsfdi+0x40>
  24:	ldr	s0, [sp, #4]
  28:	fneg	s0, s0
  2c:	bl	0 <__fixunssfdi>
  30:	mov	x8, xzr
  34:	subs	x8, x8, x0
  38:	str	x8, [sp, #8]
  3c:	b	4c <__fixsfdi+0x4c>
  40:	ldr	s0, [sp, #4]
  44:	bl	0 <__fixunssfdi>
  48:	str	x0, [sp, #8]
  4c:	ldr	x0, [sp, #8]
  50:	ldp	x29, x30, [sp, #16]
  54:	add	sp, sp, #0x20
  58:	ret

fixsfsi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixsfsi>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	ldur	s0, [x29, #-4]
  14:	bl	24 <__fixint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixint>:
  24:	sub	sp, sp, #0x40
  28:	stp	x29, x30, [sp, #48]
  2c:	add	x29, sp, #0x30
  30:	mov	w8, #0x7fffffff            	// #2147483647
  34:	mov	w9, #0x80000000            	// #-2147483648
  38:	mov	w10, #0xffffffff            	// #-1
  3c:	mov	w11, #0x1                   	// #1
  40:	stur	s0, [x29, #-8]
  44:	stur	w8, [x29, #-12]
  48:	stur	w9, [x29, #-16]
  4c:	ldur	s0, [x29, #-8]
  50:	str	w9, [sp, #8]
  54:	str	w10, [sp, #4]
  58:	str	w11, [sp]
  5c:	bl	14c <toRep>
  60:	stur	w0, [x29, #-20]
  64:	ldur	w8, [x29, #-20]
  68:	and	w8, w8, #0x7fffffff
  6c:	str	w8, [sp, #24]
  70:	ldur	w8, [x29, #-20]
  74:	ldr	w9, [sp, #8]
  78:	tst	w8, w9
  7c:	ldr	w8, [sp, #4]
  80:	ldr	w10, [sp]
  84:	csel	w11, w8, w10, ne  // ne = any
  88:	str	w11, [sp, #20]
  8c:	ldr	w11, [sp, #24]
  90:	lsr	w11, w11, #23
  94:	subs	w11, w11, #0x7f
  98:	str	w11, [sp, #16]
  9c:	ldr	w11, [sp, #24]
  a0:	and	w11, w11, #0x7fffff
  a4:	orr	w11, w11, #0x800000
  a8:	str	w11, [sp, #12]
  ac:	ldr	w11, [sp, #16]
  b0:	cmp	w11, #0x0
  b4:	cset	w11, ge  // ge = tcont
  b8:	tbnz	w11, #0, c4 <__fixint+0xa0>
  bc:	stur	wzr, [x29, #-4]
  c0:	b	13c <__fixint+0x118>
  c4:	ldr	w8, [sp, #16]
  c8:	mov	w9, w8
  cc:	cmp	x9, #0x20
  d0:	b.cc	f0 <__fixint+0xcc>  // b.lo, b.ul, b.last
  d4:	ldr	w8, [sp, #20]
  d8:	mov	w9, #0x80000000            	// #-2147483648
  dc:	mov	w10, #0x7fffffff            	// #2147483647
  e0:	cmp	w8, #0x1
  e4:	csel	w8, w10, w9, eq  // eq = none
  e8:	stur	w8, [x29, #-4]
  ec:	b	13c <__fixint+0x118>
  f0:	ldr	w8, [sp, #16]
  f4:	cmp	w8, #0x17
  f8:	b.ge	120 <__fixint+0xfc>  // b.tcont
  fc:	ldr	w8, [sp, #20]
 100:	ldr	w9, [sp, #12]
 104:	ldr	w10, [sp, #16]
 108:	mov	w11, #0x17                  	// #23
 10c:	subs	w10, w11, w10
 110:	lsr	w9, w9, w10
 114:	mul	w8, w8, w9
 118:	stur	w8, [x29, #-4]
 11c:	b	13c <__fixint+0x118>
 120:	ldr	w8, [sp, #20]
 124:	ldr	w9, [sp, #12]
 128:	ldr	w10, [sp, #16]
 12c:	subs	w10, w10, #0x17
 130:	lsl	w9, w9, w10
 134:	mul	w8, w8, w9
 138:	stur	w8, [x29, #-4]
 13c:	ldur	w0, [x29, #-4]
 140:	ldp	x29, x30, [sp, #48]
 144:	add	sp, sp, #0x40
 148:	ret

000000000000014c <toRep>:
 14c:	sub	sp, sp, #0x10
 150:	str	s0, [sp, #12]
 154:	ldr	w8, [sp, #12]
 158:	str	w8, [sp, #8]
 15c:	ldr	w0, [sp, #8]
 160:	add	sp, sp, #0x10
 164:	ret

fixsfti.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixsfti>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	ldur	s0, [x29, #-4]
  14:	bl	24 <__fixint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixint>:
  24:	sub	sp, sp, #0x80
  28:	stp	x29, x30, [sp, #112]
  2c:	add	x29, sp, #0x70
  30:	stur	s0, [x29, #-20]
  34:	mov	x8, #0x7fffffffffffffff    	// #9223372036854775807
  38:	stur	x8, [x29, #-40]
  3c:	mov	x8, #0xffffffffffffffff    	// #-1
  40:	stur	x8, [x29, #-48]
  44:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
  48:	str	x9, [sp, #56]
  4c:	mov	x9, xzr
  50:	str	x9, [sp, #48]
  54:	ldur	s0, [x29, #-20]
  58:	str	x8, [sp]
  5c:	bl	1d4 <toRep>
  60:	str	w0, [sp, #44]
  64:	ldr	w10, [sp, #44]
  68:	and	w10, w10, #0x7fffffff
  6c:	str	w10, [sp, #40]
  70:	ldr	w10, [sp, #44]
  74:	ands	w10, w10, #0x80000000
  78:	ldr	x8, [sp]
  7c:	cneg	x9, x8, eq  // eq = none
  80:	csetm	x11, ne  // ne = any
  84:	str	x11, [sp, #24]
  88:	str	x9, [sp, #16]
  8c:	ldr	w12, [sp, #40]
  90:	lsr	w12, w12, #23
  94:	subs	w12, w12, #0x7f
  98:	str	w12, [sp, #12]
  9c:	ldr	w12, [sp, #40]
  a0:	mov	w13, #0x800000              	// #8388608
  a4:	bfxil	w13, w12, #0, #23
  a8:	str	w13, [sp, #8]
  ac:	ldr	w12, [sp, #12]
  b0:	tbz	w12, #31, c8 <__fixint+0xa4>
  b4:	b	b8 <__fixint+0x94>
  b8:	mov	x8, xzr
  bc:	stur	x8, [x29, #-8]
  c0:	stur	x8, [x29, #-16]
  c4:	b	1c0 <__fixint+0x19c>
  c8:	ldr	w8, [sp, #12]
  cc:	subs	w8, w8, #0x80
  d0:	b.cc	104 <__fixint+0xe0>  // b.lo, b.ul, b.last
  d4:	b	d8 <__fixint+0xb4>
  d8:	ldr	x8, [sp, #24]
  dc:	ldr	x9, [sp, #16]
  e0:	eor	x9, x9, #0x1
  e4:	orr	x8, x9, x8
  e8:	subs	x8, x8, #0x0
  ec:	csetm	x9, eq  // eq = none
  f0:	mov	x10, #0x7fffffffffffffff    	// #9223372036854775807
  f4:	cinv	x10, x10, ne  // ne = any
  f8:	stur	x10, [x29, #-8]
  fc:	stur	x9, [x29, #-16]
 100:	b	1c0 <__fixint+0x19c>
 104:	ldr	w8, [sp, #12]
 108:	subs	w8, w8, #0x16
 10c:	b.gt	150 <__fixint+0x12c>
 110:	b	114 <__fixint+0xf0>
 114:	ldr	x8, [sp, #16]
 118:	ldr	x9, [sp, #24]
 11c:	ldr	w10, [sp, #8]
 120:	ldr	w11, [sp, #12]
 124:	mov	w12, #0x17                  	// #23
 128:	subs	w11, w12, w11
 12c:	lsr	w10, w10, w11
 130:	mov	w13, w10
 134:	mul	x9, x9, x13
 138:	umulh	x14, x8, x13
 13c:	add	x9, x14, x9
 140:	mul	x8, x8, x13
 144:	stur	x8, [x29, #-16]
 148:	stur	x9, [x29, #-8]
 14c:	b	1c0 <__fixint+0x19c>
 150:	ldr	x8, [sp, #24]
 154:	ldr	x9, [sp, #16]
 158:	ldr	w10, [sp, #8]
 15c:	mov	w11, w10
 160:	ldr	w10, [sp, #12]
 164:	subs	w10, w10, #0x17
 168:	mov	w12, w10
 16c:	mov	x13, xzr
 170:	sub	x14, x13, x12
 174:	lsr	x14, x11, x14
 178:	subs	x15, x12, #0x0
 17c:	csel	x14, x13, x14, eq  // eq = none
 180:	lsl	x16, x11, x12
 184:	subs	x12, x12, #0x40
 188:	subs	x12, x12, #0x0
 18c:	csel	x14, x16, x14, ge  // ge = tcont
 190:	mov	w16, w10
 194:	lsl	x11, x11, x16
 198:	csel	x11, x13, x11, ge  // ge = tcont
 19c:	mul	x13, x9, x14
 1a0:	umulh	x14, x9, x11
 1a4:	add	x13, x14, x13
 1a8:	mul	x8, x8, x11
 1ac:	add	x8, x13, x8
 1b0:	mul	x9, x9, x11
 1b4:	stur	x9, [x29, #-16]
 1b8:	stur	x8, [x29, #-8]
 1bc:	b	1c0 <__fixint+0x19c>
 1c0:	ldur	x0, [x29, #-16]
 1c4:	ldur	x1, [x29, #-8]
 1c8:	ldp	x29, x30, [sp, #112]
 1cc:	add	sp, sp, #0x80
 1d0:	ret

00000000000001d4 <toRep>:
 1d4:	sub	sp, sp, #0x10
 1d8:	str	s0, [sp, #12]
 1dc:	ldr	w8, [sp, #12]
 1e0:	str	w8, [sp, #8]
 1e4:	ldr	w0, [sp, #8]
 1e8:	add	sp, sp, #0x10
 1ec:	ret

fixunsdfdi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunsdfdi>:
   0:	sub	sp, sp, #0x20
   4:	str	d0, [sp, #16]
   8:	ldr	d0, [sp, #16]
   c:	fcmp	d0, #0.0
  10:	cset	w8, ls  // ls = plast
  14:	tbnz	w8, #0, 1c <__fixunsdfdi+0x1c>
  18:	b	24 <__fixunsdfdi+0x24>
  1c:	str	xzr, [sp, #24]
  20:	b	74 <__fixunsdfdi+0x74>
  24:	ldr	d0, [sp, #16]
  28:	mov	x8, #0x41f0000000000000    	// #4751297606875873280
  2c:	fmov	d1, x8
  30:	fdiv	d0, d0, d1
  34:	fcvtzu	w9, d0
  38:	str	w9, [sp, #12]
  3c:	ldr	d0, [sp, #16]
  40:	ldr	s2, [sp, #12]
  44:	mov	v3.16b, v2.16b
  48:	ucvtf	d3, d3
  4c:	fmul	d1, d3, d1
  50:	fsub	d0, d0, d1
  54:	fcvtzu	w9, d0
  58:	str	w9, [sp, #8]
  5c:	ldr	w9, [sp, #12]
  60:	mov	w8, w9
  64:	ldr	w9, [sp, #8]
  68:	mov	w10, w9
  6c:	orr	x8, x10, x8, lsl #32
  70:	str	x8, [sp, #24]
  74:	ldr	x0, [sp, #24]
  78:	add	sp, sp, #0x20
  7c:	ret

fixunsdfsi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunsdfsi>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp, #8]
  10:	ldr	d0, [sp, #8]
  14:	bl	24 <__fixuint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixuint>:
  24:	sub	sp, sp, #0x50
  28:	stp	x29, x30, [sp, #64]
  2c:	add	x29, sp, #0x40
  30:	mov	w8, #0xffffffff            	// #-1
  34:	mov	w9, #0x1                   	// #1
  38:	stur	d0, [x29, #-16]
  3c:	ldur	d0, [x29, #-16]
  40:	str	w8, [sp, #12]
  44:	str	w9, [sp, #8]
  48:	bl	124 <toRep>
  4c:	stur	x0, [x29, #-24]
  50:	ldur	x10, [x29, #-24]
  54:	and	x10, x10, #0x7fffffffffffffff
  58:	str	x10, [sp, #32]
  5c:	ldur	x10, [x29, #-24]
  60:	tst	x10, #0x8000000000000000
  64:	ldr	w8, [sp, #12]
  68:	ldr	w9, [sp, #8]
  6c:	csel	w11, w8, w9, ne  // ne = any
  70:	str	w11, [sp, #28]
  74:	ldr	x10, [sp, #32]
  78:	lsr	x10, x10, #52
  7c:	subs	x10, x10, #0x3ff
  80:	str	w10, [sp, #24]
  84:	ldr	x12, [sp, #32]
  88:	and	x12, x12, #0xfffffffffffff
  8c:	orr	x12, x12, #0x10000000000000
  90:	str	x12, [sp, #16]
  94:	ldr	w10, [sp, #28]
  98:	cmp	w10, w8
  9c:	b.eq	b0 <__fixuint+0x8c>  // b.none
  a0:	ldr	w8, [sp, #24]
  a4:	cmp	w8, #0x0
  a8:	cset	w8, ge  // ge = tcont
  ac:	tbnz	w8, #0, b8 <__fixuint+0x94>
  b0:	stur	wzr, [x29, #-4]
  b4:	b	114 <__fixuint+0xf0>
  b8:	ldr	w8, [sp, #24]
  bc:	mov	w9, w8
  c0:	cmp	x9, #0x20
  c4:	b.cc	d4 <__fixuint+0xb0>  // b.lo, b.ul, b.last
  c8:	mov	w8, #0xffffffff            	// #-1
  cc:	stur	w8, [x29, #-4]
  d0:	b	114 <__fixuint+0xf0>
  d4:	ldr	w8, [sp, #24]
  d8:	cmp	w8, #0x34
  dc:	b.ge	100 <__fixuint+0xdc>  // b.tcont
  e0:	ldr	x8, [sp, #16]
  e4:	ldr	w9, [sp, #24]
  e8:	mov	w10, #0x34                  	// #52
  ec:	subs	w9, w10, w9
  f0:	mov	w11, w9
  f4:	lsr	x8, x8, x11
  f8:	stur	w8, [x29, #-4]
  fc:	b	114 <__fixuint+0xf0>
 100:	ldr	x8, [sp, #16]
 104:	ldr	w9, [sp, #24]
 108:	subs	w9, w9, #0x34
 10c:	lsl	w8, w8, w9
 110:	stur	w8, [x29, #-4]
 114:	ldur	w0, [x29, #-4]
 118:	ldp	x29, x30, [sp, #64]
 11c:	add	sp, sp, #0x50
 120:	ret

0000000000000124 <toRep>:
 124:	sub	sp, sp, #0x10
 128:	str	d0, [sp, #8]
 12c:	ldr	x8, [sp, #8]
 130:	str	x8, [sp]
 134:	ldr	x0, [sp]
 138:	add	sp, sp, #0x10
 13c:	ret

fixunsdfti.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunsdfti>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp, #8]
  10:	ldr	d0, [sp, #8]
  14:	bl	24 <__fixuint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixuint>:
  24:	sub	sp, sp, #0x50
  28:	stp	x29, x30, [sp, #64]
  2c:	add	x29, sp, #0x40
  30:	stur	d0, [x29, #-24]
  34:	ldur	d0, [x29, #-24]
  38:	bl	168 <toRep>
  3c:	str	x0, [sp, #32]
  40:	ldr	x8, [sp, #32]
  44:	and	x8, x8, #0x7fffffffffffffff
  48:	str	x8, [sp, #24]
  4c:	ldr	x8, [sp, #32]
  50:	ands	x8, x8, #0x8000000000000000
  54:	mov	w9, #0xffffffff            	// #-1
  58:	cneg	w9, w9, eq  // eq = none
  5c:	str	w9, [sp, #20]
  60:	ldr	x10, [sp, #24]
  64:	lsr	x10, x10, #52
  68:	subs	w9, w10, #0x3ff
  6c:	mov	w0, w9
  70:	str	w0, [sp, #16]
  74:	ldr	x11, [sp, #24]
  78:	mov	x12, #0x10000000000000      	// #4503599627370496
  7c:	bfxil	x12, x11, #0, #52
  80:	str	x12, [sp, #8]
  84:	ldr	w9, [sp, #20]
  88:	adds	w9, w9, #0x1
  8c:	b.eq	a0 <__fixuint+0x7c>  // b.none
  90:	b	94 <__fixuint+0x70>
  94:	ldr	w8, [sp, #16]
  98:	tbz	w8, #31, b0 <__fixuint+0x8c>
  9c:	b	a0 <__fixuint+0x7c>
  a0:	mov	x8, xzr
  a4:	stur	x8, [x29, #-8]
  a8:	stur	x8, [x29, #-16]
  ac:	b	154 <__fixuint+0x130>
  b0:	ldr	w8, [sp, #16]
  b4:	subs	w8, w8, #0x80
  b8:	b.cc	d0 <__fixuint+0xac>  // b.lo, b.ul, b.last
  bc:	b	c0 <__fixuint+0x9c>
  c0:	mov	x8, #0xffffffffffffffff    	// #-1
  c4:	stur	x8, [x29, #-8]
  c8:	stur	x8, [x29, #-16]
  cc:	b	154 <__fixuint+0x130>
  d0:	ldr	w8, [sp, #16]
  d4:	subs	w8, w8, #0x33
  d8:	b.gt	108 <__fixuint+0xe4>
  dc:	b	e0 <__fixuint+0xbc>
  e0:	ldr	x8, [sp, #8]
  e4:	ldr	w9, [sp, #16]
  e8:	mov	w10, #0x34                  	// #52
  ec:	subs	w9, w10, w9
  f0:	mov	w11, w9
  f4:	lsr	x8, x8, x11
  f8:	mov	x11, xzr
  fc:	stur	x11, [x29, #-8]
 100:	stur	x8, [x29, #-16]
 104:	b	154 <__fixuint+0x130>
 108:	ldr	x8, [sp, #8]
 10c:	ldr	w9, [sp, #16]
 110:	subs	w9, w9, #0x34
 114:	mov	w10, w9
 118:	mov	x11, xzr
 11c:	sub	x12, x11, x10
 120:	lsr	x12, x8, x12
 124:	subs	x13, x10, #0x0
 128:	csel	x12, x11, x12, eq  // eq = none
 12c:	lsl	x14, x8, x10
 130:	subs	x10, x10, #0x40
 134:	subs	x10, x10, #0x0
 138:	csel	x12, x14, x12, ge  // ge = tcont
 13c:	mov	w14, w9
 140:	lsl	x8, x8, x14
 144:	csel	x8, x11, x8, ge  // ge = tcont
 148:	stur	x8, [x29, #-16]
 14c:	stur	x12, [x29, #-8]
 150:	b	154 <__fixuint+0x130>
 154:	ldur	x0, [x29, #-16]
 158:	ldur	x1, [x29, #-8]
 15c:	ldp	x29, x30, [sp, #64]
 160:	add	sp, sp, #0x50
 164:	ret

0000000000000168 <toRep>:
 168:	sub	sp, sp, #0x10
 16c:	str	d0, [sp, #8]
 170:	ldr	x8, [sp, #8]
 174:	str	x8, [sp]
 178:	ldr	x0, [sp]
 17c:	add	sp, sp, #0x10
 180:	ret

fixunssfdi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunssfdi>:
   0:	sub	sp, sp, #0x20
   4:	str	s0, [sp, #20]
   8:	ldr	s0, [sp, #20]
   c:	fcmp	s0, #0.0
  10:	cset	w8, ls  // ls = plast
  14:	tbnz	w8, #0, 1c <__fixunssfdi+0x1c>
  18:	b	24 <__fixunssfdi+0x24>
  1c:	str	xzr, [sp, #24]
  20:	b	80 <__fixunssfdi+0x80>
  24:	ldr	s0, [sp, #20]
  28:	fcvt	d1, s0
  2c:	str	d1, [sp, #8]
  30:	ldr	d1, [sp, #8]
  34:	mov	x8, #0x41f0000000000000    	// #4751297606875873280
  38:	fmov	d2, x8
  3c:	fdiv	d1, d1, d2
  40:	fcvtzu	w9, d1
  44:	str	w9, [sp, #4]
  48:	ldr	d1, [sp, #8]
  4c:	ldr	s0, [sp, #4]
  50:	mov	v3.16b, v0.16b
  54:	ucvtf	d3, d3
  58:	fmul	d2, d3, d2
  5c:	fsub	d1, d1, d2
  60:	fcvtzu	w9, d1
  64:	str	w9, [sp]
  68:	ldr	w9, [sp, #4]
  6c:	mov	w8, w9
  70:	ldr	w9, [sp]
  74:	mov	w10, w9
  78:	orr	x8, x10, x8, lsl #32
  7c:	str	x8, [sp, #24]
  80:	ldr	x0, [sp, #24]
  84:	add	sp, sp, #0x20
  88:	ret

fixunssfsi.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunssfsi>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	ldur	s0, [x29, #-4]
  14:	bl	24 <__fixuint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixuint>:
  24:	sub	sp, sp, #0x40
  28:	stp	x29, x30, [sp, #48]
  2c:	add	x29, sp, #0x30
  30:	mov	w8, #0x80000000            	// #-2147483648
  34:	mov	w9, #0xffffffff            	// #-1
  38:	mov	w10, #0x1                   	// #1
  3c:	stur	s0, [x29, #-8]
  40:	ldur	s0, [x29, #-8]
  44:	str	w8, [sp, #16]
  48:	str	w9, [sp, #12]
  4c:	str	w10, [sp, #8]
  50:	bl	12c <toRep>
  54:	stur	w0, [x29, #-12]
  58:	ldur	w8, [x29, #-12]
  5c:	and	w8, w8, #0x7fffffff
  60:	stur	w8, [x29, #-16]
  64:	ldur	w8, [x29, #-12]
  68:	ldr	w9, [sp, #16]
  6c:	tst	w8, w9
  70:	ldr	w8, [sp, #12]
  74:	ldr	w10, [sp, #8]
  78:	csel	w11, w8, w10, ne  // ne = any
  7c:	stur	w11, [x29, #-20]
  80:	ldur	w11, [x29, #-16]
  84:	lsr	w11, w11, #23
  88:	subs	w11, w11, #0x7f
  8c:	str	w11, [sp, #24]
  90:	ldur	w11, [x29, #-16]
  94:	and	w11, w11, #0x7fffff
  98:	orr	w11, w11, #0x800000
  9c:	str	w11, [sp, #20]
  a0:	ldur	w11, [x29, #-20]
  a4:	cmp	w11, w8
  a8:	b.eq	bc <__fixuint+0x98>  // b.none
  ac:	ldr	w8, [sp, #24]
  b0:	cmp	w8, #0x0
  b4:	cset	w8, ge  // ge = tcont
  b8:	tbnz	w8, #0, c4 <__fixuint+0xa0>
  bc:	stur	wzr, [x29, #-4]
  c0:	b	11c <__fixuint+0xf8>
  c4:	ldr	w8, [sp, #24]
  c8:	mov	w9, w8
  cc:	cmp	x9, #0x20
  d0:	b.cc	e0 <__fixuint+0xbc>  // b.lo, b.ul, b.last
  d4:	mov	w8, #0xffffffff            	// #-1
  d8:	stur	w8, [x29, #-4]
  dc:	b	11c <__fixuint+0xf8>
  e0:	ldr	w8, [sp, #24]
  e4:	cmp	w8, #0x17
  e8:	b.ge	108 <__fixuint+0xe4>  // b.tcont
  ec:	ldr	w8, [sp, #20]
  f0:	ldr	w9, [sp, #24]
  f4:	mov	w10, #0x17                  	// #23
  f8:	subs	w9, w10, w9
  fc:	lsr	w8, w8, w9
 100:	stur	w8, [x29, #-4]
 104:	b	11c <__fixuint+0xf8>
 108:	ldr	w8, [sp, #20]
 10c:	ldr	w9, [sp, #24]
 110:	subs	w9, w9, #0x17
 114:	lsl	w8, w8, w9
 118:	stur	w8, [x29, #-4]
 11c:	ldur	w0, [x29, #-4]
 120:	ldp	x29, x30, [sp, #48]
 124:	add	sp, sp, #0x40
 128:	ret

000000000000012c <toRep>:
 12c:	sub	sp, sp, #0x10
 130:	str	s0, [sp, #12]
 134:	ldr	w8, [sp, #12]
 138:	str	w8, [sp, #8]
 13c:	ldr	w0, [sp, #8]
 140:	add	sp, sp, #0x10
 144:	ret

fixunssfti.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fixunssfti>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	ldur	s0, [x29, #-4]
  14:	bl	24 <__fixuint>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__fixuint>:
  24:	sub	sp, sp, #0x40
  28:	stp	x29, x30, [sp, #48]
  2c:	add	x29, sp, #0x30
  30:	stur	s0, [x29, #-20]
  34:	ldur	s0, [x29, #-20]
  38:	bl	168 <toRep>
  3c:	str	w0, [sp, #24]
  40:	ldr	w8, [sp, #24]
  44:	and	w8, w8, #0x7fffffff
  48:	str	w8, [sp, #20]
  4c:	ldr	w8, [sp, #24]
  50:	ands	w8, w8, #0x80000000
  54:	mov	w9, #0xffffffff            	// #-1
  58:	cneg	w9, w9, eq  // eq = none
  5c:	str	w9, [sp, #16]
  60:	ldr	w9, [sp, #20]
  64:	lsr	w9, w9, #23
  68:	subs	w9, w9, #0x7f
  6c:	str	w9, [sp, #12]
  70:	ldr	w9, [sp, #20]
  74:	mov	w10, #0x800000              	// #8388608
  78:	bfxil	w10, w9, #0, #23
  7c:	str	w10, [sp, #8]
  80:	ldr	w9, [sp, #16]
  84:	adds	w9, w9, #0x1
  88:	b.eq	9c <__fixuint+0x78>  // b.none
  8c:	b	90 <__fixuint+0x6c>
  90:	ldr	w8, [sp, #12]
  94:	tbz	w8, #31, ac <__fixuint+0x88>
  98:	b	9c <__fixuint+0x78>
  9c:	mov	x8, xzr
  a0:	stur	x8, [x29, #-8]
  a4:	stur	x8, [x29, #-16]
  a8:	b	154 <__fixuint+0x130>
  ac:	ldr	w8, [sp, #12]
  b0:	subs	w8, w8, #0x80
  b4:	b.cc	cc <__fixuint+0xa8>  // b.lo, b.ul, b.last
  b8:	b	bc <__fixuint+0x98>
  bc:	mov	x8, #0xffffffffffffffff    	// #-1
  c0:	stur	x8, [x29, #-8]
  c4:	stur	x8, [x29, #-16]
  c8:	b	154 <__fixuint+0x130>
  cc:	ldr	w8, [sp, #12]
  d0:	subs	w8, w8, #0x16
  d4:	b.gt	104 <__fixuint+0xe0>
  d8:	b	dc <__fixuint+0xb8>
  dc:	ldr	w8, [sp, #8]
  e0:	ldr	w9, [sp, #12]
  e4:	mov	w10, #0x17                  	// #23
  e8:	subs	w9, w10, w9
  ec:	lsr	w8, w8, w9
  f0:	mov	w11, w8
  f4:	mov	x12, xzr
  f8:	stur	x12, [x29, #-8]
  fc:	stur	x11, [x29, #-16]
 100:	b	154 <__fixuint+0x130>
 104:	ldr	w8, [sp, #8]
 108:	mov	w9, w8
 10c:	ldr	w8, [sp, #12]
 110:	subs	w8, w8, #0x17
 114:	mov	w10, w8
 118:	mov	x11, xzr
 11c:	sub	x12, x11, x10
 120:	lsr	x12, x9, x12
 124:	subs	x13, x10, #0x0
 128:	csel	x12, x11, x12, eq  // eq = none
 12c:	lsl	x14, x9, x10
 130:	subs	x10, x10, #0x40
 134:	subs	x10, x10, #0x0
 138:	csel	x12, x14, x12, ge  // ge = tcont
 13c:	mov	w14, w8
 140:	lsl	x9, x9, x14
 144:	csel	x9, x11, x9, ge  // ge = tcont
 148:	stur	x9, [x29, #-16]
 14c:	stur	x12, [x29, #-8]
 150:	b	154 <__fixuint+0x130>
 154:	ldur	x0, [x29, #-16]
 158:	ldur	x1, [x29, #-8]
 15c:	ldp	x29, x30, [sp, #48]
 160:	add	sp, sp, #0x40
 164:	ret

0000000000000168 <toRep>:
 168:	sub	sp, sp, #0x10
 16c:	str	s0, [sp, #12]
 170:	ldr	w8, [sp, #12]
 174:	str	w8, [sp, #8]
 178:	ldr	w0, [sp, #8]
 17c:	add	sp, sp, #0x10
 180:	ret

floatdidf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatdidf>:
   0:	sub	sp, sp, #0x20
   4:	adrp	x8, 0 <__floatdidf>
   8:	add	x8, x8, #0x0
   c:	mov	x9, #0x41f0000000000000    	// #4751297606875873280
  10:	fmov	d0, x9
  14:	mov	x9, #0x4330000000000000    	// #4841369599423283200
  18:	fmov	d1, x9
  1c:	str	x0, [sp, #24]
  20:	ldr	x8, [x8]
  24:	str	x8, [sp, #16]
  28:	ldr	x8, [sp, #24]
  2c:	asr	x8, x8, #32
  30:	scvtf	d2, w8
  34:	fmul	d0, d2, d0
  38:	str	d0, [sp, #8]
  3c:	ldr	x9, [sp, #24]
  40:	and	x9, x9, #0xffffffff
  44:	ldr	x10, [sp, #16]
  48:	orr	x9, x10, x9
  4c:	str	x9, [sp, #16]
  50:	ldr	d0, [sp, #8]
  54:	fsub	d0, d0, d1
  58:	ldr	d1, [sp, #16]
  5c:	fadd	d0, d0, d1
  60:	str	d0, [sp]
  64:	ldr	d0, [sp]
  68:	add	sp, sp, #0x20
  6c:	ret

floatdisf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatdisf>:
   0:	sub	sp, sp, #0x30
   4:	str	x0, [sp, #32]
   8:	ldr	x8, [sp, #32]
   c:	cbnz	x8, 1c <__floatdisf+0x1c>
  10:	fmov	s0, wzr
  14:	str	s0, [sp, #44]
  18:	b	1a0 <__floatdisf+0x1a0>
  1c:	mov	w8, #0x40                  	// #64
  20:	str	w8, [sp, #28]
  24:	ldr	x9, [sp, #32]
  28:	asr	x9, x9, #63
  2c:	str	x9, [sp, #16]
  30:	ldr	x9, [sp, #32]
  34:	ldr	x10, [sp, #16]
  38:	eor	x9, x9, x10
  3c:	ldr	x10, [sp, #16]
  40:	subs	x9, x9, x10
  44:	str	x9, [sp, #32]
  48:	ldr	x9, [sp, #32]
  4c:	clz	x9, x9
  50:	subs	w8, w8, w9
  54:	str	w8, [sp, #12]
  58:	ldr	w8, [sp, #12]
  5c:	subs	w8, w8, #0x1
  60:	str	w8, [sp, #8]
  64:	ldr	w8, [sp, #12]
  68:	cmp	w8, #0x18
  6c:	b.le	158 <__floatdisf+0x158>
  70:	ldr	w8, [sp, #12]
  74:	cmp	w8, #0x19
  78:	str	w8, [sp]
  7c:	b.eq	94 <__floatdisf+0x94>  // b.none
  80:	b	84 <__floatdisf+0x84>
  84:	ldr	w8, [sp]
  88:	cmp	w8, #0x1a
  8c:	b.eq	a4 <__floatdisf+0xa4>  // b.none
  90:	b	a8 <__floatdisf+0xa8>
  94:	ldr	x8, [sp, #32]
  98:	lsl	x8, x8, #1
  9c:	str	x8, [sp, #32]
  a0:	b	f4 <__floatdisf+0xf4>
  a4:	b	f4 <__floatdisf+0xf4>
  a8:	ldr	x8, [sp, #32]
  ac:	ldr	w9, [sp, #12]
  b0:	subs	w9, w9, #0x1a
  b4:	mov	w10, w9
  b8:	lsr	x8, x8, x10
  bc:	ldr	x10, [sp, #32]
  c0:	ldr	w9, [sp, #12]
  c4:	mov	w11, #0x5a                  	// #90
  c8:	subs	w9, w11, w9
  cc:	mov	x12, #0xffffffffffffffff    	// #-1
  d0:	mov	w13, w9
  d4:	lsr	x12, x12, x13
  d8:	tst	x10, x12
  dc:	cset	w9, ne  // ne = any
  e0:	and	w9, w9, #0x1
  e4:	mov	w0, w9
  e8:	sxtw	x10, w0
  ec:	orr	x8, x8, x10
  f0:	str	x8, [sp, #32]
  f4:	ldr	x8, [sp, #32]
  f8:	tst	x8, #0x4
  fc:	cset	w9, ne  // ne = any
 100:	and	w9, w9, #0x1
 104:	mov	w0, w9
 108:	sxtw	x8, w0
 10c:	ldr	x10, [sp, #32]
 110:	orr	x8, x10, x8
 114:	str	x8, [sp, #32]
 118:	ldr	x8, [sp, #32]
 11c:	add	x8, x8, #0x1
 120:	str	x8, [sp, #32]
 124:	ldr	x8, [sp, #32]
 128:	asr	x8, x8, #2
 12c:	str	x8, [sp, #32]
 130:	ldr	x8, [sp, #32]
 134:	and	x8, x8, #0x1000000
 138:	cbz	x8, 154 <__floatdisf+0x154>
 13c:	ldr	x8, [sp, #32]
 140:	asr	x8, x8, #1
 144:	str	x8, [sp, #32]
 148:	ldr	w9, [sp, #8]
 14c:	add	w9, w9, #0x1
 150:	str	w9, [sp, #8]
 154:	b	174 <__floatdisf+0x174>
 158:	ldr	w8, [sp, #12]
 15c:	mov	w9, #0x18                  	// #24
 160:	subs	w8, w9, w8
 164:	ldr	x10, [sp, #32]
 168:	mov	w11, w8
 16c:	lsl	x10, x10, x11
 170:	str	x10, [sp, #32]
 174:	ldr	x8, [sp, #16]
 178:	and	w8, w8, #0x80000000
 17c:	ldr	w9, [sp, #8]
 180:	add	w9, w9, #0x7f
 184:	orr	w8, w8, w9, lsl #23
 188:	ldr	x10, [sp, #32]
 18c:	and	w9, w10, #0x7fffff
 190:	orr	w8, w8, w9
 194:	str	w8, [sp, #4]
 198:	ldr	w8, [sp, #4]
 19c:	str	w8, [sp, #44]
 1a0:	ldr	s0, [sp, #44]
 1a4:	add	sp, sp, #0x30
 1a8:	ret

floatsidf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatsidf>:
   0:	sub	sp, sp, #0x40
   4:	stp	x29, x30, [sp, #48]
   8:	add	x29, sp, #0x30
   c:	mov	w8, #0x20                  	// #32
  10:	stur	w0, [x29, #-12]
  14:	stur	w8, [x29, #-16]
  18:	ldur	w8, [x29, #-12]
  1c:	cbnz	w8, 34 <__floatsidf+0x34>
  20:	mov	x8, xzr
  24:	mov	x0, x8
  28:	bl	e0 <fromRep>
  2c:	stur	d0, [x29, #-8]
  30:	b	d0 <__floatsidf+0xd0>
  34:	str	xzr, [sp, #24]
  38:	ldur	w8, [x29, #-12]
  3c:	cmp	w8, #0x0
  40:	cset	w8, ge  // ge = tcont
  44:	tbnz	w8, #0, 60 <__floatsidf+0x60>
  48:	mov	x8, #0x8000000000000000    	// #-9223372036854775808
  4c:	str	x8, [sp, #24]
  50:	ldur	w9, [x29, #-12]
  54:	mov	w10, wzr
  58:	subs	w9, w10, w9
  5c:	stur	w9, [x29, #-12]
  60:	ldur	w8, [x29, #-12]
  64:	clz	w8, w8
  68:	mov	w9, #0x1f                  	// #31
  6c:	subs	w8, w9, w8
  70:	str	w8, [sp, #20]
  74:	ldr	w8, [sp, #20]
  78:	mov	w9, #0x34                  	// #52
  7c:	subs	w8, w9, w8
  80:	str	w8, [sp, #4]
  84:	ldur	w8, [x29, #-12]
  88:	mov	w10, w8
  8c:	ldr	w8, [sp, #4]
  90:	mov	w11, w8
  94:	lsl	x10, x10, x11
  98:	eor	x10, x10, #0x10000000000000
  9c:	str	x10, [sp, #8]
  a0:	ldr	w8, [sp, #20]
  a4:	add	w8, w8, #0x3ff
  a8:	mov	w0, w8
  ac:	sxtw	x10, w0
  b0:	ldr	x11, [sp, #8]
  b4:	add	x10, x11, x10, lsl #52
  b8:	str	x10, [sp, #8]
  bc:	ldr	x10, [sp, #8]
  c0:	ldr	x11, [sp, #24]
  c4:	orr	x0, x10, x11
  c8:	bl	e0 <fromRep>
  cc:	stur	d0, [x29, #-8]
  d0:	ldur	d0, [x29, #-8]
  d4:	ldp	x29, x30, [sp, #48]
  d8:	add	sp, sp, #0x40
  dc:	ret

00000000000000e0 <fromRep>:
  e0:	sub	sp, sp, #0x10
  e4:	str	x0, [sp, #8]
  e8:	ldr	x8, [sp, #8]
  ec:	str	x8, [sp]
  f0:	ldr	d0, [sp]
  f4:	add	sp, sp, #0x10
  f8:	ret

floatsisf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatsisf>:
   0:	sub	sp, sp, #0x40
   4:	stp	x29, x30, [sp, #48]
   8:	add	x29, sp, #0x30
   c:	mov	w8, #0x20                  	// #32
  10:	stur	w0, [x29, #-8]
  14:	stur	w8, [x29, #-12]
  18:	ldur	w8, [x29, #-8]
  1c:	cbnz	w8, 34 <__floatsisf+0x34>
  20:	mov	w8, wzr
  24:	mov	w0, w8
  28:	bl	158 <fromRep>
  2c:	stur	s0, [x29, #-4]
  30:	b	148 <__floatsisf+0x148>
  34:	stur	wzr, [x29, #-16]
  38:	ldur	w8, [x29, #-8]
  3c:	cmp	w8, #0x0
  40:	cset	w8, ge  // ge = tcont
  44:	tbnz	w8, #0, 60 <__floatsisf+0x60>
  48:	mov	w8, #0x80000000            	// #-2147483648
  4c:	stur	w8, [x29, #-16]
  50:	ldur	w8, [x29, #-8]
  54:	mov	w9, wzr
  58:	subs	w8, w9, w8
  5c:	stur	w8, [x29, #-8]
  60:	ldur	w8, [x29, #-8]
  64:	clz	w8, w8
  68:	mov	w9, #0x1f                  	// #31
  6c:	subs	w8, w9, w8
  70:	stur	w8, [x29, #-20]
  74:	ldur	w8, [x29, #-20]
  78:	cmp	w8, #0x17
  7c:	b.gt	a8 <__floatsisf+0xa8>
  80:	ldur	w8, [x29, #-20]
  84:	mov	w9, #0x17                  	// #23
  88:	subs	w8, w9, w8
  8c:	str	w8, [sp, #20]
  90:	ldur	w8, [x29, #-8]
  94:	ldr	w9, [sp, #20]
  98:	lsl	w8, w8, w9
  9c:	eor	w8, w8, #0x800000
  a0:	str	w8, [sp, #24]
  a4:	b	120 <__floatsisf+0x120>
  a8:	ldur	w8, [x29, #-20]
  ac:	subs	w8, w8, #0x17
  b0:	str	w8, [sp, #16]
  b4:	ldur	w8, [x29, #-8]
  b8:	ldr	w9, [sp, #16]
  bc:	lsr	w8, w8, w9
  c0:	eor	w8, w8, #0x800000
  c4:	str	w8, [sp, #24]
  c8:	ldur	w8, [x29, #-8]
  cc:	ldrsw	x10, [sp, #16]
  d0:	mov	x11, #0x20                  	// #32
  d4:	subs	x10, x11, x10
  d8:	lsl	w8, w8, w10
  dc:	str	w8, [sp, #12]
  e0:	ldr	w8, [sp, #12]
  e4:	mov	w9, #0x80000000            	// #-2147483648
  e8:	cmp	w8, w9
  ec:	b.ls	fc <__floatsisf+0xfc>  // b.plast
  f0:	ldr	w8, [sp, #24]
  f4:	add	w8, w8, #0x1
  f8:	str	w8, [sp, #24]
  fc:	ldr	w8, [sp, #12]
 100:	mov	w9, #0x80000000            	// #-2147483648
 104:	cmp	w8, w9
 108:	b.ne	120 <__floatsisf+0x120>  // b.any
 10c:	ldr	w8, [sp, #24]
 110:	and	w8, w8, #0x1
 114:	ldr	w9, [sp, #24]
 118:	add	w8, w9, w8
 11c:	str	w8, [sp, #24]
 120:	ldur	w8, [x29, #-20]
 124:	add	w8, w8, #0x7f
 128:	ldr	w9, [sp, #24]
 12c:	add	w8, w9, w8, lsl #23
 130:	str	w8, [sp, #24]
 134:	ldr	w8, [sp, #24]
 138:	ldur	w9, [x29, #-16]
 13c:	orr	w0, w8, w9
 140:	bl	158 <fromRep>
 144:	stur	s0, [x29, #-4]
 148:	ldur	s0, [x29, #-4]
 14c:	ldp	x29, x30, [sp, #48]
 150:	add	sp, sp, #0x40
 154:	ret

0000000000000158 <fromRep>:
 158:	sub	sp, sp, #0x10
 15c:	str	w0, [sp, #12]
 160:	ldr	w8, [sp, #12]
 164:	str	w8, [sp, #8]
 168:	ldr	s0, [sp, #8]
 16c:	add	sp, sp, #0x10
 170:	ret

floattidf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floattidf>:
   0:	sub	sp, sp, #0x70
   4:	stp	x29, x30, [sp, #96]
   8:	add	x29, sp, #0x60
   c:	stur	x1, [x29, #-24]
  10:	stur	x0, [x29, #-32]
  14:	ldur	x8, [x29, #-24]
  18:	ldur	x9, [x29, #-32]
  1c:	orr	x8, x9, x8
  20:	cbnz	x8, 34 <__floattidf+0x34>
  24:	b	28 <__floattidf+0x28>
  28:	mov	x8, xzr
  2c:	stur	x8, [x29, #-8]
  30:	b	2b0 <__floattidf+0x2b0>
  34:	mov	w8, #0x80                  	// #128
  38:	stur	w8, [x29, #-36]
  3c:	ldur	x9, [x29, #-24]
  40:	asr	x9, x9, #63
  44:	str	x9, [sp, #40]
  48:	str	x9, [sp, #32]
  4c:	ldur	x9, [x29, #-32]
  50:	ldur	x10, [x29, #-24]
  54:	ldr	x11, [sp, #32]
  58:	ldr	x12, [sp, #40]
  5c:	eor	x10, x10, x12
  60:	eor	x9, x9, x11
  64:	subs	x9, x9, x11
  68:	sbcs	x10, x10, x12
  6c:	stur	x9, [x29, #-32]
  70:	stur	x10, [x29, #-24]
  74:	ldur	x1, [x29, #-24]
  78:	ldur	x0, [x29, #-32]
  7c:	str	w8, [sp, #12]
  80:	bl	0 <__clzti2>
  84:	ldr	w8, [sp, #12]
  88:	subs	w13, w8, w0
  8c:	str	w13, [sp, #28]
  90:	ldr	w13, [sp, #28]
  94:	subs	w13, w13, #0x1
  98:	str	w13, [sp, #24]
  9c:	ldr	w13, [sp, #28]
  a0:	subs	w13, w13, #0x36
  a4:	b.lt	21c <__floattidf+0x21c>  // b.tstop
  a8:	b	ac <__floattidf+0xac>
  ac:	ldr	w8, [sp, #28]
  b0:	mov	w9, w8
  b4:	subs	w8, w8, #0x36
  b8:	str	w9, [sp, #8]
  bc:	b.eq	d4 <__floattidf+0xd4>  // b.none
  c0:	b	c4 <__floattidf+0xc4>
  c4:	ldr	w8, [sp, #8]
  c8:	subs	w9, w8, #0x37
  cc:	b.eq	f0 <__floattidf+0xf0>  // b.none
  d0:	b	f4 <__floattidf+0xf4>
  d4:	ldur	x8, [x29, #-32]
  d8:	ldur	x9, [x29, #-24]
  dc:	extr	x9, x9, x8, #63
  e0:	lsl	x8, x8, #1
  e4:	stur	x9, [x29, #-24]
  e8:	stur	x8, [x29, #-32]
  ec:	b	1a0 <__floattidf+0x1a0>
  f0:	b	1a0 <__floattidf+0x1a0>
  f4:	ldur	x8, [x29, #-32]
  f8:	ldur	x9, [x29, #-24]
  fc:	ldr	w10, [sp, #28]
 100:	subs	w11, w10, #0x37
 104:	mov	w12, w11
 108:	mov	x13, xzr
 10c:	sub	x14, x13, x12
 110:	lsl	x14, x9, x14
 114:	subs	x15, x12, #0x0
 118:	csel	x14, x13, x14, eq  // eq = none
 11c:	mov	w16, w11
 120:	lsr	x17, x8, x16
 124:	orr	x14, x17, x14
 128:	lsr	x17, x9, x12
 12c:	subs	x12, x12, #0x40
 130:	subs	x12, x12, #0x0
 134:	csel	x14, x17, x14, ge  // ge = tcont
 138:	lsr	x16, x9, x16
 13c:	csel	x16, x13, x16, ge  // ge = tcont
 140:	mov	w11, #0xb7                  	// #183
 144:	subs	w10, w11, w10
 148:	mov	w17, w10
 14c:	sub	x18, x13, x17
 150:	lsr	x18, x8, x18
 154:	subs	x0, x17, #0x0
 158:	csel	x18, x13, x18, eq  // eq = none
 15c:	mov	w1, w10
 160:	lsl	x2, x8, x1
 164:	subs	x3, x17, #0x40
 168:	subs	x3, x3, #0x0
 16c:	csel	x13, x13, x2, ge  // ge = tcont
 170:	lsl	x9, x9, x1
 174:	orr	x9, x18, x9
 178:	lsl	x8, x8, x17
 17c:	csel	x8, x8, x9, ge  // ge = tcont
 180:	orr	x8, x13, x8
 184:	subs	x8, x8, #0x0
 188:	cset	w10, ne  // ne = any
 18c:	mov	w9, w10
 190:	orr	x9, x14, x9
 194:	stur	x16, [x29, #-24]
 198:	stur	x9, [x29, #-32]
 19c:	b	1a0 <__floattidf+0x1a0>
 1a0:	ldur	x8, [x29, #-32]
 1a4:	and	x9, x8, #0x4
 1a8:	orr	x8, x8, x9, lsr #2
 1ac:	stur	x8, [x29, #-32]
 1b0:	ldur	x8, [x29, #-24]
 1b4:	ldur	x9, [x29, #-32]
 1b8:	adds	x9, x9, #0x1
 1bc:	mov	x10, xzr
 1c0:	adcs	x8, x8, x10
 1c4:	stur	x9, [x29, #-32]
 1c8:	stur	x8, [x29, #-24]
 1cc:	ldur	x8, [x29, #-32]
 1d0:	ldur	x9, [x29, #-24]
 1d4:	extr	x8, x9, x8, #2
 1d8:	asr	x9, x9, #2
 1dc:	stur	x9, [x29, #-24]
 1e0:	stur	x8, [x29, #-32]
 1e4:	ldurb	w11, [x29, #-26]
 1e8:	tbz	w11, #5, 218 <__floattidf+0x218>
 1ec:	b	1f0 <__floattidf+0x1f0>
 1f0:	ldur	x8, [x29, #-32]
 1f4:	ldur	x9, [x29, #-24]
 1f8:	extr	x8, x9, x8, #1
 1fc:	asr	x9, x9, #1
 200:	stur	x9, [x29, #-24]
 204:	stur	x8, [x29, #-32]
 208:	ldr	w10, [sp, #24]
 20c:	add	w10, w10, #0x1
 210:	str	w10, [sp, #24]
 214:	b	218 <__floattidf+0x218>
 218:	b	278 <__floattidf+0x278>
 21c:	ldr	w8, [sp, #28]
 220:	mov	w9, #0x35                  	// #53
 224:	subs	w8, w9, w8
 228:	ldur	x10, [x29, #-24]
 22c:	ldur	x11, [x29, #-32]
 230:	mov	w12, w8
 234:	mov	x13, xzr
 238:	sub	x14, x13, x12
 23c:	lsr	x14, x11, x14
 240:	subs	x15, x12, #0x0
 244:	csel	x14, x13, x14, eq  // eq = none
 248:	mov	w16, w8
 24c:	lsl	x10, x10, x16
 250:	orr	x10, x14, x10
 254:	lsl	x14, x11, x12
 258:	subs	x12, x12, #0x40
 25c:	subs	x12, x12, #0x0
 260:	csel	x10, x14, x10, ge  // ge = tcont
 264:	lsl	x11, x11, x16
 268:	csel	x11, x13, x11, ge  // ge = tcont
 26c:	stur	x11, [x29, #-32]
 270:	stur	x10, [x29, #-24]
 274:	b	278 <__floattidf+0x278>
 278:	ldr	w8, [sp, #32]
 27c:	and	w8, w8, #0x80000000
 280:	ldr	w9, [sp, #24]
 284:	mov	w10, #0x3ff00000            	// #1072693248
 288:	add	w9, w10, w9, lsl #20
 28c:	orr	w8, w8, w9
 290:	ldur	w9, [x29, #-28]
 294:	bfxil	w8, w9, #0, #20
 298:	str	w8, [sp, #20]
 29c:	ldur	w8, [x29, #-32]
 2a0:	str	w8, [sp, #16]
 2a4:	ldr	d0, [sp, #16]
 2a8:	stur	d0, [x29, #-8]
 2ac:	b	2b0 <__floattidf+0x2b0>
 2b0:	ldur	d0, [x29, #-8]
 2b4:	ldp	x29, x30, [sp, #96]
 2b8:	add	sp, sp, #0x70
 2bc:	ret

floattisf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floattisf>:
   0:	sub	sp, sp, #0x70
   4:	stp	x29, x30, [sp, #96]
   8:	add	x29, sp, #0x60
   c:	stur	x1, [x29, #-24]
  10:	stur	x0, [x29, #-32]
  14:	ldur	x8, [x29, #-24]
  18:	ldur	x9, [x29, #-32]
  1c:	orr	x8, x9, x8
  20:	cbnz	x8, 34 <__floattisf+0x34>
  24:	b	28 <__floattisf+0x28>
  28:	mov	w8, wzr
  2c:	stur	w8, [x29, #-4]
  30:	b	2a8 <__floattisf+0x2a8>
  34:	mov	w8, #0x80                  	// #128
  38:	stur	w8, [x29, #-36]
  3c:	ldur	x9, [x29, #-24]
  40:	asr	x9, x9, #63
  44:	str	x9, [sp, #40]
  48:	str	x9, [sp, #32]
  4c:	ldur	x9, [x29, #-32]
  50:	ldur	x10, [x29, #-24]
  54:	ldr	x11, [sp, #32]
  58:	ldr	x12, [sp, #40]
  5c:	eor	x10, x10, x12
  60:	eor	x9, x9, x11
  64:	subs	x9, x9, x11
  68:	sbcs	x10, x10, x12
  6c:	stur	x9, [x29, #-32]
  70:	stur	x10, [x29, #-24]
  74:	ldur	x1, [x29, #-24]
  78:	ldur	x0, [x29, #-32]
  7c:	str	w8, [sp, #12]
  80:	bl	0 <__clzti2>
  84:	ldr	w8, [sp, #12]
  88:	subs	w13, w8, w0
  8c:	str	w13, [sp, #28]
  90:	ldr	w13, [sp, #28]
  94:	subs	w13, w13, #0x1
  98:	str	w13, [sp, #24]
  9c:	ldr	w13, [sp, #28]
  a0:	subs	w13, w13, #0x19
  a4:	b.lt	21c <__floattisf+0x21c>  // b.tstop
  a8:	b	ac <__floattisf+0xac>
  ac:	ldr	w8, [sp, #28]
  b0:	mov	w9, w8
  b4:	subs	w8, w8, #0x19
  b8:	str	w9, [sp, #8]
  bc:	b.eq	d4 <__floattisf+0xd4>  // b.none
  c0:	b	c4 <__floattisf+0xc4>
  c4:	ldr	w8, [sp, #8]
  c8:	subs	w9, w8, #0x1a
  cc:	b.eq	f0 <__floattisf+0xf0>  // b.none
  d0:	b	f4 <__floattisf+0xf4>
  d4:	ldur	x8, [x29, #-32]
  d8:	ldur	x9, [x29, #-24]
  dc:	extr	x9, x9, x8, #63
  e0:	lsl	x8, x8, #1
  e4:	stur	x9, [x29, #-24]
  e8:	stur	x8, [x29, #-32]
  ec:	b	1a0 <__floattisf+0x1a0>
  f0:	b	1a0 <__floattisf+0x1a0>
  f4:	ldur	x8, [x29, #-32]
  f8:	ldur	x9, [x29, #-24]
  fc:	ldr	w10, [sp, #28]
 100:	subs	w11, w10, #0x1a
 104:	mov	w12, w11
 108:	mov	x13, xzr
 10c:	sub	x14, x13, x12
 110:	lsl	x14, x9, x14
 114:	subs	x15, x12, #0x0
 118:	csel	x14, x13, x14, eq  // eq = none
 11c:	mov	w16, w11
 120:	lsr	x17, x8, x16
 124:	orr	x14, x17, x14
 128:	lsr	x17, x9, x12
 12c:	subs	x12, x12, #0x40
 130:	subs	x12, x12, #0x0
 134:	csel	x14, x17, x14, ge  // ge = tcont
 138:	lsr	x16, x9, x16
 13c:	csel	x16, x13, x16, ge  // ge = tcont
 140:	mov	w11, #0x9a                  	// #154
 144:	subs	w10, w11, w10
 148:	mov	w17, w10
 14c:	sub	x18, x13, x17
 150:	lsr	x18, x8, x18
 154:	subs	x0, x17, #0x0
 158:	csel	x18, x13, x18, eq  // eq = none
 15c:	mov	w1, w10
 160:	lsl	x2, x8, x1
 164:	subs	x3, x17, #0x40
 168:	subs	x3, x3, #0x0
 16c:	csel	x13, x13, x2, ge  // ge = tcont
 170:	lsl	x9, x9, x1
 174:	orr	x9, x18, x9
 178:	lsl	x8, x8, x17
 17c:	csel	x8, x8, x9, ge  // ge = tcont
 180:	orr	x8, x13, x8
 184:	subs	x8, x8, #0x0
 188:	cset	w10, ne  // ne = any
 18c:	mov	w9, w10
 190:	orr	x9, x14, x9
 194:	stur	x16, [x29, #-24]
 198:	stur	x9, [x29, #-32]
 19c:	b	1a0 <__floattisf+0x1a0>
 1a0:	ldur	x8, [x29, #-32]
 1a4:	and	x9, x8, #0x4
 1a8:	orr	x8, x8, x9, lsr #2
 1ac:	stur	x8, [x29, #-32]
 1b0:	ldur	x8, [x29, #-24]
 1b4:	ldur	x9, [x29, #-32]
 1b8:	adds	x9, x9, #0x1
 1bc:	mov	x10, xzr
 1c0:	adcs	x8, x8, x10
 1c4:	stur	x9, [x29, #-32]
 1c8:	stur	x8, [x29, #-24]
 1cc:	ldur	x8, [x29, #-32]
 1d0:	ldur	x9, [x29, #-24]
 1d4:	extr	x8, x9, x8, #2
 1d8:	asr	x9, x9, #2
 1dc:	stur	x9, [x29, #-24]
 1e0:	stur	x8, [x29, #-32]
 1e4:	ldurb	w11, [x29, #-29]
 1e8:	tbz	w11, #0, 218 <__floattisf+0x218>
 1ec:	b	1f0 <__floattisf+0x1f0>
 1f0:	ldur	x8, [x29, #-32]
 1f4:	ldur	x9, [x29, #-24]
 1f8:	extr	x8, x9, x8, #1
 1fc:	asr	x9, x9, #1
 200:	stur	x9, [x29, #-24]
 204:	stur	x8, [x29, #-32]
 208:	ldr	w10, [sp, #24]
 20c:	add	w10, w10, #0x1
 210:	str	w10, [sp, #24]
 214:	b	218 <__floattisf+0x218>
 218:	b	278 <__floattisf+0x278>
 21c:	ldr	w8, [sp, #28]
 220:	mov	w9, #0x18                  	// #24
 224:	subs	w8, w9, w8
 228:	ldur	x10, [x29, #-24]
 22c:	ldur	x11, [x29, #-32]
 230:	mov	w12, w8
 234:	mov	x13, xzr
 238:	sub	x14, x13, x12
 23c:	lsr	x14, x11, x14
 240:	subs	x15, x12, #0x0
 244:	csel	x14, x13, x14, eq  // eq = none
 248:	mov	w16, w8
 24c:	lsl	x10, x10, x16
 250:	orr	x10, x14, x10
 254:	lsl	x14, x11, x12
 258:	subs	x12, x12, #0x40
 25c:	subs	x12, x12, #0x0
 260:	csel	x10, x14, x10, ge  // ge = tcont
 264:	lsl	x11, x11, x16
 268:	csel	x11, x13, x11, ge  // ge = tcont
 26c:	stur	x11, [x29, #-32]
 270:	stur	x10, [x29, #-24]
 274:	b	278 <__floattisf+0x278>
 278:	ldr	w8, [sp, #32]
 27c:	and	w8, w8, #0x80000000
 280:	ldr	w9, [sp, #24]
 284:	mov	w10, #0x3f800000            	// #1065353216
 288:	add	w9, w10, w9, lsl #23
 28c:	orr	w8, w8, w9
 290:	ldur	w9, [x29, #-32]
 294:	bfxil	w8, w9, #0, #23
 298:	str	w8, [sp, #16]
 29c:	ldr	s0, [sp, #16]
 2a0:	stur	s0, [x29, #-4]
 2a4:	b	2a8 <__floattisf+0x2a8>
 2a8:	ldur	s0, [x29, #-4]
 2ac:	ldp	x29, x30, [sp, #96]
 2b0:	add	sp, sp, #0x70
 2b4:	ret

floatundidf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatundidf>:
   0:	sub	sp, sp, #0x20
   4:	adrp	x8, 0 <__floatundidf>
   8:	add	x8, x8, #0x0
   c:	adrp	x9, 0 <__floatundidf>
  10:	add	x9, x9, #0x0
  14:	mov	x10, #0x100000              	// #1048576
  18:	movk	x10, #0x4530, lsl #48
  1c:	fmov	d0, x10
  20:	str	x0, [sp, #24]
  24:	ldr	x8, [x8]
  28:	str	x8, [sp, #16]
  2c:	ldr	x8, [x9]
  30:	str	x8, [sp, #8]
  34:	ldr	x8, [sp, #24]
  38:	ldr	x9, [sp, #16]
  3c:	orr	x8, x9, x8, lsr #32
  40:	str	x8, [sp, #16]
  44:	ldr	x8, [sp, #24]
  48:	and	x8, x8, #0xffffffff
  4c:	ldr	x9, [sp, #8]
  50:	orr	x8, x9, x8
  54:	str	x8, [sp, #8]
  58:	ldr	d1, [sp, #16]
  5c:	fsub	d0, d1, d0
  60:	ldr	d1, [sp, #8]
  64:	fadd	d0, d0, d1
  68:	str	d0, [sp]
  6c:	ldr	d0, [sp]
  70:	add	sp, sp, #0x20
  74:	ret

floatundisf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatundisf>:
   0:	sub	sp, sp, #0x30
   4:	str	x0, [sp, #32]
   8:	ldr	x8, [sp, #32]
   c:	cbnz	x8, 1c <__floatundisf+0x1c>
  10:	fmov	s0, wzr
  14:	str	s0, [sp, #44]
  18:	b	170 <__floatundisf+0x170>
  1c:	mov	w8, #0x40                  	// #64
  20:	str	w8, [sp, #28]
  24:	ldr	x9, [sp, #32]
  28:	clz	x9, x9
  2c:	subs	w8, w8, w9
  30:	str	w8, [sp, #24]
  34:	ldr	w8, [sp, #24]
  38:	subs	w8, w8, #0x1
  3c:	str	w8, [sp, #20]
  40:	ldr	w8, [sp, #24]
  44:	cmp	w8, #0x18
  48:	b.le	134 <__floatundisf+0x134>
  4c:	ldr	w8, [sp, #24]
  50:	cmp	w8, #0x19
  54:	str	w8, [sp, #12]
  58:	b.eq	70 <__floatundisf+0x70>  // b.none
  5c:	b	60 <__floatundisf+0x60>
  60:	ldr	w8, [sp, #12]
  64:	cmp	w8, #0x1a
  68:	b.eq	80 <__floatundisf+0x80>  // b.none
  6c:	b	84 <__floatundisf+0x84>
  70:	ldr	x8, [sp, #32]
  74:	lsl	x8, x8, #1
  78:	str	x8, [sp, #32]
  7c:	b	d0 <__floatundisf+0xd0>
  80:	b	d0 <__floatundisf+0xd0>
  84:	ldr	x8, [sp, #32]
  88:	ldr	w9, [sp, #24]
  8c:	subs	w9, w9, #0x1a
  90:	mov	w10, w9
  94:	lsr	x8, x8, x10
  98:	ldr	x10, [sp, #32]
  9c:	ldr	w9, [sp, #24]
  a0:	mov	w11, #0x5a                  	// #90
  a4:	subs	w9, w11, w9
  a8:	mov	x12, #0xffffffffffffffff    	// #-1
  ac:	mov	w13, w9
  b0:	lsr	x12, x12, x13
  b4:	tst	x10, x12
  b8:	cset	w9, ne  // ne = any
  bc:	and	w9, w9, #0x1
  c0:	mov	w0, w9
  c4:	sxtw	x10, w0
  c8:	orr	x8, x8, x10
  cc:	str	x8, [sp, #32]
  d0:	ldr	x8, [sp, #32]
  d4:	tst	x8, #0x4
  d8:	cset	w9, ne  // ne = any
  dc:	and	w9, w9, #0x1
  e0:	mov	w0, w9
  e4:	sxtw	x8, w0
  e8:	ldr	x10, [sp, #32]
  ec:	orr	x8, x10, x8
  f0:	str	x8, [sp, #32]
  f4:	ldr	x8, [sp, #32]
  f8:	add	x8, x8, #0x1
  fc:	str	x8, [sp, #32]
 100:	ldr	x8, [sp, #32]
 104:	lsr	x8, x8, #2
 108:	str	x8, [sp, #32]
 10c:	ldr	x8, [sp, #32]
 110:	and	x8, x8, #0x1000000
 114:	cbz	x8, 130 <__floatundisf+0x130>
 118:	ldr	x8, [sp, #32]
 11c:	lsr	x8, x8, #1
 120:	str	x8, [sp, #32]
 124:	ldr	w9, [sp, #20]
 128:	add	w9, w9, #0x1
 12c:	str	w9, [sp, #20]
 130:	b	150 <__floatundisf+0x150>
 134:	ldr	w8, [sp, #24]
 138:	mov	w9, #0x18                  	// #24
 13c:	subs	w8, w9, w8
 140:	ldr	x10, [sp, #32]
 144:	mov	w11, w8
 148:	lsl	x10, x10, x11
 14c:	str	x10, [sp, #32]
 150:	ldr	w8, [sp, #20]
 154:	add	w8, w8, #0x7f
 158:	ldr	x9, [sp, #32]
 15c:	and	w9, w9, #0x7fffff
 160:	orr	w8, w9, w8, lsl #23
 164:	str	w8, [sp, #16]
 168:	ldr	w8, [sp, #16]
 16c:	str	w8, [sp, #44]
 170:	ldr	s0, [sp, #44]
 174:	add	sp, sp, #0x30
 178:	ret

floatunsidf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatunsidf>:
   0:	sub	sp, sp, #0x40
   4:	stp	x29, x30, [sp, #48]
   8:	add	x29, sp, #0x30
   c:	mov	w8, #0x20                  	// #32
  10:	stur	w0, [x29, #-12]
  14:	stur	w8, [x29, #-16]
  18:	ldur	w8, [x29, #-12]
  1c:	cbnz	w8, 34 <__floatunsidf+0x34>
  20:	mov	x8, xzr
  24:	mov	x0, x8
  28:	bl	ac <fromRep>
  2c:	stur	d0, [x29, #-8]
  30:	b	9c <__floatunsidf+0x9c>
  34:	ldur	w8, [x29, #-12]
  38:	clz	w8, w8
  3c:	mov	w9, #0x1f                  	// #31
  40:	subs	w8, w9, w8
  44:	stur	w8, [x29, #-20]
  48:	ldur	w8, [x29, #-20]
  4c:	mov	w9, #0x34                  	// #52
  50:	subs	w8, w9, w8
  54:	str	w8, [sp, #12]
  58:	ldur	w8, [x29, #-12]
  5c:	mov	w10, w8
  60:	ldr	w8, [sp, #12]
  64:	mov	w11, w8
  68:	lsl	x10, x10, x11
  6c:	eor	x10, x10, #0x10000000000000
  70:	str	x10, [sp, #16]
  74:	ldur	w8, [x29, #-20]
  78:	add	w8, w8, #0x3ff
  7c:	mov	w0, w8
  80:	sxtw	x10, w0
  84:	ldr	x11, [sp, #16]
  88:	add	x10, x11, x10, lsl #52
  8c:	str	x10, [sp, #16]
  90:	ldr	x0, [sp, #16]
  94:	bl	ac <fromRep>
  98:	stur	d0, [x29, #-8]
  9c:	ldur	d0, [x29, #-8]
  a0:	ldp	x29, x30, [sp, #48]
  a4:	add	sp, sp, #0x40
  a8:	ret

00000000000000ac <fromRep>:
  ac:	sub	sp, sp, #0x10
  b0:	str	x0, [sp, #8]
  b4:	ldr	x8, [sp, #8]
  b8:	str	x8, [sp]
  bc:	ldr	d0, [sp]
  c0:	add	sp, sp, #0x10
  c4:	ret

floatunsisf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatunsisf>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	mov	w8, #0x20                  	// #32
  10:	stur	w0, [x29, #-8]
  14:	stur	w8, [x29, #-12]
  18:	ldur	w8, [x29, #-8]
  1c:	cbnz	w8, 34 <__floatunsisf+0x34>
  20:	mov	w8, wzr
  24:	mov	w0, w8
  28:	bl	124 <fromRep>
  2c:	stur	s0, [x29, #-4]
  30:	b	114 <__floatunsisf+0x114>
  34:	ldur	w8, [x29, #-8]
  38:	clz	w8, w8
  3c:	mov	w9, #0x1f                  	// #31
  40:	subs	w8, w9, w8
  44:	str	w8, [sp, #16]
  48:	ldr	w8, [sp, #16]
  4c:	cmp	w8, #0x17
  50:	b.gt	7c <__floatunsisf+0x7c>
  54:	ldr	w8, [sp, #16]
  58:	mov	w9, #0x17                  	// #23
  5c:	subs	w8, w9, w8
  60:	str	w8, [sp, #8]
  64:	ldur	w8, [x29, #-8]
  68:	ldr	w9, [sp, #8]
  6c:	lsl	w8, w8, w9
  70:	eor	w8, w8, #0x800000
  74:	str	w8, [sp, #12]
  78:	b	f4 <__floatunsisf+0xf4>
  7c:	ldr	w8, [sp, #16]
  80:	subs	w8, w8, #0x17
  84:	str	w8, [sp, #4]
  88:	ldur	w8, [x29, #-8]
  8c:	ldr	w9, [sp, #4]
  90:	lsr	w8, w8, w9
  94:	eor	w8, w8, #0x800000
  98:	str	w8, [sp, #12]
  9c:	ldur	w8, [x29, #-8]
  a0:	ldrsw	x10, [sp, #4]
  a4:	mov	x11, #0x20                  	// #32
  a8:	subs	x10, x11, x10
  ac:	lsl	w8, w8, w10
  b0:	str	w8, [sp]
  b4:	ldr	w8, [sp]
  b8:	mov	w9, #0x80000000            	// #-2147483648
  bc:	cmp	w8, w9
  c0:	b.ls	d0 <__floatunsisf+0xd0>  // b.plast
  c4:	ldr	w8, [sp, #12]
  c8:	add	w8, w8, #0x1
  cc:	str	w8, [sp, #12]
  d0:	ldr	w8, [sp]
  d4:	mov	w9, #0x80000000            	// #-2147483648
  d8:	cmp	w8, w9
  dc:	b.ne	f4 <__floatunsisf+0xf4>  // b.any
  e0:	ldr	w8, [sp, #12]
  e4:	and	w8, w8, #0x1
  e8:	ldr	w9, [sp, #12]
  ec:	add	w8, w9, w8
  f0:	str	w8, [sp, #12]
  f4:	ldr	w8, [sp, #16]
  f8:	add	w8, w8, #0x7f
  fc:	ldr	w9, [sp, #12]
 100:	add	w8, w9, w8, lsl #23
 104:	str	w8, [sp, #12]
 108:	ldr	w0, [sp, #12]
 10c:	bl	124 <fromRep>
 110:	stur	s0, [x29, #-4]
 114:	ldur	s0, [x29, #-4]
 118:	ldp	x29, x30, [sp, #32]
 11c:	add	sp, sp, #0x30
 120:	ret

0000000000000124 <fromRep>:
 124:	sub	sp, sp, #0x10
 128:	str	w0, [sp, #12]
 12c:	ldr	w8, [sp, #12]
 130:	str	w8, [sp, #8]
 134:	ldr	s0, [sp, #8]
 138:	add	sp, sp, #0x10
 13c:	ret

floatuntidf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatuntidf>:
   0:	sub	sp, sp, #0x50
   4:	stp	x29, x30, [sp, #64]
   8:	add	x29, sp, #0x40
   c:	str	x1, [sp, #40]
  10:	str	x0, [sp, #32]
  14:	ldr	x8, [sp, #40]
  18:	ldr	x9, [sp, #32]
  1c:	orr	x8, x9, x8
  20:	cbnz	x8, 34 <__floatuntidf+0x34>
  24:	b	28 <__floatuntidf+0x28>
  28:	mov	x8, xzr
  2c:	stur	x8, [x29, #-8]
  30:	b	26c <__floatuntidf+0x26c>
  34:	mov	w8, #0x80                  	// #128
  38:	str	w8, [sp, #28]
  3c:	ldr	x1, [sp, #40]
  40:	ldr	x0, [sp, #32]
  44:	str	w8, [sp, #4]
  48:	bl	0 <__clzti2>
  4c:	ldr	w8, [sp, #4]
  50:	subs	w9, w8, w0
  54:	str	w9, [sp, #24]
  58:	ldr	w9, [sp, #24]
  5c:	subs	w9, w9, #0x1
  60:	str	w9, [sp, #20]
  64:	ldr	w9, [sp, #24]
  68:	subs	w9, w9, #0x36
  6c:	b.lt	1e4 <__floatuntidf+0x1e4>  // b.tstop
  70:	b	74 <__floatuntidf+0x74>
  74:	ldr	w8, [sp, #24]
  78:	mov	w9, w8
  7c:	subs	w8, w8, #0x36
  80:	str	w9, [sp]
  84:	b.eq	9c <__floatuntidf+0x9c>  // b.none
  88:	b	8c <__floatuntidf+0x8c>
  8c:	ldr	w8, [sp]
  90:	subs	w9, w8, #0x37
  94:	b.eq	b8 <__floatuntidf+0xb8>  // b.none
  98:	b	bc <__floatuntidf+0xbc>
  9c:	ldr	x8, [sp, #32]
  a0:	ldr	x9, [sp, #40]
  a4:	extr	x9, x9, x8, #63
  a8:	lsl	x8, x8, #1
  ac:	str	x9, [sp, #40]
  b0:	str	x8, [sp, #32]
  b4:	b	168 <__floatuntidf+0x168>
  b8:	b	168 <__floatuntidf+0x168>
  bc:	ldr	x8, [sp, #32]
  c0:	ldr	x9, [sp, #40]
  c4:	ldr	w10, [sp, #24]
  c8:	subs	w11, w10, #0x37
  cc:	mov	w12, w11
  d0:	mov	x13, xzr
  d4:	sub	x14, x13, x12
  d8:	lsl	x14, x9, x14
  dc:	subs	x15, x12, #0x0
  e0:	csel	x14, x13, x14, eq  // eq = none
  e4:	mov	w16, w11
  e8:	lsr	x17, x8, x16
  ec:	orr	x14, x17, x14
  f0:	lsr	x17, x9, x12
  f4:	subs	x12, x12, #0x40
  f8:	subs	x12, x12, #0x0
  fc:	csel	x14, x17, x14, ge  // ge = tcont
 100:	lsr	x16, x9, x16
 104:	csel	x16, x13, x16, ge  // ge = tcont
 108:	mov	w11, #0xb7                  	// #183
 10c:	subs	w10, w11, w10
 110:	mov	w17, w10
 114:	sub	x18, x13, x17
 118:	lsr	x18, x8, x18
 11c:	subs	x0, x17, #0x0
 120:	csel	x18, x13, x18, eq  // eq = none
 124:	mov	w1, w10
 128:	lsl	x2, x8, x1
 12c:	subs	x3, x17, #0x40
 130:	subs	x3, x3, #0x0
 134:	csel	x13, x13, x2, ge  // ge = tcont
 138:	lsl	x9, x9, x1
 13c:	orr	x9, x18, x9
 140:	lsl	x8, x8, x17
 144:	csel	x8, x8, x9, ge  // ge = tcont
 148:	orr	x8, x13, x8
 14c:	subs	x8, x8, #0x0
 150:	cset	w10, ne  // ne = any
 154:	mov	w9, w10
 158:	orr	x9, x14, x9
 15c:	str	x16, [sp, #40]
 160:	str	x9, [sp, #32]
 164:	b	168 <__floatuntidf+0x168>
 168:	ldr	x8, [sp, #32]
 16c:	and	x9, x8, #0x4
 170:	orr	x8, x8, x9, lsr #2
 174:	str	x8, [sp, #32]
 178:	ldr	x8, [sp, #40]
 17c:	ldr	x9, [sp, #32]
 180:	adds	x9, x9, #0x1
 184:	mov	x10, xzr
 188:	adcs	x8, x8, x10
 18c:	str	x9, [sp, #32]
 190:	str	x8, [sp, #40]
 194:	ldr	x8, [sp, #32]
 198:	ldr	x9, [sp, #40]
 19c:	extr	x8, x9, x8, #2
 1a0:	lsr	x9, x9, #2
 1a4:	str	x9, [sp, #40]
 1a8:	str	x8, [sp, #32]
 1ac:	ldrb	w11, [sp, #38]
 1b0:	tbz	w11, #5, 1e0 <__floatuntidf+0x1e0>
 1b4:	b	1b8 <__floatuntidf+0x1b8>
 1b8:	ldr	x8, [sp, #32]
 1bc:	ldr	x9, [sp, #40]
 1c0:	extr	x8, x9, x8, #1
 1c4:	lsr	x9, x9, #1
 1c8:	str	x9, [sp, #40]
 1cc:	str	x8, [sp, #32]
 1d0:	ldr	w10, [sp, #20]
 1d4:	add	w10, w10, #0x1
 1d8:	str	w10, [sp, #20]
 1dc:	b	1e0 <__floatuntidf+0x1e0>
 1e0:	b	240 <__floatuntidf+0x240>
 1e4:	ldr	w8, [sp, #24]
 1e8:	mov	w9, #0x35                  	// #53
 1ec:	subs	w8, w9, w8
 1f0:	ldr	x10, [sp, #40]
 1f4:	ldr	x11, [sp, #32]
 1f8:	mov	w12, w8
 1fc:	mov	x13, xzr
 200:	sub	x14, x13, x12
 204:	lsr	x14, x11, x14
 208:	subs	x15, x12, #0x0
 20c:	csel	x14, x13, x14, eq  // eq = none
 210:	mov	w16, w8
 214:	lsl	x10, x10, x16
 218:	orr	x10, x14, x10
 21c:	lsl	x14, x11, x12
 220:	subs	x12, x12, #0x40
 224:	subs	x12, x12, #0x0
 228:	csel	x10, x14, x10, ge  // ge = tcont
 22c:	lsl	x11, x11, x16
 230:	csel	x11, x13, x11, ge  // ge = tcont
 234:	str	x11, [sp, #32]
 238:	str	x10, [sp, #40]
 23c:	b	240 <__floatuntidf+0x240>
 240:	ldr	w8, [sp, #20]
 244:	ldr	w9, [sp, #36]
 248:	bfi	w9, w8, #20, #12
 24c:	mov	w8, #0x3ff00000            	// #1072693248
 250:	add	w8, w9, w8
 254:	str	w8, [sp, #12]
 258:	ldr	w8, [sp, #32]
 25c:	str	w8, [sp, #8]
 260:	ldr	d0, [sp, #8]
 264:	stur	d0, [x29, #-8]
 268:	b	26c <__floatuntidf+0x26c>
 26c:	ldur	d0, [x29, #-8]
 270:	ldp	x29, x30, [sp, #64]
 274:	add	sp, sp, #0x50
 278:	ret

floatuntisf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__floatuntisf>:
   0:	sub	sp, sp, #0x50
   4:	stp	x29, x30, [sp, #64]
   8:	add	x29, sp, #0x40
   c:	str	x1, [sp, #40]
  10:	str	x0, [sp, #32]
  14:	ldr	x8, [sp, #40]
  18:	ldr	x9, [sp, #32]
  1c:	orr	x8, x9, x8
  20:	cbnz	x8, 34 <__floatuntisf+0x34>
  24:	b	28 <__floatuntisf+0x28>
  28:	mov	w8, wzr
  2c:	stur	w8, [x29, #-4]
  30:	b	264 <__floatuntisf+0x264>
  34:	mov	w8, #0x80                  	// #128
  38:	str	w8, [sp, #28]
  3c:	ldr	x1, [sp, #40]
  40:	ldr	x0, [sp, #32]
  44:	str	w8, [sp, #12]
  48:	bl	0 <__clzti2>
  4c:	ldr	w8, [sp, #12]
  50:	subs	w9, w8, w0
  54:	str	w9, [sp, #24]
  58:	ldr	w9, [sp, #24]
  5c:	subs	w9, w9, #0x1
  60:	str	w9, [sp, #20]
  64:	ldr	w9, [sp, #24]
  68:	subs	w9, w9, #0x19
  6c:	b.lt	1e4 <__floatuntisf+0x1e4>  // b.tstop
  70:	b	74 <__floatuntisf+0x74>
  74:	ldr	w8, [sp, #24]
  78:	mov	w9, w8
  7c:	subs	w8, w8, #0x19
  80:	str	w9, [sp, #8]
  84:	b.eq	9c <__floatuntisf+0x9c>  // b.none
  88:	b	8c <__floatuntisf+0x8c>
  8c:	ldr	w8, [sp, #8]
  90:	subs	w9, w8, #0x1a
  94:	b.eq	b8 <__floatuntisf+0xb8>  // b.none
  98:	b	bc <__floatuntisf+0xbc>
  9c:	ldr	x8, [sp, #32]
  a0:	ldr	x9, [sp, #40]
  a4:	extr	x9, x9, x8, #63
  a8:	lsl	x8, x8, #1
  ac:	str	x9, [sp, #40]
  b0:	str	x8, [sp, #32]
  b4:	b	168 <__floatuntisf+0x168>
  b8:	b	168 <__floatuntisf+0x168>
  bc:	ldr	x8, [sp, #32]
  c0:	ldr	x9, [sp, #40]
  c4:	ldr	w10, [sp, #24]
  c8:	subs	w11, w10, #0x1a
  cc:	mov	w12, w11
  d0:	mov	x13, xzr
  d4:	sub	x14, x13, x12
  d8:	lsl	x14, x9, x14
  dc:	subs	x15, x12, #0x0
  e0:	csel	x14, x13, x14, eq  // eq = none
  e4:	mov	w16, w11
  e8:	lsr	x17, x8, x16
  ec:	orr	x14, x17, x14
  f0:	lsr	x17, x9, x12
  f4:	subs	x12, x12, #0x40
  f8:	subs	x12, x12, #0x0
  fc:	csel	x14, x17, x14, ge  // ge = tcont
 100:	lsr	x16, x9, x16
 104:	csel	x16, x13, x16, ge  // ge = tcont
 108:	mov	w11, #0x9a                  	// #154
 10c:	subs	w10, w11, w10
 110:	mov	w17, w10
 114:	sub	x18, x13, x17
 118:	lsr	x18, x8, x18
 11c:	subs	x0, x17, #0x0
 120:	csel	x18, x13, x18, eq  // eq = none
 124:	mov	w1, w10
 128:	lsl	x2, x8, x1
 12c:	subs	x3, x17, #0x40
 130:	subs	x3, x3, #0x0
 134:	csel	x13, x13, x2, ge  // ge = tcont
 138:	lsl	x9, x9, x1
 13c:	orr	x9, x18, x9
 140:	lsl	x8, x8, x17
 144:	csel	x8, x8, x9, ge  // ge = tcont
 148:	orr	x8, x13, x8
 14c:	subs	x8, x8, #0x0
 150:	cset	w10, ne  // ne = any
 154:	mov	w9, w10
 158:	orr	x9, x14, x9
 15c:	str	x16, [sp, #40]
 160:	str	x9, [sp, #32]
 164:	b	168 <__floatuntisf+0x168>
 168:	ldr	x8, [sp, #32]
 16c:	and	x9, x8, #0x4
 170:	orr	x8, x8, x9, lsr #2
 174:	str	x8, [sp, #32]
 178:	ldr	x8, [sp, #40]
 17c:	ldr	x9, [sp, #32]
 180:	adds	x9, x9, #0x1
 184:	mov	x10, xzr
 188:	adcs	x8, x8, x10
 18c:	str	x9, [sp, #32]
 190:	str	x8, [sp, #40]
 194:	ldr	x8, [sp, #32]
 198:	ldr	x9, [sp, #40]
 19c:	extr	x8, x9, x8, #2
 1a0:	lsr	x9, x9, #2
 1a4:	str	x9, [sp, #40]
 1a8:	str	x8, [sp, #32]
 1ac:	ldrb	w11, [sp, #35]
 1b0:	tbz	w11, #0, 1e0 <__floatuntisf+0x1e0>
 1b4:	b	1b8 <__floatuntisf+0x1b8>
 1b8:	ldr	x8, [sp, #32]
 1bc:	ldr	x9, [sp, #40]
 1c0:	extr	x8, x9, x8, #1
 1c4:	lsr	x9, x9, #1
 1c8:	str	x9, [sp, #40]
 1cc:	str	x8, [sp, #32]
 1d0:	ldr	w10, [sp, #20]
 1d4:	add	w10, w10, #0x1
 1d8:	str	w10, [sp, #20]
 1dc:	b	1e0 <__floatuntisf+0x1e0>
 1e0:	b	240 <__floatuntisf+0x240>
 1e4:	ldr	w8, [sp, #24]
 1e8:	mov	w9, #0x18                  	// #24
 1ec:	subs	w8, w9, w8
 1f0:	ldr	x10, [sp, #40]
 1f4:	ldr	x11, [sp, #32]
 1f8:	mov	w12, w8
 1fc:	mov	x13, xzr
 200:	sub	x14, x13, x12
 204:	lsr	x14, x11, x14
 208:	subs	x15, x12, #0x0
 20c:	csel	x14, x13, x14, eq  // eq = none
 210:	mov	w16, w8
 214:	lsl	x10, x10, x16
 218:	orr	x10, x14, x10
 21c:	lsl	x14, x11, x12
 220:	subs	x12, x12, #0x40
 224:	subs	x12, x12, #0x0
 228:	csel	x10, x14, x10, ge  // ge = tcont
 22c:	lsl	x11, x11, x16
 230:	csel	x11, x13, x11, ge  // ge = tcont
 234:	str	x11, [sp, #32]
 238:	str	x10, [sp, #40]
 23c:	b	240 <__floatuntisf+0x240>
 240:	ldr	w8, [sp, #20]
 244:	ldr	w9, [sp, #32]
 248:	bfi	w9, w8, #23, #9
 24c:	mov	w8, #0x3f800000            	// #1065353216
 250:	add	w8, w9, w8
 254:	str	w8, [sp, #16]
 258:	ldr	s0, [sp, #16]
 25c:	stur	s0, [x29, #-4]
 260:	b	264 <__floatuntisf+0x264>
 264:	ldur	s0, [x29, #-4]
 268:	ldp	x29, x30, [sp, #64]
 26c:	add	sp, sp, #0x50
 270:	ret

int_util.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__compilerrt_abort_impl>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	stur	x0, [x29, #-8]
  10:	stur	w1, [x29, #-12]
  14:	str	x2, [sp, #8]
  18:	bl	0 <abort>

lshrdi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__lshrdi3>:
   0:	sub	sp, sp, #0x30
   4:	mov	w8, #0x20                  	// #32
   8:	str	x0, [sp, #32]
   c:	str	w1, [sp, #28]
  10:	str	w8, [sp, #24]
  14:	ldr	x9, [sp, #32]
  18:	str	x9, [sp, #16]
  1c:	ldr	w8, [sp, #28]
  20:	and	w8, w8, #0x20
  24:	cbz	w8, 44 <__lshrdi3+0x44>
  28:	str	wzr, [sp, #12]
  2c:	ldr	w8, [sp, #20]
  30:	ldr	w9, [sp, #28]
  34:	subs	w9, w9, #0x20
  38:	lsr	w8, w8, w9
  3c:	str	w8, [sp, #8]
  40:	b	90 <__lshrdi3+0x90>
  44:	ldr	w8, [sp, #28]
  48:	cbnz	w8, 58 <__lshrdi3+0x58>
  4c:	ldr	x8, [sp, #32]
  50:	str	x8, [sp, #40]
  54:	b	98 <__lshrdi3+0x98>
  58:	ldr	w8, [sp, #20]
  5c:	ldr	w9, [sp, #28]
  60:	lsr	w8, w8, w9
  64:	str	w8, [sp, #12]
  68:	ldr	w8, [sp, #20]
  6c:	ldr	w9, [sp, #28]
  70:	mov	w10, #0x20                  	// #32
  74:	subs	w9, w10, w9
  78:	lsl	w8, w8, w9
  7c:	ldr	w9, [sp, #16]
  80:	ldr	w10, [sp, #28]
  84:	lsr	w9, w9, w10
  88:	orr	w8, w8, w9
  8c:	str	w8, [sp, #8]
  90:	ldr	x8, [sp, #8]
  94:	str	x8, [sp, #40]
  98:	ldr	x0, [sp, #40]
  9c:	add	sp, sp, #0x30
  a0:	ret

lshrti3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__lshrti3>:
   0:	sub	sp, sp, #0x50
   4:	str	x1, [sp, #56]
   8:	str	x0, [sp, #48]
   c:	str	w2, [sp, #44]
  10:	mov	w8, #0x40                  	// #64
  14:	str	w8, [sp, #40]
  18:	ldr	x9, [sp, #48]
  1c:	ldr	x10, [sp, #56]
  20:	str	x10, [sp, #24]
  24:	str	x9, [sp, #16]
  28:	ldrb	w8, [sp, #44]
  2c:	tbz	w8, #6, 54 <__lshrti3+0x54>
  30:	b	34 <__lshrti3+0x34>
  34:	mov	x8, xzr
  38:	str	x8, [sp, #8]
  3c:	ldr	x8, [sp, #24]
  40:	ldr	w9, [sp, #44]
  44:	mov	w10, w9
  48:	lsr	x8, x8, x10
  4c:	str	x8, [sp]
  50:	b	bc <__lshrti3+0xbc>
  54:	ldr	w8, [sp, #44]
  58:	cbnz	w8, 74 <__lshrti3+0x74>
  5c:	b	60 <__lshrti3+0x60>
  60:	ldr	x8, [sp, #48]
  64:	ldr	x9, [sp, #56]
  68:	str	x9, [sp, #72]
  6c:	str	x8, [sp, #64]
  70:	b	d0 <__lshrti3+0xd0>
  74:	ldr	x8, [sp, #24]
  78:	ldr	w9, [sp, #44]
  7c:	mov	w10, w9
  80:	lsr	x8, x8, x10
  84:	str	x8, [sp, #8]
  88:	ldr	x8, [sp, #24]
  8c:	ldr	w9, [sp, #44]
  90:	mov	w10, w9
  94:	mov	w9, w10
  98:	mov	w11, wzr
  9c:	sub	w9, w11, w9
  a0:	mov	w12, w9
  a4:	lsl	x8, x8, x12
  a8:	ldr	x12, [sp, #16]
  ac:	lsr	x10, x12, x10
  b0:	orr	x8, x8, x10
  b4:	str	x8, [sp]
  b8:	b	bc <__lshrti3+0xbc>
  bc:	ldr	x8, [sp]
  c0:	ldr	x9, [sp, #8]
  c4:	str	x9, [sp, #72]
  c8:	str	x8, [sp, #64]
  cc:	b	d0 <__lshrti3+0xd0>
  d0:	ldr	x0, [sp, #64]
  d4:	ldr	x1, [sp, #72]
  d8:	add	sp, sp, #0x50
  dc:	ret

moddi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__moddi3>:
   0:	sub	sp, sp, #0x40
   4:	stp	x29, x30, [sp, #48]
   8:	add	x29, sp, #0x30
   c:	mov	w8, #0x3f                  	// #63
  10:	add	x2, sp, #0x8
  14:	stur	x0, [x29, #-8]
  18:	stur	x1, [x29, #-16]
  1c:	stur	w8, [x29, #-20]
  20:	ldur	x9, [x29, #-16]
  24:	asr	x9, x9, #63
  28:	str	x9, [sp, #16]
  2c:	ldur	x9, [x29, #-16]
  30:	ldr	x10, [sp, #16]
  34:	eor	x9, x9, x10
  38:	ldr	x10, [sp, #16]
  3c:	subs	x9, x9, x10
  40:	stur	x9, [x29, #-16]
  44:	ldur	x9, [x29, #-8]
  48:	asr	x9, x9, #63
  4c:	str	x9, [sp, #16]
  50:	ldur	x9, [x29, #-8]
  54:	ldr	x10, [sp, #16]
  58:	eor	x9, x9, x10
  5c:	ldr	x10, [sp, #16]
  60:	subs	x9, x9, x10
  64:	stur	x9, [x29, #-8]
  68:	ldur	x0, [x29, #-8]
  6c:	ldur	x1, [x29, #-16]
  70:	bl	0 <__udivmoddi4>
  74:	ldr	x9, [sp, #8]
  78:	ldr	x10, [sp, #16]
  7c:	eor	x9, x9, x10
  80:	ldr	x10, [sp, #16]
  84:	subs	x9, x9, x10
  88:	mov	x0, x9
  8c:	ldp	x29, x30, [sp, #48]
  90:	add	sp, sp, #0x40
  94:	ret

modsi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__modsi3>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	w0, [x29, #-4]
  10:	str	w1, [sp, #8]
  14:	ldur	w8, [x29, #-4]
  18:	ldur	w0, [x29, #-4]
  1c:	ldr	w1, [sp, #8]
  20:	str	w8, [sp, #4]
  24:	bl	0 <__divsi3>
  28:	ldr	w8, [sp, #8]
  2c:	mul	w8, w0, w8
  30:	ldr	w9, [sp, #4]
  34:	subs	w0, w9, w8
  38:	ldp	x29, x30, [sp, #16]
  3c:	add	sp, sp, #0x20
  40:	ret

modti3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__modti3>:
   0:	sub	sp, sp, #0x70
   4:	stp	x29, x30, [sp, #96]
   8:	add	x29, sp, #0x60
   c:	stur	x1, [x29, #-8]
  10:	stur	x0, [x29, #-16]
  14:	stur	x3, [x29, #-24]
  18:	stur	x2, [x29, #-32]
  1c:	mov	w8, #0x7f                  	// #127
  20:	stur	w8, [x29, #-36]
  24:	ldur	x9, [x29, #-24]
  28:	asr	x9, x9, #63
  2c:	str	x9, [sp, #40]
  30:	str	x9, [sp, #32]
  34:	ldur	x9, [x29, #-32]
  38:	ldur	x10, [x29, #-24]
  3c:	ldr	x11, [sp, #32]
  40:	ldr	x12, [sp, #40]
  44:	eor	x10, x10, x12
  48:	eor	x9, x9, x11
  4c:	subs	x9, x9, x11
  50:	sbcs	x10, x10, x12
  54:	stur	x9, [x29, #-32]
  58:	stur	x10, [x29, #-24]
  5c:	ldur	x9, [x29, #-8]
  60:	asr	x9, x9, #63
  64:	str	x9, [sp, #40]
  68:	str	x9, [sp, #32]
  6c:	ldur	x9, [x29, #-16]
  70:	ldur	x10, [x29, #-8]
  74:	ldr	x11, [sp, #32]
  78:	ldr	x12, [sp, #40]
  7c:	eor	x10, x10, x12
  80:	eor	x9, x9, x11
  84:	subs	x9, x9, x11
  88:	sbcs	x10, x10, x12
  8c:	stur	x9, [x29, #-16]
  90:	stur	x10, [x29, #-8]
  94:	ldur	x1, [x29, #-8]
  98:	ldur	x0, [x29, #-16]
  9c:	ldur	x3, [x29, #-24]
  a0:	ldur	x2, [x29, #-32]
  a4:	add	x4, sp, #0x10
  a8:	bl	0 <__udivmodti4>
  ac:	ldr	x9, [sp, #16]
  b0:	ldr	x10, [sp, #24]
  b4:	ldr	x11, [sp, #32]
  b8:	ldr	x12, [sp, #40]
  bc:	eor	x10, x10, x12
  c0:	eor	x9, x9, x11
  c4:	subs	x9, x9, x11
  c8:	sbcs	x10, x10, x12
  cc:	str	x0, [sp, #8]
  d0:	mov	x0, x9
  d4:	str	x1, [sp]
  d8:	mov	x1, x10
  dc:	ldp	x29, x30, [sp, #96]
  e0:	add	sp, sp, #0x70
  e4:	ret

muldc3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__muldc3>:
   0:	sub	sp, sp, #0x70
   4:	str	d0, [sp, #88]
   8:	str	d1, [sp, #80]
   c:	str	d2, [sp, #72]
  10:	str	d3, [sp, #64]
  14:	ldr	d0, [sp, #88]
  18:	ldr	d1, [sp, #72]
  1c:	fmul	d0, d0, d1
  20:	str	d0, [sp, #56]
  24:	ldr	d0, [sp, #80]
  28:	ldr	d1, [sp, #64]
  2c:	fmul	d0, d0, d1
  30:	str	d0, [sp, #48]
  34:	ldr	d0, [sp, #88]
  38:	ldr	d1, [sp, #64]
  3c:	fmul	d0, d0, d1
  40:	str	d0, [sp, #40]
  44:	ldr	d0, [sp, #80]
  48:	ldr	d1, [sp, #72]
  4c:	fmul	d0, d0, d1
  50:	str	d0, [sp, #32]
  54:	ldr	d0, [sp, #56]
  58:	ldr	d1, [sp, #48]
  5c:	fsub	d0, d0, d1
  60:	str	d0, [sp, #16]
  64:	ldr	d0, [sp, #40]
  68:	ldr	d1, [sp, #32]
  6c:	fadd	d0, d0, d1
  70:	str	d0, [sp, #24]
  74:	ldr	d0, [sp, #16]
  78:	fcmp	d0, d0
  7c:	b.vc	460 <__muldc3+0x460>
  80:	b	84 <__muldc3+0x84>
  84:	ldr	d0, [sp, #24]
  88:	fcmp	d0, d0
  8c:	b.vc	460 <__muldc3+0x460>
  90:	b	94 <__muldc3+0x94>
  94:	mov	w8, wzr
  98:	str	w8, [sp, #12]
  9c:	ldr	d0, [sp, #88]
  a0:	fabs	d0, d0
  a4:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
  a8:	fmov	d1, x9
  ac:	fcmp	d0, d1
  b0:	b.eq	d4 <__muldc3+0xd4>  // b.none
  b4:	b	b8 <__muldc3+0xb8>
  b8:	ldr	d0, [sp, #80]
  bc:	fabs	d0, d0
  c0:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
  c4:	fmov	d1, x8
  c8:	fcmp	d0, d1
  cc:	b.ne	1a0 <__muldc3+0x1a0>  // b.any
  d0:	b	d4 <__muldc3+0xd4>
  d4:	ldr	d0, [sp, #88]
  d8:	fabs	d1, d0
  dc:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
  e0:	fmov	d2, x8
  e4:	fcmp	d1, d2
  e8:	fmov	d1, xzr
  ec:	fmov	d3, #1.000000000000000000e+00
  f0:	fcsel	d4, d3, d1, eq  // eq = none
  f4:	mov	v5.16b, v0.16b
  f8:	mov	v6.16b, v4.16b
  fc:	movi	v7.2d, #0x0
 100:	fneg	v7.2d, v7.2d
 104:	bit	v6.16b, v5.16b, v7.16b
 108:	str	d6, [sp, #88]
 10c:	ldr	d0, [sp, #80]
 110:	fabs	d4, d0
 114:	fcmp	d4, d2
 118:	fcsel	d1, d3, d1, eq  // eq = none
 11c:	mov	v5.16b, v0.16b
 120:	mov	v16.16b, v1.16b
 124:	bit	v16.16b, v5.16b, v7.16b
 128:	str	d16, [sp, #80]
 12c:	ldr	d0, [sp, #72]
 130:	fcmp	d0, d0
 134:	b.vc	160 <__muldc3+0x160>
 138:	b	13c <__muldc3+0x13c>
 13c:	ldr	d0, [sp, #72]
 140:	mov	v1.16b, v0.16b
 144:	fmov	d0, xzr
 148:	mov	v2.16b, v0.16b
 14c:	movi	v3.2d, #0x0
 150:	fneg	v3.2d, v3.2d
 154:	bit	v2.16b, v1.16b, v3.16b
 158:	str	d2, [sp, #72]
 15c:	b	160 <__muldc3+0x160>
 160:	ldr	d0, [sp, #64]
 164:	fcmp	d0, d0
 168:	b.vc	194 <__muldc3+0x194>
 16c:	b	170 <__muldc3+0x170>
 170:	ldr	d0, [sp, #64]
 174:	mov	v1.16b, v0.16b
 178:	fmov	d0, xzr
 17c:	mov	v2.16b, v0.16b
 180:	movi	v3.2d, #0x0
 184:	fneg	v3.2d, v3.2d
 188:	bit	v2.16b, v1.16b, v3.16b
 18c:	str	d2, [sp, #64]
 190:	b	194 <__muldc3+0x194>
 194:	mov	w8, #0x1                   	// #1
 198:	str	w8, [sp, #12]
 19c:	b	1a0 <__muldc3+0x1a0>
 1a0:	ldr	d0, [sp, #72]
 1a4:	fabs	d0, d0
 1a8:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 1ac:	fmov	d1, x8
 1b0:	fcmp	d0, d1
 1b4:	b.eq	1d8 <__muldc3+0x1d8>  // b.none
 1b8:	b	1bc <__muldc3+0x1bc>
 1bc:	ldr	d0, [sp, #64]
 1c0:	fabs	d0, d0
 1c4:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 1c8:	fmov	d1, x8
 1cc:	fcmp	d0, d1
 1d0:	b.ne	2a4 <__muldc3+0x2a4>  // b.any
 1d4:	b	1d8 <__muldc3+0x1d8>
 1d8:	ldr	d0, [sp, #72]
 1dc:	fabs	d1, d0
 1e0:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 1e4:	fmov	d2, x8
 1e8:	fcmp	d1, d2
 1ec:	fmov	d1, xzr
 1f0:	fmov	d3, #1.000000000000000000e+00
 1f4:	fcsel	d4, d3, d1, eq  // eq = none
 1f8:	mov	v5.16b, v0.16b
 1fc:	mov	v6.16b, v4.16b
 200:	movi	v7.2d, #0x0
 204:	fneg	v7.2d, v7.2d
 208:	bit	v6.16b, v5.16b, v7.16b
 20c:	str	d6, [sp, #72]
 210:	ldr	d0, [sp, #64]
 214:	fabs	d4, d0
 218:	fcmp	d4, d2
 21c:	fcsel	d1, d3, d1, eq  // eq = none
 220:	mov	v5.16b, v0.16b
 224:	mov	v16.16b, v1.16b
 228:	bit	v16.16b, v5.16b, v7.16b
 22c:	str	d16, [sp, #64]
 230:	ldr	d0, [sp, #88]
 234:	fcmp	d0, d0
 238:	b.vc	264 <__muldc3+0x264>
 23c:	b	240 <__muldc3+0x240>
 240:	ldr	d0, [sp, #88]
 244:	mov	v1.16b, v0.16b
 248:	fmov	d0, xzr
 24c:	mov	v2.16b, v0.16b
 250:	movi	v3.2d, #0x0
 254:	fneg	v3.2d, v3.2d
 258:	bit	v2.16b, v1.16b, v3.16b
 25c:	str	d2, [sp, #88]
 260:	b	264 <__muldc3+0x264>
 264:	ldr	d0, [sp, #80]
 268:	fcmp	d0, d0
 26c:	b.vc	298 <__muldc3+0x298>
 270:	b	274 <__muldc3+0x274>
 274:	ldr	d0, [sp, #80]
 278:	mov	v1.16b, v0.16b
 27c:	fmov	d0, xzr
 280:	mov	v2.16b, v0.16b
 284:	movi	v3.2d, #0x0
 288:	fneg	v3.2d, v3.2d
 28c:	bit	v2.16b, v1.16b, v3.16b
 290:	str	d2, [sp, #80]
 294:	b	298 <__muldc3+0x298>
 298:	mov	w8, #0x1                   	// #1
 29c:	str	w8, [sp, #12]
 2a0:	b	2a4 <__muldc3+0x2a4>
 2a4:	ldr	w8, [sp, #12]
 2a8:	cbnz	w8, 3fc <__muldc3+0x3fc>
 2ac:	b	2b0 <__muldc3+0x2b0>
 2b0:	ldr	d0, [sp, #56]
 2b4:	fabs	d0, d0
 2b8:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 2bc:	fmov	d1, x8
 2c0:	fcmp	d0, d1
 2c4:	b.eq	320 <__muldc3+0x320>  // b.none
 2c8:	b	2cc <__muldc3+0x2cc>
 2cc:	ldr	d0, [sp, #48]
 2d0:	fabs	d0, d0
 2d4:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 2d8:	fmov	d1, x8
 2dc:	fcmp	d0, d1
 2e0:	b.eq	320 <__muldc3+0x320>  // b.none
 2e4:	b	2e8 <__muldc3+0x2e8>
 2e8:	ldr	d0, [sp, #40]
 2ec:	fabs	d0, d0
 2f0:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 2f4:	fmov	d1, x8
 2f8:	fcmp	d0, d1
 2fc:	b.eq	320 <__muldc3+0x320>  // b.none
 300:	b	304 <__muldc3+0x304>
 304:	ldr	d0, [sp, #32]
 308:	fabs	d0, d0
 30c:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 310:	fmov	d1, x8
 314:	fcmp	d0, d1
 318:	b.ne	3fc <__muldc3+0x3fc>  // b.any
 31c:	b	320 <__muldc3+0x320>
 320:	ldr	d0, [sp, #88]
 324:	fcmp	d0, d0
 328:	b.vc	354 <__muldc3+0x354>
 32c:	b	330 <__muldc3+0x330>
 330:	ldr	d0, [sp, #88]
 334:	mov	v1.16b, v0.16b
 338:	fmov	d0, xzr
 33c:	mov	v2.16b, v0.16b
 340:	movi	v3.2d, #0x0
 344:	fneg	v3.2d, v3.2d
 348:	bit	v2.16b, v1.16b, v3.16b
 34c:	str	d2, [sp, #88]
 350:	b	354 <__muldc3+0x354>
 354:	ldr	d0, [sp, #80]
 358:	fcmp	d0, d0
 35c:	b.vc	388 <__muldc3+0x388>
 360:	b	364 <__muldc3+0x364>
 364:	ldr	d0, [sp, #80]
 368:	mov	v1.16b, v0.16b
 36c:	fmov	d0, xzr
 370:	mov	v2.16b, v0.16b
 374:	movi	v3.2d, #0x0
 378:	fneg	v3.2d, v3.2d
 37c:	bit	v2.16b, v1.16b, v3.16b
 380:	str	d2, [sp, #80]
 384:	b	388 <__muldc3+0x388>
 388:	ldr	d0, [sp, #72]
 38c:	fcmp	d0, d0
 390:	b.vc	3bc <__muldc3+0x3bc>
 394:	b	398 <__muldc3+0x398>
 398:	ldr	d0, [sp, #72]
 39c:	mov	v1.16b, v0.16b
 3a0:	fmov	d0, xzr
 3a4:	mov	v2.16b, v0.16b
 3a8:	movi	v3.2d, #0x0
 3ac:	fneg	v3.2d, v3.2d
 3b0:	bit	v2.16b, v1.16b, v3.16b
 3b4:	str	d2, [sp, #72]
 3b8:	b	3bc <__muldc3+0x3bc>
 3bc:	ldr	d0, [sp, #64]
 3c0:	fcmp	d0, d0
 3c4:	b.vc	3f0 <__muldc3+0x3f0>
 3c8:	b	3cc <__muldc3+0x3cc>
 3cc:	ldr	d0, [sp, #64]
 3d0:	mov	v1.16b, v0.16b
 3d4:	fmov	d0, xzr
 3d8:	mov	v2.16b, v0.16b
 3dc:	movi	v3.2d, #0x0
 3e0:	fneg	v3.2d, v3.2d
 3e4:	bit	v2.16b, v1.16b, v3.16b
 3e8:	str	d2, [sp, #64]
 3ec:	b	3f0 <__muldc3+0x3f0>
 3f0:	mov	w8, #0x1                   	// #1
 3f4:	str	w8, [sp, #12]
 3f8:	b	3fc <__muldc3+0x3fc>
 3fc:	ldr	w8, [sp, #12]
 400:	cbz	w8, 45c <__muldc3+0x45c>
 404:	b	408 <__muldc3+0x408>
 408:	ldr	d0, [sp, #88]
 40c:	ldr	d1, [sp, #72]
 410:	fmul	d0, d0, d1
 414:	ldr	d1, [sp, #80]
 418:	ldr	d2, [sp, #64]
 41c:	fmul	d1, d1, d2
 420:	fsub	d0, d0, d1
 424:	mov	x8, #0x7ff0000000000000    	// #9218868437227405312
 428:	fmov	d1, x8
 42c:	fmul	d0, d0, d1
 430:	str	d0, [sp, #16]
 434:	ldr	d0, [sp, #88]
 438:	ldr	d2, [sp, #64]
 43c:	fmul	d0, d0, d2
 440:	ldr	d2, [sp, #80]
 444:	ldr	d3, [sp, #72]
 448:	fmul	d2, d2, d3
 44c:	fadd	d0, d0, d2
 450:	fmul	d0, d0, d1
 454:	str	d0, [sp, #24]
 458:	b	45c <__muldc3+0x45c>
 45c:	b	460 <__muldc3+0x460>
 460:	ldr	d0, [sp, #16]
 464:	ldr	d1, [sp, #24]
 468:	str	d0, [sp, #96]
 46c:	str	d1, [sp, #104]
 470:	ldr	d0, [sp, #96]
 474:	ldr	d1, [sp, #104]
 478:	add	sp, sp, #0x70
 47c:	ret

muldf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__muldf3>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp, #8]
  10:	str	d1, [sp]
  14:	ldr	d0, [sp, #8]
  18:	ldr	d1, [sp]
  1c:	bl	2c <__mulXf3__>
  20:	ldp	x29, x30, [sp, #16]
  24:	add	sp, sp, #0x20
  28:	ret

000000000000002c <__mulXf3__>:
  2c:	sub	sp, sp, #0x80
  30:	stp	x29, x30, [sp, #112]
  34:	add	x29, sp, #0x70
  38:	stur	d0, [x29, #-16]
  3c:	stur	d1, [x29, #-24]
  40:	ldur	d0, [x29, #-16]
  44:	bl	3b4 <toRep>
  48:	lsr	x8, x0, #52
  4c:	and	x8, x8, #0x7ff
  50:	stur	w8, [x29, #-28]
  54:	ldur	d0, [x29, #-24]
  58:	bl	3b4 <toRep>
  5c:	lsr	x9, x0, #52
  60:	and	x9, x9, #0x7ff
  64:	stur	w9, [x29, #-32]
  68:	ldur	d0, [x29, #-16]
  6c:	bl	3b4 <toRep>
  70:	ldur	d0, [x29, #-24]
  74:	str	x0, [sp]
  78:	bl	3b4 <toRep>
  7c:	ldr	x10, [sp]
  80:	eor	x11, x10, x0
  84:	and	x11, x11, #0x8000000000000000
  88:	stur	x11, [x29, #-40]
  8c:	ldur	d0, [x29, #-16]
  90:	bl	3b4 <toRep>
  94:	and	x10, x0, #0xfffffffffffff
  98:	stur	x10, [x29, #-48]
  9c:	ldur	d0, [x29, #-24]
  a0:	bl	3b4 <toRep>
  a4:	and	x10, x0, #0xfffffffffffff
  a8:	str	x10, [sp, #56]
  ac:	str	wzr, [sp, #52]
  b0:	ldur	w8, [x29, #-28]
  b4:	subs	w8, w8, #0x1
  b8:	cmp	w8, #0x7fe
  bc:	b.cs	d0 <__mulXf3__+0xa4>  // b.hs, b.nlast
  c0:	ldur	w8, [x29, #-32]
  c4:	subs	w8, w8, #0x1
  c8:	cmp	w8, #0x7fe
  cc:	b.cc	238 <__mulXf3__+0x20c>  // b.lo, b.ul, b.last
  d0:	ldur	d0, [x29, #-16]
  d4:	bl	3b4 <toRep>
  d8:	and	x8, x0, #0x7fffffffffffffff
  dc:	str	x8, [sp, #40]
  e0:	ldur	d0, [x29, #-24]
  e4:	bl	3b4 <toRep>
  e8:	and	x8, x0, #0x7fffffffffffffff
  ec:	str	x8, [sp, #32]
  f0:	ldr	x8, [sp, #40]
  f4:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
  f8:	cmp	x8, x9
  fc:	b.ls	118 <__mulXf3__+0xec>  // b.plast
 100:	ldur	d0, [x29, #-16]
 104:	bl	3b4 <toRep>
 108:	orr	x0, x0, #0x8000000000000
 10c:	bl	3d0 <fromRep>
 110:	stur	d0, [x29, #-8]
 114:	b	3a4 <__mulXf3__+0x378>
 118:	ldr	x8, [sp, #32]
 11c:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 120:	cmp	x8, x9
 124:	b.ls	140 <__mulXf3__+0x114>  // b.plast
 128:	ldur	d0, [x29, #-24]
 12c:	bl	3b4 <toRep>
 130:	orr	x0, x0, #0x8000000000000
 134:	bl	3d0 <fromRep>
 138:	stur	d0, [x29, #-8]
 13c:	b	3a4 <__mulXf3__+0x378>
 140:	ldr	x8, [sp, #40]
 144:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 148:	cmp	x8, x9
 14c:	b.ne	180 <__mulXf3__+0x154>  // b.any
 150:	ldr	x8, [sp, #32]
 154:	cbz	x8, 170 <__mulXf3__+0x144>
 158:	ldr	x8, [sp, #40]
 15c:	ldur	x9, [x29, #-40]
 160:	orr	x0, x8, x9
 164:	bl	3d0 <fromRep>
 168:	stur	d0, [x29, #-8]
 16c:	b	3a4 <__mulXf3__+0x378>
 170:	mov	x0, #0x7ff8000000000000    	// #9221120237041090560
 174:	bl	3d0 <fromRep>
 178:	stur	d0, [x29, #-8]
 17c:	b	3a4 <__mulXf3__+0x378>
 180:	ldr	x8, [sp, #32]
 184:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 188:	cmp	x8, x9
 18c:	b.ne	1c0 <__mulXf3__+0x194>  // b.any
 190:	ldr	x8, [sp, #40]
 194:	cbz	x8, 1b0 <__mulXf3__+0x184>
 198:	ldr	x8, [sp, #32]
 19c:	ldur	x9, [x29, #-40]
 1a0:	orr	x0, x8, x9
 1a4:	bl	3d0 <fromRep>
 1a8:	stur	d0, [x29, #-8]
 1ac:	b	3a4 <__mulXf3__+0x378>
 1b0:	mov	x0, #0x7ff8000000000000    	// #9221120237041090560
 1b4:	bl	3d0 <fromRep>
 1b8:	stur	d0, [x29, #-8]
 1bc:	b	3a4 <__mulXf3__+0x378>
 1c0:	ldr	x8, [sp, #40]
 1c4:	cbnz	x8, 1d8 <__mulXf3__+0x1ac>
 1c8:	ldur	x0, [x29, #-40]
 1cc:	bl	3d0 <fromRep>
 1d0:	stur	d0, [x29, #-8]
 1d4:	b	3a4 <__mulXf3__+0x378>
 1d8:	ldr	x8, [sp, #32]
 1dc:	cbnz	x8, 1f0 <__mulXf3__+0x1c4>
 1e0:	ldur	x0, [x29, #-40]
 1e4:	bl	3d0 <fromRep>
 1e8:	stur	d0, [x29, #-8]
 1ec:	b	3a4 <__mulXf3__+0x378>
 1f0:	ldr	x8, [sp, #40]
 1f4:	mov	x9, #0x10000000000000      	// #4503599627370496
 1f8:	cmp	x8, x9
 1fc:	b.cs	214 <__mulXf3__+0x1e8>  // b.hs, b.nlast
 200:	sub	x0, x29, #0x30
 204:	bl	3ec <normalize>
 208:	ldr	w8, [sp, #52]
 20c:	add	w8, w8, w0
 210:	str	w8, [sp, #52]
 214:	ldr	x8, [sp, #32]
 218:	mov	x9, #0x10000000000000      	// #4503599627370496
 21c:	cmp	x8, x9
 220:	b.cs	238 <__mulXf3__+0x20c>  // b.hs, b.nlast
 224:	add	x0, sp, #0x38
 228:	bl	3ec <normalize>
 22c:	ldr	w8, [sp, #52]
 230:	add	w8, w8, w0
 234:	str	w8, [sp, #52]
 238:	ldur	x8, [x29, #-48]
 23c:	orr	x8, x8, #0x10000000000000
 240:	stur	x8, [x29, #-48]
 244:	ldr	x8, [sp, #56]
 248:	orr	x8, x8, #0x10000000000000
 24c:	str	x8, [sp, #56]
 250:	ldur	x0, [x29, #-48]
 254:	ldr	x8, [sp, #56]
 258:	lsl	x1, x8, #11
 25c:	add	x2, sp, #0x18
 260:	add	x3, sp, #0x10
 264:	bl	464 <wideMultiply>
 268:	ldur	w9, [x29, #-28]
 26c:	ldur	w10, [x29, #-32]
 270:	add	w9, w9, w10
 274:	subs	w9, w9, #0x3ff
 278:	ldr	w10, [sp, #52]
 27c:	add	w9, w9, w10
 280:	str	w9, [sp, #12]
 284:	ldr	x8, [sp, #24]
 288:	and	x8, x8, #0x10000000000000
 28c:	cbz	x8, 2a0 <__mulXf3__+0x274>
 290:	ldr	w8, [sp, #12]
 294:	add	w8, w8, #0x1
 298:	str	w8, [sp, #12]
 29c:	b	2b0 <__mulXf3__+0x284>
 2a0:	add	x0, sp, #0x18
 2a4:	add	x1, sp, #0x10
 2a8:	mov	w2, #0x1                   	// #1
 2ac:	bl	544 <wideLeftShift>
 2b0:	ldr	w8, [sp, #12]
 2b4:	cmp	w8, #0x7ff
 2b8:	b.lt	2d4 <__mulXf3__+0x2a8>  // b.tstop
 2bc:	ldur	x8, [x29, #-40]
 2c0:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 2c4:	orr	x0, x9, x8
 2c8:	bl	3d0 <fromRep>
 2cc:	stur	d0, [x29, #-8]
 2d0:	b	3a4 <__mulXf3__+0x378>
 2d4:	ldr	w8, [sp, #12]
 2d8:	cmp	w8, #0x0
 2dc:	cset	w8, gt
 2e0:	tbnz	w8, #0, 32c <__mulXf3__+0x300>
 2e4:	ldr	w8, [sp, #12]
 2e8:	mov	w9, w8
 2ec:	mov	x10, #0x1                   	// #1
 2f0:	subs	x9, x10, x9
 2f4:	str	w9, [sp, #8]
 2f8:	ldr	w8, [sp, #8]
 2fc:	mov	w10, w8
 300:	cmp	x10, #0x40
 304:	b.cc	318 <__mulXf3__+0x2ec>  // b.lo, b.ul, b.last
 308:	ldur	x0, [x29, #-40]
 30c:	bl	3d0 <fromRep>
 310:	stur	d0, [x29, #-8]
 314:	b	3a4 <__mulXf3__+0x378>
 318:	ldr	w2, [sp, #8]
 31c:	add	x0, sp, #0x18
 320:	add	x1, sp, #0x10
 324:	bl	5b0 <wideRightShiftWithSticky>
 328:	b	348 <__mulXf3__+0x31c>
 32c:	ldr	x8, [sp, #24]
 330:	and	x8, x8, #0xfffffffffffff
 334:	str	x8, [sp, #24]
 338:	ldrsw	x8, [sp, #12]
 33c:	ldr	x9, [sp, #24]
 340:	orr	x8, x9, x8, lsl #52
 344:	str	x8, [sp, #24]
 348:	ldur	x8, [x29, #-40]
 34c:	ldr	x9, [sp, #24]
 350:	orr	x8, x9, x8
 354:	str	x8, [sp, #24]
 358:	ldr	x8, [sp, #16]
 35c:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
 360:	cmp	x8, x9
 364:	b.ls	374 <__mulXf3__+0x348>  // b.plast
 368:	ldr	x8, [sp, #24]
 36c:	add	x8, x8, #0x1
 370:	str	x8, [sp, #24]
 374:	ldr	x8, [sp, #16]
 378:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
 37c:	cmp	x8, x9
 380:	b.ne	398 <__mulXf3__+0x36c>  // b.any
 384:	ldr	x8, [sp, #24]
 388:	and	x8, x8, #0x1
 38c:	ldr	x9, [sp, #24]
 390:	add	x8, x9, x8
 394:	str	x8, [sp, #24]
 398:	ldr	x0, [sp, #24]
 39c:	bl	3d0 <fromRep>
 3a0:	stur	d0, [x29, #-8]
 3a4:	ldur	d0, [x29, #-8]
 3a8:	ldp	x29, x30, [sp, #112]
 3ac:	add	sp, sp, #0x80
 3b0:	ret

00000000000003b4 <toRep>:
 3b4:	sub	sp, sp, #0x10
 3b8:	str	d0, [sp, #8]
 3bc:	ldr	x8, [sp, #8]
 3c0:	str	x8, [sp]
 3c4:	ldr	x0, [sp]
 3c8:	add	sp, sp, #0x10
 3cc:	ret

00000000000003d0 <fromRep>:
 3d0:	sub	sp, sp, #0x10
 3d4:	str	x0, [sp, #8]
 3d8:	ldr	x8, [sp, #8]
 3dc:	str	x8, [sp]
 3e0:	ldr	d0, [sp]
 3e4:	add	sp, sp, #0x10
 3e8:	ret

00000000000003ec <normalize>:
 3ec:	sub	sp, sp, #0x30
 3f0:	stp	x29, x30, [sp, #32]
 3f4:	add	x29, sp, #0x20
 3f8:	mov	x8, #0x10000000000000      	// #4503599627370496
 3fc:	mov	w9, #0x1                   	// #1
 400:	stur	x0, [x29, #-8]
 404:	ldur	x10, [x29, #-8]
 408:	ldr	x0, [x10]
 40c:	str	x8, [sp, #8]
 410:	str	w9, [sp, #4]
 414:	bl	730 <rep_clz>
 418:	ldr	x8, [sp, #8]
 41c:	str	w0, [sp]
 420:	mov	x0, x8
 424:	bl	730 <rep_clz>
 428:	ldr	w9, [sp]
 42c:	subs	w11, w9, w0
 430:	stur	w11, [x29, #-12]
 434:	ldur	w11, [x29, #-12]
 438:	mov	w8, w11
 43c:	ldur	x10, [x29, #-8]
 440:	ldr	x12, [x10]
 444:	lsl	x8, x12, x8
 448:	str	x8, [x10]
 44c:	ldur	w11, [x29, #-12]
 450:	ldr	w13, [sp, #4]
 454:	subs	w0, w13, w11
 458:	ldp	x29, x30, [sp, #32]
 45c:	add	sp, sp, #0x30
 460:	ret

0000000000000464 <wideMultiply>:
 464:	sub	sp, sp, #0x50
 468:	str	x0, [sp, #72]
 46c:	str	x1, [sp, #64]
 470:	str	x2, [sp, #56]
 474:	str	x3, [sp, #48]
 478:	ldr	x8, [sp, #72]
 47c:	and	x8, x8, #0xffffffff
 480:	ldr	x9, [sp, #64]
 484:	and	x9, x9, #0xffffffff
 488:	mul	x8, x8, x9
 48c:	str	x8, [sp, #40]
 490:	ldr	x8, [sp, #72]
 494:	and	x8, x8, #0xffffffff
 498:	ldr	x9, [sp, #64]
 49c:	lsr	x9, x9, #32
 4a0:	mul	x8, x8, x9
 4a4:	str	x8, [sp, #32]
 4a8:	ldr	x8, [sp, #72]
 4ac:	lsr	x8, x8, #32
 4b0:	ldr	x9, [sp, #64]
 4b4:	and	x9, x9, #0xffffffff
 4b8:	mul	x8, x8, x9
 4bc:	str	x8, [sp, #24]
 4c0:	ldr	x8, [sp, #72]
 4c4:	lsr	x8, x8, #32
 4c8:	ldr	x9, [sp, #64]
 4cc:	lsr	x9, x9, #32
 4d0:	mul	x8, x8, x9
 4d4:	str	x8, [sp, #16]
 4d8:	ldr	x8, [sp, #40]
 4dc:	and	x8, x8, #0xffffffff
 4e0:	str	x8, [sp, #8]
 4e4:	ldr	x8, [sp, #40]
 4e8:	lsr	x8, x8, #32
 4ec:	ldr	x9, [sp, #32]
 4f0:	add	x8, x8, w9, uxtw
 4f4:	ldr	x10, [sp, #24]
 4f8:	add	x8, x8, w10, uxtw
 4fc:	str	x8, [sp]
 500:	ldr	x8, [sp, #8]
 504:	ldr	x11, [sp]
 508:	add	x8, x8, x11, lsl #32
 50c:	ldr	x11, [sp, #48]
 510:	str	x8, [x11]
 514:	ldr	x8, [sp, #32]
 518:	ldr	x11, [sp, #24]
 51c:	lsr	x11, x11, #32
 520:	add	x8, x11, x8, lsr #32
 524:	ldr	x11, [sp]
 528:	add	x8, x8, x11, lsr #32
 52c:	ldr	x11, [sp, #16]
 530:	add	x8, x8, x11
 534:	ldr	x11, [sp, #56]
 538:	str	x8, [x11]
 53c:	add	sp, sp, #0x50
 540:	ret

0000000000000544 <wideLeftShift>:
 544:	sub	sp, sp, #0x20
 548:	mov	x8, #0x40                  	// #64
 54c:	str	x0, [sp, #24]
 550:	str	x1, [sp, #16]
 554:	str	w2, [sp, #12]
 558:	ldr	x9, [sp, #24]
 55c:	ldr	x9, [x9]
 560:	ldr	w10, [sp, #12]
 564:	mov	w11, w10
 568:	lsl	x9, x9, x11
 56c:	ldr	x11, [sp, #16]
 570:	ldr	x11, [x11]
 574:	ldrsw	x12, [sp, #12]
 578:	subs	x8, x8, x12
 57c:	lsr	x8, x11, x8
 580:	orr	x8, x9, x8
 584:	ldr	x9, [sp, #24]
 588:	str	x8, [x9]
 58c:	ldr	x8, [sp, #16]
 590:	ldr	x8, [x8]
 594:	ldr	w10, [sp, #12]
 598:	mov	w9, w10
 59c:	lsl	x8, x8, x9
 5a0:	ldr	x9, [sp, #16]
 5a4:	str	x8, [x9]
 5a8:	add	sp, sp, #0x20
 5ac:	ret

00000000000005b0 <wideRightShiftWithSticky>:
 5b0:	sub	sp, sp, #0x20
 5b4:	str	x0, [sp, #24]
 5b8:	str	x1, [sp, #16]
 5bc:	str	w2, [sp, #12]
 5c0:	ldr	w8, [sp, #12]
 5c4:	mov	w9, w8
 5c8:	cmp	x9, #0x40
 5cc:	b.cs	664 <wideRightShiftWithSticky+0xb4>  // b.hs, b.nlast
 5d0:	ldr	x8, [sp, #16]
 5d4:	ldr	x8, [x8]
 5d8:	ldr	w9, [sp, #12]
 5dc:	mov	w10, w9
 5e0:	mov	x11, #0x40                  	// #64
 5e4:	subs	x10, x11, x10
 5e8:	lsl	x8, x8, x10
 5ec:	cmp	x8, #0x0
 5f0:	cset	w9, ne  // ne = any
 5f4:	and	w9, w9, #0x1
 5f8:	strb	w9, [sp, #11]
 5fc:	ldr	x8, [sp, #24]
 600:	ldr	x8, [x8]
 604:	ldr	w9, [sp, #12]
 608:	mov	w10, w9
 60c:	subs	x10, x11, x10
 610:	lsl	x8, x8, x10
 614:	ldr	x10, [sp, #16]
 618:	ldr	x10, [x10]
 61c:	ldr	w9, [sp, #12]
 620:	mov	w11, w9
 624:	lsr	x10, x10, x11
 628:	orr	x8, x8, x10
 62c:	ldrb	w9, [sp, #11]
 630:	mov	w0, w9
 634:	and	x10, x0, #0x1
 638:	orr	x8, x8, x10
 63c:	ldr	x10, [sp, #16]
 640:	str	x8, [x10]
 644:	ldr	x8, [sp, #24]
 648:	ldr	x8, [x8]
 64c:	ldr	w9, [sp, #12]
 650:	mov	w10, w9
 654:	lsr	x8, x8, x10
 658:	ldr	x10, [sp, #24]
 65c:	str	x8, [x10]
 660:	b	728 <wideRightShiftWithSticky+0x178>
 664:	ldr	w8, [sp, #12]
 668:	mov	w9, w8
 66c:	cmp	x9, #0x80
 670:	b.cs	6e8 <wideRightShiftWithSticky+0x138>  // b.hs, b.nlast
 674:	ldr	x8, [sp, #24]
 678:	ldr	x8, [x8]
 67c:	ldr	w9, [sp, #12]
 680:	mov	w10, w9
 684:	mov	x11, #0x80                  	// #128
 688:	subs	x10, x11, x10
 68c:	lsl	x8, x8, x10
 690:	ldr	x10, [sp, #16]
 694:	ldr	x10, [x10]
 698:	orr	x8, x8, x10
 69c:	cmp	x8, #0x0
 6a0:	cset	w9, ne  // ne = any
 6a4:	and	w9, w9, #0x1
 6a8:	strb	w9, [sp, #10]
 6ac:	ldr	x8, [sp, #24]
 6b0:	ldr	x8, [x8]
 6b4:	ldr	w9, [sp, #12]
 6b8:	mov	w10, w9
 6bc:	subs	x10, x10, #0x40
 6c0:	lsr	x8, x8, x10
 6c4:	ldrb	w9, [sp, #10]
 6c8:	mov	w0, w9
 6cc:	and	x10, x0, #0x1
 6d0:	orr	x8, x8, x10
 6d4:	ldr	x10, [sp, #16]
 6d8:	str	x8, [x10]
 6dc:	ldr	x8, [sp, #24]
 6e0:	str	xzr, [x8]
 6e4:	b	728 <wideRightShiftWithSticky+0x178>
 6e8:	ldr	x8, [sp, #24]
 6ec:	ldr	x8, [x8]
 6f0:	ldr	x9, [sp, #16]
 6f4:	ldr	x9, [x9]
 6f8:	orr	x8, x8, x9
 6fc:	cmp	x8, #0x0
 700:	cset	w10, ne  // ne = any
 704:	and	w10, w10, #0x1
 708:	strb	w10, [sp, #9]
 70c:	ldrb	w10, [sp, #9]
 710:	mov	w0, w10
 714:	and	x8, x0, #0x1
 718:	ldr	x9, [sp, #16]
 71c:	str	x8, [x9]
 720:	ldr	x8, [sp, #24]
 724:	str	xzr, [x8]
 728:	add	sp, sp, #0x20
 72c:	ret

0000000000000730 <rep_clz>:
 730:	sub	sp, sp, #0x10
 734:	str	x0, [sp, #8]
 738:	ldr	x8, [sp, #8]
 73c:	clz	x8, x8
 740:	mov	w0, w8
 744:	add	sp, sp, #0x10
 748:	ret

muldi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__muldi3>:
   0:	sub	sp, sp, #0x40
   4:	stp	x29, x30, [sp, #48]
   8:	add	x29, sp, #0x30
   c:	stur	x0, [x29, #-8]
  10:	stur	x1, [x29, #-16]
  14:	ldur	x8, [x29, #-8]
  18:	str	x8, [sp, #24]
  1c:	ldur	x8, [x29, #-16]
  20:	str	x8, [sp, #16]
  24:	ldr	w0, [sp, #24]
  28:	ldr	w1, [sp, #16]
  2c:	bl	6c <__muldsi3>
  30:	str	x0, [sp, #8]
  34:	ldr	w9, [sp, #28]
  38:	ldr	w10, [sp, #16]
  3c:	mul	w9, w9, w10
  40:	ldr	w10, [sp, #24]
  44:	ldr	w11, [sp, #20]
  48:	mul	w10, w10, w11
  4c:	add	w9, w9, w10
  50:	ldr	w10, [sp, #12]
  54:	add	w9, w10, w9
  58:	str	w9, [sp, #12]
  5c:	ldr	x0, [sp, #8]
  60:	ldp	x29, x30, [sp, #48]
  64:	add	sp, sp, #0x40
  68:	ret

000000000000006c <__muldsi3>:
  6c:	sub	sp, sp, #0x20
  70:	mov	w8, #0x10                  	// #16
  74:	mov	w9, #0xffff                	// #65535
  78:	str	w0, [sp, #28]
  7c:	str	w1, [sp, #24]
  80:	str	w8, [sp, #12]
  84:	str	w9, [sp, #8]
  88:	ldr	w8, [sp, #28]
  8c:	and	w8, w8, #0xffff
  90:	ldr	w9, [sp, #24]
  94:	and	w9, w9, #0xffff
  98:	mul	w8, w8, w9
  9c:	str	w8, [sp, #16]
  a0:	ldr	w8, [sp, #16]
  a4:	mov	x10, #0x10                  	// #16
  a8:	lsr	w8, w8, #16
  ac:	str	w8, [sp, #4]
  b0:	ldr	w8, [sp, #16]
  b4:	and	w8, w8, #0xffff
  b8:	str	w8, [sp, #16]
  bc:	ldr	w8, [sp, #28]
  c0:	mov	x2, x10
  c4:	lsr	w8, w8, w2
  c8:	ldr	w9, [sp, #24]
  cc:	and	w9, w9, #0xffff
  d0:	mul	w8, w8, w9
  d4:	ldr	w9, [sp, #4]
  d8:	add	w8, w9, w8
  dc:	str	w8, [sp, #4]
  e0:	ldr	w8, [sp, #4]
  e4:	and	w8, w8, #0xffff
  e8:	ldr	w9, [sp, #16]
  ec:	add	w8, w9, w8, lsl #16
  f0:	str	w8, [sp, #16]
  f4:	ldr	w8, [sp, #4]
  f8:	mov	x3, x10
  fc:	lsr	w8, w8, w3
 100:	str	w8, [sp, #20]
 104:	ldr	w8, [sp, #16]
 108:	mov	x4, x10
 10c:	lsr	w8, w8, w4
 110:	str	w8, [sp, #4]
 114:	ldr	w8, [sp, #16]
 118:	and	w8, w8, #0xffff
 11c:	str	w8, [sp, #16]
 120:	ldr	w8, [sp, #24]
 124:	mov	x5, x10
 128:	lsr	w8, w8, w5
 12c:	ldr	w9, [sp, #28]
 130:	and	w9, w9, #0xffff
 134:	mul	w8, w8, w9
 138:	ldr	w9, [sp, #4]
 13c:	add	w8, w9, w8
 140:	str	w8, [sp, #4]
 144:	ldr	w8, [sp, #4]
 148:	and	w8, w8, #0xffff
 14c:	ldr	w9, [sp, #16]
 150:	add	w8, w9, w8, lsl #16
 154:	str	w8, [sp, #16]
 158:	ldr	w8, [sp, #4]
 15c:	ldr	w9, [sp, #20]
 160:	add	w8, w9, w8, lsr #16
 164:	str	w8, [sp, #20]
 168:	ldr	w8, [sp, #28]
 16c:	mov	x6, x10
 170:	lsr	w8, w8, w6
 174:	ldr	w9, [sp, #24]
 178:	lsr	w9, w9, w10
 17c:	mul	w8, w8, w9
 180:	ldr	w9, [sp, #20]
 184:	add	w8, w9, w8
 188:	str	w8, [sp, #20]
 18c:	ldr	x0, [sp, #16]
 190:	add	sp, sp, #0x20
 194:	ret

mulodi4.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulodi4>:
   0:	sub	sp, sp, #0x60
   4:	mov	w8, #0x40                  	// #64
   8:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
   c:	mov	x10, #0x7fffffffffffffff    	// #9223372036854775807
  10:	str	x0, [sp, #80]
  14:	str	x1, [sp, #72]
  18:	str	x2, [sp, #64]
  1c:	str	w8, [sp, #60]
  20:	str	x9, [sp, #48]
  24:	str	x10, [sp, #40]
  28:	ldr	x10, [sp, #64]
  2c:	str	wzr, [x10]
  30:	ldr	x10, [sp, #80]
  34:	ldr	x11, [sp, #72]
  38:	mul	x10, x10, x11
  3c:	str	x10, [sp, #32]
  40:	ldr	x10, [sp, #80]
  44:	cmp	x10, x9
  48:	b.ne	78 <__mulodi4+0x78>  // b.any
  4c:	ldr	x8, [sp, #72]
  50:	cbz	x8, 6c <__mulodi4+0x6c>
  54:	ldr	x8, [sp, #72]
  58:	cmp	x8, #0x1
  5c:	b.eq	6c <__mulodi4+0x6c>  // b.none
  60:	ldr	x8, [sp, #64]
  64:	mov	w9, #0x1                   	// #1
  68:	str	w9, [x8]
  6c:	ldr	x8, [sp, #32]
  70:	str	x8, [sp, #88]
  74:	b	18c <__mulodi4+0x18c>
  78:	ldr	x8, [sp, #72]
  7c:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
  80:	cmp	x8, x9
  84:	b.ne	b4 <__mulodi4+0xb4>  // b.any
  88:	ldr	x8, [sp, #80]
  8c:	cbz	x8, a8 <__mulodi4+0xa8>
  90:	ldr	x8, [sp, #80]
  94:	cmp	x8, #0x1
  98:	b.eq	a8 <__mulodi4+0xa8>  // b.none
  9c:	ldr	x8, [sp, #64]
  a0:	mov	w9, #0x1                   	// #1
  a4:	str	w9, [x8]
  a8:	ldr	x8, [sp, #32]
  ac:	str	x8, [sp, #88]
  b0:	b	18c <__mulodi4+0x18c>
  b4:	ldr	x8, [sp, #80]
  b8:	asr	x8, x8, #63
  bc:	str	x8, [sp, #24]
  c0:	ldr	x8, [sp, #80]
  c4:	ldr	x9, [sp, #24]
  c8:	eor	x8, x8, x9
  cc:	ldr	x9, [sp, #24]
  d0:	subs	x8, x8, x9
  d4:	str	x8, [sp, #16]
  d8:	ldr	x8, [sp, #72]
  dc:	asr	x8, x8, #63
  e0:	str	x8, [sp, #8]
  e4:	ldr	x8, [sp, #72]
  e8:	ldr	x9, [sp, #8]
  ec:	eor	x8, x8, x9
  f0:	ldr	x9, [sp, #8]
  f4:	subs	x8, x8, x9
  f8:	str	x8, [sp]
  fc:	ldr	x8, [sp, #16]
 100:	cmp	x8, #0x2
 104:	b.lt	114 <__mulodi4+0x114>  // b.tstop
 108:	ldr	x8, [sp]
 10c:	cmp	x8, #0x2
 110:	b.ge	120 <__mulodi4+0x120>  // b.tcont
 114:	ldr	x8, [sp, #32]
 118:	str	x8, [sp, #88]
 11c:	b	18c <__mulodi4+0x18c>
 120:	ldr	x8, [sp, #24]
 124:	ldr	x9, [sp, #8]
 128:	cmp	x8, x9
 12c:	b.ne	158 <__mulodi4+0x158>  // b.any
 130:	ldr	x8, [sp, #16]
 134:	ldr	x9, [sp]
 138:	mov	x10, #0x7fffffffffffffff    	// #9223372036854775807
 13c:	sdiv	x9, x10, x9
 140:	cmp	x8, x9
 144:	b.le	154 <__mulodi4+0x154>
 148:	ldr	x8, [sp, #64]
 14c:	mov	w9, #0x1                   	// #1
 150:	str	w9, [x8]
 154:	b	184 <__mulodi4+0x184>
 158:	ldr	x8, [sp, #16]
 15c:	ldr	x9, [sp]
 160:	mov	x10, xzr
 164:	subs	x9, x10, x9
 168:	mov	x10, #0x8000000000000000    	// #-9223372036854775808
 16c:	sdiv	x9, x10, x9
 170:	cmp	x8, x9
 174:	b.le	184 <__mulodi4+0x184>
 178:	ldr	x8, [sp, #64]
 17c:	mov	w9, #0x1                   	// #1
 180:	str	w9, [x8]
 184:	ldr	x8, [sp, #32]
 188:	str	x8, [sp, #88]
 18c:	ldr	x0, [sp, #88]
 190:	add	sp, sp, #0x60
 194:	ret

mulosi4.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulosi4>:
   0:	sub	sp, sp, #0x40
   4:	mov	w8, #0x20                  	// #32
   8:	mov	w9, #0x80000000            	// #-2147483648
   c:	mov	w10, #0x7fffffff            	// #2147483647
  10:	str	w0, [sp, #56]
  14:	str	w1, [sp, #52]
  18:	str	x2, [sp, #40]
  1c:	str	w8, [sp, #36]
  20:	str	w9, [sp, #32]
  24:	str	w10, [sp, #28]
  28:	ldr	x11, [sp, #40]
  2c:	str	wzr, [x11]
  30:	ldr	w8, [sp, #56]
  34:	ldr	w10, [sp, #52]
  38:	mul	w8, w8, w10
  3c:	str	w8, [sp, #24]
  40:	ldr	w8, [sp, #56]
  44:	cmp	w8, w9
  48:	b.ne	78 <__mulosi4+0x78>  // b.any
  4c:	ldr	w8, [sp, #52]
  50:	cbz	w8, 6c <__mulosi4+0x6c>
  54:	ldr	w8, [sp, #52]
  58:	cmp	w8, #0x1
  5c:	b.eq	6c <__mulosi4+0x6c>  // b.none
  60:	ldr	x8, [sp, #40]
  64:	mov	w9, #0x1                   	// #1
  68:	str	w9, [x8]
  6c:	ldr	w8, [sp, #24]
  70:	str	w8, [sp, #60]
  74:	b	190 <__mulosi4+0x190>
  78:	ldr	w8, [sp, #52]
  7c:	mov	w9, #0x80000000            	// #-2147483648
  80:	cmp	w8, w9
  84:	b.ne	b4 <__mulosi4+0xb4>  // b.any
  88:	ldr	w8, [sp, #56]
  8c:	cbz	w8, a8 <__mulosi4+0xa8>
  90:	ldr	w8, [sp, #56]
  94:	cmp	w8, #0x1
  98:	b.eq	a8 <__mulosi4+0xa8>  // b.none
  9c:	ldr	x8, [sp, #40]
  a0:	mov	w9, #0x1                   	// #1
  a4:	str	w9, [x8]
  a8:	ldr	w8, [sp, #24]
  ac:	str	w8, [sp, #60]
  b0:	b	190 <__mulosi4+0x190>
  b4:	ldr	w8, [sp, #56]
  b8:	mov	x9, #0x1f                  	// #31
  bc:	asr	w8, w8, #31
  c0:	str	w8, [sp, #20]
  c4:	ldr	w8, [sp, #56]
  c8:	ldr	w10, [sp, #20]
  cc:	eor	w8, w8, w10
  d0:	ldr	w10, [sp, #20]
  d4:	subs	w8, w8, w10
  d8:	str	w8, [sp, #16]
  dc:	ldr	w8, [sp, #52]
  e0:	asr	w8, w8, w9
  e4:	str	w8, [sp, #12]
  e8:	ldr	w8, [sp, #52]
  ec:	ldr	w9, [sp, #12]
  f0:	eor	w8, w8, w9
  f4:	ldr	w9, [sp, #12]
  f8:	subs	w8, w8, w9
  fc:	str	w8, [sp, #8]
 100:	ldr	w8, [sp, #16]
 104:	cmp	w8, #0x2
 108:	b.lt	118 <__mulosi4+0x118>  // b.tstop
 10c:	ldr	w8, [sp, #8]
 110:	cmp	w8, #0x2
 114:	b.ge	124 <__mulosi4+0x124>  // b.tcont
 118:	ldr	w8, [sp, #24]
 11c:	str	w8, [sp, #60]
 120:	b	190 <__mulosi4+0x190>
 124:	ldr	w8, [sp, #20]
 128:	ldr	w9, [sp, #12]
 12c:	cmp	w8, w9
 130:	b.ne	15c <__mulosi4+0x15c>  // b.any
 134:	ldr	w8, [sp, #16]
 138:	ldr	w9, [sp, #8]
 13c:	mov	w10, #0x7fffffff            	// #2147483647
 140:	sdiv	w9, w10, w9
 144:	cmp	w8, w9
 148:	b.le	158 <__mulosi4+0x158>
 14c:	ldr	x8, [sp, #40]
 150:	mov	w9, #0x1                   	// #1
 154:	str	w9, [x8]
 158:	b	188 <__mulosi4+0x188>
 15c:	ldr	w8, [sp, #16]
 160:	ldr	w9, [sp, #8]
 164:	mov	w10, wzr
 168:	subs	w9, w10, w9
 16c:	mov	w10, #0x80000000            	// #-2147483648
 170:	sdiv	w9, w10, w9
 174:	cmp	w8, w9
 178:	b.le	188 <__mulosi4+0x188>
 17c:	ldr	x8, [sp, #40]
 180:	mov	w9, #0x1                   	// #1
 184:	str	w9, [x8]
 188:	ldr	w8, [sp, #24]
 18c:	str	w8, [sp, #60]
 190:	ldr	w0, [sp, #60]
 194:	add	sp, sp, #0x40
 198:	ret

muloti4.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__muloti4>:
   0:	sub	sp, sp, #0xe0
   4:	stp	x29, x30, [sp, #208]
   8:	add	x29, sp, #0xd0
   c:	stur	x1, [x29, #-24]
  10:	stur	x0, [x29, #-32]
  14:	stur	x3, [x29, #-40]
  18:	stur	x2, [x29, #-48]
  1c:	stur	x4, [x29, #-56]
  20:	mov	w8, #0x80                  	// #128
  24:	stur	w8, [x29, #-60]
  28:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
  2c:	stur	x9, [x29, #-72]
  30:	mov	x9, xzr
  34:	stur	x9, [x29, #-80]
  38:	mov	x9, #0x7fffffffffffffff    	// #9223372036854775807
  3c:	stur	x9, [x29, #-88]
  40:	mov	x9, #0xffffffffffffffff    	// #-1
  44:	stur	x9, [x29, #-96]
  48:	ldur	x9, [x29, #-56]
  4c:	mov	w8, wzr
  50:	str	w8, [x9]
  54:	ldur	x9, [x29, #-24]
  58:	ldur	x10, [x29, #-32]
  5c:	ldur	x11, [x29, #-48]
  60:	ldur	x12, [x29, #-40]
  64:	mul	x12, x10, x12
  68:	umulh	x13, x10, x11
  6c:	add	x12, x13, x12
  70:	mul	x9, x9, x11
  74:	add	x9, x12, x9
  78:	mul	x10, x10, x11
  7c:	str	x10, [sp, #96]
  80:	str	x9, [sp, #104]
  84:	ldur	x9, [x29, #-32]
  88:	ldur	x10, [x29, #-24]
  8c:	eor	x10, x10, #0x8000000000000000
  90:	orr	x9, x9, x10
  94:	cbnz	x9, ec <__muloti4+0xec>
  98:	b	9c <__muloti4+0x9c>
  9c:	ldur	x8, [x29, #-40]
  a0:	ldur	x9, [x29, #-48]
  a4:	orr	x8, x9, x8
  a8:	cbz	x8, d8 <__muloti4+0xd8>
  ac:	b	b0 <__muloti4+0xb0>
  b0:	ldur	x8, [x29, #-40]
  b4:	ldur	x9, [x29, #-48]
  b8:	eor	x9, x9, #0x1
  bc:	orr	x8, x9, x8
  c0:	cbz	x8, d8 <__muloti4+0xd8>
  c4:	b	c8 <__muloti4+0xc8>
  c8:	ldur	x8, [x29, #-56]
  cc:	mov	w9, #0x1                   	// #1
  d0:	str	w9, [x8]
  d4:	b	d8 <__muloti4+0xd8>
  d8:	ldr	x8, [sp, #96]
  dc:	ldr	x9, [sp, #104]
  e0:	stur	x9, [x29, #-8]
  e4:	stur	x8, [x29, #-16]
  e8:	b	31c <__muloti4+0x31c>
  ec:	ldur	x8, [x29, #-48]
  f0:	ldur	x9, [x29, #-40]
  f4:	eor	x9, x9, #0x8000000000000000
  f8:	orr	x8, x8, x9
  fc:	cbnz	x8, 154 <__muloti4+0x154>
 100:	b	104 <__muloti4+0x104>
 104:	ldur	x8, [x29, #-24]
 108:	ldur	x9, [x29, #-32]
 10c:	orr	x8, x9, x8
 110:	cbz	x8, 140 <__muloti4+0x140>
 114:	b	118 <__muloti4+0x118>
 118:	ldur	x8, [x29, #-24]
 11c:	ldur	x9, [x29, #-32]
 120:	eor	x9, x9, #0x1
 124:	orr	x8, x9, x8
 128:	cbz	x8, 140 <__muloti4+0x140>
 12c:	b	130 <__muloti4+0x130>
 130:	ldur	x8, [x29, #-56]
 134:	mov	w9, #0x1                   	// #1
 138:	str	w9, [x8]
 13c:	b	140 <__muloti4+0x140>
 140:	ldr	x8, [sp, #96]
 144:	ldr	x9, [sp, #104]
 148:	stur	x9, [x29, #-8]
 14c:	stur	x8, [x29, #-16]
 150:	b	31c <__muloti4+0x31c>
 154:	ldur	x8, [x29, #-24]
 158:	asr	x8, x8, #63
 15c:	str	x8, [sp, #88]
 160:	str	x8, [sp, #80]
 164:	ldur	x8, [x29, #-32]
 168:	ldur	x9, [x29, #-24]
 16c:	ldr	x10, [sp, #80]
 170:	ldr	x11, [sp, #88]
 174:	eor	x9, x9, x11
 178:	eor	x8, x8, x10
 17c:	subs	x8, x8, x10
 180:	sbcs	x9, x9, x11
 184:	str	x8, [sp, #64]
 188:	str	x9, [sp, #72]
 18c:	ldur	x8, [x29, #-40]
 190:	asr	x8, x8, #63
 194:	str	x8, [sp, #56]
 198:	str	x8, [sp, #48]
 19c:	ldur	x8, [x29, #-48]
 1a0:	ldur	x9, [x29, #-40]
 1a4:	ldr	x10, [sp, #48]
 1a8:	ldr	x11, [sp, #56]
 1ac:	eor	x9, x9, x11
 1b0:	eor	x8, x8, x10
 1b4:	subs	x8, x8, x10
 1b8:	sbcs	x9, x9, x11
 1bc:	str	x8, [sp, #32]
 1c0:	str	x9, [sp, #40]
 1c4:	ldr	x8, [sp, #72]
 1c8:	ldr	x9, [sp, #64]
 1cc:	subs	x9, x9, #0x2
 1d0:	cset	w12, cc  // cc = lo, ul, last
 1d4:	subs	x8, x8, #0x0
 1d8:	cset	w13, lt  // lt = tstop
 1dc:	csel	w12, w12, w13, eq  // eq = none
 1e0:	tbnz	w12, #0, 20c <__muloti4+0x20c>
 1e4:	b	1e8 <__muloti4+0x1e8>
 1e8:	ldr	x8, [sp, #40]
 1ec:	ldr	x9, [sp, #32]
 1f0:	subs	x9, x9, #0x1
 1f4:	cset	w10, hi  // hi = pmore
 1f8:	subs	x8, x8, #0x0
 1fc:	cset	w11, gt
 200:	csel	w10, w10, w11, eq  // eq = none
 204:	tbnz	w10, #0, 220 <__muloti4+0x220>
 208:	b	20c <__muloti4+0x20c>
 20c:	ldr	x8, [sp, #96]
 210:	ldr	x9, [sp, #104]
 214:	stur	x9, [x29, #-8]
 218:	stur	x8, [x29, #-16]
 21c:	b	31c <__muloti4+0x31c>
 220:	ldr	x8, [sp, #80]
 224:	ldr	x9, [sp, #88]
 228:	ldr	x10, [sp, #48]
 22c:	ldr	x11, [sp, #56]
 230:	eor	x9, x9, x11
 234:	eor	x8, x8, x10
 238:	orr	x8, x8, x9
 23c:	cbnz	x8, 2a0 <__muloti4+0x2a0>
 240:	b	244 <__muloti4+0x244>
 244:	ldr	x8, [sp, #72]
 248:	ldr	x9, [sp, #64]
 24c:	ldr	x2, [sp, #32]
 250:	ldr	x3, [sp, #40]
 254:	mov	x0, #0xffffffffffffffff    	// #-1
 258:	mov	x1, #0x7fffffffffffffff    	// #9223372036854775807
 25c:	str	x8, [sp, #24]
 260:	str	x9, [sp, #16]
 264:	bl	0 <__divti3>
 268:	ldr	x8, [sp, #16]
 26c:	subs	x8, x8, x0
 270:	cset	w10, ls  // ls = plast
 274:	ldr	x9, [sp, #24]
 278:	subs	x9, x9, x1
 27c:	cset	w11, le
 280:	csel	w10, w10, w11, eq  // eq = none
 284:	tbnz	w10, #0, 29c <__muloti4+0x29c>
 288:	b	28c <__muloti4+0x28c>
 28c:	ldur	x8, [x29, #-56]
 290:	mov	w9, #0x1                   	// #1
 294:	str	w9, [x8]
 298:	b	29c <__muloti4+0x29c>
 29c:	b	308 <__muloti4+0x308>
 2a0:	ldr	x8, [sp, #72]
 2a4:	ldr	x9, [sp, #64]
 2a8:	ldr	x10, [sp, #40]
 2ac:	ldr	x11, [sp, #32]
 2b0:	mov	x12, xzr
 2b4:	subs	x2, x12, x11
 2b8:	sbcs	x3, x12, x10
 2bc:	mov	x1, #0x8000000000000000    	// #-9223372036854775808
 2c0:	mov	x0, x12
 2c4:	str	x8, [sp, #8]
 2c8:	str	x9, [sp]
 2cc:	bl	0 <__divti3>
 2d0:	ldr	x8, [sp]
 2d4:	subs	x8, x8, x0
 2d8:	cset	w13, ls  // ls = plast
 2dc:	ldr	x9, [sp, #8]
 2e0:	subs	x9, x9, x1
 2e4:	cset	w14, le
 2e8:	csel	w13, w13, w14, eq  // eq = none
 2ec:	tbnz	w13, #0, 304 <__muloti4+0x304>
 2f0:	b	2f4 <__muloti4+0x2f4>
 2f4:	ldur	x8, [x29, #-56]
 2f8:	mov	w9, #0x1                   	// #1
 2fc:	str	w9, [x8]
 300:	b	304 <__muloti4+0x304>
 304:	b	308 <__muloti4+0x308>
 308:	ldr	x8, [sp, #96]
 30c:	ldr	x9, [sp, #104]
 310:	stur	x9, [x29, #-8]
 314:	stur	x8, [x29, #-16]
 318:	b	31c <__muloti4+0x31c>
 31c:	ldur	x0, [x29, #-16]
 320:	ldur	x1, [x29, #-8]
 324:	ldp	x29, x30, [sp, #208]
 328:	add	sp, sp, #0xe0
 32c:	ret

mulsc3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulsc3>:
   0:	sub	sp, sp, #0x40
   4:	str	s0, [sp, #52]
   8:	str	s1, [sp, #48]
   c:	str	s2, [sp, #44]
  10:	str	s3, [sp, #40]
  14:	ldr	s0, [sp, #52]
  18:	ldr	s1, [sp, #44]
  1c:	fmul	s0, s0, s1
  20:	str	s0, [sp, #36]
  24:	ldr	s0, [sp, #48]
  28:	ldr	s1, [sp, #40]
  2c:	fmul	s0, s0, s1
  30:	str	s0, [sp, #32]
  34:	ldr	s0, [sp, #52]
  38:	ldr	s1, [sp, #40]
  3c:	fmul	s0, s0, s1
  40:	str	s0, [sp, #28]
  44:	ldr	s0, [sp, #48]
  48:	ldr	s1, [sp, #44]
  4c:	fmul	s0, s0, s1
  50:	str	s0, [sp, #24]
  54:	ldr	s0, [sp, #36]
  58:	ldr	s1, [sp, #32]
  5c:	fsub	s0, s0, s1
  60:	str	s0, [sp, #16]
  64:	ldr	s0, [sp, #28]
  68:	ldr	s1, [sp, #24]
  6c:	fadd	s0, s0, s1
  70:	str	s0, [sp, #20]
  74:	ldr	s0, [sp, #16]
  78:	fcmp	s0, s0
  7c:	b.vc	438 <__mulsc3+0x438>
  80:	b	84 <__mulsc3+0x84>
  84:	ldr	s0, [sp, #20]
  88:	fcmp	s0, s0
  8c:	b.vc	438 <__mulsc3+0x438>
  90:	b	94 <__mulsc3+0x94>
  94:	mov	w8, wzr
  98:	str	w8, [sp, #12]
  9c:	ldr	s0, [sp, #52]
  a0:	fabs	s0, s0
  a4:	mov	w8, #0x7f800000            	// #2139095040
  a8:	fmov	s1, w8
  ac:	fcmp	s0, s1
  b0:	b.eq	d4 <__mulsc3+0xd4>  // b.none
  b4:	b	b8 <__mulsc3+0xb8>
  b8:	ldr	s0, [sp, #48]
  bc:	fabs	s0, s0
  c0:	mov	w8, #0x7f800000            	// #2139095040
  c4:	fmov	s1, w8
  c8:	fcmp	s0, s1
  cc:	b.ne	194 <__mulsc3+0x194>  // b.any
  d0:	b	d4 <__mulsc3+0xd4>
  d4:	ldr	s0, [sp, #52]
  d8:	fabs	s1, s0
  dc:	mov	w8, #0x7f800000            	// #2139095040
  e0:	fmov	s2, w8
  e4:	fcmp	s1, s2
  e8:	fmov	s1, wzr
  ec:	fmov	s3, #1.000000000000000000e+00
  f0:	fcsel	s4, s3, s1, eq  // eq = none
  f4:	mov	v5.16b, v0.16b
  f8:	mov	v6.16b, v4.16b
  fc:	movi	v7.4s, #0x80, lsl #24
 100:	bit	v6.16b, v5.16b, v7.16b
 104:	str	s6, [sp, #52]
 108:	ldr	s0, [sp, #48]
 10c:	fabs	s4, s0
 110:	fcmp	s4, s2
 114:	fcsel	s1, s3, s1, eq  // eq = none
 118:	mov	v5.16b, v0.16b
 11c:	mov	v16.16b, v1.16b
 120:	bit	v16.16b, v5.16b, v7.16b
 124:	str	s16, [sp, #48]
 128:	ldr	s0, [sp, #44]
 12c:	fcmp	s0, s0
 130:	b.vc	158 <__mulsc3+0x158>
 134:	b	138 <__mulsc3+0x138>
 138:	ldr	s0, [sp, #44]
 13c:	mov	v1.16b, v0.16b
 140:	fmov	s0, wzr
 144:	mov	v2.16b, v0.16b
 148:	movi	v3.4s, #0x80, lsl #24
 14c:	bit	v2.16b, v1.16b, v3.16b
 150:	str	s2, [sp, #44]
 154:	b	158 <__mulsc3+0x158>
 158:	ldr	s0, [sp, #40]
 15c:	fcmp	s0, s0
 160:	b.vc	188 <__mulsc3+0x188>
 164:	b	168 <__mulsc3+0x168>
 168:	ldr	s0, [sp, #40]
 16c:	mov	v1.16b, v0.16b
 170:	fmov	s0, wzr
 174:	mov	v2.16b, v0.16b
 178:	movi	v3.4s, #0x80, lsl #24
 17c:	bit	v2.16b, v1.16b, v3.16b
 180:	str	s2, [sp, #40]
 184:	b	188 <__mulsc3+0x188>
 188:	mov	w8, #0x1                   	// #1
 18c:	str	w8, [sp, #12]
 190:	b	194 <__mulsc3+0x194>
 194:	ldr	s0, [sp, #44]
 198:	fabs	s0, s0
 19c:	mov	w8, #0x7f800000            	// #2139095040
 1a0:	fmov	s1, w8
 1a4:	fcmp	s0, s1
 1a8:	b.eq	1cc <__mulsc3+0x1cc>  // b.none
 1ac:	b	1b0 <__mulsc3+0x1b0>
 1b0:	ldr	s0, [sp, #40]
 1b4:	fabs	s0, s0
 1b8:	mov	w8, #0x7f800000            	// #2139095040
 1bc:	fmov	s1, w8
 1c0:	fcmp	s0, s1
 1c4:	b.ne	28c <__mulsc3+0x28c>  // b.any
 1c8:	b	1cc <__mulsc3+0x1cc>
 1cc:	ldr	s0, [sp, #44]
 1d0:	fabs	s1, s0
 1d4:	mov	w8, #0x7f800000            	// #2139095040
 1d8:	fmov	s2, w8
 1dc:	fcmp	s1, s2
 1e0:	fmov	s1, wzr
 1e4:	fmov	s3, #1.000000000000000000e+00
 1e8:	fcsel	s4, s3, s1, eq  // eq = none
 1ec:	mov	v5.16b, v0.16b
 1f0:	mov	v6.16b, v4.16b
 1f4:	movi	v7.4s, #0x80, lsl #24
 1f8:	bit	v6.16b, v5.16b, v7.16b
 1fc:	str	s6, [sp, #44]
 200:	ldr	s0, [sp, #40]
 204:	fabs	s4, s0
 208:	fcmp	s4, s2
 20c:	fcsel	s1, s3, s1, eq  // eq = none
 210:	mov	v5.16b, v0.16b
 214:	mov	v16.16b, v1.16b
 218:	bit	v16.16b, v5.16b, v7.16b
 21c:	str	s16, [sp, #40]
 220:	ldr	s0, [sp, #52]
 224:	fcmp	s0, s0
 228:	b.vc	250 <__mulsc3+0x250>
 22c:	b	230 <__mulsc3+0x230>
 230:	ldr	s0, [sp, #52]
 234:	mov	v1.16b, v0.16b
 238:	fmov	s0, wzr
 23c:	mov	v2.16b, v0.16b
 240:	movi	v3.4s, #0x80, lsl #24
 244:	bit	v2.16b, v1.16b, v3.16b
 248:	str	s2, [sp, #52]
 24c:	b	250 <__mulsc3+0x250>
 250:	ldr	s0, [sp, #48]
 254:	fcmp	s0, s0
 258:	b.vc	280 <__mulsc3+0x280>
 25c:	b	260 <__mulsc3+0x260>
 260:	ldr	s0, [sp, #48]
 264:	mov	v1.16b, v0.16b
 268:	fmov	s0, wzr
 26c:	mov	v2.16b, v0.16b
 270:	movi	v3.4s, #0x80, lsl #24
 274:	bit	v2.16b, v1.16b, v3.16b
 278:	str	s2, [sp, #48]
 27c:	b	280 <__mulsc3+0x280>
 280:	mov	w8, #0x1                   	// #1
 284:	str	w8, [sp, #12]
 288:	b	28c <__mulsc3+0x28c>
 28c:	ldr	w8, [sp, #12]
 290:	cbnz	w8, 3d4 <__mulsc3+0x3d4>
 294:	b	298 <__mulsc3+0x298>
 298:	ldr	s0, [sp, #36]
 29c:	fabs	s0, s0
 2a0:	mov	w8, #0x7f800000            	// #2139095040
 2a4:	fmov	s1, w8
 2a8:	fcmp	s0, s1
 2ac:	b.eq	308 <__mulsc3+0x308>  // b.none
 2b0:	b	2b4 <__mulsc3+0x2b4>
 2b4:	ldr	s0, [sp, #32]
 2b8:	fabs	s0, s0
 2bc:	mov	w8, #0x7f800000            	// #2139095040
 2c0:	fmov	s1, w8
 2c4:	fcmp	s0, s1
 2c8:	b.eq	308 <__mulsc3+0x308>  // b.none
 2cc:	b	2d0 <__mulsc3+0x2d0>
 2d0:	ldr	s0, [sp, #28]
 2d4:	fabs	s0, s0
 2d8:	mov	w8, #0x7f800000            	// #2139095040
 2dc:	fmov	s1, w8
 2e0:	fcmp	s0, s1
 2e4:	b.eq	308 <__mulsc3+0x308>  // b.none
 2e8:	b	2ec <__mulsc3+0x2ec>
 2ec:	ldr	s0, [sp, #24]
 2f0:	fabs	s0, s0
 2f4:	mov	w8, #0x7f800000            	// #2139095040
 2f8:	fmov	s1, w8
 2fc:	fcmp	s0, s1
 300:	b.ne	3d4 <__mulsc3+0x3d4>  // b.any
 304:	b	308 <__mulsc3+0x308>
 308:	ldr	s0, [sp, #52]
 30c:	fcmp	s0, s0
 310:	b.vc	338 <__mulsc3+0x338>
 314:	b	318 <__mulsc3+0x318>
 318:	ldr	s0, [sp, #52]
 31c:	mov	v1.16b, v0.16b
 320:	fmov	s0, wzr
 324:	mov	v2.16b, v0.16b
 328:	movi	v3.4s, #0x80, lsl #24
 32c:	bit	v2.16b, v1.16b, v3.16b
 330:	str	s2, [sp, #52]
 334:	b	338 <__mulsc3+0x338>
 338:	ldr	s0, [sp, #48]
 33c:	fcmp	s0, s0
 340:	b.vc	368 <__mulsc3+0x368>
 344:	b	348 <__mulsc3+0x348>
 348:	ldr	s0, [sp, #48]
 34c:	mov	v1.16b, v0.16b
 350:	fmov	s0, wzr
 354:	mov	v2.16b, v0.16b
 358:	movi	v3.4s, #0x80, lsl #24
 35c:	bit	v2.16b, v1.16b, v3.16b
 360:	str	s2, [sp, #48]
 364:	b	368 <__mulsc3+0x368>
 368:	ldr	s0, [sp, #44]
 36c:	fcmp	s0, s0
 370:	b.vc	398 <__mulsc3+0x398>
 374:	b	378 <__mulsc3+0x378>
 378:	ldr	s0, [sp, #44]
 37c:	mov	v1.16b, v0.16b
 380:	fmov	s0, wzr
 384:	mov	v2.16b, v0.16b
 388:	movi	v3.4s, #0x80, lsl #24
 38c:	bit	v2.16b, v1.16b, v3.16b
 390:	str	s2, [sp, #44]
 394:	b	398 <__mulsc3+0x398>
 398:	ldr	s0, [sp, #40]
 39c:	fcmp	s0, s0
 3a0:	b.vc	3c8 <__mulsc3+0x3c8>
 3a4:	b	3a8 <__mulsc3+0x3a8>
 3a8:	ldr	s0, [sp, #40]
 3ac:	mov	v1.16b, v0.16b
 3b0:	fmov	s0, wzr
 3b4:	mov	v2.16b, v0.16b
 3b8:	movi	v3.4s, #0x80, lsl #24
 3bc:	bit	v2.16b, v1.16b, v3.16b
 3c0:	str	s2, [sp, #40]
 3c4:	b	3c8 <__mulsc3+0x3c8>
 3c8:	mov	w8, #0x1                   	// #1
 3cc:	str	w8, [sp, #12]
 3d0:	b	3d4 <__mulsc3+0x3d4>
 3d4:	ldr	w8, [sp, #12]
 3d8:	cbz	w8, 434 <__mulsc3+0x434>
 3dc:	b	3e0 <__mulsc3+0x3e0>
 3e0:	ldr	s0, [sp, #52]
 3e4:	ldr	s1, [sp, #44]
 3e8:	fmul	s0, s0, s1
 3ec:	ldr	s1, [sp, #48]
 3f0:	ldr	s2, [sp, #40]
 3f4:	fmul	s1, s1, s2
 3f8:	fsub	s0, s0, s1
 3fc:	mov	w8, #0x7f800000            	// #2139095040
 400:	fmov	s1, w8
 404:	fmul	s0, s0, s1
 408:	str	s0, [sp, #16]
 40c:	ldr	s0, [sp, #52]
 410:	ldr	s2, [sp, #40]
 414:	fmul	s0, s0, s2
 418:	ldr	s2, [sp, #48]
 41c:	ldr	s3, [sp, #44]
 420:	fmul	s2, s2, s3
 424:	fadd	s0, s0, s2
 428:	fmul	s0, s0, s1
 42c:	str	s0, [sp, #20]
 430:	b	434 <__mulsc3+0x434>
 434:	b	438 <__mulsc3+0x438>
 438:	ldr	s0, [sp, #16]
 43c:	ldr	s1, [sp, #20]
 440:	str	s0, [sp, #56]
 444:	str	s1, [sp, #60]
 448:	ldr	s0, [sp, #56]
 44c:	ldr	s1, [sp, #60]
 450:	add	sp, sp, #0x40
 454:	ret

mulsf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulsf3>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	str	s1, [sp, #8]
  14:	ldur	s0, [x29, #-4]
  18:	ldr	s1, [sp, #8]
  1c:	bl	2c <__mulXf3__>
  20:	ldp	x29, x30, [sp, #16]
  24:	add	sp, sp, #0x20
  28:	ret

000000000000002c <__mulXf3__>:
  2c:	sub	sp, sp, #0x60
  30:	stp	x29, x30, [sp, #80]
  34:	add	x29, sp, #0x50
  38:	stur	s0, [x29, #-8]
  3c:	stur	s1, [x29, #-12]
  40:	ldur	s0, [x29, #-8]
  44:	bl	3b4 <toRep>
  48:	mov	x8, #0x17                  	// #23
  4c:	lsr	w9, w0, #23
  50:	and	w9, w9, #0xff
  54:	stur	w9, [x29, #-16]
  58:	ldur	s0, [x29, #-12]
  5c:	str	x8, [sp, #8]
  60:	bl	3b4 <toRep>
  64:	ldr	x8, [sp, #8]
  68:	lsr	w8, w0, w8
  6c:	and	w8, w8, #0xff
  70:	stur	w8, [x29, #-20]
  74:	ldur	s0, [x29, #-8]
  78:	bl	3b4 <toRep>
  7c:	ldur	s0, [x29, #-12]
  80:	str	w0, [sp, #4]
  84:	bl	3b4 <toRep>
  88:	ldr	w8, [sp, #4]
  8c:	eor	w9, w8, w0
  90:	and	w9, w9, #0x80000000
  94:	stur	w9, [x29, #-24]
  98:	ldur	s0, [x29, #-8]
  9c:	bl	3b4 <toRep>
  a0:	and	w8, w0, #0x7fffff
  a4:	stur	w8, [x29, #-28]
  a8:	ldur	s0, [x29, #-12]
  ac:	bl	3b4 <toRep>
  b0:	and	w8, w0, #0x7fffff
  b4:	stur	w8, [x29, #-32]
  b8:	stur	wzr, [x29, #-36]
  bc:	ldur	w8, [x29, #-16]
  c0:	subs	w8, w8, #0x1
  c4:	cmp	w8, #0xfe
  c8:	b.cs	dc <__mulXf3__+0xb0>  // b.hs, b.nlast
  cc:	ldur	w8, [x29, #-20]
  d0:	subs	w8, w8, #0x1
  d4:	cmp	w8, #0xfe
  d8:	b.cc	23c <__mulXf3__+0x210>  // b.lo, b.ul, b.last
  dc:	ldur	s0, [x29, #-8]
  e0:	bl	3b4 <toRep>
  e4:	and	w8, w0, #0x7fffffff
  e8:	str	w8, [sp, #40]
  ec:	ldur	s0, [x29, #-12]
  f0:	bl	3b4 <toRep>
  f4:	and	w8, w0, #0x7fffffff
  f8:	str	w8, [sp, #36]
  fc:	ldr	w8, [sp, #40]
 100:	mov	w9, #0x7f800000            	// #2139095040
 104:	cmp	w8, w9
 108:	b.ls	124 <__mulXf3__+0xf8>  // b.plast
 10c:	ldur	s0, [x29, #-8]
 110:	bl	3b4 <toRep>
 114:	orr	w0, w0, #0x400000
 118:	bl	3d0 <fromRep>
 11c:	stur	s0, [x29, #-4]
 120:	b	3a4 <__mulXf3__+0x378>
 124:	ldr	w8, [sp, #36]
 128:	mov	w9, #0x7f800000            	// #2139095040
 12c:	cmp	w8, w9
 130:	b.ls	14c <__mulXf3__+0x120>  // b.plast
 134:	ldur	s0, [x29, #-12]
 138:	bl	3b4 <toRep>
 13c:	orr	w0, w0, #0x400000
 140:	bl	3d0 <fromRep>
 144:	stur	s0, [x29, #-4]
 148:	b	3a4 <__mulXf3__+0x378>
 14c:	ldr	w8, [sp, #40]
 150:	mov	w9, #0x7f800000            	// #2139095040
 154:	cmp	w8, w9
 158:	b.ne	18c <__mulXf3__+0x160>  // b.any
 15c:	ldr	w8, [sp, #36]
 160:	cbz	w8, 17c <__mulXf3__+0x150>
 164:	ldr	w8, [sp, #40]
 168:	ldur	w9, [x29, #-24]
 16c:	orr	w0, w8, w9
 170:	bl	3d0 <fromRep>
 174:	stur	s0, [x29, #-4]
 178:	b	3a4 <__mulXf3__+0x378>
 17c:	mov	w0, #0x7fc00000            	// #2143289344
 180:	bl	3d0 <fromRep>
 184:	stur	s0, [x29, #-4]
 188:	b	3a4 <__mulXf3__+0x378>
 18c:	ldr	w8, [sp, #36]
 190:	mov	w9, #0x7f800000            	// #2139095040
 194:	cmp	w8, w9
 198:	b.ne	1cc <__mulXf3__+0x1a0>  // b.any
 19c:	ldr	w8, [sp, #40]
 1a0:	cbz	w8, 1bc <__mulXf3__+0x190>
 1a4:	ldr	w8, [sp, #36]
 1a8:	ldur	w9, [x29, #-24]
 1ac:	orr	w0, w8, w9
 1b0:	bl	3d0 <fromRep>
 1b4:	stur	s0, [x29, #-4]
 1b8:	b	3a4 <__mulXf3__+0x378>
 1bc:	mov	w0, #0x7fc00000            	// #2143289344
 1c0:	bl	3d0 <fromRep>
 1c4:	stur	s0, [x29, #-4]
 1c8:	b	3a4 <__mulXf3__+0x378>
 1cc:	ldr	w8, [sp, #40]
 1d0:	cbnz	w8, 1e4 <__mulXf3__+0x1b8>
 1d4:	ldur	w0, [x29, #-24]
 1d8:	bl	3d0 <fromRep>
 1dc:	stur	s0, [x29, #-4]
 1e0:	b	3a4 <__mulXf3__+0x378>
 1e4:	ldr	w8, [sp, #36]
 1e8:	cbnz	w8, 1fc <__mulXf3__+0x1d0>
 1ec:	ldur	w0, [x29, #-24]
 1f0:	bl	3d0 <fromRep>
 1f4:	stur	s0, [x29, #-4]
 1f8:	b	3a4 <__mulXf3__+0x378>
 1fc:	ldr	w8, [sp, #40]
 200:	cmp	w8, #0x800, lsl #12
 204:	b.cs	21c <__mulXf3__+0x1f0>  // b.hs, b.nlast
 208:	sub	x0, x29, #0x1c
 20c:	bl	3ec <normalize>
 210:	ldur	w8, [x29, #-36]
 214:	add	w8, w8, w0
 218:	stur	w8, [x29, #-36]
 21c:	ldr	w8, [sp, #36]
 220:	cmp	w8, #0x800, lsl #12
 224:	b.cs	23c <__mulXf3__+0x210>  // b.hs, b.nlast
 228:	sub	x0, x29, #0x20
 22c:	bl	3ec <normalize>
 230:	ldur	w8, [x29, #-36]
 234:	add	w8, w8, w0
 238:	stur	w8, [x29, #-36]
 23c:	ldur	w8, [x29, #-28]
 240:	orr	w8, w8, #0x800000
 244:	stur	w8, [x29, #-28]
 248:	ldur	w8, [x29, #-32]
 24c:	orr	w8, w8, #0x800000
 250:	stur	w8, [x29, #-32]
 254:	ldur	w0, [x29, #-28]
 258:	ldur	w8, [x29, #-32]
 25c:	lsl	w1, w8, #8
 260:	add	x2, sp, #0x20
 264:	add	x3, sp, #0x1c
 268:	bl	460 <wideMultiply>
 26c:	ldur	w8, [x29, #-16]
 270:	ldur	w9, [x29, #-20]
 274:	add	w8, w8, w9
 278:	subs	w8, w8, #0x7f
 27c:	ldur	w9, [x29, #-36]
 280:	add	w8, w8, w9
 284:	str	w8, [sp, #24]
 288:	ldr	w8, [sp, #32]
 28c:	and	w8, w8, #0x800000
 290:	cbz	w8, 2a4 <__mulXf3__+0x278>
 294:	ldr	w8, [sp, #24]
 298:	add	w8, w8, #0x1
 29c:	str	w8, [sp, #24]
 2a0:	b	2b4 <__mulXf3__+0x288>
 2a4:	add	x0, sp, #0x20
 2a8:	add	x1, sp, #0x1c
 2ac:	mov	w2, #0x1                   	// #1
 2b0:	bl	4b0 <wideLeftShift>
 2b4:	ldr	w8, [sp, #24]
 2b8:	cmp	w8, #0xff
 2bc:	b.lt	2d8 <__mulXf3__+0x2ac>  // b.tstop
 2c0:	ldur	w8, [x29, #-24]
 2c4:	mov	w9, #0x7f800000            	// #2139095040
 2c8:	orr	w0, w9, w8
 2cc:	bl	3d0 <fromRep>
 2d0:	stur	s0, [x29, #-4]
 2d4:	b	3a4 <__mulXf3__+0x378>
 2d8:	ldr	w8, [sp, #24]
 2dc:	cmp	w8, #0x0
 2e0:	cset	w8, gt
 2e4:	tbnz	w8, #0, 32c <__mulXf3__+0x300>
 2e8:	ldr	w8, [sp, #24]
 2ec:	mov	w9, #0x1                   	// #1
 2f0:	subs	w8, w9, w8
 2f4:	str	w8, [sp, #20]
 2f8:	ldr	w8, [sp, #20]
 2fc:	mov	w10, w8
 300:	cmp	x10, #0x20
 304:	b.cc	318 <__mulXf3__+0x2ec>  // b.lo, b.ul, b.last
 308:	ldur	w0, [x29, #-24]
 30c:	bl	3d0 <fromRep>
 310:	stur	s0, [x29, #-4]
 314:	b	3a4 <__mulXf3__+0x378>
 318:	ldr	w2, [sp, #20]
 31c:	add	x0, sp, #0x20
 320:	add	x1, sp, #0x1c
 324:	bl	514 <wideRightShiftWithSticky>
 328:	b	348 <__mulXf3__+0x31c>
 32c:	ldr	w8, [sp, #32]
 330:	and	w8, w8, #0x7fffff
 334:	str	w8, [sp, #32]
 338:	ldr	w8, [sp, #24]
 33c:	ldr	w9, [sp, #32]
 340:	orr	w8, w9, w8, lsl #23
 344:	str	w8, [sp, #32]
 348:	ldur	w8, [x29, #-24]
 34c:	ldr	w9, [sp, #32]
 350:	orr	w8, w9, w8
 354:	str	w8, [sp, #32]
 358:	ldr	w8, [sp, #28]
 35c:	mov	w9, #0x80000000            	// #-2147483648
 360:	cmp	w8, w9
 364:	b.ls	374 <__mulXf3__+0x348>  // b.plast
 368:	ldr	w8, [sp, #32]
 36c:	add	w8, w8, #0x1
 370:	str	w8, [sp, #32]
 374:	ldr	w8, [sp, #28]
 378:	mov	w9, #0x80000000            	// #-2147483648
 37c:	cmp	w8, w9
 380:	b.ne	398 <__mulXf3__+0x36c>  // b.any
 384:	ldr	w8, [sp, #32]
 388:	and	w8, w8, #0x1
 38c:	ldr	w9, [sp, #32]
 390:	add	w8, w9, w8
 394:	str	w8, [sp, #32]
 398:	ldr	w0, [sp, #32]
 39c:	bl	3d0 <fromRep>
 3a0:	stur	s0, [x29, #-4]
 3a4:	ldur	s0, [x29, #-4]
 3a8:	ldp	x29, x30, [sp, #80]
 3ac:	add	sp, sp, #0x60
 3b0:	ret

00000000000003b4 <toRep>:
 3b4:	sub	sp, sp, #0x10
 3b8:	str	s0, [sp, #12]
 3bc:	ldr	w8, [sp, #12]
 3c0:	str	w8, [sp, #8]
 3c4:	ldr	w0, [sp, #8]
 3c8:	add	sp, sp, #0x10
 3cc:	ret

00000000000003d0 <fromRep>:
 3d0:	sub	sp, sp, #0x10
 3d4:	str	w0, [sp, #12]
 3d8:	ldr	w8, [sp, #12]
 3dc:	str	w8, [sp, #8]
 3e0:	ldr	s0, [sp, #8]
 3e4:	add	sp, sp, #0x10
 3e8:	ret

00000000000003ec <normalize>:
 3ec:	sub	sp, sp, #0x30
 3f0:	stp	x29, x30, [sp, #32]
 3f4:	add	x29, sp, #0x20
 3f8:	mov	w8, #0x800000              	// #8388608
 3fc:	mov	w9, #0x1                   	// #1
 400:	stur	x0, [x29, #-8]
 404:	ldur	x10, [x29, #-8]
 408:	ldr	w0, [x10]
 40c:	str	w8, [sp, #16]
 410:	str	w9, [sp, #12]
 414:	bl	68c <rep_clz>
 418:	ldr	w8, [sp, #16]
 41c:	str	w0, [sp, #8]
 420:	mov	w0, w8
 424:	bl	68c <rep_clz>
 428:	ldr	w8, [sp, #8]
 42c:	subs	w9, w8, w0
 430:	stur	w9, [x29, #-12]
 434:	ldur	w9, [x29, #-12]
 438:	ldur	x10, [x29, #-8]
 43c:	ldr	w11, [x10]
 440:	lsl	w9, w11, w9
 444:	str	w9, [x10]
 448:	ldur	w9, [x29, #-12]
 44c:	ldr	w11, [sp, #12]
 450:	subs	w0, w11, w9
 454:	ldp	x29, x30, [sp, #32]
 458:	add	sp, sp, #0x30
 45c:	ret

0000000000000460 <wideMultiply>:
 460:	sub	sp, sp, #0x20
 464:	str	w0, [sp, #28]
 468:	str	w1, [sp, #24]
 46c:	str	x2, [sp, #16]
 470:	str	x3, [sp, #8]
 474:	ldr	w8, [sp, #28]
 478:	mov	w9, w8
 47c:	ldr	w8, [sp, #24]
 480:	mov	w10, w8
 484:	mul	x9, x9, x10
 488:	str	x9, [sp]
 48c:	ldr	x9, [sp]
 490:	lsr	x9, x9, #32
 494:	ldr	x10, [sp, #16]
 498:	str	w9, [x10]
 49c:	ldr	x10, [sp]
 4a0:	ldr	x11, [sp, #8]
 4a4:	str	w10, [x11]
 4a8:	add	sp, sp, #0x20
 4ac:	ret

00000000000004b0 <wideLeftShift>:
 4b0:	sub	sp, sp, #0x20
 4b4:	mov	x8, #0x20                  	// #32
 4b8:	str	x0, [sp, #24]
 4bc:	str	x1, [sp, #16]
 4c0:	str	w2, [sp, #12]
 4c4:	ldr	x9, [sp, #24]
 4c8:	ldr	w10, [x9]
 4cc:	ldr	w11, [sp, #12]
 4d0:	lsl	w10, w10, w11
 4d4:	ldr	x9, [sp, #16]
 4d8:	ldr	w11, [x9]
 4dc:	ldrsw	x9, [sp, #12]
 4e0:	subs	x8, x8, x9
 4e4:	lsr	w8, w11, w8
 4e8:	orr	w8, w10, w8
 4ec:	ldr	x9, [sp, #24]
 4f0:	str	w8, [x9]
 4f4:	ldr	x9, [sp, #16]
 4f8:	ldr	w8, [x9]
 4fc:	ldr	w10, [sp, #12]
 500:	lsl	w8, w8, w10
 504:	ldr	x9, [sp, #16]
 508:	str	w8, [x9]
 50c:	add	sp, sp, #0x20
 510:	ret

0000000000000514 <wideRightShiftWithSticky>:
 514:	sub	sp, sp, #0x20
 518:	str	x0, [sp, #24]
 51c:	str	x1, [sp, #16]
 520:	str	w2, [sp, #12]
 524:	ldr	w8, [sp, #12]
 528:	mov	w9, w8
 52c:	cmp	x9, #0x20
 530:	b.cs	5c0 <wideRightShiftWithSticky+0xac>  // b.hs, b.nlast
 534:	ldr	x8, [sp, #16]
 538:	ldr	w9, [x8]
 53c:	ldr	w10, [sp, #12]
 540:	mov	w8, w10
 544:	mov	x11, #0x20                  	// #32
 548:	subs	x8, x11, x8
 54c:	lsl	w8, w9, w8
 550:	cmp	w8, #0x0
 554:	cset	w8, ne  // ne = any
 558:	mov	w9, #0x1                   	// #1
 55c:	and	w8, w8, w9
 560:	strb	w8, [sp, #11]
 564:	ldr	x12, [sp, #24]
 568:	ldr	w8, [x12]
 56c:	ldr	w9, [sp, #12]
 570:	mov	w12, w9
 574:	subs	x11, x11, x12
 578:	lsl	w8, w8, w11
 57c:	ldr	x12, [sp, #16]
 580:	ldr	w9, [x12]
 584:	ldr	w10, [sp, #12]
 588:	lsr	w9, w9, w10
 58c:	orr	w8, w8, w9
 590:	ldrb	w9, [sp, #11]
 594:	and	w9, w9, #0x1
 598:	orr	w8, w8, w9
 59c:	ldr	x12, [sp, #16]
 5a0:	str	w8, [x12]
 5a4:	ldr	x12, [sp, #24]
 5a8:	ldr	w8, [x12]
 5ac:	ldr	w9, [sp, #12]
 5b0:	lsr	w8, w8, w9
 5b4:	ldr	x12, [sp, #24]
 5b8:	str	w8, [x12]
 5bc:	b	684 <wideRightShiftWithSticky+0x170>
 5c0:	ldr	w8, [sp, #12]
 5c4:	mov	w9, w8
 5c8:	cmp	x9, #0x40
 5cc:	b.cs	644 <wideRightShiftWithSticky+0x130>  // b.hs, b.nlast
 5d0:	ldr	x8, [sp, #24]
 5d4:	ldr	w9, [x8]
 5d8:	ldr	w10, [sp, #12]
 5dc:	mov	w8, w10
 5e0:	mov	x11, #0x40                  	// #64
 5e4:	subs	x8, x11, x8
 5e8:	lsl	w8, w9, w8
 5ec:	ldr	x11, [sp, #16]
 5f0:	ldr	w9, [x11]
 5f4:	orr	w8, w8, w9
 5f8:	cmp	w8, #0x0
 5fc:	cset	w8, ne  // ne = any
 600:	mov	w9, #0x1                   	// #1
 604:	and	w8, w8, w9
 608:	strb	w8, [sp, #10]
 60c:	ldr	x11, [sp, #24]
 610:	ldr	w8, [x11]
 614:	ldr	w9, [sp, #12]
 618:	mov	w11, w9
 61c:	subs	x11, x11, #0x20
 620:	lsr	w8, w8, w11
 624:	ldrb	w9, [sp, #10]
 628:	and	w9, w9, #0x1
 62c:	orr	w8, w8, w9
 630:	ldr	x12, [sp, #16]
 634:	str	w8, [x12]
 638:	ldr	x12, [sp, #24]
 63c:	str	wzr, [x12]
 640:	b	684 <wideRightShiftWithSticky+0x170>
 644:	ldr	x8, [sp, #24]
 648:	ldr	w9, [x8]
 64c:	ldr	x8, [sp, #16]
 650:	ldr	w10, [x8]
 654:	orr	w9, w9, w10
 658:	cmp	w9, #0x0
 65c:	cset	w9, ne  // ne = any
 660:	mov	w10, #0x1                   	// #1
 664:	and	w9, w9, w10
 668:	strb	w9, [sp, #9]
 66c:	ldrb	w9, [sp, #9]
 670:	and	w9, w9, #0x1
 674:	ldr	x8, [sp, #16]
 678:	str	w9, [x8]
 67c:	ldr	x8, [sp, #24]
 680:	str	wzr, [x8]
 684:	add	sp, sp, #0x20
 688:	ret

000000000000068c <rep_clz>:
 68c:	sub	sp, sp, #0x10
 690:	str	w0, [sp, #12]
 694:	ldr	w8, [sp, #12]
 698:	clz	w0, w8
 69c:	add	sp, sp, #0x10
 6a0:	ret

multi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__multi3>:
   0:	sub	sp, sp, #0x60
   4:	stp	x29, x30, [sp, #80]
   8:	add	x29, sp, #0x50
   c:	stur	x1, [x29, #-8]
  10:	stur	x0, [x29, #-16]
  14:	stur	x3, [x29, #-24]
  18:	stur	x2, [x29, #-32]
  1c:	ldur	x8, [x29, #-16]
  20:	ldur	x9, [x29, #-8]
  24:	str	x9, [sp, #40]
  28:	str	x8, [sp, #32]
  2c:	ldur	x8, [x29, #-32]
  30:	ldur	x9, [x29, #-24]
  34:	str	x9, [sp, #24]
  38:	str	x8, [sp, #16]
  3c:	ldr	x0, [sp, #32]
  40:	ldr	x1, [sp, #16]
  44:	bl	8c <__mulddi3>
  48:	str	x1, [sp, #8]
  4c:	str	x0, [sp]
  50:	ldr	x8, [sp, #40]
  54:	ldr	x9, [sp, #16]
  58:	mul	x8, x8, x9
  5c:	ldr	x9, [sp, #32]
  60:	ldr	x10, [sp, #24]
  64:	mul	x9, x9, x10
  68:	add	x8, x8, x9
  6c:	ldr	x9, [sp, #8]
  70:	add	x8, x9, x8
  74:	str	x8, [sp, #8]
  78:	ldr	x0, [sp]
  7c:	ldr	x1, [sp, #8]
  80:	ldp	x29, x30, [sp, #80]
  84:	add	sp, sp, #0x60
  88:	ret

000000000000008c <__mulddi3>:
  8c:	sub	sp, sp, #0x40
  90:	str	x0, [sp, #56]
  94:	str	x1, [sp, #48]
  98:	mov	w8, #0x20                  	// #32
  9c:	str	w8, [sp, #28]
  a0:	mov	w8, #0xffffffff            	// #-1
  a4:	mov	w9, w8
  a8:	str	x9, [sp, #16]
  ac:	ldr	w8, [sp, #56]
  b0:	mov	w9, w8
  b4:	ldr	w8, [sp, #48]
  b8:	mov	w10, w8
  bc:	mul	x9, x9, x10
  c0:	str	x9, [sp, #32]
  c4:	ldr	w8, [sp, #36]
  c8:	mov	w9, w8
  cc:	str	x9, [sp, #8]
  d0:	ldr	w8, [sp, #32]
  d4:	mov	w9, w8
  d8:	str	x9, [sp, #32]
  dc:	ldr	w8, [sp, #60]
  e0:	mov	w9, w8
  e4:	ldr	w8, [sp, #48]
  e8:	mov	w10, w8
  ec:	mul	x9, x9, x10
  f0:	ldr	x10, [sp, #8]
  f4:	add	x9, x10, x9
  f8:	str	x9, [sp, #8]
  fc:	ldr	x9, [sp, #8]
 100:	ldr	x10, [sp, #32]
 104:	add	x9, x10, x9, lsl #32
 108:	str	x9, [sp, #32]
 10c:	ldr	w8, [sp, #12]
 110:	mov	w9, w8
 114:	str	x9, [sp, #40]
 118:	ldr	w8, [sp, #36]
 11c:	mov	w9, w8
 120:	str	x9, [sp, #8]
 124:	ldr	w8, [sp, #32]
 128:	mov	w9, w8
 12c:	str	x9, [sp, #32]
 130:	ldr	w8, [sp, #52]
 134:	mov	w9, w8
 138:	ldr	w8, [sp, #56]
 13c:	mov	w10, w8
 140:	mul	x9, x9, x10
 144:	ldr	x10, [sp, #8]
 148:	add	x9, x10, x9
 14c:	str	x9, [sp, #8]
 150:	ldr	x9, [sp, #8]
 154:	ldr	x10, [sp, #32]
 158:	add	x9, x10, x9, lsl #32
 15c:	str	x9, [sp, #32]
 160:	ldr	w8, [sp, #12]
 164:	mov	w9, w8
 168:	ldr	x10, [sp, #40]
 16c:	add	x9, x10, x9
 170:	str	x9, [sp, #40]
 174:	ldr	w8, [sp, #60]
 178:	mov	w9, w8
 17c:	ldr	w8, [sp, #52]
 180:	mov	w10, w8
 184:	mul	x9, x9, x10
 188:	ldr	x10, [sp, #40]
 18c:	add	x9, x10, x9
 190:	str	x9, [sp, #40]
 194:	ldr	x0, [sp, #32]
 198:	ldr	x1, [sp, #40]
 19c:	add	sp, sp, #0x40
 1a0:	ret

multf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__multf3>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	str	q0, [sp, #16]
  10:	str	q1, [sp]
  14:	ldr	q0, [sp, #16]
  18:	ldr	q1, [sp]
  1c:	bl	2c <__mulXf3__>
  20:	ldp	x29, x30, [sp, #32]
  24:	add	sp, sp, #0x30
  28:	ret

000000000000002c <__mulXf3__>:
  2c:	sub	sp, sp, #0x120
  30:	stp	x29, x30, [sp, #256]
  34:	str	x28, [sp, #272]
  38:	add	x29, sp, #0x100
  3c:	sub	x8, x29, #0x30
  40:	str	q0, [x8, #16]
  44:	str	q1, [x8]
  48:	ldr	q0, [x8, #16]
  4c:	str	x8, [sp, #48]
  50:	bl	57c <toRep>
  54:	ubfx	x8, x1, #48, #15
  58:	stur	w8, [x29, #-52]
  5c:	ldr	x9, [sp, #48]
  60:	ldr	q0, [x9]
  64:	str	x0, [sp, #40]
  68:	bl	57c <toRep>
  6c:	ubfx	x9, x1, #48, #15
  70:	stur	w9, [x29, #-56]
  74:	ldr	x10, [sp, #48]
  78:	ldr	q0, [x10, #16]
  7c:	str	x0, [sp, #32]
  80:	bl	57c <toRep>
  84:	ldr	x10, [sp, #48]
  88:	ldr	q0, [x10]
  8c:	str	x0, [sp, #24]
  90:	str	x1, [sp, #16]
  94:	bl	57c <toRep>
  98:	ldr	x10, [sp, #16]
  9c:	eor	x11, x10, x1
  a0:	and	x11, x11, #0x8000000000000000
  a4:	mov	x12, xzr
  a8:	stur	x12, [x29, #-80]
  ac:	stur	x11, [x29, #-72]
  b0:	ldr	x11, [sp, #48]
  b4:	ldr	q0, [x11, #16]
  b8:	str	x0, [sp, #8]
  bc:	bl	57c <toRep>
  c0:	and	x10, x1, #0xffffffffffff
  c4:	stur	x0, [x29, #-96]
  c8:	stur	x10, [x29, #-88]
  cc:	ldr	x10, [sp, #48]
  d0:	ldr	q0, [x10]
  d4:	bl	57c <toRep>
  d8:	and	x10, x1, #0xffffffffffff
  dc:	stur	x0, [x29, #-112]
  e0:	stur	x10, [x29, #-104]
  e4:	mov	w8, wzr
  e8:	stur	w8, [x29, #-116]
  ec:	ldur	w8, [x29, #-52]
  f0:	subs	w8, w8, #0x1
  f4:	mov	w9, #0x7ffd                	// #32765
  f8:	subs	w8, w8, w9
  fc:	b.hi	11c <__mulXf3__+0xf0>  // b.pmore
 100:	b	104 <__mulXf3__+0xd8>
 104:	ldur	w8, [x29, #-56]
 108:	subs	w8, w8, #0x1
 10c:	mov	w9, #0x7ffe                	// #32766
 110:	subs	w8, w8, w9
 114:	b.cc	360 <__mulXf3__+0x334>  // b.lo, b.ul, b.last
 118:	b	11c <__mulXf3__+0xf0>
 11c:	ldr	x8, [sp, #48]
 120:	ldr	q0, [x8, #16]
 124:	bl	57c <toRep>
 128:	and	x8, x1, #0x7fffffffffffffff
 12c:	str	x0, [sp, #112]
 130:	str	x8, [sp, #120]
 134:	ldr	x8, [sp, #48]
 138:	ldr	q0, [x8]
 13c:	bl	57c <toRep>
 140:	and	x8, x1, #0x7fffffffffffffff
 144:	str	x0, [sp, #96]
 148:	str	x8, [sp, #104]
 14c:	ldr	x8, [sp, #120]
 150:	ldr	x9, [sp, #112]
 154:	subs	x9, x9, #0x0
 158:	cset	w10, eq  // eq = none
 15c:	mov	x11, #0x7fff000000000000    	// #9223090561878065152
 160:	subs	x8, x8, x11
 164:	cset	w12, cc  // cc = lo, ul, last
 168:	csel	w10, w10, w12, eq  // eq = none
 16c:	tbnz	w10, #0, 194 <__mulXf3__+0x168>
 170:	b	174 <__mulXf3__+0x148>
 174:	ldr	x8, [sp, #48]
 178:	ldr	q0, [x8, #16]
 17c:	bl	57c <toRep>
 180:	orr	x1, x1, #0x800000000000
 184:	bl	59c <fromRep>
 188:	ldr	x8, [sp, #48]
 18c:	str	q0, [x8, #32]
 190:	b	564 <__mulXf3__+0x538>
 194:	ldr	x8, [sp, #104]
 198:	ldr	x9, [sp, #96]
 19c:	subs	x9, x9, #0x0
 1a0:	cset	w10, eq  // eq = none
 1a4:	mov	x11, #0x7fff000000000000    	// #9223090561878065152
 1a8:	subs	x8, x8, x11
 1ac:	cset	w12, cc  // cc = lo, ul, last
 1b0:	csel	w10, w10, w12, eq  // eq = none
 1b4:	tbnz	w10, #0, 1dc <__mulXf3__+0x1b0>
 1b8:	b	1bc <__mulXf3__+0x190>
 1bc:	ldr	x8, [sp, #48]
 1c0:	ldr	q0, [x8]
 1c4:	bl	57c <toRep>
 1c8:	orr	x1, x1, #0x800000000000
 1cc:	bl	59c <fromRep>
 1d0:	ldr	x8, [sp, #48]
 1d4:	str	q0, [x8, #32]
 1d8:	b	564 <__mulXf3__+0x538>
 1dc:	ldr	x8, [sp, #112]
 1e0:	ldr	x9, [sp, #120]
 1e4:	eor	x9, x9, #0x7fff000000000000
 1e8:	orr	x8, x8, x9
 1ec:	cbnz	x8, 248 <__mulXf3__+0x21c>
 1f0:	b	1f4 <__mulXf3__+0x1c8>
 1f4:	ldr	x8, [sp, #104]
 1f8:	ldr	x9, [sp, #96]
 1fc:	orr	x8, x9, x8
 200:	cbz	x8, 230 <__mulXf3__+0x204>
 204:	b	208 <__mulXf3__+0x1dc>
 208:	ldr	x8, [sp, #120]
 20c:	ldr	x9, [sp, #112]
 210:	ldur	x10, [x29, #-72]
 214:	ldur	x11, [x29, #-80]
 218:	orr	x0, x9, x11
 21c:	orr	x1, x8, x10
 220:	bl	59c <fromRep>
 224:	ldr	x8, [sp, #48]
 228:	str	q0, [x8, #32]
 22c:	b	564 <__mulXf3__+0x538>
 230:	mov	x0, xzr
 234:	mov	x1, #0x7fff800000000000    	// #9223231299366420480
 238:	bl	59c <fromRep>
 23c:	ldr	x8, [sp, #48]
 240:	str	q0, [x8, #32]
 244:	b	564 <__mulXf3__+0x538>
 248:	ldr	x8, [sp, #96]
 24c:	ldr	x9, [sp, #104]
 250:	eor	x9, x9, #0x7fff000000000000
 254:	orr	x8, x8, x9
 258:	cbnz	x8, 2b4 <__mulXf3__+0x288>
 25c:	b	260 <__mulXf3__+0x234>
 260:	ldr	x8, [sp, #120]
 264:	ldr	x9, [sp, #112]
 268:	orr	x8, x9, x8
 26c:	cbz	x8, 29c <__mulXf3__+0x270>
 270:	b	274 <__mulXf3__+0x248>
 274:	ldr	x8, [sp, #104]
 278:	ldr	x9, [sp, #96]
 27c:	ldur	x10, [x29, #-72]
 280:	ldur	x11, [x29, #-80]
 284:	orr	x0, x9, x11
 288:	orr	x1, x8, x10
 28c:	bl	59c <fromRep>
 290:	ldr	x8, [sp, #48]
 294:	str	q0, [x8, #32]
 298:	b	564 <__mulXf3__+0x538>
 29c:	mov	x0, xzr
 2a0:	mov	x1, #0x7fff800000000000    	// #9223231299366420480
 2a4:	bl	59c <fromRep>
 2a8:	ldr	x8, [sp, #48]
 2ac:	str	q0, [x8, #32]
 2b0:	b	564 <__mulXf3__+0x538>
 2b4:	ldr	x8, [sp, #120]
 2b8:	ldr	x9, [sp, #112]
 2bc:	orr	x8, x9, x8
 2c0:	cbnz	x8, 2e0 <__mulXf3__+0x2b4>
 2c4:	b	2c8 <__mulXf3__+0x29c>
 2c8:	ldur	x1, [x29, #-72]
 2cc:	ldur	x0, [x29, #-80]
 2d0:	bl	59c <fromRep>
 2d4:	ldr	x8, [sp, #48]
 2d8:	str	q0, [x8, #32]
 2dc:	b	564 <__mulXf3__+0x538>
 2e0:	ldr	x8, [sp, #104]
 2e4:	ldr	x9, [sp, #96]
 2e8:	orr	x8, x9, x8
 2ec:	cbnz	x8, 30c <__mulXf3__+0x2e0>
 2f0:	b	2f4 <__mulXf3__+0x2c8>
 2f4:	ldur	x1, [x29, #-72]
 2f8:	ldur	x0, [x29, #-80]
 2fc:	bl	59c <fromRep>
 300:	ldr	x8, [sp, #48]
 304:	str	q0, [x8, #32]
 308:	b	564 <__mulXf3__+0x538>
 30c:	ldrh	w8, [sp, #126]
 310:	mov	w9, w8
 314:	cbnz	x9, 334 <__mulXf3__+0x308>
 318:	b	31c <__mulXf3__+0x2f0>
 31c:	sub	x0, x29, #0x60
 320:	bl	5c0 <normalize>
 324:	ldur	w8, [x29, #-116]
 328:	add	w8, w8, w0
 32c:	stur	w8, [x29, #-116]
 330:	b	334 <__mulXf3__+0x308>
 334:	ldrh	w8, [sp, #110]
 338:	mov	w9, w8
 33c:	cbnz	x9, 35c <__mulXf3__+0x330>
 340:	b	344 <__mulXf3__+0x318>
 344:	sub	x0, x29, #0x70
 348:	bl	5c0 <normalize>
 34c:	ldur	w8, [x29, #-116]
 350:	add	w8, w8, w0
 354:	stur	w8, [x29, #-116]
 358:	b	35c <__mulXf3__+0x330>
 35c:	b	360 <__mulXf3__+0x334>
 360:	ldur	x8, [x29, #-88]
 364:	orr	x8, x8, #0x1000000000000
 368:	stur	x8, [x29, #-88]
 36c:	ldur	x8, [x29, #-104]
 370:	orr	x8, x8, #0x1000000000000
 374:	stur	x8, [x29, #-104]
 378:	ldur	x1, [x29, #-88]
 37c:	ldur	x0, [x29, #-96]
 380:	ldur	x8, [x29, #-112]
 384:	ldur	x9, [x29, #-104]
 388:	extr	x3, x9, x8, #49
 38c:	lsl	x2, x8, #15
 390:	add	x4, sp, #0x50
 394:	add	x5, sp, #0x40
 398:	bl	6d8 <wideMultiply>
 39c:	ldur	w10, [x29, #-52]
 3a0:	ldur	w11, [x29, #-56]
 3a4:	add	w10, w10, w11
 3a8:	ldur	w11, [x29, #-116]
 3ac:	add	w10, w10, w11
 3b0:	mov	w11, #0xffffc001            	// #-16383
 3b4:	add	w10, w10, w11
 3b8:	str	w10, [sp, #60]
 3bc:	ldrb	w10, [sp, #94]
 3c0:	tbz	w10, #0, 3d8 <__mulXf3__+0x3ac>
 3c4:	b	3c8 <__mulXf3__+0x39c>
 3c8:	ldr	w8, [sp, #60]
 3cc:	add	w8, w8, #0x1
 3d0:	str	w8, [sp, #60]
 3d4:	b	3ec <__mulXf3__+0x3c0>
 3d8:	add	x0, sp, #0x50
 3dc:	add	x1, sp, #0x40
 3e0:	mov	w2, #0x1                   	// #1
 3e4:	bl	a20 <wideLeftShift>
 3e8:	b	3ec <__mulXf3__+0x3c0>
 3ec:	ldr	w8, [sp, #60]
 3f0:	mov	w9, #0x7fff                	// #32767
 3f4:	subs	w8, w8, w9
 3f8:	b.lt	41c <__mulXf3__+0x3f0>  // b.tstop
 3fc:	b	400 <__mulXf3__+0x3d4>
 400:	ldur	x0, [x29, #-80]
 404:	ldur	x8, [x29, #-72]
 408:	orr	x1, x8, #0x7fff000000000000
 40c:	bl	59c <fromRep>
 410:	ldr	x8, [sp, #48]
 414:	str	q0, [x8, #32]
 418:	b	564 <__mulXf3__+0x538>
 41c:	ldr	w8, [sp, #60]
 420:	subs	w8, w8, #0x0
 424:	b.gt	478 <__mulXf3__+0x44c>
 428:	b	42c <__mulXf3__+0x400>
 42c:	ldr	w8, [sp, #60]
 430:	mov	w9, #0x1                   	// #1
 434:	subs	w8, w9, w8
 438:	str	w8, [sp, #56]
 43c:	ldr	w8, [sp, #56]
 440:	subs	w8, w8, #0x80
 444:	b.cc	464 <__mulXf3__+0x438>  // b.lo, b.ul, b.last
 448:	b	44c <__mulXf3__+0x420>
 44c:	ldur	x1, [x29, #-72]
 450:	ldur	x0, [x29, #-80]
 454:	bl	59c <fromRep>
 458:	ldr	x8, [sp, #48]
 45c:	str	q0, [x8, #32]
 460:	b	564 <__mulXf3__+0x538>
 464:	ldr	w2, [sp, #56]
 468:	add	x0, sp, #0x50
 46c:	add	x1, sp, #0x40
 470:	bl	c04 <wideRightShiftWithSticky>
 474:	b	4a4 <__mulXf3__+0x478>
 478:	ldr	x8, [sp, #88]
 47c:	and	x8, x8, #0xffffffffffff
 480:	str	x8, [sp, #88]
 484:	ldr	w9, [sp, #60]
 488:	mov	w8, w9
 48c:	ldr	x10, [sp, #80]
 490:	ldr	x11, [sp, #88]
 494:	orr	x8, x11, x8, lsl #48
 498:	str	x10, [sp, #80]
 49c:	str	x8, [sp, #88]
 4a0:	b	4a4 <__mulXf3__+0x478>
 4a4:	ldur	x8, [x29, #-72]
 4a8:	ldur	x9, [x29, #-80]
 4ac:	ldr	x10, [sp, #88]
 4b0:	ldr	x11, [sp, #80]
 4b4:	orr	x9, x11, x9
 4b8:	orr	x8, x10, x8
 4bc:	str	x8, [sp, #88]
 4c0:	str	x9, [sp, #80]
 4c4:	ldr	x8, [sp, #64]
 4c8:	ldr	x9, [sp, #72]
 4cc:	subs	x10, x9, #0x0
 4d0:	cset	w12, ge  // ge = tcont
 4d4:	subs	x8, x8, #0x0
 4d8:	cset	w13, eq  // eq = none
 4dc:	mov	x11, #0x8000000000000000    	// #-9223372036854775808
 4e0:	subs	x9, x9, x11
 4e4:	csel	w12, w13, w12, eq  // eq = none
 4e8:	tbnz	w12, #0, 510 <__mulXf3__+0x4e4>
 4ec:	b	4f0 <__mulXf3__+0x4c4>
 4f0:	ldr	x8, [sp, #88]
 4f4:	ldr	x9, [sp, #80]
 4f8:	adds	x9, x9, #0x1
 4fc:	mov	x10, xzr
 500:	adcs	x8, x8, x10
 504:	str	x9, [sp, #80]
 508:	str	x8, [sp, #88]
 50c:	b	510 <__mulXf3__+0x4e4>
 510:	ldr	x8, [sp, #64]
 514:	ldr	x9, [sp, #72]
 518:	eor	x9, x9, #0x8000000000000000
 51c:	orr	x8, x8, x9
 520:	cbnz	x8, 54c <__mulXf3__+0x520>
 524:	b	528 <__mulXf3__+0x4fc>
 528:	ldr	x8, [sp, #88]
 52c:	ldr	x9, [sp, #80]
 530:	and	x10, x9, #0x1
 534:	adds	x9, x9, x10
 538:	mov	x10, xzr
 53c:	adcs	x8, x8, x10
 540:	str	x9, [sp, #80]
 544:	str	x8, [sp, #88]
 548:	b	54c <__mulXf3__+0x520>
 54c:	ldr	x1, [sp, #88]
 550:	ldr	x0, [sp, #80]
 554:	bl	59c <fromRep>
 558:	ldr	x8, [sp, #48]
 55c:	str	q0, [x8, #32]
 560:	b	564 <__mulXf3__+0x538>
 564:	ldr	x8, [sp, #48]
 568:	ldr	q0, [x8, #32]
 56c:	ldr	x28, [sp, #272]
 570:	ldp	x29, x30, [sp, #256]
 574:	add	sp, sp, #0x120
 578:	ret

000000000000057c <toRep>:
 57c:	sub	sp, sp, #0x20
 580:	str	q0, [sp, #16]
 584:	ldr	q0, [sp, #16]
 588:	str	q0, [sp]
 58c:	ldr	x0, [sp]
 590:	ldr	x1, [sp, #8]
 594:	add	sp, sp, #0x20
 598:	ret

000000000000059c <fromRep>:
 59c:	sub	sp, sp, #0x20
 5a0:	mov	v0.d[0], x0
 5a4:	mov	v0.d[1], x1
 5a8:	str	q0, [sp, #16]
 5ac:	ldr	q0, [sp, #16]
 5b0:	str	q0, [sp]
 5b4:	ldr	q0, [sp]
 5b8:	add	sp, sp, #0x20
 5bc:	ret

00000000000005c0 <normalize>:
 5c0:	sub	sp, sp, #0x40
 5c4:	stp	x29, x30, [sp, #48]
 5c8:	add	x29, sp, #0x30
 5cc:	mov	x8, xzr
 5d0:	mov	x1, #0x1000000000000       	// #281474976710656
 5d4:	mov	w9, #0x1                   	// #1
 5d8:	stur	x0, [x29, #-8]
 5dc:	ldur	x10, [x29, #-8]
 5e0:	ldr	q0, [x10]
 5e4:	mov	v1.16b, v0.16b
 5e8:	mov	d2, v0.d[1]
 5ec:	fmov	x0, d1
 5f0:	str	x1, [sp, #24]
 5f4:	fmov	x1, d2
 5f8:	str	x8, [sp, #16]
 5fc:	str	w9, [sp, #12]
 600:	bl	ee0 <rep_clz>
 604:	ldr	x8, [sp, #16]
 608:	str	w0, [sp, #8]
 60c:	mov	x0, x8
 610:	ldr	x1, [sp, #24]
 614:	bl	ee0 <rep_clz>
 618:	ldr	w9, [sp, #8]
 61c:	subs	w11, w9, w0
 620:	stur	w11, [x29, #-12]
 624:	ldur	w11, [x29, #-12]
 628:	mov	w8, w11
 62c:	mov	v0.d[0], x8
 630:	ldr	x8, [sp, #16]
 634:	mov	v0.d[1], x8
 638:	ldur	x10, [x29, #-8]
 63c:	ldr	q3, [x10]
 640:	mov	x12, #0x40                  	// #64
 644:	mov	v1.16b, v3.16b
 648:	mov	d2, v3.d[1]
 64c:	fmov	x13, d0
 650:	subs	x13, x13, #0x40
 654:	fmov	x14, d0
 658:	subs	x12, x12, x14
 65c:	fmov	x14, d0
 660:	cmp	x14, #0x40
 664:	cset	w11, cc  // cc = lo, ul, last
 668:	fmov	x14, d0
 66c:	fmov	x15, d1
 670:	fmov	x16, d0
 674:	lsl	x15, x15, x16
 678:	fmov	x16, d1
 67c:	lsr	x12, x16, x12
 680:	fmov	x16, d2
 684:	fmov	x17, d0
 688:	lsl	x16, x16, x17
 68c:	orr	x12, x12, x16
 690:	fmov	x16, d1
 694:	lsl	x13, x16, x13
 698:	tst	w11, #0x1
 69c:	csel	x15, x15, x8, ne  // ne = any
 6a0:	tst	w11, #0x1
 6a4:	csel	x12, x12, x13, ne  // ne = any
 6a8:	fmov	x13, d2
 6ac:	cmp	x14, #0x0
 6b0:	csel	x12, x13, x12, eq  // eq = none
 6b4:	mov	v3.d[0], x15
 6b8:	mov	v3.d[1], x12
 6bc:	str	q3, [x10]
 6c0:	ldur	w11, [x29, #-12]
 6c4:	ldr	w18, [sp, #12]
 6c8:	subs	w0, w18, w11
 6cc:	ldp	x29, x30, [sp, #48]
 6d0:	add	sp, sp, #0x40
 6d4:	ret

00000000000006d8 <wideMultiply>:
 6d8:	sub	sp, sp, #0x150
 6dc:	str	x29, [sp, #320]
 6e0:	str	x1, [sp, #312]
 6e4:	str	x0, [sp, #304]
 6e8:	str	x3, [sp, #296]
 6ec:	str	x2, [sp, #288]
 6f0:	str	x4, [sp, #280]
 6f4:	str	x5, [sp, #272]
 6f8:	ldr	w8, [sp, #316]
 6fc:	mov	w9, w8
 700:	ldr	w8, [sp, #300]
 704:	mov	w10, w8
 708:	mul	x9, x9, x10
 70c:	str	x9, [sp, #264]
 710:	ldr	w8, [sp, #316]
 714:	mov	w9, w8
 718:	ldr	w8, [sp, #296]
 71c:	mov	w10, w8
 720:	mul	x9, x9, x10
 724:	str	x9, [sp, #256]
 728:	ldr	w8, [sp, #316]
 72c:	mov	w9, w8
 730:	ldr	w8, [sp, #292]
 734:	mov	w10, w8
 738:	mul	x9, x9, x10
 73c:	str	x9, [sp, #248]
 740:	ldr	w8, [sp, #316]
 744:	mov	w9, w8
 748:	ldr	w8, [sp, #288]
 74c:	mov	w10, w8
 750:	mul	x9, x9, x10
 754:	str	x9, [sp, #240]
 758:	ldr	w8, [sp, #312]
 75c:	mov	w9, w8
 760:	ldr	w8, [sp, #300]
 764:	mov	w10, w8
 768:	mul	x9, x9, x10
 76c:	str	x9, [sp, #232]
 770:	ldr	w8, [sp, #312]
 774:	mov	w9, w8
 778:	ldr	w8, [sp, #296]
 77c:	mov	w10, w8
 780:	mul	x9, x9, x10
 784:	str	x9, [sp, #224]
 788:	ldr	w8, [sp, #312]
 78c:	mov	w9, w8
 790:	ldr	w8, [sp, #292]
 794:	mov	w10, w8
 798:	mul	x9, x9, x10
 79c:	str	x9, [sp, #216]
 7a0:	ldr	w8, [sp, #312]
 7a4:	mov	w9, w8
 7a8:	ldr	w8, [sp, #288]
 7ac:	mov	w10, w8
 7b0:	mul	x9, x9, x10
 7b4:	str	x9, [sp, #208]
 7b8:	ldr	w8, [sp, #308]
 7bc:	mov	w9, w8
 7c0:	ldr	w8, [sp, #300]
 7c4:	mov	w10, w8
 7c8:	mul	x9, x9, x10
 7cc:	str	x9, [sp, #200]
 7d0:	ldr	w8, [sp, #308]
 7d4:	mov	w9, w8
 7d8:	ldr	w8, [sp, #296]
 7dc:	mov	w10, w8
 7e0:	mul	x9, x9, x10
 7e4:	str	x9, [sp, #192]
 7e8:	ldr	w8, [sp, #308]
 7ec:	mov	w9, w8
 7f0:	ldr	w8, [sp, #292]
 7f4:	mov	w10, w8
 7f8:	mul	x9, x9, x10
 7fc:	str	x9, [sp, #184]
 800:	ldr	w8, [sp, #308]
 804:	mov	w9, w8
 808:	ldr	w8, [sp, #288]
 80c:	mov	w10, w8
 810:	mul	x9, x9, x10
 814:	str	x9, [sp, #176]
 818:	ldr	w8, [sp, #304]
 81c:	mov	w9, w8
 820:	ldr	w8, [sp, #300]
 824:	mov	w10, w8
 828:	mul	x9, x9, x10
 82c:	str	x9, [sp, #168]
 830:	ldr	w8, [sp, #304]
 834:	mov	w9, w8
 838:	ldr	w8, [sp, #296]
 83c:	mov	w10, w8
 840:	mul	x9, x9, x10
 844:	str	x9, [sp, #160]
 848:	ldr	w8, [sp, #304]
 84c:	mov	w9, w8
 850:	ldr	w8, [sp, #292]
 854:	mov	w10, w8
 858:	mul	x9, x9, x10
 85c:	str	x9, [sp, #152]
 860:	ldr	w8, [sp, #304]
 864:	mov	w9, w8
 868:	ldr	w8, [sp, #288]
 86c:	mov	w10, w8
 870:	mul	x9, x9, x10
 874:	str	x9, [sp, #144]
 878:	ldr	x9, [sp, #144]
 87c:	mov	x10, xzr
 880:	str	x10, [sp, #136]
 884:	str	x9, [sp, #128]
 888:	ldr	x9, [sp, #176]
 88c:	ldr	x11, [sp, #152]
 890:	adds	x9, x9, x11
 894:	adcs	x11, x10, x10
 898:	str	x9, [sp, #112]
 89c:	str	x11, [sp, #120]
 8a0:	ldr	x9, [sp, #208]
 8a4:	ldr	x11, [sp, #184]
 8a8:	adds	x9, x9, x11
 8ac:	adcs	x11, x10, x10
 8b0:	ldr	x12, [sp, #160]
 8b4:	adds	x9, x9, x12
 8b8:	adcs	x11, x11, x10
 8bc:	str	x9, [sp, #96]
 8c0:	str	x11, [sp, #104]
 8c4:	ldr	x9, [sp, #240]
 8c8:	ldr	x11, [sp, #216]
 8cc:	adds	x9, x9, x11
 8d0:	adcs	x11, x10, x10
 8d4:	ldr	x12, [sp, #192]
 8d8:	adds	x9, x9, x12
 8dc:	adcs	x11, x11, x10
 8e0:	ldr	x12, [sp, #168]
 8e4:	adds	x9, x9, x12
 8e8:	adcs	x11, x11, x10
 8ec:	str	x9, [sp, #80]
 8f0:	str	x11, [sp, #88]
 8f4:	ldr	x9, [sp, #248]
 8f8:	ldr	x11, [sp, #224]
 8fc:	adds	x9, x9, x11
 900:	adcs	x11, x10, x10
 904:	ldr	x12, [sp, #200]
 908:	adds	x9, x9, x12
 90c:	adcs	x11, x11, x10
 910:	str	x9, [sp, #64]
 914:	str	x11, [sp, #72]
 918:	ldr	x9, [sp, #256]
 91c:	ldr	x11, [sp, #232]
 920:	adds	x9, x9, x11
 924:	adcs	x11, x10, x10
 928:	str	x9, [sp, #48]
 92c:	str	x11, [sp, #56]
 930:	ldr	x9, [sp, #264]
 934:	str	x10, [sp, #40]
 938:	str	x9, [sp, #32]
 93c:	ldr	x9, [sp, #128]
 940:	ldr	w8, [sp, #112]
 944:	mov	w11, w8
 948:	adds	x9, x9, x11, lsl #32
 94c:	adcs	x11, x10, x10
 950:	str	x9, [sp, #16]
 954:	str	x11, [sp, #24]
 958:	ldr	x9, [sp, #136]
 95c:	ldur	x11, [sp, #116]
 960:	adds	x9, x9, x11
 964:	adcs	x11, x10, x10
 968:	ldr	x12, [sp, #96]
 96c:	adds	x9, x9, x12
 970:	adcs	x11, x11, x10
 974:	ldr	x12, [sp, #80]
 978:	adds	x9, x9, x12, lsl #32
 97c:	adcs	x11, x11, x10
 980:	str	x9, [sp]
 984:	str	x11, [sp, #8]
 988:	ldr	x9, [sp, #16]
 98c:	ldr	x11, [sp, #24]
 990:	ldr	x12, [sp]
 994:	add	x11, x11, x12
 998:	ldr	x12, [sp, #272]
 99c:	str	x9, [x12]
 9a0:	str	x11, [x12, #8]
 9a4:	ldr	x9, [sp, #8]
 9a8:	ldr	w8, [sp, #124]
 9ac:	mov	w11, w8
 9b0:	adds	x9, x9, x11
 9b4:	adcs	x11, x10, x10
 9b8:	ldr	x12, [sp, #104]
 9bc:	adds	x9, x9, x12
 9c0:	adcs	x10, x11, x10
 9c4:	ldr	x11, [sp, #80]
 9c8:	ldr	x12, [sp, #88]
 9cc:	extr	x11, x12, x11, #32
 9d0:	lsr	x12, x12, #32
 9d4:	adds	x9, x9, x11
 9d8:	adcs	x10, x10, x12
 9dc:	ldr	x11, [sp, #72]
 9e0:	ldr	x12, [sp, #64]
 9e4:	adds	x9, x9, x12
 9e8:	adcs	x10, x10, x11
 9ec:	ldr	x11, [sp, #48]
 9f0:	ldr	x12, [sp, #56]
 9f4:	extr	x12, x12, x11, #32
 9f8:	adds	x9, x9, x11, lsl #32
 9fc:	adcs	x10, x10, x12
 a00:	ldr	x11, [sp, #32]
 a04:	add	x10, x10, x11
 a08:	ldr	x11, [sp, #280]
 a0c:	str	x9, [x11]
 a10:	str	x10, [x11, #8]
 a14:	ldr	x29, [sp, #320]
 a18:	add	sp, sp, #0x150
 a1c:	ret

0000000000000a20 <wideLeftShift>:
 a20:	sub	sp, sp, #0x20
 a24:	mov	x8, #0x80                  	// #128
 a28:	str	x0, [sp, #24]
 a2c:	str	x1, [sp, #16]
 a30:	str	w2, [sp, #12]
 a34:	ldr	x9, [sp, #24]
 a38:	ldr	q0, [x9]
 a3c:	ldr	w10, [sp, #12]
 a40:	mov	w9, w10
 a44:	mov	x11, xzr
 a48:	mov	v1.d[0], x9
 a4c:	mov	v1.d[1], x11
 a50:	mov	x9, #0x40                  	// #64
 a54:	mov	v2.16b, v0.16b
 a58:	mov	d3, v0.d[1]
 a5c:	fmov	x12, d1
 a60:	subs	x12, x12, #0x40
 a64:	fmov	x13, d1
 a68:	subs	x13, x9, x13
 a6c:	fmov	x14, d1
 a70:	cmp	x14, #0x40
 a74:	cset	w10, cc  // cc = lo, ul, last
 a78:	fmov	x14, d1
 a7c:	fmov	x15, d2
 a80:	fmov	x16, d1
 a84:	lsl	x15, x15, x16
 a88:	fmov	x16, d2
 a8c:	lsr	x13, x16, x13
 a90:	fmov	x16, d3
 a94:	fmov	x17, d1
 a98:	lsl	x16, x16, x17
 a9c:	orr	x13, x13, x16
 aa0:	fmov	x16, d2
 aa4:	lsl	x12, x16, x12
 aa8:	tst	w10, #0x1
 aac:	csel	x15, x15, x11, ne  // ne = any
 ab0:	tst	w10, #0x1
 ab4:	csel	x12, x13, x12, ne  // ne = any
 ab8:	fmov	x13, d3
 abc:	cmp	x14, #0x0
 ac0:	csel	x12, x13, x12, eq  // eq = none
 ac4:	ldr	x13, [sp, #16]
 ac8:	ldr	q0, [x13]
 acc:	ldrsw	x13, [sp, #12]
 ad0:	subs	x8, x8, x13
 ad4:	mov	v4.d[0], x8
 ad8:	mov	v4.d[1], x11
 adc:	mov	v1.16b, v0.16b
 ae0:	mov	d2, v0.d[1]
 ae4:	fmov	x8, d4
 ae8:	subs	x8, x8, #0x40
 aec:	fmov	x13, d4
 af0:	subs	x13, x9, x13
 af4:	fmov	x14, d4
 af8:	cmp	x14, #0x40
 afc:	cset	w10, cc  // cc = lo, ul, last
 b00:	fmov	x14, d4
 b04:	fmov	x16, d2
 b08:	fmov	x17, d4
 b0c:	lsr	x16, x16, x17
 b10:	fmov	x17, d1
 b14:	fmov	x18, d4
 b18:	lsr	x17, x17, x18
 b1c:	fmov	x18, d2
 b20:	lsl	x13, x18, x13
 b24:	orr	x13, x17, x13
 b28:	fmov	x17, d2
 b2c:	lsr	x8, x17, x8
 b30:	tst	w10, #0x1
 b34:	csel	x8, x13, x8, ne  // ne = any
 b38:	fmov	x13, d1
 b3c:	cmp	x14, #0x0
 b40:	csel	x8, x13, x8, eq  // eq = none
 b44:	tst	w10, #0x1
 b48:	csel	x13, x16, x11, ne  // ne = any
 b4c:	orr	x8, x15, x8
 b50:	orr	x12, x12, x13
 b54:	mov	v0.d[0], x8
 b58:	mov	v0.d[1], x12
 b5c:	ldr	x8, [sp, #24]
 b60:	str	q0, [x8]
 b64:	ldr	x8, [sp, #16]
 b68:	ldr	q0, [x8]
 b6c:	ldr	w10, [sp, #12]
 b70:	mov	w8, w10
 b74:	mov	v5.d[0], x8
 b78:	mov	v5.d[1], x11
 b7c:	mov	v1.16b, v0.16b
 b80:	mov	d2, v0.d[1]
 b84:	fmov	x8, d5
 b88:	subs	x8, x8, #0x40
 b8c:	fmov	x12, d5
 b90:	subs	x9, x9, x12
 b94:	fmov	x12, d5
 b98:	cmp	x12, #0x40
 b9c:	cset	w10, cc  // cc = lo, ul, last
 ba0:	fmov	x12, d5
 ba4:	fmov	x13, d1
 ba8:	fmov	x14, d5
 bac:	lsl	x13, x13, x14
 bb0:	fmov	x14, d1
 bb4:	lsr	x9, x14, x9
 bb8:	fmov	x14, d2
 bbc:	fmov	x15, d5
 bc0:	lsl	x14, x14, x15
 bc4:	orr	x9, x9, x14
 bc8:	fmov	x14, d1
 bcc:	lsl	x8, x14, x8
 bd0:	tst	w10, #0x1
 bd4:	csel	x11, x13, x11, ne  // ne = any
 bd8:	tst	w10, #0x1
 bdc:	csel	x8, x9, x8, ne  // ne = any
 be0:	fmov	x9, d2
 be4:	cmp	x12, #0x0
 be8:	csel	x8, x9, x8, eq  // eq = none
 bec:	mov	v0.d[0], x11
 bf0:	mov	v0.d[1], x8
 bf4:	ldr	x8, [sp, #16]
 bf8:	str	q0, [x8]
 bfc:	add	sp, sp, #0x20
 c00:	ret

0000000000000c04 <wideRightShiftWithSticky>:
 c04:	sub	sp, sp, #0x20
 c08:	str	x0, [sp, #24]
 c0c:	str	x1, [sp, #16]
 c10:	str	w2, [sp, #12]
 c14:	ldr	w8, [sp, #12]
 c18:	subs	w8, w8, #0x7f
 c1c:	b.hi	d78 <wideRightShiftWithSticky+0x174>  // b.pmore
 c20:	b	c24 <wideRightShiftWithSticky+0x20>
 c24:	ldr	x8, [sp, #16]
 c28:	ldr	x9, [x8, #8]
 c2c:	ldr	x8, [x8]
 c30:	ldr	w10, [sp, #12]
 c34:	mov	w11, w10
 c38:	mov	w10, #0x80                  	// #128
 c3c:	mov	w12, w10
 c40:	subs	x13, x12, x11
 c44:	mov	x14, xzr
 c48:	sub	x15, x14, x13
 c4c:	lsr	x15, x8, x15
 c50:	subs	x13, x13, #0x0
 c54:	csel	x15, x14, x15, eq  // eq = none
 c58:	sub	x16, x14, x11
 c5c:	lsl	x8, x8, x16
 c60:	mov	w10, #0x40                  	// #64
 c64:	mov	w17, w10
 c68:	subs	x11, x17, x11
 c6c:	subs	x11, x11, #0x0
 c70:	csel	x18, x14, x8, ge  // ge = tcont
 c74:	lsl	x9, x9, x16
 c78:	orr	x9, x15, x9
 c7c:	csel	x8, x8, x9, ge  // ge = tcont
 c80:	orr	x8, x18, x8
 c84:	subs	x8, x8, #0x0
 c88:	cset	w10, ne  // ne = any
 c8c:	strb	w10, [sp, #8]
 c90:	ldr	x9, [sp, #24]
 c94:	ldr	x15, [x9, #8]
 c98:	ldr	x9, [x9]
 c9c:	ldr	w10, [sp, #12]
 ca0:	mov	w16, w10
 ca4:	subs	x12, x12, x16
 ca8:	sub	x18, x14, x12
 cac:	lsr	x18, x9, x18
 cb0:	subs	x12, x12, #0x0
 cb4:	csel	x18, x14, x18, eq  // eq = none
 cb8:	sub	x0, x14, x16
 cbc:	lsl	x15, x15, x0
 cc0:	orr	x15, x18, x15
 cc4:	lsl	x9, x9, x0
 cc8:	subs	x17, x17, x16
 ccc:	subs	x17, x17, #0x0
 cd0:	csel	x15, x9, x15, ge  // ge = tcont
 cd4:	csel	x9, x14, x9, ge  // ge = tcont
 cd8:	ldr	x18, [sp, #16]
 cdc:	ldr	x1, [x18]
 ce0:	ldr	x2, [x18, #8]
 ce4:	lsl	x0, x2, x0
 ce8:	subs	x3, x16, #0x0
 cec:	csel	x0, x14, x0, eq  // eq = none
 cf0:	lsr	x1, x1, x16
 cf4:	orr	x0, x1, x0
 cf8:	lsr	x1, x2, x16
 cfc:	subs	x16, x16, #0x40
 d00:	subs	x16, x16, #0x0
 d04:	csel	x0, x1, x0, ge  // ge = tcont
 d08:	csel	x1, x14, x1, ge  // ge = tcont
 d0c:	orr	x9, x9, x0
 d10:	orr	x15, x15, x1
 d14:	ldrb	w10, [sp, #8]
 d18:	mov	w0, w10
 d1c:	and	x0, x0, #0x1
 d20:	orr	x9, x9, x0
 d24:	str	x15, [x18, #8]
 d28:	str	x9, [x18]
 d2c:	ldr	x9, [sp, #24]
 d30:	ldr	x15, [x9]
 d34:	ldr	x18, [x9, #8]
 d38:	ldr	w10, [sp, #12]
 d3c:	mov	w0, w10
 d40:	sub	x1, x14, x0
 d44:	lsl	x1, x18, x1
 d48:	subs	x2, x0, #0x0
 d4c:	csel	x1, x14, x1, eq  // eq = none
 d50:	lsr	x15, x15, x0
 d54:	orr	x15, x15, x1
 d58:	lsr	x18, x18, x0
 d5c:	subs	x0, x0, #0x40
 d60:	subs	x0, x0, #0x0
 d64:	csel	x15, x18, x15, ge  // ge = tcont
 d68:	csel	x14, x14, x18, ge  // ge = tcont
 d6c:	str	x14, [x9, #8]
 d70:	str	x15, [x9]
 d74:	b	ed8 <wideRightShiftWithSticky+0x2d4>
 d78:	ldr	w8, [sp, #12]
 d7c:	subs	w8, w8, #0xff
 d80:	b.hi	e78 <wideRightShiftWithSticky+0x274>  // b.pmore
 d84:	b	d88 <wideRightShiftWithSticky+0x184>
 d88:	ldr	x8, [sp, #24]
 d8c:	ldr	x9, [x8, #8]
 d90:	ldr	x8, [x8]
 d94:	ldr	w10, [sp, #12]
 d98:	mov	w11, w10
 d9c:	mov	w10, #0x100                 	// #256
 da0:	mov	w12, w10
 da4:	subs	x12, x12, x11
 da8:	mov	x13, xzr
 dac:	sub	x14, x13, x12
 db0:	lsr	x14, x8, x14
 db4:	subs	x12, x12, #0x0
 db8:	csel	x14, x13, x14, eq  // eq = none
 dbc:	sub	x15, x13, x11
 dc0:	lsl	x9, x9, x15
 dc4:	orr	x9, x14, x9
 dc8:	lsl	x8, x8, x15
 dcc:	mov	w10, #0xc0                  	// #192
 dd0:	mov	w14, w10
 dd4:	subs	x11, x14, x11
 dd8:	subs	x11, x11, #0x0
 ddc:	csel	x9, x8, x9, ge  // ge = tcont
 de0:	csel	x8, x13, x8, ge  // ge = tcont
 de4:	ldr	x14, [sp, #16]
 de8:	ldr	x15, [x14, #8]
 dec:	ldr	x14, [x14]
 df0:	orr	x8, x8, x14
 df4:	orr	x9, x9, x15
 df8:	orr	x8, x8, x9
 dfc:	subs	x8, x8, #0x0
 e00:	cset	w10, ne  // ne = any
 e04:	strb	w10, [sp, #4]
 e08:	ldr	x9, [sp, #24]
 e0c:	ldr	x14, [x9]
 e10:	ldr	x9, [x9, #8]
 e14:	ldr	w10, [sp, #12]
 e18:	mov	w15, w10
 e1c:	subs	x16, x15, #0x80
 e20:	sub	x17, x13, x15
 e24:	lsl	x17, x9, x17
 e28:	subs	x16, x16, #0x0
 e2c:	csel	x17, x13, x17, eq  // eq = none
 e30:	lsr	x14, x14, x15
 e34:	orr	x14, x14, x17
 e38:	lsr	x9, x9, x15
 e3c:	subs	x15, x15, #0xc0
 e40:	subs	x15, x15, #0x0
 e44:	csel	x14, x9, x14, ge  // ge = tcont
 e48:	csel	x9, x13, x9, ge  // ge = tcont
 e4c:	ldrb	w10, [sp, #4]
 e50:	mov	w17, w10
 e54:	and	x17, x17, #0x1
 e58:	orr	x14, x14, x17
 e5c:	ldr	x17, [sp, #16]
 e60:	str	x9, [x17, #8]
 e64:	str	x14, [x17]
 e68:	ldr	x9, [sp, #24]
 e6c:	str	x13, [x9, #8]
 e70:	str	x13, [x9]
 e74:	b	ed4 <wideRightShiftWithSticky+0x2d0>
 e78:	ldr	x8, [sp, #24]
 e7c:	ldr	x9, [x8]
 e80:	ldr	x8, [x8, #8]
 e84:	ldr	x10, [sp, #16]
 e88:	ldr	x11, [x10]
 e8c:	ldr	x10, [x10, #8]
 e90:	orr	x8, x8, x10
 e94:	orr	x9, x9, x11
 e98:	orr	x8, x9, x8
 e9c:	subs	x8, x8, #0x0
 ea0:	cset	w12, ne  // ne = any
 ea4:	strb	w12, [sp]
 ea8:	ldrb	w12, [sp]
 eac:	mov	w9, w12
 eb0:	and	x9, x9, #0x1
 eb4:	ldr	x10, [sp, #16]
 eb8:	mov	x11, xzr
 ebc:	str	x11, [x10, #8]
 ec0:	str	x9, [x10]
 ec4:	ldr	x9, [sp, #24]
 ec8:	str	x11, [x9, #8]
 ecc:	str	x11, [x9]
 ed0:	b	ed4 <wideRightShiftWithSticky+0x2d0>
 ed4:	b	ed8 <wideRightShiftWithSticky+0x2d4>
 ed8:	add	sp, sp, #0x20
 edc:	ret

0000000000000ee0 <rep_clz>:
 ee0:	sub	sp, sp, #0x30
 ee4:	mov	v0.d[0], x0
 ee8:	mov	v0.d[1], x1
 eec:	str	q0, [sp, #32]
 ef0:	ldr	q0, [sp, #32]
 ef4:	str	q0, [sp, #16]
 ef8:	ldr	x8, [sp, #24]
 efc:	cbz	x8, f10 <rep_clz+0x30>
 f00:	ldr	x8, [sp, #24]
 f04:	str	x8, [sp, #8]
 f08:	str	xzr, [sp]
 f0c:	b	f20 <rep_clz+0x40>
 f10:	ldr	x8, [sp, #16]
 f14:	str	x8, [sp, #8]
 f18:	mov	x8, #0x40                  	// #64
 f1c:	str	x8, [sp]
 f20:	ldr	x8, [sp, #8]
 f24:	clz	x8, x8
 f28:	lsl	x8, x8, #32
 f2c:	ldr	x9, [sp]
 f30:	add	x8, x9, x8, asr #32
 f34:	mov	w0, w8
 f38:	add	sp, sp, #0x30
 f3c:	ret

mulvdi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulvdi3>:
   0:	sub	sp, sp, #0x70
   4:	stp	x29, x30, [sp, #96]
   8:	add	x29, sp, #0x60
   c:	mov	w8, #0x40                  	// #64
  10:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
  14:	mov	x10, #0x7fffffffffffffff    	// #9223372036854775807
  18:	adrp	x11, 0 <__mulvdi3>
  1c:	add	x11, x11, #0x0
  20:	adrp	x12, 0 <__mulvdi3>
  24:	add	x12, x12, #0x0
  28:	stur	x0, [x29, #-16]
  2c:	stur	x1, [x29, #-24]
  30:	stur	w8, [x29, #-28]
  34:	stur	x9, [x29, #-40]
  38:	str	x10, [sp, #48]
  3c:	ldur	x10, [x29, #-16]
  40:	cmp	x10, x9
  44:	str	x11, [sp, #8]
  48:	str	x12, [sp]
  4c:	b.ne	88 <__mulvdi3+0x88>  // b.any
  50:	ldur	x8, [x29, #-24]
  54:	cbz	x8, 64 <__mulvdi3+0x64>
  58:	ldur	x8, [x29, #-24]
  5c:	cmp	x8, #0x1
  60:	b.ne	78 <__mulvdi3+0x78>  // b.any
  64:	ldur	x8, [x29, #-16]
  68:	ldur	x9, [x29, #-24]
  6c:	mul	x8, x8, x9
  70:	stur	x8, [x29, #-8]
  74:	b	1c0 <__mulvdi3+0x1c0>
  78:	ldr	x0, [sp, #8]
  7c:	mov	w1, #0x1a                  	// #26
  80:	ldr	x2, [sp]
  84:	bl	0 <__compilerrt_abort_impl>
  88:	ldur	x8, [x29, #-24]
  8c:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
  90:	cmp	x8, x9
  94:	b.ne	d0 <__mulvdi3+0xd0>  // b.any
  98:	ldur	x8, [x29, #-16]
  9c:	cbz	x8, ac <__mulvdi3+0xac>
  a0:	ldur	x8, [x29, #-16]
  a4:	cmp	x8, #0x1
  a8:	b.ne	c0 <__mulvdi3+0xc0>  // b.any
  ac:	ldur	x8, [x29, #-16]
  b0:	ldur	x9, [x29, #-24]
  b4:	mul	x8, x8, x9
  b8:	stur	x8, [x29, #-8]
  bc:	b	1c0 <__mulvdi3+0x1c0>
  c0:	ldr	x0, [sp, #8]
  c4:	mov	w1, #0x1f                  	// #31
  c8:	ldr	x2, [sp]
  cc:	bl	0 <__compilerrt_abort_impl>
  d0:	ldur	x8, [x29, #-16]
  d4:	asr	x8, x8, #63
  d8:	str	x8, [sp, #40]
  dc:	ldur	x8, [x29, #-16]
  e0:	ldr	x9, [sp, #40]
  e4:	eor	x8, x8, x9
  e8:	ldr	x9, [sp, #40]
  ec:	subs	x8, x8, x9
  f0:	str	x8, [sp, #32]
  f4:	ldur	x8, [x29, #-24]
  f8:	asr	x8, x8, #63
  fc:	str	x8, [sp, #24]
 100:	ldur	x8, [x29, #-24]
 104:	ldr	x9, [sp, #24]
 108:	eor	x8, x8, x9
 10c:	ldr	x9, [sp, #24]
 110:	subs	x8, x8, x9
 114:	str	x8, [sp, #16]
 118:	ldr	x8, [sp, #32]
 11c:	cmp	x8, #0x2
 120:	b.lt	130 <__mulvdi3+0x130>  // b.tstop
 124:	ldr	x8, [sp, #16]
 128:	cmp	x8, #0x2
 12c:	b.ge	144 <__mulvdi3+0x144>  // b.tcont
 130:	ldur	x8, [x29, #-16]
 134:	ldur	x9, [x29, #-24]
 138:	mul	x8, x8, x9
 13c:	stur	x8, [x29, #-8]
 140:	b	1c0 <__mulvdi3+0x1c0>
 144:	ldr	x8, [sp, #40]
 148:	ldr	x9, [sp, #24]
 14c:	cmp	x8, x9
 150:	b.ne	180 <__mulvdi3+0x180>  // b.any
 154:	ldr	x8, [sp, #32]
 158:	ldr	x9, [sp, #16]
 15c:	mov	x10, #0x7fffffffffffffff    	// #9223372036854775807
 160:	sdiv	x9, x10, x9
 164:	cmp	x8, x9
 168:	b.le	17c <__mulvdi3+0x17c>
 16c:	ldr	x0, [sp, #8]
 170:	mov	w1, #0x29                  	// #41
 174:	ldr	x2, [sp]
 178:	bl	0 <__compilerrt_abort_impl>
 17c:	b	1b0 <__mulvdi3+0x1b0>
 180:	ldr	x8, [sp, #32]
 184:	ldr	x9, [sp, #16]
 188:	mov	x10, xzr
 18c:	subs	x9, x10, x9
 190:	mov	x10, #0x8000000000000000    	// #-9223372036854775808
 194:	sdiv	x9, x10, x9
 198:	cmp	x8, x9
 19c:	b.le	1b0 <__mulvdi3+0x1b0>
 1a0:	ldr	x0, [sp, #8]
 1a4:	mov	w1, #0x2c                  	// #44
 1a8:	ldr	x2, [sp]
 1ac:	bl	0 <__compilerrt_abort_impl>
 1b0:	ldur	x8, [x29, #-16]
 1b4:	ldur	x9, [x29, #-24]
 1b8:	mul	x8, x8, x9
 1bc:	stur	x8, [x29, #-8]
 1c0:	ldur	x0, [x29, #-8]
 1c4:	ldp	x29, x30, [sp, #96]
 1c8:	add	sp, sp, #0x70
 1cc:	ret

mulvsi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulvsi3>:
   0:	sub	sp, sp, #0x50
   4:	stp	x29, x30, [sp, #64]
   8:	add	x29, sp, #0x40
   c:	mov	w8, #0x20                  	// #32
  10:	mov	w9, #0x80000000            	// #-2147483648
  14:	mov	w10, #0x7fffffff            	// #2147483647
  18:	adrp	x11, 0 <__mulvsi3>
  1c:	add	x11, x11, #0x0
  20:	adrp	x12, 0 <__mulvsi3>
  24:	add	x12, x12, #0x0
  28:	stur	w0, [x29, #-8]
  2c:	stur	w1, [x29, #-12]
  30:	stur	w8, [x29, #-16]
  34:	stur	w9, [x29, #-20]
  38:	stur	w10, [x29, #-24]
  3c:	ldur	w8, [x29, #-8]
  40:	cmp	w8, w9
  44:	str	x11, [sp, #16]
  48:	str	x12, [sp, #8]
  4c:	b.ne	88 <__mulvsi3+0x88>  // b.any
  50:	ldur	w8, [x29, #-12]
  54:	cbz	w8, 64 <__mulvsi3+0x64>
  58:	ldur	w8, [x29, #-12]
  5c:	cmp	w8, #0x1
  60:	b.ne	78 <__mulvsi3+0x78>  // b.any
  64:	ldur	w8, [x29, #-8]
  68:	ldur	w9, [x29, #-12]
  6c:	mul	w8, w8, w9
  70:	stur	w8, [x29, #-4]
  74:	b	1c4 <__mulvsi3+0x1c4>
  78:	ldr	x0, [sp, #16]
  7c:	mov	w1, #0x1a                  	// #26
  80:	ldr	x2, [sp, #8]
  84:	bl	0 <__compilerrt_abort_impl>
  88:	ldur	w8, [x29, #-12]
  8c:	mov	w9, #0x80000000            	// #-2147483648
  90:	cmp	w8, w9
  94:	b.ne	d0 <__mulvsi3+0xd0>  // b.any
  98:	ldur	w8, [x29, #-8]
  9c:	cbz	w8, ac <__mulvsi3+0xac>
  a0:	ldur	w8, [x29, #-8]
  a4:	cmp	w8, #0x1
  a8:	b.ne	c0 <__mulvsi3+0xc0>  // b.any
  ac:	ldur	w8, [x29, #-8]
  b0:	ldur	w9, [x29, #-12]
  b4:	mul	w8, w8, w9
  b8:	stur	w8, [x29, #-4]
  bc:	b	1c4 <__mulvsi3+0x1c4>
  c0:	ldr	x0, [sp, #16]
  c4:	mov	w1, #0x1f                  	// #31
  c8:	ldr	x2, [sp, #8]
  cc:	bl	0 <__compilerrt_abort_impl>
  d0:	ldur	w8, [x29, #-8]
  d4:	mov	x9, #0x1f                  	// #31
  d8:	asr	w8, w8, #31
  dc:	stur	w8, [x29, #-28]
  e0:	ldur	w8, [x29, #-8]
  e4:	ldur	w10, [x29, #-28]
  e8:	eor	w8, w8, w10
  ec:	ldur	w10, [x29, #-28]
  f0:	subs	w8, w8, w10
  f4:	str	w8, [sp, #32]
  f8:	ldur	w8, [x29, #-12]
  fc:	asr	w8, w8, w9
 100:	str	w8, [sp, #28]
 104:	ldur	w8, [x29, #-12]
 108:	ldr	w9, [sp, #28]
 10c:	eor	w8, w8, w9
 110:	ldr	w9, [sp, #28]
 114:	subs	w8, w8, w9
 118:	str	w8, [sp, #24]
 11c:	ldr	w8, [sp, #32]
 120:	cmp	w8, #0x2
 124:	b.lt	134 <__mulvsi3+0x134>  // b.tstop
 128:	ldr	w8, [sp, #24]
 12c:	cmp	w8, #0x2
 130:	b.ge	148 <__mulvsi3+0x148>  // b.tcont
 134:	ldur	w8, [x29, #-8]
 138:	ldur	w9, [x29, #-12]
 13c:	mul	w8, w8, w9
 140:	stur	w8, [x29, #-4]
 144:	b	1c4 <__mulvsi3+0x1c4>
 148:	ldur	w8, [x29, #-28]
 14c:	ldr	w9, [sp, #28]
 150:	cmp	w8, w9
 154:	b.ne	184 <__mulvsi3+0x184>  // b.any
 158:	ldr	w8, [sp, #32]
 15c:	ldr	w9, [sp, #24]
 160:	mov	w10, #0x7fffffff            	// #2147483647
 164:	sdiv	w9, w10, w9
 168:	cmp	w8, w9
 16c:	b.le	180 <__mulvsi3+0x180>
 170:	ldr	x0, [sp, #16]
 174:	mov	w1, #0x29                  	// #41
 178:	ldr	x2, [sp, #8]
 17c:	bl	0 <__compilerrt_abort_impl>
 180:	b	1b4 <__mulvsi3+0x1b4>
 184:	ldr	w8, [sp, #32]
 188:	ldr	w9, [sp, #24]
 18c:	mov	w10, wzr
 190:	subs	w9, w10, w9
 194:	mov	w10, #0x80000000            	// #-2147483648
 198:	sdiv	w9, w10, w9
 19c:	cmp	w8, w9
 1a0:	b.le	1b4 <__mulvsi3+0x1b4>
 1a4:	ldr	x0, [sp, #16]
 1a8:	mov	w1, #0x2c                  	// #44
 1ac:	ldr	x2, [sp, #8]
 1b0:	bl	0 <__compilerrt_abort_impl>
 1b4:	ldur	w8, [x29, #-8]
 1b8:	ldur	w9, [x29, #-12]
 1bc:	mul	w8, w8, w9
 1c0:	stur	w8, [x29, #-4]
 1c4:	ldur	w0, [x29, #-4]
 1c8:	ldp	x29, x30, [sp, #64]
 1cc:	add	sp, sp, #0x50
 1d0:	ret

mulvti3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__mulvti3>:
   0:	sub	sp, sp, #0xd0
   4:	stp	x29, x30, [sp, #192]
   8:	add	x29, sp, #0xc0
   c:	stur	x1, [x29, #-24]
  10:	stur	x0, [x29, #-32]
  14:	stur	x3, [x29, #-40]
  18:	stur	x2, [x29, #-48]
  1c:	mov	w8, #0x80                  	// #128
  20:	stur	w8, [x29, #-52]
  24:	mov	x9, #0x8000000000000000    	// #-9223372036854775808
  28:	stur	x9, [x29, #-72]
  2c:	mov	x9, xzr
  30:	stur	x9, [x29, #-80]
  34:	mov	x9, #0x7fffffffffffffff    	// #9223372036854775807
  38:	str	x9, [sp, #104]
  3c:	mov	x9, #0xffffffffffffffff    	// #-1
  40:	str	x9, [sp, #96]
  44:	ldur	x9, [x29, #-32]
  48:	ldur	x10, [x29, #-24]
  4c:	eor	x10, x10, #0x8000000000000000
  50:	orr	x9, x9, x10
  54:	cbnz	x9, d4 <__mulvti3+0xd4>
  58:	b	5c <__mulvti3+0x5c>
  5c:	ldur	x8, [x29, #-40]
  60:	ldur	x9, [x29, #-48]
  64:	orr	x8, x9, x8
  68:	cbz	x8, 88 <__mulvti3+0x88>
  6c:	b	70 <__mulvti3+0x70>
  70:	ldur	x8, [x29, #-40]
  74:	ldur	x9, [x29, #-48]
  78:	eor	x9, x9, #0x1
  7c:	orr	x8, x9, x8
  80:	cbnz	x8, bc <__mulvti3+0xbc>
  84:	b	88 <__mulvti3+0x88>
  88:	ldur	x8, [x29, #-24]
  8c:	ldur	x9, [x29, #-32]
  90:	ldur	x10, [x29, #-48]
  94:	ldur	x11, [x29, #-40]
  98:	mul	x11, x9, x11
  9c:	umulh	x12, x9, x10
  a0:	add	x11, x12, x11
  a4:	mul	x8, x8, x10
  a8:	add	x8, x11, x8
  ac:	mul	x9, x9, x10
  b0:	stur	x9, [x29, #-16]
  b4:	stur	x8, [x29, #-8]
  b8:	b	37c <__mulvti3+0x37c>
  bc:	adrp	x0, 0 <__mulvti3>
  c0:	add	x0, x0, #0x0
  c4:	adrp	x2, 0 <__mulvti3>
  c8:	add	x2, x2, #0x0
  cc:	mov	w1, #0x1c                  	// #28
  d0:	bl	0 <__compilerrt_abort_impl>
  d4:	ldur	x8, [x29, #-48]
  d8:	ldur	x9, [x29, #-40]
  dc:	eor	x9, x9, #0x8000000000000000
  e0:	orr	x8, x8, x9
  e4:	cbnz	x8, 164 <__mulvti3+0x164>
  e8:	b	ec <__mulvti3+0xec>
  ec:	ldur	x8, [x29, #-24]
  f0:	ldur	x9, [x29, #-32]
  f4:	orr	x8, x9, x8
  f8:	cbz	x8, 118 <__mulvti3+0x118>
  fc:	b	100 <__mulvti3+0x100>
 100:	ldur	x8, [x29, #-24]
 104:	ldur	x9, [x29, #-32]
 108:	eor	x9, x9, #0x1
 10c:	orr	x8, x9, x8
 110:	cbnz	x8, 14c <__mulvti3+0x14c>
 114:	b	118 <__mulvti3+0x118>
 118:	ldur	x8, [x29, #-24]
 11c:	ldur	x9, [x29, #-32]
 120:	ldur	x10, [x29, #-48]
 124:	ldur	x11, [x29, #-40]
 128:	mul	x11, x9, x11
 12c:	umulh	x12, x9, x10
 130:	add	x11, x12, x11
 134:	mul	x8, x8, x10
 138:	add	x8, x11, x8
 13c:	mul	x9, x9, x10
 140:	stur	x9, [x29, #-16]
 144:	stur	x8, [x29, #-8]
 148:	b	37c <__mulvti3+0x37c>
 14c:	adrp	x0, 0 <__mulvti3>
 150:	add	x0, x0, #0x0
 154:	adrp	x2, 0 <__mulvti3>
 158:	add	x2, x2, #0x0
 15c:	mov	w1, #0x21                  	// #33
 160:	bl	0 <__compilerrt_abort_impl>
 164:	ldur	x8, [x29, #-24]
 168:	asr	x8, x8, #63
 16c:	str	x8, [sp, #88]
 170:	str	x8, [sp, #80]
 174:	ldur	x8, [x29, #-32]
 178:	ldur	x9, [x29, #-24]
 17c:	ldr	x10, [sp, #80]
 180:	ldr	x11, [sp, #88]
 184:	eor	x9, x9, x11
 188:	eor	x8, x8, x10
 18c:	subs	x8, x8, x10
 190:	sbcs	x9, x9, x11
 194:	str	x8, [sp, #64]
 198:	str	x9, [sp, #72]
 19c:	ldur	x8, [x29, #-40]
 1a0:	asr	x8, x8, #63
 1a4:	str	x8, [sp, #56]
 1a8:	str	x8, [sp, #48]
 1ac:	ldur	x8, [x29, #-48]
 1b0:	ldur	x9, [x29, #-40]
 1b4:	ldr	x10, [sp, #48]
 1b8:	ldr	x11, [sp, #56]
 1bc:	eor	x9, x9, x11
 1c0:	eor	x8, x8, x10
 1c4:	subs	x8, x8, x10
 1c8:	sbcs	x9, x9, x11
 1cc:	str	x8, [sp, #32]
 1d0:	str	x9, [sp, #40]
 1d4:	ldr	x8, [sp, #72]
 1d8:	ldr	x9, [sp, #64]
 1dc:	subs	x9, x9, #0x2
 1e0:	cset	w12, cc  // cc = lo, ul, last
 1e4:	subs	x8, x8, #0x0
 1e8:	cset	w13, lt  // lt = tstop
 1ec:	csel	w12, w12, w13, eq  // eq = none
 1f0:	tbnz	w12, #0, 21c <__mulvti3+0x21c>
 1f4:	b	1f8 <__mulvti3+0x1f8>
 1f8:	ldr	x8, [sp, #40]
 1fc:	ldr	x9, [sp, #32]
 200:	subs	x9, x9, #0x1
 204:	cset	w10, hi  // hi = pmore
 208:	subs	x8, x8, #0x0
 20c:	cset	w11, gt
 210:	csel	w10, w10, w11, eq  // eq = none
 214:	tbnz	w10, #0, 250 <__mulvti3+0x250>
 218:	b	21c <__mulvti3+0x21c>
 21c:	ldur	x8, [x29, #-24]
 220:	ldur	x9, [x29, #-32]
 224:	ldur	x10, [x29, #-48]
 228:	ldur	x11, [x29, #-40]
 22c:	mul	x11, x9, x11
 230:	umulh	x12, x9, x10
 234:	add	x11, x12, x11
 238:	mul	x8, x8, x10
 23c:	add	x8, x11, x8
 240:	mul	x9, x9, x10
 244:	stur	x9, [x29, #-16]
 248:	stur	x8, [x29, #-8]
 24c:	b	37c <__mulvti3+0x37c>
 250:	ldr	x8, [sp, #80]
 254:	ldr	x9, [sp, #88]
 258:	ldr	x10, [sp, #48]
 25c:	ldr	x11, [sp, #56]
 260:	eor	x9, x9, x11
 264:	eor	x8, x8, x10
 268:	orr	x8, x8, x9
 26c:	cbnz	x8, 2d8 <__mulvti3+0x2d8>
 270:	b	274 <__mulvti3+0x274>
 274:	ldr	x8, [sp, #72]
 278:	ldr	x9, [sp, #64]
 27c:	ldr	x2, [sp, #32]
 280:	ldr	x3, [sp, #40]
 284:	mov	x0, #0xffffffffffffffff    	// #-1
 288:	mov	x1, #0x7fffffffffffffff    	// #9223372036854775807
 28c:	str	x8, [sp, #24]
 290:	str	x9, [sp, #16]
 294:	bl	0 <__divti3>
 298:	ldr	x8, [sp, #16]
 29c:	subs	x8, x8, x0
 2a0:	cset	w10, ls  // ls = plast
 2a4:	ldr	x9, [sp, #24]
 2a8:	subs	x9, x9, x1
 2ac:	cset	w11, le
 2b0:	csel	w10, w10, w11, eq  // eq = none
 2b4:	tbnz	w10, #0, 2d4 <__mulvti3+0x2d4>
 2b8:	b	2bc <__mulvti3+0x2bc>
 2bc:	adrp	x0, 0 <__mulvti3>
 2c0:	add	x0, x0, #0x0
 2c4:	adrp	x2, 0 <__mulvti3>
 2c8:	add	x2, x2, #0x0
 2cc:	mov	w1, #0x2b                  	// #43
 2d0:	bl	0 <__compilerrt_abort_impl>
 2d4:	b	348 <__mulvti3+0x348>
 2d8:	ldr	x8, [sp, #72]
 2dc:	ldr	x9, [sp, #64]
 2e0:	ldr	x10, [sp, #40]
 2e4:	ldr	x11, [sp, #32]
 2e8:	mov	x12, xzr
 2ec:	subs	x2, x12, x11
 2f0:	sbcs	x3, x12, x10
 2f4:	mov	x1, #0x8000000000000000    	// #-9223372036854775808
 2f8:	mov	x0, x12
 2fc:	str	x8, [sp, #8]
 300:	str	x9, [sp]
 304:	bl	0 <__divti3>
 308:	ldr	x8, [sp]
 30c:	subs	x8, x8, x0
 310:	cset	w13, ls  // ls = plast
 314:	ldr	x9, [sp, #8]
 318:	subs	x9, x9, x1
 31c:	cset	w14, le
 320:	csel	w13, w13, w14, eq  // eq = none
 324:	tbnz	w13, #0, 344 <__mulvti3+0x344>
 328:	b	32c <__mulvti3+0x32c>
 32c:	adrp	x0, 0 <__mulvti3>
 330:	add	x0, x0, #0x0
 334:	adrp	x2, 0 <__mulvti3>
 338:	add	x2, x2, #0x0
 33c:	mov	w1, #0x2e                  	// #46
 340:	bl	0 <__compilerrt_abort_impl>
 344:	b	348 <__mulvti3+0x348>
 348:	ldur	x8, [x29, #-24]
 34c:	ldur	x9, [x29, #-32]
 350:	ldur	x10, [x29, #-48]
 354:	ldur	x11, [x29, #-40]
 358:	mul	x11, x9, x11
 35c:	umulh	x12, x9, x10
 360:	add	x11, x12, x11
 364:	mul	x8, x8, x10
 368:	add	x8, x11, x8
 36c:	mul	x9, x9, x10
 370:	stur	x9, [x29, #-16]
 374:	stur	x8, [x29, #-8]
 378:	b	37c <__mulvti3+0x37c>
 37c:	ldur	x0, [x29, #-16]
 380:	ldur	x1, [x29, #-8]
 384:	ldp	x29, x30, [sp, #192]
 388:	add	sp, sp, #0xd0
 38c:	ret

negdf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negdf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp, #8]
  10:	ldr	d0, [sp, #8]
  14:	bl	48 <toRep>
  18:	eor	x0, x0, #0x8000000000000000
  1c:	bl	2c <fromRep>
  20:	ldp	x29, x30, [sp, #16]
  24:	add	sp, sp, #0x20
  28:	ret

000000000000002c <fromRep>:
  2c:	sub	sp, sp, #0x10
  30:	str	x0, [sp, #8]
  34:	ldr	x8, [sp, #8]
  38:	str	x8, [sp]
  3c:	ldr	d0, [sp]
  40:	add	sp, sp, #0x10
  44:	ret

0000000000000048 <toRep>:
  48:	sub	sp, sp, #0x10
  4c:	str	d0, [sp, #8]
  50:	ldr	x8, [sp, #8]
  54:	str	x8, [sp]
  58:	ldr	x0, [sp]
  5c:	add	sp, sp, #0x10
  60:	ret

negdi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negdi2>:
   0:	sub	sp, sp, #0x10
   4:	mov	x8, xzr
   8:	str	x0, [sp, #8]
   c:	ldr	x9, [sp, #8]
  10:	subs	x0, x8, x9
  14:	add	sp, sp, #0x10
  18:	ret

negsf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negsf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	ldur	s0, [x29, #-4]
  14:	bl	48 <toRep>
  18:	eor	w0, w0, #0x80000000
  1c:	bl	2c <fromRep>
  20:	ldp	x29, x30, [sp, #16]
  24:	add	sp, sp, #0x20
  28:	ret

000000000000002c <fromRep>:
  2c:	sub	sp, sp, #0x10
  30:	str	w0, [sp, #12]
  34:	ldr	w8, [sp, #12]
  38:	str	w8, [sp, #8]
  3c:	ldr	s0, [sp, #8]
  40:	add	sp, sp, #0x10
  44:	ret

0000000000000048 <toRep>:
  48:	sub	sp, sp, #0x10
  4c:	str	s0, [sp, #12]
  50:	ldr	w8, [sp, #12]
  54:	str	w8, [sp, #8]
  58:	ldr	w0, [sp, #8]
  5c:	add	sp, sp, #0x10
  60:	ret

negti2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negti2>:
   0:	sub	sp, sp, #0x10
   4:	str	x1, [sp, #8]
   8:	str	x0, [sp]
   c:	ldr	x8, [sp, #8]
  10:	ldr	x9, [sp]
  14:	mov	x10, xzr
  18:	subs	x0, x10, x9
  1c:	sbcs	x1, x10, x8
  20:	add	sp, sp, #0x10
  24:	ret

negvdi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negvdi2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	mov	x8, #0x8000000000000000    	// #-9223372036854775808
  10:	str	x0, [sp, #8]
  14:	str	x8, [sp]
  18:	ldr	x9, [sp, #8]
  1c:	cmp	x9, x8
  20:	b.ne	3c <__negvdi2+0x3c>  // b.any
  24:	adrp	x0, 0 <__negvdi2>
  28:	add	x0, x0, #0x0
  2c:	mov	w1, #0x16                  	// #22
  30:	adrp	x2, 0 <__negvdi2>
  34:	add	x2, x2, #0x0
  38:	bl	0 <__compilerrt_abort_impl>
  3c:	ldr	x8, [sp, #8]
  40:	mov	x9, xzr
  44:	subs	x0, x9, x8
  48:	ldp	x29, x30, [sp, #16]
  4c:	add	sp, sp, #0x20
  50:	ret

negvsi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negvsi2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	mov	w8, #0x80000000            	// #-2147483648
  10:	stur	w0, [x29, #-4]
  14:	str	w8, [sp, #8]
  18:	ldur	w9, [x29, #-4]
  1c:	cmp	w9, w8
  20:	b.ne	3c <__negvsi2+0x3c>  // b.any
  24:	adrp	x0, 0 <__negvsi2>
  28:	add	x0, x0, #0x0
  2c:	mov	w1, #0x16                  	// #22
  30:	adrp	x2, 0 <__negvsi2>
  34:	add	x2, x2, #0x0
  38:	bl	0 <__compilerrt_abort_impl>
  3c:	ldur	w8, [x29, #-4]
  40:	mov	w9, wzr
  44:	subs	w0, w9, w8
  48:	ldp	x29, x30, [sp, #16]
  4c:	add	sp, sp, #0x20
  50:	ret

negvti2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__negvti2>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	str	x1, [sp, #24]
  10:	str	x0, [sp, #16]
  14:	mov	x8, #0x8000000000000000    	// #-9223372036854775808
  18:	str	x8, [sp, #8]
  1c:	mov	x8, xzr
  20:	str	x8, [sp]
  24:	ldr	x8, [sp, #16]
  28:	ldr	x9, [sp, #24]
  2c:	eor	x9, x9, #0x8000000000000000
  30:	orr	x8, x8, x9
  34:	cbnz	x8, 54 <__negvti2+0x54>
  38:	b	3c <__negvti2+0x3c>
  3c:	adrp	x0, 0 <__negvti2>
  40:	add	x0, x0, #0x0
  44:	adrp	x2, 0 <__negvti2>
  48:	add	x2, x2, #0x0
  4c:	mov	w1, #0x18                  	// #24
  50:	bl	0 <__compilerrt_abort_impl>
  54:	ldr	x8, [sp, #24]
  58:	ldr	x9, [sp, #16]
  5c:	mov	x10, xzr
  60:	subs	x0, x10, x9
  64:	sbcs	x1, x10, x8
  68:	ldp	x29, x30, [sp, #32]
  6c:	add	sp, sp, #0x30
  70:	ret

os_version_check.c.o:     file format elf64-littleaarch64


paritydi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__paritydi2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	x0, [sp, #8]
  10:	ldr	x8, [sp, #8]
  14:	str	x8, [sp]
  18:	ldr	w9, [sp, #4]
  1c:	ldr	w10, [sp]
  20:	eor	w0, w9, w10
  24:	bl	0 <__paritysi2>
  28:	ldp	x29, x30, [sp, #16]
  2c:	add	sp, sp, #0x20
  30:	ret

paritysi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__paritysi2>:
   0:	sub	sp, sp, #0x10
   4:	mov	w8, #0x6996                	// #27030
   8:	str	w0, [sp, #12]
   c:	ldr	w9, [sp, #12]
  10:	str	w9, [sp, #8]
  14:	ldr	w9, [sp, #8]
  18:	ldr	w10, [sp, #8]
  1c:	eor	w9, w10, w9, lsr #16
  20:	str	w9, [sp, #8]
  24:	ldr	w9, [sp, #8]
  28:	ldr	w10, [sp, #8]
  2c:	eor	w9, w10, w9, lsr #8
  30:	str	w9, [sp, #8]
  34:	ldr	w9, [sp, #8]
  38:	ldr	w10, [sp, #8]
  3c:	eor	w9, w10, w9, lsr #4
  40:	str	w9, [sp, #8]
  44:	ldr	w9, [sp, #8]
  48:	and	w9, w9, #0xf
  4c:	asr	w8, w8, w9
  50:	and	w0, w8, #0x1
  54:	add	sp, sp, #0x10
  58:	ret

parityti2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__parityti2>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	mov	v0.d[0], x0
  10:	mov	v0.d[1], x1
  14:	str	q0, [sp, #16]
  18:	ldr	q0, [sp, #16]
  1c:	str	q0, [sp]
  20:	ldr	x8, [sp, #8]
  24:	ldr	x9, [sp]
  28:	eor	x0, x8, x9
  2c:	bl	0 <__paritydi2>
  30:	ldp	x29, x30, [sp, #32]
  34:	add	sp, sp, #0x30
  38:	ret

popcountdi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__popcountdi2>:
   0:	sub	sp, sp, #0x20
   4:	str	x0, [sp, #24]
   8:	ldr	x8, [sp, #24]
   c:	str	x8, [sp, #16]
  10:	ldr	x8, [sp, #16]
  14:	ldr	x9, [sp, #16]
  18:	lsr	x9, x9, #1
  1c:	and	x9, x9, #0x5555555555555555
  20:	subs	x8, x8, x9
  24:	str	x8, [sp, #16]
  28:	ldr	x8, [sp, #16]
  2c:	lsr	x8, x8, #2
  30:	and	x8, x8, #0x3333333333333333
  34:	ldr	x9, [sp, #16]
  38:	and	x9, x9, #0x3333333333333333
  3c:	add	x8, x8, x9
  40:	str	x8, [sp, #16]
  44:	ldr	x8, [sp, #16]
  48:	ldr	x9, [sp, #16]
  4c:	add	x8, x8, x9, lsr #4
  50:	and	x8, x8, #0xf0f0f0f0f0f0f0f
  54:	str	x8, [sp, #16]
  58:	ldr	x8, [sp, #16]
  5c:	ldr	x9, [sp, #16]
  60:	add	x8, x8, x9, lsr #32
  64:	str	w8, [sp, #12]
  68:	ldr	w8, [sp, #12]
  6c:	ldr	w10, [sp, #12]
  70:	add	w8, w8, w10, lsr #16
  74:	str	w8, [sp, #12]
  78:	ldr	w8, [sp, #12]
  7c:	ldr	w10, [sp, #12]
  80:	add	w8, w8, w10, lsr #8
  84:	and	w0, w8, #0x7f
  88:	add	sp, sp, #0x20
  8c:	ret

popcountsi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__popcountsi2>:
   0:	sub	sp, sp, #0x10
   4:	str	w0, [sp, #12]
   8:	ldr	w8, [sp, #12]
   c:	str	w8, [sp, #8]
  10:	ldr	w8, [sp, #8]
  14:	ldr	w9, [sp, #8]
  18:	lsr	w9, w9, #1
  1c:	and	w9, w9, #0x55555555
  20:	subs	w8, w8, w9
  24:	str	w8, [sp, #8]
  28:	ldr	w8, [sp, #8]
  2c:	lsr	w8, w8, #2
  30:	and	w8, w8, #0x33333333
  34:	ldr	w9, [sp, #8]
  38:	and	w9, w9, #0x33333333
  3c:	add	w8, w8, w9
  40:	str	w8, [sp, #8]
  44:	ldr	w8, [sp, #8]
  48:	ldr	w9, [sp, #8]
  4c:	add	w8, w8, w9, lsr #4
  50:	and	w8, w8, #0xf0f0f0f
  54:	str	w8, [sp, #8]
  58:	ldr	w8, [sp, #8]
  5c:	ldr	w9, [sp, #8]
  60:	add	w8, w8, w9, lsr #16
  64:	str	w8, [sp, #8]
  68:	ldr	w8, [sp, #8]
  6c:	ldr	w9, [sp, #8]
  70:	add	w8, w8, w9, lsr #8
  74:	and	w0, w8, #0x3f
  78:	add	sp, sp, #0x10
  7c:	ret

popcountti2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__popcountti2>:
   0:	sub	sp, sp, #0x30
   4:	str	x1, [sp, #40]
   8:	str	x0, [sp, #32]
   c:	ldr	x8, [sp, #32]
  10:	ldr	x9, [sp, #40]
  14:	str	x9, [sp, #24]
  18:	str	x8, [sp, #16]
  1c:	ldr	x8, [sp, #24]
  20:	ldr	x9, [sp, #16]
  24:	lsr	x10, x9, #1
  28:	lsr	x11, x8, #1
  2c:	and	x11, x11, #0x5555555555555555
  30:	and	x10, x10, #0x5555555555555555
  34:	subs	x9, x9, x10
  38:	sbcs	x8, x8, x11
  3c:	str	x9, [sp, #16]
  40:	str	x8, [sp, #24]
  44:	ldr	x8, [sp, #24]
  48:	ldr	x9, [sp, #16]
  4c:	lsr	x10, x9, #2
  50:	lsr	x11, x8, #2
  54:	and	x11, x11, #0x3333333333333333
  58:	and	x10, x10, #0x3333333333333333
  5c:	and	x8, x8, #0x3333333333333333
  60:	and	x9, x9, #0x3333333333333333
  64:	add	x9, x10, x9
  68:	add	x8, x11, x8
  6c:	str	x8, [sp, #24]
  70:	str	x9, [sp, #16]
  74:	ldr	x8, [sp, #16]
  78:	ldr	x9, [sp, #24]
  7c:	extr	x10, x9, x8, #4
  80:	lsr	x11, x9, #4
  84:	adds	x8, x8, x10
  88:	adcs	x9, x9, x11
  8c:	and	x9, x9, #0xf0f0f0f0f0f0f0f
  90:	and	x8, x8, #0xf0f0f0f0f0f0f0f
  94:	str	x8, [sp, #16]
  98:	str	x9, [sp, #24]
  9c:	ldr	x8, [sp, #24]
  a0:	ldr	x9, [sp, #16]
  a4:	add	x8, x9, x8
  a8:	str	x8, [sp, #8]
  ac:	ldr	w12, [sp, #12]
  b0:	ldr	w13, [sp, #8]
  b4:	add	w12, w13, w12
  b8:	mov	w0, w12
  bc:	str	w0, [sp, #4]
  c0:	ldr	w12, [sp, #4]
  c4:	add	w12, w12, w12, lsr #16
  c8:	str	w12, [sp, #4]
  cc:	ldr	w12, [sp, #4]
  d0:	add	w12, w12, w12, lsr #8
  d4:	and	w0, w12, #0xff
  d8:	add	sp, sp, #0x30
  dc:	ret

powidf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__powidf2>:
   0:	sub	sp, sp, #0x20
   4:	fmov	d1, #1.000000000000000000e+00
   8:	str	d0, [sp, #24]
   c:	str	w0, [sp, #20]
  10:	ldr	w8, [sp, #20]
  14:	cmp	w8, #0x0
  18:	cset	w8, lt  // lt = tstop
  1c:	and	w8, w8, #0x1
  20:	str	w8, [sp, #16]
  24:	str	d1, [sp, #8]
  28:	ldr	w8, [sp, #20]
  2c:	and	w8, w8, #0x1
  30:	cbz	w8, 44 <__powidf2+0x44>
  34:	ldr	d0, [sp, #24]
  38:	ldr	d1, [sp, #8]
  3c:	fmul	d0, d1, d0
  40:	str	d0, [sp, #8]
  44:	ldr	w8, [sp, #20]
  48:	mov	w9, #0x2                   	// #2
  4c:	sdiv	w8, w8, w9
  50:	str	w8, [sp, #20]
  54:	ldr	w8, [sp, #20]
  58:	cbnz	w8, 60 <__powidf2+0x60>
  5c:	b	74 <__powidf2+0x74>
  60:	ldr	d0, [sp, #24]
  64:	ldr	d1, [sp, #24]
  68:	fmul	d0, d1, d0
  6c:	str	d0, [sp, #24]
  70:	b	28 <__powidf2+0x28>
  74:	ldr	w8, [sp, #16]
  78:	cbz	w8, 90 <__powidf2+0x90>
  7c:	ldr	d0, [sp, #8]
  80:	fmov	d1, #1.000000000000000000e+00
  84:	fdiv	d0, d1, d0
  88:	str	d0, [sp]
  8c:	b	9c <__powidf2+0x9c>
  90:	ldr	x8, [sp, #8]
  94:	fmov	d0, x8
  98:	str	d0, [sp]
  9c:	ldr	d0, [sp]
  a0:	add	sp, sp, #0x20
  a4:	ret

powisf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__powisf2>:
   0:	sub	sp, sp, #0x20
   4:	fmov	s1, #1.000000000000000000e+00
   8:	str	s0, [sp, #28]
   c:	str	w0, [sp, #24]
  10:	ldr	w8, [sp, #24]
  14:	cmp	w8, #0x0
  18:	cset	w8, lt  // lt = tstop
  1c:	and	w8, w8, #0x1
  20:	str	w8, [sp, #20]
  24:	str	s1, [sp, #16]
  28:	ldr	w8, [sp, #24]
  2c:	and	w8, w8, #0x1
  30:	cbz	w8, 44 <__powisf2+0x44>
  34:	ldr	s0, [sp, #28]
  38:	ldr	s1, [sp, #16]
  3c:	fmul	s0, s1, s0
  40:	str	s0, [sp, #16]
  44:	ldr	w8, [sp, #24]
  48:	mov	w9, #0x2                   	// #2
  4c:	sdiv	w8, w8, w9
  50:	str	w8, [sp, #24]
  54:	ldr	w8, [sp, #24]
  58:	cbnz	w8, 60 <__powisf2+0x60>
  5c:	b	74 <__powisf2+0x74>
  60:	ldr	s0, [sp, #28]
  64:	ldr	s1, [sp, #28]
  68:	fmul	s0, s1, s0
  6c:	str	s0, [sp, #28]
  70:	b	28 <__powisf2+0x28>
  74:	ldr	w8, [sp, #20]
  78:	cbz	w8, 90 <__powisf2+0x90>
  7c:	ldr	s0, [sp, #16]
  80:	fmov	s1, #1.000000000000000000e+00
  84:	fdiv	s0, s1, s0
  88:	str	s0, [sp, #12]
  8c:	b	9c <__powisf2+0x9c>
  90:	ldr	w8, [sp, #16]
  94:	fmov	s0, w8
  98:	str	s0, [sp, #12]
  9c:	ldr	s0, [sp, #12]
  a0:	add	sp, sp, #0x20
  a4:	ret

powitf2.c.o:     file format elf64-littleaarch64


subdf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__subdf3>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	stur	d0, [x29, #-8]
  10:	str	d1, [sp, #16]
  14:	ldur	d0, [x29, #-8]
  18:	ldr	d1, [sp, #16]
  1c:	str	d0, [sp, #8]
  20:	mov	v0.16b, v1.16b
  24:	bl	6c <toRep>
  28:	eor	x0, x0, #0x8000000000000000
  2c:	bl	50 <fromRep>
  30:	ldr	d1, [sp, #8]
  34:	str	d0, [sp]
  38:	mov	v0.16b, v1.16b
  3c:	ldr	d1, [sp]
  40:	bl	0 <__adddf3>
  44:	ldp	x29, x30, [sp, #32]
  48:	add	sp, sp, #0x30
  4c:	ret

0000000000000050 <fromRep>:
  50:	sub	sp, sp, #0x10
  54:	str	x0, [sp, #8]
  58:	ldr	x8, [sp, #8]
  5c:	str	x8, [sp]
  60:	ldr	d0, [sp]
  64:	add	sp, sp, #0x10
  68:	ret

000000000000006c <toRep>:
  6c:	sub	sp, sp, #0x10
  70:	str	d0, [sp, #8]
  74:	ldr	x8, [sp, #8]
  78:	str	x8, [sp]
  7c:	ldr	x0, [sp]
  80:	add	sp, sp, #0x10
  84:	ret

subsf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__subsf3>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	str	s1, [sp, #8]
  14:	ldur	s0, [x29, #-4]
  18:	ldr	s1, [sp, #8]
  1c:	str	s0, [sp, #4]
  20:	mov	v0.16b, v1.16b
  24:	bl	6c <toRep>
  28:	eor	w0, w0, #0x80000000
  2c:	bl	50 <fromRep>
  30:	ldr	s1, [sp, #4]
  34:	str	s0, [sp]
  38:	mov	v0.16b, v1.16b
  3c:	ldr	s1, [sp]
  40:	bl	0 <__addsf3>
  44:	ldp	x29, x30, [sp, #16]
  48:	add	sp, sp, #0x20
  4c:	ret

0000000000000050 <fromRep>:
  50:	sub	sp, sp, #0x10
  54:	str	w0, [sp, #12]
  58:	ldr	w8, [sp, #12]
  5c:	str	w8, [sp, #8]
  60:	ldr	s0, [sp, #8]
  64:	add	sp, sp, #0x10
  68:	ret

000000000000006c <toRep>:
  6c:	sub	sp, sp, #0x10
  70:	str	s0, [sp, #12]
  74:	ldr	w8, [sp, #12]
  78:	str	w8, [sp, #8]
  7c:	ldr	w0, [sp, #8]
  80:	add	sp, sp, #0x10
  84:	ret

subvdi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__subvdi3>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	stur	x0, [x29, #-8]
  10:	str	x1, [sp, #16]
  14:	ldur	x8, [x29, #-8]
  18:	ldr	x9, [sp, #16]
  1c:	subs	x8, x8, x9
  20:	str	x8, [sp, #8]
  24:	ldr	x8, [sp, #16]
  28:	cmp	x8, #0x0
  2c:	cset	w10, lt  // lt = tstop
  30:	tbnz	w10, #0, 60 <__subvdi3+0x60>
  34:	ldr	x8, [sp, #8]
  38:	ldur	x9, [x29, #-8]
  3c:	cmp	x8, x9
  40:	b.le	5c <__subvdi3+0x5c>
  44:	adrp	x0, 0 <__subvdi3>
  48:	add	x0, x0, #0x0
  4c:	mov	w1, #0x17                  	// #23
  50:	adrp	x2, 0 <__subvdi3>
  54:	add	x2, x2, #0x0
  58:	bl	0 <__compilerrt_abort_impl>
  5c:	b	88 <__subvdi3+0x88>
  60:	ldr	x8, [sp, #8]
  64:	ldur	x9, [x29, #-8]
  68:	cmp	x8, x9
  6c:	b.gt	88 <__subvdi3+0x88>
  70:	adrp	x0, 0 <__subvdi3>
  74:	add	x0, x0, #0x0
  78:	mov	w1, #0x1a                  	// #26
  7c:	adrp	x2, 0 <__subvdi3>
  80:	add	x2, x2, #0x0
  84:	bl	0 <__compilerrt_abort_impl>
  88:	ldr	x0, [sp, #8]
  8c:	ldp	x29, x30, [sp, #32]
  90:	add	sp, sp, #0x30
  94:	ret

subvsi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__subvsi3>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	w0, [x29, #-4]
  10:	str	w1, [sp, #8]
  14:	ldur	w8, [x29, #-4]
  18:	ldr	w9, [sp, #8]
  1c:	subs	w8, w8, w9
  20:	str	w8, [sp, #4]
  24:	ldr	w8, [sp, #8]
  28:	cmp	w8, #0x0
  2c:	cset	w8, lt  // lt = tstop
  30:	tbnz	w8, #0, 60 <__subvsi3+0x60>
  34:	ldr	w8, [sp, #4]
  38:	ldur	w9, [x29, #-4]
  3c:	cmp	w8, w9
  40:	b.le	5c <__subvsi3+0x5c>
  44:	adrp	x0, 0 <__subvsi3>
  48:	add	x0, x0, #0x0
  4c:	mov	w1, #0x17                  	// #23
  50:	adrp	x2, 0 <__subvsi3>
  54:	add	x2, x2, #0x0
  58:	bl	0 <__compilerrt_abort_impl>
  5c:	b	88 <__subvsi3+0x88>
  60:	ldr	w8, [sp, #4]
  64:	ldur	w9, [x29, #-4]
  68:	cmp	w8, w9
  6c:	b.gt	88 <__subvsi3+0x88>
  70:	adrp	x0, 0 <__subvsi3>
  74:	add	x0, x0, #0x0
  78:	mov	w1, #0x1a                  	// #26
  7c:	adrp	x2, 0 <__subvsi3>
  80:	add	x2, x2, #0x0
  84:	bl	0 <__compilerrt_abort_impl>
  88:	ldr	w0, [sp, #4]
  8c:	ldp	x29, x30, [sp, #16]
  90:	add	sp, sp, #0x20
  94:	ret

subvti3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__subvti3>:
   0:	sub	sp, sp, #0x40
   4:	stp	x29, x30, [sp, #48]
   8:	add	x29, sp, #0x30
   c:	stur	x1, [x29, #-8]
  10:	stur	x0, [x29, #-16]
  14:	str	x3, [sp, #24]
  18:	str	x2, [sp, #16]
  1c:	ldur	x8, [x29, #-8]
  20:	ldur	x9, [x29, #-16]
  24:	ldr	x10, [sp, #24]
  28:	ldr	x11, [sp, #16]
  2c:	subs	x9, x9, x11
  30:	sbcs	x8, x8, x10
  34:	str	x9, [sp]
  38:	str	x8, [sp, #8]
  3c:	ldr	x8, [sp, #24]
  40:	tbnz	x8, #63, 90 <__subvti3+0x90>
  44:	b	48 <__subvti3+0x48>
  48:	ldr	x8, [sp, #8]
  4c:	ldr	x9, [sp]
  50:	ldur	x10, [x29, #-8]
  54:	ldur	x11, [x29, #-16]
  58:	subs	x9, x9, x11
  5c:	cset	w12, ls  // ls = plast
  60:	subs	x8, x8, x10
  64:	cset	w13, le
  68:	csel	w12, w12, w13, eq  // eq = none
  6c:	tbnz	w12, #0, 8c <__subvti3+0x8c>
  70:	b	74 <__subvti3+0x74>
  74:	adrp	x0, 0 <__subvti3>
  78:	add	x0, x0, #0x0
  7c:	adrp	x2, 0 <__subvti3>
  80:	add	x2, x2, #0x0
  84:	mov	w1, #0x19                  	// #25
  88:	bl	0 <__compilerrt_abort_impl>
  8c:	b	d8 <__subvti3+0xd8>
  90:	ldr	x8, [sp, #8]
  94:	ldr	x9, [sp]
  98:	ldur	x10, [x29, #-8]
  9c:	ldur	x11, [x29, #-16]
  a0:	subs	x9, x9, x11
  a4:	cset	w12, hi  // hi = pmore
  a8:	subs	x8, x8, x10
  ac:	cset	w13, gt
  b0:	csel	w12, w12, w13, eq  // eq = none
  b4:	tbnz	w12, #0, d4 <__subvti3+0xd4>
  b8:	b	bc <__subvti3+0xbc>
  bc:	adrp	x0, 0 <__subvti3>
  c0:	add	x0, x0, #0x0
  c4:	adrp	x2, 0 <__subvti3>
  c8:	add	x2, x2, #0x0
  cc:	mov	w1, #0x1c                  	// #28
  d0:	bl	0 <__compilerrt_abort_impl>
  d4:	b	d8 <__subvti3+0xd8>
  d8:	ldr	x0, [sp]
  dc:	ldr	x1, [sp, #8]
  e0:	ldp	x29, x30, [sp, #48]
  e4:	add	sp, sp, #0x40
  e8:	ret

subtf3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__subtf3>:
   0:	sub	sp, sp, #0x60
   4:	stp	x29, x30, [sp, #80]
   8:	add	x29, sp, #0x50
   c:	mov	x8, xzr
  10:	stur	q0, [x29, #-16]
  14:	stur	q1, [x29, #-32]
  18:	ldur	q0, [x29, #-16]
  1c:	ldur	q1, [x29, #-32]
  20:	str	q0, [sp, #32]
  24:	mov	v0.16b, v1.16b
  28:	str	x8, [sp, #24]
  2c:	bl	84 <toRep>
  30:	ldr	x8, [sp, #24]
  34:	eor	x0, x0, x8
  38:	eor	x1, x1, #0x8000000000000000
  3c:	bl	60 <fromRep>
  40:	ldr	q1, [sp, #32]
  44:	str	q0, [sp]
  48:	mov	v0.16b, v1.16b
  4c:	ldr	q1, [sp]
  50:	bl	0 <__addtf3>
  54:	ldp	x29, x30, [sp, #80]
  58:	add	sp, sp, #0x60
  5c:	ret

0000000000000060 <fromRep>:
  60:	sub	sp, sp, #0x20
  64:	mov	v0.d[0], x0
  68:	mov	v0.d[1], x1
  6c:	str	q0, [sp, #16]
  70:	ldr	q0, [sp, #16]
  74:	str	q0, [sp]
  78:	ldr	q0, [sp]
  7c:	add	sp, sp, #0x20
  80:	ret

0000000000000084 <toRep>:
  84:	sub	sp, sp, #0x20
  88:	str	q0, [sp, #16]
  8c:	ldr	q0, [sp, #16]
  90:	str	q0, [sp]
  94:	ldr	x0, [sp]
  98:	ldr	x1, [sp, #8]
  9c:	add	sp, sp, #0x20
  a0:	ret

trampoline_setup.c.o:     file format elf64-littleaarch64


truncdfhf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__truncdfhf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp, #8]
  10:	ldr	d0, [sp, #8]
  14:	bl	24 <__truncXfYf2__>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__truncXfYf2__>:
  24:	sub	sp, sp, #0x140
  28:	stp	x29, x30, [sp, #256]
  2c:	stp	x28, x23, [sp, #272]
  30:	stp	x22, x21, [sp, #288]
  34:	stp	x20, x19, [sp, #304]
  38:	add	x29, sp, #0x100
  3c:	sub	x8, x29, #0x60
  40:	mov	w9, #0x40                  	// #64
  44:	mov	w10, #0xb                   	// #11
  48:	mov	w11, #0x7ff                 	// #2047
  4c:	mov	w12, #0x3ff                 	// #1023
  50:	mov	x13, #0x10000000000000      	// #4503599627370496
  54:	mov	x14, #0xfffffffffffff       	// #4503599627370495
  58:	mov	x15, #0x7ff0000000000000    	// #9218868437227405312
  5c:	mov	x16, #0x8000000000000000    	// #-9223372036854775808
  60:	mov	x17, #0x7fffffffffffffff    	// #9223372036854775807
  64:	mov	x18, #0x3ffffffffff         	// #4398046511103
  68:	mov	x0, #0x20000000000         	// #2199023255552
  6c:	mov	x1, #0x8000000000000       	// #2251799813685248
  70:	mov	x2, #0x7ffffffffffff       	// #2251799813685247
  74:	mov	w3, #0x10                  	// #16
  78:	mov	w4, #0x5                   	// #5
  7c:	mov	w5, #0x1f                  	// #31
  80:	mov	w6, #0xf                   	// #15
  84:	mov	w7, #0x3f1                 	// #1009
  88:	mov	w19, #0x40f                 	// #1039
  8c:	mov	x20, #0x3f10000000000000    	// #4544132024016830464
  90:	mov	x21, #0x40f0000000000000    	// #4679240012837945344
  94:	mov	w22, #0x200                 	// #512
  98:	mov	w23, #0x1ff                 	// #511
  9c:	str	d0, [x8, #88]
  a0:	str	w9, [x8, #84]
  a4:	str	w10, [x8, #80]
  a8:	str	w11, [x8, #76]
  ac:	str	w12, [x8, #72]
  b0:	str	x13, [x8, #64]
  b4:	str	x14, [x8, #56]
  b8:	str	x15, [x8, #48]
  bc:	str	x16, [x8, #40]
  c0:	str	x17, [x8, #32]
  c4:	str	x18, [x8, #24]
  c8:	str	x0, [x8, #16]
  cc:	str	x1, [x8, #8]
  d0:	str	x2, [x8]
  d4:	stur	w3, [x29, #-100]
  d8:	stur	w4, [x29, #-104]
  dc:	stur	w5, [x29, #-108]
  e0:	stur	w6, [x29, #-112]
  e4:	stur	w7, [x29, #-116]
  e8:	stur	w19, [x29, #-120]
  ec:	str	x20, [sp, #128]
  f0:	str	x21, [sp, #120]
  f4:	strh	w22, [sp, #118]
  f8:	strh	w23, [sp, #116]
  fc:	ldr	d0, [x8, #88]
 100:	str	x20, [sp, #16]
 104:	str	x21, [sp, #8]
 108:	bl	33c <srcToRep>
 10c:	str	x0, [sp, #104]
 110:	ldr	x8, [sp, #104]
 114:	and	x8, x8, #0x7fffffffffffffff
 118:	str	x8, [sp, #96]
 11c:	ldr	x8, [sp, #104]
 120:	and	x8, x8, #0x8000000000000000
 124:	str	x8, [sp, #88]
 128:	ldr	x8, [sp, #96]
 12c:	ldr	x13, [sp, #16]
 130:	subs	x8, x8, x13
 134:	ldr	x14, [sp, #96]
 138:	ldr	x15, [sp, #8]
 13c:	subs	x14, x14, x15
 140:	cmp	x8, x14
 144:	b.cs	1b4 <__truncXfYf2__+0x190>  // b.hs, b.nlast
 148:	ldr	x8, [sp, #96]
 14c:	lsr	x8, x8, #42
 150:	strh	w8, [sp, #86]
 154:	ldrh	w8, [sp, #86]
 158:	subs	w8, w8, #0xfc, lsl #12
 15c:	strh	w8, [sp, #86]
 160:	ldr	x9, [sp, #96]
 164:	and	x9, x9, #0x3ffffffffff
 168:	str	x9, [sp, #72]
 16c:	ldr	x9, [sp, #72]
 170:	mov	x10, #0x20000000000         	// #2199023255552
 174:	cmp	x9, x10
 178:	b.ls	18c <__truncXfYf2__+0x168>  // b.plast
 17c:	ldrh	w8, [sp, #86]
 180:	add	w8, w8, #0x1
 184:	strh	w8, [sp, #86]
 188:	b	1b0 <__truncXfYf2__+0x18c>
 18c:	ldr	x8, [sp, #72]
 190:	mov	x9, #0x20000000000         	// #2199023255552
 194:	cmp	x8, x9
 198:	b.ne	1b0 <__truncXfYf2__+0x18c>  // b.any
 19c:	ldrh	w8, [sp, #86]
 1a0:	and	w8, w8, #0x1
 1a4:	ldrh	w9, [sp, #86]
 1a8:	add	w8, w9, w8
 1ac:	strh	w8, [sp, #86]
 1b0:	b	308 <__truncXfYf2__+0x2e4>
 1b4:	ldr	x8, [sp, #96]
 1b8:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 1bc:	cmp	x8, x9
 1c0:	b.ls	1fc <__truncXfYf2__+0x1d8>  // b.plast
 1c4:	mov	w8, #0x7c00                	// #31744
 1c8:	strh	w8, [sp, #86]
 1cc:	ldrh	w8, [sp, #86]
 1d0:	orr	w8, w8, #0x200
 1d4:	strh	w8, [sp, #86]
 1d8:	ldr	x9, [sp, #96]
 1dc:	and	x9, x9, #0x7ffffffffffff
 1e0:	lsr	x9, x9, #42
 1e4:	and	x9, x9, #0x1ff
 1e8:	ldrh	w8, [sp, #86]
 1ec:	mov	w10, w8
 1f0:	orr	x9, x10, x9
 1f4:	strh	w9, [sp, #86]
 1f8:	b	308 <__truncXfYf2__+0x2e4>
 1fc:	ldr	x8, [sp, #96]
 200:	mov	x9, #0x40f0000000000000    	// #4679240012837945344
 204:	cmp	x8, x9
 208:	b.cc	218 <__truncXfYf2__+0x1f4>  // b.lo, b.ul, b.last
 20c:	mov	w8, #0x7c00                	// #31744
 210:	strh	w8, [sp, #86]
 214:	b	308 <__truncXfYf2__+0x2e4>
 218:	ldr	x8, [sp, #96]
 21c:	lsr	x8, x8, #52
 220:	str	w8, [sp, #68]
 224:	ldr	w8, [sp, #68]
 228:	mov	w9, #0x3f0                 	// #1008
 22c:	subs	w8, w9, w8
 230:	add	w8, w8, #0x1
 234:	str	w8, [sp, #64]
 238:	ldr	x10, [sp, #104]
 23c:	and	x10, x10, #0xfffffffffffff
 240:	orr	x10, x10, #0x10000000000000
 244:	str	x10, [sp, #56]
 248:	ldr	w8, [sp, #64]
 24c:	cmp	w8, #0x34
 250:	b.le	260 <__truncXfYf2__+0x23c>
 254:	mov	w8, #0x0                   	// #0
 258:	strh	w8, [sp, #86]
 25c:	b	308 <__truncXfYf2__+0x2e4>
 260:	ldr	x8, [sp, #56]
 264:	ldr	w9, [sp, #64]
 268:	mov	w10, #0x40                  	// #64
 26c:	subs	w9, w10, w9
 270:	mov	w11, w9
 274:	lsl	x8, x8, x11
 278:	cmp	x8, #0x0
 27c:	cset	w9, ne  // ne = any
 280:	and	w9, w9, #0x1
 284:	strb	w9, [sp, #55]
 288:	ldr	x8, [sp, #56]
 28c:	ldr	w9, [sp, #64]
 290:	mov	w11, w9
 294:	lsr	x8, x8, x11
 298:	ldrb	w9, [sp, #55]
 29c:	mov	w0, w9
 2a0:	and	x11, x0, #0x1
 2a4:	orr	x8, x8, x11
 2a8:	str	x8, [sp, #40]
 2ac:	ldr	x8, [sp, #40]
 2b0:	lsr	x8, x8, #42
 2b4:	strh	w8, [sp, #86]
 2b8:	ldr	x11, [sp, #40]
 2bc:	and	x11, x11, #0x3ffffffffff
 2c0:	str	x11, [sp, #32]
 2c4:	ldr	x11, [sp, #32]
 2c8:	mov	x12, #0x20000000000         	// #2199023255552
 2cc:	cmp	x11, x12
 2d0:	b.ls	2e4 <__truncXfYf2__+0x2c0>  // b.plast
 2d4:	ldrh	w8, [sp, #86]
 2d8:	add	w8, w8, #0x1
 2dc:	strh	w8, [sp, #86]
 2e0:	b	308 <__truncXfYf2__+0x2e4>
 2e4:	ldr	x8, [sp, #32]
 2e8:	mov	x9, #0x20000000000         	// #2199023255552
 2ec:	cmp	x8, x9
 2f0:	b.ne	308 <__truncXfYf2__+0x2e4>  // b.any
 2f4:	ldrh	w8, [sp, #86]
 2f8:	and	w8, w8, #0x1
 2fc:	ldrh	w9, [sp, #86]
 300:	add	w8, w9, w8
 304:	strh	w8, [sp, #86]
 308:	ldrh	w8, [sp, #86]
 30c:	mov	w9, w8
 310:	ldr	x10, [sp, #88]
 314:	orr	x9, x9, x10, lsr #48
 318:	strh	w9, [sp, #30]
 31c:	ldrh	w0, [sp, #30]
 320:	bl	358 <dstFromRep>
 324:	ldp	x20, x19, [sp, #304]
 328:	ldp	x22, x21, [sp, #288]
 32c:	ldp	x28, x23, [sp, #272]
 330:	ldp	x29, x30, [sp, #256]
 334:	add	sp, sp, #0x140
 338:	ret

000000000000033c <srcToRep>:
 33c:	sub	sp, sp, #0x10
 340:	str	d0, [sp, #8]
 344:	ldr	x8, [sp, #8]
 348:	str	x8, [sp]
 34c:	ldr	x0, [sp]
 350:	add	sp, sp, #0x10
 354:	ret

0000000000000358 <dstFromRep>:
 358:	sub	sp, sp, #0x10
 35c:	strh	w0, [sp, #14]
 360:	ldrh	w8, [sp, #14]
 364:	strh	w8, [sp, #12]
 368:	ldrh	w0, [sp, #12]
 36c:	add	sp, sp, #0x10
 370:	ret

truncdfsf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__truncdfsf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	str	d0, [sp, #8]
  10:	ldr	d0, [sp, #8]
  14:	bl	24 <__truncXfYf2__>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__truncXfYf2__>:
  24:	sub	sp, sp, #0x140
  28:	stp	x29, x30, [sp, #256]
  2c:	stp	x28, x23, [sp, #272]
  30:	stp	x22, x21, [sp, #288]
  34:	stp	x20, x19, [sp, #304]
  38:	add	x29, sp, #0x100
  3c:	sub	x8, x29, #0x60
  40:	mov	w9, #0x40                  	// #64
  44:	mov	w10, #0xb                   	// #11
  48:	mov	w11, #0x7ff                 	// #2047
  4c:	mov	w12, #0x3ff                 	// #1023
  50:	mov	x13, #0x10000000000000      	// #4503599627370496
  54:	mov	x14, #0xfffffffffffff       	// #4503599627370495
  58:	mov	x15, #0x7ff0000000000000    	// #9218868437227405312
  5c:	mov	x16, #0x8000000000000000    	// #-9223372036854775808
  60:	mov	x17, #0x7fffffffffffffff    	// #9223372036854775807
  64:	mov	x18, #0x1fffffff            	// #536870911
  68:	mov	x0, #0x10000000            	// #268435456
  6c:	mov	x1, #0x8000000000000       	// #2251799813685248
  70:	mov	x2, #0x7ffffffffffff       	// #2251799813685247
  74:	mov	w3, #0x20                  	// #32
  78:	mov	w4, #0x8                   	// #8
  7c:	mov	w5, #0xff                  	// #255
  80:	mov	w6, #0x7f                  	// #127
  84:	mov	w7, #0x381                 	// #897
  88:	mov	w19, #0x47f                 	// #1151
  8c:	mov	x20, #0x3810000000000000    	// #4039728865751334912
  90:	mov	x21, #0x47f0000000000000    	// #5183643171103440896
  94:	mov	w22, #0x400000              	// #4194304
  98:	mov	w23, #0x3fffff              	// #4194303
  9c:	str	d0, [x8, #88]
  a0:	stur	w9, [x29, #-12]
  a4:	stur	w10, [x29, #-16]
  a8:	stur	w11, [x29, #-20]
  ac:	stur	w12, [x29, #-24]
  b0:	str	x13, [x8, #64]
  b4:	str	x14, [x8, #56]
  b8:	str	x15, [x8, #48]
  bc:	str	x16, [x8, #40]
  c0:	str	x17, [x8, #32]
  c4:	str	x18, [x8, #24]
  c8:	str	x0, [x8, #16]
  cc:	str	x1, [x8, #8]
  d0:	str	x2, [x8]
  d4:	stur	w3, [x29, #-100]
  d8:	stur	w4, [x29, #-104]
  dc:	stur	w5, [x29, #-108]
  e0:	stur	w6, [x29, #-112]
  e4:	stur	w7, [x29, #-116]
  e8:	stur	w19, [x29, #-120]
  ec:	str	x20, [sp, #128]
  f0:	str	x21, [sp, #120]
  f4:	str	w22, [sp, #116]
  f8:	str	w23, [sp, #112]
  fc:	ldr	d0, [x8, #88]
 100:	str	x20, [sp, #16]
 104:	str	x21, [sp, #8]
 108:	bl	33c <srcToRep>
 10c:	str	x0, [sp, #104]
 110:	ldr	x8, [sp, #104]
 114:	and	x8, x8, #0x7fffffffffffffff
 118:	str	x8, [sp, #96]
 11c:	ldr	x8, [sp, #104]
 120:	and	x8, x8, #0x8000000000000000
 124:	str	x8, [sp, #88]
 128:	ldr	x8, [sp, #96]
 12c:	ldr	x13, [sp, #16]
 130:	subs	x8, x8, x13
 134:	ldr	x14, [sp, #96]
 138:	ldr	x15, [sp, #8]
 13c:	subs	x14, x14, x15
 140:	cmp	x8, x14
 144:	b.cs	1b8 <__truncXfYf2__+0x194>  // b.hs, b.nlast
 148:	ldr	x8, [sp, #96]
 14c:	lsr	x8, x8, #29
 150:	str	w8, [sp, #84]
 154:	ldr	w8, [sp, #84]
 158:	mov	w9, #0xc0000000            	// #-1073741824
 15c:	subs	w8, w8, w9
 160:	str	w8, [sp, #84]
 164:	ldr	x10, [sp, #96]
 168:	and	x10, x10, #0x1fffffff
 16c:	str	x10, [sp, #72]
 170:	ldr	x10, [sp, #72]
 174:	mov	x11, #0x10000000            	// #268435456
 178:	cmp	x10, x11
 17c:	b.ls	190 <__truncXfYf2__+0x16c>  // b.plast
 180:	ldr	w8, [sp, #84]
 184:	add	w8, w8, #0x1
 188:	str	w8, [sp, #84]
 18c:	b	1b4 <__truncXfYf2__+0x190>
 190:	ldr	x8, [sp, #72]
 194:	mov	x9, #0x10000000            	// #268435456
 198:	cmp	x8, x9
 19c:	b.ne	1b4 <__truncXfYf2__+0x190>  // b.any
 1a0:	ldr	w8, [sp, #84]
 1a4:	and	w8, w8, #0x1
 1a8:	ldr	w9, [sp, #84]
 1ac:	add	w8, w9, w8
 1b0:	str	w8, [sp, #84]
 1b4:	b	308 <__truncXfYf2__+0x2e4>
 1b8:	ldr	x8, [sp, #96]
 1bc:	mov	x9, #0x7ff0000000000000    	// #9218868437227405312
 1c0:	cmp	x8, x9
 1c4:	b.ls	200 <__truncXfYf2__+0x1dc>  // b.plast
 1c8:	mov	w8, #0x7f800000            	// #2139095040
 1cc:	str	w8, [sp, #84]
 1d0:	ldr	w8, [sp, #84]
 1d4:	orr	w8, w8, #0x400000
 1d8:	str	w8, [sp, #84]
 1dc:	ldr	x9, [sp, #96]
 1e0:	and	x9, x9, #0x7ffffffffffff
 1e4:	lsr	x9, x9, #29
 1e8:	and	x9, x9, #0x3fffff
 1ec:	ldr	w8, [sp, #84]
 1f0:	mov	w10, w8
 1f4:	orr	x9, x10, x9
 1f8:	str	w9, [sp, #84]
 1fc:	b	308 <__truncXfYf2__+0x2e4>
 200:	ldr	x8, [sp, #96]
 204:	mov	x9, #0x47f0000000000000    	// #5183643171103440896
 208:	cmp	x8, x9
 20c:	b.cc	21c <__truncXfYf2__+0x1f8>  // b.lo, b.ul, b.last
 210:	mov	w8, #0x7f800000            	// #2139095040
 214:	str	w8, [sp, #84]
 218:	b	308 <__truncXfYf2__+0x2e4>
 21c:	ldr	x8, [sp, #96]
 220:	lsr	x8, x8, #52
 224:	str	w8, [sp, #68]
 228:	ldr	w8, [sp, #68]
 22c:	mov	w9, #0x380                 	// #896
 230:	subs	w8, w9, w8
 234:	add	w8, w8, #0x1
 238:	str	w8, [sp, #64]
 23c:	ldr	x10, [sp, #104]
 240:	and	x10, x10, #0xfffffffffffff
 244:	orr	x10, x10, #0x10000000000000
 248:	str	x10, [sp, #56]
 24c:	ldr	w8, [sp, #64]
 250:	cmp	w8, #0x34
 254:	b.le	260 <__truncXfYf2__+0x23c>
 258:	str	wzr, [sp, #84]
 25c:	b	308 <__truncXfYf2__+0x2e4>
 260:	ldr	x8, [sp, #56]
 264:	ldr	w9, [sp, #64]
 268:	mov	w10, #0x40                  	// #64
 26c:	subs	w9, w10, w9
 270:	mov	w11, w9
 274:	lsl	x8, x8, x11
 278:	cmp	x8, #0x0
 27c:	cset	w9, ne  // ne = any
 280:	and	w9, w9, #0x1
 284:	strb	w9, [sp, #55]
 288:	ldr	x8, [sp, #56]
 28c:	ldr	w9, [sp, #64]
 290:	mov	w11, w9
 294:	lsr	x8, x8, x11
 298:	ldrb	w9, [sp, #55]
 29c:	mov	w0, w9
 2a0:	and	x11, x0, #0x1
 2a4:	orr	x8, x8, x11
 2a8:	str	x8, [sp, #40]
 2ac:	ldr	x8, [sp, #40]
 2b0:	lsr	x8, x8, #29
 2b4:	str	w8, [sp, #84]
 2b8:	ldr	x11, [sp, #40]
 2bc:	and	x11, x11, #0x1fffffff
 2c0:	str	x11, [sp, #32]
 2c4:	ldr	x11, [sp, #32]
 2c8:	mov	x12, #0x10000000            	// #268435456
 2cc:	cmp	x11, x12
 2d0:	b.ls	2e4 <__truncXfYf2__+0x2c0>  // b.plast
 2d4:	ldr	w8, [sp, #84]
 2d8:	add	w8, w8, #0x1
 2dc:	str	w8, [sp, #84]
 2e0:	b	308 <__truncXfYf2__+0x2e4>
 2e4:	ldr	x8, [sp, #32]
 2e8:	mov	x9, #0x10000000            	// #268435456
 2ec:	cmp	x8, x9
 2f0:	b.ne	308 <__truncXfYf2__+0x2e4>  // b.any
 2f4:	ldr	w8, [sp, #84]
 2f8:	and	w8, w8, #0x1
 2fc:	ldr	w9, [sp, #84]
 300:	add	w8, w9, w8
 304:	str	w8, [sp, #84]
 308:	ldr	w8, [sp, #84]
 30c:	mov	w9, w8
 310:	ldr	x10, [sp, #88]
 314:	orr	x9, x9, x10, lsr #32
 318:	str	w9, [sp, #28]
 31c:	ldr	w0, [sp, #28]
 320:	bl	358 <dstFromRep>
 324:	ldp	x20, x19, [sp, #304]
 328:	ldp	x22, x21, [sp, #288]
 32c:	ldp	x28, x23, [sp, #272]
 330:	ldp	x29, x30, [sp, #256]
 334:	add	sp, sp, #0x140
 338:	ret

000000000000033c <srcToRep>:
 33c:	sub	sp, sp, #0x10
 340:	str	d0, [sp, #8]
 344:	ldr	x8, [sp, #8]
 348:	str	x8, [sp]
 34c:	ldr	x0, [sp]
 350:	add	sp, sp, #0x10
 354:	ret

0000000000000358 <dstFromRep>:
 358:	sub	sp, sp, #0x10
 35c:	str	w0, [sp, #12]
 360:	ldr	w8, [sp, #12]
 364:	str	w8, [sp, #8]
 368:	ldr	s0, [sp, #8]
 36c:	add	sp, sp, #0x10
 370:	ret

truncsfhf2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__truncsfhf2>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	s0, [x29, #-4]
  10:	ldur	s0, [x29, #-4]
  14:	bl	24 <__truncXfYf2__>
  18:	ldp	x29, x30, [sp, #16]
  1c:	add	sp, sp, #0x20
  20:	ret

0000000000000024 <__truncXfYf2__>:
  24:	sub	sp, sp, #0xe0
  28:	stp	x29, x30, [sp, #160]
  2c:	str	x23, [sp, #176]
  30:	stp	x22, x21, [sp, #192]
  34:	stp	x20, x19, [sp, #208]
  38:	add	x29, sp, #0xa0
  3c:	sub	x8, x29, #0x8
  40:	mov	w9, #0x20                  	// #32
  44:	mov	w10, #0x8                   	// #8
  48:	mov	w11, #0xff                  	// #255
  4c:	mov	w12, #0x7f                  	// #127
  50:	mov	w13, #0x800000              	// #8388608
  54:	mov	w14, #0x7fffff              	// #8388607
  58:	mov	w15, #0x7f800000            	// #2139095040
  5c:	mov	w16, #0x80000000            	// #-2147483648
  60:	mov	w17, #0x7fffffff            	// #2147483647
  64:	mov	w18, #0x1fff                	// #8191
  68:	mov	w0, #0x1000                	// #4096
  6c:	mov	w1, #0x400000              	// #4194304
  70:	mov	w2, #0x3fffff              	// #4194303
  74:	mov	w3, #0x10                  	// #16
  78:	mov	w4, #0x5                   	// #5
  7c:	mov	w5, #0x1f                  	// #31
  80:	mov	w6, #0xf                   	// #15
  84:	mov	w7, #0x71                  	// #113
  88:	mov	w19, #0x8f                  	// #143
  8c:	mov	w20, #0x38800000            	// #947912704
  90:	mov	w21, #0x47800000            	// #1199570944
  94:	mov	w22, #0x200                 	// #512
  98:	mov	w23, #0x1ff                 	// #511
  9c:	str	s0, [x8, #4]
  a0:	str	w9, [x8]
  a4:	stur	w10, [x29, #-12]
  a8:	stur	w11, [x29, #-16]
  ac:	stur	w12, [x29, #-20]
  b0:	stur	w13, [x29, #-24]
  b4:	stur	w14, [x29, #-28]
  b8:	stur	w15, [x29, #-32]
  bc:	stur	w16, [x29, #-36]
  c0:	stur	w17, [x29, #-40]
  c4:	stur	w18, [x29, #-44]
  c8:	stur	w0, [x29, #-48]
  cc:	stur	w1, [x29, #-52]
  d0:	stur	w2, [x29, #-56]
  d4:	stur	w3, [x29, #-60]
  d8:	stur	w4, [x29, #-64]
  dc:	stur	w5, [x29, #-68]
  e0:	stur	w6, [x29, #-72]
  e4:	stur	w7, [x29, #-76]
  e8:	str	w19, [sp, #80]
  ec:	str	w20, [sp, #76]
  f0:	str	w21, [sp, #72]
  f4:	strh	w22, [sp, #70]
  f8:	strh	w23, [sp, #68]
  fc:	ldr	s0, [x8, #4]
 100:	str	w20, [sp, #16]
 104:	str	w21, [sp, #12]
 108:	bl	340 <srcToRep>
 10c:	str	w0, [sp, #64]
 110:	ldr	w9, [sp, #64]
 114:	and	w9, w9, #0x7fffffff
 118:	str	w9, [sp, #60]
 11c:	ldr	w9, [sp, #64]
 120:	and	w9, w9, #0x80000000
 124:	str	w9, [sp, #56]
 128:	ldr	w9, [sp, #60]
 12c:	ldr	w10, [sp, #16]
 130:	subs	w9, w9, w10
 134:	ldr	w11, [sp, #60]
 138:	ldr	w12, [sp, #12]
 13c:	subs	w11, w11, w12
 140:	cmp	w9, w11
 144:	b.cs	1ac <__truncXfYf2__+0x188>  // b.hs, b.nlast
 148:	ldr	w8, [sp, #60]
 14c:	lsr	w8, w8, #13
 150:	strh	w8, [sp, #54]
 154:	ldrh	w8, [sp, #54]
 158:	subs	w8, w8, #0x1c, lsl #12
 15c:	strh	w8, [sp, #54]
 160:	ldr	w8, [sp, #60]
 164:	and	w8, w8, #0x1fff
 168:	str	w8, [sp, #48]
 16c:	ldr	w8, [sp, #48]
 170:	cmp	w8, #0x1, lsl #12
 174:	b.ls	188 <__truncXfYf2__+0x164>  // b.plast
 178:	ldrh	w8, [sp, #54]
 17c:	add	w8, w8, #0x1
 180:	strh	w8, [sp, #54]
 184:	b	1a8 <__truncXfYf2__+0x184>
 188:	ldr	w8, [sp, #48]
 18c:	cmp	w8, #0x1, lsl #12
 190:	b.ne	1a8 <__truncXfYf2__+0x184>  // b.any
 194:	ldrh	w8, [sp, #54]
 198:	and	w8, w8, #0x1
 19c:	ldrh	w9, [sp, #54]
 1a0:	add	w8, w9, w8
 1a4:	strh	w8, [sp, #54]
 1a8:	b	2ec <__truncXfYf2__+0x2c8>
 1ac:	ldr	w8, [sp, #60]
 1b0:	mov	w9, #0x7f800000            	// #2139095040
 1b4:	cmp	w8, w9
 1b8:	b.ls	1f0 <__truncXfYf2__+0x1cc>  // b.plast
 1bc:	mov	w8, #0x7c00                	// #31744
 1c0:	strh	w8, [sp, #54]
 1c4:	ldrh	w8, [sp, #54]
 1c8:	orr	w8, w8, #0x200
 1cc:	strh	w8, [sp, #54]
 1d0:	ldr	w8, [sp, #60]
 1d4:	and	w8, w8, #0x3fffff
 1d8:	lsr	w8, w8, #13
 1dc:	and	w8, w8, #0x1ff
 1e0:	ldrh	w9, [sp, #54]
 1e4:	orr	w8, w9, w8
 1e8:	strh	w8, [sp, #54]
 1ec:	b	2ec <__truncXfYf2__+0x2c8>
 1f0:	ldr	w8, [sp, #60]
 1f4:	mov	w9, #0x47800000            	// #1199570944
 1f8:	cmp	w8, w9
 1fc:	b.cc	20c <__truncXfYf2__+0x1e8>  // b.lo, b.ul, b.last
 200:	mov	w8, #0x7c00                	// #31744
 204:	strh	w8, [sp, #54]
 208:	b	2ec <__truncXfYf2__+0x2c8>
 20c:	ldr	w8, [sp, #60]
 210:	lsr	w8, w8, #23
 214:	str	w8, [sp, #44]
 218:	ldr	w8, [sp, #44]
 21c:	mov	w9, #0x70                  	// #112
 220:	subs	w8, w9, w8
 224:	add	w8, w8, #0x1
 228:	str	w8, [sp, #40]
 22c:	ldr	w8, [sp, #64]
 230:	and	w8, w8, #0x7fffff
 234:	orr	w8, w8, #0x800000
 238:	str	w8, [sp, #36]
 23c:	ldr	w8, [sp, #40]
 240:	cmp	w8, #0x17
 244:	b.le	254 <__truncXfYf2__+0x230>
 248:	mov	w8, #0x0                   	// #0
 24c:	strh	w8, [sp, #54]
 250:	b	2ec <__truncXfYf2__+0x2c8>
 254:	ldr	w8, [sp, #36]
 258:	ldr	w9, [sp, #40]
 25c:	mov	w10, #0x20                  	// #32
 260:	subs	w9, w10, w9
 264:	lsl	w8, w8, w9
 268:	cmp	w8, #0x0
 26c:	cset	w8, ne  // ne = any
 270:	mov	w9, #0x1                   	// #1
 274:	and	w8, w8, w9
 278:	strb	w8, [sp, #35]
 27c:	ldr	w8, [sp, #36]
 280:	ldr	w9, [sp, #40]
 284:	lsr	w8, w8, w9
 288:	ldrb	w9, [sp, #35]
 28c:	and	w9, w9, #0x1
 290:	orr	w8, w8, w9
 294:	str	w8, [sp, #28]
 298:	ldr	w8, [sp, #28]
 29c:	lsr	w8, w8, #13
 2a0:	strh	w8, [sp, #54]
 2a4:	ldr	w8, [sp, #28]
 2a8:	and	w8, w8, #0x1fff
 2ac:	str	w8, [sp, #24]
 2b0:	ldr	w8, [sp, #24]
 2b4:	cmp	w8, #0x1, lsl #12
 2b8:	b.ls	2cc <__truncXfYf2__+0x2a8>  // b.plast
 2bc:	ldrh	w8, [sp, #54]
 2c0:	add	w8, w8, #0x1
 2c4:	strh	w8, [sp, #54]
 2c8:	b	2ec <__truncXfYf2__+0x2c8>
 2cc:	ldr	w8, [sp, #24]
 2d0:	cmp	w8, #0x1, lsl #12
 2d4:	b.ne	2ec <__truncXfYf2__+0x2c8>  // b.any
 2d8:	ldrh	w8, [sp, #54]
 2dc:	and	w8, w8, #0x1
 2e0:	ldrh	w9, [sp, #54]
 2e4:	add	w8, w9, w8
 2e8:	strh	w8, [sp, #54]
 2ec:	ldrh	w8, [sp, #54]
 2f0:	ldr	w9, [sp, #56]
 2f4:	orr	w8, w8, w9, lsr #16
 2f8:	strh	w8, [sp, #22]
 2fc:	ldrh	w0, [sp, #22]
 300:	bl	35c <dstFromRep>
 304:	ldp	x20, x19, [sp, #208]
 308:	ldp	x22, x21, [sp, #192]
 30c:	ldr	x23, [sp, #176]
 310:	ldp	x29, x30, [sp, #160]
 314:	add	sp, sp, #0xe0
 318:	ret

000000000000031c <__gnu_f2h_ieee>:
 31c:	sub	sp, sp, #0x20
 320:	stp	x29, x30, [sp, #16]
 324:	add	x29, sp, #0x10
 328:	stur	s0, [x29, #-4]
 32c:	ldur	s0, [x29, #-4]
 330:	bl	0 <__truncsfhf2>
 334:	ldp	x29, x30, [sp, #16]
 338:	add	sp, sp, #0x20
 33c:	ret

0000000000000340 <srcToRep>:
 340:	sub	sp, sp, #0x10
 344:	str	s0, [sp, #12]
 348:	ldr	w8, [sp, #12]
 34c:	str	w8, [sp, #8]
 350:	ldr	w0, [sp, #8]
 354:	add	sp, sp, #0x10
 358:	ret

000000000000035c <dstFromRep>:
 35c:	sub	sp, sp, #0x10
 360:	strh	w0, [sp, #14]
 364:	ldrh	w8, [sp, #14]
 368:	strh	w8, [sp, #12]
 36c:	ldrh	w0, [sp, #12]
 370:	add	sp, sp, #0x10
 374:	ret

ucmpdi2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ucmpdi2>:
   0:	sub	sp, sp, #0x30
   4:	str	x0, [sp, #32]
   8:	str	x1, [sp, #24]
   c:	ldr	x8, [sp, #32]
  10:	str	x8, [sp, #16]
  14:	ldr	x8, [sp, #24]
  18:	str	x8, [sp, #8]
  1c:	ldr	w9, [sp, #20]
  20:	ldr	w10, [sp, #12]
  24:	cmp	w9, w10
  28:	b.cs	34 <__ucmpdi2+0x34>  // b.hs, b.nlast
  2c:	str	wzr, [sp, #44]
  30:	b	8c <__ucmpdi2+0x8c>
  34:	ldr	w8, [sp, #20]
  38:	ldr	w9, [sp, #12]
  3c:	cmp	w8, w9
  40:	b.ls	50 <__ucmpdi2+0x50>  // b.plast
  44:	mov	w8, #0x2                   	// #2
  48:	str	w8, [sp, #44]
  4c:	b	8c <__ucmpdi2+0x8c>
  50:	ldr	w8, [sp, #16]
  54:	ldr	w9, [sp, #8]
  58:	cmp	w8, w9
  5c:	b.cs	68 <__ucmpdi2+0x68>  // b.hs, b.nlast
  60:	str	wzr, [sp, #44]
  64:	b	8c <__ucmpdi2+0x8c>
  68:	ldr	w8, [sp, #16]
  6c:	ldr	w9, [sp, #8]
  70:	cmp	w8, w9
  74:	b.ls	84 <__ucmpdi2+0x84>  // b.plast
  78:	mov	w8, #0x2                   	// #2
  7c:	str	w8, [sp, #44]
  80:	b	8c <__ucmpdi2+0x8c>
  84:	mov	w8, #0x1                   	// #1
  88:	str	w8, [sp, #44]
  8c:	ldr	w0, [sp, #44]
  90:	add	sp, sp, #0x30
  94:	ret

ucmpti2.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__ucmpti2>:
   0:	sub	sp, sp, #0x50
   4:	mov	v0.d[0], x0
   8:	mov	v0.d[1], x1
   c:	mov	v1.d[0], x2
  10:	mov	v1.d[1], x3
  14:	str	q0, [sp, #48]
  18:	str	q1, [sp, #32]
  1c:	ldr	q0, [sp, #48]
  20:	str	q0, [sp, #16]
  24:	ldr	q0, [sp, #32]
  28:	str	q0, [sp]
  2c:	ldr	x8, [sp, #24]
  30:	ldr	x9, [sp, #8]
  34:	cmp	x8, x9
  38:	b.cs	44 <__ucmpti2+0x44>  // b.hs, b.nlast
  3c:	str	wzr, [sp, #76]
  40:	b	9c <__ucmpti2+0x9c>
  44:	ldr	x8, [sp, #24]
  48:	ldr	x9, [sp, #8]
  4c:	cmp	x8, x9
  50:	b.ls	60 <__ucmpti2+0x60>  // b.plast
  54:	mov	w8, #0x2                   	// #2
  58:	str	w8, [sp, #76]
  5c:	b	9c <__ucmpti2+0x9c>
  60:	ldr	x8, [sp, #16]
  64:	ldr	x9, [sp]
  68:	cmp	x8, x9
  6c:	b.cs	78 <__ucmpti2+0x78>  // b.hs, b.nlast
  70:	str	wzr, [sp, #76]
  74:	b	9c <__ucmpti2+0x9c>
  78:	ldr	x8, [sp, #16]
  7c:	ldr	x9, [sp]
  80:	cmp	x8, x9
  84:	b.ls	94 <__ucmpti2+0x94>  // b.plast
  88:	mov	w8, #0x2                   	// #2
  8c:	str	w8, [sp, #76]
  90:	b	9c <__ucmpti2+0x9c>
  94:	mov	w8, #0x1                   	// #1
  98:	str	w8, [sp, #76]
  9c:	ldr	w0, [sp, #76]
  a0:	add	sp, sp, #0x50
  a4:	ret

udivdi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__udivdi3>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	mov	x8, xzr
  10:	str	x0, [sp, #8]
  14:	str	x1, [sp]
  18:	ldr	x0, [sp, #8]
  1c:	ldr	x1, [sp]
  20:	mov	x2, x8
  24:	bl	0 <__udivmoddi4>
  28:	ldp	x29, x30, [sp, #16]
  2c:	add	sp, sp, #0x20
  30:	ret

udivmoddi4.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__udivmoddi4>:
   0:	sub	sp, sp, #0x60
   4:	str	x0, [sp, #80]
   8:	str	x1, [sp, #72]
   c:	str	x2, [sp, #64]
  10:	mov	w8, #0x20                  	// #32
  14:	str	w8, [sp, #60]
  18:	mov	w8, #0x40                  	// #64
  1c:	str	w8, [sp, #56]
  20:	ldr	x9, [sp, #80]
  24:	str	x9, [sp, #48]
  28:	ldr	x9, [sp, #72]
  2c:	str	x9, [sp, #40]
  30:	ldr	w8, [sp, #52]
  34:	cbnz	w8, bc <__udivmoddi4+0xbc>
  38:	b	3c <__udivmoddi4+0x3c>
  3c:	ldr	w8, [sp, #44]
  40:	cbnz	w8, 90 <__udivmoddi4+0x90>
  44:	b	48 <__udivmoddi4+0x48>
  48:	ldr	x8, [sp, #64]
  4c:	cbz	x8, 78 <__udivmoddi4+0x78>
  50:	b	54 <__udivmoddi4+0x54>
  54:	ldr	w8, [sp, #48]
  58:	ldr	w9, [sp, #40]
  5c:	udiv	w10, w8, w9
  60:	mul	w9, w10, w9
  64:	subs	w8, w8, w9
  68:	mov	w11, w8
  6c:	ldr	x12, [sp, #64]
  70:	str	x11, [x12]
  74:	b	78 <__udivmoddi4+0x78>
  78:	ldr	w8, [sp, #48]
  7c:	ldr	w9, [sp, #40]
  80:	udiv	w8, w8, w9
  84:	mov	w10, w8
  88:	str	x10, [sp, #88]
  8c:	b	63c <__udivmoddi4+0x63c>
  90:	ldr	x8, [sp, #64]
  94:	cbz	x8, b0 <__udivmoddi4+0xb0>
  98:	b	9c <__udivmoddi4+0x9c>
  9c:	ldr	w8, [sp, #48]
  a0:	mov	w9, w8
  a4:	ldr	x10, [sp, #64]
  a8:	str	x9, [x10]
  ac:	b	b0 <__udivmoddi4+0xb0>
  b0:	mov	x8, xzr
  b4:	str	x8, [sp, #88]
  b8:	b	63c <__udivmoddi4+0x63c>
  bc:	ldr	w8, [sp, #40]
  c0:	cbnz	w8, 29c <__udivmoddi4+0x29c>
  c4:	b	c8 <__udivmoddi4+0xc8>
  c8:	ldr	w8, [sp, #44]
  cc:	cbnz	w8, 11c <__udivmoddi4+0x11c>
  d0:	b	d4 <__udivmoddi4+0xd4>
  d4:	ldr	x8, [sp, #64]
  d8:	cbz	x8, 104 <__udivmoddi4+0x104>
  dc:	b	e0 <__udivmoddi4+0xe0>
  e0:	ldr	w8, [sp, #52]
  e4:	ldr	w9, [sp, #40]
  e8:	udiv	w10, w8, w9
  ec:	mul	w9, w10, w9
  f0:	subs	w8, w8, w9
  f4:	mov	w11, w8
  f8:	ldr	x12, [sp, #64]
  fc:	str	x11, [x12]
 100:	b	104 <__udivmoddi4+0x104>
 104:	ldr	w8, [sp, #52]
 108:	ldr	w9, [sp, #40]
 10c:	udiv	w8, w8, w9
 110:	mov	w10, w8
 114:	str	x10, [sp, #88]
 118:	b	63c <__udivmoddi4+0x63c>
 11c:	ldr	w8, [sp, #48]
 120:	cbnz	w8, 17c <__udivmoddi4+0x17c>
 124:	b	128 <__udivmoddi4+0x128>
 128:	ldr	x8, [sp, #64]
 12c:	cbz	x8, 164 <__udivmoddi4+0x164>
 130:	b	134 <__udivmoddi4+0x134>
 134:	ldr	w8, [sp, #52]
 138:	ldr	w9, [sp, #44]
 13c:	udiv	w10, w8, w9
 140:	mul	w9, w10, w9
 144:	subs	w8, w8, w9
 148:	str	w8, [sp, #28]
 14c:	mov	w8, wzr
 150:	str	w8, [sp, #24]
 154:	ldr	x11, [sp, #24]
 158:	ldr	x12, [sp, #64]
 15c:	str	x11, [x12]
 160:	b	164 <__udivmoddi4+0x164>
 164:	ldr	w8, [sp, #52]
 168:	ldr	w9, [sp, #44]
 16c:	udiv	w8, w8, w9
 170:	mov	w10, w8
 174:	str	x10, [sp, #88]
 178:	b	63c <__udivmoddi4+0x63c>
 17c:	ldr	w8, [sp, #44]
 180:	subs	w9, w8, #0x1
 184:	and	w8, w8, w9
 188:	cbnz	w8, 1e8 <__udivmoddi4+0x1e8>
 18c:	b	190 <__udivmoddi4+0x190>
 190:	ldr	x8, [sp, #64]
 194:	cbz	x8, 1c8 <__udivmoddi4+0x1c8>
 198:	b	19c <__udivmoddi4+0x19c>
 19c:	ldr	w8, [sp, #48]
 1a0:	str	w8, [sp, #24]
 1a4:	ldr	w8, [sp, #52]
 1a8:	ldr	w9, [sp, #44]
 1ac:	subs	w9, w9, #0x1
 1b0:	and	w8, w8, w9
 1b4:	str	w8, [sp, #28]
 1b8:	ldr	x10, [sp, #24]
 1bc:	ldr	x11, [sp, #64]
 1c0:	str	x10, [x11]
 1c4:	b	1c8 <__udivmoddi4+0x1c8>
 1c8:	ldr	w8, [sp, #52]
 1cc:	ldr	w9, [sp, #44]
 1d0:	rbit	w9, w9
 1d4:	clz	w9, w9
 1d8:	lsr	w8, w8, w9
 1dc:	mov	w10, w8
 1e0:	str	x10, [sp, #88]
 1e4:	b	63c <__udivmoddi4+0x63c>
 1e8:	ldr	w8, [sp, #44]
 1ec:	clz	w8, w8
 1f0:	ldr	w9, [sp, #52]
 1f4:	clz	w9, w9
 1f8:	subs	w8, w8, w9
 1fc:	str	w8, [sp, #20]
 200:	ldr	w8, [sp, #20]
 204:	subs	w8, w8, #0x1f
 208:	b.cc	238 <__udivmoddi4+0x238>  // b.lo, b.ul, b.last
 20c:	b	210 <__udivmoddi4+0x210>
 210:	ldr	x8, [sp, #64]
 214:	cbz	x8, 22c <__udivmoddi4+0x22c>
 218:	b	21c <__udivmoddi4+0x21c>
 21c:	ldr	x8, [sp, #48]
 220:	ldr	x9, [sp, #64]
 224:	str	x8, [x9]
 228:	b	22c <__udivmoddi4+0x22c>
 22c:	mov	x8, xzr
 230:	str	x8, [sp, #88]
 234:	b	63c <__udivmoddi4+0x63c>
 238:	ldr	w8, [sp, #20]
 23c:	add	w8, w8, #0x1
 240:	str	w8, [sp, #20]
 244:	mov	w8, wzr
 248:	str	w8, [sp, #32]
 24c:	ldr	w9, [sp, #48]
 250:	ldr	w10, [sp, #20]
 254:	sub	w10, w8, w10
 258:	lsl	w9, w9, w10
 25c:	str	w9, [sp, #36]
 260:	ldr	w9, [sp, #52]
 264:	ldr	w10, [sp, #20]
 268:	mov	w0, w10
 26c:	lsr	w9, w9, w0
 270:	str	w9, [sp, #28]
 274:	ldr	w9, [sp, #52]
 278:	ldr	w10, [sp, #20]
 27c:	mov	w1, w10
 280:	sub	w8, w8, w1
 284:	lsl	w8, w9, w8
 288:	ldr	w9, [sp, #48]
 28c:	lsr	w9, w9, w1
 290:	orr	w8, w8, w9
 294:	str	w8, [sp, #24]
 298:	b	554 <__udivmoddi4+0x554>
 29c:	ldr	w8, [sp, #44]
 2a0:	cbnz	w8, 468 <__udivmoddi4+0x468>
 2a4:	b	2a8 <__udivmoddi4+0x2a8>
 2a8:	ldr	w8, [sp, #40]
 2ac:	subs	w9, w8, #0x1
 2b0:	and	w8, w8, w9
 2b4:	cbnz	w8, 35c <__udivmoddi4+0x35c>
 2b8:	b	2bc <__udivmoddi4+0x2bc>
 2bc:	ldr	x8, [sp, #64]
 2c0:	cbz	x8, 2e8 <__udivmoddi4+0x2e8>
 2c4:	b	2c8 <__udivmoddi4+0x2c8>
 2c8:	ldr	w8, [sp, #48]
 2cc:	ldr	w9, [sp, #40]
 2d0:	subs	w9, w9, #0x1
 2d4:	and	w8, w8, w9
 2d8:	mov	w10, w8
 2dc:	ldr	x11, [sp, #64]
 2e0:	str	x10, [x11]
 2e4:	b	2e8 <__udivmoddi4+0x2e8>
 2e8:	ldr	w8, [sp, #40]
 2ec:	subs	w8, w8, #0x1
 2f0:	b.ne	304 <__udivmoddi4+0x304>  // b.any
 2f4:	b	2f8 <__udivmoddi4+0x2f8>
 2f8:	ldr	x8, [sp, #48]
 2fc:	str	x8, [sp, #88]
 300:	b	63c <__udivmoddi4+0x63c>
 304:	ldr	w8, [sp, #40]
 308:	rbit	w8, w8
 30c:	clz	w8, w8
 310:	str	w8, [sp, #20]
 314:	ldr	w8, [sp, #52]
 318:	ldr	w9, [sp, #20]
 31c:	mov	w0, w9
 320:	lsr	w8, w8, w0
 324:	str	w8, [sp, #36]
 328:	ldr	w8, [sp, #52]
 32c:	ldr	w9, [sp, #20]
 330:	mov	w1, w9
 334:	mov	w9, wzr
 338:	sub	w9, w9, w1
 33c:	lsl	w8, w8, w9
 340:	ldr	w9, [sp, #48]
 344:	lsr	w9, w9, w1
 348:	orr	w8, w8, w9
 34c:	str	w8, [sp, #32]
 350:	ldr	x10, [sp, #32]
 354:	str	x10, [sp, #88]
 358:	b	63c <__udivmoddi4+0x63c>
 35c:	ldr	w8, [sp, #40]
 360:	clz	w8, w8
 364:	ldr	w9, [sp, #52]
 368:	clz	w9, w9
 36c:	subs	w8, w8, w9
 370:	add	w8, w8, #0x21
 374:	str	w8, [sp, #20]
 378:	ldr	w8, [sp, #20]
 37c:	subs	w8, w8, #0x20
 380:	b.ne	3a8 <__udivmoddi4+0x3a8>  // b.any
 384:	b	388 <__udivmoddi4+0x388>
 388:	mov	w8, wzr
 38c:	str	w8, [sp, #32]
 390:	ldr	w9, [sp, #48]
 394:	str	w9, [sp, #36]
 398:	str	w8, [sp, #28]
 39c:	ldr	w8, [sp, #52]
 3a0:	str	w8, [sp, #24]
 3a4:	b	464 <__udivmoddi4+0x464>
 3a8:	ldr	w8, [sp, #20]
 3ac:	subs	w8, w8, #0x1f
 3b0:	b.hi	410 <__udivmoddi4+0x410>  // b.pmore
 3b4:	b	3b8 <__udivmoddi4+0x3b8>
 3b8:	mov	w8, wzr
 3bc:	str	w8, [sp, #32]
 3c0:	ldr	w9, [sp, #48]
 3c4:	ldr	w10, [sp, #20]
 3c8:	sub	w10, w8, w10
 3cc:	lsl	w9, w9, w10
 3d0:	str	w9, [sp, #36]
 3d4:	ldr	w9, [sp, #52]
 3d8:	ldr	w10, [sp, #20]
 3dc:	mov	w0, w10
 3e0:	lsr	w9, w9, w0
 3e4:	str	w9, [sp, #28]
 3e8:	ldr	w9, [sp, #52]
 3ec:	ldr	w10, [sp, #20]
 3f0:	mov	w1, w10
 3f4:	sub	w8, w8, w1
 3f8:	lsl	w8, w9, w8
 3fc:	ldr	w9, [sp, #48]
 400:	lsr	w9, w9, w1
 404:	orr	w8, w8, w9
 408:	str	w8, [sp, #24]
 40c:	b	460 <__udivmoddi4+0x460>
 410:	ldr	w8, [sp, #48]
 414:	ldr	w9, [sp, #20]
 418:	mov	w10, wzr
 41c:	sub	w9, w10, w9
 420:	lsl	w8, w8, w9
 424:	str	w8, [sp, #32]
 428:	ldr	w8, [sp, #52]
 42c:	ldr	w9, [sp, #20]
 430:	sub	w11, w10, w9
 434:	lsl	w8, w8, w11
 438:	ldr	w11, [sp, #48]
 43c:	lsr	w9, w11, w9
 440:	orr	w8, w8, w9
 444:	str	w8, [sp, #36]
 448:	str	w10, [sp, #28]
 44c:	ldr	w8, [sp, #52]
 450:	ldr	w9, [sp, #20]
 454:	lsr	w8, w8, w9
 458:	str	w8, [sp, #24]
 45c:	b	460 <__udivmoddi4+0x460>
 460:	b	464 <__udivmoddi4+0x464>
 464:	b	550 <__udivmoddi4+0x550>
 468:	ldr	w8, [sp, #44]
 46c:	clz	w8, w8
 470:	ldr	w9, [sp, #52]
 474:	clz	w9, w9
 478:	subs	w8, w8, w9
 47c:	str	w8, [sp, #20]
 480:	ldr	w8, [sp, #20]
 484:	subs	w8, w8, #0x20
 488:	b.cc	4b8 <__udivmoddi4+0x4b8>  // b.lo, b.ul, b.last
 48c:	b	490 <__udivmoddi4+0x490>
 490:	ldr	x8, [sp, #64]
 494:	cbz	x8, 4ac <__udivmoddi4+0x4ac>
 498:	b	49c <__udivmoddi4+0x49c>
 49c:	ldr	x8, [sp, #48]
 4a0:	ldr	x9, [sp, #64]
 4a4:	str	x8, [x9]
 4a8:	b	4ac <__udivmoddi4+0x4ac>
 4ac:	mov	x8, xzr
 4b0:	str	x8, [sp, #88]
 4b4:	b	63c <__udivmoddi4+0x63c>
 4b8:	ldr	w8, [sp, #20]
 4bc:	add	w8, w8, #0x1
 4c0:	str	w8, [sp, #20]
 4c4:	mov	w8, wzr
 4c8:	str	w8, [sp, #32]
 4cc:	ldr	w8, [sp, #20]
 4d0:	subs	w8, w8, #0x20
 4d4:	b.ne	4f8 <__udivmoddi4+0x4f8>  // b.any
 4d8:	b	4dc <__udivmoddi4+0x4dc>
 4dc:	ldr	w8, [sp, #48]
 4e0:	str	w8, [sp, #36]
 4e4:	mov	w8, wzr
 4e8:	str	w8, [sp, #28]
 4ec:	ldr	w8, [sp, #52]
 4f0:	str	w8, [sp, #24]
 4f4:	b	54c <__udivmoddi4+0x54c>
 4f8:	ldr	w8, [sp, #48]
 4fc:	ldr	w9, [sp, #20]
 500:	mov	w10, wzr
 504:	sub	w9, w10, w9
 508:	lsl	w8, w8, w9
 50c:	str	w8, [sp, #36]
 510:	ldr	w8, [sp, #52]
 514:	ldr	w9, [sp, #20]
 518:	mov	w0, w9
 51c:	lsr	w8, w8, w0
 520:	str	w8, [sp, #28]
 524:	ldr	w8, [sp, #52]
 528:	ldr	w9, [sp, #20]
 52c:	mov	w1, w9
 530:	sub	w9, w10, w1
 534:	lsl	w8, w8, w9
 538:	ldr	w9, [sp, #48]
 53c:	lsr	w9, w9, w1
 540:	orr	w8, w8, w9
 544:	str	w8, [sp, #24]
 548:	b	54c <__udivmoddi4+0x54c>
 54c:	b	550 <__udivmoddi4+0x550>
 550:	b	554 <__udivmoddi4+0x554>
 554:	mov	w8, wzr
 558:	str	w8, [sp, #16]
 55c:	b	560 <__udivmoddi4+0x560>
 560:	ldr	w8, [sp, #20]
 564:	cbz	w8, 600 <__udivmoddi4+0x600>
 568:	b	56c <__udivmoddi4+0x56c>
 56c:	ldr	w8, [sp, #28]
 570:	ldr	w9, [sp, #24]
 574:	extr	w8, w8, w9, #31
 578:	str	w8, [sp, #28]
 57c:	ldr	w8, [sp, #24]
 580:	ldr	w9, [sp, #36]
 584:	extr	w8, w8, w9, #31
 588:	str	w8, [sp, #24]
 58c:	ldr	w8, [sp, #36]
 590:	ldr	w9, [sp, #32]
 594:	extr	w8, w8, w9, #31
 598:	str	w8, [sp, #36]
 59c:	ldr	w8, [sp, #32]
 5a0:	ldr	w9, [sp, #16]
 5a4:	orr	w8, w9, w8, lsl #1
 5a8:	str	w8, [sp, #32]
 5ac:	ldr	x10, [sp, #40]
 5b0:	ldr	x11, [sp, #24]
 5b4:	mvn	x11, x11
 5b8:	add	x10, x11, x10
 5bc:	asr	x10, x10, #63
 5c0:	str	x10, [sp, #8]
 5c4:	ldr	w8, [sp, #8]
 5c8:	and	w8, w8, #0x1
 5cc:	mov	w0, w8
 5d0:	str	w0, [sp, #16]
 5d4:	ldr	x10, [sp, #40]
 5d8:	ldr	x11, [sp, #8]
 5dc:	and	x10, x10, x11
 5e0:	ldr	x11, [sp, #24]
 5e4:	subs	x10, x11, x10
 5e8:	str	x10, [sp, #24]
 5ec:	b	5f0 <__udivmoddi4+0x5f0>
 5f0:	ldr	w8, [sp, #20]
 5f4:	subs	w8, w8, #0x1
 5f8:	str	w8, [sp, #20]
 5fc:	b	560 <__udivmoddi4+0x560>
 600:	ldr	x8, [sp, #32]
 604:	ldr	w9, [sp, #16]
 608:	mov	w10, w9
 60c:	orr	x8, x10, x8, lsl #1
 610:	str	x8, [sp, #32]
 614:	ldr	x8, [sp, #64]
 618:	cbz	x8, 630 <__udivmoddi4+0x630>
 61c:	b	620 <__udivmoddi4+0x620>
 620:	ldr	x8, [sp, #24]
 624:	ldr	x9, [sp, #64]
 628:	str	x8, [x9]
 62c:	b	630 <__udivmoddi4+0x630>
 630:	ldr	x8, [sp, #32]
 634:	str	x8, [sp, #88]
 638:	b	63c <__udivmoddi4+0x63c>
 63c:	ldr	x0, [sp, #88]
 640:	add	sp, sp, #0x60
 644:	ret

udivmodsi4.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__udivmodsi4>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	stur	w0, [x29, #-4]
  10:	stur	w1, [x29, #-8]
  14:	str	x2, [sp, #16]
  18:	ldur	w0, [x29, #-4]
  1c:	ldur	w1, [x29, #-8]
  20:	bl	0 <__udivsi3>
  24:	str	w0, [sp, #12]
  28:	ldur	w8, [x29, #-4]
  2c:	ldr	w9, [sp, #12]
  30:	ldur	w10, [x29, #-8]
  34:	mul	w9, w9, w10
  38:	subs	w8, w8, w9
  3c:	ldr	x11, [sp, #16]
  40:	str	w8, [x11]
  44:	ldr	w0, [sp, #12]
  48:	ldp	x29, x30, [sp, #32]
  4c:	add	sp, sp, #0x30
  50:	ret

udivmodti4.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__udivmodti4>:
   0:	sub	sp, sp, #0xa0
   4:	str	x1, [sp, #136]
   8:	str	x0, [sp, #128]
   c:	str	x3, [sp, #120]
  10:	str	x2, [sp, #112]
  14:	str	x4, [sp, #104]
  18:	mov	w8, #0x40                  	// #64
  1c:	str	w8, [sp, #100]
  20:	mov	w8, #0x80                  	// #128
  24:	str	w8, [sp, #96]
  28:	ldr	x9, [sp, #128]
  2c:	ldr	x10, [sp, #136]
  30:	str	x10, [sp, #88]
  34:	str	x9, [sp, #80]
  38:	ldr	x9, [sp, #112]
  3c:	ldr	x10, [sp, #120]
  40:	str	x10, [sp, #72]
  44:	str	x9, [sp, #64]
  48:	ldr	x9, [sp, #88]
  4c:	cbnz	x9, e4 <__udivmodti4+0xe4>
  50:	b	54 <__udivmodti4+0x54>
  54:	ldr	x8, [sp, #72]
  58:	cbnz	x8, b0 <__udivmodti4+0xb0>
  5c:	b	60 <__udivmodti4+0x60>
  60:	ldr	x8, [sp, #104]
  64:	cbz	x8, 94 <__udivmodti4+0x94>
  68:	b	6c <__udivmodti4+0x6c>
  6c:	ldr	x8, [sp, #80]
  70:	ldr	x9, [sp, #64]
  74:	udiv	x10, x8, x9
  78:	mul	x9, x10, x9
  7c:	subs	x8, x8, x9
  80:	ldr	x9, [sp, #104]
  84:	mov	x10, xzr
  88:	str	x10, [x9, #8]
  8c:	str	x8, [x9]
  90:	b	94 <__udivmodti4+0x94>
  94:	ldr	x8, [sp, #80]
  98:	ldr	x9, [sp, #64]
  9c:	udiv	x8, x8, x9
  a0:	mov	x9, xzr
  a4:	str	x9, [sp, #152]
  a8:	str	x8, [sp, #144]
  ac:	b	740 <__udivmodti4+0x740>
  b0:	ldr	x8, [sp, #104]
  b4:	cbz	x8, d4 <__udivmodti4+0xd4>
  b8:	b	bc <__udivmodti4+0xbc>
  bc:	ldr	x8, [sp, #80]
  c0:	ldr	x9, [sp, #104]
  c4:	mov	x10, xzr
  c8:	str	x10, [x9, #8]
  cc:	str	x8, [x9]
  d0:	b	d4 <__udivmodti4+0xd4>
  d4:	mov	x8, xzr
  d8:	str	x8, [sp, #152]
  dc:	str	x8, [sp, #144]
  e0:	b	740 <__udivmodti4+0x740>
  e4:	ldr	x8, [sp, #64]
  e8:	cbnz	x8, 300 <__udivmodti4+0x300>
  ec:	b	f0 <__udivmodti4+0xf0>
  f0:	ldr	x8, [sp, #72]
  f4:	cbnz	x8, 14c <__udivmodti4+0x14c>
  f8:	b	fc <__udivmodti4+0xfc>
  fc:	ldr	x8, [sp, #104]
 100:	cbz	x8, 130 <__udivmodti4+0x130>
 104:	b	108 <__udivmodti4+0x108>
 108:	ldr	x8, [sp, #88]
 10c:	ldr	x9, [sp, #64]
 110:	udiv	x10, x8, x9
 114:	mul	x9, x10, x9
 118:	subs	x8, x8, x9
 11c:	ldr	x9, [sp, #104]
 120:	mov	x10, xzr
 124:	str	x10, [x9, #8]
 128:	str	x8, [x9]
 12c:	b	130 <__udivmodti4+0x130>
 130:	ldr	x8, [sp, #88]
 134:	ldr	x9, [sp, #64]
 138:	udiv	x8, x8, x9
 13c:	mov	x9, xzr
 140:	str	x9, [sp, #152]
 144:	str	x8, [sp, #144]
 148:	b	740 <__udivmodti4+0x740>
 14c:	ldr	x8, [sp, #80]
 150:	cbnz	x8, 1b8 <__udivmodti4+0x1b8>
 154:	b	158 <__udivmodti4+0x158>
 158:	ldr	x8, [sp, #104]
 15c:	cbz	x8, 19c <__udivmodti4+0x19c>
 160:	b	164 <__udivmodti4+0x164>
 164:	ldr	x8, [sp, #88]
 168:	ldr	x9, [sp, #72]
 16c:	udiv	x10, x8, x9
 170:	mul	x9, x10, x9
 174:	subs	x8, x8, x9
 178:	str	x8, [sp, #40]
 17c:	mov	x8, xzr
 180:	str	x8, [sp, #32]
 184:	ldr	x8, [sp, #32]
 188:	ldr	x9, [sp, #40]
 18c:	ldr	x10, [sp, #104]
 190:	str	x9, [x10, #8]
 194:	str	x8, [x10]
 198:	b	19c <__udivmodti4+0x19c>
 19c:	ldr	x8, [sp, #88]
 1a0:	ldr	x9, [sp, #72]
 1a4:	udiv	x8, x8, x9
 1a8:	mov	x9, xzr
 1ac:	str	x9, [sp, #152]
 1b0:	str	x8, [sp, #144]
 1b4:	b	740 <__udivmodti4+0x740>
 1b8:	ldr	x8, [sp, #72]
 1bc:	subs	x9, x8, #0x1
 1c0:	and	x8, x8, x9
 1c4:	cbnz	x8, 230 <__udivmodti4+0x230>
 1c8:	b	1cc <__udivmodti4+0x1cc>
 1cc:	ldr	x8, [sp, #104]
 1d0:	cbz	x8, 20c <__udivmodti4+0x20c>
 1d4:	b	1d8 <__udivmodti4+0x1d8>
 1d8:	ldr	x8, [sp, #80]
 1dc:	str	x8, [sp, #32]
 1e0:	ldr	x8, [sp, #88]
 1e4:	ldr	x9, [sp, #72]
 1e8:	subs	x9, x9, #0x1
 1ec:	and	x8, x8, x9
 1f0:	str	x8, [sp, #40]
 1f4:	ldr	x8, [sp, #32]
 1f8:	ldr	x9, [sp, #40]
 1fc:	ldr	x10, [sp, #104]
 200:	str	x9, [x10, #8]
 204:	str	x8, [x10]
 208:	b	20c <__udivmodti4+0x20c>
 20c:	ldr	x8, [sp, #88]
 210:	ldr	x9, [sp, #72]
 214:	rbit	x9, x9
 218:	clz	x9, x9
 21c:	lsr	x8, x8, x9
 220:	mov	x9, xzr
 224:	str	x9, [sp, #152]
 228:	str	x8, [sp, #144]
 22c:	b	740 <__udivmodti4+0x740>
 230:	ldr	x8, [sp, #72]
 234:	clz	x8, x8
 238:	ldr	x9, [sp, #88]
 23c:	clz	x9, x9
 240:	subs	w8, w8, w9
 244:	str	w8, [sp, #28]
 248:	ldr	w8, [sp, #28]
 24c:	subs	w8, w8, #0x3f
 250:	b.cc	28c <__udivmodti4+0x28c>  // b.lo, b.ul, b.last
 254:	b	258 <__udivmodti4+0x258>
 258:	ldr	x8, [sp, #104]
 25c:	cbz	x8, 27c <__udivmodti4+0x27c>
 260:	b	264 <__udivmodti4+0x264>
 264:	ldr	x8, [sp, #80]
 268:	ldr	x9, [sp, #88]
 26c:	ldr	x10, [sp, #104]
 270:	str	x9, [x10, #8]
 274:	str	x8, [x10]
 278:	b	27c <__udivmodti4+0x27c>
 27c:	mov	x8, xzr
 280:	str	x8, [sp, #152]
 284:	str	x8, [sp, #144]
 288:	b	740 <__udivmodti4+0x740>
 28c:	ldr	w8, [sp, #28]
 290:	add	w8, w8, #0x1
 294:	str	w8, [sp, #28]
 298:	mov	x9, xzr
 29c:	str	x9, [sp, #48]
 2a0:	ldr	x9, [sp, #80]
 2a4:	ldr	w8, [sp, #28]
 2a8:	mov	w10, wzr
 2ac:	sub	w8, w10, w8
 2b0:	mov	w11, w8
 2b4:	lsl	x9, x9, x11
 2b8:	str	x9, [sp, #56]
 2bc:	ldr	x9, [sp, #88]
 2c0:	ldr	w8, [sp, #28]
 2c4:	mov	w11, w8
 2c8:	lsr	x9, x9, x11
 2cc:	str	x9, [sp, #40]
 2d0:	ldr	x9, [sp, #88]
 2d4:	ldr	w8, [sp, #28]
 2d8:	mov	w11, w8
 2dc:	mov	w8, w11
 2e0:	sub	w8, w10, w8
 2e4:	mov	w12, w8
 2e8:	lsl	x9, x9, x12
 2ec:	ldr	x12, [sp, #80]
 2f0:	lsr	x11, x12, x11
 2f4:	orr	x9, x9, x11
 2f8:	str	x9, [sp, #32]
 2fc:	b	610 <__udivmodti4+0x610>
 300:	ldr	x8, [sp, #72]
 304:	cbnz	x8, 50c <__udivmodti4+0x50c>
 308:	b	30c <__udivmodti4+0x30c>
 30c:	ldr	x8, [sp, #64]
 310:	subs	x9, x8, #0x1
 314:	and	x8, x8, x9
 318:	cbnz	x8, 3dc <__udivmodti4+0x3dc>
 31c:	b	320 <__udivmodti4+0x320>
 320:	ldr	x8, [sp, #104]
 324:	cbz	x8, 350 <__udivmodti4+0x350>
 328:	b	32c <__udivmodti4+0x32c>
 32c:	ldr	x8, [sp, #80]
 330:	ldr	x9, [sp, #64]
 334:	subs	x9, x9, #0x1
 338:	and	x8, x8, x9
 33c:	ldr	x9, [sp, #104]
 340:	mov	x10, xzr
 344:	str	x10, [x9, #8]
 348:	str	x8, [x9]
 34c:	b	350 <__udivmodti4+0x350>
 350:	ldr	x8, [sp, #64]
 354:	subs	x8, x8, #0x1
 358:	b.ne	374 <__udivmodti4+0x374>  // b.any
 35c:	b	360 <__udivmodti4+0x360>
 360:	ldr	x8, [sp, #80]
 364:	ldr	x9, [sp, #88]
 368:	str	x9, [sp, #152]
 36c:	str	x8, [sp, #144]
 370:	b	740 <__udivmodti4+0x740>
 374:	ldr	x8, [sp, #64]
 378:	rbit	x8, x8
 37c:	clz	x8, x8
 380:	str	w8, [sp, #28]
 384:	ldr	x9, [sp, #88]
 388:	ldr	w8, [sp, #28]
 38c:	mov	w10, w8
 390:	lsr	x9, x9, x10
 394:	str	x9, [sp, #56]
 398:	ldr	x9, [sp, #88]
 39c:	ldr	w8, [sp, #28]
 3a0:	mov	w10, w8
 3a4:	mov	w8, w10
 3a8:	mov	w11, wzr
 3ac:	sub	w8, w11, w8
 3b0:	mov	w12, w8
 3b4:	lsl	x9, x9, x12
 3b8:	ldr	x12, [sp, #80]
 3bc:	lsr	x10, x12, x10
 3c0:	orr	x9, x9, x10
 3c4:	str	x9, [sp, #48]
 3c8:	ldr	x9, [sp, #48]
 3cc:	ldr	x10, [sp, #56]
 3d0:	str	x10, [sp, #152]
 3d4:	str	x9, [sp, #144]
 3d8:	b	740 <__udivmodti4+0x740>
 3dc:	ldr	x8, [sp, #64]
 3e0:	clz	x8, x8
 3e4:	ldr	x9, [sp, #88]
 3e8:	clz	x9, x9
 3ec:	subs	w8, w8, w9
 3f0:	add	w8, w8, #0x41
 3f4:	str	w8, [sp, #28]
 3f8:	ldr	w8, [sp, #28]
 3fc:	subs	w8, w8, #0x40
 400:	b.ne	428 <__udivmodti4+0x428>  // b.any
 404:	b	408 <__udivmodti4+0x408>
 408:	mov	x8, xzr
 40c:	str	x8, [sp, #48]
 410:	ldr	x9, [sp, #80]
 414:	str	x9, [sp, #56]
 418:	str	x8, [sp, #40]
 41c:	ldr	x8, [sp, #88]
 420:	str	x8, [sp, #32]
 424:	b	508 <__udivmodti4+0x508>
 428:	ldr	w8, [sp, #28]
 42c:	subs	w8, w8, #0x3f
 430:	b.hi	4a0 <__udivmodti4+0x4a0>  // b.pmore
 434:	b	438 <__udivmodti4+0x438>
 438:	mov	x8, xzr
 43c:	str	x8, [sp, #48]
 440:	ldr	x8, [sp, #80]
 444:	ldr	w9, [sp, #28]
 448:	mov	w10, wzr
 44c:	sub	w9, w10, w9
 450:	mov	w11, w9
 454:	lsl	x8, x8, x11
 458:	str	x8, [sp, #56]
 45c:	ldr	x8, [sp, #88]
 460:	ldr	w9, [sp, #28]
 464:	mov	w11, w9
 468:	lsr	x8, x8, x11
 46c:	str	x8, [sp, #40]
 470:	ldr	x8, [sp, #88]
 474:	ldr	w9, [sp, #28]
 478:	mov	w11, w9
 47c:	mov	w9, w11
 480:	sub	w9, w10, w9
 484:	mov	w12, w9
 488:	lsl	x8, x8, x12
 48c:	ldr	x12, [sp, #80]
 490:	lsr	x11, x12, x11
 494:	orr	x8, x8, x11
 498:	str	x8, [sp, #32]
 49c:	b	504 <__udivmodti4+0x504>
 4a0:	ldr	x8, [sp, #80]
 4a4:	ldr	w9, [sp, #28]
 4a8:	mov	w10, wzr
 4ac:	sub	w9, w10, w9
 4b0:	mov	w11, w9
 4b4:	lsl	x8, x8, x11
 4b8:	str	x8, [sp, #48]
 4bc:	ldr	x8, [sp, #88]
 4c0:	ldr	w9, [sp, #28]
 4c4:	sub	w10, w10, w9
 4c8:	mov	w11, w10
 4cc:	lsl	x8, x8, x11
 4d0:	ldr	x11, [sp, #80]
 4d4:	mov	w12, w9
 4d8:	lsr	x11, x11, x12
 4dc:	orr	x8, x8, x11
 4e0:	str	x8, [sp, #56]
 4e4:	mov	x8, xzr
 4e8:	str	x8, [sp, #40]
 4ec:	ldr	x8, [sp, #88]
 4f0:	ldr	w9, [sp, #28]
 4f4:	mov	w11, w9
 4f8:	lsr	x8, x8, x11
 4fc:	str	x8, [sp, #32]
 500:	b	504 <__udivmodti4+0x504>
 504:	b	508 <__udivmodti4+0x508>
 508:	b	60c <__udivmodti4+0x60c>
 50c:	ldr	x8, [sp, #72]
 510:	clz	x8, x8
 514:	ldr	x9, [sp, #88]
 518:	clz	x9, x9
 51c:	subs	w8, w8, w9
 520:	str	w8, [sp, #28]
 524:	ldr	w8, [sp, #28]
 528:	subs	w8, w8, #0x40
 52c:	b.cc	568 <__udivmodti4+0x568>  // b.lo, b.ul, b.last
 530:	b	534 <__udivmodti4+0x534>
 534:	ldr	x8, [sp, #104]
 538:	cbz	x8, 558 <__udivmodti4+0x558>
 53c:	b	540 <__udivmodti4+0x540>
 540:	ldr	x8, [sp, #80]
 544:	ldr	x9, [sp, #88]
 548:	ldr	x10, [sp, #104]
 54c:	str	x9, [x10, #8]
 550:	str	x8, [x10]
 554:	b	558 <__udivmodti4+0x558>
 558:	mov	x8, xzr
 55c:	str	x8, [sp, #152]
 560:	str	x8, [sp, #144]
 564:	b	740 <__udivmodti4+0x740>
 568:	ldr	w8, [sp, #28]
 56c:	add	w8, w8, #0x1
 570:	str	w8, [sp, #28]
 574:	mov	x9, xzr
 578:	str	x9, [sp, #48]
 57c:	ldr	w8, [sp, #28]
 580:	subs	w8, w8, #0x40
 584:	b.ne	5a8 <__udivmodti4+0x5a8>  // b.any
 588:	b	58c <__udivmodti4+0x58c>
 58c:	ldr	x8, [sp, #80]
 590:	str	x8, [sp, #56]
 594:	mov	x8, xzr
 598:	str	x8, [sp, #40]
 59c:	ldr	x8, [sp, #88]
 5a0:	str	x8, [sp, #32]
 5a4:	b	608 <__udivmodti4+0x608>
 5a8:	ldr	x8, [sp, #88]
 5ac:	ldr	w9, [sp, #28]
 5b0:	mov	w10, w9
 5b4:	lsr	x8, x8, x10
 5b8:	str	x8, [sp, #40]
 5bc:	ldr	x8, [sp, #88]
 5c0:	ldr	w9, [sp, #28]
 5c4:	mov	w10, w9
 5c8:	mov	w9, w10
 5cc:	mov	w11, wzr
 5d0:	sub	w9, w11, w9
 5d4:	mov	w12, w9
 5d8:	lsl	x8, x8, x12
 5dc:	ldr	x12, [sp, #80]
 5e0:	lsr	x10, x12, x10
 5e4:	orr	x8, x8, x10
 5e8:	str	x8, [sp, #32]
 5ec:	ldr	x8, [sp, #80]
 5f0:	ldr	w9, [sp, #28]
 5f4:	sub	w9, w11, w9
 5f8:	mov	w10, w9
 5fc:	lsl	x8, x8, x10
 600:	str	x8, [sp, #56]
 604:	b	608 <__udivmodti4+0x608>
 608:	b	60c <__udivmodti4+0x60c>
 60c:	b	610 <__udivmodti4+0x610>
 610:	mov	w8, wzr
 614:	str	w8, [sp, #24]
 618:	b	61c <__udivmodti4+0x61c>
 61c:	ldr	w8, [sp, #28]
 620:	cbz	w8, 6e8 <__udivmodti4+0x6e8>
 624:	b	628 <__udivmodti4+0x628>
 628:	ldr	x8, [sp, #40]
 62c:	ldr	x9, [sp, #32]
 630:	extr	x8, x8, x9, #63
 634:	str	x8, [sp, #40]
 638:	ldr	x8, [sp, #32]
 63c:	ldr	x9, [sp, #56]
 640:	extr	x8, x8, x9, #63
 644:	str	x8, [sp, #32]
 648:	ldr	x8, [sp, #56]
 64c:	ldr	x9, [sp, #48]
 650:	extr	x8, x8, x9, #63
 654:	str	x8, [sp, #56]
 658:	ldr	x8, [sp, #48]
 65c:	ldr	w10, [sp, #24]
 660:	mov	w9, w10
 664:	orr	x8, x9, x8, lsl #1
 668:	str	x8, [sp, #48]
 66c:	ldr	x8, [sp, #72]
 670:	ldr	x9, [sp, #64]
 674:	ldr	x11, [sp, #32]
 678:	ldr	x12, [sp, #40]
 67c:	mvn	x12, x12
 680:	mvn	x11, x11
 684:	adds	x9, x11, x9
 688:	adcs	x8, x12, x8
 68c:	asr	x8, x8, #63
 690:	str	x8, [sp, #8]
 694:	str	x8, [sp]
 698:	ldr	w10, [sp]
 69c:	and	w10, w10, #0x1
 6a0:	str	w10, [sp, #24]
 6a4:	ldr	x8, [sp, #64]
 6a8:	ldr	x11, [sp, #72]
 6ac:	ldr	x12, [sp]
 6b0:	ldr	x13, [sp, #8]
 6b4:	and	x11, x11, x13
 6b8:	and	x8, x8, x12
 6bc:	ldr	x12, [sp, #40]
 6c0:	ldr	x13, [sp, #32]
 6c4:	subs	x8, x13, x8
 6c8:	sbcs	x11, x12, x11
 6cc:	str	x8, [sp, #32]
 6d0:	str	x11, [sp, #40]
 6d4:	b	6d8 <__udivmodti4+0x6d8>
 6d8:	ldr	w8, [sp, #28]
 6dc:	subs	w8, w8, #0x1
 6e0:	str	w8, [sp, #28]
 6e4:	b	61c <__udivmodti4+0x61c>
 6e8:	ldr	x8, [sp, #48]
 6ec:	ldr	x9, [sp, #56]
 6f0:	extr	x9, x9, x8, #63
 6f4:	ldr	w10, [sp, #24]
 6f8:	mov	w11, w10
 6fc:	orr	x8, x11, x8, lsl #1
 700:	str	x9, [sp, #56]
 704:	str	x8, [sp, #48]
 708:	ldr	x8, [sp, #104]
 70c:	cbz	x8, 72c <__udivmodti4+0x72c>
 710:	b	714 <__udivmodti4+0x714>
 714:	ldr	x8, [sp, #32]
 718:	ldr	x9, [sp, #40]
 71c:	ldr	x10, [sp, #104]
 720:	str	x9, [x10, #8]
 724:	str	x8, [x10]
 728:	b	72c <__udivmodti4+0x72c>
 72c:	ldr	x8, [sp, #48]
 730:	ldr	x9, [sp, #56]
 734:	str	x9, [sp, #152]
 738:	str	x8, [sp, #144]
 73c:	b	740 <__udivmodti4+0x740>
 740:	ldr	x0, [sp, #144]
 744:	ldr	x1, [sp, #152]
 748:	add	sp, sp, #0xa0
 74c:	ret

udivsi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__udivsi3>:
   0:	sub	sp, sp, #0x30
   4:	mov	w8, #0x20                  	// #32
   8:	str	w0, [sp, #40]
   c:	str	w1, [sp, #36]
  10:	str	w8, [sp, #32]
  14:	ldr	w8, [sp, #36]
  18:	cbnz	w8, 24 <__udivsi3+0x24>
  1c:	str	wzr, [sp, #44]
  20:	b	14c <__udivsi3+0x14c>
  24:	ldr	w8, [sp, #40]
  28:	cbnz	w8, 34 <__udivsi3+0x34>
  2c:	str	wzr, [sp, #44]
  30:	b	14c <__udivsi3+0x14c>
  34:	ldr	w8, [sp, #36]
  38:	clz	w8, w8
  3c:	ldr	w9, [sp, #40]
  40:	clz	w9, w9
  44:	subs	w8, w8, w9
  48:	str	w8, [sp, #20]
  4c:	ldr	w8, [sp, #20]
  50:	cmp	w8, #0x1f
  54:	b.ls	60 <__udivsi3+0x60>  // b.plast
  58:	str	wzr, [sp, #44]
  5c:	b	14c <__udivsi3+0x14c>
  60:	ldr	w8, [sp, #20]
  64:	cmp	w8, #0x1f
  68:	b.ne	78 <__udivsi3+0x78>  // b.any
  6c:	ldr	w8, [sp, #40]
  70:	str	w8, [sp, #44]
  74:	b	14c <__udivsi3+0x14c>
  78:	ldr	w8, [sp, #20]
  7c:	add	w8, w8, #0x1
  80:	str	w8, [sp, #20]
  84:	ldr	w8, [sp, #40]
  88:	ldr	w9, [sp, #20]
  8c:	mov	w10, #0x20                  	// #32
  90:	subs	w9, w10, w9
  94:	lsl	w8, w8, w9
  98:	str	w8, [sp, #28]
  9c:	ldr	w8, [sp, #40]
  a0:	ldr	w9, [sp, #20]
  a4:	lsr	w8, w8, w9
  a8:	str	w8, [sp, #24]
  ac:	str	wzr, [sp, #16]
  b0:	ldr	w8, [sp, #20]
  b4:	cmp	w8, #0x0
  b8:	cset	w8, ls  // ls = plast
  bc:	tbnz	w8, #0, 134 <__udivsi3+0x134>
  c0:	ldr	w8, [sp, #24]
  c4:	ldr	w9, [sp, #28]
  c8:	mov	x10, #0x1f                  	// #31
  cc:	lsr	w9, w9, #31
  d0:	orr	w8, w9, w8, lsl #1
  d4:	str	w8, [sp, #24]
  d8:	ldr	w8, [sp, #28]
  dc:	ldr	w9, [sp, #16]
  e0:	orr	w8, w9, w8, lsl #1
  e4:	str	w8, [sp, #28]
  e8:	ldr	w8, [sp, #36]
  ec:	ldr	w9, [sp, #24]
  f0:	subs	w8, w8, w9
  f4:	subs	w8, w8, #0x1
  f8:	asr	w8, w8, w10
  fc:	str	w8, [sp, #12]
 100:	ldr	w8, [sp, #12]
 104:	and	w8, w8, #0x1
 108:	str	w8, [sp, #16]
 10c:	ldr	w8, [sp, #36]
 110:	ldr	w9, [sp, #12]
 114:	and	w8, w8, w9
 118:	ldr	w9, [sp, #24]
 11c:	subs	w8, w9, w8
 120:	str	w8, [sp, #24]
 124:	ldr	w8, [sp, #20]
 128:	subs	w8, w8, #0x1
 12c:	str	w8, [sp, #20]
 130:	b	b0 <__udivsi3+0xb0>
 134:	ldr	w8, [sp, #28]
 138:	ldr	w9, [sp, #16]
 13c:	orr	w8, w9, w8, lsl #1
 140:	str	w8, [sp, #28]
 144:	ldr	w8, [sp, #28]
 148:	str	w8, [sp, #44]
 14c:	ldr	w0, [sp, #44]
 150:	add	sp, sp, #0x30
 154:	ret

udivti3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__udivti3>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	str	x1, [sp, #24]
  10:	str	x0, [sp, #16]
  14:	str	x3, [sp, #8]
  18:	str	x2, [sp]
  1c:	ldr	x1, [sp, #24]
  20:	ldr	x0, [sp, #16]
  24:	ldr	x3, [sp, #8]
  28:	ldr	x2, [sp]
  2c:	mov	x4, xzr
  30:	bl	0 <__udivmodti4>
  34:	ldp	x29, x30, [sp, #32]
  38:	add	sp, sp, #0x30
  3c:	ret

umoddi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__umoddi3>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	add	x2, sp, #0x8
  10:	stur	x0, [x29, #-8]
  14:	str	x1, [sp, #16]
  18:	ldur	x0, [x29, #-8]
  1c:	ldr	x1, [sp, #16]
  20:	bl	0 <__udivmoddi4>
  24:	ldr	x8, [sp, #8]
  28:	mov	x0, x8
  2c:	ldp	x29, x30, [sp, #32]
  30:	add	sp, sp, #0x30
  34:	ret

umodsi3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__umodsi3>:
   0:	sub	sp, sp, #0x20
   4:	stp	x29, x30, [sp, #16]
   8:	add	x29, sp, #0x10
   c:	stur	w0, [x29, #-4]
  10:	str	w1, [sp, #8]
  14:	ldur	w8, [x29, #-4]
  18:	ldur	w0, [x29, #-4]
  1c:	ldr	w1, [sp, #8]
  20:	str	w8, [sp, #4]
  24:	bl	0 <__udivsi3>
  28:	ldr	w8, [sp, #8]
  2c:	mul	w8, w0, w8
  30:	ldr	w9, [sp, #4]
  34:	subs	w0, w9, w8
  38:	ldp	x29, x30, [sp, #16]
  3c:	add	sp, sp, #0x20
  40:	ret

umodti3.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__umodti3>:
   0:	sub	sp, sp, #0x50
   4:	stp	x29, x30, [sp, #64]
   8:	add	x29, sp, #0x40
   c:	stur	x1, [x29, #-8]
  10:	stur	x0, [x29, #-16]
  14:	str	x3, [sp, #40]
  18:	str	x2, [sp, #32]
  1c:	ldur	x1, [x29, #-8]
  20:	ldur	x0, [x29, #-16]
  24:	ldr	x3, [sp, #40]
  28:	ldr	x2, [sp, #32]
  2c:	add	x4, sp, #0x10
  30:	bl	0 <__udivmodti4>
  34:	ldr	x8, [sp, #16]
  38:	ldr	x9, [sp, #24]
  3c:	str	x0, [sp, #8]
  40:	mov	x0, x8
  44:	str	x1, [sp]
  48:	mov	x1, x9
  4c:	ldp	x29, x30, [sp, #64]
  50:	add	sp, sp, #0x50
  54:	ret

emutls.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__emutls_get_address>:
   0:	sub	sp, sp, #0x30
   4:	stp	x29, x30, [sp, #32]
   8:	add	x29, sp, #0x20
   c:	stur	x0, [x29, #-8]
  10:	ldur	x0, [x29, #-8]
  14:	bl	a0 <emutls_get_index>
  18:	str	x0, [sp, #16]
  1c:	ldr	x8, [sp, #16]
  20:	subs	x9, x8, #0x1
  24:	str	x9, [sp, #16]
  28:	mov	x0, x8
  2c:	bl	13c <emutls_get_address_array>
  30:	str	x0, [sp, #8]
  34:	ldr	x8, [sp, #8]
  38:	add	x8, x8, #0x10
  3c:	ldr	x9, [sp, #16]
  40:	mov	x10, #0x8                   	// #8
  44:	mul	x9, x10, x9
  48:	add	x8, x8, x9
  4c:	ldr	x8, [x8]
  50:	cbnz	x8, 78 <__emutls_get_address+0x78>
  54:	ldur	x0, [x29, #-8]
  58:	bl	26c <emutls_allocate_object>
  5c:	ldr	x8, [sp, #8]
  60:	add	x8, x8, #0x10
  64:	ldr	x9, [sp, #16]
  68:	mov	x10, #0x8                   	// #8
  6c:	mul	x9, x10, x9
  70:	add	x8, x8, x9
  74:	str	x0, [x8]
  78:	ldr	x8, [sp, #8]
  7c:	add	x8, x8, #0x10
  80:	ldr	x9, [sp, #16]
  84:	mov	x10, #0x8                   	// #8
  88:	mul	x9, x10, x9
  8c:	add	x8, x8, x9
  90:	ldr	x0, [x8]
  94:	ldp	x29, x30, [sp, #32]
  98:	add	sp, sp, #0x30
  9c:	ret

00000000000000a0 <emutls_get_index>:
  a0:	sub	sp, sp, #0x30
  a4:	stp	x29, x30, [sp, #32]
  a8:	add	x29, sp, #0x20
  ac:	stur	x0, [x29, #-8]
  b0:	ldur	x8, [x29, #-8]
  b4:	add	x8, x8, #0x10
  b8:	ldar	x8, [x8]
  bc:	str	x8, [sp, #8]
  c0:	ldr	x8, [sp, #8]
  c4:	str	x8, [sp, #16]
  c8:	ldr	x8, [sp, #16]
  cc:	cbnz	x8, 12c <emutls_get_index+0x8c>
  d0:	b	d4 <emutls_get_index+0x34>
  d4:	bl	318 <emutls_init_once>
  d8:	bl	4c8 <emutls_lock>
  dc:	ldur	x8, [x29, #-8]
  e0:	ldr	x8, [x8, #16]
  e4:	str	x8, [sp, #16]
  e8:	ldr	x8, [sp, #16]
  ec:	cbnz	x8, 124 <emutls_get_index+0x84>
  f0:	b	f4 <emutls_get_index+0x54>
  f4:	adrp	x8, 0 <__emutls_get_address>
  f8:	ldr	x9, [x8]
  fc:	add	x9, x9, #0x1
 100:	str	x9, [x8]
 104:	str	x9, [sp, #16]
 108:	ldur	x8, [x29, #-8]
 10c:	add	x8, x8, #0x10
 110:	ldr	x9, [sp, #16]
 114:	str	x9, [sp]
 118:	ldr	x9, [sp]
 11c:	stlr	x9, [x8]
 120:	b	124 <emutls_get_index+0x84>
 124:	bl	4e4 <emutls_unlock>
 128:	b	12c <emutls_get_index+0x8c>
 12c:	ldr	x0, [sp, #16]
 130:	ldp	x29, x30, [sp, #32]
 134:	add	sp, sp, #0x30
 138:	ret

000000000000013c <emutls_get_address_array>:
 13c:	sub	sp, sp, #0x50
 140:	stp	x29, x30, [sp, #64]
 144:	add	x29, sp, #0x40
 148:	stur	x0, [x29, #-8]
 14c:	bl	594 <emutls_getspecific>
 150:	stur	x0, [x29, #-16]
 154:	ldur	x8, [x29, #-16]
 158:	cbnz	x8, 1b8 <emutls_get_address_array+0x7c>
 15c:	ldur	x0, [x29, #-8]
 160:	bl	500 <emutls_new_data_array_size>
 164:	stur	x0, [x29, #-24]
 168:	ldur	x0, [x29, #-24]
 16c:	bl	534 <emutls_asize>
 170:	bl	0 <malloc>
 174:	stur	x0, [x29, #-16]
 178:	ldur	x8, [x29, #-16]
 17c:	cbz	x8, 1a8 <emutls_get_address_array+0x6c>
 180:	ldur	x8, [x29, #-16]
 184:	add	x0, x8, #0x10
 188:	ldur	x8, [x29, #-24]
 18c:	mov	x9, #0x8                   	// #8
 190:	mul	x2, x8, x9
 194:	mov	w10, wzr
 198:	mov	w1, w10
 19c:	bl	0 <memset>
 1a0:	ldur	x8, [x29, #-16]
 1a4:	str	xzr, [x8]
 1a8:	ldur	x0, [x29, #-16]
 1ac:	ldur	x1, [x29, #-24]
 1b0:	bl	554 <emutls_check_array_set_size>
 1b4:	b	25c <emutls_get_address_array+0x120>
 1b8:	ldur	x8, [x29, #-8]
 1bc:	ldur	x9, [x29, #-16]
 1c0:	ldr	x9, [x9, #8]
 1c4:	cmp	x8, x9
 1c8:	b.ls	25c <emutls_get_address_array+0x120>  // b.plast
 1cc:	ldur	x8, [x29, #-16]
 1d0:	ldr	x8, [x8, #8]
 1d4:	str	x8, [sp, #32]
 1d8:	ldur	x0, [x29, #-8]
 1dc:	bl	500 <emutls_new_data_array_size>
 1e0:	str	x0, [sp, #24]
 1e4:	ldur	x0, [x29, #-16]
 1e8:	ldr	x8, [sp, #24]
 1ec:	str	x0, [sp, #16]
 1f0:	mov	x0, x8
 1f4:	bl	534 <emutls_asize>
 1f8:	ldr	x8, [sp, #16]
 1fc:	str	x0, [sp, #8]
 200:	mov	x0, x8
 204:	ldr	x1, [sp, #8]
 208:	bl	0 <realloc>
 20c:	stur	x0, [x29, #-16]
 210:	ldur	x8, [x29, #-16]
 214:	cbz	x8, 250 <emutls_get_address_array+0x114>
 218:	ldur	x8, [x29, #-16]
 21c:	add	x8, x8, #0x10
 220:	ldr	x9, [sp, #32]
 224:	mov	x10, #0x8                   	// #8
 228:	mul	x9, x10, x9
 22c:	add	x0, x8, x9
 230:	ldr	x8, [sp, #24]
 234:	ldr	x9, [sp, #32]
 238:	subs	x8, x8, x9
 23c:	mov	x9, #0x8                   	// #8
 240:	mul	x2, x8, x9
 244:	mov	w11, wzr
 248:	mov	w1, w11
 24c:	bl	0 <memset>
 250:	ldur	x0, [x29, #-16]
 254:	ldr	x1, [sp, #24]
 258:	bl	554 <emutls_check_array_set_size>
 25c:	ldur	x0, [x29, #-16]
 260:	ldp	x29, x30, [sp, #64]
 264:	add	sp, sp, #0x50
 268:	ret

000000000000026c <emutls_allocate_object>:
 26c:	sub	sp, sp, #0x30
 270:	stp	x29, x30, [sp, #32]
 274:	add	x29, sp, #0x20
 278:	stur	x0, [x29, #-8]
 27c:	ldur	x8, [x29, #-8]
 280:	ldr	x8, [x8]
 284:	str	x8, [sp, #16]
 288:	ldur	x8, [x29, #-8]
 28c:	ldr	x8, [x8, #8]
 290:	str	x8, [sp, #8]
 294:	ldr	x8, [sp, #8]
 298:	cmp	x8, #0x8
 29c:	b.cs	2a8 <emutls_allocate_object+0x3c>  // b.hs, b.nlast
 2a0:	mov	x8, #0x8                   	// #8
 2a4:	str	x8, [sp, #8]
 2a8:	ldr	x8, [sp, #8]
 2ac:	ldr	x9, [sp, #8]
 2b0:	subs	x9, x9, #0x1
 2b4:	and	x8, x8, x9
 2b8:	cbz	x8, 2c0 <emutls_allocate_object+0x54>
 2bc:	bl	0 <abort>
 2c0:	ldr	x0, [sp, #8]
 2c4:	ldr	x1, [sp, #16]
 2c8:	bl	5b4 <emutls_memalign_alloc>
 2cc:	str	x0, [sp]
 2d0:	ldur	x8, [x29, #-8]
 2d4:	ldr	x8, [x8, #24]
 2d8:	cbz	x8, 2f4 <emutls_allocate_object+0x88>
 2dc:	ldr	x0, [sp]
 2e0:	ldur	x8, [x29, #-8]
 2e4:	ldr	x1, [x8, #24]
 2e8:	ldr	x2, [sp, #16]
 2ec:	bl	0 <memcpy>
 2f0:	b	308 <emutls_allocate_object+0x9c>
 2f4:	ldr	x0, [sp]
 2f8:	ldr	x2, [sp, #16]
 2fc:	mov	w8, wzr
 300:	mov	w1, w8
 304:	bl	0 <memset>
 308:	ldr	x0, [sp]
 30c:	ldp	x29, x30, [sp, #32]
 310:	add	sp, sp, #0x30
 314:	ret

0000000000000318 <emutls_init_once>:
 318:	stp	x29, x30, [sp, #-16]!
 31c:	mov	x29, sp
 320:	adrp	x0, 0 <__emutls_get_address>
 324:	add	x0, x0, #0x0
 328:	adrp	x1, 0 <__emutls_get_address>
 32c:	add	x1, x1, #0x0
 330:	bl	0 <pthread_once>
 334:	ldp	x29, x30, [sp], #16
 338:	ret

000000000000033c <emutls_init>:
 33c:	stp	x29, x30, [sp, #-16]!
 340:	mov	x29, sp
 344:	adrp	x0, 0 <__emutls_get_address>
 348:	add	x0, x0, #0x0
 34c:	adrp	x1, 0 <__emutls_get_address>
 350:	add	x1, x1, #0x0
 354:	bl	0 <pthread_key_create>
 358:	cbz	w0, 360 <emutls_init+0x24>
 35c:	bl	0 <abort>
 360:	adrp	x8, 0 <__emutls_get_address>
 364:	add	x8, x8, #0x0
 368:	mov	w9, #0x1                   	// #1
 36c:	strb	w9, [x8]
 370:	ldp	x29, x30, [sp], #16
 374:	ret

0000000000000378 <emutls_key_destructor>:
 378:	sub	sp, sp, #0x20
 37c:	stp	x29, x30, [sp, #16]
 380:	add	x29, sp, #0x10
 384:	str	x0, [sp, #8]
 388:	ldr	x8, [sp, #8]
 38c:	str	x8, [sp]
 390:	ldr	x8, [sp]
 394:	ldr	x8, [x8]
 398:	cmp	x8, #0x0
 39c:	cset	w9, ls  // ls = plast
 3a0:	tbnz	w9, #0, 3c0 <emutls_key_destructor+0x48>
 3a4:	ldr	x8, [sp]
 3a8:	ldr	x9, [x8]
 3ac:	subs	x9, x9, #0x1
 3b0:	str	x9, [x8]
 3b4:	ldr	x0, [sp]
 3b8:	bl	3dc <emutls_setspecific>
 3bc:	b	3d0 <emutls_key_destructor+0x58>
 3c0:	ldr	x0, [sp]
 3c4:	bl	40c <emutls_shutdown>
 3c8:	ldr	x0, [sp, #8]
 3cc:	bl	0 <free>
 3d0:	ldp	x29, x30, [sp, #16]
 3d4:	add	sp, sp, #0x20
 3d8:	ret

00000000000003dc <emutls_setspecific>:
 3dc:	sub	sp, sp, #0x20
 3e0:	stp	x29, x30, [sp, #16]
 3e4:	add	x29, sp, #0x10
 3e8:	adrp	x8, 0 <__emutls_get_address>
 3ec:	add	x8, x8, #0x0
 3f0:	str	x0, [sp, #8]
 3f4:	ldr	w0, [x8]
 3f8:	ldr	x1, [sp, #8]
 3fc:	bl	0 <pthread_setspecific>
 400:	ldp	x29, x30, [sp, #16]
 404:	add	sp, sp, #0x20
 408:	ret

000000000000040c <emutls_shutdown>:
 40c:	sub	sp, sp, #0x20
 410:	stp	x29, x30, [sp, #16]
 414:	add	x29, sp, #0x10
 418:	str	x0, [sp, #8]
 41c:	ldr	x8, [sp, #8]
 420:	cbz	x8, 48c <emutls_shutdown+0x80>
 424:	str	xzr, [sp]
 428:	ldr	x8, [sp]
 42c:	ldr	x9, [sp, #8]
 430:	ldr	x9, [x9, #8]
 434:	cmp	x8, x9
 438:	b.cs	48c <emutls_shutdown+0x80>  // b.hs, b.nlast
 43c:	ldr	x8, [sp, #8]
 440:	add	x8, x8, #0x10
 444:	ldr	x9, [sp]
 448:	mov	x10, #0x8                   	// #8
 44c:	mul	x9, x10, x9
 450:	add	x8, x8, x9
 454:	ldr	x8, [x8]
 458:	cbz	x8, 47c <emutls_shutdown+0x70>
 45c:	ldr	x8, [sp, #8]
 460:	add	x8, x8, #0x10
 464:	ldr	x9, [sp]
 468:	mov	x10, #0x8                   	// #8
 46c:	mul	x9, x10, x9
 470:	add	x8, x8, x9
 474:	ldr	x0, [x8]
 478:	bl	498 <emutls_memalign_free>
 47c:	ldr	x8, [sp]
 480:	add	x8, x8, #0x1
 484:	str	x8, [sp]
 488:	b	428 <emutls_shutdown+0x1c>
 48c:	ldp	x29, x30, [sp, #16]
 490:	add	sp, sp, #0x20
 494:	ret

0000000000000498 <emutls_memalign_free>:
 498:	sub	sp, sp, #0x20
 49c:	stp	x29, x30, [sp, #16]
 4a0:	add	x29, sp, #0x10
 4a4:	str	x0, [sp, #8]
 4a8:	ldr	x8, [sp, #8]
 4ac:	mov	x9, #0xfffffffffffffff8    	// #-8
 4b0:	add	x8, x8, x9
 4b4:	ldr	x0, [x8]
 4b8:	bl	0 <free>
 4bc:	ldp	x29, x30, [sp, #16]
 4c0:	add	sp, sp, #0x20
 4c4:	ret

00000000000004c8 <emutls_lock>:
 4c8:	stp	x29, x30, [sp, #-16]!
 4cc:	mov	x29, sp
 4d0:	adrp	x0, 0 <__emutls_get_address>
 4d4:	add	x0, x0, #0x0
 4d8:	bl	0 <pthread_mutex_lock>
 4dc:	ldp	x29, x30, [sp], #16
 4e0:	ret

00000000000004e4 <emutls_unlock>:
 4e4:	stp	x29, x30, [sp, #-16]!
 4e8:	mov	x29, sp
 4ec:	adrp	x0, 0 <__emutls_get_address>
 4f0:	add	x0, x0, #0x0
 4f4:	bl	0 <pthread_mutex_unlock>
 4f8:	ldp	x29, x30, [sp], #16
 4fc:	ret

0000000000000500 <emutls_new_data_array_size>:
 500:	sub	sp, sp, #0x10
 504:	mov	x8, #0x2                   	// #2
 508:	str	x0, [sp, #8]
 50c:	str	x8, [sp]
 510:	ldr	x8, [sp, #8]
 514:	ldr	x9, [sp]
 518:	add	x8, x8, x9
 51c:	add	x8, x8, #0xf
 520:	and	x8, x8, #0xfffffffffffffff0
 524:	ldr	x9, [sp]
 528:	subs	x0, x8, x9
 52c:	add	sp, sp, #0x10
 530:	ret

0000000000000534 <emutls_asize>:
 534:	sub	sp, sp, #0x10
 538:	mov	x8, #0x8                   	// #8
 53c:	str	x0, [sp, #8]
 540:	ldr	x9, [sp, #8]
 544:	mul	x8, x9, x8
 548:	add	x0, x8, #0x10
 54c:	add	sp, sp, #0x10
 550:	ret

0000000000000554 <emutls_check_array_set_size>:
 554:	sub	sp, sp, #0x20
 558:	stp	x29, x30, [sp, #16]
 55c:	add	x29, sp, #0x10
 560:	str	x0, [sp, #8]
 564:	str	x1, [sp]
 568:	ldr	x8, [sp, #8]
 56c:	cbnz	x8, 574 <emutls_check_array_set_size+0x20>
 570:	bl	0 <abort>
 574:	ldr	x8, [sp]
 578:	ldr	x9, [sp, #8]
 57c:	str	x8, [x9, #8]
 580:	ldr	x0, [sp, #8]
 584:	bl	3dc <emutls_setspecific>
 588:	ldp	x29, x30, [sp, #16]
 58c:	add	sp, sp, #0x20
 590:	ret

0000000000000594 <emutls_getspecific>:
 594:	stp	x29, x30, [sp, #-16]!
 598:	mov	x29, sp
 59c:	adrp	x8, 0 <__emutls_get_address>
 5a0:	add	x8, x8, #0x0
 5a4:	ldr	w0, [x8]
 5a8:	bl	0 <pthread_getspecific>
 5ac:	ldp	x29, x30, [sp], #16
 5b0:	ret

00000000000005b4 <emutls_memalign_alloc>:
 5b4:	sub	sp, sp, #0x30
 5b8:	stp	x29, x30, [sp, #32]
 5bc:	add	x29, sp, #0x20
 5c0:	stur	x0, [x29, #-8]
 5c4:	str	x1, [sp, #16]
 5c8:	ldur	x8, [x29, #-8]
 5cc:	subs	x8, x8, #0x1
 5d0:	add	x8, x8, #0x8
 5d4:	ldr	x9, [sp, #16]
 5d8:	add	x0, x8, x9
 5dc:	bl	0 <malloc>
 5e0:	str	x0, [sp]
 5e4:	cbnz	x0, 5ec <emutls_memalign_alloc+0x38>
 5e8:	bl	0 <abort>
 5ec:	ldr	x8, [sp]
 5f0:	ldur	x9, [x29, #-8]
 5f4:	subs	x9, x9, #0x1
 5f8:	add	x9, x9, #0x8
 5fc:	add	x8, x8, x9
 600:	ldur	x9, [x29, #-8]
 604:	subs	x9, x9, #0x1
 608:	bic	x8, x8, x9
 60c:	str	x8, [sp, #8]
 610:	ldr	x8, [sp]
 614:	ldr	x9, [sp, #8]
 618:	mov	x10, #0xfffffffffffffff8    	// #-8
 61c:	add	x9, x9, x10
 620:	str	x8, [x9]
 624:	ldr	x0, [sp, #8]
 628:	ldp	x29, x30, [sp, #32]
 62c:	add	sp, sp, #0x30
 630:	ret

enable_execute_stack.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__enable_execute_stack>:
   0:	sub	sp, sp, #0x50
   4:	stp	x29, x30, [sp, #64]
   8:	add	x29, sp, #0x40
   c:	mov	w8, #0x1e                  	// #30
  10:	mov	w2, #0x7                   	// #7
  14:	stur	x0, [x29, #-8]
  18:	mov	w0, w8
  1c:	str	w2, [sp, #4]
  20:	bl	0 <sysconf>
  24:	stur	x0, [x29, #-16]
  28:	ldur	x9, [x29, #-16]
  2c:	subs	x9, x9, #0x1
  30:	mvn	x9, x9
  34:	stur	x9, [x29, #-24]
  38:	ldur	x9, [x29, #-8]
  3c:	str	x9, [sp, #32]
  40:	ldr	x9, [sp, #32]
  44:	ldur	x10, [x29, #-24]
  48:	and	x9, x9, x10
  4c:	str	x9, [sp, #24]
  50:	ldr	x9, [sp, #32]
  54:	add	x9, x9, #0x30
  58:	ldur	x10, [x29, #-16]
  5c:	add	x9, x9, x10
  60:	ldur	x10, [x29, #-24]
  64:	and	x9, x9, x10
  68:	str	x9, [sp, #16]
  6c:	ldr	x9, [sp, #16]
  70:	ldr	x10, [sp, #24]
  74:	subs	x9, x9, x10
  78:	str	x9, [sp, #8]
  7c:	ldr	x0, [sp, #24]
  80:	ldr	x1, [sp, #8]
  84:	ldr	w2, [sp, #4]
  88:	bl	0 <mprotect>
  8c:	ldp	x29, x30, [sp, #64]
  90:	add	sp, sp, #0x50
  94:	ret

eprintf.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__eprintf>:
   0:	sub	sp, sp, #0x50
   4:	stp	x29, x30, [sp, #64]
   8:	add	x29, sp, #0x40
   c:	adrp	x8, 0 <stderr>
  10:	ldr	x8, [x8]
  14:	adrp	x9, 0 <__eprintf>
  18:	add	x9, x9, #0x0
  1c:	mov	w10, #0x1a                  	// #26
  20:	adrp	x11, 0 <__eprintf>
  24:	add	x11, x11, #0x0
  28:	stur	x0, [x29, #-8]
  2c:	stur	x1, [x29, #-16]
  30:	stur	x2, [x29, #-24]
  34:	str	x3, [sp, #32]
  38:	ldr	x0, [x8]
  3c:	ldur	x1, [x29, #-8]
  40:	ldur	x2, [x29, #-16]
  44:	ldur	x3, [x29, #-24]
  48:	ldr	x4, [sp, #32]
  4c:	str	x8, [sp, #24]
  50:	str	x9, [sp, #16]
  54:	str	w10, [sp, #12]
  58:	str	x11, [sp]
  5c:	bl	0 <fprintf>
  60:	ldr	x8, [sp, #24]
  64:	ldr	x9, [x8]
  68:	mov	x0, x9
  6c:	bl	0 <fflush>
  70:	ldr	x8, [sp, #16]
  74:	mov	x0, x8
  78:	ldr	w1, [sp, #12]
  7c:	ldr	x2, [sp]
  80:	bl	0 <__compilerrt_abort_impl>

gcc_personality_v0.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__gcc_personality_v0>:
   0:	sub	sp, sp, #0xa0
   4:	stp	x29, x30, [sp, #144]
   8:	add	x29, sp, #0x90
   c:	stur	w0, [x29, #-8]
  10:	stur	w1, [x29, #-12]
  14:	stur	x2, [x29, #-24]
  18:	stur	x3, [x29, #-32]
  1c:	stur	x4, [x29, #-40]
  20:	ldur	w8, [x29, #-12]
  24:	and	w8, w8, #0x1
  28:	cbz	w8, 40 <__gcc_personality_v0+0x40>
  2c:	ldur	x0, [x29, #-32]
  30:	ldur	x1, [x29, #-40]
  34:	bl	21c <continueUnwind>
  38:	stur	w0, [x29, #-4]
  3c:	b	20c <__gcc_personality_v0+0x20c>
  40:	ldur	x0, [x29, #-40]
  44:	bl	0 <_Unwind_GetLanguageSpecificData>
  48:	stur	x0, [x29, #-48]
  4c:	ldur	x8, [x29, #-48]
  50:	cbnz	x8, 68 <__gcc_personality_v0+0x68>
  54:	ldur	x0, [x29, #-32]
  58:	ldur	x1, [x29, #-40]
  5c:	bl	21c <continueUnwind>
  60:	stur	w0, [x29, #-4]
  64:	b	20c <__gcc_personality_v0+0x20c>
  68:	ldur	x0, [x29, #-40]
  6c:	bl	0 <_Unwind_GetIP>
  70:	subs	x8, x0, #0x1
  74:	stur	x8, [x29, #-56]
  78:	ldur	x0, [x29, #-40]
  7c:	bl	0 <_Unwind_GetRegionStart>
  80:	stur	x0, [x29, #-64]
  84:	ldur	x8, [x29, #-56]
  88:	ldur	x9, [x29, #-64]
  8c:	subs	x8, x8, x9
  90:	str	x8, [sp, #72]
  94:	ldur	x8, [x29, #-48]
  98:	add	x9, x8, #0x1
  9c:	stur	x9, [x29, #-48]
  a0:	ldrb	w10, [x8]
  a4:	strb	w10, [sp, #71]
  a8:	ldrb	w10, [sp, #71]
  ac:	cmp	w10, #0xff
  b0:	b.eq	c0 <__gcc_personality_v0+0xc0>  // b.none
  b4:	ldrb	w1, [sp, #71]
  b8:	sub	x0, x29, #0x30
  bc:	bl	238 <readEncodedPointer>
  c0:	ldur	x8, [x29, #-48]
  c4:	add	x9, x8, #0x1
  c8:	stur	x9, [x29, #-48]
  cc:	ldrb	w10, [x8]
  d0:	strb	w10, [sp, #70]
  d4:	ldrb	w10, [sp, #70]
  d8:	cmp	w10, #0xff
  dc:	b.eq	e8 <__gcc_personality_v0+0xe8>  // b.none
  e0:	sub	x0, x29, #0x30
  e4:	bl	470 <readULEB128>
  e8:	sub	x0, x29, #0x30
  ec:	ldur	x8, [x29, #-48]
  f0:	add	x9, x8, #0x1
  f4:	stur	x9, [x29, #-48]
  f8:	ldrb	w10, [x8]
  fc:	strb	w10, [sp, #69]
 100:	bl	470 <readULEB128>
 104:	str	w0, [sp, #64]
 108:	ldur	x8, [x29, #-48]
 10c:	str	x8, [sp, #56]
 110:	ldr	x8, [sp, #56]
 114:	ldr	w10, [sp, #64]
 118:	mov	w9, w10
 11c:	add	x8, x8, x9
 120:	str	x8, [sp, #48]
 124:	ldr	x8, [sp, #56]
 128:	str	x8, [sp, #40]
 12c:	ldr	x8, [sp, #40]
 130:	ldr	x9, [sp, #48]
 134:	cmp	x8, x9
 138:	b.cs	1fc <__gcc_personality_v0+0x1fc>  // b.hs, b.nlast
 13c:	ldrb	w1, [sp, #69]
 140:	add	x8, sp, #0x28
 144:	mov	x0, x8
 148:	str	x8, [sp, #8]
 14c:	bl	238 <readEncodedPointer>
 150:	str	x0, [sp, #32]
 154:	ldrb	w1, [sp, #69]
 158:	ldr	x0, [sp, #8]
 15c:	bl	238 <readEncodedPointer>
 160:	str	x0, [sp, #24]
 164:	ldrb	w1, [sp, #69]
 168:	ldr	x0, [sp, #8]
 16c:	bl	238 <readEncodedPointer>
 170:	str	x0, [sp, #16]
 174:	ldr	x0, [sp, #8]
 178:	bl	470 <readULEB128>
 17c:	ldr	x8, [sp, #16]
 180:	cbnz	x8, 188 <__gcc_personality_v0+0x188>
 184:	b	12c <__gcc_personality_v0+0x12c>
 188:	ldr	x8, [sp, #32]
 18c:	ldr	x9, [sp, #72]
 190:	cmp	x8, x9
 194:	b.hi	1f8 <__gcc_personality_v0+0x1f8>  // b.pmore
 198:	ldr	x8, [sp, #72]
 19c:	ldr	x9, [sp, #32]
 1a0:	ldr	x10, [sp, #24]
 1a4:	add	x9, x9, x10
 1a8:	cmp	x8, x9
 1ac:	b.cs	1f8 <__gcc_personality_v0+0x1f8>  // b.hs, b.nlast
 1b0:	ldur	x0, [x29, #-40]
 1b4:	ldur	x2, [x29, #-32]
 1b8:	mov	w8, wzr
 1bc:	mov	w1, w8
 1c0:	bl	0 <_Unwind_SetGR>
 1c4:	ldur	x0, [x29, #-40]
 1c8:	mov	w1, #0x1                   	// #1
 1cc:	mov	x9, xzr
 1d0:	mov	x2, x9
 1d4:	bl	0 <_Unwind_SetGR>
 1d8:	ldur	x0, [x29, #-40]
 1dc:	ldur	x9, [x29, #-64]
 1e0:	ldr	x10, [sp, #16]
 1e4:	add	x1, x9, x10
 1e8:	bl	0 <_Unwind_SetIP>
 1ec:	mov	w8, #0x7                   	// #7
 1f0:	stur	w8, [x29, #-4]
 1f4:	b	20c <__gcc_personality_v0+0x20c>
 1f8:	b	12c <__gcc_personality_v0+0x12c>
 1fc:	ldur	x0, [x29, #-32]
 200:	ldur	x1, [x29, #-40]
 204:	bl	21c <continueUnwind>
 208:	stur	w0, [x29, #-4]
 20c:	ldur	w0, [x29, #-4]
 210:	ldp	x29, x30, [sp, #144]
 214:	add	sp, sp, #0xa0
 218:	ret

000000000000021c <continueUnwind>:
 21c:	sub	sp, sp, #0x10
 220:	mov	w8, #0x8                   	// #8
 224:	str	x0, [sp, #8]
 228:	str	x1, [sp]
 22c:	mov	w0, w8
 230:	add	sp, sp, #0x10
 234:	ret

0000000000000238 <readEncodedPointer>:
 238:	sub	sp, sp, #0x50
 23c:	stp	x29, x30, [sp, #64]
 240:	add	x29, sp, #0x40
 244:	stur	x0, [x29, #-16]
 248:	sturb	w1, [x29, #-17]
 24c:	ldur	x8, [x29, #-16]
 250:	ldr	x8, [x8]
 254:	str	x8, [sp, #32]
 258:	str	xzr, [sp, #24]
 25c:	ldurb	w9, [x29, #-17]
 260:	cmp	w9, #0xff
 264:	b.ne	270 <readEncodedPointer+0x38>  // b.any
 268:	stur	xzr, [x29, #-8]
 26c:	b	460 <readEncodedPointer+0x228>
 270:	ldurb	w8, [x29, #-17]
 274:	and	w8, w8, #0xf
 278:	subs	w8, w8, #0x0
 27c:	mov	w9, w8
 280:	ubfx	x9, x9, #0, #32
 284:	cmp	x9, #0xc
 288:	str	x9, [sp, #16]
 28c:	b.hi	384 <readEncodedPointer+0x14c>  // b.pmore
 290:	adrp	x8, 0 <__gcc_personality_v0>
 294:	add	x8, x8, #0x0
 298:	ldr	x11, [sp, #16]
 29c:	ldrsw	x10, [x8, x11, lsl #2]
 2a0:	add	x9, x8, x10
 2a4:	br	x9
 2a8:	ldr	x8, [sp, #32]
 2ac:	ldr	x8, [x8]
 2b0:	str	x8, [sp, #24]
 2b4:	ldr	x8, [sp, #32]
 2b8:	add	x8, x8, #0x8
 2bc:	str	x8, [sp, #32]
 2c0:	b	39c <readEncodedPointer+0x164>
 2c4:	add	x0, sp, #0x20
 2c8:	bl	470 <readULEB128>
 2cc:	str	x0, [sp, #24]
 2d0:	b	39c <readEncodedPointer+0x164>
 2d4:	ldr	x8, [sp, #32]
 2d8:	ldrh	w9, [x8]
 2dc:	mov	w8, w9
 2e0:	str	x8, [sp, #24]
 2e4:	ldr	x8, [sp, #32]
 2e8:	add	x8, x8, #0x2
 2ec:	str	x8, [sp, #32]
 2f0:	b	39c <readEncodedPointer+0x164>
 2f4:	ldr	x8, [sp, #32]
 2f8:	ldr	w9, [x8]
 2fc:	mov	w8, w9
 300:	str	x8, [sp, #24]
 304:	ldr	x8, [sp, #32]
 308:	add	x8, x8, #0x4
 30c:	str	x8, [sp, #32]
 310:	b	39c <readEncodedPointer+0x164>
 314:	ldr	x8, [sp, #32]
 318:	ldr	x8, [x8]
 31c:	str	x8, [sp, #24]
 320:	ldr	x8, [sp, #32]
 324:	add	x8, x8, #0x8
 328:	str	x8, [sp, #32]
 32c:	b	39c <readEncodedPointer+0x164>
 330:	ldr	x8, [sp, #32]
 334:	ldrsh	x8, [x8]
 338:	str	x8, [sp, #24]
 33c:	ldr	x8, [sp, #32]
 340:	add	x8, x8, #0x2
 344:	str	x8, [sp, #32]
 348:	b	39c <readEncodedPointer+0x164>
 34c:	ldr	x8, [sp, #32]
 350:	ldrsw	x8, [x8]
 354:	str	x8, [sp, #24]
 358:	ldr	x8, [sp, #32]
 35c:	add	x8, x8, #0x4
 360:	str	x8, [sp, #32]
 364:	b	39c <readEncodedPointer+0x164>
 368:	ldr	x8, [sp, #32]
 36c:	ldr	x8, [x8]
 370:	str	x8, [sp, #24]
 374:	ldr	x8, [sp, #32]
 378:	add	x8, x8, #0x8
 37c:	str	x8, [sp, #32]
 380:	b	39c <readEncodedPointer+0x164>
 384:	adrp	x0, 0 <__gcc_personality_v0>
 388:	add	x0, x0, #0x0
 38c:	mov	w1, #0x68                  	// #104
 390:	adrp	x2, 0 <__gcc_personality_v0>
 394:	add	x2, x2, #0x0
 398:	bl	0 <__compilerrt_abort_impl>
 39c:	ldurb	w8, [x29, #-17]
 3a0:	and	w8, w8, #0x70
 3a4:	str	w8, [sp, #12]
 3a8:	cbz	w8, 400 <readEncodedPointer+0x1c8>
 3ac:	b	3b0 <readEncodedPointer+0x178>
 3b0:	ldr	w8, [sp, #12]
 3b4:	cmp	w8, #0x10
 3b8:	b.eq	404 <readEncodedPointer+0x1cc>  // b.none
 3bc:	b	3c0 <readEncodedPointer+0x188>
 3c0:	ldr	w8, [sp, #12]
 3c4:	cmp	w8, #0x20
 3c8:	b.eq	41c <readEncodedPointer+0x1e4>  // b.none
 3cc:	b	3d0 <readEncodedPointer+0x198>
 3d0:	ldr	w8, [sp, #12]
 3d4:	cmp	w8, #0x30
 3d8:	b.eq	41c <readEncodedPointer+0x1e4>  // b.none
 3dc:	b	3e0 <readEncodedPointer+0x1a8>
 3e0:	ldr	w8, [sp, #12]
 3e4:	cmp	w8, #0x40
 3e8:	b.eq	41c <readEncodedPointer+0x1e4>  // b.none
 3ec:	b	3f0 <readEncodedPointer+0x1b8>
 3f0:	ldr	w8, [sp, #12]
 3f4:	cmp	w8, #0x50
 3f8:	b.eq	41c <readEncodedPointer+0x1e4>  // b.none
 3fc:	b	41c <readEncodedPointer+0x1e4>
 400:	b	434 <readEncodedPointer+0x1fc>
 404:	ldur	x8, [x29, #-16]
 408:	ldr	x8, [x8]
 40c:	ldr	x9, [sp, #24]
 410:	add	x8, x9, x8
 414:	str	x8, [sp, #24]
 418:	b	434 <readEncodedPointer+0x1fc>
 41c:	adrp	x0, 0 <__gcc_personality_v0>
 420:	add	x0, x0, #0x0
 424:	mov	w1, #0x7a                  	// #122
 428:	adrp	x2, 0 <__gcc_personality_v0>
 42c:	add	x2, x2, #0x0
 430:	bl	0 <__compilerrt_abort_impl>
 434:	ldurb	w8, [x29, #-17]
 438:	and	w8, w8, #0x80
 43c:	cbz	w8, 44c <readEncodedPointer+0x214>
 440:	ldr	x8, [sp, #24]
 444:	ldr	x8, [x8]
 448:	str	x8, [sp, #24]
 44c:	ldr	x8, [sp, #32]
 450:	ldur	x9, [x29, #-16]
 454:	str	x8, [x9]
 458:	ldr	x8, [sp, #24]
 45c:	stur	x8, [x29, #-8]
 460:	ldur	x0, [x29, #-8]
 464:	ldp	x29, x30, [sp, #64]
 468:	add	sp, sp, #0x50
 46c:	ret

0000000000000470 <readULEB128>:
 470:	sub	sp, sp, #0x30
 474:	str	x0, [sp, #40]
 478:	str	xzr, [sp, #32]
 47c:	str	xzr, [sp, #24]
 480:	ldr	x8, [sp, #40]
 484:	ldr	x8, [x8]
 488:	str	x8, [sp, #8]
 48c:	ldr	x8, [sp, #8]
 490:	add	x9, x8, #0x1
 494:	str	x9, [sp, #8]
 498:	ldrb	w10, [x8]
 49c:	strb	w10, [sp, #23]
 4a0:	ldrb	w10, [sp, #23]
 4a4:	and	w10, w10, #0x7f
 4a8:	ldr	x8, [sp, #24]
 4ac:	lsl	w8, w10, w8
 4b0:	mov	w0, w8
 4b4:	sxtw	x9, w0
 4b8:	ldr	x11, [sp, #32]
 4bc:	orr	x9, x11, x9
 4c0:	str	x9, [sp, #32]
 4c4:	ldr	x9, [sp, #24]
 4c8:	add	x9, x9, #0x7
 4cc:	str	x9, [sp, #24]
 4d0:	ldrb	w8, [sp, #23]
 4d4:	and	w8, w8, #0x80
 4d8:	cbnz	w8, 48c <readULEB128+0x1c>
 4dc:	ldr	x8, [sp, #8]
 4e0:	ldr	x9, [sp, #40]
 4e4:	str	x8, [x9]
 4e8:	ldr	x0, [sp, #32]
 4ec:	add	sp, sp, #0x30
 4f0:	ret

clear_cache.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__clear_cache>:
   0:	sub	sp, sp, #0x40
   4:	str	x0, [sp, #56]
   8:	str	x1, [sp, #48]
   c:	ldr	x8, [sp, #56]
  10:	str	x8, [sp, #40]
  14:	ldr	x8, [sp, #48]
  18:	str	x8, [sp, #32]
  1c:	adrp	x8, 0 <__clear_cache>
  20:	ldr	x8, [x8]
  24:	cbnz	x8, 3c <__clear_cache+0x3c>
  28:	b	2c <__clear_cache+0x2c>
  2c:	mrs	x8, ctr_el0
  30:	adrp	x9, 0 <__clear_cache>
  34:	str	x8, [x9]
  38:	b	3c <__clear_cache+0x3c>
  3c:	adrp	x8, 0 <__clear_cache>
  40:	ldr	x8, [x8]
  44:	tbnz	w8, #28, c0 <__clear_cache+0xc0>
  48:	b	4c <__clear_cache+0x4c>
  4c:	adrp	x8, 0 <__clear_cache>
  50:	ldr	x8, [x8]
  54:	ubfx	x8, x8, #16, #4
  58:	mov	w9, #0x4                   	// #4
  5c:	lsl	w8, w9, w8
  60:	mov	w0, w8
  64:	sxtw	x10, w0
  68:	str	x10, [sp, #16]
  6c:	ldr	x10, [sp, #40]
  70:	ldr	x11, [sp, #16]
  74:	mov	x12, xzr
  78:	subs	x11, x12, x11
  7c:	and	x10, x10, x11
  80:	str	x10, [sp, #24]
  84:	b	88 <__clear_cache+0x88>
  88:	ldr	x8, [sp, #24]
  8c:	ldr	x9, [sp, #32]
  90:	subs	x8, x8, x9
  94:	b.cs	bc <__clear_cache+0xbc>  // b.hs, b.nlast
  98:	b	9c <__clear_cache+0x9c>
  9c:	ldr	x8, [sp, #24]
  a0:	dc	cvau, x8
  a4:	b	a8 <__clear_cache+0xa8>
  a8:	ldr	x8, [sp, #16]
  ac:	ldr	x9, [sp, #24]
  b0:	add	x8, x9, x8
  b4:	str	x8, [sp, #24]
  b8:	b	88 <__clear_cache+0x88>
  bc:	b	c0 <__clear_cache+0xc0>
  c0:	dsb	ish
  c4:	adrp	x8, 0 <__clear_cache>
  c8:	ldr	x8, [x8]
  cc:	tbnz	w8, #29, 148 <__clear_cache+0x148>
  d0:	b	d4 <__clear_cache+0xd4>
  d4:	adrp	x8, 0 <__clear_cache>
  d8:	ldr	x8, [x8]
  dc:	and	x8, x8, #0xf
  e0:	mov	w9, #0x4                   	// #4
  e4:	lsl	w8, w9, w8
  e8:	mov	w0, w8
  ec:	sxtw	x10, w0
  f0:	str	x10, [sp, #8]
  f4:	ldr	x10, [sp, #40]
  f8:	ldr	x11, [sp, #8]
  fc:	mov	x12, xzr
 100:	subs	x11, x12, x11
 104:	and	x10, x10, x11
 108:	str	x10, [sp, #24]
 10c:	b	110 <__clear_cache+0x110>
 110:	ldr	x8, [sp, #24]
 114:	ldr	x9, [sp, #32]
 118:	subs	x8, x8, x9
 11c:	b.cs	144 <__clear_cache+0x144>  // b.hs, b.nlast
 120:	b	124 <__clear_cache+0x124>
 124:	ldr	x8, [sp, #24]
 128:	ic	ivau, x8
 12c:	b	130 <__clear_cache+0x130>
 130:	ldr	x8, [sp, #8]
 134:	ldr	x9, [sp, #24]
 138:	add	x8, x9, x8
 13c:	str	x8, [sp, #24]
 140:	b	110 <__clear_cache+0x110>
 144:	b	148 <__clear_cache+0x148>
 148:	isb
 14c:	add	sp, sp, #0x40
 150:	ret

fp_mode.c.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <__fe_getround>:
   0:	sub	sp, sp, #0x20
   4:	mrs	x8, fpcr
   8:	str	x8, [sp, #16]
   c:	ldr	x8, [sp, #16]
  10:	ubfx	x8, x8, #22, #2
  14:	str	x8, [sp, #16]
  18:	ldr	x8, [sp, #16]
  1c:	mov	x9, x8
  20:	subs	x8, x8, #0x3
  24:	str	x9, [sp, #8]
  28:	b.hi	6c <__fe_getround+0x6c>  // b.pmore
  2c:	adrp	x8, 0 <__fe_getround>
  30:	add	x8, x8, #0x0
  34:	ldr	x11, [sp, #8]
  38:	ldrsw	x10, [x8, x11, lsl #2]
  3c:	add	x9, x8, x10
  40:	br	x9
  44:	mov	w8, #0x2                   	// #2
  48:	str	w8, [sp, #28]
  4c:	b	78 <__fe_getround+0x78>
  50:	mov	w8, #0x1                   	// #1
  54:	str	w8, [sp, #28]
  58:	b	78 <__fe_getround+0x78>
  5c:	mov	w8, #0x3                   	// #3
  60:	str	w8, [sp, #28]
  64:	b	78 <__fe_getround+0x78>
  68:	b	6c <__fe_getround+0x6c>
  6c:	mov	w8, wzr
  70:	str	w8, [sp, #28]
  74:	b	78 <__fe_getround+0x78>
  78:	ldr	w0, [sp, #28]
  7c:	add	sp, sp, #0x20
  80:	ret

0000000000000084 <__fe_raise_inexact>:
  84:	sub	sp, sp, #0x10
  88:	mrs	x8, fpsr
  8c:	str	x8, [sp, #8]
  90:	ldr	x8, [sp, #8]
  94:	orr	x8, x8, #0x10
  98:	msr	fpsr, x8
  9c:	mov	w0, wzr
  a0:	add	sp, sp, #0x10
  a4:	ret
